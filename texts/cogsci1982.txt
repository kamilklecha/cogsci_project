UntitledConscious, Subconscious, Unconscious: A Neodissoclatlon Perspective John F.
 Kihlstrom University of Wisconsin What gives us the impression that we are conscious? What kind of evidence would convince us that a machine such as a computer, or a lower animal such as a dolphin or a chimpanzee, or — for that matter — another hvman being, was conscious? Cognitive scientists of all stripes, especially those who specialize in psychology, philosophy, and artificial intelligence, disagree violently on the answers, and even on whether these are sensible questions.
 But nobody doubts that we humans, at least, possess consciousness.
 The facts that erase any doubt about ourselves are the facts of experience.
 As James put it in the Principles, "the first fact for us, then.
 .
 .
is that thinking of some sort goes on" (p.
 224).
 Introspectively, the experience of consciousness seems to have to do with two things: monitoring ourselves and our environment, such that certain perceptual events and memories come to be accurately represented in phenomenal awareness; and controlling ourselves and our environment, such that we are able to voluntarily initiate and terminate behavioral and cognitive activities.
 Cognitive science has been vexed by the problem of consciousness since its prehistory.
 It has had a checkered past, for example, in psychology: almost the whole of the field for James, but a virtual nonentity with the onslaught of the behaviorist movement.
 Interest in the topic persisted in the hands of the psychoanalysts, aol was revived within mainstream psychology with the cognitive revolution and its emphasis on attention and the span of apprehension.
 Neurologists commonly encounter disorders of consciousness of various types, and those associated with the "splitbrain" syndrome have recently received much notice.
 Ethologists and behavioral biologists have considered whether lower animals possess the capacity for awareness and voluntary control over their actions — though this concern within comparative psychology has been supplanted to some degree by a series of similar questions having to do with the capacity for language.
 Parallel concerns have sometimes caught the fancy of those in the artificial intelligence movement, who must deal with the question of whether computers will ever possess consciousness in the sense of awareness and voluntary control over what they are doing.
 The problems posed by the experience of consciousness for contemporary cognitive science boil down to questions like these: What is the nature of consciousness? What is it good for? Are there unconscious mental processes, and if so what are they like and what are they good for? Finally, who cares? That is, would cognitive science proceed any differently if its practitioners did not ask questions like these? Let us get some perspective on these questions by turning to some early authorities, before examining some more recent theoretical and empirical developments.
 William James devoted the better part of four chapters of the Principles to the topic of consciousness.
 At the same time, he argued vigorously against the notion of unconscious thought, although he did agree that there were brain processes associated with mental activity of which «e might not be aware.
 As if in warning to Freud and the other psychoanalysts who were to follow, James asserted that the concept of unconscious states of mind "is the sovereign means of believing what one likes in psychology, and of turning what might become a science into a tumblingground for whimsies" (p.
 163).
 But the Freudian psychology which was yet to come shared the force of James' critique with other trends in the psychology of his time, such as those which implicated unconscious inference in perception and judgment.
 To the contrary, he argued that either the allegedly unconscious thought was rapidly forgotten; or that it represented a revision of an earlier (and conscious) thought; or that it was not a thought at all, but merely an innate or habittial brain process.
 For James, thought and consciousness were identical.
 It was as difficult for him to contemplate unconscious thought as it was for Hume to contemplate a round square cupola on Berkeley College.
 Nevertheless, James did admit that under some circumstances "the total possible consciousness may be split into parts which coexist but mutually ignore each other, and share the objects of knowledge between them" (p.
 206).
 Following Janet and Prince, from whom he drew most of his examples, he referred to this phenomenon as representing "secondary" consciousness, rather than "unconsciousness.
" In order to understand what James had in mind, it is necessary to consider an important but almostforgotten school of thought within psychiatry and psychology at the turn of the century.
 It is commonly thought that the concept of unconscious mental processes traces its origin to Freud and the theory of psychoanalysis.
 To the contrary, as Ellenberger has shown, the idea has a long history before Freud.
 In 1775, with the appearance of Mesmer on the European medical scene, speculation about the unconscious combined with rationalized, materialistic versions of primitive psychotherapeutic procedures to form what is known as the First Dynamic Psychiatry, whose leader was the French neurologist and psychiatrist J.
M.
 Charcot.
 This psychiatry was concerned with demonstrable "functional" as opposed to "organic" mental illnesses — that is, those pathological syndromes which appeared not to be associated with brain insult, injury, or disease.
 It attempted to account for a wide range of phenomena, including hysteria, fugue (then called ambulatory automatism), and multiple personality; the "magnetic diseases" of catalepsy, lethargy, and somnambulism (so named because of their resemblance to certain phenomena of animal magnetism, a precursor of hypnosis); spiritistic practices such as automatic writing and crystalgazing; hypnosis; and suggestibility In the normal waking state.
 Each of these phenomena, the school held, represented the power of ideits to turn into action (one of the meanings of "dynamic" in the psychological sense); and each seemed to reflect a change in consciousness, as thought and actions occurred outside phenomenal awareness and voluntary control.
 The First Dynamic Psychiatry, with its emphasis on unconscious mental contents and processes, invoked one or another of two explicit models of the mind.
 The point of view known as dipsychism (e.
g.
, Dessoir) held that the mind consisted of two layers, each of which in turn consisted of chains 1 of assoclaclons.
 The "upper consciousness" uas active In Che normal waking stace, while Che "lower consciousness" was active in such phenomena as dreams, hysteria, and hypnosis.
 According Co Che "closed" version of dlpsychlsm, the lower consciousness contained mental contents which passed into it through the upper consciousness: unattended stimuli, forgotten memories, and various daydreams and fantasies.
 This point of view contrasts with Che less materialistic "open" version.
 In which the lower consciousness uas held to be In direct communication with other minds.
 According to polypsychism (e.
g.
, Durand de Gros), each segment of Che anatomy was served by its own mental structures, called egos, each of which was capable of perception, memory, and thought.
 These structures, in turn, were subject to the control of a superordlnace structure which was identified with normal consciousness.
 When the link between subordinate and superordlnate egos was broken, certain aspects of cognition and action were carried out subconsciously.
 Clearly, the concepts of dlpsychlsm and polypsychism are at the root of Freud's first (consciouspreconsclousunconscious) and second (Idegosuperego) models of the mind.
 The issues confronted by the First Dynamic Psychiatry were subsequently taken up by another French psychiatrist, Pierre Janet.
 Following the principle of analysisthensynthesis familiar in physiology, Janet began by considering the elementary parts of the mental system.
 Instead of following the lead of the earlier faculty psychology, or the chanlcal analogies of the structuralists, he argued that the elementary structures of the mind were psychological automatisms; complex acts, tuned to environmental and personal circumstances, proceeded by an Idea and accompanied by an emotion.
 Each of these psychological automatisms, by combining cognition, conation, and emotion with action, represented a rudimentary consciousness.
 According to Janet, all of these elementary automatisms ordinarily were bound together into a single, united stream of consciousness, and operated in awareness and under voluntary control.
 Under certain circumstances, however, one or more of these automatisms could be split off — Janet's term was disaggregation — from the rest, functioning either outside awareness, or voluntary control, or both.
 This dissociation view of the unconscious, as distinct from the repression view elaborated by Freud and his followers, was further developed by the American psychologist and psychiatrist Morton Prince.
 Prince, following the practice of his day as exemplified by James' ten arguments against the existence of unconscious thoughts, reserved the term "unconscious" for Che dormant traces of forgotten memories and unattended perceptual inputs, as well as the strictly neurophyslological processes associated with mental activity.
 Instead, he offered Che cerm coconscloua.
 referring CO menCal accivity which cakes place oucslde phenomenal awareness.
 Prince preferred this term because it connoted mental activity rather than the lack of mencadon (as in Che ordinarylanguage conception of unconsciousness associated with concussion or coma); and because It permitted the division of consciousness Into parallel streams wlchouc one or more of Chese being oucslde awareness.
 Coconsclous mental acclvicies performed oucslde awareness, togecher with unconscious mental concents and brain processes, formed Che subconscious.
 This conceptualization of consciousness was very popular on both sides of the Atlantic, featured prominently In the pages of the thennew Journal of Abnormal and Social Psychology (founded and edited by Prince), and was the chief alternative within dynamic psychiacry Co Freudian psychoanalysis.
 However, IC was a.
 concepcuallzatlon which was shortlived.
 The eventual dominance of psychoanalysis in clinical psychology and scientific personology led investigators to be interested In different syndromes and phenomena, a different model of the mind, and the eventual replacement of dissociation by repression as the hypothetical mechanism for blocking mental contents from consciousness.
 At the same time, the behavlorlst revolution in academic psychology removed consciousness (not to mention the unconscious) from the vocabulary of the science.
 At fault as well were the dissociation theorists themselves, who often made extravagant claims for the centrallty of their phenomenon and whose Investigations were often methodologically flawed.
 The final blow to the concept stemmed from the interpretation that dissociated streams of consciousness, because they were Ignorant (Janet's term) of each other, should not Influence each other.
 Numerous demonstrations of mutual Interference between ostensibly dissociated tasks showed the contrary, and reference to dissociation gradually disappeared.
 In part, the Insistence of both early and late dissociation theorists of noninterference between dissociated mental activities seems Co stem from a misunderstanding of James' metaphor of the stream of consciousness.
 Following the metaphor, it is sometimes held that two screams of wacer, running parallel but separated by tall banks, should not affect each other.
 However, If the two streams originate from the same source, each will certainly draw some of the flow from the other.
 Given a model of attention such as Kahneman's, in which a single source of attentlonal capacity may be deployed in multiple directions, James' metaphor would certainly lead one to predict some degree of mutual Interference between simultaneous, thought dissociated, tasks.
 In fact, the available evidence indicates that simultaneous tasks performed outside of awareness (for example, in hypnosis) do interfere with each other, with the extent of interference a function of the attentlonal demands of the tasks in question.
 Where the tasks are easy, there is little or no Interference; where one or both are difficult.
 Interference increases proportionately.
 Awareness and control are the defining feature of dissociation, while noninterference Is an open, empirical question.
 Viewed In these terms, a number of phenomena — observed in the laboratory, the clinic, and in the ordinary course of everyday living — seem to invite a notion such as dissociation.
 Some of the observations are dramatic, some mundane; the quality of some of the research is impeccable; some demonstrations are marred by poor methodology or contaminated by extraneous socialpsychological variables.
 Some of the results are open to alternative interpretations, and the possibility of performing a definitive experiment seems slim.
 Some of the claims, in fact, may turn out on close investigation to be false.
 But not all of them are false.
 To deny some of them is to deny the facts of our everyday experience.
 In each of these instances, some aspect of past or present experience cannot be brought into phenomenal awareness, or voluntary control has been lost over thought and action.
 Consider, first, the observations of cerebral commlsuotomy patients (and incacc subjeccs run under special laboracory condlclons), whose rlghc hand literally does not know what Che left one is doing: Here is a division in consciousness associated with a literal division in brain structures.
 Or consider Korsakoff's syndrooe, whose dominant feature is an extremely dense anterograde amnesia: recent experiments have revealed, somewhat surprisingly, that these patients can acquire new information, and that this new learning can have an impact on subsequent cognition and action — even though the patients have no recollection of the learning experience, and cannot voluntarily retrieve the critical memories.
 Turning from neurology to psychiatry, there are the very syndromes that caught the attention of the practitioners of the First Dynamic Psychiatry: hysterical anesthesias, paralyses, and amnesias, in which a person complains that he or she cannot remember certain events from the past, perceive stimuli in certain modalities, or voluntarily move certain portions of the body — all in the absence of any demonstrable organic brain syndrome; fugue states, in which a person loses his or her identity as well as the whole of the autobiographical record, relocates, and takes up a new life under a new name; and multiple personality, where separate personalities, each with its own identity, characteristic features, and personal history, seem to inhabit the same body, separated by amnesic barriers and alternating control over overt action and phenomenal awareness.
 In the laboratory, phenomena phenotypically similar to the symptoms of hysteria — analgesia and other negative hallucinations, spanning all the perceptual modalities; paralyses; compulsive automatisms in the form of posthypnotic suggestions; and poschypnodc amnesia for events and experiences transpiring during the state — can be induced in normal subjects simply by the hypnotist's spoken word — provided that the subjects are hypnotizable to begin with.
 Under more familiar conditions, we have nvmerous experiments on divided attention in which Information In the unattended channel Influences performance outside awareness; and experiments on multiple simultaneous tasks in which complex activities, executed at an acceptable level of performance, are unrecalled afterwards.
 Then there are all the experiments on perceptual defense and subliminal perception.
 In the domain of memory, there are of course the phenomena of statedependent retention, contextdependent retention, and other manifestations of the encoding specificity principle.
 There are also compelling demonstrations that unremembered experiences can influence perceptual recognition, and of significant savings in relearning material which appears, even after sensitive testing, to have been completely forgotten.
 Examples of dissociation can also be found in abundance outside the clinic and the laboratory.
 One such experience is familiar to all of us: the dream of REM sleep, in which vivid images are constructed without our intending to do so, and in which complex plots are played out five or more times a night (on average), only to be completely forgotten in the morning.
 Similarly, there is the pavor noctumus (night terror) common in children, which scares the daylights out of their parents even though the episodes are never remembered by the children themselves.
 The sleepwalker carries out complex motor activities while deeply in NREM sleep, and remembers nothing of it in the morning.
 (Sleeptalking, by the way, which also occurs in NREM sleep, is a doubtful case of dissociation, because the speech does not seem to be intelligent or goaldirected in most cases.
) ilarkening back to the literature on statedependent retention, there have been demonstrations that some individuals can respond to hypnoticlike suggestions during (REM) sleep, and continue responding on subsequent nights even though they are amnesic for their actions, and the suggestions, during intervening periods of wakefulness.
 Given observations such as these, Hilgard has recently revived the concerns of the First Dynamic Psycliiatry by proposing a "neodissoclation" theory of divided consciousness.
 He begins with the assumption that the cognitive apparatus is organized hierarchically, with various subsystems monitoring and controlling thought and action in various domains.
 Under ordinary circumstances, each subsystem is in communication with each of the others, and with a superordlnate central executive structure.
 It is this central executive which is the source of our subjective feelings of awareness and intentionallty.
 Under certain circumstances, Hilgard holds, a subsystem (or more than one) can lose contact with the central executive.
 In this case, percepts, memories, and actions represented in one of the subsystems fail Co be represented in phenomenal awareness; or perceptual exploration, memorial reconstruction, and overt action occur outside the control of the central executive.
 Despite this loss of communication with the central executive, the dissociated subsystems can, in principle, continue to interact with each other.
 This continued interaction is the source of the facilitation and interference effects which formed the basis of the empirical critique of the Initial versions of dissociation theory.
 It should be clear that Che subconscious of neodissoclation theory is rather different from Che unconscious as Ic is conceptualized by other schools within psychology.
 Neodissoclation theory differs from psychoanalysis, for example, because the subconscious is not restricted Co primitive sexual and aggressive Impulses, and those memories and ideas associated with them.
 Nor do subconscious mental processes operate according to Che Irrational "primary process" principles associated with the Freudian unconscious (as opposed to the rational, "secondary process" of the ego).
 Dissociated percepts and memories can be closely tied to objective reality; and dissociated ideas can be rational and even creative.
 Equally Important, rendering something subconscious is not necessarily motivated by defense against anxiety, as is Che case with Freudian repression.
 It can simply happen, as in the case of hysteria, fugue, or multiple personality; or it can be done for entirely adaptive purposes, as in the case of the subjects who voluntarily enter hypnosis or go to a movie precisely so they will become totally absorbed in the action on the screen, forgetting for awhile their everyday concerns (and even who they are).
 The subconscious of neodissoclation theory also differs in important ways from the manner in which unconscious mental contents and processes are construed, at least implicitly, in classical theories of human Information processing.
 Here four major trends can be discerned: an identification of consciousness with attention, shortterm memory, or working memory — in other words, what we are aware of apprehending at any particular moment; with complex as opposed to simple, or difficult as opposed to routine, informationprocessing procedures; with the availability of linguistic representations for ideas and experiences; and with declarative, as opposed to procedural, knowledge.
 But the subconscious of neodissoclation theory is not restricted to Che procedural knowledge by which we detect features in perceptual stimuli, decode and encode language, retrieve memories, make judgments, perform routine motor tasks, and the like.
 It can also involve complex factual knowledge, both semantic and episodic In nature, concerning the presence of certain stimuli or the occurrence of certain past events.
 Nor Is It restricted to the simple, automatic, and routine: complex cognitive and behavioral activities apparently can be performed outside awareness.
 Linguistic contents can be rendered subconscious, and percepts and memories can be subconscious even though the person's linguistic abilities remain Intact.
 Nor, wltiiin the realm of declarative knowledge, is the subconscious simply the repository of unattended perceptual Inputs, weak memory traces, and the products of early, simple, and automatic cognitive operations.
 Neodlssociatlon theory links a diverse set of realworld and laboratory phenomena under a unified descriptive rubric, and challenges cognitive science to account for them.
 It comes as no surprise that attention can be divided, though that fact in Itself poses problems for those informationprocessing theories which are predicated on the existence of limitedcapacity channels or storage structures.
 But if attention can be divided with one stream of complex, deliberate, cognitive activity proceeding outside awareness, this seems to cause some problems for the way we usually think about things.
 The empirical base for the theory Is sometimes problematic, but the phenomena of dissociation are trying to tell us something about the nature of conscious, subconscious, and unconscious mental processing.
 If we do not take these phenomena seriously, and consider their implications for our understanding of the cognitive system, our models of the mind may be led seriously astray.
 This seems reason enough to continue to pursue neodlssociatlon theory, and to incorporate its insights into larger theories, to produce a comprehensive view of the mind in order and disorder.
 Acknowledgments Paper presented at the 4th annual conference of the Cognitive Science Society, Ann Arbor, August 1982.
 The point of view presented in this essay developed in part from research supported by Grant #MH35856 from the National Institute of Mental Health, United States Public Health Service.
 I thank Patricia A.
 Register and Leanne Wilson for their comments during the preparation of this paper, and Ernest R.
 Hilgard for promoting the concept of dissociation.
 An expanded version of this paper, with references, is forthcoming in K.
 S.
 Bowers & D.
 Meichenbaum (Eds.
), The unconscious: Several perspectives (Wiley).
 S y m p o s i u m — R e p r e s e n t a t i o n o f P r o c e s s e s a n d T i m e Modeling Events, Actions, and Time James V.
 Allen Deparunent of Computer Science University of Rochesler Rochester.
 N Y 14627 This brief note concerns what types of knuwIcJgc one must possess in order to be able to reason about events and actions.
 In particular, in comprehending stories or dialogues.
 many inferences are made based on what events and actions are described.
 These range from inferences about the temporal ordering of events to inferences concerning the beliefs and motivations of the actors.
 Here I will concentrate on the nature of events and actions and discuss their relation to temporal reasoning.
 The references below provide more detail on all these issues.
 The formalism for actions and events used in most natural language understanding systems is based on case grammar.
 Each action is represented by a set of assertions about the semantic roles the noun phrases play with respect to the verb.
 Such a formalism is a start, but does not explain how to represent what an action actually signifies.
 If one is told that a certain action occurred, what can one conclude about how the worid changed (or didn't change!).
 One possibility for such a mechanism is found in the work on problemsolving systems (e.
g.
.
 [Fikes and Nilsson.
 1971]), which suggests one common formulation of action.
 A n action is a function from one world stale to a succeeding world state and is desc'^d by a set of prerequisites and effects, or by decomposition into more primidve actions.
 While this model is extremely useful for modeling physical actions by a single actor, it does not cover a large class of actions describable in English.
 For instance, many actions seemingly describe nonactivity (e.
g.
, standing still), or acting in some nonspecified manner to preserve a state (e.
g.
, preventing your television set from being stolen).
 Difficult problems also arise in this model concerning the simultaneous occurrence of actions in domains with more than one agent.
 For example, consider a simple blocks world with one block and two robots.
 Let there be two actions, P U S H R , push the block to the right, and P U S H U push the block to the left W e would like to define the effect of these actions in terms of the block moving.
 But if the two robots perform a P U S H L and P U S H R simultaneously, the block does not move.
 Yet, we still want to say that each robot pushed the block.
 If we cannot express simultaneity of actions, the best we could do to model this situation would be lo have the block oscillate as the robots pushed alternately.
 The approach suggested here does not attempt lo answer what an event or action actually is.
 Whatever an event is, the only way we can reason about one is by considering how the world changes (or remains constant) during some U m e inlerval in which the event occurred.
 Thus it is crucial that the temporal model in the logic be general enough to capture the scope of possible events.
 Actions are then defined as a subclass of events that involve agents and are described in a similar manner, fhe notions of prerequisite, result, and methods of performing actions do not play a central role in this study.
 While they are important for reasoning about how to attain goals, they don't play an explicit role in defining when an action can be said to have occurred.
 To make this point clear, consider the simple action of turning on a light.
 There are few physical activities that are a iieccsbaiy part of performing the action of turning on a light.
 Depending on the context, vastly different patterns of beliavior can be classified as the same action.
 1 or example, turning on a light usually involves flipping a light switch, but in some circumstances it may involve tightening the Ughi bulb (in the basement), or hitting the wall (in an old house).
 Although we have knowledge about how the action can be performed, this does not define what the action is.
 The key defining characteristic of turning on the light seems to be that the agent is performing some activity which will cause the light, which is off when the action starts, to become on when the action ends.
 The importance of this observation is that we could recognize an observed pattern of activity as "turning on the light" even If we had never seen or thought about that pattern previously.
 With this model, it is theoretically srniple to describe two actions occurring simultaneously.
 The temporal condition;) for each will be asserted to hold over the same time interval.
 It is then up to the reasoning component to infer any interactions that m a y arise.
 While this has not solved anything by itself, at least the complex problem can be expressed in the temporal logic, and reasoning techniques can then be investigated.
 With respect to modeling time, I want to make Just two basic claims.
 The first is that representations based on assigning dates for each time are unworkable.
 The second is that the underlying logic of time should be based on the notion of time intervals rather than time points.
 There are many difficulties that arise in systems based ou date lines.
 In such an approach, each time is represented by a value (e.
g.
, a number) and relationships between times can be computed by some operation on the values (e.
g.
, numeric ordering).
 O n e problem is that dates are not often supplied.
 M u c h temporal information in English is supplied only on a relative basis (e.
g.
, E occuned before E ) , both by the explicit mention of such relationships and by tense.
 For example, in the sentence "We found the letter while John was away," the temporal connective "while" indicates that the time of the find event occuaed during the time that John was away, and the past tense indicates that both events occurred in the past (i.
e.
, before now).
 The other major difficulty with datebased systems is that there can be considerable uncertainty in our temporal knowledge.
 For instance, we might know that either event E occurred before event E \ or vice versa.
 Hut in any case, the .
times of E and E" did not overlap.
 One can only capture such information with a partial ordering relationship: no dates can be assigned that capture these constraints.
 This is not to say that dating is not a useful technique when it is possible, it just cannot be the foundation of the representation.
 Turning lo the time interval/lime point conirovciby, wc can easily observe that both appear to be referred lo in English.
 Thus, w e can say, "We found the letter at 12 o'clock.
" " W e found the letter yesterday.
" The most straightforward approach to dealing wiih time ilica seems lo be to introduce points in lime and then define intervals from those points (e.
g.
, [McDermott, 1981; Bruce.
 1972]).
 1 do not use this scheme for two reasons.
 The first is that such a representation is too uniform and does not facilitate structunng knowledge in a way convenient for typical temporal reasoning tasks.
 The second is that it encourages one to think of time as being isomorphic to the real line, which is a serious mistake.
 The central issue concerning the first point is the importance of the during relation for reasoning.
 A major pari of our temporal knowledge appears to be of the form "event £• occurred during event L.
" Our knowledge of the during relation allows u highly structured representation of time.
 In pariiciilar.
 a common way of inferring that some condition P holds during an interval T is to show that P holds in an interval that contains T.
 For instance, I might know that m y office is locked today because it has been locked all week.
 Furthermore, such a during hierarchy allows reaboniiig processes to be locaUzed so that irrelevant facts are never considered.
 For instance, if one is concerned with what is true "today," one need consider only those intervals that are during "today.
" or above "today" In the during hierarchy.
 If a fact is indexed by an interval wholly contained by an interval representing "yesiterday," then it cannot affect whai is true now.
 On the second issue, some annoying characteristics arise from allowing zero width of time points.
 For instance, two intervals that meet must either have a point in common or have a point between them.
 Thus to describe an event consisting of a light being transformed & o m being ofT to being on, either the interval where it is off meets the interval where it is on, and thus there is a point where the light is both on and oS, or the interval where it is off is strictly before the interval where it is on, and thus there is a point between the two intervals where the light is neither on or off.
 This can be avoided by a technical trick such as ueating all intervals as open on their beginning and closed on their end.
 but such tricks simply emphasize the unnaturalness of the approach.
 In an intervalbased system, such issues need not arise: two intervals may meet without having any point in common.
 Given this intervalbased representation of lime, what is the equivalent of time points? For instance, we otlen talk of the beginning or ending times of events.
 ITiere is no reason to assume, however, that the beginning and ending tunes are instanuneous points.
 O n e might suggest that there is a m i n i m u m size e of intervals, such that aU intervals of size less than or equal to e are considered to be points, llie consequence of this would be that two such point intervals could then only be related by the relations < and =.
 This approach is useful but only if there is not one fixed value for e.
 for the size at which an interval is considered to be a point depends on the reasoning task being done.
 For instance, the smallest time intervals we care about in everyday life are probably of the order of seconds, as physicists or computer scienusts, we may consider times on the order of nanoseconds.
 Thus the interval size that we want to consider ai points varies depending on the task as well as the proximity to the current time.
 References Allen, J.
F.
, "An intervalbased representation of temporal knowledge," Proc.
, 7th IJCAI, Vancouver, B.
C.
, 1981.
 Allen, J.
F.
, "What's necessary to hide?: Reasoning about action verbs," Proc.
, 19th Annual Meeung, Assoc.
 Computational Linguisucs, 7781, Stanford U.
, 1981.
 Bruce.
 B.
C.
, "A model for temporal references and its application in a question answering program," Artificial Intelligence 3, 1972.
 Pikes, R£.
.
 and N.
J.
 Nilsson, "STRIPS: A new approach to the apphcation of theorem proving to problem solving," Artificial Intelligence 2.
 189205.
 1971.
 McDermott.
 D.
, "A temporal logic for reasoning about processes and plans," Research Report 196, I)ept.
 Computer Science, Yale U.
, March 1981.
 S O M E ISSUES O N M E C H A N I S T I C M E N T A L M O D E L S Johan de Kleer and John Seely Brown X E R O X P A R C Cognitive and Instructional Sciences 3333 Coyote Hill Road Palo Alto.
 Califorma 94304 I N T R O D U C T I O N Our longrange goal is to develop a model of how a penon acquires an understanding of mechanisnc devices such as physical machines, electronic and hydraulic devices, or reactore.
 W e lay out a framework for invesQgating the structure of what we call mechanisiic mental models: people's mental models of physical devices.
 Doing so involves developing a precise notion of a qualitative simulation.
 The concept of qualitative simulation derives from the c o m m o n inuition of "picturing in one's mmd's eye, how the machine operates.
" Although one would intuitively expect qualitative simulanons to be simpler than quantitative simulations of a given device, they turn out to be equally complex, but in a different way.
 These complexities arise, in part, frxnn the fact that devices may appear nondeterministic and undeiconstrained when the quantities and forces involved in their malceup are viewed solely from a qualitative perspective.
 Therefore, if the qualitative simulaaon of the device is to behave detenninistically.
 additional knowledge and reasoning must be used to disambiguate these "apparent" ambiguities.
 It is surprisingly difficult to construa mental models of a device that are capable of predicting the consequences of events not considered during the creation of the model.
 Thus, the process for constructing a good mental model involves a different k m d of problemsolving than the process for "running" the resultant mental model a distinction that we find crudal for understanding how people use mental models.
 In &ct.
 simply clarifying the differences between the work involved in constructing a qualitative simulation — a process we call envisioning — and the work involved in simulating the result of this construction — a process we call running — Qim out to have both theoretical and practical ramifications.
 QUALITATIVE SIMULATIONS A Basis for Mechanistic Mental Models Complex devices, such as machines, are built from combinations of simpler devices (components).
 Let us assume we know the behaviors of the components, as well as the way in which they are connected (o form the composite device.
 The behaviors of the components are described qualitadvely.
 such as "going up" or "going down.
" "high" or "low.
" The qualitative simulation always presents the events in tht functioning of the machine in their causal order.
 Figure I illustrates a conventional doorbuzzer (for the moment ignoring the button that activates ihe buzzer).
 The buzzer is a simple device, but complex enough to use for illustrating ideas of qualiiauvc sunulatioiL 'Tho paper is on abndged uid revised version of dc KIcer & Brawn (82).
 1 _ A O cuJVtK Figure 1 : Buzzer The buzzer's qualitative simuladon might be described as: The clapperswitch of the buzzer closes, which causes the coil to conduct a current, thereby generating an electromagnetic field which in turn pulls the clapper arm away from the switch contact, opening the switch, shutting off the magnetic field, allowing the clapper arm to return to its closed position, and thereby start the whole process oyer ag/aiii The simplicity of the qualitative simulation as expressed in the preceding example is deceptive.
 Qualitative simuladon encompasses a variety of ideas which need to be carefully differentiated.
 For example, we must distinguish simulation as a process from the results of that process.
 A simulaaon process operates on a representation describing the device, producing another reprcsentabon that describes how the device functions.
 One source of confusion is that this latter representauon can likewise be "interpreted" or simulated, but doing so will produce very little more than what is already explicitly represented in the functional representauon produced by the first kind of simulatioa' W e need to distinguish four related notions which foim die basic distinctions for a theory of qualitative reasomng.
 The most basic, device topology, is a representation of the structure of the device (Le.
, of its physical organization).
 For example, the steam plant's structure consists of a steam generator, turbine, condenser, their connecting pipes, etc.
 The second, envisioning, is an inference process which.
 given the device's structure, determines its function.
 The third, causal •model, describes the functiomng of the device (i.
e.
, a description of how the device's behavior results from its consntuent components which is stated in terms of how the components causally interact).
 The last is the running of the causal model to produce a specific behavior for the device, by giving a chain of events each causally related to the previous one.
 Thus, both the structure and functioning of a device arc represented by some knowledgerepresentadon scheme ^ e repcuuve opening and dosing of the switch (i.
e.
, i(s vibrauon) produces an audible sound.
 V̂of£ that this litter kind of simulnoon is just one of the kinds of inference nicchanisms Lhat can use or inicrprci" the funciional representauon.
 Others can inspect it in order 10 answer such ciuĉ tions as Could i cause y to happen?" (device topology and causal model respectively), with Che former being the input to (he envisioning process and the laaer being its output; this output causal model is.
 in cum.
 then used in che running.
 The example of qualitative simulation presented earlier is ambiguous as to whether it refcn to che envisioning, che causal model, or che ninning.
 Envisioning, Le« determining che functioning of a device solely from its stnicture often requires some very subtle reasoning.
 The cask, in essence, is co figure out how che device works given only ics stnKture and che knowledge of some basic principles.
 Stnicture descnbes (he physical organization of (he device, namely che constituent components and how they arc connected, but it does not describe how the componencs function in che particular device.
 The "behaviors" of each component are described assumug nothing about the particular context in which the component is embedded (i.
c the description is contextfree).
 These betuviors form a compoaent model (or schema) which characterizes all (he potential behaviors of the component; the envisioning process instantiates a specific behavior for each component from these models.
 These componenc models are che basic principles which che envisioning process draws upon to derive the functioning from che suucture.
 T o determine che functioning of (he overall device each com* poncnt's model must be examined and an individual specific behavior instantiated for iL Thus, the functioning of the entire device is deter mined, in part by "glmng together" the specific behaviors of all of its components.
 The problem for envisioning is detennining for each component which behavior, given aU che possible behaviois its model characterizes, is actually being manifested.
 What makes che problemsolving effort involved in the scructurecofimction inference process difficult is that the behavior of the overall device is constrained, not only by local interactioos of its component behaviors, but also by global interactions.
 Therefore, in principle, the behavior models of che components which are specified qualitatively may not provide enough information co identify the correct fiinctioning of the device.
 For example, if values are described qualitatively, often finegrained distinctions cannot be made between thenL Thus, in Che case of che buzzer, the envisioning may not be able co determine wliich is greater, che force of che magnetic field or che restoring force of che spring.
 Knowing which is greater may, in faa, be crucial co deducing che correct functioning of che device.
 In order to describe bow the resultant behavior derives from che behaviors of che constituents, first, each important event in Che overall behavior must be causally related to preceding events.
 Then.
 each c^isal relauonship must be explained by some fragment of the component model of one of its components.
 The example describing Figure U is.
 at best, an abridged description of the buzzer's function.
 It causally relates each event co che preceding one.
 but fails co state any rationale for these causal coimecnons.
 Because it is impossible to tell, a priori, whether the component models lead to unique behavior.
 (he problemsolver must entertain (he possibility (hat (he structural evidence is undeiconstraimng.
 Therefore the envisioning must (ake into account (he possibility that one structure may have multiple possible fiinctionmgs among which the envisioning cannot, in principle.
 distinguish.
 8 "Running" the resulting causal model is closest co che original psychological innjicion of "picturing, in one's mind's eye, how che machine operates.
" By running che model, one, in essence, does a straightforward simulauon of the machine; Che running itself does not have co determine or "prove" che causal or temporal ordering of events, as the envisioning process already has done so, and encoded (he information in (he causal model which serves as (he input data for che running process.
 The simplicity and elegance of che running process is (he result of che complex problemsolvmg (Le.
, envisioning) chat constructed iL That our intuition that 'picturing, in one's mind's eye.
 how che machine operates" is simple, is manifested by this running process.
 However, chat sense of simplicity is deceptive, for the tunning is not possible without the more complex problemsolving which preceded It.
 removing all the ambiguities about how che machine might be fimctioning.
 Understandably, the problems that arise in constructing causal models and the mechanisms that sufiice in solving these problems are important for cognitive psychology and artificial intelligence.
 For psychology, they are important because they provide a framework for analyzing the "competency" involved in determining how a novel machine functions.
 Inasmuch as envisioning is restricted (o being based solely on structural evidence, it becomes an interesting inference strategy in its o w n right for artificial intelligence applications, especially given the desire for artificial inceUigence systems to b« robust, and to be capable to deal with novel sioiations.
 The resulting models are more likely to be void of any implicit assumptions or builtin presuppositions based on how the device was intended to behave, AMBIGUITIES ASD ASSUMPTIONS Origiii of AmbiguitiM In general, ambiguities originate from the fact that che information available to the qualitative analysis underdetertnines or only partially characterizes the actual behavior of che overall device.
 There are chiee reasons for Chis underdetermination.
 The first and most obvious is that the quantities referenced by the component models are qualitative and thus finegrained distinctions cannot be made between the attribute values or component sutes.
 Second, because the implicit time progression in the simulation is qualitative, it is not always possible to determine che actual ordering of events.
 And che chird reason.
 not directly related co che qualicative nanire of the models, comes from che limitations on che kinds of information capwred by the models.
 Because envisioning tries co identify a global flow of acnon by piecing together local causeeffect rules of the component m o d e K a component model encodes only those aspects of the component's behavior that can be used in such a fashion.
 However, our understanding of a given component often involves more knowledge than is (or.
 perhaps, could be) encoded in such mechanistic rules.
 For example, in modeling the internal operadon of a p u m p we know from the laws of physics that Suid is conserved in passing through the pump.
 But, because this piece of knowledge is a constraint, it cannot be represented by any causeeffea rule: the inability to encode it can lead to a given component model being underdetermined.
 Origin of Assumptions In the buzzer example, because of tbe qualitative nanire of the attribute values, the envisioning process cannot determine whether the spring is stronger than the magnetic field.
 In this "impasse," it is forced to consider two hypothetical situations: one in which it assumes the spring is stronger than the magnetic field and one in which it assumes the spring is weaker than the field.
 Impasses occur when envisiomng cannot evaluate a transition condition (e.
g.
, the condition of the switch being open) or invoke an attribute equation (e.
g.
.
 that of field strength bemg proportional to coil current) to deiermme the value of an unknown attribute.
 In order to proceed around unpasses, the envisioning must introduce assumptions about the truth or falsity of conditions or about tbe values of unknown attributes.
 The buzzer example can be used to illustrate an impasse which arises from the envisioning being unable to determine whether a transition condition holds.
 In this impasse, the envisioner introduces an assumption that the condition "force from the coil > restoring force of the spring" is true, and then proceeds to analyze the new resulting state.
 Of course, the resulting causal model win then contain two accounts of the device's functioning: one in which the clapper rises and one in which it does noL Additional knowledge and reasoning strategics must then be used to verify or rejea the various assumptions that were created to enable die envisioner to proceed around such impasses.
 These strategies combined with a much more extensive analysis of the kinds of assumptions needed in order to construct a causal model have been detailed in the expanded version of this paper.
 R E F E R E N C E S de KIccr.
 J.
 and IS.
 Brown.
 Assumptions and Ambiguities in Mechanisuc Mental Models," to appear in Meniai Models, edited by D.
 Gcnmcr and A.
 S.
 Stevens, Eribaum, 1981 \ Nolo Cuiiccming Qujilirativc IVoccss Theory Ken Korhus M i l Al Lab 545 I'cchiioloiB' Square C;iiiil.
ri(li;c.
 Mass.
 02139 U S A I.
 Iiitroductloo Many kinds of changes occur in physical situations.
 Hiings move, collide, tlow.
 bend, heat up.
 cixil down, stretch, break, ;ind boil.
 Hicsc and the oiher things that happen to cause changes in objects over lime .
ire intuitively characterized as processes.
 Much of formal physics consists of charucterizaiiuns of processes by dilTcrcntial equations which describe how the piiramctcrs of objects change over time.
 Rut tlie notion of process is richer and more structured tlinn this.
 W e often reach conclusions about physical proccss.
's based on very little infomiauon.
 For example, wc know diat if we heat water in a scaled container the water can eventually boil, and if wc continue to do so the container can explode.
 To undcrsund c o m m o n sense physical rcasonmg we must undcistand how to reason qualitatively about priKcsscs.
 their effects, and their limits.
 I have been developing a theory, called Ou.
ilit.
iiive Proccxs ihet̂ rv.
 tor this purposcfKorbus, 1981, 1982].
 I expect this dicory, when ftilly developed, to provide a reprcscnt.
niional Iramcwork for understanding human c o m m o n sense physical reasoning.
 It should also be useftil for constructing computer programs that reason about complex physical systems as well as c o m m o n sense reasoning.
 Programs tliat explain, repair and operate complex sŷ iciiiN bucli as nuclear power plants and stcain machinery will need to draw the kinds of conclusions this theory sanctions.
 QualilatiNC rc.
nsoning about quantities is a problem that has !oi!g plagued Art̂ 'icial Intelligence and Cognitive Science.
 M.
iny schemes liavc been tned.
 including simple symbolic vocabularies ( T A I L V K R Y T A L L etc.
), real numbers, intervals, fuzzy logic and so fonh.
 N o n e arc very satisfying.
 Phc reason is that none of Uie above schemes makes distinctions that arc relevant to physical reasoning.
 Reasoning about processes provides a strong constraint on the choice of rcprescnudon for quantities.
 Processes usually start and stop when ordcr:ngs between quantities change.
 For example, when two objects with unequal temperatures are brought into contact there will be a heat flow from one to the other uhich will stop when the temperatures are cquaL In Qualitative Process theory the value of quantities are represented by a partial ordering of other quanuties detcnnined by the domain physics.
 The representation appears both useful and naturaL O P theory is mainly concerned with die form of physical theories and only indirectly about Uicir specific content For example, heat flow processes which don't conserve energy and transfer "caloric fluid" can be wnttcn as well as the classical physical dcscriptioiL Newtonian.
 Aristotelian, and Impetus theories of motion can all be encoded.
 Thus Q P theory provides a language for writing physical theories.
 In panicular.
 the primiuvcs are simple processes (such as flows, state changes, and mr.
ion), die means of combination are scquentiality and shared parameters, and die means of abstraction are naming these combinations, including encapsulating a piece of the process history la k m d of beha\ioral description, see (Hayes.
 19791) for the situation as a new process.
 The basic Qualitative Process dieory is not intended to capture die fiill range of qualitauve reasoning about the physical world.
 Instead it is concerned with describing die weakest kind of information diat still allows uscliil conclusions to be dniwn.
 lliere are two reasons why diis weak level of description is interesting.
 First, conclusions from weak information arc often required to drive die search for conclusions from more deuiilcd information (an il'iustration is (dcKlecr.
 197S)).
 More importantly.
 I believe dial die ba:.
ic dieory can be used to write what corresponds to people's c o m m o n sense physical knowledge.
 To capture more sophisticated kinds of phys cal reasoning (for example, how an engineer makes estimates of circu.
t parameters or stresses on a bridge) extension theories containing more dcuiled reprcsentiitions of quantity, functions, and processes will b<; needed.
 Kxainplcs of extension dieories could include order of in igiiitude estimates and numbers.
 By providing a shared b;isic theory, future studies of more sophisticated domains m.
ny yield a way to classify kinds of physical reasoning according to die extension dieorio Uiey require.
 1 An Example Ilicre arc several kinds of reasoning Uiat can be performed using Qualitative Process dieory, including reasoning about die limits of processes ("What might happen if diis valve is lefl open?") and consequences of alternate siluations ("How would die turning up die stove affect die heaung of die ketde?") as well as explaining some problems involved in causal reasoning.
 Several examples of c o m m o n sense phenomena have been examined in Uiis context, including modelling a boiler, motion, materials (saying diat you can push with a string but not pull with it), and an oscillator.
 A n informal example will illusuate its flavor.
 Here is a simple problem involving physical systems diat we solve easily: Imagine looking al a large lank, partially filled with water, iou can see iwo pipes leading into it.
 and you note that the level in the lank it dropping.
 Your goal is lo figure out why this is happening.
 In Q P theory terms, why diis is happening" means finding a set of processes which are causing die changes in die situation.
 (In the complicated physical systems which comprise much of our technology, diis is much harder dian die simple example depicted here, because die reladonship between what we can observe (through instruments) and die processes which serve as an explanation is much less direct).
 ITie reasoning goes as follows: PI No process affects level directly, but level is qualitatively proportional lo Amountof fluid.
 [2] The only processes which affect Amountof a contained fluid are boiling, evaporation, and fluid flow.
 [3] No heat source is visible, so boiling can be luied ouL [4] The time scale is sbon.
 so evaporation can be ruled out [5] By exclusion, fluid flow must be die source of die influence.
 [6] Fluid flow requires a fluid padL [7] Only two pipes are visible, so assume diose are die only fluid connections to die tank.
 [8] Only two fluid flows arc possible, one dirough each pipe.
 Fluid flow can be measured: in diis case both flows are into die tank.
 [9| Therefore die influence of die fluid flows is posiuve.
 [in] Tlicreforc die level of die tank should be increasing, not dixrcasing.
 [11] liiiher (1) Other processes affecting amountof exist (2) F.
vaporation or lloiling are occuring (3) Measurements arc wrong (4) Odicr fluid padis exist \\2] Pragmatically, (4) is die most likely  e,g.
, a large leak in die tank.
 Knowing what can be measured .
nnd die pragmatic information used in ruling out cvaporadon and in occcpung the leak as die best prospect arc not part of Q P dieory, but instead illustrate die interaction of die dieory with other kinds of world knowledge.
 Note that die key to die dcducuon is die assumption of a finite vocabulary of processes liiat could cause the observed change.
 Hayes (Hayes.
 Liquids) suggests rcTSoning by elimination is a powerful technique in c o m m o n sense reasoning; organizing physical knowledge around a v(x:abulary of priKcsscs provides funhcr oppununity to do so.
 3.
 Current State of the llicory The current state of die dieory is described in [Forbus.
 1982J.
 Furdicr dieoretical developments are being carried out in die context of reasoning about simple fluid and mechanical systems.
 A n 10 implcmcntauon is underway.
 4.
 References Clement.
 John "A Cunccptuol Model Discussed by Galileo and Used Iniuiiivcly by Physics Sludcnts" to appear in MfilUfll MllUfiJS.
 D.
 Gcnuicr and A.
 Stevens, cdiiois.
 dcKlccr.
 Juhun "Qualitauve and Quantitative Knowledge in Classical Mechanics" TR352.
 Mil AI Lab.
 Cambndge.
 Massachusetts.
 1975 Forbus.
 K.
 "Qualitative Reasoning about Physical Processes" Proceedings of lJCAI7.
1981 Forbus.
 K.
 "Qualitative Process Theory" M I T AI Lab M e m o No.
 664, February, 1982 Hayes.
 Patrick J.
 "Naive Physics 1  Ontology for Liquids" M e m o, Centre pour les etudes Scmantiques et Cognitives, Geneva, 1979 McQoskey, M.
 "Naive Theories of Motion" to appear in Mental Models.
 D.
 Gcntncr and A.
 Stevens, editors.
 11 S y m p o s i u m — M e t a p h o r The Preconceptual Basis of Experlencial Metaphor Mark Johnson Department of Philosophy Southern Illinois University at Carbondale Standard nodels of metaphoric comprehension share at least the follouing set of basic assumptions: (1) Meaning is conceptual structure.
 (2) Comprehending a metaphor of the form "A is B" requires a grasp of the appropriate conceptual structure for the "A" and "B" (topicvehicle) components, and it also requires the ability to map the B̂  domain onto the A domain in a contextually appropriate fashion.
 (3) The mapping or projection procedure depends principally on underlying similarities between the two domains.
 Versions of this position differ as to the nature of the mapping mechanism.
 Some treat the metaphoric projection as a simple transfer of discrete properties or relations from the B̂  domain over to the A domain, with appropriate changes being made to apply the transferred predicates to the new domain.
 Others argue that a more complex model is needed, one in which the entire system of predicates for the B domain, with all of its complex internal relations, must somehow be projected as a whole in such a way as to restructure Che conceptual system for the A domain.
 It is commonly believed by those who operate with some version of this standard model that the chief problem posed by netaphor for artificial intelligence is to discover the way in which contextual clues determine the precise nature of the projective process of metaphoric understanding.
 While I agree that this is the main difficulty, I want to suggest that it is less amenable to solution than moat cognitive scientists believe.
 The reason for my pessimism is that, contrary to the accepted view, understanding a metaphor is not Just a process of grasping certain conceptual structurings.
 In the metaphors of ordinary and technical discourse alike, there Is also a preconceptual basis in experience that gives the metaphor the meaning it has and that cannot be reduced to concepts or conceptual structure (as mental representations).
 My argument is based upon an analysis of some of the preconceptual factors involved in the comprehension of what I call "experiential" metaphors.
 An experiential metaphor is a process of experiencing, conceptualizing, and calking about one domain of experience as it is structured in terms of another domain of a different kind.
 Such metaphors are basic processes of everyday experience, and they are not mere linguistic ornaments or rhetorical modes of expression.
 The experiential metaphor MARRIAGE IS A BUSINESS PARTNERSHIP, for example, is one of several metaphors in American culture that structures the way some people understand, act out, and reason about their marriages.
 It is not a matter of mere words that ue use to calk about marriage; rather, it is one possible structuring of marital relations that provides coherence, order, and significance in the lives of chose who live by che metaphor.
 But che MARRIAGE IS A BUSINESS PARTNERSHIP metaphor is more than a conceptual structuring of some aspects of one's marriage.
 It involves nonstructural, preconceptual elements without which the metaphor would have no significance for us.
 These preconceptual elements in experience consist of various capacities, skills, values, and purposes in which the conceptual structures are rooted and from which they take cheir nourishment.
 With reference to the BUSINESS PARTNERSHIP metaphor I Identify four such elements: (1) General human purposes, (2) Cultural institutions and practices, (3) Theoretical paradigms, (4) Individual characteristics and patterns (including (1) individual purposes, (11) Individual castes and values, and (ill) personality traits).
 I am claiming that understanding a metaphor involves more than grasping conceptual structure—it also involves preconceptual elements that are neither discrete predicates nor structured relations.
 Such elements are a basic part of our ordinary experience without which no metaphor could have the power it does to shape our understanding, action, and language.
 If this analysis is correct, it calls for a rethinking of certain fundamental assumptions guiding work on metaphor in cognitive science.
 12 Towards a Comoutatlonal Model of kietaphor in C o m m o n Sense Reasoning Jaime G.
 Carbonell CarnegleMetlon University Pittsburgh, PA 15213 1.
 I n t r o d u c t i o n The theory that metaphor dominates large aspects of human thinking, as well playing a significant role in linguistic communication, has been argued with considerable force [10, 8.
 3.
 1|.
 However, the validity of such a theory is a matter of continuing debate that appears neither to dissuade its proponents nor convince its detractors.
 Being among the proponents, I propose to develop a computationally effective, common sense reasoning system based on underlying metaphors.
 I claim that if such a system exhibits cognitively plausible common sense reasoning capabilities, it will demonstrate the utility of metaphoncal reasoning.
 Moreover, if the model can account for observed instances of naive human reasoning t>etter than existing inference systems, it will provide convincing evidence m favor of the metaphorical reasoning theory.
 This brief paper investigates aspects of the metaphoncal rezisoning phenomenon and describes the initial steps towards developing a computationaf model.
 that such reasoning is seldom necessary and when applied requires a more concerted cognitive effort than mundane metaphorical inference.
 3.
 Towards Metaphorical Reasoning: The Balance ly/ietaphor Consider a prevalent metaphor reasoning about imponderable or abstract entities as though they were obiects with a measurable weight.
 One of several reasoning patterns based on this simple metaphor is the balance principle.
 The physical analog of this reasoning pattern is a prototypical scale with two balanced plates.
 Large numbers of metaphors appeal to this simple device coupled with the processes of bringing the system into (and out of) equilibrium.
 First, consider some examples of the basic metaphor, in which ihe relevant aspect of an abstract concept maps onto the weight' 0/ an unspecilied physical object.
 Arms control is a weighty ii 2.
 Experiential Reasoning vs Formal Systems Humans learn from experience to a degree ttiat no fonnaf system.
 Al model, or philosophical theory can match.
 The statement that the human mind is (or contains) the sum total of its experiences is in itself rather vacuous.
 A more precise formulation of expenencebased reasoning may be structured in terms of coordinated answers to the following questions: H o w are experiences brought to tiear in understanding new situations? H o w is long term memory modified and indexed? H o w are inference patterns acquired in a particular domain and adapted to apply in novel situations? H o w does a person "see the light" wtien a previously incomprehensible problem is viewed from a new perspecove? H ow are the vast maionty of irrelevant or inappropriate experiences and inference patterns filtered out in the understanding process? Answering all these "how" questions requires a process model capable of orqanizing large amount of knowledge and mapping relevant aspects of past experience to new situations.
 Some meaningful starts have been made towards largescale eoisodicbased memory organization [14.
15,12, 9J and towards episodic based analogical reasoning [5,4,2], Bearing these questions in mind.
 I turn towards the issue of common sense reasoning In knowledgench mundane domains.
 Mv central claim is that reasoning in mundane, recurrent :.
.
^„tion; o t̂ jilili.
,.
.
.
;;̂  diiierent ircm rt„:,oning in more abstract and exponentially unique situations (such as some mathematical or puzzlesolving domains).
 The former consists of recalling cippropriaie past experiences and inference patterns, whereas the latter requires knowledgepoor searcn processes more typical of past and present Al problem solving systems.
 Since computer programs perform much tiefter in simple, elegant, abstract domains man m "scruffy" exoenencench human domains, it is evident that a fundamental reasoning mechanism is lacking from the Al repenoire The issue is not merely tnat Al systems lack experience in mundane human scenarios  they would be unable to benefit from such experience if it were encoded in their knowledge base.
 I postulate that the missing reasoning method is one of metaphorbased transfer of proven inference patterns and experiential knowledge across domains.
 This is not to say that humans are largely incapable of more formal reasoning, but rather 13 The worries of a nation weigh heavily upon his shoulders.
 The Argentirte air force launched a mmssiv* attacK on ttie British fleet.
 One frigate was heavily damaged, but only light casualties were suffered by British sailors.
 The Argentines payed a /leavjrtoll in downed aircraft IMot tieing in the mood for heavy drama, John went to a light comedy, which turned out to be a piece of meaningless fluff.
 Pendergast was a real /ieairyMre>g/i( in the 1920s Saint Louis political scene.
 The crime weighed heavily upon his conscience.
 The weight of the evidence was overwhelming.
 Weight clearly represents different things in the various metaphors: the seventy of a nation's problems, the number of attacking aircraft, the extent of physical damage, the emotional affect on auaiences of theatrical productions, the amount of political muscle (to use another metaphor), the reaction to violated moral principles, and the degree to which evidence is found to be convincing.
 In general, more is heavier: less is lighter.
 One may argue that since language Is heavily endowed with words that describe v/eight.
 mass and other physical attnbutes (such as hight and onentation[10)), one borrows such words when discussing more abstract entities [13] • tor lack of alternate vocabulary.
 Whereas this argument is widely accepted, it falls far short of the conjecture I wish to make.
 Conjecture: Physical metaphors directly mirror the unaeriying inference processes.
 Patterns ot inference valid lor physical attributes are mapped invariant and reinstantiated in the target domain of the metaphor.
 In order to illustrate the validity of this coniecture consider a common inference pattern based on the weight of physical Mass IS virlually synonymous witti weigtit in naive reasoning.
 objects: The inference pattern is the balance principle mentioned earlier as applied to a scale with two plates.
 The scale can be in balance or tipped towards either side, as a function o> the relative weights of objects placed m the respective plates.
 Inference consists of placing obiects m ttie scale and predicting tho resultant situation  no claim is made as to whether this process occurs in a propositional framework or as visual imagery, although I favor the former.
 How could such a simple inference pattern be useful? How could it appfy to complex, nonphysical domains? Consider the following examples of metaphoncal communication based on this inference pattern: The jury found the uretght of the evidence favoring the defendant.
 His impeccable record weighed heavily in his favor, whereas the prosecution witness, being a confessed conman, carried little weight with the jury.
 O n balance the state failed to amass sufficient evidence for a solid case.
 The SS20 missile tips the balance of power in favor of the Soviets.
 Both conservative and liberal arguments appeared to carry equal weight with the president, and his decision hung on the balance.
 However, his longstanding opposition to abortion tipped the scale In favor of the conservatives.
 The Steeters were the heavy pregame favorites, but the Browns started piling up points and accumulated a massive halftime lead.
 In spite of a late ralty, the steelers did not score heavily enough to pull the game o«it The job applicant's shyness weighed against her, tjut her excellent recommendations lipped the scales in her favor.
 In each example above the same basic underlying inference pattern recurs, whether representing the.
 outcome of a trial, statements of relative military power, decisionmaking processes.
 or the outcome of a sporting event.
 The inference pattern itself is quite simple: it takes as input signed quantities  whose magnitudes are analogous to their stated "weight" and whose signs depend on which side of a binary issue those weights correspond  and selects the side with the maximai weight, computing some qualitative estimate of how for out of balance the system is.
 Moreover, the inference pattern also serves to infer the rough weight of one side if the weight of the other side and the resultant balance state are known.
 (E.
g.
, If Georgia won the football game scoring only 17 points, Alabama's scoring must have been really light) The central issue in my discussion is that this very simple inference pattern based on a physical metaphor accounts for very large numbers of inferences in mundane human situations.
 Given the existence of such a simple and widely applicable pattern, why should one suppose that more complicated inference methods explain human reasoning more accurately? It is my belief that there exist a moderate number of general inference patterns such as the present one.
 which together span most mundane human situations, fy/loreover.
 the tew other patterns I have found thus far are also rooted on simple physical principles or other directly experienced phenomena.
 However, since the current study is only in its initial stages, the hypothesis that metaphorical inference predominates human cognition retains the status of a conjecture, pending additional investigation.
 I woukj say that the weight of the evidence is as yet insufficient to tip the academic scales.
 4.
 Requirements on a computational model Metaphoricallybased general patterns of inference do not appear confined to naive reasoning in mundane situations.
 Gentner (7) and Johnson (8) have argued the significant role that metaphor plays in formulating scientific theories.
 In our preliminary investigations.
 Larkin and I [11] have isolated general inference patterns in scientific reasoning that transcend the traditional boundaries of a science.
 For instance, the notion of equilibrium (of forces on a ngkl obiect, or of ion transfer in aqueous solutions, etc.
) is, in essence, a more precise and general formulation of the balance metaphor.
 Reasoning based on recumng general inference patterns seems to pervade every aspect of human cognition.
 These patterns encapsulate sets of rules to be used in unison, and thereby bypass the combinatorial problems in traditional rulebased deductive inference.
 The inference patterns are frozen from experience and generalized to apply in many relevant domains.
 I have started working on a computational model that acquires and generalizes recurring inference patterns from prior experience [G], bul let us focus on the equaily basic issue of how such patterns may be used in the reasoning process.
 Conceptually, the process may be divided into three stages: 1.
 Index the relevant inference patterns appropriate to the situation at hand.
 The establishment of the appropriate metaphor is the really difficult part.
 This is why it is much easier to understand someone's descnption of observed or expenenced events (the metaphor is explicitly referenced by the choice of words), than to generate appropriate action " the typical distinction between planning and plan comprehension.
 2.
 Instantiate the inference patterns in the specific situation.
 Computationally, the process of instantiation and the process of searching for appropnate inference patterns are two aspects of the same mechanism.
 3.
 Carry out the inferences stipulated In the retrieved patterns, and check whether additional inference patterns are invoked as a result of the expanded knowledge state.
 At the present stage in the investigation.
 I am searching for general inference patterns and the metaphors that give rise to them, both in mundane and in scientific scenarios.
 As these patterns are discovered, they are cataloged according to the situational features that indicate their presence.
 The basic metaphor underlying each inference pattern is recorded along with exemplary linguistic manifestations.
 The intemeil structure of the inference patterns themselves are simple to encode in an Al system.
 The difficulty arises in connecting them to the external worid (i.
e.
, establishing appropnate mappings) and in determining the conditions of applicability for each inference pattern (which are more accurately represented by continuous functions than simple binary tests).
 For instance, it is difficult to formulate a general process capable of drawing the mapping between the "weight" of a hypothetical object and the corresponding aspect of the nonphysical entity under consideration, so that the balance inference pattern my apply.
 It is equally difficult to determine the degree to which this or any other inference pattern can make a useful contribution to novel situations that bear sufficient similarity to past experience [4], 5 .
 F u t u r e D i r e c t i o n s if one lends credence to the metaphorical reasoning hypothesis, several avenues of continued research suggest themselves.
 • Continue the development of a computational model to test the theory of metaphorical inference and thereby force a finergrain analysis of the phenomenon.
 • Examine the extent to which linguistic metaphors reflect underiying inference patterns.
 The existence of a number generally useful inference patterns based on underiying metaphors is not incompatible with the possibility that the vasi maiority of meljpho.
s i=rnain niiire linguistic devices, as previously thought.
 In essence, the existence of a phenomenon does not necessarily imply its universal 14 presence.
 This is a matter id be resolved by more comprehensive future investigation.
 • Investigate the close connection bet\A/een models of expenentlal learning and metaphorical inference.
 In fact, my earlier investigation of patterns of analogical reasoning in learning problem solving strategies first suggested that the inference patterns that could be acquired from experience coincide with those underlying many common metaphors [4.
3).
 • Exploit the human ability for experientiallybaaed metaphorical reasoning in order to enhance the educational process.
 In fact.
 Sleeman and others have independently used the balance metaphor to help teach algebra to young or learning disabled children.
 Briefly, a scale is viewed as an equation, where the quantities on the nght and left hand sides must balance.
 Algebraic manipulations correspond to adding or deleting equal amounts of weight froin both sides of the scale, hence preserving balance.
 First, the child is taught to use the scale with colorcoded boxes or different (integral) weights.
 Then, the transfer to numbers in simple algebraic equations Is performed.
 Preliminary results indicate that children learn faster and better when they are able to use explicitly this general inference pattern.
 I foresee other applications ot this and other metaphorical inference patterns in facilitating instruction of more abstract concepts.
 The teacher must make the mapping explicit to the student in domains alien to his or her past experience.
 As discussed earlier, establishing and Instantiating the appropriats mapping is also the most problematical phase from a computational standpoint and therefore should correspond to the most difficult step in the learning process.
 Yale University, Nov.
 1980.
 10.
 Lakoff, G.
 and Johnson, M.
, Metaphors We Live By.
 Chicago University Press, 1980.
 11.
 Larkin.
 J.
 H.
 and Carbonell, J.
 G.
, "General Patterns of Scientific Inference: A Basis tor Robust and Extensible Instructional Systems," 1982.
 Proposal to the Office of Naval Research.
 12.
 Lebowitz, M.
, Generalization and Memory in an Integrated Understanding System, PhO dissertation, Yale University, Oct.
 1980.
 13.
 Oftony, A.
 (Ed.
), Metaphor and Thought, Cambridge University Press.
 1979.
 14.
 Schank.
 R.
 C, "Reminding and Memory Organization: An Introduction to lulOPS," Tech.
 report 170, Yale University Comp.
 Sci.
 Dept, 1979.
 15.
 Schank, R.
 C, "Language and lulemory.
" Cognitive Science.
 Vol.
 4.
 No.
 3,1980 .
 pp.
 243284.
 6.
 References 1.
 Burstein.
 M.
 H.
, "Concept Formation Through the Interaction of Multiple Models.
" Proceedings of the Third Annual Conference of the Cognitive Science Society, 1981 Cart)one«, J.
G.
.
 "A Computational Model of Problem Solving by Analogy.
* Proceedings of the Seventh International Joint Conference on Artificial Intelligence, August 1981 ,pp.
 147152.
 Cart>oneil.
 J.
 G.
.
 "Metaphor An Inescapable Phenomenon in Natural Language Comprehension," in Knowledge Representation lor Language Processing Systems.
 W.
 Lehnert and M.
 Ringle, eds.
.
 I^ew Jersey: Eribaum, 1982.
 Cartsoneii J.
 G.
.
 "Learning by Analogy: Formulating and Generalizinci Plar.
̂  from Pist E/penence.
" m Machine Learning.
 R.
 S.
 Michalski.
 J.
 G.
 Carbonell and T.
 M.
 Mitchell, eds.
.
 Palo Alto, CA: Tioga Pub.
 Co.
.
 1982.
 Carbonell, J.
 G.
, "Invariance Hierarchies in Metaphor Interpretation," Proceedings of m e Third Meeting of the Cognitive Science Society.
 August 1981 , pp.
 292295.
 Carbonell, J.
 G, "Acquinng Problem Solving Skills by Analogy.
" Proceedings of the Second Meeting ot the American Association lor Artificial intelligence.
 1962 , Pittsburgh.
 Centner, •.
, "The Structure of Analogical Models in Science," Tech.
 report 4451.
 Bolt Beranek and Newman, 1980.
 Johnson, M.
, 'Metaphorical Reasoning," 1982.
 Unpublished meuiuscnpt Kolodner, J.
 L.
, Retrieval and Organizational Strategies in Conceptual Memory: A Computer Model.
 PhO dissertation, 15 METAPHORS FOR MARRUGE IN OUR CULTURE Naomi Qulnn Duka University Lakoff and Johnson, In Mecaphors We Live By (1980), frequently allude to metaphors "in our culture.
" This paper explores the way in which culture can be said to constrain metaphorical thinking in one domain, that of American marriage.
 It undertakes systematic analysis of a.
 sample of metaphors used by 22 American interviewees, spouses in 11 marriages, over an average of 1516 hourlong Interviews per individual.
 Superficially, the particular metaphorical expressions used by a given individual would seem to vary widely.
 But these expressions can be shown to cluster around one or another of a small number of underlying metaphorical models to which that Individual consistently returns.
 Thus a husband who conceptualizes his marriage as BUILDING A DURABLE PRODUCT is able to express this underlying metaphorical model in terms of a number of different concrete products or general types of products, sometimes switching from product to product in a single utterance: a metal in "we forged a lifetime proposition," an unspecified construction of the sort one might build in one's home workshop in "marriage is a doityourself project," something capable of structural improvement in "our marriage was strengthened," an edifice in "we made that the cornerstone," once again an edifice and then something made out of a malleable material, perhaps clay.
 In "they had a basic solid foundation in their marriages that could be shaped into something good," and something like a car built out of cannibalized parts, which then takes on the properties of a.
 chemical such as epoxy glue in "we have both looked into the other person and found their best parts and used these parts to make the relationship gel.
" Another husband who conceptualizes marriage as TRAVEL sometimes speaks of the marriage as a train or trolley capable of "getting off the track," other times as foot travel in "he's running the same path I was before I got married.
" and "If I weren't married I'd be running down the sane line," and still elsewhere as some kind of maneuverable vehicle in "I Just observe others' marriages and try to run mine down the middle.
" Moreover, analysis reveals that the vast majority of these stable metaphorical models themselves fall into two broad classes: metaphors of marriage as some kind of effortful activity—e.
g.
, WORK, BUILDING A DURABLE PRODUCT, A QUEST, AH INVESTMENT, GROWTH, A STRUGGLE, A JOURNEY, TRAVEL —or marriage as some kind of dual relationship— e.
g.
, A PARTNERSHIP, TWO PATHS CROSSING, MUTUAL PARENTING, BEING A UNITED FRONT, BEING A PAIR, BEING ONE PERSON, BEING A COUPLE, A SPATIAL RELATIONSHIP.
 Thus the superficially variable metaphors which Interviewees employ can be seen to be highly constrained.
 What constrains them is apparently some kind of (still deeper) underlying folk theory about the nature of the marital relationship, which says that such an enduring attachment between two people takes effort to achieve or insure.
 Individuals are free to conceptualize their marriages in terms of any kind of experience drawn from either or both of the two classes, dual relationship and effortful activity.
 They may also choose to foreground metaphor from one of these to the neglect of the other—understanding their marriage primarily or entirely in terms of the nature of the relationship they have, or alternatively, in terms of the effort involved in sustaining that relationship.
 However, given individuals are very likely to employ metaphorical models of both classes.
 When this is done, the metaphorical model selected from the class of effortful activities matches an entailment of the metaphorical model which characterizes the nature of the relationship.
 The mapping Is one of goal implementation: that is, given some entailment of the relationship conveyed in one metaphorical model, how can such an entailment plausibly be implemented? Thus, for example, the husband with the model of marriage as BUILDING A DURABLE PRODUCT (an effortful activity) is implementing, in this enterprise, the goal of making a permanent marriage.
 Permanence is entailed by BEING A COUPLE (a dual relationship), a metaphorical model central in his thinking about the nature of his marriage and others he knows (Qulnn 1981).
 For this husband, being a couple entails being permanently coupled together, hence "durably built.
" The husband who regards marriage as TRAVEL (an effortful activity) means, by keeping his marriage on the track and running it down the middle, that he regulates the proportion of time he and his wife spend together and apart, or as he puts it, the proportion of time their "paths run together" and "run apart.
" Hla metaphorical model for their marital relationship is one of TWO PATHS CROSSING (a dual relationship).
 Achieving a balance between "crossed" time and separate time, which he views as the central entailment of marriage as TWO PATHS CROSSING, he then conceptualizes in terms of the necessity to stay on the path, keep on the track, and steer a correct course.
 Still another husband views his marriage as a SPATIAL RELATIONSHIP (a dual relationship) in which spouses must be "pretty clear where each of us are" in some kind of uncharted territory, and "try to get a good sense of where we are" or else "we might satellite far enough away so we're not sure what's in between us" in what appears to be outer space.
 If two people are constantly shifting position visavis one another, as in this SPATIAL RELATIONSHIP model of marriage, the overriding concern is to keep in contact.
 This is met, by this husband, with an INQUIRY model (effortful activity), which involves "space to kind of work out where each of us were," "a lot of searching," "miles of talking," and "communicating.
" These husbands all seem to agree that marriage requires some effortful activity.
 The particular effort required depends upon a prior conceptualization of the natire of the relationship itself.
 In each case, the metaphorical model of the relationahip is problematic in some entailment, the problem solution becomes a goal of the marriage, and a solution for this marital goal is couched in a further metaphorical model.
 Whether this view of marriage aa problem and solution is universal crossculturally, or whether it is a distinctively American way of viewing marriage, perhaps certain other relationships, and even other aspects of life, I can only speculate.
 What do these observations suggest for a theory of metaphorical understanding? First, ongoing metaphorical understandings are relatively stable 16 and chese stable uaderscandings are baaed in underlying metaphorical models.
 Metaphorical expressions which instantiate a given model can be varied at will to take advantage of different properties of concrete objects or events.
 Thus MARRIAGE IS BUILDING A DURABLE PRODUCT allows its user to understand his marital axperience in terms of conemstones, reassembled parts, and the gelling process with equal facility.
 Second, these underlying metaphorical models themselves cannot be anything at all.
 They are constrained to members of those classes which are culturally appropriate source domains for the target experience (to use Carbonell's [1981] terms).
 Members of a culture share knowledge of these appropriate source domains.
 A considerable economy of learning and memory is achieved in this organization of cultural knowledge by metaphorical class that would be lost if target experiences were assigned directly to culturally permissible metaphors or metaphorical models.
 Within classes, an Individual has latitude in selecting whatever metaphorical model does the best Job of characterizing, for that person, the target experience.
 Third, underlying metaphorical models cannot be studied in isolation from one another.
 In ongoing understanding, they frequently bear relationships to one another.
 Here I have given an example of metaphorical models which are mapped onto entailments of other metaphorical models by way of goal implementation.
 Elsewhere, Johnson (1982) has provided a hypothetical example of a different kind of mapping, which we might distinguish as substitution.
 While metaphorical models, as I have claimed here, are relatively stable understandings of experience, it often happens that one such modal ceases to adequately capture experience for its user.
 Another model which shares multiple entailments with the earlier one may then be substituted for it; the shared entailments serve as bridges.
 If time allowed, I would give additional examples of such substitution froa my material.
 For instance, the husband who conceptualized marriage as BEING A COOPLE felt that he and bis wife were growing closer over time, and spoke of his more recent marital experience as BEING ONE PERSON.
 Given goal impleaentatlon, substitution, and other possible relationships between metaphorical models, it becomes critical to study the vinderstanding process in the context of life story discourse.
 References Carbonell, Jaime, Jr.
 1981 Metaphor: an inescapable phenomenon in natural language comprehension.
 Unpublished ms.
 Johnson, Mark 1982 Metaphorical reasoning.
 Unpublished ms.
 Lakoff, George and Mark Johnson 1980 Metaphors We Live By.
 Chicago: University of Chicago Press.
 Quinn, Naomi 1981 Marriage is a doityourself project: the organization of marital goals.
 In Proceedings of the Third Annual Conference of the Cognitive Science Society, Berkeley, California, August 1921.
 Pp.
 3140.
 17 Metaphoric Gestures David McNeill University of Chicago An analysis of the internal structure of saying, for example, "that's ok" as based on pointing and saying "ok," suggests a form in which this (virtual) action could be expressed—namely, as a pointing gesture.
 Such a gesture would be regarded as a second manifestation of the internal action structure—the utterance of "that's ok" being the first (first in communicative importance).
 The same can be said of other utterances.
 The externalization of action structures in gestures offers a way of studying the internal organization of language actions that is separate from speech.
 The gesture and the speech can be compared in a relationship that is comparable in its ability to bring out details to triangulation.
 Internal thoughts of actions— manipulations and movements of objects in the world—seem to play a metaphoric role in language actions.
 In producing speech a concept or meaning is shown through a (virtual) action—this imaginary manipulation or movement of objects.
 In the following example the concepts of pursuit and inaccessibility are presented in a complex gestural image of moving but nonclosing objects.
 This image immediately presents a global and undivided picture of the conceptual content, while concurrently the content is segmented into words and arranged across time in the speech channel (the fact that the gesture image arises first shows that it is not a response to the words).
 (1) Speech: they urn wanted to get where Anansi was Gesture: both hands held apart in the air, right hand flutters back and forth (where the underlining shows the temporal extent of the gesture).
 The synthesis of thoughts on which this language action was based (as revealed in the gesture) was a (virtual) placement of two objects, one in motion, but without closure.
 This image shows directly the concepts of pursuit and inaccessibility.
 The utterance of "the wanted to get where Anansi was" is an expression of the same internal structure, as numerous detailed parallels of form between the speech and gesture channels show.
 For example, the participants (referred to by the pronoun and proper name) correspond to the two hands (that is, the gesture was two handed rather than one handed).
 The two hands were held apart at spatial extremes, and in the sentence appear at temporal extremes (rather than together as would have been possible in a frame such as "the sons [coreferent of "they"] and Anansi couldn't get together"); one participant is not in motion, and in the sentence is referred to in a stative locative construction ("where Anansi was"); the other participants are in motion, and in the sentence are referred to by the subject of a verb of motion ("they wanted to get"); and the motion of these participants in the gesture was of small extent and ineffectual, and in the sentence are referred to by the subject of the verb "want.
" All of these parallels are explicable if the gesture and utterance were joint manifestations of the same internal structure—a synthesis based on the idea of placement and movement of objects.
 This idea is a metaphor for pursuit and inaccessibility.
 (It is well to remind ourselves that the relationship between the structure of language actions and that of language objects—these being two completely different perspectives—is anything but clear; therefore it is not particularly interesting to ask how "thoughts based on actions such as placement of objects translate into deep structures or other linguistic object configurations.
) Gesture evidence reveals a very widespread use of metaphoric thinking in performing language actions in which thoughts related to actions are used to show meanings of a nonaction kind.
 Mathematics discussions are accompanied by a flow of gesture which show mathematical ideas in the form of actions.
 The mathematical meaning of a dual is that each concept is replaced by its converse; for example, the dual of upward is downward.
 The following examples (24), taken from nonconsecutive places in a technical mathematics discussion, each contain a gesture in which a hand rotates through the air from one orientation to the opposite orientation; the gestures therefore show the concept of a dual in the action realm.
 (2) Speech: this gives complete duality Gesture: right hand palm rotates upward (3) Speech: when you dualize Gesture: right hand palm rotates downward (4) Speech: the powers of x kind of give a dual Gesture: right hand palm rotates front to back Another mathematical concept is that of a limit, and in the following examples the hands move toward some boundary marked by the other hand or a sudden stop; thus these gestures also are images of a mathematical concept in the action realm.
 (5) Speech: it's an inverse limit Gesture: right hand flattens; left hand moves uo to 18 right hand (6) Speech: the inverse limit oTT.
.
(trails off) Gesture: right hand goes down, then up as to a boundary (7) Speech: which is a limit, a directTimit Gesture: right hand moves down, then up as to a boundary Example (5) also included a second gesture that showed the concept of an inverse: (5') Speech: it's an inverse limit Gesture: right hand moves in a tight loop The concept of finiteness is shown by enclosing or pinching down on a space by curling the fingers and hands; thus here too is a mathematical concept in the action realm.
 (8) Speech: through the finite pieces Gesture: fingers curl inward (9) Speech: to get the finite group scheme Gesture: fingers curl inward (10) Speech: some finite group functor Gesture: forms a two handed bounded shape with palms facing and fingers curled A rule of gesture production is that new movements indicate changes of meaning; and so a gesture can indicate the emergence in discourse of a new element of meaning ("information focus").
 Thus in (2), for example, the new element was the concept of duality, and the other examples can be interpreted in a parallel way.
 Utterances are structured to make salient the same elements of meaning.
 This is another parallel that suggests a common source for gesture and speech.
 In (2), "that gives complete duality" was structured and pronounced to achieve the same effect as the gesture: reference to the concept of duality was held off until the final sentence position (the position of the rheme) where it was given main stress, and was introduced in full lexical form.
 On the other hand, the sentence topic was announced first with a pronoun, and was weakly stressed.
 The transitive sentence form also enhanced the information focus of duality.
 Internally the model for (2) seems to have been that something (the sentence topic) was pushing forward the example the gesture demonstrated of duality (hence the use of "gives").
 19 METAPHOR AND THE CONSTRUCTION OP REALITY by George Lakoff Ualvarslcy of California ac Berkeley Johnson and I (1980) have argued that metaphors are essentially conceptual In nature, rather than linguistic, and that a metaphor provides a way of understanding one kind of thing In terns of another.
 Since we base our actions in our understanding, and since actions are real, it follows that reality, especially on the social, interpersonal, and emotional domains, is structured according to our metaphors.
 Though I think this is an essentially correct view, it is certainly oversimplified and in need of more detailed study.
 Here are some of the questions that I think need to be answered:  Which conceptual metaphors do we live by, and which do we use "merely" for the sake of understanding?  What does it mean to live by a metaphor?  Which metaphors do we believe, and which don't we believe?  Are some metaphors more essential than others in defining a concept? And finally:  To what extent does a given metaphor "create" the structure of a concept it defines, and to what extent does it merely "decorate" an already given structure? In addition, I will review very briefly some results on imagebased metaphorical concepts.
 These results suggest to me that even spatial understanding may not be universal.
 20 S y m p o s i u m — C o n t r o l o f A r m s UHY IS IT EASY TO CONTROL YOUR ARHS7 Peter H.
 Green* Conputtr Science Oipartnent Illinois Inititut* of Tochnolojy Chicigo, Illinois iOi\i Hon can our nervous systens control all the variables needed to 9uid* our arnsT How can ue represent the abstract pattern of an action such as handwritin; 50 that it nay be realized in any of an infinity of variants—lar^e, SHall, horizontal, vertical, vith the hand weighted, or even by holding the pencil stationary and noving the paper? (lost researchers who try to represent novenents of artificial arns by neans of conputer pro^rans have chosen, in the interest of supposed conputational sinplicity, to use the smallest nunber of "degrees of freedon*, or independent joint novetients that will allow desired hand novenents.
 I will discuss the opposite idea: nanely, the idea that a large nunber of "redundant" degrees of freedon, when used in the style that I will discuss, can sinplify the control task, in that, if there are enough ways of noving, a recipe involving just a few of then can usually be found that will approxinate any desired novenent.
 In particular, the presence of "redundant" degrees of freedon allows us to rely nore on ballistic (freeswinging) novenents than is generally done in research on artificial arns, so that physics, rather than coflputation, accounts for nuch of the trajectory.
 Conputations are required to set up the constraints defining and initializing a lowdegreeoffreedon 'virtual a m * in such a way that a satisfactory ballistic novenent exists.
 Thus, a conplicated physical arn behaves like a fanily of easily controlled virtual arns.
 Anong the points to be discussed: Using nonentun saves energy, and it sinplifies control.
 Novefients nay be controlled by sending new paraneters to systens that control the nusdes, rather than by controlling the Nuscles directly.
 The principal task in tracking a noving object, rather than being to mninize instantaneous errors, nay be to synchronize an internal pattern generator to the noveitent.
 The present style of control identifies sinilar novenents as cousins, rather than regarding then as unrelated canputations.
 The sane overt nuscle noveoent can be nore or less difficult, depending upon the higher up patterns in this hierarchy fron which it is derived.
 (See Greene, P.
H.
 (1»72), Problens of organization of Notor systeHS, in Rosen, R.
 and Snell, F.
H.
, eds.
, ErS3rSSi.
iS.
IbjarSii£3l_lioioay^__Vaii_2, New York: Acadenic Press and Greene (1782), Uhy is it easy to control your arns? j8SI£Sal_a£.
!!aiaE_£a]»iEaif to »Ppear.
) 21 Internal Directional Reference Frames for Motor Coordination C.
C.
 Boylls Rehabilitative Engineering Research and Development Center Palo Alto Veterans Administration Medical Center Palo Alto, California 94304 Several decades ago, Graham Brown (11) found that the spontaneous walking of a highdecerebrate cat can be continuously transformed from rectilinear locomotion into either circling or uphill/downhill progression by appropriate changes of head position.
 The cat's performance thus carries with it an attribute of "spatial directionality" which can be independently regulated by the CNS; and the method of regulation relies.
 In this instance, upon postural biases created by tonic neck and labyrinthine reflexes.
 Recently, experiments using decerebrate cats similar to Graham Brown's have indicated that activity within the olivocerebellar system of the brainstem Is associated with postural alterations resembling those elicited from neck and labyrinths (4,5).
 These, too, bias the locomotor musculature so as to influence the overall directionality of walking in a wide variety of ways.
 However, there is one area in which the directional control exerted by the olivocerebellar system differs considerably from that seen by Graham Brown: It has "mefflory", in that a posture adopted by an animal as a function of olivocerebellar activity is retained for many tens of seconds after that activity ceases.
 By contrast, the postures of Graham Brown's animals reflect only the current position of the head, without any apparent recollection of previous positions.
 The directional skews associated with head movement can thus be changed in "real time" from step to step, while olivocerebellar skews establish an enduring postural context within which many steps (or other activities) may occur.
 It thus is tempting to hypothesize that the olivocerebellar system exists in the CNS to regulate, via postural mechanisms, an internal directional reference frame within which motor actions are elaborated and, perhaps, evaluated.
 But then, why should such a faculty exist? The idea of an internal directional reference for movement was first derived theoretically from consideration of CNS mechanisms to simplify the controllable degrees of freedom in the skeletomotor system (2,8; P.
H.
 Greene, this volume).
 The technique for doing this is to create functional dependencies (e.
g.
, fixed ratios) amongst movement parameters affecting different joints, as is frequently encountered experimentally (10,9).
 One particular form of functional dependence employs socalled "muscle linkages" (3) of synergists at different joints, the activities of which covary in some prescribed manner (cf.
, ref.
 12 for experimental examples).
 Actions carried out with such a linkage are characterized by a distinct directional skew that becomes quite apparent as the covarying parameters of the linkage are altered.
 Graphic illustrations of such a process may be seen In, for instance, Graham Brownlike changes in the coactivation of human leg musculature (elicited with galvanic labyrinthine stimulation) as a continuous function of neck position (13).
 Consequently, one might well see olivocerebellar directional biasing as just another way to parameterize muscle linkages and simplify the motor control process.
 But this would provide no facile explanation for the extended timecourse of such 22 biasing, nor would it define the conditions that presumably spur the olivocerebellar system into establishing a particular directional reference frame.
 A speculative approach to the last question is suggested by neurophysiological studies of the olivocerebellar system and its role in regulating eye movement (ref.
 1 for review).
 In brief, activation of the appropriate (anatomically) part of the system Institutes a secondslong nystagmus of the eyes seemingly equivalent to the olivocerebellar postural biasing of the skeletal muscles described above.
 This nystagmus also resembles the phenomenon of optokinetic afternystagmus (OKAN) that occurs in humans and animals following exposure to wholefield motion of the visual world.
 It may come as no surprise, therefore, that the olivocerebellar system has proved to receive retinal imagemotion cues which are nearly optimal for optokinetic eye movements.
 What Is more interesting is that, in stationary human subjects, the development of OKAN is associated with illusory sensations of selfmotion or "vection", which, in darkness following exposure to the moving visual stimulus, persist for prolonged periods of time (7).
 The rationale for this persistence, or "memory", would appear to involve an appreciation for momentum: The subject feels accelerated to some velocity by the moving visual world, and has no reason to feel decelerated when that world is no longer visible.
 While appropriate studies seem not to have been done, it seems reasonable to suppose that humans and animals experiencing vection will alter their motor behavior as a function of this sensation.
 Just as they would were they experiencing actual selfmotion.
 Because of the long timecourse associated with vection, such motor adjustments will likely take the form of "static" postural biasing altering the directionality of movement.
 Might this be the sort of directional skewing produced by the olivocerebellar system? Might the perception of selfmotion along particular trajectories be associated with the creation of olivocerebellar directional reference frames for movement? The arguments above have been helped somewhat by the demonstration that vection sensations (and accompanying "OKAN") can be released by proprioceptive cues from the limbs ( 6 ) — which, besides providing a role for the massive somatosensory input to the olivocerebellar apparatus.
 Indicates that selfmotion cues derive from multisensory processing.
 Those cues probably also owe themselves to knowledge of efferent command signals, since the quality of selfmotion illusions depend upon a subject's assumptions about movement he or she is producing voluntarily.
 Fortunately, it appears possible to go back to Graham Brown's cat and its olivocerebellar system to see whether the directional skewing it participates in can be triggered by those conditions leading to vection in humans.
 Wor1( is now underway toward that end.
 References 1.
 Barmack, N.
H.
 Immediate and sustained influences of visual olivocerebellar activity on eye movement.
 In: Talbott, R.
E.
, and Humphrey, D.
R.
 (Ed.
), Posture and floveflient.
 Raven (New York), 1979: 123168.
 2.
 Bernstein, N.
A.
 On the Construction of Movement, Medgiz (Moscow, 1947).
 3.
 Boylls, C.
C.
 A theory of cerebellar function with applications to locomotion.
 II.
 The relation of anterior lobe climbing fiber function to locomotor behavior in the cat.
 In: COINS Technical Report 751, Dept.
 Computer * Information Sciences, Univ.
 Massachusetts (Amherst), 1976.
 4.
 Boylls, C.
C.
 Prolonged alterations of muscle activity Induced in locomoting premammillary cats by microstiroulation of the inferior olive.
 Brain Res.
, 197fi, 195: 445450.
 5.
 Boylls, C.
C.
 Contributions to locomotor coordination of an olivocerebellar projection to the vermis in the cat: Experimental results and theoretical proposals.
.
 In: Courville, J.
, Lamarre, Y.
, and de Montigny, C.
 (Ed.
), The Inferior Olivary Nucleus: Anatomy and Physiology, Raven (New York), 1980: 321348.
 6.
 Brandt, T.
, Buchele, W.
, and Arnold, F.
 Arthrokinetic nystagmus and eaomotion sensation.
 Exp.
 Brain Res.
, 1977, 30: 331338.
 7.
 Brandt, T.
, Oichgans, J.
, and Koenig, E.
 Differential effects of central versus peripheral vision on egocentric and exocentric motion perception.
 Exp.
 Brain Res.
, 1973, 16: 476491.
 8.
 Greene, P.
H.
 Problems of organization of motor systems.
 Prog.
 Theor.
 Biol.
, 1972, 2: 304338.
 9.
 Kelso, J.
A.
S.
, Holt, K.
G.
, Rubin, P.
, and Kugler, P.
N.
 Patterns of human interlimb coordination emerge frDm the properties of nonlinear, limit cycle oscillatory processes: Theory and data.
 J.
 Mot.
 Behav.
, 1981, 13: 226261.
 10.
 Lacquaniti, F.
, and Soechting, J.
F.
 Coordination of arm and wrist motion during a reaching task.
 J.
 Neurosci.
, 1982, 2: 399408.
 11.
 Lundberg, A.
, and Phillips, C.
G.
 T.
 Graham Brown's film on locomotion in the decerebrate cat.
 J.
 Physiol.
 (Lond), 1973, 231: 90P91P.
 12.
 Nashner, L.
M.
 Fixed patterns of rapid postural responses among leg muscles during stance.
 Exp.
 Brain Res.
, 1977, 30: 1324.
 13.
 Nashner, L.
M.
, and Wolfson, P.
 Influence of head position and proprioceptive cues on short latency postural reflexes evoked by galvanic stimulation of the human labyrinth.
 Brain Res.
, 1974, 67: 255268.
 23 Conscioua and unconscious coi.
ponents of intentional control.
 Bernard J.
 Baars and Diane N.
 Kraff.
er State University of Mew York at Stony Brook.
 How is intentional action controlled? Other papers in this sw.
posiur.
s provide evidence for a style of motor control in which executives issue very general cotrjr.
ands, which are interpreted "distributively" by intelligent specialized subsystems, which are sensitive to local context.
 LiKewise, there are classical suggestions that conscious con.
por.
ents of intentional control serve an executive function, but without controlling motor systeirs in great detail: instead, the subsysteir.
s controlling actions interpret very siirple conscious contents intelligently, with a view to local context (Jatr.
es, 1890).
 We suggest that there is much to be said for Jair.
es' view of intentional control; ^Jrther, his view fits a conception of conscious processes advanced by Baars (in press), suggesting that conscious representations are global , coherent , and informative in a r.
ervous system consisting of distributed specialists which control all information processing details (Figjre 1).
 Figure 1 Globally Distribute) In form it Ion; CONSCIOUS Spaclall imd Syttam* (UacanMlaiM ) Table 1: Capability Dn a theory of Conscious Processes 1.
 Computationally Lnef fie lent.
 2.
 Great range, A relational capacity.
 3.
 Apparent inity, seriality, 4 limited capacity.
 Constraints conscious contents.
 Unconseious processors Highly efficient in specialized tasks.
 Limited domains & relative autonomy.
 Very diverse, parallel, and together have great capacity.
 Table 1 shows a set of widelyaccepted facts about conscious vs.
 unconseious processes which fit this fieneral view.
 Like conscious processes, entirely global processes are !ear.
putationally inefficient because they require the cooperation or tacit ccnsent of maiy other processes to remain i^lcbal.
 TViey have great range' of possible content siroe any specialist, or set of specialists has potential access to the global data base, and great relational capacity, for the san.
e reason.
 Global representations, like conscious contents, have apparent jr.
ity' because internal contradictions woula ur.
ply cotr.
petition between different prccesscrs, which '.
jculc destabilize the global representation; !.
ence any oom.
peting representations rr.
ust ̂  displayed serially , and the global component would seem to have limited capacity.
.
 Siff.
ilarly, the unconscious processors of Table 1 resemble the specialized processors of Figure 1.
 Though this is only a firstapproxination m.
odel of conscious v3_.
 unconscious activity, it will serve as a basis for approaching conscious vs.
 unconscious components of intentional activity.
 Note that conscious contents are globally available, but most detailed information processing is performed locally by a large set of specialized, distributed processors.
 Ihe specialized processors maintain the processing initiative.
 Now consider the facts shown in Table 2 about contrasts between conscious and unconscious aspects of intentional activities.
 Table 2 ; Conscious eonsponents Probleir.
 assignment Problem solution (.
ihal) Goal representation Goal feedback Biofeedback signal Seriality of nonautomatic tasKS.
 Stimulus for reflexes and externallydriven automatic tasks.
 Intentional modulation of reflexes and autom.
atic tasks.
 Unconscious components (») Problem incubation Goal execution Openloop adjustment of future actions.
 System, controlling biofeedbacK.
 Parallelisr.
 of automatic tasks.
 Detailed control cf reflexes and automatic tasks.
 24 (•) Some of these may be mor.
entarily conscious, but too briefly to be retrievable subsequently.
 Note first that in classical problemsolving tasKS, the stage of .
 problem.
assignr.
ent — the accur.
ulation of constraints on a possible solution — is conscious; however, all the detailed prohttp://Jair.
es'cesses working toward a solution operate urconsciouslv, while t^e solution itself becott.
es conscious unexpectealy, as ar.
 "nha!" experience.
 In intentional problem solving, the very fact that a goal is trade conscious sen/es to trigger 'jnccnscious systeir.
s able to contribute to this goal.
 This fits the rough T.
odel of Figure 1, since distributed specialists can be triggered hy a global display of a goal.
 These specialists then work locally on a solution, and can return a solution to the global display when they reach it.
 In the ciassioaj.
 prcblea.
solving case, the differences between conscious and unconscious parts are quite obvious; however, xuch the sarr.
e corr.
ponents T.
gy also operate in other cases of intentional control, where they ir.
ay occur much more quickly jini less discretely.
 For example in biofeedback training, a conscious feedback signal is triggered by an otherwise unconscious neural process.
 In itself, this is sufficient for intentional control of the unconscious process to develop.
 The model suggests that the feedbacK is "broadcast" globally, throughout the nervous system, so that one subsystem out of maiy millions that can control the feedback can "decide" to act whenever the feedback occurs.
 In this fashion, sensory feedback can come to control otherwise totally unrelated neural processes: thus, a feedback click can cocr.
e to control a .
single TOtor unit (Basmajian, iQ'^j), and the tast of saccharin can come to elicit suppression of ircir.
jne function twder \ Cohen, 1982).
 The "executive ignorance" of conscious processes is not llir.
ited to new or exotic intentional control tasks.
 Williaa James (1890), among others, has pointed out that "we" do net know in any detail how we do anything .
 One can account for this ignorance by assuring that we do not need to know anything: we can just know the goal consciously, and :jnccnscious hut very intelligent specialists will take care of execution of the goal.
 flote also in Table 2 that feedback from an intentional action is ecnscious, a fact that presur.
ably permits 'jnconscious Ijr.
proven.
ents in planning and execution to take place, in preparation for the next tur.
e that the action will be performed.
 Ihis is especiallv true if there is a mismatch between the intended action and its performance.
 But the case has so far been over simplified.
 In fact, we cannot think of an action as being controlled by a single goal.
 Baars 4 Mattson (1981) maintain that an intention is indeed a multileveled gcal structure'^, of v*.
ich only a few goals tend to be conscious.
 The multileveled intention can be separated into presuppositions of the conscious goal, and subordinate systems involved in executing the conscious goal.
 Further, practically all intentional actions consist of a continuous mixture of conscious and unconscious components.
 Generally speaking, most routine components tend to be largely unconscious, while these components that are new or involve som.
e choicepoint may be conscious.
 Thus, in skilled typing, we may be conscious of nonroutine starting points of action, of input and output, and of attempts to override, modulate, or interrupt the typing task.
 Generally we seem, to be unconscious of the mapping between letters and fingerstrokes, of the details of motor control, and of highly repetitive input or output.
 nS we acquire proficiency in a task, it tends to becom.
e less and less conscious — in terms of the m.
odel, it tends to be consigned to specialized, autonomous systeir.
s with fewer global messages.
 Schneider (1980) has found that tasKS which are initially slow, serial and capacitylljr.
ited become increasingly fast, parallel and unli^.
ited as they becoff.
e autom.
atic with practice.
 This is alm.
ost a perfec characterization of the difference between global and local processes in the current model.
 Coff.
petitlon: One of the most important properties of the model is that it permits competition; there is m.
uch reason to think that corr.
petition plays a central role in the control of intentional activity (Norman 4 Shallice, 1980).
 One can in.
agine a nur.
ber of different kinds of coff.
petition in this model: 1.
 Conflicting intentions: intentions may be incompatible.
 Ln this, often the mismatching components seem, to become conscious.
 2.
 Conflict between superordinate and subordinate components of a single intention.
 This is typically the case with psychopathologics (see Table 5).
 5.
 Conflict between an intention and its execution.
 Slips can be defined as actions that violate the actor's own expectations (Baars 4 Mattson, 1981).
 Slips often become conscious, perhaps because global broadcasting helps to reeouple a previously deeov^sled goal cor.
ponent, whose absence penritted the slip to occur.
 U.
 Conflict between intentions and external reality.
 And of course, som.
etimes the m.
eans needed to carry out an intention are unexpectedly unavailable.
 Table 5 Perceived intentional vs.
 unintentional activities.
 Intentional: Sense of some conscious control Most ordinary actions, thoughts, iirages, and feelings.
 Effect of "paradoxical intention" on unintentional activities Success in wellknown tasks Skeletal m.
uscle control Internally motivated actions.
 Activities whose pace is unforced.
 Unintentional: Sense of no conscious control (») Actions: compulsions, undesired habits, slips, ties, speech defects, and addictions.
 Thoughts and images: phobic, obsessive, hallucinatory, anxietyprovoking, depressive.
 Feelings: anxious, depressive, etc.
 Resisted unintentional activities.
 Failure in wellknown tasks (TOT phenomenon) Reflexes, autonomic functions, and automatic processes cued externally.
 Externally coerced actions.
 Actions triggered by direct brain stiir.
ulation (Penfield 4 Roberts).
 Slips induced experim.
en tally.
 Activities that are forced at a pace faster than normal.
 (•) Some processes which do not yield a sense of 25 conscious control may in fact be triggered by brief conscious contents that cannot be retrieved.
 We suggest the following general conclusions, based on the material presented in Table 3: Intentional activities appear to be triggered by conscious contents.
 Intentions are violated not only when the action is jnexpeeted, but also when the subordinate systeir appears to resist control — e.
g.
 when it takes longer to find a certain word than one expects.
 This suggests that intentions carry infonr.
ation about the typical duration and difficulty of a known task.
 Further, it also suggests that "rr.
ental effort" occurs not as a function of the coir.
plexity of a task, but rather, as a function of th.
e deRree of perceived resistance to the intention, car.
pared to the expected d'jration and difficulty of the tasK.
 This view tr.
ay also help explain the related case of perceived coercion (a case of unintentionalr.
ess which is r.
ot just a political fact, but also occurs very often in our educational system).
 Such perceived coercion ftan: an outside source tr.
ay bring about a great deal of internal cctr.
petitior.
 between systems attempting to exert executive control in a way that is insensitive tc the den'.
ands of the subordinate system.
 Gne implication is that intentions, too, have their own "ecology": a successful intention must fit into the system as a whole, or competition will occur which will increase the perceived effort in carrying out the intention.
 References Baars, B.
J.
 Conscious contents provide the .
ervous systetr.
 with coherent, global infonr.
ation.
 In R.
J.
 Davidson, G.
 Schwartz, i 0.
 Shapiro (eds.
) Corsciousness i selfregulation (Vol.
 j).
 N.
Y.
: PI en or.
, in press.
 Baars, E.
J.
 4 Mattson, M.
E.
 Consciousness and intention: n framevcrk and some evidence.
 Cognition ĵ  Brain Theory, igfll, 4(3), 2U7265, Basmajian, J.
V.
 Control and training of individual T.
ctor units.
 Science.
 1963, 141, 4iW441.
 Jam.
es, W.
 The principles of psychology.
 N.
?.
: Holt, ifigo.
 Schneider, W.
 4 Fisk, A.
D.
 Dual task autom.
atic and controlled processing of temporal and spatial patterns.
 (Tech.
 Rep.
 8002) Univwsity of Illinois, February, 1980.
 26 http://Jam.
esS u b m i t t e d P a p e r s How do Children Learn to Judge Gramnatlcality? A Psychologically Plausible Computer Model Mallory Selfrldge Department of EE and CS University of Connecticut Storrs, CT.
 06268 1.
0 Introduction If a young child is asked whether the sentence "ball me the throw" sounds "silly" or "ok", chances are the child will respond "silly.
" Encouraged to "fix it up," the child may well generate "throw me the ball.
" Such behavior was reported by Gleitman et al.
 [7] for children of twoandahalf and five years.
 It implies that by these ages children have acquired at least some ability to Judge a sentence's grammaticality.
 Further, Gleitman et al.
 report that by age five, children's judgements increase in sophistication.
 Thus children's ability to judge granmaticality apparently Increases as they learn language.
 Unfortunately, little is known about the mechanisms responsible for the development of such abilities.
 Pinker [lO], reviewing language acquisition models, reports no work in this direction.
 Anderson's [l] model of language learning does not address learning to make granmaticality judgements.
 Recent research (e.
g.
 [2,3,8]) on syntactic recognition and learning has not been integrated into a model of child learning.
 The question ranains: "how do children leam to make gramnaticallty Judgements?" This paper addresses this question by proposing a three stage model, implemented and tested in the CHILD program [12,13,14,15].
 During stage one CHILD knows word meanings but not syntax, and can understand sentences, but cannot tell that word order is incorrect.
 During the second stage, CHILD has learned active syntax, and notices incorrect word order for active sentences.
 During the third stage, CHILD learns passive syntax, and notices incorrect word order for both active and passive sentences, this progression corresponds generally to Gleitman et al.
's finding that as children learn more language their ability to make grammaticality judgements increases.
 child's mechanisms may provide part of the answer to the problem of how children learn to make grammatical!ty judgements of sentences with incorrect word order.
 These mechanisms have been developed to account for a number of different data about child language learning [l4], and their extension to the problem of granmaticality judgements has been straightforward.
 The CHILD model suggests that children learn to make such Judgements almost entirely as a sideeffect of mechanisms whose primary function is directed elsewhere.
 This paper describes the CHILD program, and presents sample output.
 The question of learning to make grammatlcality Judgements is considered, and several predictions are described which may confirm or deny this account.
 2.
0 The CHILD Program CHILD is a computer model of the development of language comprehension and generation abilities written in Franz LISP and currently running on a DEC VAX 11/780.
 It begins with world knowledge and language experiences similar to those received by children, and learns a subset of the word meaning and syntax which children leam.
 After learning, CHILD can correctly understand utterances which it previously misunderstood, and can generate English describing events it "observes.
" child's language comprehension process is a version of the CA program [4] which incorporates mechanisms derived from Wilks' [I6] preference parsing.
 CHILD'S analysis process combines Conceptual Dependency (CD) [ U ] word meanings to form a CD representing the meaning of the entire utterance.
 Understanding begins when the meanings of input words are placed in a short term memory.
 CHILD then retrieves semantic requirements associated with those slots but specific to that particular word.
 It searches the short term memory for a word meaning which best satisfies those features, and fills the empty slot with that meaning.
 The syntactic features are formed from the positional predicates PRECEDES and FOLLOWS.
 These relate the position of a candidate slot filler to either the word they were stored under, a filler of another slot in that word's meaning, or a lexical function word.
 Each slot in the meaning of a word has a collection of features describing where in the input a filler is expected to be.
 In order to understand different voices, these features are organized into disjunctive "feature sets.
" Each set characterizes one order in which slot fillers appear.
 During understanding, feature set selection Is performed by considering which set most successfully characterizes the input.
 CHILD learns syntax by acquiring syntactic features and build dlsiunctlve feature sets.
 After having understood an utterance, CHILD examines a record of the input, and examines the meaning of every input word.
 It then examines every empty slot in each such meaning.
 It accesses the record of the input to find where in the input the filler for that slot occurred.
 It creates a description of this position using PRECEDES and FOLLOWS.
 CHILD must then decide whether this description constitutes a new feature set or should be merged with an existing feature set.
 CHILD'S strategy is based on a suggestion by Iba [8].
 CHILD compares the features extracted from the current input with any existing feature sets: the position description is merged with a previous set only if one is a subset of the other.
 Otherwise, the description Is learned as a new feature set.
 CHILD notices that a sentence is ungrammatical if any syntactic features within the selected feature set characterizing the position of a slot filler are not true of the position of that filler.
 CHILD uses these features to generate an explanation of why the sentence was ungrammatical, and uses its language generation abilities [6] to generate a correct version based on the sentence's understood meaning according Co whatever word meaning and syntax it knows about at that stage of learning.
 3.
0 Learning to Make Grammatlcality Judgements The following example is edited from a complete 27 run of the program during which it learns meaning and syntax for all the words it knows.
 The example begins after CHILD has learned meanings for "throw", "me".
 "Child," "Mom," "on.
" "table," and "ball.
" For this example, the meaning of "throw" has been simplified from a complex CD into $THROW and processing of "the" has been ignored.
 As shown below.
 CHILD is initially given an ordinary sentence which it understands correctly.
 The second sentence has incorrect word order.
 CHILD understands this sentence correctly, but falls to notice the incorrect order.
 :HILD hears "throw me the ball" CHILD understands (STHROW ACTOR (CHILD) OBJECT (BALL!) TO (PARENTl)) :HILD hears "ball me the throw" pHILD understands KSTHROW ACTOR (CHILD) OBJECT (BALLl) TO (PARENT!)) Transition to the second stage occurs when CHILD learns active syntax for "throw.
" This occurs when it hears an example sentence whose interpretation is unambiguous, and has heard the word a number of times without modifying its meaning.
 Given this sentence, CHILD notes the positions of the fillers (summarized in linear order here), and stores them in a feature set under the word "throw.
" CHILD hears: "throw me the ball" CHILD'S understanding is: ($THROW ACTOR (CHILD) OBJECT (BALLl) TO (PARENT!)) CHILD learns syntax of "throw" order is: STHROW TO OBJECT ATTQIPTING MERGE OF NEW FEATURES WITH EXISTING SET NO EXISTING FEATURES SETS CREATING NEW FEATURE SET Having learned active syntax for "throw," CHILD uses this knowledge during stage 2 understanding.
 It notices when the word order of a sentence is Incorrect, as the first sentence below shows.
 CHILD prints out the reasons it thought the sentence was incorrect, and generates a correct version from the understood meaning of the sentence.
 However, CHILD also decides that a passive sentence with correct order is incorrect, as the second sentence below demonstrates.
 CHILD hears "ball me the throw" CHILD understands (STHROW ACTOR (CHILD) OBJECT (BALL!) TO (PARENT!)) INCORRECT SENTENCE NOTICED: "throw" should precede "ball" "throw" should precede "me" CORRECTION: "throw me the ball" CHILD hears ; "the ball was throw n on the table by Child" CHILD understands (STHROW ACTOR (CHILD) OBJECT (BALLl) TO (TOP VAL (TABLED)) INCORRECT SENTENCE NOTICED: "Child should precede "throw" "throw" should precede "ball" CORRECTION: "Child throw ball on table" The transition to the third stage occurs when CHILD 28 learns passive syntax for "throw," and creates a second feature set for the new syntactic features.
 CHILD hears: "the ball was throw n to Mom by Child" child's understanding is: (STHROW ACTOR (CHILD) OBJECT (BALL!) TO (PARENT!)) CHILD learns syntax of "throw" order is: OBJECT "was" STHROW "to" TO "by" ACTOR ATTEMPTING MERGE OF NEW FEATURES WITH EXISTING SET MERGE FAILS CREATING NEW FEATURE SET Once CHILD has learned passive syntax (reported in more detail in [l5]).
 It can then Judge passive sentences.
 It correctly Judges the passive sentence which it previously Judged Incorrect.
 The second sentence below is an incorrect passive, and CHILD correctly understands it, prints out the reasons It was Judged incorrect, and generates its corrected version.
 CHILD hears "the bjll was throw n on the table by Child" CHILD understands (STHROW ACTOR (CHILD) OBJECT (BALL!) TO (TOP VAL (TABLE!))) CHILD hears: "the ball to Mom throw n by Child" child's understanding is: (STHROW ACTOR (CHILD) OBJECT (BALL!) TO (PARENT!)) INCORRECT SENTENCE NOTICED: "the ball" should precede "was" "thrown" should precede "to Mom" CORRECTION: "the ball was thrown to Mom by Child" As shown above, CHILD does progress through a series of stages which generally correspond to data reported by Gleltman et al.
, during which it learns to make increasingly accurate and complex graamadcallty Judgements.
 Initially knowing no syntax, all sentences are Judged correct.
 After learning active syntax, it successfully Judges active sentences, but Judges passive sentences as if they should have been active.
 Upon learning passive syntax, CHILD Judges both active and passive sentences correctly.
 In the complete run, CHILD also learns to understand noun phrases, prepositional phrases, and adverbial phrases, and learns to make Judgements about sentences containing these constructions.
 4.
0 How Do Children Learn to Make Gr< Judgements? ticality child's answer to this question depends upon a number of factors: a) the representation of language syntax as a set of independent features characterizing the position in the input where a slot filler may occur; b) learning of syntactic features while learning to understand; c) the evaluation of syntactic features and semantic preferences as a necessary part of understanding.
 Given these mechanisms, children make grammaticality Judgements by analyzing syntactic violations occurring during understanding.
 They generate correct versions of incorrect sentences by applying their language generation ability to the understood meaning of that sentence.
 Thus children acquire the ability to make grammatlcality Judgements as a side effect of acquiring syntactic features needed for understanding.
 This account of learning to make grammatlcallty judgements makes several predictions.
 First, this model predicts that people's judgements of incorrect sentences will not merely be "grammatical" or "not grammatical," but rather judgements as to the relative gransatlcalness of a sentence.
 This prediction follows from CHILD'S generation of a number of different reasons for a sentence's Incorrectness.
 Second, this model predicts that as a child learns Increasing amounts of syntax he will find certain sentences Increasingly ungrammatical.
 This is because newly learned syntax becomes available to Judge graimatlcality, and thus the number of violated syntactic features Increases.
 Third, this model predicts that before learning passive syntax children will judge nonreversible passive sentences to be ungrammatlcal.
 This is because at this stage they are using active syntax to understand passive sentences.
 Later, when they have learned passive syntax, they will no longer judge nonreversible passive sentences ungrammadcal.
 Clearly, this work, has not completely solved the problem of how children learn to make grammatlcallty judgements, since there are certainly a large number of complex syntactic constructions which CHILD cannot handle.
 In addition, it Is not even clear what exactly constitutes such Judgements, since Gleltman et al.
 report that children think sentences are "silly" for a number of reasons not discussed here.
 It is hoped, however, that this approach will prove a promising direction for further research, since it Is grounded in mechanisms which manifest and explain a number of other psychological data.
 Acknowledgements Thanlcs to Rich Cullingford for sponsoring this paper, and to Peter Selfridge, Oliver Selfridge, Don Dickerson, Jason Engleberg, and Marie Blenkowskl for helpful discussions of this work and for conmenting on drafts of this paper.
 [7] Gleltman, L.
R.
, Gleltman, H.
 and Shipley, E.
F.
 (1972).
 The Emergence of the Child as Grammarian, Cognition, 12/3:116A.
 [8] Iba, G.
 (1979).
 Learning Disjunctive Concepts from Examples.
 M.
I.
T.
 A.
I.
 Memo #548, M.
I.
T.
, Cambridge, Mass.
 [9] Marcus, M.
 (1980).
 A Theory of Syntactic Recognition for Natural Language.
 M.
I.
T.
 Press, Cambridge, Mass.
 [10] Pinker, S.
 (1979).
 Formal Models of Language Learning.
 Cognition.
 7:217283.
 [11] Schank, R.
C.
, (1973).
 Identification of Conceptualizations Underlying Natural Language.
 In R.
C.
 Schank and K.
M.
 Colby (eds.
) Computer Models of Thought and Language.
 W.
H.
 Freeman and Co.
, San Francisco.
 [12] Selfrldge, M.
 (1980).
 A Process Model of Language Acquisition.
 Computer Science Technical Report 172, Yale University, New Haven, Ct.
 [13] Selfrldge, M.
 (1981a).
 Why Do Children Say "Goed"? A Computer Model of Child Generation.
 Proc.
 Third Annual Meeting of the Cognitive Science Society.
 Berkeley, CA.
 [14] Selfrldge, M.
 (1981b).
 A Computer Model of Child Language Acquisition.
 Proc.
 7th Int.
 Joint Conf.
 on Artificial Intelligence.
 Vancouver, Canada.
 [15] Selfrldge, M.
 (1982).
 Why Do Children Misunderstand Reversible Passives? The CHILD Program Learns to Understand Passive Sentences.
 Submitted Co the 3rd Annual AAAI Conference, Pittsburgh, Penn.
 [16] Wllks, y,, (1973).
 Parsing English II.
 In E.
 Chamlak and Y.
 Wllks (eds.
) Computational Semantics.
 NorthHolland Publishing Co.
, NY, NY.
 References [l] Anderson, J.
R.
 (1981).
 A Theory of Language Acquisition Based On General Learning Principles.
 Proc.
 7th IJCAI, Vancouver, Canada.
 [2] Baker, C.
L.
 and McCarthy, J.
J.
 (1981).
 The Logical problem of Language Acquisition.
 M.
I.
T.
 Press, Cambridge, Mass.
 [3] Berwick, R.
C.
 (1977).
 Learning Structural Descriptions of Grammar Rules from Examples.
 Proc.
 5th IJCAI, Cambridge, Mass.
 [4] Bimbaum, L.
 , and Selfrldge, M.
 (1981).
 Concepcualal Analysis of Natural Language, in Inside Computer Understanding: Five Programs plus Miniatures.
 Schank R.
 and Riesbeck C.
K.
 (eds.
), Lawrence Erlbaum Associates, Hillsdale, NJ.
 [5] Chomsky, N.
 (1965).
 Aspects of the Theory of Syntax.
 M.
I.
T.
 Press, Cambridge, Mass.
 [6] Cullingford, R.
E.
, Krueger, M.
W.
, Selfrldge, M.
 and Bienkowsky, M.
 (1981).
 Automated Explanations as a Component of a CAD System.
 IEEE Trans.
 SM&C.
 Special Issue on Human Factors and User Assistance in CAD, December, 1981.
 29 PATHFINDER: INVESTIGATING THE ACQUISITION OF COMMUNICATIVE CONVENTIONS Robert Cunmins The University of Wisconsin—Milwaukee Eric Dietrich Martin Marietta Corporation This work was supported In part by a grant from the National Science Foundation, and by the Institute of Cognitive Science, University of Colorado (Institute of Cognitive Science publication no.
 ).
 ABSTRACT PATHFINDER is a system that solves coordination problems that require acquisition of a convention governing the intended meaning of a symbol.
 LEADER blazes a trail through a maze by leaving symbols in the various paths, and FOLLOWER must find LEADER by discovering the Intended meanings of these blazes.
 PATHFINDER is the first step In a project to design a system that can solve a variety of coordination problems of the sort implicated in language acquisition.
 Solving certain coordination problems is conmuni eating.
 Since coordination problem solution can become conventional (as David Lewis has shown), communication can become conventional, and that is language in its most general form.
 As conventions are acquired, more sophisitcated coordination problems can be solved, and more sophisticated conventions can be acquired.
 Eventually, it should be possible to acquire conventions governing identifiers and general terms, and this will enable use of a first order language via a recursive procedure adapted from Tarski by Cummins.
 PATHFINDER: INVESTIGATING THE ACQUISITION OF COMMUNICATIVE CONVENTIONS The PATHFINDER project is a study of the acquisition of the capacity to communicate by means of conventiongoverned symbols, and of the knowledge structures required for such conwuni cation.
 The project revolves around a series of PATHFINDER programs, each of which contains two programs—LEADER and FOLLOWER—which together solve coordination problems in a way that requires acquisition of conventions governing the meaning of a symbol.
 We begin by sketching the theoretical background, then turn to PATHFINDER itself.
 In 1973, Jonathan Bennett (Bennett, 1973, 1976) outlined a two phase account of language acquisition based on the pioneering work of Grice on meaning (1957, 1969) and Lewis on conventions (1969).
 In phase one, he explains along Grician lines what we shall call preconventional communication: cases in which a speaker S performs some action and thereby communicates with an audience A in a way that doesn't depend on the prior existence of any shared rules or conventions.
 In phase two, he imports Lewis' account of conventions to show how preconventional cases could lead to the establishment of a convention between S and A with the result that S's acttype comes to have a conventional meaning.
 Since Bennett's work in this area has not received the attention it deserves outside of philosophy, (especially in AI and cognitive psychology) we begin with a brief review of his twophase account.
 30 Phase One: Preconventional Communication.
 Bennett takesTrom Grice the ro I lowing conditional.
 (GO If S utters E, intending thereby to get A to believe that p, and relies for the achievement of this upon the Grician Mechanism (GM), then S means by E that p.
 Here is what we shall understand by the Grician Mechanism.
 (GM) A recognizes S's intention to get A to believe that p, and is led by that recognition, through trust in S, to believe that p.
 This is a simplified version of Grices more recent accounts, but we require only a rather crude sufficient condition at this stage of the account.
 Bennett claims that (GO could be satisfied by prelinguistic S and A, i.
e.
, by S and A who share no conventional means of conmunication.
 We agree with this assessment for reasons that will emerge later.
 For now we shall simply assume that prelinguistic S and A could satisfy (GO—though perhaps only rarely and in rather special circumstances—and that (GO does In fact formulate a sufficient condition for coranunication between S and A.
 Phase Two: Conventional 1zation.
 The second phase oT~Bennett's account imports Lewis' treatment of conventions to show how a convention could emerge between S and A governing S's communicative actions.
 For present purposes, the crucial feature of Lewis's theory is this.
 (L) When a group achieves coordination In a certain situation by acting in a certain way, and they act that way because (1) they wish to achieve coordination, and (ii) each actor knows, and knows the others know, that that is how coordination has been achieved in the past, then the group has a convention governing that situation.
 (L) applies to cases Involving coordination of action, whereas our problem involves coordination between S's action and A's beliefs.
 But (L) is easily extended to accomodate this fact because the sorts of reasons A can have for adopting £ belief so as to coordinate with S are Hie same sorts of reasons A will typically have for acting so as to coordinate with S.
 In particular, A can have as a reason for adopting the belief that S intends A to believe that p in uttering E the fact that A knows, and knows that S knows, that in the past S's intention in uttering E has been to get S to believe that p.
 If A is then led, through trust in S, to believe that p, we have a case that satisfies (GO because S's utterance of E is governed by a convention existing between S and A.
 This yields the following account of conventional meaning.
 (CM) Utterancetype E conventionally means that p when uttered by S to audience A if (a) in the past, S has uttered tokens of E to A only when S meant that p, and (b) this fact is mutually known to S and A, and (c) because of this mutual knowledge it continues to be the case that when S utters tokens of E, S means, and is understood by A to mean, that p.
 We can put the preconventional case and the conventional case together in an obvious way.
 Suppose S intends to get A to believe that a coconut is about to fall on A, and S goes through a certain performance that results in A recognizing S's intention and.
via trust in S, adopting the belief that A is aboutTo be hit by a coconut.
 Here we have a preconventional case in which connunication occurs only because conditions are especially propitious, and because S's performance has a certain natural suggestiveness.
 Next time, however, the mechanism of convention will set in, and, as repetitions occur, the special conditions favoring the original success will no longer be necessary.
 S's performance can be streamlined by a process akin to stimulus substitution to the point where it need have no special features beyond the fact that A and S perceive it to be of the same type as its predecessors.
 Thus, the account allows for the fact that a sign may, so far as its physical characteristics go, have any meaning whatever.
 Extending the Account.
 As it stands, the account just sketched Fiasn't a chance of being a fullscale theory of comnunicative conventions, for it begins and ends with sentence meanings—meanings have the form "that p" where p is a proposition.
 Since there cannot be infinitely many meaning conventions, it follows that the account just rehearsed runs afoul of the fact that a natural language contains infinitely many noncompound sentences having distinct meanings.
 This defect has been repaired in Cummins (1978), by Introducing Grid an meanings for identifiers and general terms.
 Here are the relevant conditions.
 (ST) There is a convention whereby N refers to x in S's language if (a) in the past S has uttered N only when intending to identify x, and (b) this fact is mutually known by S and S's audience, and (c), because of this mutual knowledge it continues to happen that when S utters N S identifies x.
 (P) There is a convention whereby G means yellow in S's language if (a) in the past S has uttered 6 only when he/she/it meant yellow, and (b) this fact is mutually known to S and S's audience, and (c), because of this mutual knowledge it continues to happen that when S utters G, S means, and is understood to mean, yellow.
 We can now state a relation between these meanings and satisfaction conditions, and import the standard recursion on the latter, to generate conventional meanings (though not meaning conventions) for an infinity of noncompound sentences.
 (S) 'The ith member of the sequence f is red' gives the satisfaction condition for a token consisting of the general term G applied to the ith variable iff the (or a) conventional maning of G is 'red'.
 (S) allows us to go back and forth between satisfaction conditions and conventional meanings.
 If we start with cases for which conventions exist for the primitive general terms, we get satisfaction conditions for those terms by moving from the meaning to the satisfaction part.
 We can then use the standard recursion to get a satisfaction condition for any first order combination of the primitive general terms.
 Then, moving from the satisfaction part of (S) to the meaning part, we get conventional meanings, though not meaning conventions, for complex general terms.
 It is wellknown that this sufficies to fix the truthconditions for each sentence in a firstorder language.
 Investigating Convention Acquisition.
 The acquisition and use of communicative conventions has not been very extensively investigated by researchers in artificial intelligence or cognitive psychology, presumably because the requisite theoretical background has seemed lacking.
 However, putting Grice's account of communication together with Lewis' account of conventions yields a powerful theory of the acquisition of communicative conventions.
 Extending the account to apply to acquisition of conventions governing identifiers and general terms makes it possible to use the recursive apparatus of Tarski's theory of truth definitions to generate meaning conventions for every sentence in a first order language having a finite number of semantically primitive terms.
 The upshot is a theory of language acquisition for first order languages.
 This theory, however, is incomplete or vague at several critical points.
 (1) The theory tells us what it is to be a party to a comnunicative convention governing a symbol with a propositional meaning, but it does not tell us how humans can or do actually solve primitive communicative convention acquisition problems.
 (2) The theory tells us what it is to be a party to a coimiunicative convention governing an identifier or general term, but it does not tell us bow humans can or do acquire such conventions on the basis of simpler shared coitmunicative conventions, viz.
, conventions governing symbols with propositional meanings.
 We propose to meet point (1) by adding the hypothesis (i) that primitive coninunication problems can be solved, and appropriate conventions acquired, in the course of solving simple coordination problems that contain the conmunlcative problems as subproblems.
 The problem analyzed by PATHFINDER Is just such a containing problem.
 We propose to meet point (2) by adding two hypotheses: (11) that the power of a group of agents to solve coordination problems increases as that group acquires coitmunicative conventions; (ill) that solving relatively more complex containing coordination problems enables agents to acquire relatively more sophisticated communicative conventions.
 It is these three hypotheses that the PATHFINDER PROJECT is primarily designed to investigate.
 PATHFINDER: Embedding Communication Problems in other Coordination Problems.
 Prelingulstlc communication problems are ditticult to solve in part because propositional attitudes are hidden.
 It is difficult for a speakeraudience pair to determine whether or not they have succeeded.
 This difficulty can be overcome by embedding primitive communication problems in other noncoimiunicatlve coordination problems that are more tractable.
 If S and A are engaged in some cooperative activity, the success or failure of their efforts to communicate will be more or less obviously reflected in the success or failure of that activity.
 In PATHFINDER, LEADER and FOLLOWER must solve such an embedded coordination problem.
 LEADER blazes a trail through a maze by leaving symbols in the various paths, and FOLLOWER must find LEADER by discovering the intended meanings of these blazes: LEADER must enable FOLLOWER to find LEADER.
 In the process, they must solve a primitive corimunication problem.
 For example, in the levelone version of PATHFINDER, FOLLOWER may learn that when LEADER marked a path "Y", LEADER meant that that path is to be avoided.
 Suppose FOLLOWER locates LEADER by avoiding paths marked "Y".
 Then LEADER and FOLLOWER will have solved their main coordination problem, and they will have solved a primitive communication 31 problem as well.
 Most importently, however, they win have solved a primitive convention acquisition problem: both know that "Y" means "avoid this path".
 This convention can be used in the solution of other related coordination problems, thereby increasing the power of LEADER and FOLLOWER to solve such problems, and hence increasing their power to acquire other conventions.
 For example, it is evidently easier for FOLLOWER to grasp an identifer in the context of an already understood instruction.
 "Avoid Y at zz," links use of the identifier to solving the embedding coordination problem (find LEADER), thereby making it possible for LEADER and FOLLOWER to recognize successful conmunication, and hence to acquire a convention governing use of the identifier.
 Conventions are a special kind of knowledge that increase capacity to solve coordination problems far more effectively than other types of shared knowledge.
 Advanced LEADERFOLLOWER pairs will come to share conventions governing such things as the identifiers, general terms, and syntactic rules of a relatively sophisticated language.
 Preliminary research has suggested a list of parameters of two types, intrinsic and contextual, the values of which define a relative level of sophistication.
 The coordination problems analyzed by PATHFINDER are significantly different from each other depending on the type of maze FOLLOWER faces (intrinsic parameters) and Uie amount and type of knowledge, including conventions, shared by LEADER and FOLLOWER (contextual parameters).
 This is especially significant given the hpypothesis that the capacity of two parties (LEADER and FOLLOWER, SPEAKER and AUDIENCE) to solve coordination problems should increase as simple problems are solved and conventions are acquired for future use.
 Intrinsic Parameters.
 FOLLOWER will eventually have T o Face mazes STat vary in at least the following ways: (1) number of branches per node; (ji) number of symbols per branch (including blanks); (ill) complexity of symbols—e.
g.
, context sensitivity and reference to other parts of the maze; (1v) noise—e.
g.
, symbollike objects in the maze not left by leader.
 Contextual parameters.
 To solve the coordination probTem se? by a relatively general maze, LEADER and FOLLOWER will have to share some knowledge.
 The amount and type of shared knowledge are contextual parameters of the coordination problem, for they specify the cognitive context in which the coordination problem is attacked.
 These include: (1) previously acquired conventions, if any, (11) mutual knowledge of capacities—e.
g.
, can LEADER cut down a tree, and does LEADER know FOLLOWER knows this? (ill) mutual knowledge of what is likely to be a natural rather than an artefactual feature—e.
g.
, that pine cones are noise in a forest, but possible blazes in a building; (iv) mutual antecedent knowledge of the terrritory; (v) mutual knowledge of behavioral and cognitive tendencies.
 These parameters are best thought of as "passed" to LEADER and FOLLOWER from containing systems that specify the goals (blaze trail; find LEADER), contain records of mutual knowledge, and handle general reasoning and decision making, including when to give up, or to give up trying hard and just "try something" (a conmon strategy in conmunication).
 The levelone version of PATHFINDER (which has already been implemented), involves a maze in which all branching is binary, there is at most one symbol per branch, and noise is limited by the assumption that only the symbols encountered at the first node are significant.
 In a levelone maze, FOLLOWER 32 faces a relatively simple but nontrivial task.
 A maze that is general along all four dimensions specified above will evidently require a highly "experienced" LEADERFOLLOWER team, a team that, we suspect, will have to share several powerful conventions to be effective.
 Sumnary.
 The PATHFINDER project is designed to investigate the following strategy for language acoulsition.
 S and A, given some shared knowledge and goals, but no shared conventional means of conmunication, solve a coordination problem such as that faced by LEADER and FOLLOWER.
 Several successes produce a shared convention.
 Now that S and A share a convention, they can solve more diffecult coordination problems, hence acquire more sophisticated conventions.
 Eventually, S and A will be able to acquire conventions governing identifiers and general terms, and hence, by a recursive process, a first order language.
 Since solving certain coordination problems is communicating, and coordination problem solution can become conventional, communication can become conventional, and that Is language.
 Standard approaches to the problem of symbolic communication have emphasized acquisition of knowledge of a language.
 Yet it seems clear that learning a language is neither necessary nor sufficient for communication.
 Knowledge of a language is a means to understanding a speaker, or communicating with an audience.
 Language use and understanding is not likely to be properly understood if it is studied Independently of the cognitive task that motivates it.
 The present project, in emphasizing the acquisition of communicative conventions, focuses on the cognitive task which language learning subserves and thereby avoids studying language acquisition 'out of context".
 REFERENCES Bennett, Jonathan (1973).
 "The MeaningNoainallst Strategy.
" Foundations of Language 10, 141168.
 Bennett, Jonathan (1976).
 Linguistic Behavior.
 Cambridge: Cambridge University Press.
 Cunmins, Robert (1978).
 "Intention, Meaning and TruthConditions.
" Philosophical Studies 35, 345360.
 Grice, H.
 P.
 (1957).
 "Meaning.
" The Philosophical Review 66, 377388.
 Grice, H.
 P.
 (1969).
 "Utterer's Meaning and Intentions.
" The Philosophical Review 78, 147177.
 Lewis, David (1969).
 Convention.
 Cambridge: Cambridge University Press.
 PLAY CONSIDERED AS A STRATEGY FOR KNOWLEDGE _ ACQUISITION Paul 0.
 Scott Department of Computer and Communication ScIences University of Michigan April 1982 1: INTRODUCTION If you ask a layman what he means by the term 'play' he will probably reply "activities which are useless but fun" or something very similar.
 If you ask a developmental psychologist the same question you will probably get much the same answer although he is likely to phrase it differently:"Play consists of behaviors and behavioral sequences that are organism dominated rather than stimulus dominated, behaviors that appear to be intrinsically motivated and apparently performed 'for their own sake' and that are conducted with relative relaxation and positive affect.
" Weisler and ncCal1 (197&) Patterns of behavior which appear to have no external purpose but are nevertheless enjoyable for the participant present something of a biological paradox.
 The majority of activities which are accompanied by positive affect clearly promote, either directly or indirectly, the participant's homeostatic or reproductive goals.
 An adequate theory of play must resolve this paradox by attributing a function to play.
 A number of theor i es have been advanced which attempt to do this by suggesting what the organism may gain by engaging in play.
 Space does not permit a discussion of the relative merits of these theories but see Weisler and McCall {I976) and Gilmore (I966) for reviews.
 Fortunately one particular theory appears to enjoy almost universal support.
 This we shall call the 'Cognitive Development Hypothesis'.
 Its basic premise is that the organism learns something through the process of play which is of value in later life.
 This theory has been advanced in a bewildering variety of forms which largely reflect the enormous range of things which a child learns.
 Taken together these various theories amount to a claim that play is the fundamental learning strategy by which children acquire mastery of themselves and of the perceptual, motor, cognitive and social skills which they will need throughout life.
 The cognitive development hypothesis provides an explanation of the function of play and hence resolves the paradox.
 It is very widely accepted by developmental psychologists, primato1ogists, pediatricians and laymen.
 Strangely it has received little acknowledgment from learning theorists.
 Thus a large and reputable text on learning theory (Hilgard and Bower 1975) contains no index reference for play.
 Piaget does assign a relatively minor role to play in his model but regards it as a particular case of assimilation rather than a fundamental learning strategy.
 Play has been equally ignored by artificial intelligence researchers interested in machine learning.
 I am not aware of any program which explicitly incorporates play as a learning activity although I think it would be fair to describe the behavior of AM (Lenat 1976) as playing with numbers.
 Otherwise AI programs seem to be based on the assumption that learning must be either a classroom experience (learning with a teacher) or an apprenticeship (learning while doing the task).
 This paper is intended to exhort both learning theorists and Al workers to take play more seriously.
 Although the cognit hypothesis provides an expl function of play it does complete theory.
 Such a theor account of how play activi motivated and rewarded.
 It content and structure of pla cognitive development hypothes framework within which more may be developed.
 The res devoted to sketching the outli theory.
 ive development anation of the not constitute a y must provide an ty is instigated, must explain the y activities.
 The is only provides a complete theories t of thi s paper i s nes of one such 2: A THEORY OF PLAY If play is a method of building a cognitive representation then any theory of play must make some assumptions about the nature of the representation which is built.
 I therefore begin the development of the theory with the following postulate:Play is an activity directed towards building a representation of the world in terms of the organism's abilities to do things to or with the entities which it encounters in the world.
 This hypothesis makes a strong claim about what is learned during play.
 It asserts that the organism is attempting to discover what it can do rather than what it should do.
 That is, it is not primarily concerned with learning what actions have desirable outcomes.
 It Is of course possible, and indeed probable, that the organism will obtain information about what it should do as a side effect of trying to discover what it can do, but the claim made in the hypothesis is that such information is not the goal of play behavior.
 Note that this does not imply that the organism will not be trying to determine the consequences of its actions but only that it will not be directly concerned with the values of those consequences.
 This form of representation in which the world is modelled in terms of how it relates to the organism's behavioral capabilities has some obvious merits.
 For example, it is an essential prerequisite for any kind of problem solving behavior since it enables the organism to generate alternative courses of action in a 33 given situation.
 However, since it is most readily understood in terms of simple motor responses to a given event there is a serious danger of underestimating its power and generality.
 It is therefore worth pointing out that it strongly resembles Gibson's notion of 'affordances' (Gibson 1977).
 It is also closely related to the pragmatic theory of meaning due to Peirce (1878) and subsequently elaborated by James.
 Dewey and Mead among others.
 For this reason we shall refer to it as a 'pragmatic representation'.
 Objectbased programming languages such as SIMULA and SMALLTALK represent entities using what is essentially a pragmatic represenlat ion.
 3: IMPLICATIONS OF THE HYPOTHESIS We now explore some of the implications of the hypothesis that play is a strategy for building a pragmatic representation of the world.
 In executing an ordinary goal oriented task the organism is attempting to effect some change of state in Its world.
 In doing this it uses knowledge of the properties of the world.
 In play the organism Is attempting to effect some change of state within its own representation of that world.
 In doing this it will use knowledge regarding that representation.
 Thus it can be seen that the goals of play are metagoals and hence that play involves access to metaknowledge.
 What sort of metaknowledge would bt relevant for the development of a pragmatic representation? If the organism is to discover what it can do then it presumably needs to have some representation of what it does not know it can do.
 That Is the metaknowledge mutt represent the organism's ignorance.
 Such a representation could be used to determine the course of play behavior.
 Thus the organism would in effect conduct experiments whose purpose is to reduce its own ignorance of its capablities in a manner loosely analagous with scientific research.
 The Introduction of the concept of metaknowledge raises the spectre of an infinite regress.
 Where does the metaknowledge come from? Is it necessary to play at playing In order to discover how to play? The threat of an endless regress can be avoided if the same activities which provide information for the pragmatic representation of the world also provide the Information needed to build a model of the organism's ignorance.
 This constraint Is not only satisfiable but also explains one of the basic empirical findings regarding play and exploratory behavior: the probability that a child will play or explore is related by an invertedU curve to the novelty of a situation.
 In a highly familiar situation the child will have a detailed pragmatic representation and correspondingly low ignorance and thus there is little to be gained by play.
 Conversely in a totally unfamiliar situation the child will have virtually no pragmatic representation and hence have no knowledge of its own Ignorance.
 In such circumstances he or she would essentially not know how to play.
 Only in the Intermediate case in which a partial pragmatic representation exists Is the child an Ie to construct potentially useful play activities.
 34 li: A SIMPLE IMPLEMENTATION In order to clarify the ideas discussed In the preceding section by providing a concrete example and to demonstrate that such hypotheses can indeed lead to a successful learning program, I shall now describe a very simple concept learning program which learns by playing.
 The organism in this case is a LISP program called PAN.
 PAN operates in a simple blocksworld type of environment.
 In this world are numerous objects which each have the properties of color.
size.
texture and shape.
 Each of these properties may take one of several discrete values.
 PAN Is able to apply three types of action to these objects.
 It can push them, kick them and pick them up.
 However these actions wilt only result In the object moving in certain cases.
 For example the operation of picking up might only result in the object moving If the object were small.
 Initially PAN does not know what classes of objects its three kinds of action will succeed on.
 Thus PAN's task is to discover the equivalence classes of kickable objects, pushable objects and objects which may be picked up.
 It must experiment entirely without external guidance until it is confident that it can predict the applicability of an action to an object.
 PAN does th i s by deveI op i ng a cI ass hierarchy.
 Initially it possesses only one class  the class 'Things'.
 All objects are instances of this class and all actions are initially attached to this class.
 As part of the attachment of an action to a class PAN stores an estimate of the probability that the action can be applied to a member of that class.
 This probability estimate is revised every time PAN tries to apply that action to an instance of that class.
 If this probability estimate is very large or very small then PAN is relatively certain about the applicability of the action to instances of the class and hence has no need to conduct further experiments.
 If however the probability is in the region of 0.
5 then PAN is highly uncertain and further development of the class hierarchy is needed.
 The actual measure of uncertainty used in the system is Shannon's information function (Shannon and Weaver, IJfcg).
 In fact any function of the probability which was unimodal in the interval 0 to I with a maximum at 0.
5 and a value of 0 at 0 and 1 would serve.
 The use of the Shannon function has the advantage of allowing one to interpret it as the informational value of a new subclass rather than being a meaningless number.
 The initial probability estimate assigned to each action for its attachment to the class Things is 0.
5 and hence they each have an uncertainty of 1.
 A cycle of the system is called an experiment.
 In each experiment the system finds the action which is attached to a class with highest uncertainty.
 An instance of that class is selected and the action applied.
 If the action is successful then, apart from the increase in the estimated probability, nothing else happens and the system begins a new exper iment.
 If the action Is unsuccessful then one of two processes may occur: a new subclass may be created or the action may be detached from the class.
 If the uncertainty exceeds a certain threshold then PAN will attempt to construct a subclass of the class in which the action has Just failed and then attach the action to the new subclass.
 (The action remains attached to the original class).
 It does this by repeatedly selecting instances of the original class until it finds one on which the action succeeds.
 It then selects a random attribute of that Instance, for example its color or its size, and uses that as the criterion for membership of the new subclass.
 The action is then attached to the new subclass with an initial probability estimate which is identical to the current probability estimate for the attachment of the action to the original class.
 This newly created subclass may or may not contain a higher percentage of objects to which the action may be applied.
 If it does then the subclass is clearly useful and hence will be retained.
 If it does not then the probability estimate will eventually fall below that of the corresponding estimate in the parent class.
 When this happens the action is detached from the subclass.
 If any class has no actions attached then it is removed.
 Hence only useful classes are retained.
 In this way the system develops a hierarchy of classes as it attempts to reduce its uncertainty.
 The system is able to learn both conjunctive and disjunctive concepts and will eventually reach a stage when all uncertainties are below threshold.
 In this situation PAN announces that it is bored and halts.
 Note the system does not necessarily find a minimal set of classes to represent the concepts it is discovering.
 This could be done at the expense of more elaborate rules for modifying the hierarchy.
 It does however achieve a correct if redundant representation.
 In this respect its behavior resembles that of human beings.
 The above account is simplified in one respect.
 Once subclasses have been constructed any given object may be an instance not only of a given class but also of one or more of its subclasses.
 Thus, if PAN is doing an experiment which involves applying an action to an Instance of some class, the particular instance selected may also be a member of a subclass to which the action is also attached.
 In these circumstances the experiment is effectively transferred to the subclass which has the highest probability estimate.
 The result of the experiment modifies the probability estimates of both the subclass and the parent class.
 However a second probability estimate is also kept for each attachment which is a measure of the proportion of attempted applications which were not passed down to a subclass.
 This second probability estimate, called usage, is multiplied by the Shannon information function in determining the uncertainty.
 This is analogous to Shannon's measure of the entropy of an information source.
 The reason for this modification is that if it were omitted the uncertainty of parent classes would remain high even when the appropriate subclasses had been constructed.
 This would lead to endless redundant experimentation.
 The modification described ensures that a class with successful subclasses will have low uncertainty values despite not having probability esimates close to 1.
 As indicated earlier PAN is only intended as a demonstration that the play theory can be used as the basis of a learning system which works without the assistance of a teacher.
 We are developing a much larger version of the system in which objects may possess relational attributes and actions may change those relations.
 PAN is however only a simple instantiation of the use of a play based learning strategy.
 The pragmatic representation takes the form of a class hierarchy with actions attached to classes.
 The metaknowledge of its own ignorance takes the form of the associated uncertainties.
 The same experiments which lead to alterations in the pragmatic representation also change the representation of ignorance.
 Because PAN operates in a very restricted universe it eventually learns all that can be learned.
 Generally we should not expect this to happen.
 As the pragmatic representation becomes richer the organism has more things to be uncertain about.
 Hence the process of building the representation becomes a never ending search for something even better while retaining the best that has been achieved so far.
 •j: REFERENCES Bruner.
J.
S.
, A.
Jolly and K.
Sylva 1976 "Play  Its Role in Development and Evolution" Penguin Books Ltd.
, Harmendsworth, England Gibson,J.
J.
 1977 "The Theory of Affordances" In "Perceiving, Acting and Knowing: Toward an Ecological Psychology" Eds.
 R.
Shaw and J.
Braniford, Erblaum, pp 6782 Gilmore.
J.
B.
 1966 "Play; A Special Behaviour" In "Current Research in Motivation", Ed.
 R.
N.
 Haber, Holt, Rinehart and Winston, pp 3k335'» Lenat,0.
 1976 "AM: An Artificial Intelligence Approach to Discovery in Mathematics as Heuristic Search" Doctoral dissertation, Stanford University, July 1976.
 Peirce.
C.
S.
 I878 "How to Make Our Ideas Clear" Popular Science Monthly, January 1878, pp 286302 Reprinted in "Charles S.
 Peirce: Selected Writings" Ed.
 P.
 P.
 Wiener, Dover, 1966 Shannon,C.
E.
 and W.
Weaver I9I.
9 "The Mathematical Theory of Communication" University of Illinois Press, Urbana, Chicago, London Weisler,A.
 and R.
B.
McCal1 1976 "Exploration and Play  Resume and Redirection" American Psychologist, ̂ , pp U92508 35 An Sxperiaental Architecture chat supports ;ionTenporal Prediction Paul Robertson University of Taxas at Dallas Matural Sciences i riathematics Box 638, Hichardsoa Texas 75080.
 USA Abstract :.
 constructive theory of aemory organisation has been developed, based upon the principle of aontemporil prediction.
 The theory predicts much ;f ;ha experimental findings on recall and fargrtirj; and proviiss a computational foundation for 33ae of the intuitive notions of the society of air.
d theory.
 This paper describes an experimental architecture :hat is being used to study this form of learning.
 The architecture is a highly distributed system that achieves "structural" learing through the Tpplloation of a particularly ?ov«rful forii of natural constraint.
 •';rvori9  NonT»aporal Prediction, Distributed Pr'nlem solving, Society of Mind, Models of ^earning, Jkill Acquisition.
 Introduction Progress in 71.
31 techniques along with the ^nergsnce if sone highly distributed architectures such 23 Fahlsan [ 1 ] and Hlllis [ 2 ] has awakened an interest in exaatniag what can be done with certain architectures based on siaple ' n«uron like' processors, such as Hiaton [ 5 4 ] and Peldman L 5 ].
 X theory of learning based on the principle of r.
onteaporal prediction has been developed that is coaplaiely datadriven [ 6 7 ].
 In this paper, we describe an experimental architecture that is being used to study this fora of learning.
 KonTemporal Prediction Learning and nemory can be viewed as nechaaisras for the acquisition of knowledge.
 •<=.
owlsdge itself can be viewed as a neans of predicting events in the world.
 Our survival is In a lir;? part dependant on our ability to 'predict' the world.
 It is supposed that learning has evolved to meet this need.
 :<aking predictions about the world can be classified into two broad categories.
 Pirst, there is the class of predictions that are tise related.
 An understanding of 'Gravity' might be classified in this way, to understand 'gravity* is to pr°::.
c.
 chat when a thing is dropped it will fall CO Che ground (or the class of predictions of which that i3 a simple example).
 This form of prediction is tise related because the two defining ;v2r.
c3 \.
ho 'Iropping and the hitting on the floor) are iispar.
te in ciae.
 fne second category, to w:.
ich this paper is specifically addressed, concerns pra.
iic t.
cns chit ire unrelated to time.
 This :ind of prsdictiin concerns the classification : ivenrs.
 '>aT':, learning t.
he concept of an 'arch" .
Ziyi 13 T.
aicir.
î  i prediction about what objects •onstituts 'arn'.
 Vhen examples of arches that ;onfc.
a to c.
iis prediction are encountered they ^11 be recognised aa such, just as dropping an cb.
:ect that subsequently falls to the ground is reco.
^nised ao indicating the presence of "gravity".
 Th? iifference, is that the second category is inr?l£ce<i to tiae.
 There are several reasons why it .
3 iisfff il to make chis fora cf distinction.
 [' I I'an/ theories of learning a.
nd forgetting 3r°  ba.
.
ed upon the notion of trace decayPi eoeacy ?xrlTia3 certain observable ph9no:ienon, 'out la diffiult to justify coaput 11 :.
ons II7 and ^.
ves rise to some sorious probler.
s when dealing with predictive 3iuations Tf vastly disparate tines.
 (2) Many of the effects for which recency was proposed can be adequately explained without reference to "tiaie' or 'trace decay'.
 (5) :uiny problems that at first appear to be temporal in nature can be expressed in terms of the nontemporal paradigm.
 It is not known whether all situations can be transformed in this way.
 It may be that learning for 'temporal' situations is Itself a learned strategy, there is soma evidence to support this conjecture.
 (4) It is possible to solve the problem of nontemporal prediction computationally in terms of a highly distributed architecture of simple processors.
 Learning by Modification The notion that learning usually takes the form of modifying an existing skill is intuitively attractive.
 Many attempts at capturing this intuition computationally have been tried, STP.
IPS [ 3 ] employed an augmented triangle table that allowed old plans to be "modified' to suit new situations, an idea recently extended by Carbonell [ 9 ]• ainsky [ 10 ] discussed a form of learning in which new agents arise by 'splitting off from old ones, with only small changes and essentially the same data connectlona.
 Tha mechanism presented in this papar follows the spirit of Mlnsky's 'agent splitting' but differs In detail.
 The architecture presented differs la that Instead of splitting a single process (by copying) and then modifying the copy, it supports multiple copies of (almost) ideatical agents.
 Learning involves taking a 'suitable subset' of these agents and modifying It.
 Before describing tha architecture Itself, we should maka a few points regarding the slgniflc<uici> of this difference.
 (1) It seems llkaly that natural systems such aa the human brain can support this form of 'redundancy'.
 (2) Having multiple copies latroduces a degree of 'fault tollerence', In particular, the 'Grandmother Problem' does not arise.
 (3) Most significantly, having many copies means that a data driven mechanism can be utilized to achieve the 'split' instead of needing a cop down decision to split.
 Understanding Discontinuous Changes In Capability Instead of having a single agent that can perform a given task, the architecture supports many such agents, 'ie will refer to a set of similar agents as a processset.
 The agents of a processsot compete to influence the state of the system.
 Each agent provides its own prognosis and some indication of how reliable It believes this prognosis to ba (based on a simple probabilistic analysis).
 One agent's prognosis will be chosen as the most credible alternative.
 The computation of credibility will also bo computed on the basis of a simple probabilistic analysis.
 Instead of hypothesizing that when a thing is learned its strength gradually increases, or when it is forgotten, it gradually decreases (trace decay), this model of learning distinguishes several phases of learning.
 First, the agent is generated in isolation (we will demonstrate one algorithm for â ent creation when expounding the details of the architeccurs).
 Then, the agent must be refined 36 file:///.
ho'discover Its awn boundaries and be able to accurately compute the reliability of its own prognosis), "ir^lly, the agent aust be iiaeovered by other agents already in the system.
 Tnis final stage is one in which the agents credibility is ccaputed as the result of a probabilistic analysis, and corresponds closely to the notion of forming Klines expounded by Hinsicy L II ].
 When a new and r.
scessary agent is created, its success causes Its credibility to rise until enough saaples have been obtained to raise its credibility to a level above that of the previous 'favorite' agent for this task.
 At thia point, the new agent will suddenly be laed in place of the pr«!viou3 favorite, giving rise to an observable i iscontinuous change in perfornanoe.
 The Sjcperlaental Architecture The eiperiaental architecture can be described at several levels.
 At one level, is the general aystam topology defined by a number of intuitive connectivity restrictions described in [ 7 J and in nore detail in ^ 6 J.
 Space prevents a discussion of this aspect of the architecture.
 The heirarchy can be decomposed into neighborhoods of agents that will, for the purposes of this paper be totally connected i the overall heirarchy allows the conneuti/ity coui|u.
axxty to bs ^apt linear despite the total connectivity within neighborhoods, 'urthernore, the connectivity within a neighborhood an be relaxed [ 2 ] without loss of generality).
 A ".
eighborhood contains two computationally distinct components.
 The processors, that nay b« programoed to compute a predictive rule, and the creators that program processors for the purposes of generating new agents (learning) and repleaiahiag proceeasat 3ize when process splitting has resulted in an insufficient p r o c e s s  s e t c a r d i n a l i t y (houselceeiilng).
 'io will discuss the creator and the processor objects separately.
 A programmed processor will be refered to as an agent.
 The Anatomy of a Seighborhood Consider a neighborhood to be a two dimensional sheet of processing elements.
 Bach processor in the region recleves an input from outside the neighborhood, being totally connected each processor also recleves inputs from the outputs of every other processor in the neishborhood.
 ».
,„ 'Jf I ;nijo)n9o« O '''Ociitai Figure The neighborhood it,elf is divided Into smaller ovjriiping 'regions' (3ee Figure I).
 Each Region contains a ainijle creator and a large number of processors.
 The creator has access to all local inputs to the processors within the region, and the outpurs of each processor in the region.
 The creator can cause one or nore of the processors in its region to be reprogrammed.
 Computation perfortied by a Creator The creator aonitors both the inputs Local to the region and the number of processors that respond to the input.
 If too few processors respond to an input, the creator selects the processors that are least successful and reprograms them so as to increase the processset cardinality.
 The creator is continually performing the fallowing sequence of computations.
 (1) Compute the activity of the inputs to the region.
 This involves counting the number of active inputs locally.
 Let the activity be denoted by activity.
 (2) Compute the response size.
 This involves counting the number of processors in the region that responded to the inputs.
 Let the response size be denoted by response.
 (7) Compute the expected response size.
 In the present system, the expected response size is a linear function of the activity.
 (4; If re3ponse<expected, reprogram responseexpected processors.
 This involves choosing the required number of processors, the least successful ones are chosen first.
 Each processor keeps a record of its success.
 In our implementation, each region keeps a sorted list of processors, when n new processors are required, the first n are taken from this sorted list.
 In a truely parallel system such as might be found in Biological systems, this process can be achieved simply by broadcasting a reprogram command to all processors and using a system of inhibition to prevent reprogramming of the better processors (for a development of this Idea see [ 6 ]).
 Processing Inputs It is convenient to describe the operation of the processors in two stages.
 Plrst, how each in^ut to a processor is handled on an individual basis, and second how these inputs are combined to form a prognosis.
 « ®t^ ACTIVE NiimBn li \»tn$i»t rijjoi wtiq n rmq Ijncti Figure 2 3ach input to a processor is processed by an input weighting function, figure 2 illustrates the function of this process.
 Sach input weighting function (corresponding to input.
) samples its input whenever the process is active.
 In this way, the input weighting function computes for its input, the credibility that that input is indicative of the event being diagnosed — the probability that the input will be active when the event is diagnosed P(input.
 1 this.
agent.
active).
 Other Processor functions.
 Once the ir.
pits have been weighted according to their credibility, they can be combined to form the prognosis.
 37 C u M i u SiCliOft '•i^tm put I rttn )Q npHi : 10 111 ?f«CUU(| UAX OF • Xlnt 0«il7:t *î inimum ivwit ir» : .
VF » nfui •.
'••.
h'lfig funeiian Figure 3 Figure 3 illusrrates the basic operation of the •iiagnosia part of a processor.
 The value of success is adjusted whenever the agent Is active.
 Space prevents further development of this idea here, however, low success values Indicate failure in ispleffleating a predictive rule, and such processors •*iil ie reprogrammed by their creator when a new agent is required.
 The inherent limitations of simple Linear Threshold devices such as the prognosis function, are used as a pomrfUl natural constraint.
 This guarantees that most agents that are created fill aventuallr die (success will fall until it is eventually reprogrammed).
 This gives rise to a very eceoomical use of processors without the need for a knowledge driven resource (processor) allocation system (these ideas are developed in detail in [ 6 ]).
 Conclusion Oue to a lack of space, many significant details and much of the theory had to be omitted.
 Zzperlmants with a LISP based iapleaantatloa of the system outlined in this paper have been encouraging.
 Complex structural descriptions can been learned by the system.
 The syste* is robust in that usually, no agent Is so important that its removal will be critical (due to duplication), and a high degree of noise can be tolleratad.
 An analysis of the systaas noise immunity can be found in L 6 ]• • Is interesting that as the regions approach saturation (most proceasors are successfully programmed as agents), it becomes increasingly difficult to learn a new rule.
 This is because, before a new agent can achieve a respectable success it is reprogrammed by its creator because it is still the least successful agent.
 Only intensive training will result in the new agent being learned, and this will be at the cost 3f one of the other successful agents.
 Pull details of the architecture, and Juatlfieation of its design can be found in [ 6 ].
 References 1.
 ?ahlman.
3.
S.
 ;IET1: i System for Representing and Using RealVorld Knowledge The S.
I.
T.
 Press.
 CamoriJge :?assac hus e 11 s 1979.
 ISBN 026206093 2.
 Hillis.
W.
D.
 The Connection Machine rf.
I.
T.
 AI Memo 646 September 1981.
 3.
 Hinton.
S.
 A Parallel Computation That Assigns Cinonicil 0bj9ct3ased Frames of Reference ?roceedin?3 of IJCM7 1981.
 I.
 Hinton.
G.
F.
 i Anderson,J.
A.
 (eds) Parallel models of associative memory.
 Hilladale, SJ: 3rlbaum, 1981.
 5.
 Feldman,J.
A.
 A ^onnectioaist Model of Visual Memory In L '<• ] abo'/'e.
 5.
 Robertson,?.
 Process Dependant Localized Memory University of Texas at Dallas Technical Report.
 7.
 Robertson,?.
 SonTemporal Prediction: A Distributed System For Concept Acquisition Proceedings of the Fourth National Conference of the CSCSI/SCEIO 1982 a.
 Flkea.
R.
E.
 * Wilsson.
N.
J.
 STRIPS: A new Approach to the Application of Theorem Proving to Problem Solving Artificial Intelligence Journal, Vol.
 2, no.
3/4.
 1971 9.
 Carbonell.
J.
C A Computational Model of Analogical Problem Solving Proceedings of IJCAI7.
 1981.
 10.
 Mlnslcy,M.
 Plain talk about Neurodevelopmental Epistemology Proceedings of IJCAI5.
 1977.
 11.
 Minsk? ,M.
 '<Lines: A Theory of Memory In 'Perspectives on Cognitive Science' Donald A.
 Morman ed.
 38 THE LOGIC OF EVENTS John M.
 Morris Measurement Conoept Corporation Rone NY 13140 Some of the earliest work In the logic of events appears In Heapel [2].
 Here are some examples of what he meant by "event": "the first solar eclipse of the twentieth century," "the eruption of Mt.
 Vesuvius In A.
D.
 79.
" "the assassination of Leon Trotslcy," "the stock market crash of 1929.
" The events are whatever these phrases refer to.
 Events occur in both time and space, but the edges of the event may be fuzzy.
 An event lllce the collapse of the German economy during the 1920s or an Increase In tension between Russia and China is not the sort of thing that can be confined to a definite region of spacetime.
 Still, even though the location is vague or fuzzy, it always makes sense to ask uliscfi ani when an event Is located.
 The German banks, bankers, and householders that fell victim to the economic collapse were located in Germany; and the Increase in tension between Russia and China Includes editorials, posters, speeches, military movements, and the hearts and minds of people at definite points within the two countries.
 Similarly, it makes sense to inquire when an event occurs, even when the time boundaries are fuzzy.
 So we can always Include a place and time reference in our descrlptioos of events, even though the edges of the events may be blurred.
 A major problem in the development of a logic of events has been a criterion of identity for events, that Is a way of telling when two descriptions refer to the same event.
 A single set of objects in a single spacetime segment may be Involved in an Indefinitely large number of events.
 A Russian soldier near the Chinese border squeezes the trigger of hla rifle.
 Among the many events which occur are these: (1) various neurological and physiological events in the Russian's body, together with physical processes associated with the firing of the rifle, and the resulting physiological processes in the body of the Chinese soldier who is killed by the bullet; (2) an attack on a Chinese outpost; (3) from a psychological point of view, a Russian soldier's expression of his boredom, frustration, and contempt for the Chinese; (4) the first incident in a major RussianChinese war.
 Some people, like Anscombe, would prefer to say that only one event has occurred and that we have given four different descriptions of it.
 Goldman and others have shown that these cannot be regarded as a single event [1].
 His proof, which is very simple, is this: We may say that the Russian, in this example, expreaaed his boredom by firing his rifle; we say that the shooting nonatitutad an attack on the Chinese outpost; and we say that the killing hename an international incident because of later reactions to it.
 We would not speak in this way if all of these were descriptions of the same event, because the converse of these statements would not be true.
 We would not say that the soldier fired his rifle by expressing his boredom, or that an attack on the outpost constituted the shooting, or that an International incident became a killing.
 If (1), (2), (3)> and (4) above were identical, then relationships among them should be symmetrical; but they are not.
 For this reason they are not descriptions of the same event.
 The important thing is that it will be impossible to specify an event unambiguoualy simply by specifying the objects and the portions of space and time in and to which it occurred.
 Since an indefinitely large number of events may occur at the same point in space and time, we need additional specifications in order to describe an event uniquely.
 Distinguishing among events is Important for current events analysis, because different events will have different consequences.
 The psychological state of an isolated Russian soldier is likely to be unimportant to the current affairs historian; but the outbreak of a war along the RussianChinese border is of major importance.
 An effective systen for current events analysis will identify the event in terns of its relevance to the histMlan's goals.
 Suppose that, following the incident, a Chinese radio broadcast Is heard to characterize the shooting as "inhuman butchery" and to describe the Incident in other emotionally loaded terms.
 We can say (1) that the Chinese reported on the shooting, and (2) that the Chinese attacked the Russians as "butchers.
" Precisely the sane broadcast, at precisely the same tlm*, used the sane set of words to perform both of these actions.
 But the event reported as (2) is more significant for the historian than the event reported as (1).
 From the historian's point of view (1) and (2) are different events.
 In the symbolism developed by Jaegwon Kim [3,1] an event is represented by an expression of the form: C(*1 xn,t), P«] where (x^^ ^^.
^ x^) is an ordered ntuple of concrete objects, F'' is an nadic empirical attribute, and t is the time at which (x.
, •••> *„) is said to exemplify the attribute P".
 The ntuple of objects may be written in vector notation as X The event is said to "exist" if and only if X does exemplify P" at time t.
 (The place can oe Included among the «i.
) Thus [(x.
,x2,t),P^] might signify the event of an Israeli Fl PhantomII aircraft flying over the Suez Canal at 1:06 a.
m.
 on August 4, 1982.
 Here, x^ represents the aircraft, x, the Suez Canal, t the time, and p2 the attribute of overflying.
 (The superscript "2" indicates that it is a twoplace predicate.
) It may seem somewhat strange to speak of an event like "overflying" as an attribute, but this generalization makes the symbolism applicable to states, conditions, and other qualities, as 39 uaXl as to events.
 A problem of particular Importance for the designer of an event logic will be that of deterolnlng when two descriptions refer to the sane event.
 In the example Just given, when we receive a dozen reports of an F^ flight over the Suez Canal, ue will want to know whether there was Just one flight or a dozen flights.
 Goldman and Kim propose a rather strong criterion of Identity for two events: [(x,t),P] = [(y,t'),Q] if and only if x=y, t=t', and P=Q.
 This makes "flies over the Suez Canal" a different event from "threatens Egyptian frontiers.
" From a pragnatio point of view, the role of these two desoriptiona In an information system will be different, and we will take them as representing different events, even though the physical objects and their raw, physical motions are the same.
 The description of the flight as a "threat" depends on the context of world events in which it takes place.
 Although the flight is located in the area of the canal, its Hignifioanoe is Dot located there at all.
 The significance of the flight is In the various government officials whose attitudes make it a threat.
 It would not be a threat if it were not for these attitudes.
 The claim that the threat is located only along the flight path is what Whitehead called the "falUcy of simple location*.
 A complete analysis of the logic of events will provide us with rules for going fron one event description to another.
 We will want to know, for exaaple, bow to go from "Israeli plane flies over Suez Canal" to "Israel threatens Egyptian frontier.
" Border violations are events that can, in the aggregate, provide evidence for a current historian that tension is rising betuea two countries.
 determine, from a general description of an event, which properties are going to be significant ~ which properties are "constitutive" of the particular event, and which are merely "exemplified" by the event.
 It is Just conceivable, for Instance, that the historian is collecting the names of Soviet officers that begin with the letter "A"  for some obscure reason we can only guess at — and the Important information is the first letter of the name of the new Field Marshall.
 (This would be part of the historian's "user view," the viewpoint from which ha or she would want to look at the data.
) The first letter of the name would be constitutive of the significant event (in the sense that it would be that which makaa it signfleant), and the political attitudes of the Marshall would then be nothing more than irrelevant noise.
 The problea Is in distinguishing the significant or constitutive features of an event.
 For human observers there is little difficulty in locating Just those features of an event which are relevant to their interests.
 One fascinating characteristic of human perception is the way in which humans fail to notice elements In a situation which have no Interest for them.
 For an automated information system, however, the problem of relevance becomes acute, because the machine has no Interests of its own.
 We must be able to tell the machine how to locate those features in the information which will be useful in discriminating among relevant patterns of events [5].
 In summary, the problea for anaiva^a is determining those features, among the infinite number of features which can be extracted from the world around us, which will be significant for the goals of the ourr«it historian — such as the detection of a potential world conflict.
 To show how the logic works, consider the following hypothetic event.
 Let us suppose that a Soviet officer at the Chinese border, one General Sayev Andronovich, is promoted to Field Marshall.
 In itself, this event does not have any clear significance for the historian.
 However, if we add the Information that Andronovich is noted for his outspoken antiChineae attitudes, then his promotion becomes a significant predictor for future SovietChinese relations.
 At least two events have taken place: (1) a Soviet officer named Andronovich has been promoted; and (2) antiChinese attitudes have been encouraged in the USSR.
 Now, if we know that Andronovich is antiChinese in attitude, then we know that he belongs to the class of antiChinese Soviet officials.
 Our event logic should permit us to say that anything which happens to Andronovich is also an event which happens to an antiChinese official of the USSR.
 From this, it should be possible to derive the more general event, in which antiChinese attitudes have been encouraged.
 Finally, from this event, it should be possible to predict deterioration of SovietChinese relations.
 The role of the logical apparatus is to provide the hypotheses upon which the historian can predict the deterioration of relations.
 RS'ESEKCES 1.
 Goldman, Alvln I.
, i Ty^mn,.
^r nr u»m»r, Action.
 Englewood Cliffs: PrenUceHall, 1?rO.
 2.
 Hempel, Carl G.
.
 AaPMta Of SfilftntlflB BrelanatlOB.
 N«» Xork: Free Press, 1965.
 3.
 Kim, Jaegwon, "Events and Their Descriptions: Some Considerations," Eaaavs in Honor of Carl G.
 HenpalrMicholaa Resoher, et.
 al.
, editors, Dordrecht: D.
 Reidel Publishing Co.
, 1970, pp.
 19«215.
 4.
 Kim, Jaegwon, "Causation, Hemic Subsumption, and the Concept of Event," The Journal of Philosophy, Vol.
 UCX, no.
 8, April 1973, pp.
 217236.
 5.
 Morris, John M.
, "The Heed for Context in Event Identity," Third Annual Conference of the Cognitive Science Society, 1981, pp.
 197199.
 In an automated systen for current events analysis a central problem will be to 40 FUZZY SEMANTIC NETWORKS: A NEW KNOWLEDGE REPRESENTATION STRUCTURE BY: DOUGLAS D.
 DANKEL II KENNETH W.
 SPRAGUE COMPUTER AND INFORMATION SCIENCES UNIVERSITY OF FLORIDA GAINESVILLE.
 FL 32611 ABSTRACT This paper introduces a new method of knowledge representation called a fuzzy semantic network (FUSEN).
 FUSENs were created to model continuous or fuzzy knowledge using concepts from artificial intelligence, fuzzy set theory, and cognitive psychology.
 FUSENs have the ability to model three theories from cognitive psychology: the theory of natural categories, the family resemblance theory, and the featureset theory.
 They can also perform as most of the knowledge structures from artificial intelligence and as a fuzzy set structure.
 Presented is their structure and several examples illustrating their use.
 INTRODUCTION To have a complete understanding of an entity one must be aware of how it acts, what rules apply to it, and in what situations one might expect to find it.
 For example, it is possible to describe the color, shape, size, and subparts of a 'dog'.
 It is easy to define the sets to which 'dog' belongs and the memebers of the set called 'dog'.
 But, the concept of 'dog' is not complete unless one knows what 'dog's do and how they act.
 There should be specific memories of 'dog's.
 There should be anticipations of what to expect from 'dog's in general and from specific 'dog's in particular.
 There must also be an understanding of time, space, and the physical reality in which 'dog's operate.
 A complete concept of a 'dog' includes all of this knowledge.
 FUSENs divide this complex knowledge into four separate classes: entities and categories; actions and processes; literal and deep sentences; and rules and hypotheses.
 This paper examines the first of these classes and briefly discusses the relationships between FUSENs and three theories from cognitive psychology: natural categories, family resemblance theory, and featureset theory.
 STRUCTURE Figure 1 shows the graphical representation of FUSENs.
 The owner label defines the owner of a head node and the type label defines the association existing between the node.
 The weights represent the association strengths between nodes.
 A head node can be associated with any number of subnodes.
 Each instance of a head node and its subnodes is called a fuse.
 All nodes of a fuse can be subnodes or head nodes of other fuses.
 Figure 2 is a fuse representing a set of attributes for the category 'fruit'.
 This is determinded by examining the head node name, 'fruit'; and the type label '(attrib)'.
 The type label is a reserved work, denoted by the surrounding parentheses, describing the relationship between the subnodes and the head node.
 '(Attrib)' defines all the subnodes as attributes of the head node name 'fruit'.
 The owner label defines the parent node(s) of the head node.
 This label resolves any ambiguity created when two or more fuses have the same head node name.
 For example, if two fuses have the head node name of 'color', one would look at the owner label to see what they referenced.
 There could be fuses concerned with automobile colors, leaf colors, or colors is general.
 In Figure 2 the owner label is '()' or null.
 This means this fuse is about 'fruit' in general.
 Each subnode is a different attribute of 'fruit'.
 The weights associated with each subnode reflects how strongly that particular attribute is associated with 'fruit'.
 The link labels define the domain over which the subnode is defined.
 In Figure 2 'red' and "yellow' are defined as colors of 'fruit'.
 The weights are viewed as frequency counts.
 In Figure 2 the head node weights of 137 states that 137 instances of 'fruit' have been observed.
 The ratio of the subnode's weight to the head node weight is that subnode's association strength.
 'Red' has an association strength of 66/137 or 48.
2%.
 Figure 3 shows a fuse representing a set of apples attributes.
 The type label is '(attrib)', so the syntax of this fuse is the same as that of Figure 2.
 NATURAL CATEGORIES The theory of natural categories was developed by Rosch [ANDE80].
 Natural categories are levels of abstraction that people seem to naturally develop and use.
 Rosch feels categorization occurs to go beyond insignificant individual differences and to obtain the most information from the smallest amount of categorization.
 Figures 2 and 3 can be used as an example of natural categories.
 According to these figures, a certain object that is small, red, and sweet can be seen as an apple or a piece of fruit.
 Since these attributes match both the 'apple' and the 'fruit' fuses a computer algorithm would say the object is both an apple and a piece of fruit, which is correct.
 But, in conmunicating with humans, the algorithm will have to pick the most appropriate level of abstraction or as Rosch called it, the 'basic' level.
 The way the algorithm can find the basic level is to look at the head node weight.
 The h iqhest weight is the most frequently conceptualized concept or the basic level.
 In this example the object would be called an 'apple'.
 FAMILY RESEMBLANCE THEORY The family resemblance theory was also developed by Rosch [ANDEBO].
 This theory states 41 that every category is defined by an openended set of attributes or features.
 Natural categories have no fixed boundaries.
 For any particular category there might not be even one attribute in common with all the category members.
 An entity is judged to be a good member of a category if it has many attributes overlapping with the attributes of the category.
 The FUSEN structure models this theory very well.
 The 'fruit' and 'apple' fuses show how the concept is defined by a set of attributes.
 The number of subnodes and their weights are dynamic and can constantly change as new examples of the category are observed.
 If a green fruit is observed, the subnode 'green' with a weight of 1 will be added to the 'fruit' attribute fuse.
 In addition the 'fruit' head node weight will be incremented by 1.
 FEATURESET THEORY Featureset theory [AN0E80] assumes people recall how frequently they have seen all the various attributes of a concept.
 The more frequently seen attributes have a higher correlation or association strength with the category.
 This is exactly how fuses work.
 Figures 2 and 3 show two categories.
 The association strengths for each subnode reflects how strongly it is associated with the head node.
 Notice that 'red' is more strongly associated with 'apple' than 'fruit', and 'tart' is more strongly associated with 'fruit'.
 SUMMARY This paper briefly introduces a new method of knowledge representation called a fuzzy semantic network.
 The theory is based on the idea that knowledge can be represented by the associations between symbols and that these symbols and associations can be explicitly represented by a semantic network.
 Using semantic networks as a base, a general method of knowledge representation was developed to include ideas from many areas: artificial intelligence, mathematics, psychology.
 It is hoped that when the complete syntax is developed FUSENs will be able to represent most any kind of semantic knowledge.
.
 REFERENCES [ANDE80] Anderson, J.
R.
 1980.
 Cognitive Psychology and Its Implications.
 San Francisco, CA: W.
H.
 Freeman.
 [SPRA82] Sprague, K.
W.
 1982.
 'Fuzzy Semantic Networks'.
 Gainesville, FL: MS thesis University of Florida OTHER METHODS OF KNOWLEDGE REPRESENTATION Sprague [SPRA82] has shown how fuses can also perform as many other knowledge structures.
 In particular he discusses production rules, semantic networks, expert knowledge systems, frame theory, fuzzy sets, and stimulusresponse theory.
 Figures 2 and 3 on following page.
 owner label 'head node name .
 — type label ' — ^head node weight •nodelink subnode node weight FIGURE 1.
 Diagram of FUSEN structure 42 __̂  (attrib) 137 fruit color color color medium STnall y Figure 2.
 Example of fruit attribute fuse <attrib) color Figure 3.
 Example of apple attribute fuse 43 GETTING A N D USING CONTEXT: FUNCTIONAL CONSTRAINTS O N THE ORGANIZATION OF K N O W L E D G E James A.
 Galamboa and John B.
 Black Yale University Cognitive Science Program Studies of text comprehension (Bower, Black, and Turner 1970, Mandler and Johnson 1077, Schank and Abelson, 1077) have relied on the notion of a script or schema.
 A script represents world knowledge about common activities, events, and situations.
 It includes information about the components of these activities and the relations among the components.
 In this paper w e examine scripts for common activities (e.
g.
, cashing a check, or going to restaurants) as thejr exist prior to their instantiation in prose.
 The questions addressed in this paper are: H o w is the script knowledge structure accessed? and once the script is accessed how are its components made available? In other words, since context is so important in comprehension, we want to know how we get a context and once we have it, how does it hel^? Schank and Abelson discuss how the script knowledge structure is activated during the comprehension of narrative.
 Cleariy the easiest way to invoke a particular knowledge structure is to refer to it by name.
 Thus if the narrative explicitly mentions a situation, the retrieval of the knowledge structure should be straightforward.
 T h b can be done by a title of a passage, or by setting statements.
 W e are interested in cases where the context is not given explicitly.
 Implicit reference to the activity can be made in a number of ways.
 For instance a goal mentioned in the narrative can serve as access cue for the script typically involved in accomplishing that goal W e are concerned with a different case where the presentation of one of the aetiona in the script leads to the accessing of the script itself.
 Thus on encountering the sentence: John walked through the door and saw the head waiter.
 in a narrative, the restaurant script should be activated to contextualize subsequent sentences.
 W e test the claim that component actions will serve as access cues for their scripts if those actions are diatinetivt to the script.
 A n action is distinctive to a script if that action is performed in few if any other scripts.
 Thus, for the restaurant script, the action S E E T H E H E A D W A I T E R is highly distinctive, since it occurs in few if any other activities.
 The action of walking through the door occurs in so many activities that it is extremely low in distinctiveness to the restaurant script.
 This aspect of script structure has been developed and examined in Galambos, 1081 and 1082, and Galambos 44 and Black, 1081.
 We are also concerned with how the components of a script become available when the script is accessed.
 The question here is whether accessing the script makes all its components immediately available or whether some components have a more prominent status.
 In other experiments (Galambos and Rips, 1082), we have defined a measure of prominence called eentnlity.
 The centrality of an action is a measure of the importance of the action to the performance of the main goab of the activity.
 For example, in the restaurant activity the action E A T T H E M E A L is highly central Our hypothesis is that central actions should have a greater availability than less important actbna when using an accessed context to aid comprehension.
 Note that it is possible to select actions in such a way that these two dimensions are independent.
 The distinctive seeing the head waiter action is not particularly central to dining at restaurants, and the central eat the meal action is not particulariy distinctive (since eating can occur in many other contexts; a plane, at home, a picnic, etc.
).
 In terms of these dimensions our hypotheses are that the distinctiveness of an action should determine whether or not the script is accessed.
 The centrality of an action should influence whether the action becomes available when the script has been accessed.
 W e designed a reaction time experiment in order to test these hypotheses.
 The subjects' task was to decide whether or not two presented action phrases were components of the same activity.
 The first phrase was presented on a C R T screen for 1500 msec.
 This phrase then disappeared, and the second phrase was presented.
 The second phrase remained on the screen until the subject responded.
 The response latency was measured from the onset of the second phrase to the subject's response.
 Four actions from each of 22 activities were chosen to sample the combinations of high and low leveb of both centrality and distinctiveness.
 Thus from each activity one action (HiC/LoD) was high in centrality in the activity and low in distinctiveness, a second action (LoC/HiD) was low in centrality and high in distinctiveness.
 The third action (HiC/HiD) high in both centrality and distinctiveness, and the fourth was LoC/LoD.
 For example the four actions selected in the activity of cashing a check were: Action TjFpi HiC/Lo0 LoC/Hi0 HiC/Hi0 LoC/Lo0 Action vri t* joar signttur* raeord tht taount go to b*nk Mit in I IR« Twelve pairs of actions were constructed for each activity by combining the four types of actions in all pairs at each order.
 These twelve conditions were equated for length and word frequency.
 The sequential presentation order of the two actions matched the real order of the actions for exactly half of the trials in each condition.
 Stimuli were constructed for each subject so that all 12 conditions and all 22 activities were equally represented, but each action was presented only once.
 There were an equal number of negative trials using actions not involved in the positives.
 Twentyfour Yale undergraduates participated in the experiment.
 The mean R T s for each of the twelve (positive) conditions were: Condition HIC/Hi0 LoC/Hi0 LoC/Hi0 HiC/Hi0 HiC/HI0 LoC/HI0 HiC/Lo0 HiC/Lo0 HiC/Lo0 LoC/Lo0 LoC/Lo0 LoC/Lo0 > HiC/Lo0 > HiC/Hi0 > HiC/Lo0 > LoC/Hi0 > LoC/Lo0 > LoC/Lo0 > HiC/Hi0 > LoC/Hi0 > LoC/Lo0 > HiC/Hi0 > HiC/Lo0 > LoC/Hi0 Htan 873 880 9S4 898 1059 963 986 1124 1081 1193 1013 1073 The nomenclature here is perspicuous; for example the first entry indicates that a highly central and highly distinctive action was presented in the first position followed (after 1.
5 seconds) by a highly central but nondistinctive action, and the mean reaction time was 873 msec.
 If we are right that distinctive actions access their script, then conditions where a distinctive action (LoC/HiD or HiC/HiD) b presented Tirst should facilitate the response.
 This is because the script should be accessed in the 1.
5 seconds before the second action is presented.
 Having the appropriate context should speed the interpretation and processing of the second action, as well as simplify the sameness decision.
 W h e n the first action is not distinctive (HiC/LoD or LoC/LoD), then the script is not accessed and subjects must try to access a contextualizing structure when the second action is presented.
 This prediction is equivalent to a comparison of the Tirst six and the last six means above.
 The first six contained a distinctive action in the Urst ptosition ( /HiD).
 The prediction was confirmed.
 The difference between the two sets of means was significant \min f"(l,35) = 7.
31, p < .
02!.
 The context accessed by a distinctive first action does help subjects to confirm that the second action is in the same script.
 Our second prediction involves the centrality of the second actions following distinctive fust actions.
 Central actions are the main goals and components of the activity.
 This prominence should be represented in the organization of the underlying knowledge structure.
 W h e n the script is accessed by a distinctive first action, central second actions should be confirmed more quickly as components of that script compared with less central second actions.
 This prediction is tested by a comparison of the fust three and second three means in the list above ( /HiD  > HiC/ vs.
 /HiD  > LoC / ).
 In thb case the M i n F' was not significant but the F for the subjects was 4.
83 which was significant at the .
04 level for one and 23 degrees of freedom [for materials, F[l,2l) = 2.
03, p < .
18).
 Thus the claim that central actions are more available than noncentral actions when the script is accessed also received a certain amount of support.
 It is possible to examine more fmegrained predictions for these data.
 Perhaps the purest test of our assumptions can be obtained by comparing conditions LoC/HiD  > HiC/LoD and HiC/LoD  > LoC/HiD.
 T h b compares the same actions in different presentation order.
 Clearly the preferred order b when the dbtinctire (noncentral) action b presented before the central (nondbtinctive) action.
 The Hist action accesses the script and since the centrality of the second action makes it more available for confirmation.
 The reversed order should be much more difficult since the script b not accessed by the Hrst action and second action b not prominent in the script.
 There b a very large difference (160 msec) in favor of the optimal order of these two action types.
 The point b that the optimal order b facilitative because it exploits the functional organization of the knowledge structure.
 The results of thb experiment indicate the presence of two functional constraints on the organization of knowledge about common activities.
 Knowledge structures (like the scripts examined here) are used to provide context to better understand experience.
 T h b implies that the knowledge structures can be quickly accessed when the need for them becomes apparent.
 W h e n an isolated action b encountered it b necessary to find a context into which it Ats.
 The organization of knowledge structures must reflect thb necessity.
 The dbtinctiveness of an action to a script can be represented as a link to the superordinate script concept.
 If a dbtinctive action b encountered, then thb link can be traversed and the script concept retrieved.
 If the action b not dbtinctive then either the retrieval path b unavailable or too many available scripts are accessed and the context b ambiguous.
 Dbtinctive actions then provide one way to find an unambiguous context.
 Our results demonstrate that dbtinctiveness b a relevant structural characterbtic in the functional organization of knowledge structures for common activities.
 A second functional constraint is that knowledge structures must organize information in such a way as to have the necessary components available for utilization 45 by the comprehension processes.
 In other words, having a context means (among other things) being able to generate predictions about subsequent input in order to lessen the processing load when that input Ls encountered.
 This constraint would be satisfied if a Ibt of all information that could possibly be relevant to the context were activated when the context was retrieved.
 Alternatively, since some of the information in a contextualizing knowledge structure is likely to be more relevant, it might be that this more relevant information is more available or more easily accessed.
 Such relevant information might include the main goals of the activity and the most important actions in the performance of those goals.
 If the comprehension system can keep only a limited amount of information about a context available for prediction, then this information is probably the best sort to have.
 For instance, if the restaurant context b involved in a narrative then it is a very good prediction that subsequent input will include something about the action of eating.
 Our results indicate that this more central information does beneflt from a greater availability once the context is accessed.
 Here again we have demonstrated an important aspect of the functional organization of knowledge structures.
 In conclusion, we take thb research to be a beginning in the specification the functional organization of information in knowledge structures for common activities.
 Furthermore, we think our results outline a theory of getting and using context in order to understand experience.
 AeknowledgmenU We are grateful to Robert Abelaon, Kate Ehrlich, Brian Reiser, Scott Robertson, and William Salter for their help.
 This research was supported by a grant from the Systems Development Foundation.
 Refereoeea Bower, G.
 H.
, Black, J.
 B.
, & Turner, T.
 J.
 Scripts in memory for text.
 Cognitive Payehologg, 1079, 11, 177220.
 Galambos, JA.
 Question anawering and the plan structure of routine activities.
 Paper presented to the American Educational Research Association Annual Meeting.
 New York, New York, March 1982.
 Galambos, JA.
 QuestionAnswering and the Structure of Event Knowledge.
 Paper presented to American Psychological Association.
 Washington, D.
C.
, August, 1982.
 Galambos, J.
A.
 & Black, J.
B.
 W h y do we do what we do? Proceedings of the Third Conference of the Cognitive Science Society.
 Berkeley, California, 1981.
 Galambos, JJl.
 & Rips, L.
J.
 Memory for routines: just one thing after another? To appear in Journal of Verbal Learning and Verbal Behavior, August 1982, 22, no.
 4.
 Mandler, J.
M.
 & Johnson, N.
S.
 Remembrance of things parsed: Story structure and recall.
 Cognitive Psychology, 1977, 9, 11151.
 Schank, R.
 C.
, & Abelson, R.
 P.
 Scripts, plans, goals, and understanding.
 Hillsdale, N.
J.
: Erlbaum, 1977.
 46 Conceptual Combination and Fuzzy Set Theory Edward E.
 Smith Bolt Beranek and Newman Inc.
 and Daniel N.
 Osherson ^4a3sachusett3 Institute of Technology Conceptual combination is the process by which people combine existent simple concepts (e.
g.
, brown and apple) into novel combinations (e.
g.
, brownapple).
 As a possible formalism for conceptual combination, most proponents of prototype concepts endorse fuzzyset theory (e.
g.
, Zadeh, 1965).
 Osherson and Smith (1981), however, argue that the amalgamation of fuzzysettheory and prototype concepts is fraught with problems.
 Some fuzzyset theory.
 A key notion in fuzzyset theory is that of a characteristic function, which maps entities into numbers in a way that indicates the degree to which the entity is a member of some set or concept.
 To illustrate, consider the characteristic function, c , which measures degree of ~F membership in the concept fish (F).
 When applied to any creature x, c (x) yields a F number between 0 and 1, where the larger c (x), the more x belongs to F F.
 Thus, our pet guppy may not be very typical of fish, so it gets a characteristicfunction value of .
30.
 Our pet dog will get a very low value, say .
05.
 If we now consider pets (P), and its characteristic function c , then our guppy P and dog might be assigned the values .
70 and .
90.
 The issue of conceptual combination has often been reduced to a question about characteristic functions: namely, given that concepts P and F are combined to form the complex concept PSF, how do we specify P&F's characteristic function (c (x) ) on PSF the basis of those of P and F (c (x) ~P and c (x))? The answer from fuzzy set F theory is that c (x) is the minimum PSF of c (x) and c (x) .
 p F Applying this min rule to our pet guppy, g, yields c (g) =« min (c (g) , c (g) ) PSF P F min (.
70, .
80) .
70 This says that our guppy is less typical of pet fish than it is of fish.
 And therein lies the problem.
 For as Osherson and Smith (1981) point out, intuition suggests that a guppy will be more typical of the conjunction pet fish than of either constituent, pet or fish.
 Osherson and Smith argue that this petfish example is just one of an indefinite number of counterexamples to the min rule.
 Rationale for the present work.
 There are two problems with the Osherson and Smith (1981) counterexamples.
 First, they rest only on Osherson's and Smith's intuitions; such claims need to be tested against typicality ratings of naive subjects.
 Second, there is no indication of the generality of the failure of fuzzyset theory; perhaps Osherson and Smith's counterexamples are of a few types in some underlying taxonomy of conjunctions, where other types might conform to the theory.
 To deal with these problems, we first present a taxonomy of adjectivenoun conjunctions, and then describe some relevant experimental work.
 An initial taxonomy of adjectivenoun conjunctions.
 All counterexamples of the OshersonSmith variety, such as petfish and brownapple, have the following characteristics: the adjective concept (i.
e.
, the property denoted by the adjective) is relevant to the noun concept (i.
e.
, the object denoted by the noun) and negatively diagnostic of it; e.
g.
, being brown is relevant to whether an object is an apple, and counts against it.
 More precisely, an adjective is negatively diagnostic of a noun to the extent that knowing that the adjective is a true description of some object increases the probability that the noun is a false description of that object, and knowing that the adjective is false of some object increases the probeUjility that the noun is true of that object.
 An adjective is positively diagnostic of a noun to the extent that knowing that the adjective is true (false) of some object increases the probability that the noun is true (false) of that object.
 And an adjective is nondiagnostic of a noun to the extent that knowing that the adjective is true (false) of some object has no bearing on whether the noun is true or false of that object.
 Thus, in slicedapple the adjective is largely nondiagnostic; in red apple the adjective is positively diagnostic; and in brown apple the adjective is negatively diagnostic.
 In addition to the relation between the constituents, we also considered the degree to which the conjunction provides a true description of an object that is to be categorized.
 To keep things simple, we consider only the degree to which the tobecategorized object manifests the property denoted by the adjective in the conjunction, and we let the object take either a high or low value on this 47 property.
 This gives a total of six cases, presented in Table 1.
 Table 1 Initial Tunnoay of AdjactivaNottn Conjunctions D«9r«« to Which Object M«jiifest> Property Relation of Mjective Concept to Noun Concept Nondiagnostic Positively Oiaqnostic negatively Diagnostic High (1) unslicsd apple object 19 unsliced (3) redapple object is red (5) brownapple object is brown Low (21 unsliced apple abject is ilicsd (4) redapple object is brown (61 brownapple object is red Consider now how people might judge the typicality of various objects vis a via the different kinds of conjunctions in Table 1.
 In Case 1, since the constituent concepts are relatively independent of one another, people might separately judge the extent to which an object is an instance of the adjective concept and of the noun concept, and then combine the outcomes of these two distinct judgements into an overall typicality rating.
 Since this is the key idea behind fuzzyset theory, some variant of the theory might prove adequate for Case 1.
 In contrast, Case S, where the adjective is negatively diagnostic of the noun, captures the counterexamples used by Osherson and Smith (1981).
 Here, intuition suggests that an object with a high value on the property (e.
g.
, an apple that is indeed brown) will be rated more typical of the conjunction (brownapple) than of either constituent (brown or apple).
 The outcomes for the remaining Cases (2, 3, 4, and 6) might fall somewhere inbetween these extremes.
 An experiment to test the taxonomy.
 For each of 48 pictured objects, one group of 20 subjects rated the object's typicality with respect to an adjective concept (e.
g.
, red, brown, sliced), a second group of 20 subjects rated its typicality vis a vis a noun concept (e.
g.
, apple), and a third group of 20 rated its typicality with respect to an adjectivenoun conjunction (e.
g.
, red apple, brown apple.
 sliced apple).
 The adjectivenoun conjunctions were such that all six cases of our taxonomy were tested.
 In the Noun group, on each trial the experimenter spoke the name of a noun, then a pictured object appeared and subjects rated how good an example it was of the noun concept.
 Each picture was presented once.
 In the Adjective group, on each trial the experimenter spoke the name of an adjective, then a pictured object appeared and subjects rated how good an example the pictured property was of the adjective concept.
 Now, each picture was presented twice, once with an adjective denoting a property that the pictured object had a high value on, and once with an adjective denoting a property that the picture had a low value on.
; e.
g.
, the picture of a red apple and that of a brown apple were presented once with "red" and once with "brown.
" In the A d j Noun group, on each trial the experimenter spoke the names of an adjective and noun, then a picture was presented and subjects rated how good an example the pictured object was of the conjunctive concept.
 Each picture was presented twice, once with a conjunction whose adjective denoted a property the picture had a high value on, and once with a conjunction whose adjective denoted a property that the picture had a low value on; e.
g.
, the picture of a red apple was presented once with "red apple" and once with "brown apple.
" All subjects had ten seconds to make a judgement, the judgements being made on a 10point scale, where higher numbers indicated better examples.
 The top half of Table 2 contains the data for the three cases of the taxonomy where the object has a high value on the property denoted by the adjective.
 For Case 1, we expected the minimum rule to work.
 The results are otherwise: the conjunction's typicality clearly exceed the minimum of its constituents.
 A coiq>arable deviation from the min rule also occurred in Case 3.
 For Case 5, where we expected the largest violations of the min rule, the conjunctions' typicality exceeds the minimum value of the constituents by virtually half the scale! For all three cases, the deviation from the min rule is significant by a sign test.
 tttble 2 Typicality Ratings for Ttirse Groups, Separately for Each Case a.
 Object Has High valua on Property AdjHoun Cases It nondiagnostic 3: Positively ISiagnostic 5: Negatively Diagnostic Adjective Rating 8.
71 8.
50 6.
93 Noun Rating 7.
25 7.
81 3.
54 Ad jNoun Rating 8.
65 8.
87 8.
52 Minus HlniMB 1.
40 1.
06 4.
98 b.
 Object Has Iaw valus on Property 2: Nondiagnostic «i Positively Diagnostic 6t Negatively Diagnostic .
45 .
02 .
81 7.
25 3.
54 7.
81 .
52 .
10 .
39 .
07 .
08 .
42 As for alternatives rules within fuzzyset theory, none seem to do a better job.
 Gougin's (1969) multiplicative rule suggests that the conjunction's typicality rating should be less than the minimum value of the constituents, which is even wronger than the min rule.
 Another alternative is that the conjunction's typicality value be the average of its constituents, but this too is violated by the data (see Table 2 ) .
 The bestfitting post hoc rule is that the conjunction's typicality is the maximum of its constituents.
 The max rule works well for Cases 1 and 3 but fails for Case 5; and it is not really a serious possibility in fuzzyset theory for if conjunctive concepts are represented by a maximum then there is no obvious way to represent 48 disjunctive concepts.
 The bottom half of Table 2 contains the results for cases where the pictured object had a low value on the property denoted by the adjective.
 For all three cases the min rule works well, but only because subjects in the Adjective and AdjNoun groups judged the pictured objects to be nonmembers of the relevant concepts.
 Thus, when presented a picture of a brown apple and asked to judge its typicality of red or of redapple, most subjects gave it 0 ratings.
 This flooreffect, which prevents us from taking the data in the bottom of Table 2 as a sensitive test of the min rule, reflects a poor choice of how to experimentally implement the extent to which an object instantiates the property denoted by the adjective.
 Thus, for the concept red, had we used pictures of red apples and reddishbrown apples, we might not have obtained so many 0 ratings for the concepts red and redapple.
 This change has been made in our subsequent experiments.
 In conclusion, for cases where an object "fits" a concept well, fuzzy set theory fails to provide an adequate account of conceptual combination.
 References Osherson, D.
N.
, & Smith, E.
E.
 On the adequacy of prototype theory as a theory of concepts.
 Cognition.
 1981, 9, 3558.
 Zadeh, L.
A.
 Fuzzy sets.
 Information and Control.
 1965, 8, 338353.
 49 Natural Language Prooaaslng Ualng Spreading Activation and Lateral Inhibition Jordan Pollack & David Waltz Coordinated Science Laboratory Oniverslty of Illlnola Abstract The knowledge needed to process natural language comes nrom oany sources.
 While the knowledge Itself may be broken up modularly, Into knowledge of syntax, semantics, etc.
, the actual processing should be completely Integrated.
 This form of processing la not easily amenable to the type of processing done by serial *von Neumann" computers.
 This work In progress is an Investigation of the use of a spreading activation and lateral Inhibition network as a nechanlam for Integrated natural language processing.
 This work was supported in part by the Office of Naval Research under contract N0001475C0612.
 INTRODUCTION It has long been thought that the modular decomposlbllity of i''"T'"'g« ifnowiadyn into syntax, semantics and pragmatics implied that langimga pm̂ 'a!l.
1̂  ng could be similarly decomposed; that natural language could be processed by first parsing the syntax, then fleshing out the meaning of a syntactic derivation tree, and finally (if we could ever get to this point!) attempting to Interpret the speaker's Intentions.
 Nowadays, it has become apparent that this processing is Integrated In humans [MarslenHllson, 1980], and that It should, thus, also be in computer models [Schank k Blmbaum.
 1980; DeJong, 1980].
 However, the natural inolinatlon of von Neumann computers to run onestep at a time presents a severe roadblock to the kind of Integration needed for NLP.
 What Is needed la an integration mechanism sensitive to interpretation pressures from several directions.
 A promising approach would seem to be the use of a quantitative spreading activation / lateral Inhibition network.
 This kind of network, similar in conception to relaxation techniques for lowlevel vision, and to neural network models, works through the Iterative adjustment of realvalued node weights.
 PREVIOUS AND RELATED WORE The term "spreading activation" Is almost as overworked as the term "frame," but most systems which spread activation do It in one of two ways: As mrltftr oaaalM Interaectlon s»nroY, [Quillian, 1968; ColUns & Quillian, 19T2; Fahlman, 1980], in which a parallel intersection search Is simulated by binary marking of adjacent nodes in a breadthfirst manner, or as quantitative welifht halannln^r [Ortony, 197U; McClelland & Rumelhart, 1981], in which activation energies assigned to all nodes are Iteratively adjusted, based on local activation energies and strength of connections.
 One of the wellknown dangers of spreading activation Is its potential for overkill; an intersection search, under certain circumstances, may generate too many 50 useless Interseetiona, and quantitative adjustment may result in "heat death," where every node becomes activated.
 (A solution for this latter form of activation involves the use of decay, dampening factors, or the spread of negative energy  lateral inhibition.
) Nonetheless, both forms of spreading activation display Interesting behavior.
 For example, the previously mentioned work by Collins and Quillian showed how spreading activation could account for aspects of human memory priming, while Fahlman's work demonstrated that many forms of problem solving could be simplified when an Intersection search was computationally "free.
" Ortony, on the other hand, built a system for schema selection using damped activation, and McClelland and Rumelhart effected a close simulation of experimental results on human letter and word perception in context.
 Other work In parallel approaches to natural language processing has been done by Small [1981] and Hleger [1977] in which the traditional practice of breaking down knowledge Into syntax and semantics was turned on its head, and knowledge of all kinds was distributed to individual "word experts"; by Hendler 4 PhllUps [1981] who are working on an ACTORbased [Hewitt,1976] NLP systea; and by Gigley [1982] in which a neurollngulsticallyinspired NLP systea capable of simulating aphaslc behavior was built.
 NATURAL LANGUAGE PROCESSING USING AN ACTIVATION/INHIBITION NETWORK The authors of this paper are presently buUding a NLP system In which the knowledge sources are modular, but the processing is fully Integrated.
 The integration mechanism is an activation/inhibition network similar in nature to the one used by McClelland and Rumelhart and described below.
 An activation/inhibition network la a weighted directed graph, where node weights represent activation levels, and link weights represent strength of activation if positive, or strength of inhibition if negative.
 The process of spreading activation / lateral Inhibition Involves Iterative recomputation of activation levels.
 At each cycle, .
every node receives a contribution from each of Its neighboring nodes equivalent to the neighbor's activation level multiplied by the weight of the Intervening link.
 This contribution (scaled to range between 1 and 1) causes a proportional change in the activation level of the node; a contribution of 1 zaps the node up to Its (predefined) naxlDum activation level while a contribution of 1 saps the node of all its strength.
 Eventually, a static condition is reached where some nodes reach their maximum or oinlmum strength, while the rest of them receive contributions of 0.
 (For a complete mathematical formulation see Pollack [1982b].
) NETWORK CONSTRUCTION An activation/inhibition network such as this can sBOOthly oodel the flow of quantitative constraints up and down a nultllevel syaten.
 For natural language processing, tbe main problem becomes how to build such a Bultilevel network.
 We feel that a proper network can be built through the Judicious instantiation of network fragaenta which are represented in standard knowledge representation structures, such as fraaea [Hinsky, 1975].
 The fraaes in our systea contain the knowledge of syntax, of senantic features, and of case roles, organized to efficiently generate pieces of network on denand.
 These fianes are richly Interconnected with activation and Inhibition links, and constitute the general knowledge base of tbe aystea.
 When sentences are input, a teaporary network is constructed out of fragments stored within lexically accessed frames.
 These fragments are organized into a network by the same sort of breadthfirat operation used in a chart parser [Kay, 1973].
 The resulting network has activation links between phrase markers and their constituents, and inhibition links between pairs of phrases that have comnon constituents.
 (So far, we have done the network building by hand.
) actions are as In more detail, the required follows: First, there is breadtbflrat iMtantlatlQB of nodes representing phrase markers, case roles, and expectations for other nodes.
 These expectations are triggered when lexical Iteaa or grammatical constituents are encountered, and consist of siaple feature patterns to match and connection procedures to be carried out if the match occurs.
 Secondly, there is nattambaiiad nonnaetlon whereby if a newly instantiated node matches a pattetm, specific linkages are made.
 As an exaaple of these these two processes, if a node of type NP is instantiated, it will then cause the instantiation of an expectation that a VF will occur; if a TP is found, an S is generated and connected to both the NP and TP.
 Of course, if more than one candidate for a pattern shows up, the two candidates are connected with an inhibition link, so one will eventually be eUfflinatad.
 The aetlvatlon and.
 1nhih<t.
inn processes reinforce .
 nodes that are supported by aotivatlon links and inhibit those which are not, so, for example, expectations that are not quickly fulfilled will die.
 Furtheraore, activation and inhibition are also happening in the background frame systea by a purely word associative scheme, which helps prime good word senses (and aids in schema selection).
 Finally, nodes which become inhibited below a certain point are yarha^n poiiaotad thus keeping the active network as small as possible.
 EXAMPLE OF OPERATION Some preliminary results are presented here which demonstrate the feasibility of the activation/inhibition approach to NLF.
 As mentioned above, since the systea is In its early stages, the networks presented were built by hand.
 We demonstrate bow the system reacts to syntactic ambiguity, how a lexical preference can affect its behavior, and finally how semantic constraints can be integrated.
 Consider, then, the following sentence, which, in the absence of any semantic knowledge, is syntactically ambiguous due to the lexical ambiguity of "up": John ate up tbe street.
 The handbuilt network for this sentence is shown In figure 1 with arrows denoting activation links, and circles denoting inhibition links (following McClelland & Ruaelhart).
 Note that each node in this network is suffixed by two numbers which f that noc 1S 0 5 '.
 le.
 " \ , IVP 1 5' JNPai,^ ' VP 1 .
 / |VP 12| 1 1 JOHN Oil 1 ATE 1 2 1 , S 0 S P ,, J ^ .
 •" / : pp 2 51 \ 3 ' ?=.
£.
= 2 3 " NP 3 5  Z T L Z l ^ • PART 2 3 1 / 1 OET 3 u : i .
1 u 5 • ! / i I 1 UP 2 3 1 1 TXe 3 4 1 1 STREET n S | rlCUSE 1  llHtkx AcTlViTIOH/lnMUlTlON 'lETWOUK roR "John Eats L'p The Sheet' One would expect a robust NLP system to be confused by ambiguity but then to gracefully resolve it.
 This is Indeed what happens.
 Figure 2 contains a graph of the activation levels over time for all the nodes in the network.
 Each node is depicted by a single letter, and each activation cycle by a horizontal row in the graph.
 When a letter traces a path to the left.
 It is being inhibited and when It moves to the right, it la being activated.
 The most interesting node pairs to watch are B and C, the mutually inhibitory sentences, and G and F, the mutually inhibitory verb phrases: jchriJI Is shown as §) npOl is shown as A) 305 is shown as B) ,s05p is shown as C) ate12 is shown as D) vp12is shown as E) vp13 is shown as F vp15 is sham as G ui£3 is sfaon as H) part23 Is ahcMn as 1} FreD23 Is shown as J) aie5'> Is shown as K) detSU is shewn as L) streettS is shown as M) T«5 Is shown as N) np35 Is shown as 0, pp25 Is shown as P.
 Activation Level I C i , c r c SG t r c s r •« x C 1 G C 9C c a == c c = r • I  ,1 Jl t j«» »• •̂  ".
 • a s T a I S :•!!*• s c J a ̂ f a Fiz J H •• f r : 3 ̂: •  f t : a • r I .
^c •• f* : K3J •• : a • •• [ B .
• a H J 3 5 = ̂  ^ S «t" 3: ,i: f ;!• ;!< >— Ti i 3 + Figure 2  "Confused" 51 Bs(Jotan} (ate (up the street)) C3(John) (ate up) (the street) Gs(ate (up the street)) Fa(ate up) The system Is confused at first: B is more heavily weighted than C, so the sentence with the preposition is selected, while F is more strongly activated than Q.
 so the verbparticle phrase is selected.
 This selection is, obviously, innonaiMtant.
 But then, after about 30 cycles, the system "decides" ("Look Ma, no homunculusI") on a consistent reading of "up" as a preposition, and weights G more heavily than F.
 In the absence of semantic preferences (e.
g.
 a preference for interpreting "street" aa a location), syntactic preferences can play a role.
 Certain words ia.
 have lexical tendencies, as, for Instance, the word "does", which is most often a verb, but which is also a plural noun, meaning several female deer.
 Figure 3 demonstrates the sensitivity of an activation/inhibition network to syntactic preferences.
 The link strength flom "up" to "particle" has been increased, corresponding to a lexical preference.
 Notice that the phrases related to interpreting "up" as a preposition (B, G, J, and P) become inhibited much more quickly this time.
 However, when humans process this sentence, they also take Into account the knowledge that "street" is a good candidate for a location, but a bad candidate for the object of eating.
 The next example demonstrates the sensitivity of our NLP approach to this semantic knowledge.
 Four nodes have been added and connected into the network.
 The verb phrase "ate" is U n k e d to "ateloo" and "ateo b j , " and the verb phrase "ate up" is U n k e d to jchrfll Is shown as g) ncOl is shown as A) (s05 is afaown as B) (s05p IsatKunas C) (atel2 Is shown as 0) (vp12 is shown as E) vp13 is shown as F) vpIS is shown as G) up23 is staoun as U) part23 is shown as I) preD23 is stxja as J) ttie34 is shown as K) detSI 13 shown as I) street45 is ahoun as M) ntS is aiiowi as N) n p ^ is shown as 0} ppc5 ir shown as P) Activation Level ;te up OBJ ATE OBJ ' ATE UP LOC ATE LOC FP 2 5 VP 1 3 I PREP 2 3 I (IP 3 5 NP 0 1 VP 12 JOHN 0 11 I ATE 1 2 I | UP 2 3 1 THE 3 "tj | STREET i« 5j FlOUM t  S€)W«TlC»LLr AuGMfNTtD NrTWOBK "ateuploc" and "ateupobj.
" These nodes represent "cases" [Fillmore, 1968] of their respective nodes and are a subset of those that would be instantiated by our system.
 The patternmatching connection component would connect the prepositional phrase "up the street" to "ateloc" based on its span and on inherited features from •up" and "street".
 The modified network is shown in figure 4, and figure 5 graphs the response of the activation/inhibition network to this new information.
 As one can see, after 15 cycles, all nodes related to interpreUng "up" as a particle are being rapidly inhibited.
 (T, S, C.
 F, and I ) .
 PROSPECTS The results given above are interesting in that they demonstrate the sensitivity of activation/Inhibition networks to s U g b t IV JchrOI is shown as $) npOl is shown as A) s05 is shown as B) s05p is shown as C) ate12 is shown as D) vp12 is shown as E) vp13 is shown as F vplb is shown as 0, up23 is shown as U part23 is shown as I) ?ac .
 is shown as J) is shown as t) , ,.
• Is shown as L) (street45 is shown as M) (nit5 is shown as H) ,cp35 Is shown as 01 pp25 is shown as P) ateloc Is shown as Q) ateobj Is sfaoun as R) ataiploc is shown as S ateupobj is shorn as T) V? 1 ,' •  ' 2 : ! J ,.
 • = •: «  r ̂  • r » • 7 i.
 •: I • Tj.
 •: ic • T*: i c • *̂ : : ' ^ •e c rT : I : = : I ̂ .
 z 5 : = = I 3 Activation Level Figure 3  Syntactic Preference for "Up" as Particle 3 ^'?^^i i« I 3 f P " 0 4 .
 u« as r * 'J fa»»i': •3 1 r ;̂ * • a • : • 3 : , I Hc«« "5 • i if • c \i( Figure 5  Added Semantics a f» • • a fiin 1 *• ""a 4 •• 1̂  ,•   — *u c* f : iii'.
 I.
 M 3^" « .
1 ?: ? .
1 ra :i5:i: 52 differences In luiowle<lge.
 Currently we are working to complete the autoaatlc instantiation and connection coaponents of the systea.
 The use of a parallel and decentralized decision process can be brougbt to bear on many other Interesting problems In NLF as well.
 For instance, there are Indications that the timing and volume of spoken language both play useful roles in disambiguation [Wales and Toner, 1979]• A system based on activation and inhibition could be designed for sensitivity to these clues, since time is, after all, a crucial element in the activation/inhibition process.
 Furthermore, the processing of garden path sentences, which are an interesting but not wellunderstood phencoenon in natural language, could quite possibly be handled by an activation/inhibition network.
 Marcus [1979] built a parser which attempted to account for gardenpath sentences as a result of memory limitations.
 Unfortunately, there are garden path sentences his parser could (though shouldn't) heindle [Milne, 1980], such as: The prime number few.
 Within the framework of activation/inhibition networks, garden path sentences would be accounted for by irreversible inhibition of expectations.
 Also we have recently begun to consider ways of integrating a novel form of knowledge representation, 'event shape diagrams' [Waltz 1982], to model certain kinds of metaphor understanding and adverbial modification.
 As an example, these methods should allow us to interpret sentences such as: Robbie's metal legs ate up the space between himself and Susie.
 as meaning a kind of PTSANS [Schank 1975].
 Finally, a practical syatea based on activation/inhibition networks could be the starting point for new computing architectures.
 In this vein, [Pollack,1982] has designed a VLSI cell for parallel simulation of activation/inhibition networks, thus showing that a programmable set of logical connections (i.
e.
 links) can be run on a machine with fixed and regular physical connections (i.
e.
 wires).
 CONCLUSION The processing of natural language requires the sensitive Integration of multiple sources of knowledge.
 A mechanism very likely to achieve this integration is an activation/inhibition network.
 REFERENCES Collins, A.
 and M.
R.
 Quillian, 'Experiments on semantic memory and language comprehension' in L.
W.
 Gregg (Ed.
) Cognition la Learning and.
 Hemnrv.
 Wiley, New York, 1972.
 Church, K.
 and R.
 Patil, "Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table," presented at 56th Linguistic Society of America meeting, December, 1981.
 DeJong, C, "Prediction and Substantiation: A new approach for Natural Language Processing" Cnanitiv« Science V.
3 #.
3 pp.
 251273, 1980.
 Fahlman, S.
E.
, H£IL: A avatea for ReprRaantl ng aM Oalng RealWorld KnowlwrlTA, MIT Press, 1979.
 Clgley, H.
, "Neurollnguistlcally Baaed Modeling of Natural Language Processing," Doctoral Thesis (in preparation), University of Mass, Amherst, 1982.
 Hendler, J.
 and B.
 FhUlips, "A Flexible Control Structure for the Conceptual Analysis of Natural Language Using MessagePassing," Technical Report 088103, Texas Instruments, 1981.
 Hewitt, C, "Viewing Control Structures as Patterns of Passing Messages," MIT AI Memo UIO, 1976.
 Hobbs, J.
H.
, "A Metalanguage for Expressing Grammatical Restrictions in Nodal Spans Parsing of Natural Language.
', Report NSO2,Courant Institute, Min, January 197'* Kay, M.
, "The MIND System", in Rustin (Ed.
) N>«tural '•«"?"'""> PT̂n<>«•̂ •̂̂ ^̂n.
f• Algoritbmics Press, Hew Xork, 1973 Marcus, M.
P.
, A Theory oT SYTit.
actlc R«nngnlt1nn far Natural Language.
 MIT Press, 1980.
 MarslenWilson, W.
 and L.
 K.
 Tyler, "The Temporal Structure of Spoken Language Understanding," £ogaitlfla V.
8 #.
1 pp.
 172, 1980.
 Milne, H.
, "Using Determinism to Predict Garden Paths," DAI Research Paper 142, University of Edinburgh, 1980.
 Mlnsky, M.
, "A framework for Representing Knowledge", in Winston (Ed.
) The Pavphningv nf Computer Vlalon Megraw Hill, New lork, 1975.
 McClelland, J.
L.
 and D.
E.
 Rumelhart, "An Interactive Activation Model of the Effect of Context in Perception", Technical reports 91 4 95, Center for Human Information Processing, UCSD, 1980.
 Ortony, A.
, "SAPIENS: Spreading Activation Processing of Information Enclosed in Assooiatlve Network Structures", unpublished.
 1976.
 Pollack, J.
, "An Activation/Inhibition Network VLSI Cell", WP #31, Advanced Automation Group, Coordinated Science Laboratory, Urbana, January, 1982 Pollack, J.
, "An Activation/Inhibition Approach to Natural Language Processing", WP #35, Advanced Automation Group, Coordinated Science Laboratory, Urbana, AprU, 1982 Schank, R.
C.
, "The Primitive ACTS of Conceptual Dependency", in Schank 4 NashWebber (Eds.
) Thpopfttioa1 laauea In NLP.
 ACL, Arlington, Va.
 1975.
 Schank, R.
C.
 and L.
 Birnbaum, "Memory, Meaning, and Syntax," Research Report 189, Yale C.
S.
 Department, November 1980.
 Rieger, C, "Viewing Parsing as Word Sense Discrimination," in R.
 Dingwall (Ed.
) A Survey nf Llmnilahlt.
 Snlanna Greylock, 1977.
 Wales, R.
 and H.
 Toner, "Intonation and Ambiguity", in W.
E.
 Cooper and C.
T.
 Walker (Eds.
) Sentsnow Proeeaaing: PaYchollagulatlc Studlfla Prs.
3ented in Merrin Gpprgtt.
 Erlbaum, New Jersey, 1979Waltz, D.
L.
, "Event Shape Diagrams", To Appear in frflfi.
.
 NCAI.
 Pittsburgh, August, 1982.
 53 USING THE DANCE TO INVESTIGATE THE PRAGMATIC/SEMANTIC BOU^IDARY BETWEEN ARTIFICIAL AND MATUHAL LANGUAGES Laura Silver University of Pittsburgh Lawrence J.
 Mazlack University of Cincinnati 0.
0 ABSTRACT This work addresses the pragmatic and semantic distinctions between natural and artificial languages by the development of a contextfree generative grammar to describe motions in =odem dance.
 The dance is a particularly good vehicle as it conveys meaning, but is undescribed by a generative grammar.
 Whether or not a grac=iar describing dance motion can be considered to be for a natural or artificial language is unclear.
 1.
0 INTRODUCTION There are two different kinds of languages: natural and artificial.
 Artificial languages have been developed to deal with formal systems of mancreated knowledge.
 Natural languages enable naturally arising entities to deal with their environment.
 Generally, artificial languages deal only with truth or knowledge that is specific to their artificial environment.
 Both the written and spoken forms of human speech are universally considered to be languages.
 Animals as well as humans appear to communicate with each other through body motions.
 Whether or not body motioo should be considered a language is open to deoate.
 Some workers believe that the term "language" should be narrowly defined to Include only signaling systems which are capable of manipulating abstractions.
 Others, would consider any orlgized system of signaling to be a language.
 It is agreed that whatever a language Is, its construction and Interpretation is constrained by a specification mechanism.
 In langiiages, the construction specification is called a grannar.
 Precisely how humans come to know the grammar of a language is unknown.
 One group of workers holds that it is learned.
 The other group, believes that the capability Is innate.
 Irregardless of how men come to icnow the structures of spoken language, they certainly are capable of learning the grammars of artificial languages, for example, automata.
 Both artificial and natural language can carry meaning; i.
e.
, have semanticity.
 However, the semantic information represented by artificial languages appears to be of a different type than that of the information carried by a natural language.
 In order to develop an understanding of the pragmatic and semantic differences between natural and artificial languages, a generative grammer is being developed to represent dance generation.
 The developed grammar is artificial, that described appears to communicate naturally.
 Whether or not the dance is a language is open to question as the tokens of the dance are never abstractions.
 The problem is to understand the nature of language: of how humans perceive, understand and represent their world in their semiotic system.
 54 It is of further Interest to develop an understanding of the relationship between the natural language system and the artificial language systems also developed by humans.
 These systems are intentionally created in order to represent systematically in systems of signs other perceptions In the symbolic manner or representation.
 Systems of signs can be represented as systems of signification where perceptions exist within the plane of content and are represented by the symbolic plane of expression.
 Artificial language systems such as mathematics and logic, are usually referred to as symbol systems, however they too are language systems and function as semiotic systems, as they are formal systems of signification.
 In order to extend the analysis of information distinctions between the semantics of natural and artificial systems have to be clarified as do the distinctions between information and pragmatics.
 2.
0 BACKGROUND Language, communication and information are three tightly interwoven concepts.
 The problem of inforoatlon representation and communication Is the focus of this work.
 2.
1 Language Language is a process or symbollzatlon that enables signification of some thing by representing It by something else.
 The "thing" represented has an existential spacetime reality; the representation is an abstraction of the reality.
 Meaning is derived from the relationship between the physical and the symbolic 2.
1.
1 Meaning Language provides the capability to functionally relate symbolized meanings.
 However, language is more than individual relationships among the meanings.
 Words, which are symbols, recursively become things themselves as they are utilized.
 As things themselves, they can be used symbolically to express or represent concepts as the next order or abstraction.
 Signs, syabols, words, tokens, pictographs are the tangible products of the interrelationship between the thought and the referent.
 This interface provides an operational definition for the nature of the concept of meaning, the property cf language defined as "semanticity.
" That is, "the property of being able to convey meaning" [LYON 79].
 2.
1.
2 Semiology: An .
Analytic Tool De Saussure defined language as the Semiotic system; i.
e.
, the science of signs.
 The sign is a subsystem, or a component of Che system of language.
 The principle of "signification" indicates the relationship between the thing signified (the signified) and the things signifying it (the slgnlfier).
 Sigr.
lfiers exisc within the "plane of expression" and signifieds exist with the "plane of content.
" This relationship expressed by the sign as: sign » (signifler, signified) which is a specific relation between the plane of physical reality cr "content" and symbolic reality or "expression.
" More generally, the sign is defined as: sign = (plane of expression, plane of content) A language is considered to be comprised of a set or system of signs.
 Semiology aims to take in any system of signs, whatever their substance, and limits; images, gestures, nusical sounds, objects, and the complex associations of all these.
.
.
constitute, if not languages, at least systems of signification" [Bart 9].
 Seminology will be used as tool in the analysis conducted by their work.
 2.
2 Natural and .
^tificial Language Whether or not artifically constructed languages, or language schecas, can be considered as language "proper" is not central to this work.
 Semiology, although initially concerned with natural signalling or communication systems set the stage for the analysis of any system of signs, whether they be natural languages or artificial language systems.
 In discussing languages, Carnap states "so long as we are concerned with building this language, and not with its application and interpretation respecting a given theory, the signs of our language remain uninterpreted.
 Strictly speaking, what we construct is not a language but a schema or skeleton of a language: out of this schema we can produce at need a proper language (conceived as an instrument of communication) by interpretation of certain signs.
" [CARN].
 Cherry discusses the difference between the natural and artificial kinds of languages.
 By 'language' we shall mean those organically developed systems, whether spoken or scribed, by which humans transmit messages; but the work 'cipher,' or 'code,' will be used to mean any invented, selfconsistent system, whereby one set of symbols may be transformed into another for certain special stated purposes" [CHER 93, 94].
 This difference between "language" and "code" can be understood not as a.
 difference in structure, but as a difference in development.
 The concept of language generally implies an organic or natural development, and consequently referred to as "natural" language.
 The concept of code Implies an intentional development, and consequently if referred to as "artificial" language systems.
 2.
3 Analyzing Language The language being observed is usually called the objectlanguage.
 The language used to discuss the objectlanguage is called the metalanguage.
 The semiotic of the object language is torrulated in the metalanguage system.
 Carna? identified the semiotic analysis of the object language into the three components of syntax, semantics, and pragmatics.
 The terms syntax, semantics, and pragiatics are somewhat ambiguously applied.
 ?art of the ambiguity of these terms is a function of whether the analysis of the object language is either the natural or artificial form of language.
 According to Carnap, syntax "attends strictly to the expressions and their forms.
" However, "syntax may include rules which determine certain logical relations between sentences, e.
g.
, the relation of derlvability" [CARN 79].
 The inclusion of the property of derlvability in the syntactic component blurs the boundary between syntax and semantics.
 2.
4 Differing Semantics: Descriptive and Logical Both natural and artificial languages contain the components of syntax, semantics and pragmatics.
 In the artificial language system, semantics refers only to the expressions and their designations without reference to any particular external system.
 In the natural language system, semantics includes the analysis of meaning by pointing to referents in the extentional world.
 In essence, there are two kinds of semantics, which can be understood as depending on either contextsensitive or contextfree grammar.
 In artificially or "logically" constructed language systems, the grammar is contextfree.
 In natural language, the grammer is contextsensitive.
 This latter form of semantics could be referred to as descriptive semantics, following the terminological distinction that "descriptive linguists" do the analysis.
 Their analyses are contextsensitive, in that they include the pragmatic component of meaning.
 In contrast, the form of semantics pertaining to the artificially or logically constructed language system can be labeled logicalsemantics.
 2.
5 Communication and Information Languages can be both naturally developed and artificially created.
 At the semiotic metalevel form of analysis both forms of language are treated as object level languages as both fulfill the need to signify; i.
e.
, to represent perceptions and abstractions.
 This process of signification is more generally known as communication, where the language serves as an instrument of communication.
 In the analysis of the problems inherent in communication, workers such as Shannon and Weaver have identified three levels of difficulties which complicate the problem of identifying information, particularly at the semantic level: (a) accuracy of symbol transmission, (b) communication of meaning, and (c) effectiveness (how conduct is affected).
 These three levels are all concerned with the concept that is labeled information, yet which "information" applies is not consistent for all three levels.
 Level A uses "information" as the amount of signal transmission, where Levels B and C the "information" is the semantic and pragmatic sense.
 55 3.
0 PROBLEM DOMAIN In order to develop a contextfree information representation a doaain other than human verbal communication had to be selected.
 Verbal communication is too contextsensitive.
 Rather than working with the anbiguities of human verbal communication where it is difficult not to be pragmatic, or with information system design where the objective is to be pragmatic, the information system of human movement comcunicaclon was selected.
 Just as linguists have attempted to develop the notation tor natural language grammars, seeking to represent the logicalsemantic component, a similar gramcatical structure of human movement can be developed.
 Generally, the domain of human communication is categorized into the verbal and the nonverbal.
 The verbal includes both the verbal and written forms of natural language.
 The nonverbal includes everything that is not verbal communication.
 Within this large category of nonverbal, the domain of human movement conmunication has been selected in order to construct a formal grammar representing the logicalsemantic component of human movement information.
 3.
1 Purpose This research investigates the semantic component of the artificial language system.
 The concern addressed is the clarification between the descriptivesemantics with the contextsensitive grammar (CSG) representation, and the logicalsemantics with the contaxtfree grammar (CFG) representation.
 The purpose is to illustrate the separation of the logicalsemantic from the pragmatic, in order to demonstrate that it is possible to separate the information structure from potential meaning.
 The CFG is a template, providing the structure for the set of possible constructions any eventual user could select in order to represent any intended meaning.
 Prior to the representation of meaning a structure has to be defined whereby meaning representation can be made possible.
 Just as the information system can be viewed as both a process and referred to as a thing, a grammar can also.
 It is a template and therefore a thing, but it is a dynamic processing structure.
 3.
2 Existing Systems Representing Human Movement The representational systems for human movement are data systems in chat they are bound to some pragmatic component and that they are contextsensitive.
 Each has a basic set of symbols representing units that the user needed to represent.
 Although each representation system identifies a variety of syntactical units, no logicalsemantic or grammar has yet been developed.
 Thus there is as yet no representation for the process of human movement information.
 3.
2.
1 Notations Labanotation is one of the most widely used representational systems for notating human movement [dnot] [HL'TC].
 The notations are syntactic representations specifying syntactic units: direction, level, timing, and areas of the body, which are represented by unique symbols.
 It is not possible to use the system for anything but the description of the movement in the units provided by the initial symbol set.
 There are no structures or rules indicating relations among 56 the syntactical units to generate more complex units.
 Consequently there is no representation by a grammar expressing the information sysrem that is communicatea by the movement.
 Other notation systems are similar [SILV].
 The EscholWatchman, the flenesh, Klnesics, Choreometrics, to name only a few, only differ in the specific particularlzation of the syntactic representation.
 Why is there no system for representing the human body and its movement apart from any context? Perhaps because in the development of the representational systems, distinctions between the syntax and the logicalsemantic were never clearly understood.
 3.
2.
2 Models and SimulacionB The objectives of various designers of models and simulations of human movement have been to extend the representational facilities of the human by mechanizing the laborious task of describing and computing problems in human movement.
 The goal was to develop a computer graphic display of a human model [POTT] [BILL].
 Another area of research was the development of an interactive graphic editor for Labanotation [brow].
 The objective was to use the computer to facilitate the laborious process of hand writing Labanotation.
 This work was extended as part of the development of a graphic slmulacion for human motion [BALD] [TRAC].
 3.
2.
3 Recognizing What To Know The visual aspects of the perception of movement are essential in the design of mobile robots and the contextsensitive forms of representations are usefull.
 However, a contextfree fona of representation is preferable prior to any contextsensitive (i.
e.
 applied) form of representation.
 For example, the visual aspect can be specified as a contextsensitive situation, which subsequently can be defined using a contextfree grarmatlcal structure.
 Research on this problem is important not only for the solution to problems in movement understanding, representation and generation, but also to Illustrate the contextsensitivity of systems.
 If we wish to represent the dynamic process of information, research must be done on abstracting the information from the pragmatics of use of that information.
 The structure of the process of information must be represented prior to the pragmatic application of the Information.
 3.
4 Separating Logical and Semantic Descriptive Structures Human movement and human verbalization both have the association of meaning with the sensorial transmitcable component of movement and of speech that is transferred as a product of the information system.
 Where natural language has the symbolic representational facility of the written form, providing another channel for the transfer of the information, the movement notations do not.
 Just as the information process of human verbalization has been grammatically coded, the aspect of the problem that first needs to be addressed is the definition of the logicalsemantic, i.
e.
 the formal representation of the grammatical structure to code the information transferred via human movemenc.
 Before the graraar can be contextsensitive, it needs a contextfree fcir:.
 The problea is to develop a way to write movement infonation such that contextsensitive meanings can then be communicated in a written symoolic fona.
 3.
4 Conmiunication Systems: Human Movement Compared to Natural Language The semiotic system of human movement communication was selected as the domain in which to investigate representation of a natural activity in an artificial language.
 Adequate representation of the generative structure of the semiotic system seems to be the necessary and sufficient conditions which linguists, anthropologists and philosophers require for "language" identification.
 U'here natural language encompasses both verbal and written forms of the sounds and their meanings, movement language exists only with what can be equated with the verbal level of natural languages.
 A comparison of this difference would be equating the notations for movement with the phonological orthographic representations of the sounds of natural languages.
 Each natural language has particular orthographic s>mbols necessary to represent the sounds of that language, just as each form of movement has developed notational symbols to represent the visual perception of moveaents particular to that form.
 However, where verbal language has not only the particular phonologogical representation, it further has a representational form which is called the written from where the meaning in the experiential form can symbolically be represented.
 4.
 INVESTIGATIVE STRUCTURE The specific problem addressed is the development of a prototype for information representation, by experiment with representions of the losicalsemantic structure of human movement information using the BNF form of the contextfree granmar as the analytic tool.
 It Is posited that the situation in natural language representation is analogous to problems in information system design.
 Before the granniatical structure is constructed, conprised of the vocabulary elements of the system and the set of relations anong then, particular referents to the units are assigned, building the concextsensivitity into the initial design of the system.
 The idea of the contextfree form of representation preceeding any contextsensitive representation is the direction of this research.
 4.
1 Role or The Grara.
ar The grammar itself is a representational template, in that it does not contain the meaning, but rather provides a structure.
 The graruaar is a process in that it is used as a template.
 It is a commodity in that it is a tool constructed for analytical and representational purposes.
 It is tied to a particular form of representation, but it is relatively contextfree.
 Any language system is a particular form of a semiotic system useful to communicate a range of meanings, and sensitive to that range.
 (Whorf defined this concept as "linguistic relativity" [WHOR].
) Yet, the same semiotic system is contextfree, in that it has the feature of productivity, and can generate valid expressions to represent new meanings even in the extensional world to which it is bound.
 Looked at in this way, a grammar exists at the metalevel, providing a form of analysis for an information structure for any possible objectlevel expression that is generated in that language system.
 BNF was chosen to represent the granmar.
 It provides a method of notation with the capability to code information that is dense and nonlinear.
 BNF also lends itself to consistency verification.
 4<2 Scope: ContextFree Representation of An Information System In the analysis of the communication or semiotic system of human movement that is to be represented, only the logicalsemantic form of the semantic component will be considered in order to illustrate that contextfree representation is possible when the coding is only of the inf or::iation system rather than including the pragmatics of the communication system.
 This reception of data as information by the receiver is the pragmatic component, which is added to the input data from the sender.
 Meaning is the result of the contextual processing of data given some Information input.
 In order to develop a contextfree grammar for Che logicalsemantic of human movemenc information, a nonpurposeful context needs Co be examined, i.
e.
, where the movement is not intended to communicate any meaning buC where the units of movement are learned for the production of movement icself, which subsequenclv can be used in various contexts to communicate a variety of meanings.
 4.
3 Dance Units Dance inscruccors teach the units of the movemenc language withouc any intended transfer of information ocher than hew to produce the units of movement.
 The vocabulary of movement that is used for dance is a complex series of units, which are derlveable in terms of initial units, plus rules for connecting the various units.
 These more complex units are referred to as "combinations.
" The units and the combinations are the information communicated in dance inscruction.
 4.
4 The Goal: A Movement Semantic This methodology formally can be represented as an operation of the logical structure of the BNF grammar, operating upon the selected scope of the verbal channel of the domain of the information system of human movement yielding as a product a grammatical representation of the logicalsemantic component of the information system.
 The movement semantic will be the graimnar derived from the operation of the template processing the logicalsemantic structure of the information into a representational form.
 This product will represent the results of research of the representation of the dynamic structure of the information process in a grammatical contextfree form.
 The form of representation is that of a formal logical system.
 4.
5 Verification A form of logical verification can be acccrlislied 57 by using LEX, the lexical analyzer, and YACC, the compiler compiler of the UNIX operating system.
 One of the advantages of using the BNF notation is that the movement semantic being developed and the code that LEX recognizes are both in the contextfree form which is based upon the BNF notation.
 4.
6 Project Summary The project will: 1) represent a portion of the logicalsemantic information structure of a selected domain of human movement information, 2) represent a prototype for a written code of a representational rather than an experimental human movement language where 3) the symbolic representation of human movement information is accomplished using a dramatical rather than a descriptive template.
 The aim is to define a subset of human movement information code that meets these criteria of the logical or artificial system, such that it can be used without the problems of contradictory and ambiglous expressions that are inherent, for example, in natural language systems.
 Press, Urbana, Chicago, 1980, cl9A9.
 SILV Silver, L.
 D.
, "Towards a Movement Lanugage: On the Representation of Movecent Knowledge," manuscript.
 Interdisciplinary Departi.
ent of Information Science, University of Pittsburgh, Pittsburgh, Pennsylvania, 1981.
 TRAC Tracton, W.
 P.
, "GEL: A Graphic Editor for Labanotation with an Associated Data Structure," Movement Project Report Ho.
 15, The Moore School of Electrical Engineering, The University of Pennsylvania, Philadelphia, August 1979.
 WHOR Whorf, B.
 L.
, Language, Thought and Reality.
 The MIT Press, Cambridge, Massachusetts, 1979, cl956.
 5.
0 REFERENCES BADL Badler, S.
 J.
, Smoliar, S.
 W.
.
 "Digital Representation of Hunan Movement," Computing Sur\eys.
 Vol.
 11, No.
 1, March 1979.
 BART Barthes, Roland, Elements of Semiologv, Layers, Smith (trans.
).
 Hill and Wang, New York.
, 1968, cl964 Elements de Setniologie.
 BILL Billings, M.
P.
, Yucker, W.
 R.
, "The Computerized Anatomical Man (CAM) Model," SASACR134043, MDCG4655, CUT: NAS913228, Issue 23, 197071.
 BROTV Brown, M.
 D.
, Smoliar, S.
 W.
, "A Graphic Editor for Labanotation," Computer Graphics, Vol.
 10, No.
 2, Suomer 1976.
 CASN Camap, Rudolph, Introduction to Symbolic Logic and Its Applications, Meyer, W.
 H.
 , Wlllcinsotv J.
 (trans.
), Dover Publications, Inc.
, New York, 1958, C1954 Einfubrung in die symbolische loglk.
 Springer.
 CHER Cherry, Colin, On Hunan Communication, MIT Press, Cambridge, Massachusetts, 1980, cl957.
 DNOT The Dance Notation Bureau, Courses and Programs, New York, 1980.
 HUTC Hutchinson, A.
, Labanotation, Theather Arts Books, New York, 1977.
 LAEN Laban, R.
, The Language of Movement: A Guide to Choreutics, Plays, Inc.
, Boston, 1974, cl941.
 LYON Lyons, J.
, Semantics, Cambridge University Press, Cambridge, 1977.
 OTTE Otten, K.
, "Basis for a Science of Information," Information Science: Search for Identity, Debons, A.
 (ed.
).
 Marcel Decker, New York, 1974.
 POTT Potter, T.
 E.
, Willmert, K.
 D.
, "ThreeDimensional Display Model," Office of Naval Research, July 1975.
 SAVA Savage, G.
 J.
, Officer, J.
 M.
, "CHOREO: An Interactive Computer Model for Dance," International Journal of Man Machine Studies, Vol.
 10, 1978.
 SHAN Shannon, C.
 , U'eaver, U.
 , The Mather.
atical Theory of Communication, University of Illinois 58 WHAT CAN PHILOSOPHY CONTRIBUTE TO THE STUDY OF NATURAL LANGUAGE PROCESSING? Martin Rlagle Computer Science Department Vassar College Poughkeepsle, NY 12601 For the past twenty years philosophers have observed the development of research in natural language processing (NLP) and have offered periodic critiques of both its methods and its goals.
 (See BarHillel, 1964; Matson, 1976; Dreyfus, 1978; Searle, 1980; and Odell, 1981.
) Much of the criticism has proven to be valuable and artificial intelligence workers such as Winograd (1980) and Woods (1981) have acknowledged the positive influence of philosophical input to their work.
 A great deal of philosophical criticism of natural language processing (and of artificial intelligence in general) however, rests, on misconceptions about the actual goals and claims of this research.
 This is partly due to the fact that NLP workers have not explicitly established a set of methods and aims for their work; it is also due to the fact that there are actually a number of different goals which motivate NLP research.
 The purpose of this paper is to spell out the different objectives in the field of natural language processing in order to identify the places where philosophical criticism is legitimate and useful as well as those areas where it Is inappropriate.
 Hopefully, this analysis will be valuable to philosophers and AI workers alike.
 Research in natural language processing can easily be misconstrued to be a concerted effort towards a single goal.
 In the simplest terms, this goal would be the Implementation of a system whose linguistic powers matched those of a literate, native user of a natural language such as English or French.
 In fact, however, research In natural language processing is a loose amalgam of projects aimed at a variety of goals.
 Even though common research requirements exist, such as the development of techniques for parsing.
 Inference, memory organization, and so forth, presuppositions, methodologies, and criteria of success differ in significant ways from one project to the next.
 It is somewhat misleading, therefore, to appraise or to criticize the theoretical foundations of natural language processing as a single enterprise.
 Yet some philosophers (e.
g.
, Odell, 1981) have assumed that the principal goal of NLP is the unified goal just mentioned, and have proceeded to question the plausibility of the research on that ground alone.
 Consider the following formulations of the aims of natural language processing research: (from one natural language to another) or stylistically acceptable prose.
 3.
 To design systems which will permit the user to Initiate and direct a dialogue.
 In natural language, in a particular topic domain, with the latitude and fluency available in ordinary human dialogue.
 4.
 To design systems which will persuasively exhibit the full range of human linguistic abilities, such as reading, translating, paraphrasing.
 Interrogating, conversing, and so on.
 5.
 To design systems which are able to use and understand natural language in precisely the same way that people do.
 6.
 To design systems whose workings provide us with an explanatory model of the structures and processes responsible for human language use and understanding.
 The first four formulations involve pragmatic goals, the fifth represents an epistemologlcal goal, and the sixth an explanatory goal.
 The vast majority of efforts in natural language processing fall into the category of pragmatic goals.
 (See Waltz, 1982 for descriptive surveys of recent NLP projects.
) Most, in fact, are examples of the first or Type 1, goal.
 Systems such as LIFER (Hendrix, 1977), ROBOT (Harris, 1979) and LUNAR (Woods, Kaplan, and NashWeber, 1972), for Instance, provide natural language frontends which are used principally for database query.
 The research alms which motivate the construction of these systems (and others like them) are relatively modest insofar as the use of natural language is constrained by topic, vocabulary, syntactic breadth and user dialogue goals.
 The Type 2 goal is slightly more ambitious, since the analysis, generation, or translation of text may require a system to deal with a broad range of topics, a large vocabulary, complex syntactic constructions, and the intentions of an author (or reader) which may be less than obvious.
 Progress towards this goal has not been as substantial as progress towards the first goal, but there are programs which can analyze and paraphrase text (DeJong, 1982), produce modest translations from one natural language to another (Wilks, 1973) and generate moderately smooth English prose from an internal semantic representation (Mann & Moore, 1981).
 1.
 To design systems which will allow a user to perform some traditional operation(s) on a computer (such as database query) without thereby requiring the user to learn an artificial language or a set of formal constraints which must be applied to the use of natural language.
 2.
 To design systems which will be capable of processing textual material in order to produce accurate summaries, reliable translations.
 Serious efforts towards the Type 3 goal are very few in number and have appeared only within the past five years.
 Systems In this category include SRI's TDUS (Robinson, 1980) and BBN's HWIM (Bruce, 1982).
 Neither these, nor other systems of this sort, have achieved a level of combined reliability and efficiency which would make them suitable for broad implementation.
 However, there has recently been 59 a great deal of actenclon curned cowards this area and a greater effort to achieve this goal can be expected In the near future.
 The Type 4 goal is one which has been popularized in science fiction and the lay press, but it is not cited by AI researchers as the rationale for any serious NLP programming effort.
 This is not to say, of course, Chat Al workers have not entertained the idea of such a goal as a backdrop for their activities.
 In the proper perspective, such a goal is analogous to the one which underlies physics (and the natural sciences) namely, the eventual discovery of all lawful relationships among natural objects.
 Physics, after all, is dedicated to the objective of ultimately explaining the universe in terms of quantitative laws.
 One does not, however, invoke this goal as the aim of any particular research project.
 Moreover, it would be absurd to try to criticize a particular line of research in physics by attempting to show that this longrange goal is untenable.
 Even if the universe is not ulcimacely knowable in Cerms of Che principles of physics, the encerprise sclll provides us wich an everincreasing underscanding of nacural phenomena.
 The same holds true for research in natural language processing: Even if Che longrange goal is unattainable and that remains to be shown this does not affect the plausibility of the other three pragmatic goals nor does it invalidate the knowledge of natural language processing derived from programs designed Co achieve those goals.
 The fifth goal raises a completely different set of questions.
 Here we are concerned with Che status of Che performance rather chan wlCh Che performance icself.
 In Che case of pragmatic goals, the cricerion of success is Che degree to which a syscem is able Co deal effectively with linguistic input (or output).
 The phrase "deal effectively with" may be interpreted differently for different applicacions, but In general It implies chac Che syscaa is able Co carry out a function which would involve use and understanding of naCural language if performed by a human.
 The claim Is not made, however, chat the system actually uses or understands natural language itself.
 He can appreciate Che poinc of this last statement by considering the following question: Can the pragmatic goals be pursued without pursuing the episcemologlcal.
 goal as well? Some AI researchers would undoubtedly say 'yes' in answer to this question and would poinc to the success of nacural language interfaces such as Che one used in MYCIN (Shorcllffe, 1976), which are noC generally characterized as "language understanding" syscems.
 Cauclous researchers, such as Winograd (1973) and Leicner (1977) have emphasized Che epistemological limitations of their programs by putting the word "understand" in quotation marks when using it to refer to their natural language systems.
 Other researchers, however, freely speak of Cheir programs as nacural language undersCanders.
 Schank and Rlesbeck, for example, go one step furcher and argue chat natural language programs must be directed cowards genuine understanding: Computer programs that attempt to replicate understanding without simulating the human understanding process are doomed to failure when it comes to very complex processes.
 Nowhere has this been clearer Chan in natural language processing (Schank & Rlesbeck, 1981, p.
 2).
 The point that Schank and Rlesbeck make is a crucial one.
 If we are concerned with a Type 1 pragmatic goal, then genuine undersCandlng is probably superfluous.
 A Type 1 incerface can be limlced Co such a welldefined area of naCural language Chat we can design syscems Co "deal effecdvely with" the range of anticipated linguistic input by means of deterministic production rules, discrimination nets, or similar mechods.
 But if we are interested in Type 2, 3, or 4 pragmatic goals, then we must accept the fact that the potential for novelty, diversity, and deviant usage of linguistic inputs may be so great Chat a system would be effecclve under such condlcions only 1£ IC were able Co process Che meanings of Chose inpucs.
 And chis implies Chac ic muse be able Co genuinely underscand natural language.
 IC follows, Chen, Chac while Che Type 5 goal may be Irrelevant to the majority of pragmatic systems of the present (and recent past), it is essentially related to the development of the more ambitious pragmatic systems of the future.
 It is in this context that philosophical evaluations of natural language processing become relevant: by analyzing the conceptual requirements of genuine language understanding, the philosopher can illuminate the theoretical conditions which an NLP system muse meec.
 Moreover, unless Chese condlcions are met, the epistemological goal cannot be achieved and thus the more ambitious pragmatic goals cannot be realized.
 Whether or not AI workers explicitly view the Type 5 goal as a motivating force in their research, cherefore, Chey must acknowledge its indirect relevance if they intend to pursue a Type 2, 3, or 4 pragmatic goal.
 The Type 6 goal is one which has drawn a great deal of attention in artificial intelligence due to statements such as the following: We consider the theory and model of semantic nets to be a computational theory of superficial verbal understanding in humans (Slmnons, 1973, p.
 63).
 .
 .
 .
Cw]e shall describe a model of human language understanding that forms the basis for a set of computer programs.
 .
 .
(Schank, 1973, p.
 187).
 Both of these statements were published nearly ten years ago and since then there has been a considerable change in the claims made for the psychological significance of AI programs.
 Nevertheless, some AI researchers (especially members of Che Yale Group) sclll view Che explanaCory goal (Type 6) as a primary one, and some philosophers (e.
g.
, T.
 Simon, 1979) scill find Che view Co be worchy of criciclsm.
 An argumenc Co demonscrace the relevance of the Type 6 goal to the rest of natural language processing might go something like this: Genuine understanding is necessary for any natural language understanding systen capable of achieving Type 2, 3, or 4 pragmatic goals.
 Genuine understanding can be achieved only by processing language in the same way that humans process language.
 A system which does things in the same way as humans do them can serve as a model for explaining human language processing.
 Therefore: Pursuit of goal Types 2  5 entails pursuit of goal Type 6.
 There are, however, several problems with such an argument.
 The second premise asserts a "processproduce" identity relation which is very 60 much open to dispute.
 There are numerous instances (e.
g.
, the synthesis of urea) where an artificial process results in a substance, event, or function which is identical to a natural substance, event, or function in every respect save its mode of origin.
 It has yet to be shown that a cognitive ability, such as the understanding of natural language, can be produced only by employing exactly the same processes and structures which are involved in numan language understandiitg.
 Indeed, it has yet to be conclusively shown that all human beings understand language by means of exactly the same processes and structures.
 However, even if we accept the second praaise under some interpretation of the phrase "in the same way" the conclusion still does not follow.
 A program for natural language processing is not, itself, an explanation of anything.
 In order to be viewed as explanatory, the details of a program its variables and data structures, its control structures, and so on must be interpreted with respect to human processes and structures.
 Any program can be legitimately interpreted in a variety of ways, few of which will bear any relation to the concerns of human psychology.
 The explanatory value of a natural language program, therefore, is not inherent in the program itself but arises, rather, from the use which can be made of it by someone who is concerned with cognitive modeling.
 The use of AI programs to theorize about human language processes, in fact, is not AI research at all.
 It is a tool of cognitive psychology or, if one prefers, a methodological heuristic for a multidisciplinary investigation of phenomena such as discourse comprehension, text comprehension, and so forth.
 It does not follow, therefore, that research in natural language processing entails explanatory goals of Type 6; consequently, philosophical objections to AI programs as theories of human language abilities are irrelevant to the plausibility of AI research in natural language.
 Of all the types of goals ascribed to natural language research, then, philosophical evaluation is directly pertinent only to the epistemological goal formulated as Type 3, above.
 More specifically, the only valid judgment philosophy can provide is one which says that "the concept of natural language understanding entails X, hence a system must (be, do or have) X or it will not be capable of natural language understanding.
" The only valid objection philosophy can make to natural language processing is that "a computer, in principle, cannot (be, do or have) X.
" REFERENCES BarHlllel, Y.
 "The Present State of Automatic Translation of Language.
" In F.
 L.
 Alt (ed) Advances In Computers, New York, Academic Press, 1964.
 Bruce, B.
 C.
 "Natural Communication Between Person and Computer.
" In Lehnert & Ringle, pp.
 5588.
 De Jong, G.
 "An Overview of the FRUMP System.
" In Lehnert & Ringle, pp.
 149176.
 Dreyfus, H.
 WHAT COMPUTERS CAN'T DO, Revised Edition, New York, Harper & Row, 1978.
 Hendrlx, G.
 "The LIFER Manual," SRI Technical Note No.
 138, 1977.
 Lehnert, W.
 & Ringle, M.
 (eds) STRATEGIES FOR NATURAL LANGUAGE PROCESSING, Hillsdale, NJ, LEA, Inc.
, 1982.
 Leltner, H.
 "The Determination and Conceptual Structuring of Restricted Domains of Discourse for 'Intelligent' Interactive Systems," SIGART Newsletter, 1977, 61: 5152.
 Mann, W.
 C.
 & Moore, J.
 A.
 "Computer Generation of Multiparagraph English Text," American Journal of Computational Linguistics, 1981, 7: 1729.
 Matson, W.
 SENTIENCE, Berkeley, California, University of California Press, 1976.
 Odell, S.
 J.
 "Are Natural Language Interfaces Possible?" IBM Systems Research Technical Report TR73024, 1981.
 Robinson, A.
 "Understanding Natural Language Utterances in Dialogs About Tasks," SRI Technical Note No.
 210, 1980.
 Schank, R.
 "Identification of Conceptualizations Underlying Natural Language.
" In Schank & Colby, pp.
 187247.
 Schank, R.
 & Colby, K.
 (eds) COMPUTERS MODELS OF THOUGHT AND LANGUAGE, San Francisco, W.
H.
 Freeman, 1973.
 Schank, R.
 & Rlesbeck, C.
, INSIDE COMPUTER UNDERSTANDING, Hillsdale, NJ, LEA, Inc.
, 1981.
 Searle, J.
 "Minds, Brains, and Programs," The Behavioral and Brain Sciences, 1980, 3: 417457.
 Shortliffe, E.
 H.
 COMPUTERBASED MEDICAL CONSULTATIONS: MYCIN, New York, North Holland, 1976.
 Simmons, R.
 "Semantic Networks: Their Computation and Use for Understanding English Sentences.
" In Schank & Colby, pp.
 63113.
 Simon, T.
 W.
 "Philosophical Objections to Programs as Theories.
" In M.
 Ringle (ed) PHILOSOPHICAL PERSPECTIVES IN ARTIFICIAL INTELLIGENCE, New Jersey, Humanities Press, 1979.
 Waltz, D.
 "The State of the Art in Natural Language Processing.
" In Lehnert & Ringle, pp.
 332.
 Wilks, Y.
 "An Artificial Approach to Machine Translation.
" In Schank 5.
 Colby, pp.
 114151.
 Winograd, T.
 "A Procedural Model of Language Understanding.
" In Schank & Colby, pp.
 152186.
 Winograd, T.
 "What Does it Mean to Understand Language?," Cognitive Science, 1980, 4: 209241.
 Woods, W.
, Kaplan, R.
 & NashWeber, B.
 "The Lunar Sciences Natural Language Information System: Final Report," BEN Report No.
 2378, 1972.
 Harris, L.
 "Experience with ROBOT in Twelve Commercial Natural Language Database Query Applications," IJCAI Proceedings, 1979, 6: 365368.
 61 RECOGNIZING HUMOR IN NEWSPAPER CARTOONS BY RESOLVING AMBIGUITIES THROUGH PRAGMATICS Lawrtnea Mazlaok No»Mi M.
 Paz ABSTRACT Ntwspapcr cartoons can araphicallr display tht rasults of aabiauity in human sketch.
 Thi result can be unexptcttd and Punny.
 Captiontd cartoons dtrlwt thtir huaor froa a sudd*n inconaruitr which can bt aadt to follow by a huaan btina who can autowatically us* stortd world Knowltdso to rasolv/t tho aabiauous situation.
 LiKtwisor coMFUtar analysis of natural lanauaai stateaents also ntcds to succtssfully rtsolv* aabiauous situations.
 Coaputcrizad undarstandina of dialoaua that taKas Place bttween hunans must not only include syntactical and semantical analysiSt but also praamatical analysis.
 Praaaatics consists of an undcrstandina of the spcaKar's intantionsr the context of the utterance^ and social laplications of polit* huaan comnunication.
 Coaputer techniques have already developed been use restricted world Knowledge in resoluin* aabiauous lansuaae use.
 This paper illustrates how these techniques can be used in resoluina aaoiauous situations arisina in cartoons.
 1.
 THE GENERAL ROLE OF PRAGMATICS IN NATURAL LANGUAGE UNDERSTANDING u of lana One def Charles can be between fall in and sym to sian can on actual 1 1 thin uaae int 10 Morr chara s lan to th bols.
 s tha Ir b y use linauisti use can be n of praaa IS (1346) cterized b s and thei rcc classe Praaaatic t are indi e underst d.
 c theor called aties IS tha y the r huaan s: ico s rela ces bee ood wh Y.
 th* study praaaatics.
 developed by t praaaatics relationship us*rs.
 Sians ns.
 indices.
 tes directly ause indices en they are The aeanina of indices can be found by describtna rules for relating the sian to a context.
 These are praaaatic rules which are in essence "action" rules for •findina* relationships.
 Th* set of structures developed for desoribina th*s* rul*s »Tt callad praaaatiesemantie "trees" and divide into three cateaories: 1.
 Perforaatives  which describe the speaker's intention or aoal in usina a s*nt*ne* as a ^uastiont a eoaaandr *tc.
 2.
 Presuppositions  assuaptions about the context that are necessary to maKe that sentence verifiable.
 or appropriate, or both.
 3.
 Conversational Postulates  a class of presuppositions concernina the nature of human dialoaue which can be referred to as discourse codes of conduct.
 (Sates.
1976) For semanticpraamatic structures to 0Perat*> it is not enouah to deteraine th* meanina of individual words.
 Other types of information must be accessed.
 In order to select between comp*tina mcaninast Knowledae is required about the aramaatical funotions represented by particular word orders in the natural lanauaae sentence.
 Also.
 Knowledae about the "real world" (presuppositions) is needed; i.
e.
.
 the context in which the utterance tooK place.
 Alona wi seaanticpraaa account for "s Speech acts aoal.
 They can stateaent.
 at associated «ea Mjst be unde account for th reader of the double "aeanin th contextual Knawl*<l8*> a tic structure needs to peech acts" (performatives).
 deaonstrate the speaker's be a conaandf a <«uestion.
 a c.
 In other words.
 the nina and the iaplied action rstood.
 The theory must e fact that the listener or stateaent understands this a".
 (Bates.
 1376) Next.
 the seaanticpraaaatic structure aust explain the speaker's ability to understand sequences of lanauaae which should mean on* thina but clearly mean another (conversational postulates).
 It is assumed that normal human beinas who enter into a have aareed to be cooperative, speakers will tell each other that they will only offer assuaed to be new and relevant listener.
 and will only conversation This means the truth.
 inforaation to the request information which they sineerclr want.
 This represents a s*t of standard rules.
 D*wiatian* froa this 'code of conduct* will b* s**n as uiolations.
 2.
 SUPPLYING PRAGMATICS ANALYSIS FOR COMPUTER Th* systeas technique analysis lanauaae.
 described illustrat used to d character and those manmachi These car re are sev*ral <*u*s that make use s for includin in understandin As these tec a cartoon will be e how praaaatic ana isambiauate the s s that correspond t that correspond to ne dialoaue will b toons *T9 found in tion answerina of various a praaaatic a natural hni^ues are analyzed to lysis could be ituation.
 The 0 th* coaputer a huaan in a e identified.
 the Appendix.
 2.
1 COOPERATIVE DIALOGUE The COOP System (Kaplan.
 1373) is a •Question answerina data base system that Follows the "codes of conduct" presented earlier.
 Its objective is to provide cooperative responses from a natural lanauaae data base luery.
 Some examples from this system follow.
 COOP IS able to determine from a 62 ^utstton not onlr uhat inPornation is re^uiPtd.
 I.
e.
 the direct.
 literal, and correct responser but also that the •Questioner is unaware of hiahly pertinent facts not exFlicitl/ requested in the question.
 A heuristic used br the lyttem is Knouledae of such facts frt^uently maKes asKina the Question unnecessary.
 because the/ entail an answer.
 The system action is to isnore the question and provide the pertinent fact.
 For example: Question: Hou many students CSEllO m Sprina, 77? failed System's answer isl siuen in Sprina '77.
 CSEllO was not The answer of "zero" would not c ooperatiue.
 haue been The user who posed the aboue question presumed that the CSEllO class uas tauaht in the Sprina of 1977.
 The system on fmdina that this presumption uas false responds with a "correotlue indirect response" by supplying the nesated presumption.
 Cartoons often lead to funny results when their statements are ambiauous.
 In the cartoon TIGER (appendix, fia.
 1) there is an example of a eooperatiue response in the answer to the question: "Did he catch him?".
 Prior to this question the human in the dialoaue only Knous there is a chase aoina on and that there are two participants: Stripe and Mrs.
 ParKer's cat.
 The situation is ambiauous because we do not Know who is chasina whom.
 Here the common human presumption is doas usually chase cats and therefore Stripe must be a doa.
 The computer system on findina this presumption to be false.
 could respond with a corrective indirect response: "Nope.
 Stripe aot auav" rather than with the direct answer of "no"The computer on realiiina the possible ambiauous situation could then respond: 1) Pido is mr doa's name.
 OR 2) 'Computer* is my name.
 Z.
2 RESTRICTED DOMAIN OF DISCOURSE Another data base system.
 ROBOT (Harris.
 1978).
 uses the data base itself to find the use of words in the question.
 to build expectations.
 and to resolve ambiauities.
 The system interprets input based on what maKes sense within its limited world model, the data base.
 In processina ambiauous statements.
 several interpretations may arise.
 A heuristic used is unintentional interpretations of input questions are usually not false for the specific domain.
 but have a vacuous response (Coles.
 1972).
 To use this heuristic these interpretations are POsed to the data base as queries.
 If all interpretations fail to find a response to the question, then the answer is "there aren't any".
 This negative answer assumes that the dialoaue will only be about information contained in the data base.
 If more than one interpretation can be answered successfully, then the system enters into a clarification dialoaue.
 just as humans would haue to do when faced with an ambiauous question.
 If exactly one interpretation that is found.
 then the system responds usina this interpretation for the question.
 In the cartoon GARFIELD (appendix.
 fia.
 3) the human speaKer is asKina (jarfield to Play with Nermal.
 The followina ambiauous situation is created: 1> "Play with Nermal" means that Nermal is a toy An the COsuaaesti the "cod for an informat followu IS to ch quest ion answer t the foe aspect 1iKely t other OP sy ve in es of answ ion li p 4ues anae t and o the us ch of th o shif t ype stem direc condu er Rely t ion.
 he f to r or lai anaed e qu t in of CO rePl t re ct to to be A he ocus espon nal q Th est 10 a fol operati les wi sponse.
 it is contain reque ur 1st ic of th d with uestion e f ocu n whic 1OWUP ue response th is a Fol lowina appropriate relevant sted in a used here e oriainal a direct .
 but with is that IS most question.
 The BC carl could haue used response.
 In this (the human) is subject (the presumption here census taKer will name.
 The compute amblauous situ question: "Namci focus is analyzed seen as two quest oon (append a suaaest cartoon, a asKina que computer) .
 IS the first asK IS t r needs to tion creat Please" If the questi 1 ons : IX.
 fia.
 2) lue indirect census taKer stions of a A common question the he subject ' s realize the ed by the a chanae of on could be IS your (subject's) name.
 2) Mhat IS rour doa's name, please? 1) Mhat Please'' OR 2) "Play with Nermal" means that Nermal and Garfield should Play toaether.
 The computer system could resolve this ambiauous situation by searchina Toy and Friend domains for the entry Nermal.
 On not findina Nermal in the Toy domain but in the Friend domain the ambiauous situation IS resolved.
 The LIFER System (Hendrix.
 1378) has capabilities for extending the natural lanauaae subset that is understood by the system.
 Users may employ easytounderstand notions such as synonyms and paraphrases to extend the lanauaae.
 The users can than asK questions about information contained in the data base usina their own natural lanauaae "style".
 In this war "utterances" by the SPeaKer (user) can be understood by the listener (computer).
 In the cartoon WIZARD OF ID (appendix, fia.
 4) the human is statina to the Sire (computer) that "our records show there is a dip in unemployment" and is perhaps implying the question "what do we do next?".
 The ambiauous situation here is 63 that "a di^" could dtscnbt tithtr a Foolish ptrson or a dounuard irtnd in a statistic or Fiaurt.
 To r»»olw» this ambiauous situation the human could haut tnterid tht ^araphrasi: "DiF in un»(«Ploym*nt" ii a paraFhra«» of "temrorar/ diclini in tht uneMPloymcnt statistic".
 2.
3 UORLO KNOWLEDGE MITH FRAMES OR SCRIPTS humorous interpretation is th» untxptcttd ont.
 Throuah the use of praamatic anal/siir humorous interpretations can be rccosnizcd as ucll as aeneratvd.
 Many other s/stems uorld Knowledae and inForm the dialoaue uith a user script.
 Frames.
 simply niahly structured sets praamatics.
 Mhen an action some canonical description the frame that uill permit reconstruct the context in tooK Place.
 Frames carr subsequent statements and i»arK anaphora or presuppo proaram to slots in the c frames that will resolue t haue included ation related to in a frame or putr are Just for Keeping is carried out.
 IS stored in the proaram to which the event y ouer to the conventions that stion link the urrent or past he reference.
 Frames not only include syntactic information, ea.
 subject.
 object.
 prepositional phrases, but also semantic and praamatic facts uhich provide various reasons, motivations and purposes not explicitly stated.
 Scripts are liKe frames in that they also have empty slots that are filled uith the context from a dialoaue or text.
 Houever.
 scripts provid* uorld Knowleds* about coaaon aMPeritnces or situations in terms of SchanK's conceptual dtpcndanoy primitives.
 A text Is undtrstood br •appina sentences into actions or primitive acts as described in tht script.
 Unstated facts described in a soript but not in the sentence are assuatd to be true.
 This providts a 'bacKaround' or world Knoultdst for undtrstandina and reasonina.
 (Sehank 1975).
 The BEETLE (appendix, fia.
 5) cartoon can be used to illustrate the frame and the script concepts.
 Here the relative pronoun must be resolved in the Phrase "that aun".
 The two possibilities are: 1) shoot at that as a taraat • un.
 use that aun 2) use that aun to shoot with and shoot at the oriamal taraet.
 The aabiauous situation can be resolved by usina world Knowledae about taraet practice.
 For example.
 it is helpful to Know that taraets should not bt expensive, useful thinas.
 i.
e.
 a aun.
 and that a taraet is not located near a human beina.
 This type of information can be provided by demons in the case of frames or by the reason or aoals statement in tht case of scripts.
 2.
4 RECOGNITION OF HUMOR Humor due to ambiauous statements re«iuires the reader to recoanize that an ambiauous interpretation has occurred.
 The 64 SUMMARY Cartoons can araphica the humor due to ambiauit speech.
 It w\mr be possible humorous ambiauities us exisiina techniques.
 Three 1 use of praamatics have been first IS to resolve doubl restrictina the domain o eliminatina the occurrence mtanina.
 This dtviot is tapl in rtstriotina tht lanauasa by rtstriotina tht obJtots i to only thost that apptar bast.
 lly represent les in human to recoanize ina already evels of the described.
 The c meanina by f discourse.
 of double oytd by LIFER and by ROBOT n the doaain In tht data Tht stcond Itvtl of the use of praaaatios involves maKina the doaain laratr rathtr than restrictina it.
 Frames and scripts are used to involve more world Knowledae in the natural lanauaae analysis so as to disaabiauate based on what is common occurrences in a aiwen situation.
 The third level involves an ability to daduce from coaplex frames and scripts a Purpose and then actina in aareeaent with that purpose.
 COOP is capable of dtttraina the ^utstiontr's motiut.
 and if necessary, posma for itself a ^utstion aort in Ktepina with tht ^utstiontr's aotivt than the oriainal ^utstion.
 Praamatic dtvicts ustd ineludt proscribina conttxt, tnlaraina context.
 and dtducina motivation from conttxt.
 REFERENCES Barr, A.
 1980.
 'Natural Undtrstandina".
 AI Maaazint No.
 1, Sprina.
 Batts.
 E.
 1976.
 Lanauaat and Co Acquisition of Praaaatics.
 Press.
 New YorK.
 Intelliaence: Can Computer Thin Fraser Publishina Co.
 San Fr Coles.
 L.
S.
 1972.
 "Syntax Interpretation of Natural La Representation and Meanina: with Information Processin H.
A.
 Simon and L.
 SiKlos 44SSi Elsin.
 S.
H.
 1979.
 Mhat Is Li 2nd ed.
, PrentloeHal1, Inc.
 Cliffs.
 NJ.
 Goldstein.
 I.
 and Papert "Artificial Intelliaence.
 La the Study of Knowledae".
 MIT 337, March.
 GrosZf B.
 1960.
 "Utterance and Issues in Natural Communication".
 AI Maaazine.
 1.
 Sprina.
 Harris.
 L.
R.
 197B.
 "Usina the Itself as a Semantic Compone in the Parsina of Natural La Base Queries"' Dartmouth C 772.
 October.
 Hendrix.
 G.
.
 Sacerdoti.
 E.
.
 Saaalowiez, D.
.
 and Slocum.
 J.
 1978.
 OeveloPina a natural lanauaae interface to complex data.
 ACM transactions of database Lanauaae Uol.
 1.
 ntext: Tht Acadtaie K?.
 Boyd & ancisco.
 Directed nauaae", in Experiments a Systems.
 sy (eds.
) nauistics?.
 , Enalewood S.
 197S.
 nauaae and AI Memo.
 Objective: Lanauaae Vol.
 1 No.
 Data Basf nt to Aid nauaae Data olleae, TR frsttMS Kaplan.
 S froa a base disstrt infor«a penns/l nazlacK, L in napp onto Da Se^ttatt SehanKr R Episode Undersi Science (eds.
).
 3: 105147.
 1979.
 CO Portable nat ^uery ation dept 11 on sot ene uania.
 •J.
 1979.
 " ina Natural ta Base Sr%x er.
 •G.
 1975.
 s in Meaori'" andina Stud O.
G.
 Bobr Acadeaic Pr operative responses ural lanauaae data s/ste*.
 doctoral of computer and e> untuersitr of Sone Considerations Lanauaaes Queries eas* UorKina Paper.
 "The Structure of • Representation and les in Coanitiwe ow and A.
 Collins ess> Neu York.
 Siklossy.
L.
 and Siaon.
 H.
A.
 197Z.
 "Some Semantic Methods for Lansuaae tn Representation and MeaninaC Expennents uith Information Proccssina S/stems.
 H.
A.
 Simon and L.
 SiKloss)' (eds.
) 44SS.
 SiKloss)'.
 L.
 1978.
 impertinent ^uestionansuenna systems; justification and theory.
 ACtI proccedinas annual conference Uashinsr d.
c.
 vol 1 3944.
 Ualtz> d julyr 1979.
 an enalish lanauaac question answerina system for a larae relational database.
 CACtI uol 21 no 7, 526539.
 APPEHDIX t I I • 1>JCVJ!WMAT " • ^ ACHATE! .
 ,^ CKC! ~cC • .
7 ' ^OTAiNiAV ftjT'^J^^ FIGURE 1 V.
K.
.
.
30? .
.
 (̂  CQS^ C:gN^U6.
 j ZOYoirJi'Bn rxŷ ff̂ .
  W FIGURE 2 r î i'? .
'.
; .
  .
: L£A?;.
: R£PHRASE THAT "• '^' • 5 : '  • 5 FIGURE 3 65 w I z A o p I 0 A Clf IN ^ F'VP Ml/.
', ^VT X " ^ FIGURE 4 y; (S003' NC'.
V \ SV S<00'S3 I «,*WT MOWS TM« W»ACTIC5, BNc, Sll?.
 X WiTThS TACS5T <AT.
 =̂ ̂'J^rc^M .
viiiz: FIGURE 5 DEFAULTS REVISITH) oc "Tell me if you're guessing.
" Jane Terry Nutter Canputer Science Department SUNY at Buffalo Buffalo, New York This paper discusses default reasoning, distinguishing generalizations associated vdth defaults from both universals and statistical generalizations.
 I argue that conclusions based on defaults should be reported differently frcm conclusions which do not involve default reasoning, and that however we represent than, the related inference system must distinguish default claims from other propositions and treat than differently.
 IVo existing analyses of default reascxung are briefly criticized in light of the distinctions presented.
 1.
 intcoductian.
 A great deal of knowledge seems to take the form of generalizations: neither genuine universals, true of all things in their understood domains, nor simple statistical claims of "more than half", but claims which, although understood sometimes to fail, nevertheless warrant presumptions in the absence of conflicting information.
 Such generalizations are usually represented by defaults.
 Ihis paper examines default generalizations, distinguishing them from universals and statistical claims, and pointing out some pitfalls their implementation presents.
 Especially, it behoves us to realize that answers based on default reasoning represent educated gueses; and however useful they may be, guesses cannot safely or honestly be handed out as facts.
 2.
 gsneraliationa vs.
 universal and atatistical In English, "all" rarely means "every single thing without exception", and failing to note this can produce unfortunate results [2].
 Tb use Btachman's example, if we say that all elephants are fourlegged gray mamnals, and if we treat "all" as indicating genuine universality, then we have no way to talk about Clyde the unfortunate amputee elephant with only three legs.
 But suppose we always treat "all" as indicating a generalization Qyde the threelegged elephant, but unfortunately we can talk with equal ease about Clyde the nonmammalian elefdiant, or even about Clyde the nonelephant Indian ele{*iant.
 Generalizations cannot be treated like statistical claims either, although the difference here is more subtle.
 Most people realize that over half the population is female.
 Yet in the absence of information concerning a person's sex, one does not typically presune that the person in question is female (indeed, the presumption tends to go the other way!).
 By contrast, the nimber of flightless birds (emus, ostriches, kiwis, penguins, baby birds, etc.
) is hardly negligible.
 Yet we feel justified in assuming of birds in general that they fly.
 Generalizations usually represent causal claims, albeit masked and incomplete ones.
 Most birds fly, because the features which distinguish something as a bird evolved to facilitate flight.
 By contrast, statistical claims are pvidence for, rather than embody, causal claims.
 Furthermore, we accept statistical evidence as supporting causal claims only when there is independent reason to suppose that the phenomena involved are relevant to one another.
 For example, I recall reading sanewhere that for many years, the manbership rolls of a baker's union in New York City precisely paralleled the births and deaths in a town in India.
 Whether this actually happened is not important here; my point is, it could well happen, and if it did, no reasonable person would take it as anything more than a striking (and somewhat humorous) coincidence.
 The transitivity of inferences based on generalizations again distinguishes them from statistical claims.
 Presumability can be inherited through truthf motional inferences; but statistical relationships are far more complex, and statistical inferaices follow utterly different rules.
 For instance, consider the result of conjoining two statistical claims S and fil.
 Say the probability of fi is i, and that of 5i is x.
 Now what is the probability of S & S'? Well, let's look at seme examples.
 Suppose the subject is coin tossing.
 Say £ says "TOSS 1 will be heads," and SL says "TOss 2 will be tails.
" Thai i = y = .
5, and the probability of "Tbss 1 will be heads and toss 2 will be tails" we know to be .
25, or x^.
 But is this alvays the case? Qearly not.
 Let a be as before, and let SL be "Toss 1 will be tails.
" Now the jxobability of S & S' is 0.
 If a is the same as SL, then the probability of the conjunction is the same as the probability of a.
 Furthermore, statistical analyses tend to be applied to two fundamentally different sorts of situation.
 In the first kind, the various events are r»x hypnt.
hesi independent of one another.
 We assume that the result of toss 1 does not affect the result of toss 2.
 In the second, a causal relationship is being sought or presumed.
 At this point, probabilities become inextricably linked to the theoretical context, and in some sense take on a different meaning.
 Given one set of results fi, the probability of fi will differ depending on the hypothesis relative to which it is computed.
 More importantly, what changes tends to be not the probabilities of individual occurrences, but precisely the probabilities of cooccurrences: that is, the probability of conjunctions changes, without that of the conjuncts changing.
 So no general rule captures the way the probability of a conjunction relates to the probability of the conjuncts.
 3.
 ExamplPfi of default assumptions.
 Suppose we are designing a "travel agent" system.
 Ihe classical example of a default rule in this context is the assumption that, all else being equal, all trips originate wherever the customer currently is.
 This seems reasonable enough, but the system need hardly assume it, since it can request that information with no great loss of convenience.
 67 But consider the following "rule": within the departure time limits the customer supplies, more direct connections cire to be preferred over less direct ones.
 If someone says, "I'd like a round trip to New York," for the system then to ask, "Where are you leaving frcm?" seems reasonable; for it to ask, "Would you rather get there in one hour or nineteen and a half?" does not.
 Furthermore, imagine a system which mindlessly produced every set of connections fran Buffalo to New York — direct, via Albany, via (Houston, via Seattle, via London, via Buenos Aires.
.
.
.
 While the list might not go on forever, it will surely go on long enough to prove inconvenient.
 Some presunption must be made to order the alternatives so that reasonable ones get listed early.
 Yet we cannot simply add a universal rule that direct routes are to be preferred over indirect ones, because it isn't always true.
 Foe exan^e, some people refuse to use certain airlines or airports under any circumstances.
 Others will want to stop over for a few hours in seme intermediate city.
 There is also a more general problem.
 All else being equal, the cheaper of two routes is usually preferred over the more expensive.
 While the more direct route is usually also the cheaper, it is not always so.
 One can currently fly from Buffalo direct to Albany, tAiich is shorter and more direct than changing flights in New York City.
 But it turns out that flying via New York is cheaper.
 Whether the customer wants to fly direct or via New York City will now depend on which is more important to the custaner, convenient time scheduling or low price.
 Hence the system cannot presune absolutely either that the more direct route is pre£ecred, or that the cheaper route is.
 A guarded answer whidi presunes either, but with explicit reservations, will prove more useful than either a flat presunption which cannot be overruled (a universal) or a failure to make any presunption at all.
 Other exasples abound.
 If a customer asks to travel from New York to Cincinnati via Athens, we want the system to recognize that the custcmer probably means Athens, Ohio, and not Athens, Greece, or even Athens, Georgia.
 At the same time, this assunption should somehow be reflected in the system's response, lest travellers who mean to go to Athens, Georgia learn of Athens, Oiio by finding themselves there.
 4.
 Problfflns defaults raise.
 Perhaps the most common kind of default takes the form, "In the absence evidence that "p, you may infer p" [7,8].
 When the system is asked "p?" and finds the default rule, it attaints to derive 'p.
 If it fails to do so, it returns p as the answer.
 Hence systans augmented by this kind of rule can take advantage of generalizations of the kind above.
 So far, so good.
 But this procedure only looks reasonable so long as we deal with questions like "Can Poger the bird fly?" Then, saying "Of course, he's a bird," seans unobjectionable — but only because nothing depends on the answer.
 Notice that if we don't care what the answers to our questions are, there is little reason to implement defaults.
 After all, if we don't care, we can as well say "I don't know" as either yes or no.
 But suppose that we do care what answer we get.
 For instance, consider a medical diagnostic and treatmentreoomnending system.
 Suppose that for a particular set of symptoms, treatment Ji is generally very beneficial, but that in the exceptional cases treatment & invariably kills.
 Now if A has the symptoms in question, surely we do not want to recommend treatment i solely on the grounds that we don't yet know that A is exceptional.
 On the other hand, if the symptoms in question can themselves prove fatal, nor do we want to say we don't kncM anything about what to do for h.
 In this kind of case, we would like the system to say something like, "Treatment x naiMiiy helps," or "Prpfiimably treatment ;i helps.
" Even better would be an answer which directly tells the user what the counterindications are; but at the very least, a responsible system should warn the user that the information results fran a prpaimpfinn.
 and not an inference.
 Once the systan has issued the warning, the user can then pursue it in further questions.
 A further difficulty with defaults lies in deciding what it means for than to be true or false.
 Qearly "If Roger is a bird, then presumably Roger can fly" can be true even if Roger is a bird, but Roger can not fly.
 Indeed, "Presumably Roger can fly" can be true, even though "Roger can fly" is false.
 That is the whole point of saying 'presunably': it protects the speaker from saying something false when the facts go the "wrong" way.
 That is what it means to give a guarded response.
 Hence the truth value of defaults cannot be a simple function of the truth values of their component propositions: default operators are not truth fiActu.
onal.
 Furthermore, defaults make sense because they reflect causal (and henoe nonlogical) connections among their constituents.
 The missing information Tiaranit^a that their content cannot be a simple function of the contents of the components.
 But then we should not expect to be able to give a purely logical account of defaults [41.
 5.
 Prtablana with two goBPsed solutions.
 Several approaches to defaults have besi suggested.
 Some researchers treat defaults as modalized [6,7,8].
 Several problems with this approach have been pointed out already (see e.
g.
 [3]).
 In addition, this approach interprets "In general, birds fly" as something like "If ̂  is a bird and it is ocmpatible with what we know that x flies, then x.
 flies" [7].
 But this is only true if every single bird without exception which we do not know to be flightless does in fact fly.
 That is, if McOermott's version of the generalization is true, it can never be the case that seme bird does not fly and we can not prove that it doesn't.
 But this is surely not what the generalization means.
 The fuzzy logic approach [1,5,9,10] uses a continuum of truth values in the closed range <0,1> instead of sijiply "true" and "false".
 Several questions imnediately arise.
 First, every "assertion" in the data base must have an associatied truth value; where are we to get these from? Second, how are the tjruth values of propositions related to those of their components, and how are the truth values of conclusions related to those of the premises of the demonstration in question? Preliminary results [1] boil down to the msurprising claim that the conclusions are no better than the pranises, but also on the whole no worse (where "better" is interpreted as numerical "greater than").
 It is significant that this is already nontrivial to establish.
 Third, how do we deal with the apparent result that different demonstrations of the same proposition "establish" different truth values? But the largest problem, in my opinion, lies in the irresistible temptation to view these fuzzy truth values as probabilities.
 This tendency is encouraged by the need to assign what, in context, look much like Bayesian prior probabilities to the 68 propositions in the data base.
 Sone kind of Bayesian analysis may prove useful in A.
I.
 systenis; but there is no "cutrate" way of doing it.
 Neither fuzzy logic nor default reasoning adequately analyzes probability.
 Under the circumstances, it seems best to avoid a system which mislecxte to this extent.
 6.
 Conci,uaion.
 We would like some way to deal with the "fmny' truth status of default rules and of conclusions drawn on the basis of default asstmptions; but neither modality nor fuzzy truth values seems to capture the desired effect.
 Furthermore, there seems good reason to siqjpose that no purely logical analysis could.
 But this does not rule out the possibility that logical restrictions on defaults and their consequences can be found and described, on the basis of which a system of inferences allowing default reasoning can be developed.
 We are currently developing a semantics for default reasoning which treats defaults as propositional operators and which we hope will provide such a basis.
 Once this has been done, we can hope to deal with defaults in a reasonable and useful way.
 Hence an A.
 I.
 system which deals with defaults successfully must also have at least two properties which existing proposals lack.
 First, it must delineate the logical restrictions on defaults and their consequences without ruling out the existence of genuine exceptions, i.
e.
, recognizing that default reasoning scmetimes gives the wrong answer.
 In doing so, it should be careful to distinguish default generalizations both from genuine universals and from statistical generalizations.
 And second, when the system gives answers which eire based on default reascming, it should aoknit this weakness by issuing warnings with them.
 For without such warnings, default reasoning by any scheme is not only unsound: it is also unsafe.
 8.
 AcKnnwlpdgnieata^ I would like to thank Stuart Shapiro and the members of the SNePS Research Group at SUNY/Buffalo for their many helpful conments and suggestions.
 8.
 Refprencps.
 [1] Aronson, A.
R.
, Jacobs, B.
E.
, and Minker, J.
 A note on fuzzy deduction.
 JACM v.
 27 (1980) 5996(23.
 [2] Brachman, R.
J.
 "I lied about the trees" or defaults and definitions in knowledge representation.
 Draft (1982)• [3] Davis, M.
 Tlie mathematics of nonmonotonic reasoning.
 A.
I.
 v.
 13 (1980) 7380.
 [4] Israel, D.
J.
 What's wrong with nonmonotonic logic? Proc.
 Firs* Annial National Conference on Artifiriai TnfpUiqpncy.
 American Association for Artificial InteUigence (1980) 99101.
 [5] Lee, R.
C.
T.
 Fuzzy logic and the resolution principle.
 J a m v.
 19 (1972) 109U9.
 [6] McDermott, D.
V.
 and Doyle, J.
 Nonmonotonic logic I.
 A.
I.
 V.
 13 (1980) 4172.
 [71 McDermott, D.
 Nonmonotonic logic II.
 JSOi V.
 29 (1982) 3357.
 [8] Reiter, R.
 A logic foe default reasoning.
 A.
1^ V.
 13 (1980) 81132.
 [9] Zadeh, L.
A.
 Fuzzy sets.
 inf.
 Control v.
 8 (1965) 338353.
 [10] Zadeh, L.
A.
 Fuzzy algocittms.
 Tnf.
 Control V.
 12 (1968) 92102.
 69 PRAGMATIC FACTORS IN P R O N O U N REFERENCE ASSIGNMENT Valerie C.
 Abbott and John B.
 Black CognitlTe Science P r o g r a m Yale UniTersity, N e w Haven, C T 06620 Identifying factors that influence pronoun reference assignment is a challenge to anyone attempting to characterize the process of language understanding.
 Because a pronoun itself carries only a small part of the meaning that the understander is expected to assign to it, he or she must use contextual information to assign the pronoun an unambiguous referent.
 Characterizing aspects of the context which are used for thb purpose is an active area of psychological research.
 Many recent studies have considered the role of syntactic context, that is, the effect of structural constraints on pronoun reference in a fragment of text, typically a sentence, without recourse to constraints which might be found in the meaning of the text (Langacker, 1969; Sheldon, 1974).
 Shwartz (1981) has found evidence for the use of syntactic information in the resolution of anaphoric pronouns in single sentences.
 However, strategies based only on syntax are not sufncient to determine unambiguously the referent of all pronouns.
 Consequently, investigators have examined the role of semantic factors within sentences in directing the assignment of referents (Caramazza, Grober, Garvey, & Yates, 1977; Caramazza and Gupta, 1979; EhrUch, 1080).
 The studies reported here will focus on the use of pragmatic constraints in resolving anaphoric pronouns.
 Hirst and Brill (1080) have found that these constraints influence the time needed to assign a referent even when that referent can be unambiguously determined by syntactic rules alone.
 T h b result indicates that pragmatic context can be expected to play a significant role in reference assignment.
 However, the text fragments used in their study were only two sentences long, and the nature of the pragmatic considerations involved were not specified.
 It remains to be determined whether there are identifiable cues in longer texts which influence reference assignment of anaphoric pronouns.
 W e will be concerned with characterizing two major sources of contextual information in paragraphlength texts, and evaluating their influence on pronominal reference assignment.
 First, the presence of a clear main character may be expected to play a role in reference assignment.
 Black, Turner, and Bower (1979) have shown that the point of view provided by a main character has an observable effect on story understanding.
 In the extreme case, there may be only one character in a story.
 W h e n there is more than one character, it is still likely that the main character is given primary consideration for reference assignment.
 This was investigated in the current experiment.
 Second, Scfaank and Abelson (1977) have suggested that the goals and social roles of characters in stories may contribute to reference assignment.
 If an act is appropriate to a particular goal or role and the agent of the act is specified by a pronoun, it is likely that the pronoun will be disambiguated to the character who has the appropriate goal or role.
 Since the goab the characters in a story are pursuing, the roles they are filling, and the identity of the main character can be experimentally manipulated, we can test whether these contextual cues influence pronoun reference assignment.
 In the experiments reported below we first test whether subjects are sensitive to these cues alone and in combination in a task requiring explicit pronoun reference assignment.
 Second, in a task in which reading times for lines of text containing pronouns were measured, it was determined whether these sources of pragmatic constraint influenced the difficulty of reference assignment as measured by reading time.
 Experiment I: Explicit Aaaignment Four simple twocharacter stories were written.
 Each story contained an anaphoric pronoun in the final sentence.
 Either character could be made the main character of the story, or each character might be weighted equally.
 Additionally, each character was given a role or a goal in the story.
 Preceding the clause in which the critical pronoun appeared was a phrase containing an action appropriate to the role or goal of one character or other, or an action which was equally likely to have been performed by either of the characters.
 For instance, in "Brushing off a table, she smiled at her friend.
" the action preceding the pronoun b consbtent with the role of a waitress.
 Note that in sentences of thb sort, the subject of the main clause b interpreted as the agent of the action in the preceding phrase.
 Combination of these cues yields five presentation conditions.
 • The main character and goal or role cue are both present and indicate the same referent.
 • The main character and goal or role cue are both present and indicate conflicting referents.
 • Only the main character cue b present.
 • Only the goal or role cue b present.
 • Neither cue b present.
 Each subject was presented with two stories of the type described above, one in each of two conditions.
 Following each story on a separate page was a multiple choice question requiring identification of the character to w h o m the anaphoric pronoun referred.
 The results of thb experiment are summarized in Tigure 1 below.
 W h e n main character and role or goal cues led to assigning the same character as referent, pronoun reference was determined in accord with both by 8 4 % of the subjects, a significant difference from chance (X^ = 10.
72, £ < .
01).
 T h b shows that main character and role and goal manipulations are powerful enough to influence pronoun assignment when used together.
 In the case in which neither main character nor the phrase preceding the pronoun provided a cue concerning pronoun reference, subjects chose both characters almost equally often as the referent of the pronoun, 4 6 % of the subjects choosing one and 5 4 % choosing the other (x^ = 0.
12, ns).
 W h e n the phrase preceding the pronoun was neutral with respect to the roles or goab of both characters in the stories, but there was a main character, 70 this character was adopted as the referent of the pronouD by 8 2 % (x^ = 9.
02, £ < 01) of the subjects.
 This is essentially the same level of performance as was observed with both sources of information avaiable to the subjects.
 However, when both characters were given equal weighting in the story, but the phrase preceding the pronoun was appropriate to the role or goal of one character, the referents chosen were consistent with this character for only 6 2 % (x'̂  = 107, ns) of the subjects.
 This pattern of results seems to indicate that subjects are not making extensive use of information about the relationship between an action the agent of which b speciHed by a pronoun, and the known goals and roles of characters, in assigning the pronoun a referent.
 However, this interpretation is complicated by the results of the condition in which subjects had to make a choice between an assignment to the main character of the passage, or to another character with the role or goal appropriate to the action preceding the pronoun.
 In this situation, subjects chose the assignment which agreed with the main character 3 8 % of the time, and chose the assignment which agreed with the role or goal context 6 2 % of the time.
 Although this result is not signiHcantly different from chance (x = 107, ns), a difference in the opposite direction would be expected if only main character cues were influencing the choice.
 This result indicates that although a character's goal or role is not always sufficient to influence pronoun assignment alone, it is important when seen in combination with other information.
 The difference between the choice of I CHOICE I I CONSISTENT I INCONSISTENT I CONDITION I WITH CUE(S) I WITH CUE(S) I BOTH CUES I (CONSISTENT)I MAIN CHAR I CUE ONLY I 84 10 82 18 GOAL OR ROLE I CUE ONLY I 82 38 BOTH CUES* I (CONFLICT) I 82 38 neither" I CUE I 54 46 * consistent = consistent with goal or role cue consistency arbitrarily determined Figure 1: Subjects' choice of pronoun referents in percent.
 referent in this condition and in the condition in which main character identity is the only cue available is significant (x^ = 15.
47, £ < .
001).
 The utility of main character information thus seems to be dependent on the absence of conflicting information.
 The results of the this experiment indicate that the extent to which subjects chose one referent or the other was governed by the contextual cues manipulated.
 The main character of the story was most effective in innuencing reference assignment, with consistency of the pronoun's context with the goal or role of a character effective in nullifying this main character effect.
 It is conceivable that in this experiment asking explicitly about the referent of a pronoun altered subjects' responses.
 Thus, it seemed desirable to obtain another measure of the difficulty of assigning referents to anaphoric pronouns in the same texts.
 In the following experiment reading times for the sentences of these texts containing anaphoric pronouns were measured.
 It was expected that reading times would be fastest for pronouns in the condition in which there was a main character, and the phrase preceding the pronoun was appropriate to the role or goal of that character.
 Reading times should increase as it becomes increasingly difflcult to assign a referent unambiguously to a pronoun.
 Experiment IL Reading Tlma Materiab were the four stories used above and six additional stories of the same type written for this study.
 Each story could appear in any of the Ave conditions discussed above.
 The penultimate line of the story contained the action which was consistent with the role or goal of one character or the other, or with either.
 The final line of each story was constant over conditions and contained an anaphoric pronoun.
 Each subject read the 10 stories, two in each of the five conditions.
 They were instructed to read the stories for comprehension.
 Each story was presented one line at a time on a computer terminal, subjects pressing the "Return" key when they had finished reading each line.
 Reading times for the final line of the story were compared between conditions.
 24001 23001 READING I X 2383 TIME IN MSEC 2200! 2100! 1 X 20001 2033 BOTH 1 BOTH (CONFLICT) X 2020 MAIN CHAR ONLY X 2154 X 2104 GOAL OR NEITHER ROLE CUE ONLY PRESENT TYPE OF CUE(S) PRESENT Figure 2: Reading times for a clause containing an anaphoric pronoun The results for the five conditions are presented in Figure 2.
 The reading time data is quite consistent the data seen in Experiment I above.
 A comparison between the condition in which both cues are present and lead to the same choice of referent and that in which both cues are present but lead to conflicting choices shows faster reading times in the former condition (F = 4.
805 ̂  = 0.
033).
 Having only one cue in the form of a main character leads to almost identical reading times as having both cues and results in significantly faster 71 reading times than the confusing condition (F = 9.
487 £ =s 0.
005).
 However, although there is a trend, having only the cue of consistency with the goal or role of a character does not lead to significantly faster reading times than the confusing condition (F = 3.
022 g = 0.
080).
 The condition in which neither main character nor consistency with a goal provided a cue as to the reference of the pronoun is a puzzle.
 Although it is not significantly faster than the confusing condition (F = 1.
325 2 == 0.
258), it is also not significantly slower than the condition in which both cues are available (F = 0.
527 ĝ  = 0.
480), the condition in which only the main character is available (F = 0.
608 £ = 0.
448), or the condition in which only consistency with a goal or role is available as a cue (F = 0.
148 £ = 0.
705).
 One possible explanation is that subjects are fairly quick to realize that they have no information with which to make a decision, and proceed in hopes of obtaining the information they need in the remainder of the text.
 In other words, in the confusing condition, enough information is available, so an attempt is made to find the referent.
 This proves difficult, leading to increased reading times for such sentences.
 In the absence of relevant information, the attempt at resolution is deferred.
 The results of these two experiments show the influence on pronoun reference assignment of manipulation of pragmatic aspects of the text in which they appear.
 The main character of the text, in the absence of disconfirming evidence, is quickly and reliably assigned as the reference of these pronouns.
 They also point out that the influence of some possible pragmatic cues cannot be characterized simply.
 For example, if the action of an agent represented in the text by a pronoun b consistent with the role or goal of a character, this is not sufHcient to lead reliably to assignment of that character to the pronoun.
 However, the influence of this cue is substantial enough to lead to confusion if there is other evidence indicating another character as the referent.
 Additionally, it cannot be assumed that the less information available for pronoun reference assignment, the longer it will take subjects to read the sentence in which it appears.
 From the results of experiment 11 we can see that subjects proceed rather quickly when they have no information on which to base their choice.
 References Black, J.
 B.
, Turner, T.
 J.
, & Bower, G.
 H.
 Point of view in narrative comprehension, memory, and production.
 Journal of Verbal Learning and Vetinil Behavior, 1070, 18, 187108.
 Caramazza, A.
 & Gupta, S.
 The roles of topicalization, parallel function and verb semantics in the interpretation of pronouns.
 Linguistics, 1870, 17, 407518.
 Caramazza, A.
, Grober, E.
, Garvey, C.
 & Yates, J.
 Comprehension of anaphoric pronouns.
 Journal of VerlMl Learning and Verbal Behavior, 1077, 16, 601600.
 Ehrlich, K.
 Comprehension of pronouns.
 Quarterly Journal of Experimental Psychology, 1080, 32, 247256.
 Hirst, W.
, ft Brill, G.
 A.
 Contextual aspects of pronoun assignment.
 Journal of Verbal Learning and Verbal Behavior, 1080, 19, 168175.
 Langacker, R.
 On pronominalization and the chain of command.
 In D.
 Reibel, S.
 Schane (Ed.
), M o d e m Studies in English, Englewood Cliffs: PrenticeHaU, 1060.
 Schank, R.
C.
, and Abelson, R.
P.
 Scripts, Plans, Goals, and Understanding.
 Hillsdale, NJ: Lawrence Erlbaum Associates, 1077.
 Sheldon, A.
 The role of parallel function in the acquisition of relative clauses in English.
 Journal of Verbal Learning and Verbal Behavior, 1074, IS, 272281.
 Shwartz, S.
 The search for pronominal referents.
 Technical Report 10, Cognitive Science Program, Yale University, 1081.
 Aeknowledgmenta We are grateful to RoweU Huesmann for sponsoring this paper, and to Wendy Lehnert and Larry Bimbaum for helpful discussions regarding the research reported here.
 This research was supported by grants from the Systems Development Foundation and the Sloan Foundation.
 72 Topic and Comment in Spoken Sentence Comprehension Hans Brunner University of Indiana Chomsky (1965) has defined the Topic of a sentence as "the leftmost UP immediately dominated by S in the surface structure" and Comment as, quite simply, "the rest of the string".
 Others have either defined or used these two concepts to denote, among other things, the distinction between (1) "new" information and information that has already been conveyed (e.
g.
, Clark & Haviland, 1977), (2) the notions of "psychological subject" and "psychological predicate" (e.
g.
, Hornby, 1972), or (3) the "current" vs.
 "presupposed" information of a sentence (e.
g.
, Halliday, 1967).
 Differing interpretations abound and, in the words of deBeaugrande (1980), "it has remained unclear precisely what phenomenon we are dealing with".
 The purpose of this research was to investigate the roles of "topic" and "comment" in different semantic and syntactic contexts.
 To do this we used the gating paradigm, a procedure in which spoken sentences are repeatedly presented to subjects, the amount of spectral information from each constituent word being gradually increased with each successive repetition.
 In the first presentation of each sentence, the spectral gate size (i.
e.
, duration from the onset) of each word was only 50 msecs.
 The remainder of each word was replaced with envelopeshaped noise, a procedure which eliminates the spectral information while preserving prosodic fluctuations in the intensity of the speech.
 Each target sentence was repeated 10 times, the gate sizes being increased in 50 msec increments across repetitions.
 Subjects were instructed to simply write down whatever they could understand after each presentation of the sentence.
 The dependent measure of interest was the amount of spectral information (i.
e.
, the "gate size") necessary for comprehension of each word in the sentence.
 This technique was applied to the current issue by transforming the syntax of simple, declarative sentences so as to vary the topicalization of subject and object nouns from one sentence version to the next.
 Our syntactic transformations, taken from a study by Hornby (1972) are shown below: (i)The farmer plowed the field.
 (2)The field was plowed by the farmer.
 (3)It was the farmer who plowed the field.
 (4)It was the field that the farmer plowed.
 (5)The one who plowed the field was the farmer.
 (6)lVhat the farmer plowed was the field.
 Hornby (1972) showed that agent of a sentence serves as the topic when presented in syntactic structures with a cleft object (sentence 4), pseudocleft object (6) or in active sentences (1) and as the comment when presented either in passive sentences (2) or in sentences with cleft (3) or pseudocleft (5) agents.
 The object takes on a complementary role, being part of the comment where the agent is topicalized, and vice versa.
 The topic of each of of each syntactic form has been underlined, above, according to this criterion.
 In this study we capitalized on this exchange of roles so that, when comparing the overall effects of topic vs.
 comment status, we would be comparing each word against different tokens of itself.
 Armchair theorists have been asserting for some time now that the topic of a sentence (1) receives less intonational stress (i.
e.
, lower amplitude and FO and a shorter duration) in production and (2) is somehow prerequisite for correct interpretation of the comment.
 If this is true, then comprehension of any given word should require less spectral information when it functions as topic than when it is stretched out in time as part of the comment on what has been topicalized.
 Moreover, if the functionalist approach is correct, then there should be a wellordered interaction between topicalization and syntax, with agents requiring a smaller minimal gate size in active sentences and sentences with cleft and pseudocleft objects, where they are topicalized, than in the remaining three syntactic forms, where they are part of the comment.
 And once again, the converse should obtain for the object of each sentence.
 Neither of these predictions was supported by the results: The amount of spectral information necessary for word recognition did not decrease as a function of increasing topicalization.
 Moreover, there was a significant main effect of syntax (F( 5 , 270)=«26.
18), resulting from an increase in the amount of spectral information necessary for word recognition as the syntax of sentences became more complex.
 These results should not be construed as evidence against the functionalist approach to sentence comprehension.
 Our sentences were presented out of context, in the absence of any larger text or dialogue fraimework.
 Thus, it is doubtful that the topicalized words in these stimuli really represented anything akin to "given" or "presupposed" information for the subjects.
 Nonetheless, these results do serve to constrain some of the notions that have been advanced about the nature of topic and comment in the processing and structure of language.
 They make if quite clear that "topic" and "comment" are textual, rather than syntactic or structuralist concepts.
 Thus, any effort to define these constructs without reference to intersentential relations simply misses the purpose of topicalization in realtime processing.
 However, the results also demonstrate that it is important not to lose sight of syntactic effects in text processing.
 The syntactic constraints of these sentences did much more than just control the focus of attention; they had profound, topdown effects on the overall speed of identification as well.
 The current results are only the first in a series of experiments on this issue.
 In this talk, I will also discuss the effects of similar manipulations on materials presented in various textual frameworks.
 73 ONLESfE PROCESSING OF P R A G M A T I C ITvfFERENCES CoUeen M.
 Seifert, Scott P.
 Robertson, and John B.
 Black Cognitive Science Prognun Yale University Cognitive science researchers have proposed a wide variety of inferences and inference mechanisms that may be used in comprehending stories.
 Inferences are concepts, or links between concepts, which are not explicitly stated in a text but which are present in the final memory representation.
 Many previous psychological experiments on inferences have been unable to distinguish between inferences that are generated during comprehension (online) and those that are constructed later (for example, during summarization or question answering).
 The experiments presented here contrast four types of pragmatic inferences to determine whether they are usually generated online.
 Pragmatic inferences are a class of inferences that result from the application of world knowledge to information in a text.
 Knowledge structures typically employed in the production of pragmatic inferences (especially for narratives) are goal structures, planning mechanbms, and scripts (Schank & Abelson, 1077; Wilensky, 1078).
 A number of psychological experiments have demonstrated the use of individual schematic structures in producing pragmatic inferences (e.
g.
 Bower, Black & Turner, 1070; Graesser, Gordon, & Sawyer, 1070; Smith &.
 Collins, 1081), but have not shown the online operation of a combination of knowledge structures involved in pragmatic inference generation.
 In the two studies discussed here, we will present evidence that 1) knowledgebased inferences about goab, plans, and actions are made daring reading and 2) inferences about consequent or associated states of the world are not made during reading.
 W e will also give indirect evidence for online forward inferencing of plans from goals.
 Knowledge of goals and plans organizes otherwise disconnected text elements, and thus it is important that they be inferred early in the comprehension process (Owens, Bower, & Black, 1070; Smith & Collins, 1081).
 Lower level inference types, like story actions, are used to nil in information specified by already active schemata (Bower, Black & Turner, 1070).
 State information, however, while potentially inferable, is not predicted to be generated aa part of the comprehension process.
 There is considerable evidence that physical states that are antecedents or consequences of actions are not a central part of narrative representations (Black, 1080; Graesser, 1081; Kemper, 1082; Lehnert, Robertson, & Black, in press; Robertson, Lehnert, & Black, 1081).
 For example, when someone sits down in a restaurant, information about the position of tables and chairs is not typically accessed.
 To test for online inferences of the speciHed types, w e measured subjects' reading times for target sentences which required a pragmatic inference for coherence.
 In the Hrst experiment we wrote sixteen short (17 line) stories each containing a goal, a plan for achieving that 74 goal, a set of connected actions, and associated states.
 Eight of the stories were «cnp< based (e.
g.
 going to a restaurant, going to the movies), the other eight were plan bated (e.
g.
 robbing a store, getting directions).
 Each story included infereneeatatementa which explicitly described the goal, the plan, an act, and a state.
 Following each of these statements was an eightsyllable targetgtatement which required the preceding information to be inferred if it was not already present in memory.
 For example, sentence 2 when read alone requires that the goal stated in sentence 1 be inferred; sentence 3 requires an inference of the plan stated in sentence 2; sentence 6 may require an action inference (sentence 4) but not a state inference (sentence S).
 (Our stories were not as compact as this example suggests.
) 1.
 John was hungry.
 2.
 John hurried to a restaurant.
 3.
 John ordered the special dinner.
 4.
 The waitress brou^t the food.
 5.
 John had silverware.
 S.
 John ate his meal in a hurry.
 Targetstatements (e.
g.
 sentence 3) were presented with their associated inferencestatements (e.
g.
 sentence 2) either present or absent.
 Each subject received stories with goal, plan, act, and state inferencestatements absent, but within any one story a subject had only one high level inference type (goal or plan) and one low level inference type (act or state) left oat.
 Subjects read the stories one line at a time from a C R T screen and their reading times for the targetstatements were recorded.
 It was assumed that inference generation would be evident in increased reading times for the targetstatements in the inferencestatement absent conditions.
 After the reading task and a short intervening task, the subjects were given a recognition test (17 scale) which included the inferencestatements.
 High recognition ratings for absent inferencestatements indicates the presence of the inferences in the final story representations.
 Table 1 shows the mean reading times for targetstatements and mean recognition ratings for inferencestatements of the different types in the present and absent conditions.
 The analysis of reading times showed that goal and action targets took longer to read when their inferencestatements were absent, but this was not the case for plans or states.
 Recognition results showed a specinc interaction in which states were not falsely recognized when they are left out of the stories while the other types of inferencestatements were.
 The reading time data and recognition data together support the view that goals and actions are inferred online whereas states are not.
 Plans proved problematic and were investigated further in a second experiment.
 Tjrpt of Inftrtne* Ttrj«t RT Inftranc* Abstnt Prtsant Inf*r«ne« RteognJtion lBf»rtne« Absant Prastnt Coil Plan SUt* Act • 1.
660 1.
626 1.
538 • 1.
595 1.
550 1.
601 1.
487 1.
448 4.
89 4.
95 » 3.
62 4.
75 5.
81 6.
09 5 82 S.
06 Table 1.
 Mean reading times (sec.
) and recognition ratings for the different inference types.
 Though the reading time difference for plans was not significant in the first experiment, the high recognition rating for absent plans suggests that they were inferred at some point.
 A closer look at the materials revealed a possible explanation: knowledge of the goals in stories where the plan inferencestatements were left out may have allowed subjects to infer the plans before their targetstatements were read.
 For example, knowledge of the goal "John was hungry," may lead to a prototypical plan expectation, i.
e.
 "going to a restaurant.
' If a prototypical plan is inferred when a goal in read, the presence or absence of the plan inferencestatement would not have made any difference.
 In a second experiment, prototypical plans in our materials were changed to less typical plans to minimize forward inferencing from the goals.
 In addition, some story titles were changed to decrease the chances of inferring a goal prior to reading the goal targetstatements.
 Also, action inferences were not included in the second experiment since this effect had already been clearly demonstrated.
 The results of the modified experiment are shown in Table 2.
 The reading time differences for goal and plan inferences increased and plans now became significant.
 W e again failed to fud evidence for online state inferences.
 The recognition data remained consistent with these results, showing a high false alarm rate for goals and plans, but not for states.
 Typt of Inftrtnet Goil Plan Stit* Tirgtt .
 RT Znftrtne* Absant • 1.
764 • 1.
720 1.
536 Prasant 1.
613 1.
626 1.
490 Infaranea RacognitioN Infaranea Absant 5.
28 5.
69 • 3.
97 Prasant 5.
94 6.
27 5.
56 Table 3.
 Mean reading times (sec.
) and recognition ratings for the different inference types.
 Taken together, these experiments support the view that some pragmatic inferences, specifically goals, plans, and actions, are made during reading while others, speciflcally low level states, are not.
 It is especially important to note that high level inferences about goals and plans are made online.
 This result is congruent with models of language comprehension that incorporate strong top down uses of pragmatic knowledge during understanding.
 Active goal and plan schemata serve during reading to organize otherwise disconnected concepts in the text.
 W e also obtained indirect evidence for online forward inferencing of prototypical plans from goals since we were only able to demonstrate that plans were inferred in a backward manner from plan inferencestatements when they were nonprototypical of an active goal.
 In terms of low level actions, the results support the view that script and plan completion inferences (remember that we had both scriptbased and planbased stories) found in the representation after reading are not reconstructed at test time, but are built during reading.
 O n the other hand, there was no evidence that inferences about states of the world occur during comprehension, even though we know that they are available after comprehension and even during comprehension in response to question probes (Graesser, 1081).
 Of course, some types of states may be very important and reliably inferred in some texts (Owens, Bower, & BLck, 1079); however, the theoretical claim is that low level states in general are inferred online less often than the other types of inferences studied.
 This T m e tuning* of data about the types of inferences made online provides important constraints on inference models.
 Since pragmatic inferences are probable rather than necessary, and since there is so much inferential material available at any given time from world knowledge, direct measures are needed to tell when inferences are made and which types are made.
 Although most models of language comprehension include an inferencing component, it is important to examine how different classes of knowledge are differentially utilized by the comprehension process.
 Ackaowledgmenta We are grateful to Arthur Graesser for sponsorship and to Brian Reiser for comments on this paper.
 This research was supported by grants from the Sloan Foundation and Systems Development Foundation.
 References Black, J.
 B.
 Memory for state and action information in narratives.
 Twenty Rrst Annual Meeting of the Psychonomic Society, St.
 Louis, Missouri, 1080.
 Bower, G.
 H.
, Black, J.
 B.
, & Turner, T.
 J.
 Scripts in memory for text.
 Cognitive Psychology, 1079, 11, 177220.
 Graesser, A.
 C.
 Prose Comprehension Beyond the Word.
 N e w York: SpringerVeriag New York, 1081.
 Graesser, A.
 C , Gordon, S.
 E.
, & Sawyer, J.
 D.
 Memory for typical and atypical actions in scripted activities: Test of a script pointer t tag hypothesis.
 Journal of Verinil Learning and Verbal Behavior, 1070, 18, 319332.
 Kemper, S.
 Filling in the missing links.
 Journal of Verbal Learning and Verbal Behavior, 1082, 21, 90107.
 Lehnert, W.
 G.
, Robertson, S.
 P.
, & Black, J.
 B.
 Memory interactions during question answering.
 In H.
 Mandel, N.
 L.
 Stein, & T.
 Trabasso (Eds.
) Learning and comprehension of text.
 Hillsdale, N.
J.
: Ablex, in press.
 75 Owens, J.
, Bower, G.
 H.
, & Black, J.
 B.
 The "soap opera" effect in story recall.
 Memory and Cognition, 1979, 7, 185191.
 Robertson, S.
 P.
, Lehnert, W .
 G.
, & Black, J.
 B.
 Alterations in memory for text by leading questions.
 Paper presented at the 1082 meeting of the American Educational Research Association, New York.
 Schank, R.
 C , & Abelson, R.
 P.
 Scripts, plans, goals, and understanding.
 Hillsdale, N.
J.
: Erlbaum, 1977.
 Wilensky, R.
 W h y John married Mary: Understanding stories involving recurring goals.
 Cognitive Science, 1978, a, 235268.
 76 Generation of Useful Problem Representations in a Semantically Rich Domain: The Example of Physics Joan I.
 Heller and F.
 Reif University of California, Berkeley The initial representation of a problem can crucially determine whether the subsequent search for its solution is easy, difficult, or even impossible.
 However, the processes used to generate initial problem representations, particularly in semantically rich domains, have been studied less extensively than those used for search.
 Accordingly, the study reported in this paper has aimed to formulate and test a model specifying how human problem solvers can generate effective initial descriptions of problems in a realistically complex scientific domain.
 The preceding goal, which is prescriptive, is more general than one concerned with naturalistic studies of actual experts (Chi, Feltovich, 5 Glaser, 1981; Larkin, McDermott, Simon, S Simon, 1980).
 In particular, it focuses interest on procedures for generating good problem representations, without necessarily trying to simulate the behavior of experts and without making the assumption that experts behave optimally.
 From this general point of view, models of good problem description may thus be suggested by purely theoretical analyses as well as by observations of experts.
 (Indeed, protocol observations of experts reveal relatively little about the processes used to generate initial problem representations since these processes are usually carried out rapidly and almost automatically on the basis of much tacit knowledge.
) A prescriptive point of view, transcending naturalistic studies of expert performance, is also centrally important for attempts to improve human performance or for educational applications.
 Indeed, in instructional applications, students can not merely be taught to mimic expert performance which often relies heavily on the recognition of patterns acquired as a result of years of experience.
 Our prescriptive interest has been specifically focused on human performance in generating effective problem descriptions.
 From a theoretical point of view, this emphasis allows us to presuppose complex human capabilities (such as naturallanguage understanding and patternrecognition skills) while focusing attention on the more sophisticated cognitive skills needed to generate good problem representations.
 Furthermore, our interest has been in developing experimental approaches which (unlike some forms of computer simulation) allow direct validation of models of good human performance in problem solving tasks.
 We chose to study the generation of problem descriptions in the particular domain of physics (especially within the subfield of mechanics) because this is a realistically complex domain representative of other quantitative sciences.
 On the other hand, this domain is sufficiently simple and welldefined that the generation of problem descriptions can be specified and studied in some detail.
 Model of Problem Description Our aim was to formulate a theoretical model specifying how a human problem solver can generate, for any problem in a particular scientific domain, a useful initial problem description facilitating the subsequent solution of the problem.
 This model decomposes the description process into two successive stages.
 The first stage uses mostly domainindependent knowledge to generate a problem description which summarizes and organizes relevant information about the specified situation and problem goal, introduces convenient symbolism, etc.
 Since the generation of this basic description is relatively straightforward, we shall not discuss it further here.
 The next stage of the description procedure is more complex and involves the generation of a "theoretical description" which deliberately redescribes the problem in terms of special concepts provided by the knowledge base for the relevant domain.
 All the principles in the knowledge base, which are expressed in terms of these special concepts, become thus readily accessible to facilitate the subsequent solution of the problem.
 The generation of the theoretical problem description is based on the following considerations.
 The knowledge base about any domain contains declarative knowledge specifying the particular entities of interest in this domain, the special concepts useful for describing these entities, and principles specifying relationships between these concepts.
 For example, in the scientific domain of mechanics, the entities of interest are particles or more complex systems consisting of such particles.
 The special descriptive concepts are special concepts used to describe motion (e.
g.
, "position", "velocity", "acceleration") and special concepts used to describe the interaction between particles (e.
g.
, "force", "potential energy",.
.
.
).
 The principles specifying relations between these concepts are "interaction laws" (which specify how the force on one particle by another is related to the properties and positions of these particles) and "motion principles" (which specify how temporal changes of concepts describing motion are related to concepts describing interaction).
 The preceding kinds of declarative knowledge in the knowledge base about a particular domain provide the basis for explicit "description rules" that specify procedures for generating a theoretical description of any situation in this domain.
 In particular, these description rules specify what particular kinds of entities should be described, what special concepts should be used to describe them, what properties of these concepts should be incorporated in the description, and what checks should be made to ensure that the resulting description is consistent with the principles in the knowledge base.
 For example, our model for generating a theoretical description in the particular scientific domain of mechanics contains explicit rules specifying that attention is to be focused on particles or certain systems of particles (e.
g.
, strings, solid objects, .
 .
 .
 ) .
 The motion of each such particle is then to be described by a diagram indicating available information about its position, its velocity, and its acceleration.
 Similarly, the interaction of each such particle is to be described by a diagram indicating available information about all forces on this particle by other particles (with an explicit algorithm specifying how all these forces are to be identified and enumerated).
 Finally, the resulting description is to be checked by assessing its consistency with known motion principles (e.
g.
, by checking that the acceleration of any particle has the same direction as the total force on it).
 The preceding description procedure,specified by the model, is expected to lead to initial problem descriptions with the following properties: 77 (1) The resulting descriptions should be considerably more explicit than those commonly generated by actual experts.
 (2) Strict adherence to the description procedure should avoid most of the errors commonly committed by novices (e.
g.
, omitting forces or introducing nonexistent extraneous forces).
 (3) The description procedure should lead to problem reformulations which are more readily interpretable (e.
g.
, questions about slack strings or touching objects are automatically reinterpreted as questions about forces).
 (4) The resulting theoretical problem descriptions should substantially facilitate the subsequent solutions of these problems.
 Experimental Methods and Results Our experimental approach for testing a prescriptive theoretical model of human performance has used the following paradigm: Design carefully controlled experimental conditions to induce individual human subjects to act in accordance with the model; then observe whether the resulting performance is effective in the predicted ways.
 To implement this paradigm, we have used "externalcontrol experiments" of the following kind.
 We first design a program of stepbystep directions, and associated knowledge, whereby a human subject can be guided to act in accordance with the model (e.
g.
.
 directions which implement the steps of the specified description procedure).
 These directions are problemindependent and at an appropriate level of detail to be reliably interpretable by the subject.
 In the actual experiments an individual human subject is then induced to carry out a task (e.
g.
, the description and subsequent solution of a problem) by executing the sequentially presented directions of the program implementing the model.
 In this process the subject is asked to talk out loud about his or her thought processes.
 The resulting protocol, consisting of the subject's transcribed verbal statements and written work, can then be analyzed in detail.
 Figure 1 shows the experimental results obtained by such externalcontrol experiments designed to test the proposed model for generating effective initial descriptions of mechanics problems.
 Each subject worked on three problems.
 Figure 1 shows the performance of these subjects in generating good descriptions of motions and of forces, as well as subsequently generating solutions with correct equations and correct answers.
 The following are the main results obtained in these experiments: (1) The proposed model for generating initial problem descriptions is sufficient to lead subjects to generate explicit descriptions that are complete and entirely correct.
 In turn, these descriptions greatly facilitate the subsequent problem solutions which are then almost flawless.
 (2) Although subjects in these experiments possess a good knowledge of basic physics concepts and principles, a knowledge sufficient to implement the individual directions contained in the model, this knowledge is not sufficient to lead to good descriptions.
 These results are apparent from the much poorer performance of subjects in a comparison group working without external control of the model.
 (3) The main features of the model are, in fact, necessary for good performance.
 These results follow from experiments where subjects worked under external control of a modified model that omits certain features of the proposed model (e.
g.
, that provides a direction to enumerate all forces, but does not provide more detailed directions specifying how to enumerate them).
 (4) The experimental data also verify certain detailed predictions of the model (e.
g.
, the avoidance or occurrence of particular kinds of errors).
 78 MEAN NUMSeR CORRECT 3 ? M 9uiatd by modx 14* guiOM By modidta inoati C compwiM" ("• juiooct) "• M* •• C motion dtscr (orco îuJiioin jrnirtft dOKr PERFORMANCE  100% go • 80  40  20 0 Figure 1.
 Results of externalcontrol experiments.
 Conclusions and Implications The work briefly outlined in the preceding paragraphs leads to the following main conclusions.
 The knowledge base for any scientifc domain implies guidelines specifying how to describe effectively any situation encountered in this domain.
 These guidelines can be expressed in terms of explicit rules prescribing how to generate a useful initial description of any problem in the domain.
 Prescriptive models of effective human performance can be usefully tested by externalcontrol experiments in which individual human subjects are deliberately induced to act in accordance with a model and the resulting performance is then observed in detail.
 The work described in the preceding paragraphs was specifically undertaken to formulate a model for generating effective initial descriptions of problems in the particular domain of mechanics.
 Externalcontrol experiments show that this model, when implemented by human subjects, is very successful in leading to good initial problem descriptions that facilitate the subsequent solutions of these problems.
 It should be noted that these experiments demonstrate the effectiveness of the specified description rules implemented by human subjects, but were not designed to teach description skills.
 (Indeed, such teaching would require that control knowledge, explicitly external in these experiments, be internalized by the subjects and made habitual.
) However, such a wellvalidated model for generating effective initial problem descriptions can be used as a basis of explicit instructional methods to teach students effective problemdescription skills and thereby enhance their problemsolving abilities.
 REFERENCES Chi, M.
T.
H.
.
 Feltovich, P.
J.
, § Glaser, R.
, Categorization and representation of physics problems by experts and novices.
 Cognitive Science, 1981, Ŝ, 121152.
 Larkin, J.
H.
, McDermott, J.
, Simon, D.
P.
, 5 Simon, H.
A.
, Models of competence in solving physics problems.
 Cognitive Science, 1980, 4, 317345.
 ANALOGICAL REASONING PATTERNS IN EXPERT PROBLEM SOLVING John Clement Physios Department University of Massachusetts Amherst, Mass.
 01003 Spontaneous analogies have been observed to play a significant role in the problen solutions of scientifically trained subjects [1,2].
 In some cases analogies can even lead to the construction of a new mental model for understanding a problem domain.
 This paper describes a number of different analogical reasoning patterns that have been observed In thinking aloud protocols from expert problem solvers.
 The purpose of the present study is to identify, classify, and label the critical subprocesses involved in such analogical solutions.
 In this study each of ten subjects were given a number of problems.
 Including the following one: (21 inrtftnTnim FIGURE 1 i TTff *̂ r "̂  r.
̂__ J: , k ( " 1 ^ •i jMiliains n« U ) UMUTIVE TlMVOOTITiaRJ SMri« inn I u m t m ago Ell M10I1M Ell DTnSIM KWi lUMO ITU uucc ittsul smil CA»IT1ES ctttmii ftvimsL^ nice rÊ njat OF MIMLEn IN >aifii« i v w GCKUTH IKTOVVOMIT CASE ro cawim amust dturiai GOCUnS W MM.
(KT c ro * "tvious *K«UBT I '0 ItWKKE UMXIISTAIVII4 Of CASE • U T W t CAH 'iciLjnre! COmHEWIK I IT ENHAACINS JSE OF nnSICAl mnjITlOB 0 CASES coviwQ MM.
ar.
1 •Eurion Spring Coils Problem A weight is hung on a spring.
 The original spring Is replaced with a spring made of the same kind of wire, with the same number of coils, but with coils that are twice as wide in diameter.
 Will the spring stretch from its natural length, more, less, or the same amount under the same weight? (Assume the mass of the spring is negligible compared to the mass of the weight.
) Why do you think so? Subjects were advanced doctoral students and professors in technical fields who had reputations for being creative problem solvers.
 Seven of the ten subjects generated spontaneous analogies in solving this problem.
 A spontaneous analogy occurs when the subject, without being prompted, shifts to consider a situation B which differs in a significant way from the original problem situation A, and then tries to apply findings from 8 to A.
 In solutions by analogy the two contexts being compared are often perceptually different but they are still seen to be functionally or structurally similar in some way.
 For example, five subjects attempted to relate the problem to the analogy of a bending rod, as in the transcript excerpt below taken from video tape.
 SI: (Draws bending rod in drawing G2B of fig.
2.
) Hy intuition about that [the rod] is that if you.
, doubled the length and hung some weight on it, that.
.
 it, would bend considerably further.
.
.
 it would seem that that means that um, in the original problem, the spring in picture 2 [the wider spring] is going to hang farther.
 Here SI generates an analogy by drawing the picture of an analogous problem involving bending rods instead of stretching springs.
 This analogy has in fact led him to the correct answer, and provides a plausible but only partial justification for it.
 Etc.
 I mvaitM VAvmim pprnim otsEwtp in Eiwtr n q a m s<n»irc Analysis of more complex expert protocols however.
 makes it apparent that analogical reasoning is not a simple, onestep process, but involves a niaaber of different processes, shown below.
 (PI) Generating the Analogy.
 Given the original conception A of an Incompletely understood situation.
 the analogous conception, B, is generated, or "comes to mind"; (P2) Confiraing the Analogy Relation.
 The analogy relation between A and B must be "confirmed"; (P3) Comprehending the Analogous Case.
 Conception B must become well understood, or at least predictive; (PU) Transferring Findings.
 The subject transfers conclusions or methods from B back to A.
 Table 1 The last three processes can occur in any order.
 Analogies are often proposed tentatively, and processes (P2) and (P3) especially, can be quite time consuming.
 We have also been somewhat surprised to find that there appear to be not one, but several ways of carrying out each of the above processes.
 Some of the most important of these subprocesses are shown in fig.
2.
 The figure provides a basic typology of analogical reasoning patterns that have been observed across different subjects.
 This paper gives an example and brief explanation of each pattern.
 ANALOGY GENERATION PROCESSES 79 Aaaoclative leaps.
 The subject using an associative leap J^ps to an analogous situation that differs in many ways fron the original problem.
 A second subject, S2, generated evidence for several associative leaps In the spring problem when he said: "I feel as though I'm reasoning in circles and I think I'll make a deliberate effort to break out of the circle somehow.
.
.
like rubber bands, molecules, polyesters.
.
" apparently attempting to link the problem to other situations he knew more about.
 A third subject, S3, compared the wide and narrow springs to two blocks of foam rubber, one made with large air bubbles and one made with small air bubbles in the foaa.
 He had a strong intuition that the foan with large air bubbles would be easier to compress, and this added some support to his conjecture that the wide spring would stretch more.
 Ue hypothesize that an associative leap takes place when an established conceptual framework for situation B in long term memory is activated by an association to some aspect of the original situation A.
 Evidence for an associative leap occurs when the subject shifts to consider a new situation B that is obviously familiar to him or refers to "being reminded o f or "recalling" B.
 Generative transformations.
 This second method of generating an analogy occurs when the subject modifies the original problem rather than recalling a different analogous situation from memory.
 In other words, the subject transforms the problem by changing an aspect of it which was previously assiaed to be fixed.
 For example, S2 refers to the rod as an "unwound spring".
 In this case the unwinding of the spring is considered a transformation because the subject is modifying a feature of the spring (Its shape) that would ordinarily be held fixed in the problem.
 It is hypothesized that a generative transformation occurs when the subject focuses on an internal representation of the existing problem situation A in working memory and changes an aspect of it to create a new but closely related situation B Thus a generative transformation usually leads to the construction of a new situation B rather than activating an already constructed framework in long term memory.
 This subject also generated another analogy via a transformation below while thinking about moving the weight along the spring wire: S2: Hmnmi, what if I imagined moving the weight along the spring? Now what if I recoiled the spring and made the spring twice as long.
.
.
instead of twice as wide?.
.
.
uhhh.
.
it seems to me pretty clear that the spring that's twice as long is going to stretch more.
 The analogy to the thought experiment of comparing springs of different lengths suggests to him that a wider spring may stretch more than a narrow spring.
 Notice that the analogy was generated from the rather playful transformation of sliding the weight up and do%ni along the spring wire.
 Evidence for a third method, generating an analogy via an abstract principle, has been observed on occasion, but only infrequently Cl,2].
 ANALOGY EVALUATION PROCESSES Another finding that has surprised us is the fact that rather than simply generating a single analogy, some subjects generate chains of several analogies.
 Two types of chains are shown as processes El and E2 in fig.
2.
 These are used to evaluate analogies.
 Processes used to critique 80 and evaluate analogies are at least as important in expert problem solving as processes used to generate them.
 Bridging analogies.
 Determining a match between key relationships in oases A and B is the first and most obvious method for confirming an analogy relation CU,5,6].
 However, another interesting process in the form of a "bridging analogy" may also be used.
 For example, S2 was concerned about the apparent lack of a match between the nonconstant slope In the bending rod and the constant slope of a stretched spring.
 In order to evaluate the bending rod analogy, he constructed the intermediate, bridging example of a spring with square coils as shown in drawing E1C of fig.
2.
 This allowed him to recognize that restoring forces in the spring come Crom twisting in the wire as wall as bending— a major breakthrough in his solution which corresponds to the way in which engineering specialists view springs.
 His discussion of the square spring is evidence for a cognitive bridging analogy, C, which helps him decide whether conceptual frameworks A and B are truly analogous.
 In this case the square spring analogy eventually aqulred the role of a mental model which gave him a new understanding of how springs work.
 M = a ^ E ^ ^ h H i ^ In a question about whether one can exert a more effective force on a wheel at the top or at the axle (In pushing on the wheel of a covered wagon, for example) several subjects compared the wheel to a lever hinged on the ground (fig.
38).
 Pushing higher up on the lever would allow it to move a larger weight, they reasoned.
 Another example of a bridge, which helped one subject to confirm the appropriateness of this analogy is the spoked wha«l without a rim shown in flg.
3C.
 Although physicists usually analyze the wheel problem directly in terms of torques, mathematicians often do not.
 The reader may be Interested In conjecturing about how one mathematician, SI, solved this problem via an analogy to a pulley.
 Extension analogies.
 The diagram for process E2 in fig.
2 shows an extension analogy proposed by SI in the form of two parallel pipes.
 SI was hoping to predict whether the radius/stretch relationship in the spring was linear or quadratic or cubic, and his understanding of the bending rod analogy was not sufficient to help him.
 So he generated a further analogy to the bending rod.
 In this analogy two pipes are fixed at the left side and held together in such a way that when the weight is applied to the right side, the upper pipe is stretched and the lower pipe is compressed.
 His analysis of this thought experiment was part of an attempt to model the bending rod in more detail and determine its length/deflection relationship so that this information could in turn be used in analyzing the spring.
 In such an extension analogy, a second analogous case is used to understand the first analogous case.
 Thus analogies can be used recursively to understand and evaluate a previous analogous case.
 Extreme cases.
 Aiding in understanding an analogous case is also one of the uses of extreme cases.
 For example, 32 generated the extreme case of a very short rod In order to conflrn his prior prediction that a short rod would bend less than a long rod (process E3 in fig.
2).
 Other methods of understanding an analogous case are to use a specific fact recalled froa menory, a physical intuition, or an analysis in terms of abstract principles [2].
 Research reported in this paper was MSF Award No.
 SED 8016567.
 REFERENCES supported by SUMMARY Fig.
2 illustrates several alternative subprocesses for acheiving processes PI, P2, and P3 in Table 1.
 Together, these subprocesses constitute a collection of intuitive heuristics used by experts in solving problems via analogy.
 Few of these subprocesses are described by subjects explicitly as they occur (they do not have names for them.
) Rather, they must be inferred from patterns in the content of the subject's investigations.
 Reasoning patterns G1 and G2 in fig.
2 are analogy generation patterns.
 Pattern El, the bridging analogy, is a method for evaluating an analogy relation.
 Patterns E2.
 the extension analogy, and E3, extreme case analysis, are methods for evaluating and improving one's understanding of the analogous case.
 These reasoning patterns form a set of nondeductive problem solving strategies which: (1) are quite different from traditional problem solving procedures; (2) are associated with imagery reports; and (3) are capable of generating new insights and recognitions of previously undiscovered causal factors in a problem solution Various "compound solutions" combining two or more of the basic processes shown in fig.
2 have also been observed.
 Our current hypothesis is that most observable chains of reasoning using spontaneous analogies are describable as recursive combinations of these basic patterns.
 In the cases of the square spring and the parallel pipes, the novelty of these cases argues that they were at least in part invented by the subject rather than recalled directly from memory.
 Thus, the analogies observed do not always consist of familiar cases recalled from long term memory; Che analogies can also consist of invented cases constructed in working memory.
 Furthermore, in the square spring and parallel pipes cases, the analogy Is used as a mental model which allows the subject to understand the problem situation in a new way.
 This type of mental model construction appears to be important in the development of creative problem solutions and may play an important role in the development of new explanatory models in science [6].
 [1] Clement, J.
, Analogy Generation In Scientific Problem Solving, Proceedings of the Third Annual Meeting of the Cognitive Science Society, Berkeley, August.
 1981.
 [2] Clement, J.
, Spontaneous Analogies in Problem Solving: Part I The Progressive Construction of Mental Models.
 Paper presented at AERA annual meeting.
 Mew York City, March, 1982.
 [3] Clement, J.
, Spontaneous Analogies in Problem Solving: Part II Generation Mechanisms, Simulation, Extreme Cases, and Model Construction, working paper.
 Physics Department, University of Massachusetts, Amherst, 1982.
 [«] Gentner, D.
, The Structure of Analogical Models in Science, technical report.
 Bolt, Beranek and Newman, Inc.
, Cambridge, MA, 1980.
 [5] Gick, M.
 and Holyoak.
 K.
J.
, Analogical Problem Solving, Cognitive Psychology, 12, 306355, 1980.
 [6] Hesse, M.
, Models and Analogies in Science.
 University of Notre Dame Press, Notre"T5ame, I9bb.
 [7] Collins, A.
, Fragments of a Theory of Plausible Reasoning, in Waltz, 0.
, Theoretical Issues in Natural Language ProceaslngZ.
 UrbanaChampaign: University of Illinois, 1978.
 81 R.
VBBIT: Cognitive Science in Interface Design by Micliae! D.
 Williams Frederich N.
 Tou Richard E.
 Filces Austin Henderson Tliotn.
'is Malone Cognitive and Instructional Sciences Group X E R O X Palo Alto Research Center Palo Alto, California Abstract A new kind of user interface for information retrieval has been designed and implemented to aid users in formulating a query.
 The system, called RABBIT, relies upon a new paradigm for retrieval by reformulation, based on a psycho ogical tlieory of human lemembering.
 The paradigm actually evolved from an explicit attempt to design a 'natural' interface which imitated human relreival processes.
 To make a query in RABBIT, the user interactively refines partial descriptions of his target !tcm(s) by criticizing successive e.
\ample (and counterexample) instances that satisfy the current partial descripiion.
 Instances from the database are presented to the user from a perspective in/erred from the user's quer>' descripdou and the structure of die knowledge base.
 A m o n g odier diings, this constructed perspective reminds users of likely terms to use in their descriptions, enhances their understanding of the meiining of given terms, and prevents them from creating certain classes of semanticiilly improper query descriptions.
 R A B B I T paiticularily facilitates users who approach a ±;tabase with only a vague idea of what it is diat they want and who dius, need lo be guided in the (rc)formulation of their queries.
 R A B B I T is silso of substantial value to casual users who have limited knowledge of a given database or who must deal with a multitude of databases.
 1.
 Introduction One way to test a theory is to try to do something useful with it W e have taken a cognitive theory of human remembering together with some artificial intelligence ideas about knowledge representarion and used it to design a new paradigm for database retrieval interfaces for casual users.
 The paradigm is called retrieval by reformulation.
 A small experimental system based on diis new paradigm has been implemented in the Smalltalk jrogramming language [Ingalls, 1978) using KloneTalk Pikes, 1981] on the Xerox Dolphin and Dorado personal computers.
 Part of the motivation for designing a new kind of database interface was die unsuitability of existing datal.
iase interfaces for casual users.
 Some database interfaces (e.
g.
, S Q U A R E Boyce et al, 1975) and S Q L [Chamberlin et al, 1976) require many hours of mstruction to learn; others have a syntax which users find difficult to use and understand (e.
g.
, the boolean expressions of D I A L O G [Lockheed, 1979]).
 Interfaces based on the relational data model (Codd, 1970] usually require the user to know in advance which tables and attributes he will be needing, while usens of network databases (such as Z O G H^obertson et al.
, 1981]) frequcndy get lost during the course of their search.
 To help solve these problems we looked for inspiration to Uieories of how people retrieve information form their own memory.
 W e believe this approach is promising for two primary reason: (J) To the extent diat the interface between a person and his external memory is like the interface between the person and his internal memory the external memory may be easier and more narural to use, and (2) to die extent that human memory systems embody a 'solution' to the problems of retreivul from large heterogeneous databases, they may provide useful insights about how to design similar artificial systems.
 We began our design process by conjecturing an interface which pemiitted descriptive retreival.
 The basic tenet of descriptive retrieval is that people retrieve information from (their own) memory by iteratively constructing partial descriptions of the desired target item [Bobrow and Norman, 1975; Norman and Bobrow, 1979; Williams and Hollan, 1981].
 The problem w;is diat our conjectured system appeared to give us little more than the traditional boolean expression schemes such as D I A L O G .
 W e simply replaced die technical term 'keyword' wiih die term 'desrciptor.
' This led us to a reexamination of the problems inherent in boolean expression interfaces.
 Upon consideration we conjectured that there were three major sources of difficulty for casual users of interfaces biised upon boolean expressions of keywords: (1) the user has incomplete knowledge about the descriptive terms needed to create a auery (e.
g.
 what car colors does die database know about* red, crimson, rose, mauve?), (2) the user doesn't knov/ what kind of attributes of the item(s) he is seeking die database recognizes (e.
g.
 does die database even has an attribute for car color?), and (3) many users find the syntax of complex boolean expressions diflicult to understand.
 Yet, if people actually recall information by descriptive retreival then they must face the same problems; diey must have some trick to get by those problems.
 W e found such a trick in retrieval by instantiation.
 Retrieval by instantiation postulates diat the information retrieved at each iteration of the retrieval process is often in the form of an instannation, i.
e.
, an example item suggested (e.
g.
, analogically or metaphorically) by the partial description [Williams, 1981].
 The c o m m o n consequence of such an instantiation is that one is 'reminded' of something similar to the original item [Schank.
 1980; Kolodner, 1980; Bower.
 Turner, luid Black, 1979].
 W e conjecture that this reminding serves to counter al dirce of the problems noted for boolean expression schemes.
 Ta<i instantiations provide a template for describing the target item, access to the descriptive terms, and can provide tl;e basis for an incremental reconstruction of the target item that avoids much of the complexity inherent in highly structured descriptions.
 82 1 Retrieval by Refonnuliition The basic principle imdcrlying RABUIT is a new paradigm, retrieval by reformulation, for information retrieval elabi)rtttcd from tlie notioti of retrieval by ii\stantiation.
 The user makes a query by llî t consluicting a partial description of the item(s) in the database for which he is icaiching.
 R A B B I T then provides a description of an example instance from the database which matches the user's partial description.
 Since it is unKkely that ilic first instance will be exactly what the user Is lookiiig for the u'jcr car.
 then select ;any uf the attributes shov.
n in tite t.
rample and incorporate those descriptors, or variations of ihern.
 into his partial description, thus, re/onnulaiing his initial query.
 At any lime the user can request a new exainnle instance, one which matches the latest version of his (pariiari description, and then use the descriptors of that new instance to retlne his query description still furdier.
 Figure 1 shows RABBIT in the midst of a retrieval interaction.
 The interface consists of four primary window panes.
 The 'Description' pane specifies an implicidy defined boolean expression that appears to the user as a partial description of the item(s) he is seeking.
 The Example' pane contains an example item that matches the panial description as of the last user initiated retrieval cycle from the R A B B I T defined perspective.
 More precisely, it contains a descripdon, called the image, of an instance from some welldefined perspective (e.
g.
, " S T A R 8011 computer" can be viewed from the perspectives of "a manufactured product," "a computer," "an electronic device," "a piece of office equipment," and "a piece of stock in a store.
" ).
 The 'Matching Examples' pane lists instances which satisfy the partial descripdon as of the last retrieval cycle.
 The "Previous Description" pane contains the description used on the last retrieval cycle which determines the perepective for presentadon of the example and the list of matching examples.
 The example pane command popup menu is also displayed The example instance mentioned above is a central element of die interface.
 It serves several purposes: it fiinctions as a template, it permits access to addiuonal descriptors, it provides semantic resolution of potentially ambiguous terms, and it frequendy serves as a counterexample.
 The example instance is a template in the sense that its presentation provides a pattern for making a query using the descriptors in die instance's image.
 It permits access to new descriptive terms through die alternatives and describe commands elaborated below.
 It also provides semantic resolution in that the context of a temi such as the role name 'manufacturer' establishes and refines the term's meaning.
 The role name 'manufacturer:' could refer to a person or a nation or a corporation.
 The statement 'manufacturer: Xerox' in die context of a description of a computer product helps resolve a host of potential meanings.
 Tlie example instance is also a counterexample to the user's intentions whenever it is not exactly what die user is looking for.
 Rudier than simply permitting the user to express his displeasure with the counterexample and have R A B B I T Iry to guess what is wrong widi it, the system tries to encourage the user to articulate what is wrong widi die instance presented.
 Tlie counterexample's sunple presence serves to remind the user that his query description is incomplete or wrong and, in addition, point out ihc particular parts of his description ihat need correction or modification.
 Finally, since the amount of information known about the retrieved instance could be considerable, the information actually presented in the image is limited to be only that information which can be inferred to be relevant based on the query description the user has given so far.
 (E.
g.
, information concerning the dinner menu or house specialty of a given restaurant would be available from the perspective of "a place which serves food" but not from die perspective of "a business.
" So if die user had begun his query with the descriptor 'Rusiness', dien die image of die retrieved instance, even if it is a restaurant, would not, initially, include information about its dinner menu.
) The current implementation of RABBIT supports a small set of 5 basic operations for creating a query description given die descriptors provided in die image of the example instance.
 These operations, shown in figure 1, are require and prohibit (which specify diat the given descriptor is or is not to be a descriptor of die retrieved instance, respectively), alternatives (which presents die user widi a popup menu of alternative descnptors to the given one), specialize (which shows the specializations of die given descriptor), and describe (which allows the user to examine a description of a given descriptor or to describe recursively what diat descriptor should be).
 The describe command provides the user widi the capability to build ernbeilded descriptions, an example of which appears in figure 1 with the value of die attribute 'disk' being itself a description.
 [Tou, 1982) and (Tou, Williams, Fikes, Henderson, and Malone 19821 contain a more complete discussion of the paradigm of retrieval by reformulation and the user interface to RABBIT.
 This paradigm of retrieval by reformulation, in effect, defines a form of interaction by which R A B B I T can as.
̂ ist casual users in formulating queries.
 M u c h of the intelligence of R A B B I T comes from control of diis interaction by appealing to die conceptual structure of the database.
 3.
 Perspectives The KLONE epistemology for representing knowledge [Brachman, 1979] has had a major influence on die development of RABBIT.
 O n e of the main uses of K L O N E is the implementation o^ perspectives.
 A perspective is simply a way of describing an event or item from a particular viewpoint JBobrow and Nonnaii, 1975, Bobrow and Winograd, 1977, Goldstein and Bobrow, 1980, Goldstein, 1980].
 In R A B B I T , a perspective specifies which descriptors are included in die image of any instance presented to the user.
 R A B B I T perspectives are dynamic in that the perspective from which the user views die instances in the database changes depending on the current partial description and on where he is within the database.
 There are two distinct mechanisms RABBIT uses to construct a perspective.
 First it filters die attributes to be presented to a user by including only attributes implicitly acknowledged by the user.
 Since the partial description is a representation of the user's intent to the computer, that description is a legitimate basis for determining what information to include in the image of the example instance.
 In R A B B I T the attributes included in the image •are exacdy those that belong to the instance classes occurring in die partial description.
 For example, if one were to see the computer descibed in figure 1 retrieved under the partial description 'Product' (i.
e.
 widiout the descriptor Computer') then only die attributes 'name', 'manufacturer', and 'cost' would be presented.
 Once the user refines die partial description to specify diat he is seeking a computer, additional attributes (e.
g.
 'disk:,' 'cpu:,' .
.
.
) would appear.
 A second mechanism for creating perspectives actually extends the perspective of any given instance beyond attributes direedy held by the object.
 Note in figure 1 diat because the user has created an embedded dcsciiption about the disk of the computer sought, aspects of the disk that the user considers important (e.
g.
 capacity) have been compressed into the image of the computer.
 83 Peripectives serve four main functions in the RA13BIT interface: controlling the type and amount of information presented facilitating the user's understanding of instances enforcing certain kinds of semantic consistency organizing and managing hetero>jcncous data.
 4.
 Summary This paper has briefly described the process of designing a novel type of database interface named RABBIT.
 RABBIT relies on a new paradigm for information retrieval, itnieval by reformulation, derived iVom a cognitive science theory of humaj\ remembering loyether with some uitificial intelligence idc.
ts about knowledge representation.
 Tlie four main ideas underlying this paradigm are: 1) retrieval by constructed descripuons 2) interactive construction of queries 3) critique of example instances 4) dynamic perspecdves.
 Tile fust diree of these ideas had their origins in human psychology.
 The development of the fourth idea—dynamic perspectives—was motivated and influenced strongly by the K L  O N E knowledge representation language.
 Cognitive Science has played a crucial role in the design of RABBIT.
 W e take the tentative success of the design as an iiidicadon of the potential role of cogniuve science in the design of humancomputer interfaces.
 Acknowledgements A major portion of this work was carried out by the second author under the auspices of the M I T intern program at Xerox PARC.
 The authors would also like to acknowledge the original stimulus for this work steming from an exciting conference on artificial intelligence and humancomputer interfaces sponsored by the Army Research Insutute.
 In particular, we would like Stan H:ilpcrn, Janet Kolodner.
 and Alan Badre to know a part of what came from their efforts in putring that conference together.
 W e would also like to thank John Seely Brown, Tom Moran.
 Rick Cattell, Laura Gould, and Richard Burton for their patient discussions and guidance.
 Each contributed crucial pieces of the puzzle many of which we are still putting together.
 .
John Seely Brown's questions in particular guided our pursuit of die use of perspectives.
 Finally, we would like to thank the other members of the Cognitive and Instructional Sciences Group at Xerox P A R C for dieir continuing support and critique throughout the development of RABBir.
 References Bobrow, D.
G.
, and Norman, D.
A.
 "Some Principles of Memory Schemata," in D.
G.
 Bobrow and A.
M.
 Collins (Eds.
), Representation and Understanding: Studies in Cnnniiive Science.
 New York: Academic Press, 1975.
 Bcjbrow, D.
G.
.
 and Winograd, T.
 "An Overview of KRL: A.
 Kiiowledge Representation Language," Cognitive Science, 1, pp.
 346.
 1977.
 Bower, C.
H.
, Black, J.
B.
, and Turner, T.
J.
 Scripts in Text Comprehension and Memory, Cognitive Psychology.
 Vol 1, 177220.
 1979.
 Boyce, R.
F.
, Chamberlin.
 D.
D.
, King.
 W.
F.
, and Hammer.
 M.
M.
 "Specifying Queries as Relational Expressions: The S Q U A R E Data Sublanguage," Communications of the A C M 18.
 11 (Nov.
 1975), pp.
 621628.
 Brachman.
 R.
J.
, Bobrow, R.
J.
, Cohen.
 P.
R.
.
 Klovstad, J.
W.
.
 Webber, B.
L.
, Woods, W.
A.
 "Resemch in Natural Language Understanding: Annual Report, I September 1978 to 31 August 1979," B B N Report No.
 4274.
 Cambridge.
 M A : Bolt Beranek and Newman Inc.
.
 August, 1979.
 Chamberiin, D.
D.
, Astrahan, VI.
M.
.
 Eswaran, K.
P.
, Griffiths, P.
P.
, Lorie, R.
A.
.
 Mehl, J.
W.
.
 Reisner, P.
.
 and Wade, B.
W.
 " S E Q U E L 2: A Unified Approach to Data Definition, Manipulation, and Control," I B M Journal of Research and Development 20 (Nov.
 1976).
 pp.
 560575.
 Codd, E.
F.
 "A Relational Model of Data for Large Shared Data Bases," Communications of the A C M 13, 6 (June 1970).
 pp.
 377397.
 Fikes.
 R.
 "Highlights from KloneTalk: DisplayBased Editing and Browsmg.
 Decompositions, Qua Concepts.
 and Active RoleValue Maps," Proceedings of the 1981 K L  O N E Workshop, Jackson, New Hampshire.
 October, 1981.
 Goldstein.
 LP.
 "PIE: A networkbased personal information environment" Proceedings of the OJfice Semantics Workshop, Chatham.
 Mass.
, June, 1980.
 Goldstein, I.
P.
, & Bobrow.
 D.
 Descriptions for a programming environment.
 Proceedings of the First Annual National Conference on Artificial Intelligence, Stanford, CA, August.
 1980.
 fngalls.
 D.
H.
 "The Smalltalk76 Programming System: Design and Implementation.
" Conference Record of the Fifth Annual A C M Symposium on Principles of Programming Languages, Tucson, A Z : Januai7 1978, pp.
 916.
 Kolodner, J.
L.
 Retrieval and Organization Strategies in Conceptual Memory: A Computer Model.
 Research Report #187.
 Department of Computer Sciecne, Yale Umversity, N e w Haven, CT.
 1980.
 Ixckheed Information Systems.
 Searching, Palo Alto.
 CA, 1979.
 Guide to D I A L O G Norman.
 D.
A.
.
 and Bobrow.
 D.
G.
 "Descriptions: An Intermediate Stage in Memory Retrieval,' Cognitive Psychology il (1979), pp.
 107123.
 Robertson, G.
.
 McCracken.
 D.
, and Newell.
 A.
 "The Z O G Approach to ManMachine Communication.
" International Journal of ManMachine Studies (1981) 14, pp.
 461488.
 Schank, R.
C.
 Failuredriven memory.
 Cognition and Brain Theory, Vol.
 1, 4, 4160.
 1980.
 Tou.
 F.
 RABBIT: A novel approach to information retrieval, unpublished M.
S.
 thesis.
 Massachusetts Institute of Technology.
 Cambridge, Mass.
, forthcoming.
 Tou.
 F.
N.
, Williams.
 M.
D.
, Malone.
 T.
W.
.
 Fikes.
 R.
E.
.
 and Henderson.
 A.
 RABBIT: an Intelligent Interface.
 Xerox Technical Report, forthcoming.
 1982.
 Williams.
 M.
D.
 "Instantiation: A Data Base Interface for die Novice User," Xerox Palo Alto Research Center Working Paper, i98L Williams.
 M.
D.
, and Hollan, J.
D.
 "The Process of Retrieval from Very Long Term Memory," Cognitive Science 5 (1981), pp.
 87119.
 34 Zloof, M .
 M .
 "Query by example," in Proceedings of the National Computer Conference, A F I P S Press, Arlington, Va.
, M a y 1975.
 pp.
 431437.
 Moui Descnpiion.
 Descaptioa Pmduci CompuxtfrfietawdProOuct Connpiu«r • U:.
P: Disk iijrriiMiit'iirti.
 or 5i;kt"itts maauftKCvtrer: CrorrusfriLO.
 or :<:k;to« • Accnt'i.
u.
.
v; of chv 1^1^01o ixampU [ Attritut.
;; of .
t.
vr;;oi 1 Eruiiî  Produci Compui«Tl?e(at«dPro(luc( OEMProduct RetoOPTOduci ConiptiWT ruirri.
;: tV'l'lUV proKit'\c î sfiiî }ti':'H ruil' lWU' ilujpUM: Larri«ForrruitDt^pUm mi';moh^: Xeroxi^Cm^rrunnj informanoa .
U)oiit itarsoi 1 ~ An Ktei:\mvi! worP.
 iiaiion bviUt bn XiifDn.
; Pt*wujus Dcscnptiorv Eruixi) Product Connpui«r1teta(«dPrDdiict Comptucr aui.
ts.
: Otste i;.
ipii.
;itM: ISoKbHt^i.
 or sî i biites tTuvaiif<TcCur>r: Ataa.
 ilp:irrurru"0.
 4 Mautuiu) ixampbts AC.
in40l3 ACi.
inSOO i:n:im.
;nuo~.
?0 Figure 1.
 Example of RABBIT display.
 85 CONSTRUCTING RUNNABLE MENTAL MODELS Allan Collins Dedre Centner Bolt Beranek and Newman Inc.
 50 Moulton Street Cambridge, Massachusetts 02238 A core idea in the literature on mental models (Brown, Burton, & Zdybel, 1973; deKleer, 1977, 1979; Forbus, 1981; Hayes, 1978; Stevens & Collins, 1980) is the notion of mental simulation.
 In all these approaches mental simulation is accomplished by dividing a system into a set of states whose transition rules from state to state are known.
 Given the transition rules for each state, and the topology of connections between states, it is possible to run the system with different inputs to see what happens.
 This provides a kind of inferential power not possible with the static data structures implied in much of the literature on frames, scripts, and semantic networks (e.
g.
, Collins 6 Loftus, 1975; Minsky, 1975; Quillian, 1968; Schank & Abelson, 1977).
 The Metaphor Hypothesis In this paper we propose a specific role for metaphor in constructing runnable mental models.
 It can be stated as follows: Metaphors map the set of transition rules from one domain (the base) into another domain (the target) so that it is possible to construct a mental model to run simulations in the target domain.
 This is a special case of Centner's (1980, 1982) more general claim that metaphor is a mapping of structural relations from a base domain to a target doma in.
 We can illustrate the hypothesis by showing how three metaphors can be used to construct a runnable version of the microscopic model of evaporation discussed by Stevens and Collins (1980).
 Then, in the next section, we compare the model derived from these metaphors with the model one of our subjects used to reason about evaporation in an experiment where we asked subjects novel questions about evaporation processes.
 The first metaphor states that water molecules (or air molecules) are like billiard balls bouncing around in space.
 The warmer the water is, the more velocity (or greater energy) the average molecule has.
 The same metaphor applies to the water and air molecules in the air mass above a body of water.
 This model is incomplete insofar as it includes no notion of the attractive forces between different molecules and the polarity of the electrical charges on different sides of the molecule.
 But as a first approximation, it is a perfectly good model.
 The second metaphor states that a molecule escaping from the water is like a rocket ship escaping from earth.
 That is to say whether or not it actually escapes is a function of its initial velocity and its angle.
 In this way the model builds in a rudimentary notion of the attractive forces between molecules, by likening the notion of escape from the attraction of the other water molecules to escape from gravity.
 However, to understand some aspects of evaporation, this gravity notion of attraction is not enough.
 The third metaphor states that the molecules in the air mass over the water can be thought of as people inside a room.
 As more water molecules collect in the air mass, the room becomes more crowded with water and air molecules.
 The warmer the air mass, the larger the room.
 Thus, warm air masses are less dense then cold air masses.
 The boundary between the air and water is the entry into the room, and if everyone crowds along that border it is hard to get in.
 This crowdedroom metaphor leads to many correct predictions, but is wrong in some fundamental ways.
 In fact, the space between molecules in a cool air mass never becomes crowded.
 Cool air masses hold less moisture because the water molecules in them tend to lose energy with each interaction.
 Then the attractive forces between water molecules tend to attract the molecules back to the water surface or to form raindrops or dew.
 Now we want to show how these three metaphors enable a person to construct a runnable model of evaporation processes.
 We would argue that people usually know certain interaction rules of billiard balls such as those depicted in Figure 1.
 Velocity of each ball in the interaction is represented by a vector, and the transition rule of the interaction by the large arrow.
 Rule 1 shows that without collision, speed and direction are maintained.
 Rule 2 shows a headon  collision with a nonmoving ball where momentum is transferred from one ball to the other.
 Rules 3 and 4 show how momentum is transferred as a moving ball strikes a nonmoving ball at different angles.
 Rules 5 and 6 show typical interactions when both balls are moving.
 These rules summarize one's local knowledge about how billiard balls interact.
 From these local interaction rules, one can derive certain global properties of how a container full of molecules will behave.
 That is we can construct an aggregate model of molecular interaction (Stevens & Steinberg, 1981) based on the mechanical model of billiardball 86 interaction.
 The most important properties of this aggregate model are that there is variability of speed and direction of the molecules.
 This produces randomness o£ motions of the molecules, with some going toward the surface, some not.
 There is elasticity of interaction so that energy can be transferred from molecule to molecule, but not lost.
 Finally, there is no change in direction or velocity without a collision.
 In our view, people can either imagine molecules moving in this aggregate fashion (like seeing dust particles moving in the sunlight) or by following a single molecule moving around and encountering other molecules according to the local interaction rules shown in Figure 1.
 Q odoes not mix completely (depending on winds), then water molecules may accumulate in the air along the water's surface and no new molecules can get in, even though the air mass is not filled.
 If a crowded air mass is cooled, the water molecules may be squeezed out for lack of space.
 These behavioral properties reflect the way air masses actually behave, even though the model is essentially incorrect.
 In an earlier paper (Stevens & Collins, 1980) we described the kind of inferential power that runnable models provide for answering novel questions about the world.
 In order to see how subjects use models, we conducted an experiment where we asked subjects to reason about such questions.
 Exper iment on Mental Models OQ©O Q CD Q©Gh ® OOo * n r Pl9ura I.
 So«« Lntaractlon rulas for p«rfactly alttstic billiard balla.
 The rocketship metaphor gives a simple three state description of behavior of molecules near the surface.
 If they have any downward component of velocity, they do not escape.
 If they are headed straight up, there is some minimum initial velocity they need to escape.
 If they are headed up at an angle to the surface, the smaller the angle the greater the initial velocity they need to escape (because of the attraction of the surface over a larger part of the trajectory).
 This three state model summarizes what the rocketship metaphor implies about the effects of the water's surface.
 The crowdedroom metaphor, like the billiardball metaphor, leads to construction of an aggregate model at the microscopic level.
 The model has the following behavior.
 The warmer the air mass, the larger the room is.
 As water evaporates into the air mass, it fills up with molecules.
 Cold air masses take less time to fill up with molecules.
 When the air mass is filled, then no more water molecules can get in.
 If the air mass Four subjects were asked eight questions about evaporation.
 They were asked to explain their reasoning on each question.
 All were reasonably intelligent, but were novices about evaporation processes.
 Our analysis will center on one subject, whose model of evaporation processes was very much like the model we constructed from the three metaphors, if not exactly the same model.
 His view includes notions of the energy needed for molecules to escape from a body of water and the difficulty of water molecules entering a cold air mass because of the higher density.
 Nowhere does he mention attractive forces between molecules, which suggests that this notion is not part of his model.
 He seems to share a common misconception that visible clouds (such as one sees coming out of a boiling kettle) are made up of water vapor rather recondensed liquid water.
 This misconception forced him into several wrong explanations.
 We will present the portions of his responses to three of the questions that illustrate his use of the mental model described eibove.
 Q2: On a cold day you can see your breath.
 Why? S: I think again this is function of the water content of your breath that you are breathing out.
 On a colder day it makes what would normally be an invisible gaseous expansion of your breath (whatever), it makes it more dense.
 The cold temperature causes the water molecules to be more dense and that in turn makes it visible relative to the surrounding gases or relative to what your breath would be on a warmer day, when you don't get that cold effect causing the water content to be more dense .
 .
 .
 Q4: Which will evaporate faster, a pan of hot water placed in the refrigerator or the same pan left at room temperature? Why? 87 S: When I first read that question, my initial impression, that putting a pan of hot water in the refrigerator you suddenly have these clouds of vapor in it, threw me off for a second.
 I was thinking in terms of there is a lot evaporation.
 Well I guess, as I thought through it more, I was thinking that it was an indication of more evaporation, but it was just (let us say) the same evaporation.
 Immediately when you put it in anyway, it was more visible.
 Ahmm, as I think through it now, ray belief is that it would evaporate less than the same pan left standing at room temperature and my reasoning there is that the air in the refrigerator is going to be relatively dense relative to the room temperature air, because at a colder temperature again its molecules are closer together (what not), and that in effect leaves less room to allow the molecules from the hot water to join the air.
 .
 .
 .
 ships, and crowded rooms, he must have drawn upon some such objects in order to create the model he was using.
 Based on this model, he was able to deal quite successfully with the questions, even though his model was incorrect in several ways.
 Acknowledgments This research was supported by the Personnel and Training Programs, Psychological Sciences Division, Office of Naval Research, under contract number N0001479C0338, Contract Authority Identification Number NR 154428.
 We thank Michael Williams for an engaging conversation that led to the metaphor hypothesis of this paper, and to Ken Forbus for his comments on a draft of the paper.
 Q5: Does evaporation affect water temperature? If so, in what way, and why? S: I guess those water molecules that do leave the surface of the water are those that have the highest amounts of energy.
 I mean they can actually break free of the rest of the water molecules and go out into the air.
 Now if they have a, if they are the ones with the most energy, I guess generally heat is what will energize molecules, then that would lead me to believe that maybe, although it may not be measurable, maybe with sophisticated instruments it is, but maybe it would be measurable after your most energetic molecules have left the greater body of water.
 Those that remain are less energetic and therefore their temperature perhaps less.
 The subject's first two answers manifest the crowded room model: The particles in cold air are crowded together, which acts to make one's breath more visible and to make it more difficult for water molecules from a hot pan to get in.
 The last answer manifests the rocket ship and billiard ball models: The particles move around and those that escape are the high energy particles, leaving the low energy particles behind and hence cooling the water.
 These excerpts illustrate the underlying molecular model of evaporation that the subject had, and how he used it to find answers to novel questions.
 His model is close to, if not the same as, the model we constructed from the metaphors in the previous section.
 The ' hypothesis of the paper is that this subject's underlying model was constructed by pasting together his models of how familiar objects behave.
 While he may not have drawn upon billiard balls, rocket References Brown, J.
 S.
, Burton, R.
 R.
, & Zdybel, F.
 A modeldriven questioninganswering system for mixedinitiative computerassisted instruction.
 IEEE Transactions on Systems, Man, and CyberneticsT l573, i, 2482577" Collins, A.
, & Loftus, E.
 F.
 A spreading activation theory of semantic processing.
 Psychological Review, 1975, 82, 407428.
 de Kleer, J.
 Multiple representations of knowledge in a mechanics problem solver.
 Proceedings of the Fifth International Joint Conference on Artificial Intelligence.
 Cambridge, Mass.
: MIT, 1977, 299304.
 de Kleer, J.
 The origin and resolution of ambiguities in causal arguments.
 Proceedings of the Sixth International Joint Conference on Artificial Intelligence.
 Tokyo, Japan: 1979, 197203.
 Forbus, K.
 D.
 A study of qualitative and geometric knowledge in reasoning about motion.
 Cambridge, Mass.
: MIT AI Technical Report No.
 615, 1981.
 Gentner, D.
 Studies of metaphor and complex analogies: A structuremapping theory.
 Paper presented at the A.
P.
A.
 Symposium on Metaphor as Process, Montreal, September 1980.
 Gentner, D.
 Are scientific analogies metaphors? In D.
 S.
 Miall (Ed.
), Metaphor: Problems and perspectives.
 Brighton, Sussex: Harvester Press, Ltd.
, 1982.
 Hayes, P.
 J.
 Naive physics: Ontology for liquids.
 Unpublished manuscript, 1978.
 88 Minsky, M.
 A framework for representing knowledge.
 In P.
 H.
 Winston (Ed.
), The psychology of computer vision.
 New York: McGrawHill, 1975.
 Quillian, M.
 R.
 Semantic memory.
 In M.
 Minsky (Ed.
), Semantic information processing.
 Cambridge, MA: The MIT Press, 1968.
 Schank, R.
 C, & Abelson, R.
 P.
 Scripts, plans, goals and understanding.
 Hillsdale, N.
J.
: Erlbaum, 1977.
 Stevens, A.
 L.
, & Collins, A.
 Multiple conceptual models of a complex system.
 In R.
 E.
 Snow, P.
 Pederico, 6 W.
 E.
 Montague (Eds.
), Aptitude, Learning, and Instruction (Vol.
 2).
 Hillsdale, N.
J.
: Erlbaum, 1980.
 Stevens, A.
 L.
, & Steinberg, C.
 A typology of explanations and its application to intelligent computer aided instruction (BBN Report No.
 4626).
 Cambridge, MA: Bolt Beranek and Newman Inc.
, March 1981.
 89 BiDlrectional Inference by Scuarc Shapiro, Joao Martins and Donald McKay* DeparcmenC of Computer Science State University of New York at Buffalo 4226 Ridge Lea Road, Amherst, MY 14226 *(current address: Research & Development Activity, Special Systems Division, Federal and Special Systems Group, PO Box 517, Paoli, PA 19301) This work was supported In part by the National Science Foundation under Grants MCS87802274 and MCS8006314 and by the Instltuto Nacional de Xnvestigacao Cientlficia (Portugal) under Grant No.
 20536.
 Abstract Inference can be viewed as a search through a space of inference rules.
 Backward and forward inference differ in the direction of the search: backward inference searches from goals to ground assertions; forward inference searches from ground assertions to goals.
 This paper describes an inference procedure, called bidirectional inference, which limits the number of inference rules searched.
 Bidirectional inference results from the interaction between forward and backward inference and loosely corresponds to bidirectional search.
 We show through an example that, when used throughout a session of related tasks, bidirectional inference sets up a conversational context and prunes the search through the space of inference rules by ignoring rules which are not relevant to that context.
 1.
 Introduction Bidirectional inference (BDI) combines forward inference (FI) and backward inference (BI) to limit the search through a space of inference rules by establishing a context on the basis of an ongoing session.
 We use the term "bidirectional inference" because the resulting search loosely corresponds to bidirectional search (Kowalski 72, Pohl, 71).
 The benefits of BDI become clear during an extended session in which the user asks questions and adds assertions all of which are related.
 BDI sets up a conversational context and prunes the space of inference rules searched (either during BI or FI) by ignoring rules which are not relevant to the context.
 In BDI there are two sets of inference frontiers, one growing from the assertions added in FI and the other growing during BI from the questions asked.
 Whenever two frontiers meet some answers are produced.
 BDI has been implemented in SNIP, the SNePS Inference Package.
 We present examples of BDI and compare the results obtained using BDI with the results obtained using BI or FI only.
 Although SNIP has a much richer rule syntax than used in these examples (Shapiro, 79a, 79b) they suffice to illustrate BDI.
 Basic notions of SNIP SNIP relies on a declarative representation of inference rules (SNePS semantic network (Shapiro, 79a).
 Every rule may be used both in FI and BI.
 When a rule is used, it is activated, remaining that way until explicitly deactivated by the user.
 The activated rules are assembled into an active connection graph (acg) (McKay and Shapiro, 81) , a collection of tiULTI processes (McKay and Shapiro, 80) which carry out the inference.
 The acg also stores all the results generated by the activated rules.
 If during some deduction SNIP needs some of the rules activated during a previous deduction, it uses their results directly instead of rederiving them.
 The acg that is built for one query or assertion is not discarded after the query has been answered or the assertion "fully" understood by making all possible inferences from it.
 Rules of the network remain active, allowing a dynamic context to be constructed.
 The dynamic context is the collection of rules which have been activated.
 In addition, the active rules are more prominent: when searching for inference rules to be used, if any previously activated rules are appropriate then only those rules will be considered and no other rules will be activated.
 Hence rules apparently irrelevant to the current dynamic context are Ignored.
 3.
 Backward Inference We present an example of BI, explaining very briefly how acg's work.
 A complete explanation can be found in (McKay and Shapiro, 81).
 Suppose that SNIP is being used as a database retrieval system for some company interested in recruiting computer science (CS) majors.
 The recruiting policies of the company are stored as rules in the database (Lines 14, Fig.
 1).
 The V(x,y)| Pl«inli>9to»Uit(x) 4 CS«joc.
t(y,x) > (SaoifnftctW.
 viM.
yll Tta|><clicx>l(il i CS«joc«t(y,«l > Goocli«<Mjnct(y)l V(zl( aaadFn*FKt(zl > ScntUutituntodl 1 V(z)[ <Soo6ftofCtU) i Cradu>elng(x) > larit̂ f(xintcrriai(x) ] lepKtnoi(HIT) lop«t»ol(acil CSMjor*t(Dan.
SDMn CS.
ajac>t(T«d,a(J) C5aBjac«t(«ina,Mxn C5tBjac«t(Jatn,oaN Figure 1 Initial database company's database also contains a list of top schools and a list of the CS majors at different schools (Lines 510, Fig.
 1 ) .
 90 Every year the company updates Its database with the names of all students graduating in CS and all the schools that the company will visit during that year (Fig.
 2 ) .
 The company then uses SNIP to find out nmliqeonut (SDBn Plamingtortmit (Otn andi(tlii9(Jotnl Figure 2 Information updating the database which CS majors should be invited for interviews, which ones should be sent the company's literature, etc.
 We now consider the acg describing the reasoning of SNIP when it is aslced who should be invited for an interview.
 An acg is represented as rectangles and circles.
 Each rectangle represents a rule instance (a deduction rule together with a substitution for the variables in the rule); the antecedents appear to the left of the double line and the consequents to the right.
 Circles (called goal nodes) represent goals to be proved.
 Rule Instances and goal nodes are connected by directed edges.
 Substitutions flow through the edges.
 Rule instances and goal nodes can be viewed as producers of formulas sent out on the edges leaving them and as consumers of formulas coming in on the edges pointing to them.
 Some edges have switches (represented by square brackets) which have the effect of renaming the variables in the substitutions flowing through them.
 For ease of reference, rule instances have labels of the form An (where n is an integer).
 Those labels are used for notational convenience only and have no relation with the way acg's work.
 Initially, a request is created which contains the atomic formula being sought.
 The rule instance labeled Al in Figure 3 represents the request to 1 tortt«£ocljitKTi«»(»liD) II ({T*<V«tiol,IIlon/««>l) ® 1 Gao<H>co>pKt(i) 1 Gcaduatlnglxl 1 1 Î ivitcfocintervinidl 1 llDor\/»l,{T»<i/'xl,(«i»i«/x|) (gl^_ @ ((T«Vxl,lnon/i).
IJc ly/.
.
 .
y/ 1 itopachoollil 1 CSm]ar«t(y,zl 11 Oaatfeofetly) 1 *n/xl) / 1 nannui9cavlut(il 1 CSiiajacu(y,z) 1 1 Gaodpn'P*ct(yl 1 ' (a){(sDMt/i(,iafVillJ (ISDMC/'i.
am/'yl, laa/M.
ttO/y}, Wn/i.
Mmv'y).
 loaJVM,Joln̂ y|) Figure 3 acg for backward inference deduce all Instances of the atomic formula Inviteforinterview(who).
 The next step is to create a goal node for the atomic fomiula.
 A goal node (Gl) is added below the instance being sought.
 One of the jobs of the goal node is to natch its atomic formula against the network to find all formulas which unify with it.
 If there are ground instances the goal node produces then Immediately.
 For every matching formula in consequent position of some rule, a new rule instance is added to the acg.
 The other Job of the goal node Is to remember all substitutions it receives (these substitutions are represented enclosed in curly brackets next to the goal node).
 When a goal node receives a new substitution, it sends it to all rule instances to which it points.
 In this case, Gl can't find any ground instances of Inviteforinterview(who) but the rule V(x) [Goodprospect(x) & Graduating(x) <• Invlteforinterview(x)] may be used to derive such instances.
 Rule instance A2 is thus created by Gl (Fig.
 3 ) .
 Notice that the variable 'x' in A2 should be bound to 'who' in Al when an answer is produced by A2.
 For this reason a switch ([x/who]) is inserted in the link between A2 and Gl and has the effect of translating between variable contexts.
 Switches are computed by the network matching function (Shapiro, 77) which was used by Gl.
 For details of how this Is done see (McKay and Shapiro, 8 1 ) .
 Goal nodes G2 and G3 are created for the antecedents of A2.
 G2 finds two rules which can produce instances of Goodprospect(x) and creates the corresponding rule instances (A3 and A4, Fig.
 3 ) .
 G3 finds three ground Instances of Graduating(x), namely Graduating(Ted), Graduating (Don) and Graduating(John).
 The substitutions (Ted/x), {Don/x} and (John/x) are stored by G3 and sent to its consumer (A2).
 Goal nodes are created for the antecedents of A3 and A4.
 G4 finds two top schools (MIT and CMU), and sends the substitutions to A3.
 G5 finds the CS majors at different schools.
 Informing both A3 and A4.
 A3 deduces that both Ted and Anna are good prospects.
 A4 deduces that both Don and Ted are good prospects after receiving from 06 the information that SUNY and CMU will be visited.
 The Information about good prospects flows through the acg reaching A2 which deduces that both Ted and Don (good prospects who are graduating) should be invited for interviews and the answer is finally produced by Al.
 Notice that BI tries to get each answer in all possible ways, and so the same answer can be produced several times.
 In this particular case the answer Goodprospect(Ted) was produced twice, by rule instances A3 and A4.
 4.
 Forward Inference In this section we discuss the results obtained if the company chooses to use FI.
 We will assume that the information represented in Figure I is stored in the database and that FI is done with the information represented in Figure 2.
 Doing FI with Planningtovisit(SUNY) generates the acg of Fig.
 4: rule instance Al is created along with goal nodes for Its antecedents (Gl and G2) .
 Gl is immediately satisfied, and G2 finds CSmajorat(Don, SUNY), sending to Al the substitution {Don/y}.
 Notice that G2 is performing some amount of BI, reflecting a characteristic of SNIP in which BI and FI are closely interconnected.
 Al deduces Goodprospect(Don), creating rule instances A2 and A3 to do further FI.
 A2 deduces its consequent but A3 doesn't since Graduating(Don) is not in the database yet.
 91 Goodpco>P*̂ 'Î °'̂ > 1' SendlitecBtuxeto(Don) A3 I Goodprosp*ct(DQn) I Graduatu>g(Oon) II InvitaCoclnt«rvi«f(Dan) I I Pl«nmn9tovi»lt(SUWI I CSiMjordt(Y,SUHm II Goodpro»p«ctly) I @ (g) l(Dan/yl) Figure 4 acg for forward Inference After entering all the information of Figure 2, SNIP has deduced (acg not shovra) that Don, Ted and Anna should be sent literature and that Don and Ted should be invited for interviews.
 In other words, all possible inferences were made, even if the user was only interested in some of them.
 FI does not take the user's interests into account filling the database with assertions which may never be used.
 5.
 Bidirectional Inference In this section, we introduce BDI and show that it establishes conversational contexts, focusing snip's inferences within those contexts and thereby limiting the space of rules searched.
 BDI results from the interaction of FI and BI and can be obtained either by doing BI following FI or by doing FI following BI.
 We consider each of these cases in turn.
 5.
1.
 Backward Inference Following Forward Inference Suppose that the user says "I am planning to visit SUNY, who shall I invite for an interview?".
 In this context, by asking 'Inviteforlnterview (who)?' the user wants to consider only the CS majors from SUNY.
 Ue show how FI can be used to set up the 'SUNY context' which is then used to answer the user's query.
 In a pure BI system, finding the CS majors from SUNY who should be Invited for an interview requires finding the intersection between all CS majors from SUNY and all persons who should be invited for an interview (or, in some systems, generating all of one and testing each to see if it satisfies the other).
 The user begins by doing a small amount of FI with Plannlngtovisit(SUNY).
 The amount of inference can be defined by the number of network pattern matches performed.
 Let us assume, for the sake of argument, that by "small amount of FI" we mean that FI is only allowed two network matches.
 The first match finds the rule V(x,y)[Planningtovi3it(x) & CSmajorat(y,x) * Goodprospect(x)], setting up the rule instance Al (Fig.
 5) and the second match is used by G2 to look for instances of u I ln»itefacmt«tvl€w(»ho) 11 ({Don/xholl li/«t»l Goo<Jpco«pect(x) I Gcadu»tinq(il II Inviteforlnt»rvie»(x) I (iTsViLiDorv/iKIJotm/ill ly/xl Planunqto%asit(SUOTl 1 CSim]ocat(y,SUNin M Goodprospect (y) I @ @ llDon/yl) Figure 5 acg for bidirectional inference CSmajorat(y,SUNY), finding CSmaJorat(Don,SUNY).
 This is enough to deduce Goodprospect(Don) but nothing can be done with this because finding unactlvated rules requires a match.
 Therefore, the inference stops, leaving behind the active rule instance Al (Fig.
 5 ) .
 If the user now asks the question 'Invlteforinterview(who)?' rule instances (A2 and A3) and goal nodes (G3, G4 and G5) are created (Fig.
 5) as discussed in section 3.
 Here, however, goal node G4 finds that there Is an active rule that can produce instances of Goodprospect(x), namely Al.
 Instead of doing a network pattern match to find additional rules, it uses rule Instance Al limnediately.
 The substitution {Don/y} flows through the acg producing the answer Invlteforinterview(Don).
 In this case the CS majors from other schools were not even considered since SNIP had set up the "SUNY context".
 Suppose that CSmajorat(Don,SUNY) were not in the network and thus rule instance Al could not produce any answer even though instances of Inviteforinterview(who) could have been derived for CS majors of other schools.
 Following the query 'lnviteforinterview(who)?', SNIP would return an "I don't know" answer.
 This, at first glance, seems to be wrong.
 However, taking into account that the user only wants to consider the CS majors from SUNY this makes perfect sense, showing a feature of BDI in which derivable instances which are Irrelevant to the context are effectively ignored by SNIP.
 5.
2.
 Forward Inference Following Backward Inference Suppose that the database contained the information of Figure 1 and the user asked who should be Invited for an interview.
 SNIP builds an acg as shown in Figure 3, except that goal nodes G3 and G6 have no stored data.
 The acg produces no answers since the information in the database is insufficient.
 If the user now does FI with any of the propositions of Figure 2, the waiting goal nodes are found.
 Whenever a new assertion is produced for FI.
 and a goal node already exists that wants it, no network match is done to find additional relevant rules.
 For example, if Graduating (Ted) is entered, SNIP tells the user to invite Ted for an interview, and Ignores that Sendllteratureto(Ted) could also have been derived, since presumably the user was not Interested in this latter proposition.
 Again, BDI takes into account the conversational context, ignoring the rules irrelevant to the active context.
 6.
 Conclusions We presented an overview of BDI, pointing out the two characteristics required by a system to make the BDI behavior possible: 1.
 Every rule may be used both in FI and BI.
 2.
 There is a distinction between rules which have been activated and rules which haven't.
 Relying on these two characteristics, when SNIP (a system which uses BDI) searches for rules to be used, it looks for activated rules first and just in case of failing to find any activated rule, nonactivated rules are considered.
 In addition, as a matter of efficiency, activated rules remember all the results produced, not solving the same problem twice.
 The resulting inference loosely 92 corresponds to a bidirectional search.
 We say 'loosely corresponds' because not only may there be several bidirectional searches going on in parallel (one for each question asked) which can intersect each other, but also there are two levels of search, the first through the activated rules, and the second, which is tried only after failure of the first, through the nonactivated rules.
 The example presented, although very small and simplistic, shows that BDI effectively prunes the search through the space of inference rules by focusing the system's attention towards the interests of the user.
 In BDI, some of the disadvantages of pure FI and pure BI do not exist.
 One of the disadvantages of pure FI is that it may fill the database with derived propositions which may never be used.
 We showed that BDI ignores some derivations which do not interest the user.
 One of the disadvantages of BI is that all apparently relevant rules are Cried, regardless of the actual data.
 We showed chat BDI Ignores inactive rules in favor of rules activated by previous (forward or backward) deduction.
 7.
 Acknowledgements Ilany thanks to Terry Nutter, Ernesto Morgado, Jeannette Neal and the other members of SHeRG (the SNePS Research Group) for their coimnents on earlier versions of this paper and for their general discussions while the research was in progress.
 8.
 References 1.
 Kowalski, R.
, Andor Graphs, Theoremproving Graphs and Bidirectional Search, in Machine Intelligence 7.
 Meltzer and Michie (eds.
), Halsted Press, 1972.
 2.
 McKay D.
 and Shapiro S.
, "MULTI  a LISP Based Multiprocessing System", Proc.
 1980 LISP Conference, pp.
 2937.
 3.
 McKay D.
 and Shapiro S.
, "Using Active Connection Graphs for Reasoning with Recursive Rules", Proc.
 IJCAI81.
 pp.
 368374.
 4.
 Pohl I.
, Bidirectional Search, in Machine Intelligence 6, Meltzer and Michie (eds.
), American Elsevier, 1971, pp.
 127140.
 5.
 Shapiro S.
, "Representing and Locating Deduction Rules in a Semantic Network", in Proc.
 Workshop on PatternDirected Inference System, SIGART Newsletter 63, 1977, pp.
 1418.
 6.
 Shapiro S.
, "The SNePS Semantic Network Processing System", In Associative Networks.
 N.
V.
 Flndler (ed.
).
 Academic Press, 1979a, pp.
 179203.
 7.
 Shapiro S.
, "Numerical Quantifiers and their use in Reasoning with Negative Information", Proc.
 IJCAI79.
 1979b, pp.
 791796.
 8.
 Shapiro S.
 and McKay D.
, "Inference with Recursive Rules", Proc.
 First AAAI Conference.
 1980, pp.
 151153.
 93 A C T I V E L Y L E A R N I N G T O U S E A W O R D P R O C E S S O R John M.
 Carroll and Robert Mack IBM Thomas Watson Research Center Yorktown Heights, N e w York 10598 Learning to use a word processor provides a study of real complex human learning that is fundamentally "active", driven by the initiatives of the learner.
 People learn by actively trying things out, by reasoning, and by referring to prior knowledge.
 Our view is that these are natural ~ albeit demanding — strategies for people to adopt when confronted by a learning task of nontrivial complexity.
 What is especially noteworthy in the present case is that the learners we have studied are almost entirely innocent with respect to computer technology.
 In the context of learner innocence, we argue, these "natural" strategies entrain severe and wide ranging learning problems.
 Analysis of these problems, in turn, suggests research directions for the analysis of real human learning within Cognitive Science and practical directions In which computer word processing systems, and the educational technologies that support their training and use, might evolve.
 In this research project, ten office temporaries spent four halfdays learning to use one of two possible word processing systems in our laboratory.
 These people were highly experienced in routine office work, but quite naive with respect to computers in general and word processing in particular.
 W e asked them to Imagine a scenario in which a word processing system had recently been introduced to their office and they had been asked to be the first to learn it (to then pass this knowledge on to colleagues).
 The point was that they were to learn to use the system using the training materials that accompany it as their only resource.
 Our method involved prompting learners to "think aloud" as they worked through the training materials.
 They were to report questions that were raised in their minds, plans and strategies they felt they might be considering or following out.
 and inferences and knowledge that might have been brought to awareness by ongoing experiences.
 W e remained with the learners, to keep them talking and to intervene if at any time it appeared that a problem was so grave that a learner might leave the experiment if we did not help out.
 Our prompting remained nondirective, and indeed once learners got going we needed to prompt very infrequently.
 Our analysis consisted first of an enumeration of 'critical incidents", constrained by the consensus of the experimenters, which were cataloged and classified in various ways.
 The chief goal of this was to form a picture of the typical experience of a learner, and it is this induced "prototype" learning experience to which we will refer in what follows.
 Learning by doing.
 Our learners relentlessly wanted to learn by trying things out rather than by reading about how to do them.
 Half of our learners tried to sign on to the word processor before reading how to do so.
 In part this was impatience: they were reluctant to read a lot of explanation or get bogged down following meticulous directions.
 But It also devolved from mismatched goals: Learners wanted to discover how to do specific things at particular times.
 and this did not always accord with the sequence in which topics were treated in the manual.
 Learning by trying things out according to a personal agenda of needs and goals is not merely a preference.
 Learners who try to follow out manual instructions are often unable to do so.
 The instruction sequences are fragile in the sense that it is easy to get sidetracked and there is no provision in them for recovery.
 One example is a learner who inadvertently paginated (reformatted) a document at the beginning of an exercise on revising documents.
 This not only rearranged the lines in the file to make right margins even, it also stored the document away.
 The learner had not yet learned how to retrieve documents and the manual itself provided no recovery information for this (or any other) type of error.
 Accordingly, she was forced to try to discover how to retrieve the document on her own.
 Once the document was restored, she was faced with an equally staggering problem: the pagination operation had rearranged the lines of her file so that the revising instructions did not refer to the same document.
 A n experienced user who understood reformatting could have reinterpreted the instructions and adapted them to this rearranged text.
 But this learner had no idea what she had done, and thus was puzzled by the fact that the Instructions seemed to be wrong.
 The fragility of instruction sequences, coupled with the propensity of learners to try to recover by Initiating exploratory forays, can result In problem tangles: Learners, who may not even fully understand the individual operations, have little basis for appreciating the subtle interdependence of clusters of word processor operations.
 They find themselves in distorted or even unrecognizable problem situations.
 W h e n learners do not.
 or cannot, follow directions the problems that arise can result in their losing track of what they are trying to do.
 It is likely, of course, that this loss of task orientation contributes to the overall failure of learning — as indicated by the trouble all learners had applying their learning experiences to the routine typing "transfer task" after training.
 None of the learners were able to type, revise, and print a simple one page letter without some trouble with each of these basic skills.
 What Is more surprising perhaps is that even when learners were able to successfully follow instruction sequences out.
 they still seemed to experience a loss of task orientation, as evidenced by comments like: "What did we do?", "I know I did something, but I don't know what it is!" or "I'm getting confused because I'm not actually doing anything except following these directions.
" For these subjects, the overall orientation toward accomplishing meaningful tasks (e.
g.
, type a letter, print something out) has been subverted by a narrower orientation toward following out a sequence of instructions.
 Learning bj thinking.
 Just as learners take the initiative to try things on their own, so also are they active in trying to make sense of their experience with the word processor.
 Learning passively by rote assimilation of information is atypical.
 Rather, learners actively try to develop hypotheses about why it 0|>erates the way it does.
 These quests after meaning can be triggered by new and salient facts.
 They can be forced by discrepancies between what is expected and what actually happens.
 They can be structured by the learner's personal agenda of goals and queries, referred to as new problems arise.
 In each case, learners' lack of knowledge about word processing makes it difficult for them to reason out coherent solutions that accurately represent the objective operation of the system.
 For example, learners have no basis for recognizing and ruling out irrelevant connections: their interpretations of word processing systems are often influenced by spurious connections between what they think they need and what they perceive.
 In one case, a learner tried to decide if a "File" command had stored a document file away.
 It was not stored because the command was entered in a text input mode where all typed strings are interpreted as text, and not executed as commands.
 But she assumed that the file had been stored, and adduced evidence to confirm this premise.
 For example, at one point she notices a status message "INPUT M O D E 1 FILE" which indicates that she is in the text input mode.
 However, the word "file" matched her file command, and this was enough to suggest some kind of feedback that her "File" (as in store document) command had worked.
 In such cases, reasoning appears to consist in adducing factual support to a premise the learner would like to hold as true.
 The learner above began with the hypothesis that she had stored the document file away, and sought evidence to confirm that this was the case.
 Her adduction here was incorrect because she did not know which facts were relevant to verifying the premise.
 In other cases, reasoning appears to consist in abducing a hypothesis when it, together with other assumptions the learner may already hold, is consistent with some fact or observation.
 One learner tried to move the cursor In a protected area of the display.
 When this locked the keyboard, she hypothesized that this fact meant that she was at the right place on the screen to do what she set out to do.
 94 Learners also set goals which they actively pursue by trying to solve problems.
 They are hampered in this by their Innocence of the appropriate problem space, or domain of possible actions and interpretations relevant to accomplishing goals and addressing queries.
 Accordingly, their strategies are often local and fragmentary; they have difficulty integrating information or other experiences, and in formulating their concerns in ways that map transparently onto system functions.
 When learners cannot solve problems or answer questions, they add them to a personal agenda of goals and queries as they go along.
 As new opportunities arise, learners return to these standing queries and try to resolve them.
 Learning by knowing.
 To this point, we have argued that a new user of a word processing system relies on active exploration and ad hoc reasoning as learning strategies.
 However, not all possibilities are explored and not all hypotheses that could be reached are reached.
 What constrains these strategies is a sense of what could be appropriate ~ and this devolves from prior knowledge on the pan of the learner: knowledge about devices "like" word processors (e.
g.
, typewriters), knowledge about office routine and work in general, even knowledge culled from interacting with the word processor up to that point In time.
 Our learners were unable to resist referring to their prior knowledge about typewriters as a basis for interpreting and predicting experience with word processors.
 One came to a halt as she read an instruction in the manual which said "Backspace to erase.
" It seemed that she could not interpret this instruction for.
 as she pointed out.
 B A C K S P A C E does not erase anything.
 She had irresistibly availed herself of her knowledge of how backspacing works on a typewriter, unable to even consider that this knowledge might be inappropriate for the present case.
 Other learners tried to use S P A C E and R E T U R N keys to move the cursor ~ which insert spaces and blank lines ~ but merely move the typing point on a typewriter.
 Our learners were experienced with conventional office work: typing letters, filing, etc.
 Their knowledge about how these routine tasks are organized in the office creates expectations in them about how analogous tasks ought to be performed in the "office of the future" (as represented by the word processor in our laboratory).
 Thus, one response to revising a letter task is to retype.
 This is striking since it is the capability of the word processor to store and retrieve documents ~ for revision, among other things — that is its fundamental advance over previous office technologies.
 As a learning experience progresses, the learner is acquiring and organizing new bits of knowledge.
 The ultimate goal — and the final measure of success in the learning situation — is that of assembling these pieces into a coherent fabric, an understanding of the word processor.
 Along the way, any prior bit of knowledge is available for use as a basis for expectations concerning successive interactions with the system.
 One system we studied seemed to flaunt Inconsistency in similar operations.
 Thus, to delete a word, one positions the cursor under the word's initial character and keypresses W O R D D E L E T E .
 However, to underscore a word, one positions the cursor under the final character of a word and keypresses W O R D U N D .
 This inconsistency caused one learner to misexecute one and then the other of these two operations in a dismal cycle of negative transfer.
 Summary.
 Perhaps the most apt discussion of the world of the new user of a word processing system is that often quoted phrase of William James: 'a bloomin' buzzin' confusion" People in this situation see many things going on, but they do not know which of these are relevant to their current concerns.
 Indeed, they do not know If their current concerns are the appropriate concerns for them to have.
 The learner reads something in the manual; sees something on the display: and must try to connect the two, to integrate, to interpret.
 It would be unsurprising to find that people in such a situation suffer conceptual — or even physical — paralysis.
 They have so little basis on which to act.
 And yet people do act.
 Indeed, perhaps the most pervasive tendency we have observed is that people simply strike out into the unknown.
 If the rich and diverse sources of available information cannot be interpreted, then some of these will be ignored.
 If something can be interpreted (no matter how specious the basis for this interpretation), then it will be interpreted.
 A d hoc theories are hastily assembled out these odds and ends of paniaily relevant and partially extraneous generalization.
 A n d these "theories" are used for further prediction.
 Whatever initial confusions get into such a process, it is easy to see that they are at the mercy of an at least partially negative feedback loop: things quite often get worse before they get better.
 What's wrong? W e would argue that the learning practices people adopt here are typical, and in many situations adaptive.
 The problem in this particular learning situation is that new learners of word processors are innocent in the extreme.
 "Word processor", so far as we know, is not a natural concept.
 People who do not know about word processors have little, possibly nothing, to refer to in trying to actively learn to use such things.
 Innocence turns reasonable learning strategies into learning problems.
 95 EXAMPLES IN THE LEGAL DOMAIN: HYPOTHETICALS IN CONTRACT U W Edwlna L.
 Rlssland* Department of Computer and Information Science University of Massachusetts Amherst.
 MA 01003 Abstract In this paper, we discuss the use of examples in the law, in particular "hypotheticals" in contract law.
 We present a framework for representing examples, show how this can be used to generate new hypotheticals, and discuss their role in the dialectic of refining or learning legal doctrine.
 1.
 Introduction Oplnlona.
 Links to other cases.
 Links to legal doctrine/rules/statutes.
 A slot can have a simple filler, as In the Title, Citation or Date slots, or a complex one as in the Opinions which can be structured into main, concurring, and dissenting opinions.
 Links to other cases Include "procedural history" links, like affirmed, reversed, amended, and "substance" links, like criticised, distinguished, explained, harmonized, etc.
, which describe how the courts through their opinions related the cases.
 Examples are important in many disciplines like mathematics, law and linguistics.
 They are central to reasoning and learning processes such as induction, concept formation, rule refinement and theory formation [Hawkins 1980; Kuhn 1970: Lakatos 1976; Lenat 1977; Polya 1965; 1968; Rlssland 1978.
 1982; Soloway 1978; Winston 1975].
 In the law, where much reasoning is done by example [Levi 19'»9] and analogy [Bernan 1968], examples — i.
e.
, cases — are indispensable.
 Examples force one to consider possibilities and nuances.
 In teaching a legal doctrine, they are used to point out its "gaps, conflicts and ambiguities" [Kennedy 1980].
 They are used in restatements of the law, which are compendia of legal doctrine in the form of principles, examples and references, e.
g.
, Restatement, Second.
 Contracts [1981].
 They are critical to the "realist number" which shows both that the law is much more than a set of clearcut concepts and rules [Llewellyn 1931], as the formalists of this century and before had hoped.
 2.
 Epistenological Considerations The examples in the law that we consider are of two types: (1) "real" cases, i.
e.
, oases actually litigated; and (2) "hypothetical" cases ("hypotheticals" or "hypos").
 Both types can be represented by a franelike data structure [Mlnsky 1975] and the frames can be linked together by various types of relations.
 In describing frames for cases, we are laying out a conceptual framework to represent the knowledge used by students and teachers of the law.
 The frame for a real case includes the following slots: Title, Citation, Date, Fact Situation.
 Process Hi story/Outcomes, Arguments, •Supported in part by the National Science Foundation under grant IST80173t3.
 Opinions expressed in this report are those of the author and do not necessarily reflect views of the U.
S.
 Government.
 Hypotheticals can also be represented by a frame.
 The most important features of a hypo are the Fact Situation, the Arguments that interpret the fact situation with respect to particular legal doctrines, and the links to other hypos and real cases.
 Thus the frame for a hypo is like that for a real case.
 The links between a hypo and a real case include "abstracted from".
 "particularized from".
 "general1zed from".
 One can also make a taxonomy of cases in the law, much as in mathematics [Rlssland 1978].
 Such a taxonomy is not explored here, but the categories might include: 1.
 standard oases (typically found in the casebooks); 2.
 landmark cases that have far reaching effects; 3.
 first impression cases that bring up an issue for the first time; 4.
 counter cases that show the limits of or the invalidity of a rule or doctrine; 5.
 anomalous cases that don't seem to fit in.
 While we have used some of the link types used in LEXIS [Sprowl 1976] and legal digests and case citators like Shepard's Citations, the framework and taxonomy we have described could be used to design a legal data base that reflects more of the structure of the law than those currently in use.
 3.
 Hypotheticals in Contract Law In contract law, one master question is "Which promises should the law enforce?", where enforcement means either making the promisor fulfill his promise to the promisee (i.
e.
, "specific performance") or make the promisor pay "damages" to the promisee for his breach [Fuller and Elsenberg 1981; Knapp 1976].
 There are several ways of dealing with this question.
 The "giftconsideration" distinction tries to relate enforceability with the "consideration" given by the promisee in return for the promise [Section 17, Restatement.
 Second, Contracts]: 96 ".
.
.
the formation of a contract requires a bargain in which there is.
.
.
consideration.
.
.
" Another approach is that of "reliance" in which the (typically injurious) reliance of the promisee upon the promise is highlighted [Section 90, Restatement.
 Second, Contracts].
 A third is the use of "formalities" like the legal seal [Section 96].
 Each of these ways of looking at the master question emphasizes different aspects of a promise and each has its own stengths, weaknesses, inconsistencies and ambiguities.
 The following is a set of hypos (actually just the fact situations) typical of those used in law school to: (1) point out the giftconsideration distinction; (2) show doctrinal weaknesses and ambiguities; and (3) show possible conflicts between doctrines such as consideration and reliance.
 The hypos are really caricatures of the real case of Dougherty v.
 Salt, decided by the N.
 Y.
 Court of Appeals In 1919, which is a standard case in first year Contract Law (e.
g.
, see [Fuller and Eisenberg 1981]).
 In each of the hypos, one is to ask, "Is this promise enforceable?" In other words, if the promisor breaches, ought the promisee be awarded damages or performance? Hypol: Facts: Aunt Tlllle says, "Charlie, you are such a nice boy; I promise to give you $10,000.
" Hypo2; Facts: Same as Hypol with the addition that Charlie says, "Dear Aunt Tillie, I can't take something for nothing, let me give you my third grade painting.
" Facts: Same as Hypo2 except Charlie offers to mow T i m e ' s lawn.
 Hypo«: Facts: Same as Hypo2 except that Charlie's last name Is Picasso.
 Hypo5 introduces an emotional "heart rendering" aspect to show there are limits and exceptions to consideration doctrine, such as duress.
 Hypo6 introduces an element of reliance which leads to conflicting outcomes from reliance and consideration argumentation.
 U.
 A Frame for Promise Hypos In applying the framework of Section 2 for the domain of contract law, we used the following facets in the subframe for the fact situation of a "promise" case: 1.
 the status of the PROMISOR 2.
 the subject matter of the PROMISE 3.
 the status of the PROMISEE H.
 the RETURN ACTION by the promisee 5.
 the RELATION between the promisor and promisee The full frame of the case would also include: 1.
 ARGUMENTS for various outcomes of the hypo according to various doctrines: 2.
 further NOTES/DISCUSSION of the hypo.
 such as historical significance; 3.
 REUTIONS to other cases (real and hypothetical).
 Each of these major subblocks has facets; those for the PROMISOR and PROMISEE are similar; those for PROMISE and RETURN somewhat so.
 The PROMISOR and PROMISEE can be further described by such attributes as PERSONAL STATUS, INTENTIONS and BARGAINING POWER, which can be further broken down.
 For instance, PERSONAL STATUS includes SEX.
 AGE.
 MARITAL STATUS (these are for largely traditional.
 historical and common law reasons related to the once unequal status of women under the law).
 The description of the PROMISE Includes the subject matter of the promise and conditions on it.
 The RETURN action of the promisee can be: (1) no action; (2) forbearance (i.
e.
.
 refraining from doing an act, like suing); (3) an action.
 An action Itself has aspects like: (1) the action benefits or does not benefit the promisor; (2) the action leaves the promisor worse off/better off/the same.
 Hypo5: Facts: Same as Hypol with the addition Aunt Time's assets are in ruin and that keeping her promise to Nephew Charlie means her own children starve.
 One can also structure the RELATION facet of the promise situation for instance according to whether it is familial (e.
g.
.
 fatherdaughter) or nonfamilial (e.
g.
, debtorcreditor, friends or neighbors).
 Hypo6: Facts: Same as Hypol with the addition that Charlie makes an unreturnable deposit on a new car.
 If one argues from the standpoint of consideration doctrine, Hypol is a paradigmatic example of a pure gift, "a gratuitous promise".
 which would not be enforceable.
 Hypo2 is an attempt to make Hypol look enforceable under consideration doctrine.
 Hypo3 is another attempt to alter Hypol into an enforceable promise.
 Hypo4 is used to point out that one is making value Judgements on the consideration per contra the doctrine that one should not inquire into the adequacy of the consideration.
 'The following is a fact situation subframe instantiated for the first Aunt Tillie  Nephew Charlie hypo: PROMISOR: Aunt Tlllle PERSONAL STATUS: female, elderly, widow PERSONAL ATTRIBUTES: kind, rich INTENTIONS: the best PROMISE: $10,000 CONDITIONS: none PROMISEE: Charlie STATUS: male, young RETURN: none REUTION: FAMILIAL: AuntNephew 97 5.
 Generating Hypotheticals It is apparent that one can generate new hypotheticals — that is their frames — by changing slot fillers in a hypothetical frame.
 Since the possible fillers for a slot can often be arranged in hierarchies, many modifications can be described in terms of super, sub and sibling node substitution and thus lead to modifications affecting generality and specifity.
 For instance, generalizing Tillie and Charlie to abstract individuals A and B results in the following: Hypol': A promises B $10,000.
 Making another change gives: Hypol": "JR" promises B $10,000.
 In the last, knowing that "JR" (as in Ewing) often has bad intentions creates a hypo very different in "feeling" from the "Aunt Tllle Nephew Charlie" or "A promises B" hypos; the "JR" hypo introduces questions of "good/bad faith".
 Elaborating the description of any of the elements of the fact situation is another way a creating a new hypo.
 For instance, elaborating "Aunt Tille" to "old, senile Aunt Tillie" and "Charlie" to "manipulative, blacksheepofthefamily Charlie" gives a very different character to the hypo.
 6.
 Computergenerated hypos We are currently investigating the generation of hypotheticals using the CEG (Constrained Example Generation) method of "retrieval plus modification".
 in which a new example is generated by retrieving a known example (that comes close to what is wanted) and then modifying it to meet the current requirements [Rissland and Soloway 1980.
 Rlssland 1982].
 So far, we have been dealing only with constraints such as "more/less general/specific" "different but of the same class" (e.
g.
.
 familial).
 Higher level constraints are "heart rendering", "more/less surprising" (e.
g.
, against one's default assumptions).
 We are experimenting with ways to generate three or four sentence long hypos similar to those found as exercises in casebooks and as illustrations in the Restatements.
 To produce the English text from the frame, we are currently using sterotypical precanned text templates and then filling in the templates with information from the hypo frame.
 An example of such a template filled in the most general way is: " A promises B X in return for Y .
" More sophisticated — longer and subtler — hypos will need more sophisticated text generation such as McDonald's MUMBLE [McDonald 1981].
 7.
 Summary and Conclusions We have been studying the structure of legal knowledge, specifically real and hypothetical cases, using a structural approach of frames and relations and how one generates hypotheticals; we have actually experimented with our ideas in the domain of Contract Law, we feel that these methods are easily transferable to other domains such as Property and Torts.
 We feel our work contributes to: (1) a better understanding of the use.
 structure and generation of examples in general and legal hypotheticals in particular: (2) epistemological analysis of legal domains; (3) legal data base design; (U) hypothetical generation for teaching and ICAI (Intelligent Computer Assisted Instruction) systems.
 8.
 References Berman, H.
 J.
, "Legal Reasoning".
 In International Encyclopedia of the Social Sciences^ Fuller, L.
 L.
, and M.
 A.
 Eisenberg, Basic Contract Law.
 West Publishing Co.
, Minn.
, 1981.
 Hawkins, D.
, "The View from Below".
 For the Learning of Mathematics.
 Volume 1, NoT 2, FLM Publishing Association, Quebec, Canada, November 1980.
 Kennedy.
 D.
, "Utopian Proposal".
 Harvard Law School, 1980.
 Draft memo.
 Knapp, C.
 L.
.
 Problems in Contract Little, Brown and Co.
, 1976.
 Law.
 Kuhn.
 T.
 S.
, Thi Structure of Scientific Revolutions.
 Second Edition.
 University of Chicago Press, 1970.
 Lakatos.
 I.
, Proofs and Refutations.
 Cambridge University Press, London.
 1976.
 Lenat, D.
 B.
.
 "Automatic Theory Formation in Mathematics".
 Proc.
 IJCAI77.
 Levi, E.
 H.
, An Introduction to Legal Reasoning.
 University of Chicago Press.
 McDonald.
 D.
 D.
, "Language Production: The source of the dictionary.
" In The Nineteenth Annual Meeting of the AssociatTon for Computational Lingistics, Stanford University, 1981.
 Mlnsky, M.
 L.
, "A Framework for Representing Knowledge".
 In The Pysehology of Computer Vision, Winston (ed), McGrawHill, 1975.
 'Polya.
 G.
.
 Mathematical Discovery.
 Volume II.
 Wiley, Mew York, 1965.
 Polya, G.
, Mathematics and Plausible Reasoning, Volumes I and II.
 Princeton University Press.
 1968.
 Restatement, Second, Contracts.
 American Legal Institute.
 Philadelphia.
 1981.
 Rissland.
 E.
 L.
.
 "Constrained Example Generation".
 Submitted for publication.
 1982.
 Rissland.
 E.
 L.
, "Understanding Understanding Mathematics".
 Cognitive Science.
 Vol.
 2.
 No.
 «.
 1978.
 98 Hissland, E.
 L.
, and E.
 M.
 Soloway, "Overview of an Example Generation System".
 In Proc.
 First National Conference on Artificial Intelligence.
 Stanford, August 1980.
 Soloway, E.
 M.
, "Learning s Interpretation + Generalization: A Case Study in KnowledgeDirected Learning".
 COINS Technical Report 7813, University of Massachusetts, 1978.
 Sprowl, J.
 A.
, A Manual for ComputerAssisted Legal Research.
 American Bar Foundation, Chicago, 1976.
 Winston, P.
 H.
, "Learning Structural Descriptions from Examples" in The Psychology of Computer Vision, Winston (ed), McGrawHill.
 1975.
 99 Learning Recursive Procedures by Middleschool Ciiiidren^ Yuichiro Anzai CarnegieMellon University & Keio University and Yuzuru Uesato Keio University Introduction Recursion is a recurrent ttieme in human thinking.
 It has been around tor a long time in some fields related to cognitive science: for instance, it has taken place in informationprocessing models of cognition, in the theory of computation, in cognitive and developmental psychology, or in teaching computer progrsunming to novices.
 Intuitively, recursive formulation may lead to understanding of potentially infinite phenomena In compact, finite terms.
 On the other hand, since recursive definition involves topdown, tightly connected organization of knowledge, it may not be easy to learn, or to be applied to formulation of complex problems.
 These expectations, however, are less well examined experimentally.
 Besides, there are some other points such as memory load for executing recursive procedures, the firmly established character of recursive functions in the theory of mathematics, or practical application to teaching computer programming, which make recursion an interesting theme for cognitive science.
 As one topic related to recursion, this paper discusses the question of whether recursive procedures are cognitively difficult to learn, based on a rule induction experiment conducted on middleschool children.
 It concludes that racursive procedures may be acquired based on learning of the corresponding Iterative procedures.
 Learning Recursive Procedures A recursive function treated here is simply a function whose definition includes the function itself.
 As a simple but representative example, we use exclusively in this paper the factorial function 'tact" defined on N, the set of positive integers, as follows: factin) = fact(n•^) x n for any ntN, ̂ >^, and /acf(1) » 1.
 The above definition is recursive, but of course tact can be defined itcrativoly: lact{n) = 1 X 2 X .
 .
.
 x n for any neN.
 The above two kinds of definitions are functionally equivalent, but have many cognitivcly different points.
 Let us consider below only the point relevant here: how people acquire the recursive procadure for computing factorials, based on example data.
 First, suppose that a student is given an iterative sequence of data for factorieils: fact{>) = 1 lact(2) = 1 x 2 lact{3) = 1 x 2 x 3 .
 It may be easy for him to generalize the above simple patterned sequence, and to obtain the general iterative definition, /acr(r7) = lx2x.
.
.
xn (niN).
 Note that the induced definition itself can easily be interpreted to provide procedures (multiplications) for actual computation.
 On the other hand, suppose that the student tries to induce the factorial function based on the following recursively generated data: /acf(3) /acf(2) X 3 tact(2) = tact{^)x2 /acf(1)  1.
 In this case, although the data, if regarded declarative, can be generalized formally to generate /acr(n)«/ac/(n1)xn (neA/), the student needs to consider all the subformulas, tacHk)  lact{k\)xk (k>2 n1), to actually compute tact{n): the data allow direct generalization by converting, for example, 3 to i and 2 to n1, but he is necessary to organize the given segments of data to acquire the recursive computational procedure.
 It may be much more difficult than in the iterative case.
 However, w e can advance our speculation one more step.
 The student, while he is engaged in the task of inducing the factorial from the iterative data, might notice the regularity of embedded pattern in the data.
 The left column of Fig.
 1 illustrates it for an iterative data set.
 If this kind of structural emtiedding was discovered, acquisition of the iterative definition of the factorial may result In learning the nested procedural structure of the factorial.
 Then, if the nested structure as shown in the left of Rg.
 1 resides in memory, and if recursive data are presented, the data may match the nested structure fairiy eatsily as shown in Fig.
 1.
 Thus, the recursive procedure may be learned by the successive presentation of the iterative and recursive data sets in this order.
 '1 iact(\}x2 f=^tact{2}A3 Thanks are due to John Anderson, Robin Jeffries and Herbert Simon for their comments on this work.
 Please address correspondence to Yuichiro Anzai, Faculty of Science and Technology, Keio University.
 3141, Hiyoshi, Kohoku, Yokohama, Japan.
 Nested structure emtiedded in an iterative data set and its relation to the corresponding recursive data set The preceding simple discussion gives us the hypothesis that if a student knew none of the factorial function, or the concept of recursion, he finds it easier to learn the iterative procedure for the factorial rather than the recursive one, but after he learned it, he must already be ready to assimilate the recursive procedure.
 In the follovying rule induction experiment, we examine this hypothesis by using middleschool children.
 Experiment Subjects and procedure 88 middleschool children (age about 14) participated in the experiment.
 The rule to be induced was the numerical function for computing factorials of positive integers.
 Two kinds of formats for example data were considered.
 One was the iterative format, and the corresponding tobeinduced function was called WHITE in the experiment.
 The other was the recursive format, and the corresponding function was named BLACK.
 For each format, a sequence of three data sets was prepared.
 The first data sets for WHITE and BLACK were given as follows: First data set for W H I T E Let us think about the following computation for a given number.
 The answer to the computation is called "WHITE" For example, "WHITE of 2" is computed as follows: (1) Start with 1.
 (2) Multiply 1 by 2.
 The result is 2.
 100 ••WHITeof2"isZ.
 Now, compute 'WHITS of <".
 (Write the computation and the answer.
) First data set for B L A C K Let us think about the following computation lor a given number.
 The answer to the compulation is called 'BLACK' For example.
 "BLACK of 2" is computed as followa: (1) 'BLACK of 2' is "BLACK of T multiplied by 2.
 (2)'BLACK of ris 1.
 "BLACK of 2is Z Now.
 compute 'BLACK of 4'.
 computation and the answer.
) (Write the In each of the above data sets, two segments of information, (1) and (2).
 for the factorial of 2, and the value of it were supplied.
 There was provided a problem at the last line, which was to compute the factorial of 4.
 If a subject gave the correct answer to the problem, then he was considered to have acquired a factorialcomputing procedure, iterative or recursive, depending on which data set, WHITE or BLACK, was presented to him.
 The second data sets for WHITE and BLACK included three segments of information, and were designed as shown below: Second data set for WHITE Let us think about the following computation for a given number.
 The answer to the computation is called "WHITE" For example.
 "WHITE of 3" is computed as follows: (1) Start with 1.
 (2) Multiply 1 by 2.
 The result is 2.
 (3) Multiply 2 by 3.
 The result is 6.
 "WHITE of 3'is 6.
 Now.
 compute "WHITE of 5".
 (Write the computation and the answer.
) Second data set for BLACK Let us think about the following computation for a given number.
 The answer to the computation is called "BLACK'.
 For example, 'BLACK of 3' is computed as follows: (1) 'BLACK of 3" is "BLACK of 2' multiplied by 3.
 (2) 'BLACK of 2" is "BLACK of 1' multiplied by 2.
 (3) "BLACK of 1" is 1.
 "BLACK of 3'is 6.
 Now, compute "BLACK of S" (Write the computation and the answer.
) The third data sets, each of which contained four segments of information, were defined in a similar manner.
 The subjects were divided into two groups called G1 (n3 4S) and G2 (n s43).
 The group G1 was given the data in the order of Wl, W2.
 W3.
 B1, B2 and B3.
 where Wi and B/ denote the /th data set for WHITE and BLACK respectively.
 On the other hand, G2 was given the data in the order of B1, B2, B3, W1.
 W2 and W3.
 Both groups were given five minutes for each data set, which were ample enough for middleschool children.
 The data sheets were collected from the subjects for each data set, and no direct feedback of answers was given.
 Results and discussion The results are tabulated in Table 1.
 The more data sets presented, the greater number of subjects who answered correctly, both for WHITE and BLACK.
 The percent correct was larger for Gl's WHITE (60% for the third set) than for G2's BLACK (33% for the third set), but even the latter gave fairly good performance.
 Also, if the data for BLACK were presented after WHITE as for the group Gl, the performance was better than its opposite: G1 for BLACK gave 16%, 2 9 % and 6 4 % of percent correct for the data sets with two, three and four segments of information, but G2 for BLACK provided 0%, 1 4 % and 33%, which were relatively smaller.
 On the other hand, the performace for WHITE was similar for the two groups, regardless of the order of presentation.
 The result is ttius generally in agree with our expectations.
 It was easier for the children to have worked on the iteratively generated data sets, but acquisition of the recursive procedure was facilitated by learning the iterative one.
 Also, note that the WHITE data for Gl and G2 show a similar tendency, and the BLACK data for the two groups provide a different sort of similar tendency: the rale of increase of the percent correct decreased for the WHITE data with respect to the number of presented data sets, while it increased for ttie BLACK data.
 This particular trend may have reflected the subjects' relative difficulty in discovering regularity in a small number of information segments in a recursive data set.
 Table 1 Percent correct for the induction experiment Gl Data sat no.
 WHITE BLACK 62 BLACK VIHITE 1 2 3 11(«) 42 80 18 29 84 0 14 33 9 30 47 No.
 of subjects 46 43 (For almost all the subjects, if a subject gave the correct answer for the /th data set, he was also correct for all the itb sets, where 1<, /</.
) Thus, we think that recursive computation may be apparently difficult for children to learn, but also that it may tie acquired by inducing the nested structure, and interpreting it as a procedure, based on the recursive data.
 Let us provide one possible mechanism that generates the gross characteristics of the experimental results, which is essentially similar to the one briefly described in the previous section.
 Suppose that the third data sets for WHITE and BLACK given in the experiment were represented as followK WHITE BLACK (equal (times 1 2) 2) (equal (black 4) (times (black 3) 4)) (equal (times 2 3) 6) (equal (black 3) (times (black 2) 3)) (equal (times 8 4) 24) (equal (black Z) (times (black 1) 2)) (equal (white 4) 24) (equal (black 1) 1).
 Assume that successively emtsedding the segments in the WHITE data set, we obtained the nested formula: (equal (white 4) (times (times (times 1 2) 3) 4)).
 Note that if we identify (times (times 1 2) 3) with (black 3).
 and also identify "white" with "black", then the formula matches the first segment In the above BLACK set: (equal (black 4) (times (black 3) 4)).
 This kind of correspondence holds also for the first and second data sets.
 Generalization at this point, which yields the correspondence between (times (times (.
.
.
 (times (times 1 2) 3).
.
.
) n1) n) and (black n), provides the procedural basis for the recursive definition of the factorial function, which is based on nested arithmetic calculation.
 101 D i s c u s s i o n The relation between conceptual and procedural understanding in problem solving has raised many issues complex but central for cognitive science.
 At some deeper level of understanding, a person can both handle with knowledge procedurally, and appreciate it declaratively.
 Recursion provides a simple example for this matter since it is usually formulated in a compact fortn, its declarative representation may be simpler than the corresponding iterative form.
 But such declarative representation must be accompanied by procedural knowledge for actual computation, and this knowledge might be cognitively complex.
 The argument presented in this paper suggests that such knowledge can be acquired not directly, but by working on iterative data.
 An example of the process of learning a recursive strategy by discovering a nested structure in knowledge of results obtained by weaker, nonrecursive strategies was presented in Anzai & Simon (1979).
 The strategy acquisition process reported there is essentially similar to the recursion learning process discussed in this paper the thesis shared by the two studies is that complex recursive procedures for solving a problem may be acquired by working on the problem, using already available, nonrecursive knowledge.
 Which way of learning, by discovery or by instruction, Is better has long been a controversial problem in instructional psychology.
 Learning by doing, which is along the line discussed here and in Anzai & Simon, is basically a process of learning by discovery.
 In this regard, as suggested in this paper, recursive procedures may be learned by discovery.
 Recursive computation may be intrinsically more difficult than iterative one, since execution of recursive procedures may require more memory resources.
 But it does not mean that they can not be acquired by discovery.
 However, of course we do not deny the possibility of learning recursive procedures by topdown instruction.
 The two ways of learning are actually complementary in the real world, and both ways may play important and intertwined roles.
 Also, we should be cautious when we try to extend the consideration to more complex domains such as computer programming.
 It is because a complex task necessarily involves many different cognitive subprocesses, and it is not always easy to extract from them only the part played by recursion.
 Reference* Anzai, Y.
 4 Simon, H.
 A.
 1979 The theory of learning by doing.
 Psychological Review, 86,124140.
 102 Prior Knowledge Occupies Cognitive Capacity in Chess Problem Solving, Reading, and Thinking By Bruce K.
 Britton and Abraham Tesser Abstract Prior knowledge was varied in problem solving, thinking, and reading tasks in three experiments.
 The hypothesis was that the prior knowledge used in a cognitive task uses capacity in the same limited capacity active processing system that is used to process the ongoing task.
 In a reading experiment, prior knowledge about a target page was manipulated by controlling the preceding pages.
 In an experiment dealing with problem solving in the context of a chess game, prior knowledge was controlled by comparing experts with novices.
 In a third study subjects thought about personality descriptions of persons and groups, and about women's fashions and football plays; it was assumed that persons have more prior knowledge concerning the personality of persons than the personality of groups, that women have more prior knowledge about women's fashions, and that men have more prior knowledge about football.
 In all experiments, use of cognitive capacity in task performance was observed with a secondary task technique.
 The results of all three experiments were consistent with the hypothesis that prior knowledge uses capacity in the active processing system.
 The prior knowledge hypothesis is consistent with some aspects of current cognitive theory but not consistent with others.
 The results also suggest a fundamental and unexpected limit on the cognitive processing of experts.
 Information processing theories of cognitive processing often assume that memories of prior experience are stored over the long term in a relatively inactive state.
 They also assume that the cognitive task that is undergoing processing at a particular time is being processed in an active processing system, which some models identify as a working memory or short term memory store.
 When stored prior knowledge is to be used in the performance of a particular cognitive task, the prior knowledge is brought from the inactive state into an active state.
 In this active state the prior knowledge can be effectively used in performing the ongoing cognitive task.
 In the standard model (e.
g.
, Atkinson & Shiffrin, 1968) this change of state of prior knowledge is usually represented in a flow chart as an arrow leading from a long term memory store (the inactive memory) to a short term or working memory (the active processing system).
 Other models of cognitive processing include a similar assumption; although the metaphor of a spatial transfer of information is not always used, some change in the state of activation of the prior knowledge is expressed with other metaphors.
 The active processing system is widely believed to be limited in capacity (Broadbent, 1958, 1971; Navon & Gopher, 1979; Norman & Bobrow, 1975; Posner, 1978).
 If the active system is limited in capacity, then it is plausible to deduce that any prior knowledge that is active in it will use some of the limited capacity.
 This paper reports three tests of the hypothesis that the prior knowledge used in an ongoing task uses cognitive capacity in the same active processing system that is used to perform the ongoing task.
 This will be referred to as the prior knowledge hypothesis.
 The prior knowledge hypothesis has not been included conventionally among the explicit assumptions of cognitive processing models.
 Perhaps this is because the standard model and related models have traditionally assumed a small limit on the capacity of short term memory, with estimates ranging from 2 chunks up to 20 (Lachman, Lachman & Butterfield, 1978).
 It appears that with even a 20 unit limit, a body of prior knowledge of a size or complexity that approached that limit ~ for example, the chess knowledge of an expert chess player — if transferred to a short term store, would occupy so much of it that little or no capacity would be left over for performing the ongoing cognitive task.
 The result would be error, delay or failure on the task.
 Cognitive psychologists may have believed that this outcome did not seem likely to occur, and so the prior knowledge hypothesis may not have seemed easily compatible with models that include a small limit on the capacity of the active processing system.
 Other cognitive models are less explicit about the capacity of the active processing system, so evidence that large bodies of activated prior knowledge use capacity would be less critical for them.
 Because the hypothesis that prior knowledge uses capacity in the active processing system has not been prominent in cognitive theory, the consequences of it have not been thoroughly worked out, and some of them turn out to be interesting.
 One set of consequences is related to the use of cognitive capacity by persons who do or do not have prior knowledge about a particular cognitive task, i.
e.
, experts and novices.
 The cognitive programs of experts and novices have been investigated by protocol analysis techniques (e.
g.
, Ericsson & Simon, 1980), but these techniques do not provide data on capacity usage.
 In the present experiments the secondary task technique was used.
 This technique was designed to provide data on capacity usage.
 The prediction of the prior knowledge hypothesis is that experts will use more capacity than novices when they are performing cognitive tasks for which the experts have activated large amounts of prior knowledge.
 Apparently this prediction has not been tested previously.
 To test this prediction of the prior knowledge hypothesis, in two of the experiments reported here, 'experts' on chess, and on football, women's fashions and implicit personality theory were observed as they processed problems in their special topics and in topics in which they were not experts.
 Use of cognitive capacity was measured with a secondary task technique.
 In a third experiment, differences in prior knowledge about a text topic were induced in readers and the use of capacity was observed in reading later parts of the text.
 Another interesting consequence of the prior knowledge hypothesis is that it suggests the existence of a potential limitation on the cognitive processing of experts.
 If an expert has an extremely large amount of activated prior knowledge for a particular task, the knowledge will presumably use a correspondingly large amount of capacity.
 If the prior knowledge uses enough capacity, the capacity available for the ongoing cognitive task will be reduced: this follows from the assumption of a limited capacity, A straightforward prediction is that the ongoing task will be performed more slowly by such an expert with a very large amount of prior knowledge than by a person with less prior knowledge (assuming the prior knowledge is adequate to perform the task).
 In extreme cases of prior knowledge, so much active capacity may be occupied that the expert may not be able to complete the cognitive task at all.
 Such an hypothesis could be used to account for: (1) the long periods of time taken by extremely know103 ledgeable experts to solve problems that are solvable in less time by somewhat less knowledgeable experts, (2) the decreases in scholarly productivity that are sometimes reported anecdotally when scholars reach extremely high levels of expert knowledge about their special subject, (3) the Incubation effect in problem solving, in which problem solvers who take time off from a thoroughly studied problem, presumably allowing some prior knowledge to be deactivated, report that when they return to the problem, they have an increased chance of solution, (4) the reduction of usable cognitive capacity that may be associated with aging individuals, who presumably have large amounts of prior knowledge.
 A possible qualification of this extension of the prior knowledge hypothesis is that experts seem likely to be able to chunk their knowledge more efficiently than novices, and chunks would presumably occupy less capacity.
 But in a very high level chunk, the usable information may not be visible on the surface.
 In order to reach a level of information that actually can be used in the performance of the ongoing task, the chunk may have to be unpacked to the point where usable information 1s revealed (Estes, 1972; Johnson, 1972).
 The unpacking process may use additional capacity that the less expert can avoid.
 It should be noted that such extreme cases of prior knowledge were not included in the present studies.
 The levels of prior knowledge used in the present studies may be regarded as intermediate in size between the levels of novices and those of high level experts, and decreases in performance of the ongoing task were not expected.
 It is well to state at the outset what conclusions can be drawn from the various possible outcomes of the tests proposed here.
 If the prior knowledge is not shown to use capacity, that Is consistent with the hypothesis that the cognitive task Is performed in one active system, and the prior knowledge is active in a quite different system that does not share capacity with the first.
 If prior knowledge is shown to use capacity, that is consistent with the hypothesis that both the cognitive task and the prior knowledge are using capacity in the same active processing system.
 The results of all three experiments were that subjects took longer to react to secondary task probes in the high prior knowledge conditions.
 Thus, the results of these experiments were all consistent with the hypothesis that the prior knowledge that Is used in an ongoing cognitive task occupies capacity in the same limited capacity system that is used to perform the cognitive task.
 There are several aspects of the cognitive handling of prior knowledge that may make use of capacity.
 First, the retrieval of the bodies of knowledge from inactive memory may use capacity.
 The retrieval process presumably includes both search and decision components.
 Such a retrieval process may only occur once, at the beginning of the involvement of prior knowledge in the ongoing task, or it may be going on more or less continuously during performance of the task.
 Multiple retrievals would use capacity over a longer span of time than would a single retrieval episode.
 Second, once a particular body of knowledge has been confidently located, its change of state from an inactive to an active status may use capacity.
 Third, once that activation has occurred, the maintenance of the activated state may be necessary, at least if the active state has rapid decay properties like those of conventional short term stores.
 The maintenance may be continuous, it may be periodic, as if the activation is regularly 'refreshed,' or it may be intermittent and dependent on the time course of use of the knowledge in the task.
 Fourth, the elements of the activated body of knowledge themselves are likely to occupy capacity, and the more extensive the knowledge is, the more elements it has, and the more capacity it can be expected to occupy.
 Finally, the use of prior knowledge in the performance of the cognitive task may require additional cognitive operations that use capacity.
 These may involve the unpacking of chunks, searches through them, and decision processes associated with their use in the ongoing task.
 Or the prior knowledge may be in the form of programs of cognitive operations that are to be carried out as part of the cognitive task.
 Such programs enable additional operations, and these may use capacity.
 The results reported here clarify the interpretation of some previous research on the use of cognitive capacity in reading.
 In a series of investigations of the influence of text characteristics on the use of cognitive capacity in reading, it was found that easy passages used more capacity than difficult ones (Britton, Westbrook, & Holdredge, 1978), where ease and difficulty were defined by cloze tests and ratings.
 This finding has been replicated (Britton, 1980; Britton, Zeigler.
 & Westbrook, 1980).
 It has been pointed out by Anderson and Armbuster (in press) that the easy passages used in those studies were about topics for which readers are "more apt to have available schemata or perspectives .
 .
 .
 than are those from the difficult passages.
" (p.
 IS).
 This interpretation is similar to the notion, based qn the present results, that the readers had prior knowledge about the easy passages.
 The results of Britton, Graesser, Glynn, Hamilton, and Penland (in press) on genre differences can be interpreted along the same lines, as can the results of Britton, Westbrook, Holdredge and Curry (1979) that passages with more discourse level meaning (but identical to passages with less discourse level meaning) used more capacity.
 Some limitations of these conclusions should be noted.
 First, they may only apply to complex bodies of prior knowledge, and probably not to isolated individual units.
 For such units, the retrieval, activation, maintenance and use of the knowledge may require so few cognitive operations that no observable capacity is used.
 Also, if the use of the prior knowledge is very highly practiced it may use less capacity (Shiffrin & Schneider.
 1977; Schneider & Shiffrin, 1977).
 Second, there appears to be a special case of combinations of prior knowledge and cognitive task for which prior knowledge will probably reduce use of capacity.
 These are tasks for which the completed solution of the task is already stored in memory and is easily accessible.
 For example, if the subject is asked to multiply 37 x 8, many mental operations will be carried out to arrive at the correct answer of 296.
 But if the subject is immediately asked again to multiply 37 x 8, the prior knowledgeof the answer will be retrieved from memory, and the effect will be to reduce the number of mental operations and so the use of capacity.
 104 Dynamic Construction of Finite Aucomata From Examples Using HlllCllmbing Masaru Tomlta Computer Science Department CarnegieMellon University Pittsburgh, Pennsylvania 15213 Abstract The problem addressed In this paper is heuristIcallyguided learning of finite automata from examples.
 Given positive sample strings and negative sample strings, a finite automaton is generated and incrementally refined to accept all positive samples but no negative samples.
 This paper describes some experiments in applying hillcllmblng to modify finite automata to accept a desired regular language.
 We show that many problems can be solved by this simple method.
 We restrict our problem domain to be only over {1,0}*.
 Furthermore, since every nondeterministic finite automaton has an equivalent deterministic finite automaton (see [7]), we deal only with deterministic finite automata, that Is, there is at most one 1arrow and one 0arrow from each state.
 Thus, in this paper, the terms "finite automaton", "automaton" or "machine" all mean "deterministic finite automaton".
 Given a string s, if there is a transition from the Initial state to any of the final states, then s is accepted by the machine, otherwise s is rejected.
 For example, the machine of the sample problem Is shown in figure 1.
 1.
 Introduction Consider the following problem: Describe the property that all strings in the rightlist have but no string in the wronglist has.
 Does a string (1 1 0 1) have this property? You may answer the question by using any of the following: English, a regular expression, or a finite automaton.
^ 0 (1) (0) (01) (11) (0 0) (100) (110) (111) (000) (100100) (1 1000001 1 100001) wronaligt (10) (101) (010) (1010) (1110) (1011) (10001) (111010) (1001000) (1 1 1 1 1000) (01 1 1001 101) (11011 1001 10) (111101 10001001 1 100) It might be possible to construct the machine by a "typical" schemafilling method (i.
e.
, finding rough property in the samples first, comparing these strings carefully).
 However, in this paper, ^The answer is strings over (1 + 0)* without odd number of consecutive O's AFTER odd number of consecutive I's.
 Therefore ( 1 1 0 1) has the property.
 we try to construct the machine directly by searching in the problem space (i.
e.
, a set of all finite automata) using hillclimbing, rather than by analyzing the samples carefully.
 One of the biggest advantages of blllclimblng is its simplicity, that is, we do not have to know our problem space well, while a "typical" schemafilling method requires us to provide all possible schemas, and therefore to know everything about our problem space.
 We shall see that hillclimbing works much better than expected in our problem space, and in fact solved most of the problems.
 1.
1.
 The finite automata used in this paper Figu r« 1: The machine of the sample problem { (g) smfinal ) Each machine with n states is denoted by the following form: ((A,.
B,.
F,)(A2.
ayF2).
.
.
.
(A„.
B„.
F^).
 Each (Aj^, Bj^, Fĵ ) corresponds to the state 1, and A^ and Bĵ  indicate the destination states of the 0arrow and the 1arrow from the state 1, respectively.
 If Aĵ  or B^ is zero, then there is no 0arxow or 1arrow from the state 1, respectively.
 F^ indicates whether state 1 is one of the final states or not.
 If Tj_ is equal to 1, the state 1 is one of the final states.
 The initial state is always state 1.
 For instance, figure 1 is represented as follows: ((1 2 1)(3 1 1)(4 0 0)(3 4 D ) .
 1.
2 The problem We now are ready to describe the problem precisely.
 Given a rightlist (a set of positive sample strings) and a wronglist (a set of nega.
tive sample strings), we can think of the following three tasks: To find a machine that accepts all strings in the rightlist but none in the wronglist.
 To find a machine with n states that accepts all strings in the rightlist but none in the wronglist.
 To find the machine with fewest states (simplest machine) that accepts all strings in the rightlist but none in the wronglist.
 The first task is trivial because one can easily construct a trivial machine that accepts exactly all strings in the rightlist but nothing else.
 We 1.
 2.
 3.
 105 call the second cask c o n a c r u c d o n of finite automata, and the third task simplification of finite automata.
 1.
3.
 Sample Problems Throughout this paper, we consider the particular seven problems shown in figure 2.
 Figure 2: Sample Problems Ppobl«« 1 (•> I >) (t 1 II II 1 (1 1 0 1 1 I) I I I) 1111) 1 I 1 1 I) 111111) ProblM : U ^ HI { ') (1 0 1 01 (1 » 1 « 1 1) (1 0 1 0 1 t t 0) (1 « 1 t 1 0 1 0 1 « 1 0 1 01 nf idiu 0) 1 1 g 0 0 1 1 0 J) 1 0 o( (10 0 10 10) 110 110) (110 10 10 10) 4.
 any string without more than 2 consecutive O's.
 5.
 any string of even length which, making pairs, has an odd number of (0 1) or (1 0)'s.
 6.
 any string such that the difference between the numbers of I's and O's is 3n.
 7.
 0*1*0*1*.
 We also consider the Inverse problem of those In figure 2.
 The inverse problems are created by exchanging the rightlist and the wronglist.
 We use these U problems In our experiments and refer to the inverse problem of problem 1 as 1.
 2.
 Construction of Finite Automata In this section, we describe an experiment In constructing a finite automaton with n states from a given rightlist and a wronglist, using the hlllcllmbing.
 In particular, we let n equal 8.
 We shall see that each of the 14 problems can be solved In at most a few thousands steps.
 2.
1.
 Algorithm ProblM 3 (TM prMlM •• l>tr<d«c«< tt tIM Mtlii«la«l Problwi 4 The hlllcllmbing algorithm of this experiment Is shown In figure 3.
 in 01 1 01 0 i! (0 0) (10 0 10 0) (0 0 1 1 1 1 1 I 0 1 0 «) (0 t 0 0 1 0 0 1 0 •) ll I 1 0 0) 1» I 0) ""n (1 I 0 0 0) (0 0 0 II (0 0 0 0 0 0 0 0 0) jl 1 1 1 I 0 0 0 0 1 1) ( I I O I O I O O O O O I O I (10 10 0 10 0 0 1) (•0 0 0) (• 0 0 « •) R g u re 3: Rowchart of the HlllCllmbing ProblM S 1) 0) 0 0 1) 1 0 1) 0 1 01 0 0 0 1 1 1 1 0 II 0 0 110 0 9 0 11 11111) 0 0 01 (01 II I ll 10 1 0) (O 0 0 0 0 0 0 0 0) (10 0 0) 10 1) II 01 11110 0 10 10 0) 10 1 0 1 1 1 1 1 1 I 1 01 0 0 0 1) « 11) ProblMi 9 IJ?! II I 0 0| (10 10 10) (1 1 n (000000) M 0 1 1 II 10 1 1 1 1 0 1 1 1 n 11 0 0 1 0 0 1 0 0| 'r7"ii'n 1 0 0 1| 1 I ll 0 0 0 0 0 0 0) I 0 1 1 11 0 1 1 1 I 9 1 1 1 1| 0 0 1 0 0 1 0 0 11 M : 3 remdom M': =1 mutate(M) M:> M ProblM 7 (I I I 1 1) If g I I 0 0 I I) it 1 • II ( f O O O l O O O O t l l l (0 « 1 0 0) t 1 1 1 1 1 0 1 1 1 1 1) • •) Vil.
 rrr .
 (0 0 I 1 0 0 1 t 0 0 0) 0 10 10 10 10 1) 10 110 10) 1 0 1 0 11 0 10 10 0) I 0 I 0 0 1) 1 9 0 1 0 0 1 1 0 1 0 1) We first construct a random machine with 8 states.
 We next make a copy of this machine, where the copy is slightly altered from the original by an operator mutate.
 We compare the new machine with the original by an evaluation function E.
 The better machine is called current generation and we make a copy of this machine, and so forth.
 The worse machine Is simply discarded.
 The operator mutate and the evaluation function Z are defined more precisely in the following.
 The solution of these problems are: 1.
 1* 2.
 (1 0)* any string without an odd number of consecutive O's AFTER an odd number of consecutive I's.
 Operator mutate: Taking a machine ((Ai,Bi,Fi) .
 .
 .
(Ag,Bg,Fg)) as Its argument, the operator mutate chooses one digit randomly, and replaces it by another digit.
 That is, the mutation in our algorithm is randomly one of the following: delete an arrow.
 Insert an arrow, change the destination of an arrow to another destination, make a nonfinal state a final state, and make a final state Into a nonfinal state.
 106 Evaluation Function E: The evaluation function Z takes a machine as its argument and returns r w, where £ is the number of strings in the rightlist accepted by the machine, and w Is the number of strings In the wronglist accepted by the machine.
 If r  w < 0 then It returns 0.
 2.
2.
 Result We show In this section the result of our experiments.
 We first shov In figure U the trace of the experiment of problem 3, to see how our algorithm gradually refines a random machine into the desired machine.
 Figure 6: The Result of Construction I .
< A.
 .
<a;0 .
<a, ><8:and0 .
<f.
 .
<1.
 R g u r e 4 : Sample Trace of Problem 3 (((1 • oiia 1 1X1 0 0)10 0 9 01(4 1 l)(3 ! 1) 11(3 ! 1 11(3 ! 1 01(3 t 1) 01(3 < D) 01(3 4 1)1 )(3 ! 1 (3 ! 1 0)(3 ! 1 )(3 ! 1) 1(3 ! 1 li3 ! 1 01(3 ! 1 01(3 2 I) 01(3 ! 1) 01(3 ! 1 01(3 ; 111 4 OKt 0 0)(0 0 0 01(0 0 11(4 I 0 OHO 0 1(4 1 Id 4 OHO 0 OHO 0 11(1 1111 J nil 1 4 1 1 1H4 0 OHO 0 • 11(4 1 111 4 out 3 11(4 0 OHO 0 0 OHO 0 II 4 1 •(((1 < Oil! 0 OHO 0 (1 4 1116 3 1H4 0 01(0 0 III 4 11(6 1 1H4 0 OHO 0 1)14 0 nil 4 i)(s 3 11(4 0 01(0 0 1 1(4 0 1(11 1(11 nil ((II (111 (111 (111 4 1)(0 ((II 4 11(0 (111 4 11(1 nil < nil III! 4 11(1 t 4 1)(1 11(1 4 1)1 nil 4 1)(| (((1 4 D d 0 OHO 0 3 1)14 1 11(4 0 OHO 1)(4 5 0 OHO 11(4 5 0 OHO 0 1 1 4 3 IHO 0 01(0 3 ! 1) 3 ! 1) 3 ! 1| (3 I I) 0113 2 01(3 2 1 01(3 2 1) 01(3 i 1 01 2 i 0|(I ! I »)(» 2 1 1 1) 4 0 01(0 1 1114 5 1)10 1)10 110 )|0 1)10 1)10 3 11(0 3 1110 3 1)10 0 OHO 1 1)14 S 0 01(0 0 OH 1(0 S 1(0 5 1 10 S 0 0)0 6 0 0)10 5 9 1 0 6 0)10 0 9 1 0 2 0 (0 I [(0 1 l)|Z 9 1)17 4 1H9 0 0)(7 I 11(1 S 0)(7 7 0)(8 9 01 1(0 9 1)(4 0 0)12 9 0)19 0 1)11 6 0)12 2 0)(1 4 l)(fi 9 1) 1(4 1 1)13 1 1)11 2 0)(7 I 1)16 0 1)(4 0 0)(0 3 1|(1 2 1) 1(6 3 1)15 4 11(9 1 0111 6 0)(0 1 01(1 7 0|(6 7 0)13 6 0) ((» ! 1116 9 1)11 9 0117 9 0114 I oils 7 1)(8 3 11(4 1 0) 1(1 6 1110 0 1)12 4 1)13 7 0)(0 5 111) 6 1)17 9 1|(4 2 1) 1(3 6 OHO 3 0113 7 1)(3 4 1110 3 1117 1 OHO 4 11(0 0 0| 119 9 0112 3 11(2 0 01(2 9 11(1 5 11(1 « 1)(0 4 0)(4 2 1) 1(3 6 0)|4 i 1)(1 4 0)12 4 a|(6 I 1|(2 1 01(0 6 1)10 0 0) 1(4 7 0)|2 2 1)12 6 0)19 1 0117 5 01(7 < 11(1 ) 0)(2 0 0) ((9 3 0)16 6 0)16 2 1)11 7 11(1 1 1)15 9 1)(5 4 0)(1 6 1) 1(2 7 0)(7 I 1)13 2 0)(5 1 1|(0 3 01(3 7 01(1 9 1)(3 1 1) 1(7 9 0)(4 2 01(4 2 1)(4 3 1)(9 2 01(2 0 0)(I S 0|(9 0 l| »• 134 442 179* 277 209 300 8« 19 J» 249 1944 9M 32li 2.
3.
 Discussion To see how effectively our hlllcllmblng algorithm has performed, we compare our method with an exhaustive search.
 There are (9 x 9 x 2)8 « about 5 X 10^7 machines in our problem space.
 We now want to know the number of the desired machines in our problem space, so that we can calculate the expected number of steps until the exhaustive algorithm finds the first desired machine.
 This can be done by the following "sampling" method: take one machine In the problem space randomly, and test if this machine is the desired machine; repeat this procedure 100000 times.
 We show the expected number of steps using the exhaustive search calculated by this procedure in figure 7.
 Although the exhaustive search works better on "easy" problems.
 It is obvious in general that our hlllcllmblng works much better than the exhaustive search.
 Figura 7: The number of Steps to get ttie desired machine nil 9 1)15 0 0)(4 B 1)(0 0 0H2 1 1|(2 0 01(9 7 1)(9 0 1)) 12 20M (111 5 1)15 0 01(4 6 11(0 0 0H2 1 1)(2 4 0|(8 7 1)(5 0 11) 12 2049 (111 5 1)15 0 01(4 6 11(4 0 0H2 1 l)(2 4 0)(9 7 I|(5 0 ij) 12 2090 (1(1 5 1)15 0 oi(4 6 11(4 0 0H2 1 1)12 4 01(2 7 1)(9 0 1)) 12 2091 (111 5 1)|7 0 01(4 6 l)(4 0 01(2 1 1)(2 4 0)(2 f 1)(5 0 1}) 13 2092 totil rwit1a» 12I.
0U00* IK Each line correspomls to the current generation M.
 The column E indicates E(M), and G indicates the cumulative number of steps.
 The final machine of this trace accepts all strings in the rightlist but none in the wronglist of problem 3 (figure 5 ) .
 Problon PI Pi P3 P« P« P8 P7 PlnnP4P5p«P7HinCllmblng 98 134 2052 442 1768 277 208 300 39 1939 246 1844 888 3726 ExhaustivsSaarch 33 316 > 50000 12600 > 50000 SOOOO 90000 187 1862 > SOOOO > 50000 > 50000 > 50000 > 50000 Figure 5: The final machine of problem 3 3.
 Simplification of Finite Automata In the previous section, we saw that our hlllcllmblng method successfully produced a machine that accepts all positive sample strings but no negative sample strings.
 However, the final machine of the result of problem 2, for example, does not accept our desired regular set (1 0 ) * .
 For instance.
 It does accept a string (1 1 0 0 ) , which is not in (1 0 ) * .
 We therefore want the machine to be "generalized" so that it accepts exactly ( 1 0 ) * .
 In fact, the final machines of all problems except problem 1, 3 and 7, need to be generalized.
 We show the result of the 13 other proble figure 6, only by their final machines.
 in We define the generality of a machine In terms of its simplicity.
 The simplicity of a machine is determined by the number of states the machine has, and If two machines have the same number of states, a machine with fewer arrows and final states is simpler.
 Our task is to simplify the machines we have obtained in the previous section,so that the machines become the simplest or the most general.
 107 We call this cask, simplification of finite automata, and It can be also done by using the hillclljnblng method as in the previous section.
 3.
1.
 Algorithm The algorithm of the simplification is essentially the same as the algorithm described in the previous section.
 The major differences are as follows: the evaluation function E(M) returns a higher value if the machine M is simpler; if M does not accept seme strings in the rightlist, or does accept some strings in the wronglist, E(M) returns minus Infinity; the algorithm starts with the result of the previous experiment instead of a random macliine.
 3.
2.
 Result Let n be the number of states of the desired simplest machine.
 Then the expected number of the steps Sq Is: *n'f^.
lio».
i"|l*(''„'(a»<"')')Jwhere Uj is the number of all possible machines with j states, that is, ^Tha number of steps using hillclimbing in this figure is the sum of the number of steps to construct the 8 state machine and the number of steps to simplify it into the simplest machine.
 Although our problem domain has been regular languages, we might be able to extend it to contextfree languages by constructing PushDown automata (finite automata with stack, see [7J using a similar method.
 The final machines of these experiments are shown in figure 8.
 Figures: The Result of Simplification 'It :p4P5'P7({0 2 1)(1 ((2 1 1)(3 ((4 3 1)(3 ((3 2 1)(1 ((2 1 0)(2 ((2 3 0)(2 ((1 5 0)(3 5 0)(2 ((3 0)) 7 l)(0 I 1)) 68 0)(2 1 0)(1 2 0)) 0)(2 1 0)) 174 1)) 146 1)(1 2 I)) 971 0)(2 4 1)(2 0)(2 0 0)(1 42 l)(2 3 1)(4 1 1 0)) 363 10)) <MOrSIMPlEST> ((4 3 0j(6 6 Oj(6 2 lj(l S 1)(3 I 1)(5 4 1)) <IIOTSIMPLEST> ((2 3 0)(3 1 1)(1 2 1)) 44 ((1 5 0)(4 6 a)(4 2 l)(4 3 1)(5 2 0)(4 0 0)) <IK)TSIMPLEST> 3.
3.
 Discussion We compare our method with an exhaustive search.
 The exhaustive search generates all machines in the order of simplicity, and the first machine that accepts all strings in the rightlist but none in the wronglist is considered the simplest machine.
 Thus we can calculate the expected number of steps until the exhaustive search finds the desired machine^.
 The result is shown in figure 9.
^ The symbol " " indicates that the algorithm fails to find the simplest machine.
 This can happen when the hillclimbing algorithm climbs a "local hill".
 Fi9u re 9: The Number of Steps to obtain the simplest machine Problen PI P2 P3 P4 PS P6 P7 PlP2P3P4P5P«P74.
 Concluding Remark Our new approach to construction of finite automata from given examples has been shown to work successfully, although It could not find the simplest machines for some problems.
 To avoid climbing a "local hill", it might be possible to apply adaptive search ([6], [2J) Instead of our simple hillclimbing.
 HinClinming 98 141 2052 510 1810 451 206 445 1060 2302 930 Eihaustlva 4 170 SS3933 5624 553933 8524 563933 170 8624 46593884 553933 553933 8624 46693884 Acknowledgements I would like to thank Herbert A.
 Simon and Jaime Carbonell for supervising this work; Masakazu Nakanisbl, Yulchiro Anzai, Pat Langley and Takeo Kanade for thoughtful comments on an earlier version of this work; and Cynthia Hibbard for helping to produce this document.
 References [l] Biermann, A.
M.
 and Feldman, J.
A.
 On the Synthesis of FiniteState Acceptors.
 Al Memo 114, Stanford University, April, 1970.
 [2] Cavicchio, D.
J.
 Adaptive Search Using Simulated Evolution.
 PhD thesis.
 University of Michigan, 1970.
 [3] Feldman, J.
A.
 First Thoughts on Grammatical Inference.
 AI Memo 55, Stanford University, August, 1967.
 [4] Feldman, J.
A.
; Glps, J.
; Horning, J.
J.
; and Reder.
 S.
 Grammatical Complexity and Inference.
 AI Memo CS125, Stanford University, June, 1969.
 [5] Fogel, L.
J.
; Owens, A.
J.
; and Walsh, M.
J.
 Artificial Intelligence Through Simulated Evolution.
 Wiley, New York, 1966.
 [6] Holland, J.
H.
 Adaptation in Natural and Artificial Systems.
 The University of Michigan Press, 1975.
 [7] Hopcroft, J.
E.
 and Ullman, J.
D.
 Introduction to Automata Theory, Languages, and Computation.
 AddlsonWesley, 1979.
 [8] Lindsay, R.
K.
 Artificial Evolution of Intelligence.
 Contemporary Psychology 13(3), March, 1968.
 108 RETRIEVING MEMORIES OF PERSONAL EXPERIENCES Brian J.
 Reiser John B.
 Black Robert P.
 Abelaon Cognitive Science Program Yale University A n important upect of both comprehension and learning is the utilization of one's own past experiences to understand a current situation.
 In fact, being reminded of an experience often occurs in the process of retrieving generalizations from memory, suggesting that memories of personal experiences should be encoded in terms of the generic knowledge structures that are utilized in comprehension.
 Retrieval of these memories should therefore reflect the organization of generic knowledge (Schank, 1982).
 This paper explores the use of one such knowledge structure in the recall of past experiences.
 Schank (1982) proposed that Manory Organization PaeketB (MOPs) represent knowledge about common activities.
 A M O P is represented as a sequence of generalized aeenet, each of which consists of actions to accomplish a subgoal of the activity.
 For example, the R E S T A U R A N T M O P would contain the scenes Beingaeated, Ordering, Eating, and Paying.
 Generalized scenes can be referenced by more than one MOP.
 The generalized Paying scene contains the information that is true of paying in general, regardless of context.
 Each M O P consists of the generalized scenes that occur in that context, augmented by eontexttpeeifie knowledge, a specification of how those scenes are modified (eolored) for the particular situation.
 Each of the MOPs that refer to the Paying scene (e.
g.
, MOVIE, GROCERYSTORE, RESTAURANT) must contain the information necessary to construct a specific colored version of that scene.
 An experience typically contains many differences from the generalizations stored in generic knowledge structures.
 Schank (1982) argued that these deviations connect the contextualizing knowledge structure and memory for the individual experience.
 The (!i>nnection serves as a retrieval index for the experience (Kolodner, 1980; Schank, 1982).
 We propose that retrieval of an experience involves two types of processing: (1) Eetabliehing the context: The context necessary for retrieval will be provided by the specific knowledge structures that were utilized to guide behavior in the experience.
 (2) Finding an index: A retrieval index describing the deviation from the generic structure provides a link to an indhridnal experience.
 For example, the concept restavrant plus the index / ate too mttcA latagna and felt sick might retrieve a particular restaurant experience.
 The importance of a search context has been suggested by previous researchers (Norman & Bobrow, 1079; Williams & HoUan, 1981), but is necessary to examine whether there are any functional differences between classes of knowledge structures in memory retrieval (Reiser & Black, 1982).
 Our hypothesis is that establishment of a M O P as the context will flgure more importantly in the search process than other types of structures, such as generalized scenes.
 The uniqae aspects of adults' experiences are more likely to be deviations from contextspecific knowledge (specified by a MO P ) , than from the more abstract knowledge represented in generalized scenes.
 Furthermore, retrieval of even those experiences which are stored as scenedeviations will require the utilization of a M O P to reconstruct the contextspecific aspects of the experience.
 For example, one might remember not being able to find the right credit card while paying at a cash register, but initially fail to recall where the incident occurred, what was being paid for, etc.
 If a context such aa DEP A R T M E N T  S T O R E or R E S T A U R A N T could be retrieved, it would provide cues for reconstmcting other aspects of the experience.
 Our view may be contrasted with the position that experiences are stored as arbitrary associations between conc^ts in networks, with no functional differences between different types of concepts in memory retrieval W e examined the roles of M O P s and generalized scenes in memory retrieval in two autobiographical memory experiments.
 If it b generally necessary to retrieve a M O P structure to access a memory, then retrieval cues which do not specify a M O P should be inferior.
 If one is asked to remember a reataurantpaying experience, retrieval would be more eflicient if the processing begins with the R E S T A U R A N T M O P , rather than the generalized Paying scene.
 In addition, specification of the M O P containing a scene should lead to faster retrieval than specification solely of the scene.
 Experiment 1 Subjects saw a pair of phrases separated by a 5 second delay, then recalled a personal experience that fit the two phrases.
 One of the phrases named a M O P , and the other phrase referred to a scene; the order of presentation of the phrases was varied.
 The M O P cue named a common activity {took a ride on a train, went out drinking).
 Hie scene cue described an action sequence that could occur in a number of different contexts.
 T w o types of Scene phrases were used.
 Regular Scene cues described actions that are a normative component of an activity {picked out what you wanted, paid at the cash register), while Failure Scene cues described the failure of some goal of a scene {didn't get what you aaked for, couldn't find a seat).
 All scene cues were carefully worded so as not to reveal any particular context.
 Forty M O P and scene combinations were constructed 109 from twenty M O P , ten Failure Scene, and ten Regular Scene phrases.
 Each M O P was paired with both a Regular Scene and a Failure Scene cue; and each scene was paired with two MOPs: la.
 MOP t Failure Scene: went oat drinkiar.
 didn't get what yon aaked for lb.
 M O P + Regular Scene: went out drinking; paid at the cash register 2a.
 M O P K Failure Scene: had your hair eat; didn't get what yon asked for 2b.
 M O P + Regnlar Scene: had yoor hair cut; paid at the cash register Each subject receiyed ten combinations involving each type of scene cue, so that the M O P phrase was presented first for half of the trials for each type of combination.
 Each M O P and scene were used only once for a giren subject.
 (For example, a subject received items la and 2b, or items lb and 2a.
) Subjects were instructed to recall an experience that nt the combination of the two phrases presented on each trial, and indicate whether they could remember such an experience by pressing either the Ye» or N o key.
 W e emphasized that the memory be a tpeeifie experience, but that it was not necessary to recall all of the details of the experience before responding.
 After each Y u response, subjects wrote a brief description of the experience.
 Retrieval times were measured from the presentation of the second phrase until the button press.
 Table 1 presents the mean retrieval times for the Yea responses for 32 Yale undergraduates.
 Subjects recalled experiences more quickly when the M O P cue appeared first [mitt F'(1,U) = 798, p < .
01].
 Secondly, Regular Scene trials yielded faster retrieval times than Failure Scene trials [ m m /"(1,4S) = 9.
48, p < .
05].
 The order of presoitation equally affected the two scene types [interaction F < Ij.
 NOP First Scene First NOP * Regular Scene 4.
203 NOP * Failure Scene 5.
986 8.
4S2 8.
394 Nean S.
348 7.
120 Neen 5.
094 7.
443 6.
269 Table 1: Retrieral Times (in seconds) for Exp.
 1 The faster retrieval times when the M O P cue was presented first confirm the prediction that a M O P structure provides the context aecessary to retrieve an experience.
 W h e n the scene cue appears Hrst, extra processing is required to reconstruct a M O P context, slowing retrieval A n alternative explanation is that when the scene cue is first, an episode is retrieved, but it may not match the M O P that is presented later.
 In contrast, when the M O P is first and a memory is retrieved, it is much more likely to match the scene cue.
 Hence, the scene first trials would be slower, because sometimes the retrieved episodes must be discarded and memory search, resumed.
 However, this alternative explanation faib to account for the Failure Scene results.
 It assumes that memories retrieved with M O P s are likely to fit the scenes, while memories retrieved with scenes may not fit the MOPs.
 This is true for the Regular Scenes, since restaurant experiences typically contain a Paying scene, but paying is experienced in contexts other than restaurants.
 However, this is not true for Failure Scenes, since an episode retrieved from a M O P cue would not be particularly likely to fit the given Failure Scene description.
 Thus, the results are better explained by a model in which retrieval of the M O P is an essential stage in remembering an individual experience.
 Since the M O P provides the context for retrieval, the scene cue provides a constraint on the use of the experiences that are stored with the M O P .
 Each M O P contains a pool of available indices that specify very salient experiences in that context.
 Subjects search that pool of indices to discover whether any of those experiences could flt the scene cue.
 For the Regular Scene trials, the subject is relatively free in drawing from this pool of indices — one must be sure only that the experience that is retrieved can be reconstructed to include the necessary scene.
 However, when a Failure Scene b presented, the use of available indices is severely constrained, since an index must be found that retrieves an experience containing the particular type of goalfailure that b described in the scene cue.
 This requires careful consideration of the pool of indices, and perhaps some inferencing about the reasons that such a goal failure would arise, thus adding extra processing to the memory retrieval.
 Therefore, subjecta are slow« to remember an experience for those trials involving Failure Scene cues.
 Experiment i If constraining the target experience to a particular M O P context facilitates retrieval of an experience, then subjects should find it easier to remember an experience when given both a M O P and a scene (presented simultaneously) than when presented with a scene alone However, if activation of a context is a simple matter of retrieving associations of a scene, then there should be little difference between presentation of a M O P and scene combination and the scene in isolation.
 The facilitative nature of the M O P was tested in a second experiment by comparing retrieval times for three types of cues: (1) Scene alone, (2) M O P alone, (3) M O P + Scene combination.
 All M O P + Scene combinations from Experiment 1 were used; in addition, each M O P and each scene phrase was presented alone.
 Each subject received 10 trials of each cue type.
 (These trials w w e blocked by condition, to guard against the M O P of one trial facilitating the scene of the next triaL) The instructions differed slightly from Experiment 1.
 Subjects were told to recall an experience that fit the presented description consisting of one or two phrases.
 Since the materials in the three conditions necessarily differed in length, both reading and response times were collected for each trial Subjects first indicated when they had read the cue, and then responded to indicate whether they remembered an experience that fit the cue.
 Retrieval times were measured from the subject's reading time button press until the memory retrieval response.
 Table 2 presents the mean retrieval times for Yta responses in the three conditions for 36 Yale undergraduates.
 As predicted, subjects were able to 110 retrieve an experience more quickly when both a M O P and scene were presented, than when the scene was presented alone [min f'(1,42) = 3.
53, p < .
10; f\l,3i) = 8.
43, p < .
01 for subjecU; f[l,l8) = 8.
08, p < .
05 for itemsj.
 Subjects were faster to respond to Regular than Failure Scenes, but this difference was only marfinally signiHcant [/Jl,35) = 3.
08, p < .
10 for subjects; n« for items).
 Sctn* A Ion* NOP * Scan* NOP Alone Sctni T/pi fttgultr Scan* Ftilure Sctfl* 5.
2S0 5.
292 3.
383 4.
307 Mean 5.
294 3.
846 2.
154 Table 2: Retrieral Times (in second*) for Exp.
 2 Since the M O P provides a better search context than the generalized scene, the combination is a better retrieval cue than the scene alone.
 Subjects are slower to respond to the combinations than to the MOPs alone, because the scene cue provides an extra constraint on the use of the indices that are stored with the M O P .
 The subject must be sure that the recalled experience includes the specified scene of the M O P when given a M O P + Scene combination, but any of the indices may be used when given the M O P alone.
 Conelu*i€>nM The different structures we hAV« discussed may be considered in terms of the amount of constraint they place on the search space — Le.
, the set of experiences potentially satisfying the cue.
 A M O P constrains the set more than a generalized scene, since the scene can occur in multiple contexts.
 A M O P is somewhat less constraining than a M O P + Scene combination, since the combination specifles a particular segment of the event sequence.
 In addition, Failure Scenes are more constraining than Regular Scenes, since they specify a particular type of occurrence within a given scene.
 Our results suggest that a M O P constitutes the optimal level of specificity for a memory cue.
 Generalized scenes are not constrained enough, since they become better cues when combined with a M O P , and the scene stows retrieval when presented before the M O P .
 Once a M O P has been accessed, constraints on the use of indices may inereaae retrieval time, since the most accessible indices may not retrieve experiences that satisfy the given cue.
 Thus, subjects are slower to remember an experience that satisfies a Failure Scene cue than a Regular Scene cue, and are slower to recall an experience that satisfies both a M O P and a scene cue than one that satisfies only the M O P cue.
 In summary, we have argued that knowledge structures may be functionally distinguished by their effectiveness in providing a search context.
 Accessing a M O P is an essential part of retrieving a past experience from memory, since it provides an optimal search context, and can generate contextspecific indices to retrieve memories stored with a scene.
 Specifying the activity type by naming a M O P is facilitative, but constraining the t]rpe of experience that occurred in that context may require extra processing to generate appropriate indices.
 W e suggest that research on the use of memory in naturalistic tasks should focus on considerations of how the content of a genoic memory structure is utilized to find and reconstruct a memory for a speciflc experience.
 RefercBcea Kolodner, J.
 L.
 Retrieval and organitational stralegiea in conceptual memory: a computer modd.
 Technical Report 187, Department of Computer Science, Yale Univenity, 1080.
 Norman, D.
 A.
, ft Bobrow, D.
 G.
 Descriptions: A n intermediate stage in memory retrieval Cognitive Psychologg, 1979, 11, 107123.
 Reiser, B.
 J.
, ft Black, J.
 B.
 Processing and structural models of comprehension.
 Text, 1082, in press.
 Schank, R.
 C.
 Dynamic memory: A theory of reminding and learning in eomputere and people.
 Cambridge, M A : Cambridge University Press, 1982, in press.
 Williams, M .
 D.
, ft HoUan, J.
 D.
 The process of retrieval from verylong term memory.
 Cognitive Science, 1981, 5, 87119.
 Ill Personal Memory, Generic Memory, and Skill: A ReAnalysis of the EpisodicSemantic Distinction William F.
 Brewer Department of Psychology University of Illinois 603 E.
 Daniel Street Champaign, Illinois 61820 The purpose of this paper is to propose that human memory must be aneilyzed into three basic types: personal memory, generic memory, and skills.
 This analysis will only deal with productive memory systems and so will not cover recognition memory.
 After the classification is presented, it will be used as a framework to examine the initial work of Ebbinghaus (1885) and the episodicsemantic distinction proposed by Tulvlng (1972).
 In order to make the distinction between the three types of memory clear, consider the following example: An undergraduate goes to Che psychology building for a psychology experiment.
 He finds his way to the correct room, hesitates a minute, knocks on the door, and goes Inside.
 He sees the experimenter and a memory drum in a small bare room.
 After some preliminary instructions, he is given a number of trials on a long pairedassociate list.
 One of the items on the list is the pair DAX—FRIGID.
 After the experiment is over he breathes a sigh of relief and leaves the experimental room.
 This one event can be used Co illustrate Che chree types of memory: Personal memory.
 If, the next day, the undergraduate were asked, "Do you remember the psychology experiment you were in yesterday?" he might say something like: "Sure, I remember walking down to the room from the elevator.
 I remember feeling nervous as I stood there in front of the door.
 I remember opening the door and seeing the experimenter standing behind the table.
 I remember being surprised she was a woman.
 She had a white laboratory coat on, etc.
" If he were asked, "Was anything going through your mind while you were telling m« all this?" Che undergraduate might say somechlng like "Tes, I was seeing in my mind's eye much of whac I told you.
 I could see the door, the expression on the experimenter's face when I opened the door, etc.
" It is this type of memory that will be called personal memory in this paper.
 Generic memory.
 If, some months later, the undergraduate were asked, "Do you remember chat you were in a verballearning experiment several months ago?" he might say, "Yes.
" If asked, "Was anyChing going chrough your mind while you were giving me this answer?" he might say, "No, I just knew that I had been in the experiment.
 There were four experiments required for the course—two were filling out social psychology questionnaires, one was a perception experiment, and the other one was the verballearning experiment.
" This Is an example of the type of memory that will be called generic memory.
 Skill.
 If, some days later, the undergraduate were asked, "When I give you a nonsense syllable you tell me what word followed.
 DAX?" , he will probably say "FRIGID.
" If asked, "Was anything going through your mind when you gave the answer?" he might say, "No, I had practiced the list so many times I just knew what the response was.
" This Is an example of rote memory, one type of skill.
 This example was intended to provide an intuitive understanding of the distinction between Che 112 Chree Cypes of memory.
 The nexC secCion attempts to give a general description of each type.
 This approach to human memory is an attempt to give a psychological version of the relevant philosophical works on memory in Che lasc 70 years (Bergson, 1911; Russell, 1921; Furlong, 1951; von Leyden, 1961; Malcolm, 1963; Locke, 1971).
 Personal ry.
 A personal memory is a recollection of a particular episode In Che pasc of an Individual.
 Personal memory is (always?) experienced in terms of some type of mental imagery— predominantly visual.
 Ic usually also includes nonImaglnal InformaCion.
 The image is experienced as Che represenCaCion of a particular time and location.
 The personal memory episode Is accompanied by a propositlonal attitude that 'this occurred in the past' and is accompanied by a belief that the remembered episode was personally experienced by the individual.
 A personal memory is also frequently accompanied by a belief that it is a veridical record of the pasc episode.
 Personal memory scatements frequently flC Che linguistic frame: "I remember X.
" Thus, in Che above example: "I remember Che expression on Che experimenter's face.
" Generic memory.
 A generic memory is Che recall of some item of general knowledge.
 Generic memory is noc experienced as having occurred at a particular time and location and is not accompanied by a belief ChaC Che InformaCion was personally experienced by Che individual.
 Generic memory statements frequently fit Che linguistic frame: "I remember ChaC X.
" Thus, in Che earlier example: "I remember chat I was in a verbal learning experiment.
" Semantic memory is the subclass of generic memory which involves the memory for abstracc proposlcional InformaCion—for example: 'good is Che opposlce of bad' or 'che speed of lighc is a conscanc' The operaclon of semancic memory does noC typically carry along with it an experience of mental imagery.
 Thus when asked, "Whac is Che opposlce of good?" the correct answer Is given wlchouc reporc of any mencal imagery.
 Percepcual memory Is Che subclass of generic memory which Involves Che memory for perceptual Information—for example: a map of the United States or the Statue of Liberty.
 The operation of generic perceptual memory does typically involve mental imagery.
 Thus, If asked, "Is Oklahoma to the south of Kansas?" or "Which hand of the SCaCue of Libercy holds che corch?", mosc individuals will report a "generic" mental Image.
 These generic images are not typically experienced as Involving a parclcular time and location.
 The similarities and differences between a generic perceptual memory and a personal memory can be examined by the following exercise.
 Recall the center of your university campus (1.
=.
, form a mental map); now recall your most recent walk across that campus.
 The first is a generic perceptual memory; che second is a personal memory.
 Skill.
 A skill is Che ability to perform a given sequence of motor or cognitive actions.
 A practiced skill is typically noc accompanied by mental imagery.
 There are a number of subtypes of skill that need to be distinguished.
 Motor skills refer to the ability to carry out a sequence of motor actlooa.
 This type of memory underlies the abillty to ride a bike or hit a tennis ball.
 Rote skills refer to the ability to repeat a sequence of linguistic objects.
 This type of memory underlies the ability to repeat the alphabet or give one's social security number.
 Cognitive skills refer to the ability to carry out some sequence of cognitive operations.
 This type of memory underlies the ability to take the square root of a number or Co make Che verb agree in number with the subject in a spoken sentence.
 Many statements involving skills fit the linguistic frame: "I remember how to do X.
" Thus, "I remember how to ride a bike, how to say the alphabet, how to take a square root.
" In the next section of the paper the framework developed above is used.
 EbbinghauB.
 Gbblnghaus' 1885 monograph showed that it was possible to carry out experiments on human memory.
 However, In addition to this powerful achievement his work also served to limit the experimental Investigation of memory to a particular subclass of memory—that of skill.
 In the initial pages of the 1885 monograph Gbblnghaus contrasts personal memory with skills.
 He apparently chose to focus on skill memory for methodological reasons (i.
e.
, no need to use Introspective data).
 In fact, within the area of rote skills, he chose the savings method over the recall procedure because he felt there might still be an Important phenomenal component to recall tasks, whereas with the savings method he would just be comparing (behavioral) performance measures.
 This initial methodological decision by Ebbinghatis had an enormous impact on psychology—for 85 years in psychology the study of memory was the study of rote skills.
 Tulving.
 In the late 1960's a few psychologists were able to break out of the Ebbinghaus focus on skills and began to carry out experiments on semantic memory (e.
g.
, Collins & Quillian, 1969).
 In a seminal paper Tulving (1972) pointed out the fundamental difference in this type of experiment and formulated the distinction between semantic memory and episodic memory.
 The definition of semantic memory outlined above essentially follows Tulving's usage.
 However, Tulving's restriction of this type of memory to linguistic knowledge seemed too narrow, so I adopted the term generic memory for the larger class and the term semantic memory for the propositlonal subclass (see Hlntzman, 1978, and Schonfleld & Stones, 1979, for similar arguments).
 The construct of episodic memory, as used by Tulving, is harder to deal with.
 When it is defined in abstract terms, it seems close to personal memory as outlined above.
 Thus, Tulving states that episodic memory "stores Information about temporally dated episodes or events and temporalspatial relations among these events" (p.
 385) and proposes that statements from episodic memory refer to "a personal experience that is remembered in its temporalspatial relation to other such experienced' (p.
 387).
 However, the examples given by Tulving suggest that things are not that simple.
 Thus, one of the 4 examples of episodic memory was the statement, "Last year, while on my summer vacation, I met a retired sea captain who knew more jokes than any other person I have ever met " (p.
 386).
 Taken at face value this appears to be an example of generic memory as the term has been used in this paper.
 A clear example of a personal memory would have been a statement such as, "I remember sitting on the stool ac the bar, drinking a hot toddy while he told the traveling sailor joke, etc.
" One of the other examples suggests a more fundamental difficulty.
 "I know the word that was paired with DAX in this list was FRIGID " (p.
 387).
 In terms of the classification suggested above this is either an example of generic memory ("I remember that DAX was the word paired with FRIGID") or an example of a rote skill (given DAX the subject says "FRIGID").
 The latter Interpretation Is supported by Tulving's statement that the typical memory experiment In psychology Is an episodic memory task (p.
 390).
 Thus, the term episodic memory as used by Tulving apparently Includes personal memory, plus semantic memories about autobiographical Information, plus skills.
 In sum, the analysis presented here suggests that the distinction between semantic and episodic memory be replaced by the more analytic distinction between personal memory, generic memory, and skill.
 Research on personal memory.
 The classification of memory into three basic types has powerful implications for empirical research.
 It is clear that the Important topic of personal memory has been little studied by experimental psychologists (probably because of the residual restrictions left by Behaviorism).
 At Illinois we are currently trying to ask some of the relevant questions: What are the basic parameters of personal memory? (Brewer, in preparation) Are personal memories veridical? reconstructed? (Brewer, in preparation) How are generic memories derived from personal memories? (Brewer & Dupree, in preparation) What are the phenomenal properties associated with the different types of memory? (Brewer & Pani, in progress).
 References Bergson, H.
 Matter and memory.
 London: Allen & Unwin, 1911.
 Brewer, W.
F.
 Autobiographical memory.
 In preparation.
 Brewer, W.
F.
, & Dupree, D.
A.
 Memory for episodic and generic information.
 In preparation.
 Brewer, U.
F.
, & Panl, J.
R.
 Phenomenal reports in taska involving personal memory, generic memory and skills.
 In progress.
 Collins, A.
M.
, & Quillian, M.
R.
 Retrieval time from semantic memory.
 Journal of Verbal Learning and Verbal Behavior.
 1969, 8, 240247.
 Ebbinghaus, H.
 Memory.
 New York: Dover, 1964 ^original German edition 18857.
 Furlong, E.
J.
 A study in memory.
 London: Thomas Nelson, 1951.
 Hlntzman, D.
L.
 The psychology of learning and memory.
 San Francisco: Freeman, 1978.
 von Leyden, W.
 Remembering.
 New York: Philosophical Library, 1961.
 Locke, D.
 Memory.
 Garden City, NY: Anchor Books, 1971.
 Malcolm, N.
 Knowledge and certainty.
 Englewood Cliffs, NJ: PrenticeHall, 1963.
 Russell, B.
 The analysis of mind.
 London: Allen 6.
 Unwin.
 1921.
 Schonfleld, D.
, & Stones, M.
J.
 Remembering and aging.
 In J.
F.
 Kihlstrom and J.
E.
 Frederick (Eds.
), Functional disorders of memory.
 Hillsdale, NJ: Erlbaum, 1979.
 Tulving, E.
 Episodic and semantic memory.
 In E.
 Tulving and W.
 Donaldson (Eds.
), Organization of memory.
 New York: Academic Press, 1972.
 113 Teaporal Judgments about Natural Events Norman R.
 Brown Lanoe J.
 Rips and Steven C.
 Shevell University of Chicago The Information one reaembers about the time of an event Is rarely as precise as one would like.
 For a few consequential events, exact dates can sometimes be recalled; for example, one might remember that John Kennedy's assassination took place on November 22, 1963 or that Pearl Harbor was attacked on December 7, 1911.
 But aside from these blockbuster events and from recurrent events like birthdays and holidays, exact and explicit dates are usually unavailable.
 Even fairly Important events, such as Spiro Agnew's resignation or the DC10 crash in Chicago, which could hardly have escaped our notice at the time of their ooourrenoe, now are difficult to date accurately.
 Things could be otherwise.
 Events could be logged in memory in the way they are recorded in almanacs, and in this case determining when an event occurred would amount to simple table lookup.
 But since access to specific remembered dates is uncommon for ordinary events, it is of interest to examine the more indirect means that people use in reckoning bow long ago such events happened.
 With a few brave exceptions (e.
g.
, Linton, 1975), previous research on temporal memory has been limited to the study of short intervals (on the order of minutes or hours) and to brief events (usually words or syllables) presented to the subject in the laboratory.
 Examples are the "time perception* experiments of Fraisse (1963) and O m stein (1969), and the literature on recency Judgments in list learning (e.
g.
.
 Hacker, 1980).
 Our investigation focuses on people's accuracy in dating natural events over longer intervals.
 Like the earlier research, however, we employ experimental methods to test iadivlduala' maaory for suoh facta.
 In this respect, our studies parallel many current investigations of spatial knowledge and cognitive maps.
 nifl Ac tbiUtY PrlflClBla Consider an event such as the Chicago DC10 crash, for which no exact date is retrievable.
 How could one go about estimating its relative time of occurrence? One possibility is based on the obvious fact that, generally speaking, the longer an event is retained in memory, the less one can remember about it.
 Thus, given events that are equivalent in other respects, the event about which one remembers most is likely to be the one that happened most recently.
 We call this rule the "Accessibility Principle," since it asserts that the more accessible the information about an event, the more recent that event will seem.
 Of course, this principle is hardly foolproof.
 Factors like the initial salienoe of an event or its similarity to other events can influence the amount of information retained about it, beyond any effect of sheer passage of time.
 There is even evidence that, under certain conditions, recallable information can actually increase with delay (Erdelyi & Kleinbard, 1978).
 Nevertheless, the Accessibility Principle may still be useful as a rough guide to the time of an event, even though subject to error from variables like salience (as we demonstrate below).
 We view the Accessibility Principle as a close kin to the Lack of Knowledge Inferences described by Collins (1978) and to the AvaUabillty Heuristic of Tversky and Kahneman (1973).
 The difference Is that while Lack of Knowledge and Availability are used to draw conclusions about frequency or probability, the Accessibility Principle yields conclusions about the age of unique events.
 In the former case, one reasons that since one can't remember the event well, it probably happened infrequently or not at all.
 In the latter case, one reasons that since one can't remember the event well, it probably happened long ago.
 SubJMtlTB Ago Qf Palrfld ETMta of tha 1970'a A straightforward prediction of the Accessibility Principle is that events that are retrospectively vivid and memorable should seem more recent than events that are not (other things being equal).
 Consider, for example, the DC10 crash in Chicago and the DC10 crash in Antarctica of about the same period.
 Since the DC10 crash in Chicago is comparatively more memorable than the one in Antarctica, the Chicago crash should be Judged more recent, even though, in point of faot, it happened six months earlier (May 25, 1979 vs.
 November 28, 1979).
 We tested this prediction in an experiment using 19 pairs of events like the two DC10 crashes that were matched as closely as possible for actual time of occurrence and for the content of the events themselves.
 The pairs included sports and cultural events (e.
g.
, Saul Bellow wins the Nobel Prize vs.
 Burton Richter wins the Noble Prize) as wall as standard news storlea, all of which occurred between 1973 and 1980.
 Hltbia each pair, one of the events was designated as more memorable than the other on the basis of ratings collected from two Judges, neither of whom were aware of the hypothesis under investigation.
 A complete list of the pairs, together with their true dates and meaorabUity status, is given in Table 1.
 In the experiment proper, the 38 individual events were read to subjects In random order, and the subjects were asked to respond to each with a number that beat represented how recently the event happened.
 The numbers were chosen from a Oto9 scale, with high values corresponding to recent events and low values to old ones.
 We informed subjects before the start of the experiment that all of the events took place after 1970.
 Since the 15 subjects were of college or graduatestudent age, all of them had lived through the time of the target incidents.
 Mean recency ratings from these subjects are also displayed in Table 1.
 Although on average the true date of the memorable events is slightly earlier than that of the less memorable ones (a difference of .
05 years), subjects' ratings place the memorsthle events later.
 The overall mean rating for the memorable events is 5.
7, whereas the meeui for the less memorable events is 5.
1.
 These ratings differed significantly when either subjects or event pairs are considered a random effect [for subjects, £.
(1,14) = 20.
43, a.
 < .
01; for events, 1(1,18) = 4.
58, a.
< .
05; however, quasiHd ,25) = 4.
01, .
05 < a < 'lO]' As an example of this 114 AcceaslbUltr outcoae, SOf of tha subjects rated the Chicago DC10 craah aa occurring after the Antarctica craah, despite the fact that the opposite order is the correct one.
 Table 1 also reveals a nuaber of exceptions to the Accessibility predictions, although in oost cases these are fron pairs in which the difference in ffleoorability Is small.
 Aa one would expect, the correlation between neaorability and recency ratings is significant for these stiaulua itans [£(36) '•38, ji.
<.
05].
 Recall and PercBlTed Age ai Eynnta In 1982 Although our prediction was confirmed that more accessible events seem more recent, measurement of acceaslbility (the memorability ratings) was fairly indirect for the events of the first study.
 In a second experiment, we have evaluated accessibility more directly by measuring subjecta' recall of eventa, rather than relying on ratinga.
 We predict that the larger the number of propositions about an incident that a subject can recall, the more recent that incident will seem.
 In this neu experiment, the basic recency Judgments and recall protocols were obtained from separate subject groups.
 Notice, however, that the act of recall may itself make the associated events more accessible.
 For this reaaon, it is of interest to compare recency ratings from subjecta who have Juat completed recalling the events and recency ratings from subjects who have not engaged in recall.
 If recall increases accessibility, then ratinga of recenoyafterrecall should be systematically greater than ratings of recencywithoutrecall.
 The target events in this study were 40 headlinetype incidents that were culled from the front pages of the Chinas Tr•̂ hl•n̂  and the Mew lorlt Uiiaa.
 between January 4 and January 11, 1982.
 This collection of events included items such as: Richard Allen resigns aa National Security Advisor, the first O.
S.
 testtube baby leaves the hospital, and the D.
S.
 drops its antltruat suit against IBM.
 Since we were interested in tracking tha relationship between recency and recall at different Intervala after the eventa took place, we tested several independent groups of subjects: one Recall and one Recency group during the week immediately following the last target event, a second pair of Recall and Recency groups during the week beginning 15 days after the last event, and a third pair 60 days after the last event.
 To aasess our hypothesis that recall Increases apparent recency, we also asked subjects in the 60day Recall group for recency ratings after they had completed their recall protocols.
 Recency ratinga were elicited in a way similar to that of the first experiment (except that the subjecta were told that the events happened in the 1980's rather than the 1970's).
 Recall subjects were given the same event names (e.
g.
, Richard Allen resigns) and were asked to write down all at the facta they could remember directly related to the named events.
 The recall score for each incident waa calculated as the average number of true atoalc propositions recalled about It (see Cintsch, 1974).
 Stricter scoring methods (e.
g.
, counting only directly relevant true propositions) yielded the same pattern of results.
 Fifteen subjects participated in each of the Recall and Recency groups.
 The main results from this second study are given in Table 2 in the form of Spearman correlations between recency ratings and recall scores.
 Also shown in Table 2 are the correlations between recency and the events' true dates.
 Two facts about these data stand out.
 First, as the Accessibility Principle predicts, recall and recency are significantly correlated at each of the three Intervals.
 Data from the first interval are especially interesting since they are least likely to be influenced by media retellings and followup reports.
 Second, and somewhat surprisingly, the number of propositions recalled is a better predictor of recency than the actual date of occurrence at All three intervals.
 In addition, a trend in the rating data followed the prediction that subjective recency would increase following recall.
 The average recency rating after recall was 5.
7 for subjects in the 60day Recall group; however, the average rating from the 60day Recency group was 5.
3.
 But although this trend was significant when tested over events [£(1,39) = 13.
07, s.
 < .
01], it waa nonaignificant when tested agalnat aubjeots [£(1,28) = 1.
28, a.
 > .
10].
 lapHcationa According to the Acoeaaibility Principle, the apparent age of an event depends upon the amount of information about It that one can bring to mind.
 This principle gained credence from the results of our first study.
 In which more memorable events were rated as taking place more recently than similar events of approximately equal objective age.
 The second experiment strengthened the case for Accessibility by demonstrating that the number of facts recalled about an event is a powerful predictor of its subjective time of occurrence.
 We have little doubt that other cognitive processes can also affect temporal Judgments for natural events like these.
 As we have acknowledged, certain influential or recurrent events may be tagged with dates; the time of lesser eventa may be eatioated through their cauaal connections to these influential ones.
 Still, a glance at the items in Table 1 suggests that causal links to datable events may not always be present, and in these circumstances, the Accessibllty Principle may be the dominant method for temporal Judgments.
 The Accessibility hypothesis bears an analogy to classical strength theories of time perception, which predict that the strength of the memory trace at the time of test determines the apparent age of the associated event (see the references cited by James, 1890, Pp.
 632633, and more recently, Hinrlcha, 1970, and Morton, 1968).
 Pure strength theories, however, have not fared especially well in tests involving multiple list learning (Hintzman & Block, 1971; Flexaer & Bower, 1974).
 By Implication, these earlier results suggest that the mechanism responsible for our aooesslbility effects is not as simple as a unidimensional quantity connected to one's memory for an event.
 Our experiments leave the exact nature of the underlying mechanism as an open question.
 Nevertheless, the similarity mentioned above between the Accessibility Principle, the AvaUability Heuristic, and Lack of Knowledge Inferences may Indicate that we are tapping part of a very general and complex Inductive procedure.
 Acknowledgments We thank Martin Ringle and David Zager for their advice and assistance.
 We also acknowledge the Sloan Foundation for its support of this research.
 References Collins, A.
 Fragments of a theory of plausible reasoning.
 In D.
 I.
 Waltz (Ed.
), Thaoretleal lasuaa 1n natural langiiaya nrn115 n«i.
«i«i ng3.
 New Toric: Aaaoolatlon for Computing Maohlnery, 1978.
 Erdclyl, M.
 H.
, & Clelnb«rd, J.
 Has Ebblnghaua decayed with time?: Tbe growth of recall (hypemneala) over day a.
 Journal r»r Emarimantal Pavchologv: UUOOa—LflBmlng aM H«.
H.
nrv, 1978, 1, 275289.
 ?1.
»xa»r, &.
 J.
, i Bower, 0.
 H.
 How frequeaoy affects recency Judgments: A model for recency discrimination.
 .
rnnrnni nc Erporimantal Pavohologv.
 1974, ̂ Sli 706716.
 Fralsse, P.
 Th« DaYohol o<pr of Uoft.
 New York: Harper & Row, 1963.
 Hacker, M.
 J.
 Speed and acouraoy of recency Judgments for events in shortterm memory.
 JouraaX S£ ETParlmantal PaYChfllOgT; QiMMO.
 lifwrnlng and Hflmonr.
 1980, i.
 651675.
 Hinrlchs, J.
 V.
 A twoprocess memory strength theory for Judgients of recency.
 PavohoiQglcal RflTlw.
 1970, n , 223233.
 Hlntzman, D.
 L.
, & Block, R.
 A.
 Repetition and memory: Evidence for a multiple trace hypothesis.
 .
Innrnal at ETporiiiMnhal PaYflhQlnrr.
 i97i, M , 297306.
 James, u.
 Tha BrlBfllBlfla of BarchQlagy.
 Vol 1.
 New Tork: Holt, 1890.
 Cintseh, W.
 Tha raDP»a.
in«.
af.
lQn a£_ oaa&CZ.
.
 Hillsdale, H.
J.
: Erlbaum, 1974.
 Linton, M.
 Henory for realworld events.
 In D.
 A.
 Norman and D.
 B.
 Ruaelhart, Expinpationa in n̂inyjtinr,.
 San Franclsoo: FreeMn, 1975.
 ftorton, J.
 Repeated items and decay in memory.
 P^Tnhnnnir .
S»H«n>.
« I968, IJL 219220.
 Ornstein, R.
 B.
 On ».
h« »Tn«p<«n«« «f tim».
 Baltimore: Penguin, 1969.
 Tversky, A.
, i Kahneman, 0.
 AvallabUlty: i heuristic for Judging frequency and probabUlty.
 Cngn̂ ^̂ •̂ v̂  Pavohoiogv.
 1973, 5a 207232.
 TABLE 1 Stimulus Events, True Dates, and Mean Recency Ratings, Experiment 1 Event Pairs 1.
 Reagan and Bush nominated by the Republican convention.
 Carter and Mondale nominated for a second term by the Democratic convention.
 2.
 Dustin Hoffman won an Academy Award for gramar v.
i.
 gpamap.
 Sally Field won an Academy Award for 3.
 A DC10 crashed in Chicago.
 A DC10 crashed in Antarctica.
 4.
 Lord Mountbatten assassinated in Ireland.
 U.
S.
 Ambassador Adolph Dubs assassinated in Afghanistan.
 5.
 The Supreme Court affirmed a lower court decision ordering California Medical School to admit Allan Bakke.
 6/78 The Supreme Court ruled that labor unions could distribute material of a political nature at an employment site.
 6/78 6.
 David Berkowitz was arrested on a murder charge.
 8/77 Gene Leroy Hunt was arrested on a murder charge.
 4/78 Date 7/80 8/80 4/80 4/80 5/79 11/79 8/79 2/79 Recency Rating 8.
2 7.
5 7.
8 7.
2 7.
1 5.
5 5.
9 6.
7 7.
 West German terrorists hijacked a Lufthansa edrliner.
 An alleged bank robber, Thomas Hannan, hijacked an airplane in Nebraska.
 8.
 Hoota won an Emmy Award.
 Blaanor and Frnnlflln won an Ema^ Award.
 9.
 Annin opened on Broadway.
 Tha OlB Gaaa opened on Broadway.
 10.
Saul Bellow won a Nobel Prize in literature.
 Burton Rlchter won a Nobel Prize in physios.
 10/77 6.
5 5.
1 6.
7 5.
3 6.
0 10/77 9/77 9/77 4/77 10/77 10/76 10/76 4.
1 6.
5 6.
1 6.
1 3.
5 5.
4 4.
3 116 TABLE 1 (cont.
) 11.
Bruce Jenner won an Olyapio Goid Medal In tbe decathlon.
 7/76 Evelln Scblaak won an Olympic Gold Medal in the discus throw.
 7/76 12.
Mao Tsetung died.
 9/76 Chou Enlal died.
 1/76 13.
Muhamnad ill COs Joe Frazler.
 10/75 Huhaoaad U i EOs JeanPierre Coopnan.
 2/76 14.
E.
 L.
 Doctorow's Ragtima published.
 7/75 Irving Stone's The Greek Treaaure published.
 15.
Unda Ronatadt's aaart Llto a WbCfll won a Gold Record.
 John Denver's An Evttnin^ with John Danver won a Gold Record.
 16.
Aristotle Onaasis died.
 H.
 L.
 Hunt died.
 17.
Stave Garvey wins baseball's Most Valuable Player award.
 Jeff Burroughs wins baseball's Most Valuable Player award.
 9/75 1/75 2/75 3/75 11/74 11/74 11/74 2/74 18.
Patty Hearst kidnapped.
 J.
 Reginald Murphy, editor of tbe AtianU CoBatltutAon, kidnapped.
 2/74 19.
Spiro Agnew resigned as Vice Prea.
 10/73 Nelson Rockefeller resigned aa Governor of Mew lork.
 12/73 5.
1 3.
9 4.
8 5.
4 i».
3 4.
6 4.
7 5.
0 6.
3 4.
6 4.
8 5.
1 5.
3 4.
1 4.
1 5.
1 3.
0 4.
5 TABLE 2 Spearman Correlations between Recency Estimates, True Dates, and Number of Recalled Propositions, Experiment 2 Recency Rating •0 Days +15 Days +60 Days •p < .
05 ••p < .
01 •••p < .
001 Number of Propositions Recalled ,80»«» .
69"« .
68»«« True Date .
18 .
41»» .
34« Saia.
' The first member of each of the pairs was rated as the more memorable.
 Tbe standard error of the above means is .
46.
 117 Psychological Issues Raised by an AI Model of Reconstructive Memory Janet L.
 Kolodner Department of Computer Science Georgia Institute of Technology Atlanta, Georgia 30332 Lawrence W.
 Barsalou Department of Psychology Emory University Atlanta.
 Georgia 30332 1.
 Istzodnction this paper presents soma psychological iaplications of an AI model of reconstructive Descry.
 Psychologists have characterixed htnuin Deaory as reconstructive for years (e.
g.
, [1], [6]).
 AI siaulation of reconstuction goes further since ccaputer iaplenentation requires explicit specification of processes and representations.
 The particular AI model ve consider here is Kolodner 's (5] EMOP based model, iaplsaented in a computer program CYEDS.
 The model has three interrelated components: a retrieval process, an underlying memory organization, and processes for developing memory organization with the encoding of new events.
 The retrieval process vas designed to imitate reconstructive retrieval strategies observed in people.
 The moaory organization both supports and causes reconstructive retrieval.
 Processes for developing msaory organization build nev knowledge structures (i.
e.
, learn) as new events are encoded.
 These new knowledge structures enable subsequent reconstructive retrieval of the new events.
 One iaportanc reason such a model should be of interest Co psychologists is that it makes claiaa about human memory organization and processes.
 These claiaa stem frca the process of simulating human reconstructive memory.
 Because Che available model was incoaplete, building CTBOS required filling it in in on the baais of intuition.
 We now ask whether the added assumptions that fill holes in psychological accounts are psychologically valid.
 2.
 TiM BMOP modml 2.
1 Memory Orgaaixatioa A memory organization for reconstructive retrieval must both support and cause reconstruction.
 It must generate clusters in recall, locate and develop retrieval cues, cauae confusions in recall and recognition, and emulate other characteristics of human remembering.
 Kolodner's m^ory organization uses conceptual categories called Episodic Memory Organization Packets, or EMDPs (similar Co Scbank's m?» [7]) that organize episodes in memory.
 A central assimiption is that there is one E(CP for each type of activity a person may be involved in, where type is defined as events Chat achieve a similar goal.
 Diplomats are involved in "diplomatic meetings", "diplomatic crips", "negotiationa", and "state dinners".
 Each individual event is stored in Che EMOP(s) it fits into.
 EMDPs incorporate both episodic and generic memory (coi^nly, but incorrectly called semantic The work of the first author was partially supported by NSF under grant Ho.
 IST8116892.
 118 Dry).
 The generic component consists of generalizationa describing most of its members (i.
e.
, some members may exhibit violations of these "norms").
 Host "diplomatic meetings" discuss an international contract, for example, but a particular meeting might be called to plan an international event.
 An EMOP's second component is its organization of member episodes.
 Episodes are organized based on how they differ from Che EMOP's norms.
 An episode is indexed and retrieved from an EMOP by its relevant differences.
 When more than one episode has the same difference, a new subMDP is formed based on their similarities and differences.
 The figure below illustrates this organization: 'diplomatic meetings' norms: the actor is Cyrus Vsnce (MOPl) participants are foreign diplomats topics are international contracts participants Calked to each other goal was to resolve disputed contract diffs: / participants .
/ (1)1 \ topic / \ Gromyko / SALT I BV2 EV2 (M0P2) Day an I I I ET4 (3)1 Begin norms: partic inclnd* Begin topic concerns Israel and Arabs specialization of HOPl diffs: I I topic (5) / \ (6) Jerusal^ Camp David Accorda I  (M0P4) EV3 I I I (4) I \ (2) Jerusalem I EV3 (IOP3) Camp David Accords norms: topic is the CDA partic are Israeli specializatn of HOPl diffs: I I partic (7) / \ (8) Begin Dayan (M0P4) I EV4 The norms are features characteristic of diplomatic meetings.
 The episodes are indexed according Co Cheir similaricies and differences in Copic and participants.
 Meetings with Che same Copic or participants form EHOPs whose norms are ccnposad of their similarities.
 Below these norms, a set of similar instances are subsequently differentiated by their differences (i.
e.
, mapped into indices).
 CTRDS organizes EMDPs in three ways: (1) hierarchically, as just described; (2) by causal, temporal, and containment relationships between normative features; (3) by Chese same relations between indices.
 2.
2 Maintaining memory organisation over time the Encoding new episodes requires both retaining old organization to some extent and accomodating it to Che new input.
 When a new episode is indexed identically to an old one, a new EMOP must be formed to subsume them.
 That is, EMOP formation is triggered by "rounding" [7], which occurs when the new episode retrieves the other similar one.
 The new EMOP'a norms are the similarities between the two items, and its indices are their differences.
 Because generalizations about a kind of event based on only two it^s may be inaccurate, subsequent episodes encoded with this EMOP are used to refine these norms.
 If a feature not a norm for the first two episodes turns out to be normative for most others, what was initially an index can become a norm.
 Similarly, if a false generalization were made, norms for the first two instances can be relegated to indices.
 2.
3 Imtzirrml Retrieval cues are abstracted from requests to remember an event.
 Such requests can be partial or complete specifications of the event to be retrieved.
 A request specifies an EMOP to be searched and which indices within the EtOP are to be traversed to find the event.
 An important assumption is that an EMDP index cannot be traversed unless it is specified.
 In this way, retrieval is directed by the information in the request and further information that can be derived from it.
 Since this process can fail in several ways, reconstructive strategies are proposed to deal with various types of failure.
 First, if the information in a request does not specify an EHOP to be searched, then one or a small set of EMOPs must be chosen.
 This process sees if any of the features stated in the request have EHOPs associated with them (i.
e.
, schema triggering).
 A second type of failure stems from E(OPs being untraversable unless their indices have been specified.
 A retrieval cue may specify features that don't correspond to EMOP indices.
 Or, a retrieval cue may be so general that it doean't specify enough features to direct traversal processes to a unique item.
 In that case, plausible featurea corresponding to EMOP indices must be inferred from the given retrieval cues.
 A "fleeting with Menachim Begin" might plausibly have taken place in Jerusalem.
 The strategies which make these inferences capitalize on an EMOP's norma and knowledge about plausible relationahips between different event featurea.
 Once such information has been specified, the corresponding indices are traversed.
 Interestingly, both types of strategies mentioned so far can lead to retrieval confusions and false starts.
 A third type of strategy derives from the relationships between events in memory.
 Individual events refer to other events they are related to.
 If an event related to the requested event can be better specified, the related event can be used to further specify the requsted one.
 To recall a particular museum visit, for example, one might att^pt to recall the trip it was part of.
 3.
 Psychological Issues This model stems from observation* of how people remoiber, and what they forget.
 Although the processes and organization used to construct a complete model of reconstruction seaa to work, are they really psychologically valid? One aapect of the model that has received empirical investigation to a large extent is reconstructive retrieval strategies [81.
 People appear to elaborate upon requests to remember in many of the ways CtioS does.
 Nevertheless, many issues remain untouched or at least require further attention.
 How does the organization of a set of events constrain the manner in which people elaborate on retrieval cues? That is, to what extent are such strategies contentdependent? Do people use the elaboration strategies used by CYBDS? Do they use others? What strategiea are used most often, in what order, and for what reason? Similar to the contentdependence issue is the contextdependence issue.
 To what extent is elaboration affected by imiMdiately previoua searches for other events? for the same event? Given retrieval failure while searching an organized set of events, how do people select new parts of the organization for search? How does a retrieval access change organization? How sensitive is retrieval to incorrectly specified cues? Is the model too dependent on correctness? Perhaps the most central issues the model raises are: How are events organized in memory? And how does this organization change over time? cnnS assumes that events are the fundamental organizing units in memory.
 Is this true of human memory? If not, then what are the fundamental units? There may be several types of organizing principles.
 Others to be considered are: location (e.
g.
, a local restaurant or bar); time (e.
g.
, Christmas, summer); participants (e.
g.
, Nixon, a spouse, a close friend)? If there are several ways events are organized, what determines which will apply to a given set of events? The content of the events? The goal the organization will serve? Perhaps several organizations simultaneously exist over a set of events.
 A related issue concerns kaowing what feature(s) should be used to discriminate two episodes sorted to the same EMOP.
 There may be numerous features that distinguish two events, but only those that will be useful in the later evolution of generic knowledge should be chosen for indexing.
 How can such features be chosen? Another related iasua is how many indices are grown each time reminding occurs.
 Another central issue concerns BMOP construction.
 Is a new EMOP constructed every time someone is reminded of an old event by a current one? To what extent ia generic structure automatically acquired from and imposed on events? Or is conscious attention necessary to abstract normative information from previous events, organize it into EMDPs, and apply it to new eventa? Human data may be informative on these points.
 In the proposed memory organization, MOPs and their subMOPs form hierarchies in which conmon properties are stored once at the highest possible point in the hierarchy.
 This economy of storage parallels what psychologists call "cognitive economy" [2].
 To date, it appears that the organization of semantic memory (i.
e.
, lexical meaning) violates cognitive economy [31.
 But to what extent is this violation true of other types of generic knowledge? Does human organization of events reflect cognitive economy? Or do people have much looser, less integrated and noninclusive organizations for events? An important aspect of EMOPs is that they combine "episodic" and "generic" maaories.
 This implies that episodic and generic memory are not separate entities but are intimately connected.
 If chis is so, what exactly is the connection? When does episodic information (e.
g.
, EMOP indices) become generic (e.
g.
, EMOP norms or frame information)? When and how does generic information become confused with episodic information to 119 genarate confusiona? In EtOPa, both happen as generalizaciona are refined and corrected.
 There are a number or topics not covered in the original oodel which are nonetheleaa important to a theory of human memory organization and retrieval.
 One such iasue concerns the roles of automatic versus conscious processes that encode information into memory.
 Temporal, spatial, and frequency information appear to be automatically acquired — even without Vmoving they are doing it, people encode these fundamental aspects of events [41.
 In contrast, the acquisition of content information often seems to depend more on the use of conscious attention.
 When such information doesn't receive attention, the information la not acquired.
 How do these two types of processes interact to store events? Conscious attention may be responsible for the construction, organization, and reorganization of generic structure, since it usually containa content information.
 Automatic processes may be responsible for the strengthening of generic knowledge and the integration of spatial and temporal iaformation into it.
 Finding algorithms for these latter phenomena and interfacing them with contentoriented processes appears to be an interesting problem.
 A related issue is the role of similarity among events.
 This factor can facilitate people's memory performance on some occasions and interfere with it on others.
 Observing such phenomena in people's memory for eventa may further constrain the way in which we view generic knowledge of events and its us* during retrieval.
 In EtOPs, when a property doesn't correlate with other events, an index is set up differentiating the event with the deviant property from other events in the EMOF.
 Correlation and differentiation play the role of keeping events suitably accessible.
 An event lAich confonts to the norms of an EMOP will not be eaaily accessible because it won't have many indicea differentiating it.
 On the other hand, eventa which have differentiating featurea will be accessible if those features are specified in or derived from a retrieval cue.
 What ia the role of similarity and differentiation in people's memories? What is the actual effect they have on memory's organization? Analogy ia another area not covered in the original model.
 CTBUS does not address the migration of generic information from old EHOPs to new ones.
 Generic knowledge associated with a, particular ElOP might be uaeful, however, in creating a aew related EHDF or in understandinf something in a similar EMOP.
 To what extent doea "generic" structure generalize from one set of eventa to another? Muat a completely new structure be built for each new set or does transfer occur? Vfhat procedures trsnsfer the structure of an old EMOP to a new one? How can knowledge in one EMOP (e.
g.
, for Vance) be uaed to understand something about a related referent (e.
g.
, Haig)7 4.
 Pature Dlreetiona We are currently designing experiments that we hope will help answer the questions above.
 The experimants, no doubt, will raise additional queationa.
 Aa a joint Artificial Intelligence and Psychology project, we will address these questions in the same way we have found it profitable to consider their ancestors by building computer prograas and by collecting human data.
 References 11] 4 Studv in C^bridge Bartlett, R.
 (1932).
 '̂ flBffllfrtrilH• Experimental and Social Psychology.
 University Press, London.
 Collins, A.
M.
, & Quillian, M.
R.
 (1969).
 Retrieval time from semantic memory.
 JVLVB (8), 240247.
 Conrad, C.
 (1972).
 Cognitive Economy in semantic msory.
 JS£(92), 149154.
 Hasher, L.
 & Zacks, R.
T.
 (1979).
 Automatic and effortful processes in m^ory.
 JEP;G (108), 356388.
 Kolodnmr, J.
 L.
 (1980).
 Retrieval and organizational strategies in conceptual memory: a computer model.
 Research Report #187.
 Dept.
 of Ccmp.
 Sci.
, Yale, New Haven, CT.
 [6] Norman, D.
A.
 & Bobrow, D.
G.
 (1979).
 Descriptions: An intermediate stage in memory retrieval.
 Cognitive Psychology (11).
 107123.
 [7] Schank, R.
 C.
 (1980).
 Language and memory.
 Ssaiika.
 Ssisaaa.
 W .
 243284.
 [81 WUlima, M.
 W.
 and Hollaa, J.
 0.
 (1981).
 The Process of Retrieval From Very LongTerm Memory.
 Cognitive Science (5).
 87119.
 [21 [31 [41 [51 120 S O F T C O N T R O L O F C O G N I T I V E P R O C E S S E S Michael R.
 Fehling use/Information Sciences Institute 4676 Admiralty Way Marina del Rey.
CA 90291 Submitted to: Fourth Annual Conference of the Cognitive Science Society Ann Arbor, Michigan August 46,1982 Topic: Problem Solving and Knowledge Structures Sponsor Gary M.
 Olson 1.
INTRODUCTION A critical feature of any problem solving system is its control structure.
 This, of course, refers to a mechanism (and its associated knowledge) used allocate processing resources among the various components of the system as they are needed to carry out some task within some problem domain.
 It is clear that the control structure of a problem solver is a major determiner of that system's ability to efficiently and effectively carry out any task.
 As important as the notion of control is, it is surprising that so little woric has been devoted to it by either computer scientists interested in developing expert systems or psychologists interested in modeling human cognition.
 It has been the feeling in Artificial Intelligence that, if there were enough knowledge available in the construction of an expert system, the problem of selecting an appropriate control structure would be a minor one (Feigenbaum, 1977).
 And, as we shall discuss below, although some recent psychological models have addressed issues that are closely related to the control problem, little or no research has directly addressed the general question of control of cognitive processes.
 In this paper we report some work we are doing on the control problem.
 The ultimate goal of this research is to design and implement an expert system that controls other expert systems.
 That is, we are developing a problem solving system that is specialized to select and maintain a control regime for components of another "embedded" expert system.
 Our Expert System Controller (ESC) is able to reason about control.
 It uses both general knowledge and domain specific knowledge of the embedded system to create and maintain control plans for scheduling the use of the embedded system's component processes.
 It is our belief that the issue of reasoning about control is one that must be addressed by anyone interested in developing more powerful problem solving systems, whether those systems are intended as expert systems or as models of human cognition.
 Moreover, it is a central premise of our research that such systems require soft control.
 By this term we mean the following: The ability to apply problem solving techniques to the problem of control Itself (i.
e.
, to reason about control) The ability to select from alternative control plans the one that is most appropriate in a particular task environment The ability to apply general (albeit less powerful) knowledge when specific domain knowledge is unavailable The ability to opportunistically deviate from a selected control strategy as a response to new information.
 Soft control yields a flexibility of interaction among the various components of domain and control knowledge that allow for opportunistically allocating resources to activities most likely to make efficient progress in completing the task at hand.
 2.
METAC0GNITI0N and CONTROL First, let us discuss control in terms of human cognition by consider the vast amount of psychological research on the use of strategies to guide processing.
 A brief examination of research on this topic shows that, in any given task context, some particular processing strategy may be proposed as the organizer and controller for a more basic set of cognitive skills.
 Strategy guided models 121 have been offered as a description of many types of cognitive skills.
 Examples include models for text processing (e.
g.
, Clark, 1978), logical inference (Revlin & Leirer, 1978), memory retrieval (Brown, 1978), perception (Kolers, 1972), and so forth.
 Perhaps a generalization and expansion of the idea of processing strategy is Flavell's (1976) concept of metacognition.
 Metacognition refers to cognitive processing involving knowledge about other cognitive processes or the results of other cognitive processes.
 One place where this concept has been used extensively is the research on the topic of learning strategies (e.
g.
, O'Neil, 1978; O'Neil & Speilberger, 1979).
 This research demonstrates the ubiquity of task specific strategies.
 Each strategy appears to be a kind of specialized "control plan" that organizes the cognitive processes underlying performance in a particular task domain.
 This, in turn, suggests that there exists some general mechanism to produce these specialized control plans and to monitor their use.
 Although little work has been done to determine the characteristics of the metacognitive mechanism, we note the following important features .
 First the diversity of strategies that arise in different contexts indicates that these metacognitive structures are typically highly "tuned" to the specific problem domain Thus, both creation and selection for use of such control plans is a function of specific domain knowledge.
 Second, the use of strategies is opportunistic in that use of one strategy may be interrupted or even abandoned in favor of another known strategy as a response to some special circumstance that is noticed during task performance.
 Third, control can revert to more general knowledge and problem solving techniques when situation specific knowledge is insufficient.
 These observations together indicate that metacognition Is probably best modeled as what we refered to above as a mechanism for soft control.
 Now let us consider the need for soft control in the context of expert systems in Artificial Intelligence research.
 We wish to show that there is a need for soft control in expert system just as that required for models of human cognition.
 Recall Feigenbaum's argument, mentioned earlier, that the control problem for expert systems is secondary to the problem of representing sufficient knowledge about the problem domain.
 The knowledge in an expert system embodies primarily expert "rules of thumb" and descriptions for when such knowledge is applicable.
 Any such rule of thumb is typically a large chunkof domain specific knowledge that has compiled into it the control that would have been necessary to take the several smaller steps that are equivalent to it.
 Reasoning with such large chunks produces shorter inference chains which, therefore, greatly reduce the magnitude of the control problem for managing these inferences.
 In this sense most expert systems simply finesse the control problem by relying upon a very powerful set of domain specific principles that embody both domain knowledge and control assumptions for use of that knowledge.
 Unfortunately, the exclusive use of expert rules can have severe limitations.
 The powerful domain principles of the expert system are usually only plausible rules of inference which do not embody logically necessary relationships.
 Hence, expert systems of this sort can fail precipitously at the limit of their knowledge, that is, when the system encounters new situations for which the special rules do not apply.
 When such rules fail the system is unable to retreat to weaker but more general methods of inference to determine such things as why the rule failed in this case, how to modify it to fit, or at least, how to start from smaller and less efficient but more universal principles to derive a response to the new situation.
 That is, control is too rigid to allow the system's performance to gracefully degrade as the limits of its expert knowledge are reached.
 A general solution, which we have adopted, is to provide the expert system with an ability to revert to the more basic form of problem solving when the expert rules do not apply.
 However, control methods for using the expert rules will probably be useless for the more complex inferences required when using general principles.
 So the expert system must be able to select (or construct) a new control plan that is appropriate for the type of knowledge being used at each point in the task.
 Moreover, the system must detect when and how to make a graceful shift from one mode of inference to another.
 In general, the system must be able to develop or select from a stock of control plans that allow the system to use a variety of types of knowledge during task performance.
 Therefore, to build a more flexible expert system or a more general cognitive model, one must design a system that has the ability to reason about control.
 Furthermore, the system must be able to select an appropriate control regime for a specific task context.
 It must have the ability to apply expert "rules of thumb", or, when such rules are not available, it must be able to engage in novel reasoning using finer grained and less specific logical rules.
 And it must be able to decide when to do which.
 That is, either a cognitive model or an expert system needs a means to provide soft control.
 3.
THE EXPERT SYSTEM CONTROLLER (ESC) Next, we briefly describe some features of an expert system we are developing that realize the concept of soft control.
 As stated earlier, the primary application of this system is as an expert system to control other expert systems.
 However, in creating a problem solving architecture in which both domain and control plan reasoning are supported, we are developing a type of model that may also be valuable as a framework for developing cognitive models in which metacognitive processes, as well as the processes and knowledge they control, can be explicitly described.
 In order that our Expert System Controller (ESC) have the capability to provide soft control, it must have the following features.
 An architecture which supports problem solving about selection, modification, and use of control plans as well as problems within a substantive problem domain.
 A representation language for expressing control relations (e.
g.
, sequencing, tests, parallelism, etc.
) The ability to opportunistically modify or 122 abandon a control strategy in response to new information.
 ESC is an extension of the HearsayIll problem solving system (Erman et al.
, 1981).
 HearsayIll is a "blackboard model" in which knowledge 1s represented by a collection of individual processing components called "knowledge sources" (KSs).
 KSs embody the knowledge associated with a particular part of a problem solving task and are activated by the occurence of patterns on a "communications blackboard".
 KSs can interact during problem solving by leaving new 'triggering" patterns on the blackboard that activate other KSs.
 Since more than one KS can be activated at a time, a "scheduler" is provided that makes decisions as to the firing order of the activated KSs.
 (For the reader unfamiliar with the architecture of blackboard models, see Rummelhart, 1977, pp.
 103116.
) HearsayIII provides blackboard structures for both domain and scheduling purposes and provides for the implementation and use of knowledge sources for scheduling as well as domain knowledge sources.
 Thus, reasoning about scheduling can be accomplished by methods that are consistent with those used for problem domain reasoning.
 In order to extend the problem solving capabilities of this model to the full domain of control concepts we are adding an explicit control representation and a mechanism to react to that representation.
 The control notions that can be represented include Programmatic control relations (e.
g.
, sequential, parallel, or conditional) Nonprogrammatic control relations (e.
g.
, cooperative subprocesses [all of which combine to contribute to some goal] versus competitive subprocesses [each of which provides an alternative way to achieve a subgoal]) Descriptors of problem structures, goals, and knowledge sources.
 Descriptors of hierarchical plans as well as descriptors of conditions under which control "jumps" out of such a plan in a nonhierarchical way.
 Methods based on some work we have been doing using the DempsterShafer calculus (Shafer, 1976), to express preference relations among plans and activities (cf.
 also, Barnett, 1981).
 Besides developing an explicit representation for reasoning about control, we are augmenting the architecture of Hearsay1II to fully support the control domain as a problemsolving activity.
 This extension provides abilities such as the following Interpretation of control plans in the representation alluded to above.
 Filling out of partially specified control plans using domain independent control knowledge to affect the elaboration Optimization of execution within plans by using any applicable general knowledge.
 Construction of control plans using preference relations supplied by scheduling knowledge sources when more specific control constraints are not available.
 Conmunication of plan progress to scheduling knowledge sources, thus allowing the scheduling knowledge sources to modify and Improve plans opportunistically.
 4.
CONCLUSIONS The explicit control representation and other modifications we are making to the basic HearsayIll architecture provide a means to achieve soft control in a problem solving system.
 We believe this model will be useful as a framework for building expert systems that have greater flexibility and power than those currently available.
 This framework should also interest cognitive scientists whose concern is models of human cognitive since it provides a framework for a model in which metacognitive processes are treated uniformly with all other cognitive processes.
 Newell (1980) has pointed out that, if we are to get rid of the homunculus that always controls the processes of cognitive models, we must incorporate into those models a representation of the way that strategies arise from general and domain specific knowledge as a response to task conditions.
 Perhaps the issues that we have raised in developing our notion of soft control will help to evict this homunculus.
 Note: This research was supported by Defense Advanced Research Projects Agency contract MDA 90381C0335.
 Views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official opinion or policy of DARPA, the U.
S.
 Government, or any other person or agency connected with them.
 References Barnett, J.
 A.
 Computational Methods for a Mathematical Theory of Evidence.
 In Proc.
 7th Joint Conf.
 on Artificial Intelligence.
 IJCAI, Vancouver, B.
 C , 1981.
 Brown, A.
 L.
 Knowing When, Where, and How to Remember: a Problem of MetaCognition.
 In R.
 Glaser (Ed.
), Advances in Instructional Psycholgoy, Hillsdale, N.
J.
: Lawrence Erlbaum Associates, 1978.
 Clark, H.
 H.
 Linguistic Processes in Deductive Reasoning.
 Psychological Review, 1978, 72(4), 387404.
 Erman, L.
 D.
, London, P.
 E.
, & Fickas, S.
 F.
 The Design and Example Use of HearsayIll.
 In Proc.
 7th Joint Conf.
 on Artificial Intelligence.
 IJCAI, Vancouver, B.
 C.
, 1981.
 Feigenbaum, E.
 A.
 The Art of Artificial Intelligence.
 In Proc.
 5th Int.
 Joint Conf on Artificial Intelligence, pages 10141029.
 IJCAI, Cambridge, MA, 1977.
 Flavell, J.
 H.
 Metacognitive Aspects of Problem Solving.
 In L.
 B.
 Resnick (Ed.
), The Nature 123 of Intelligence, Hillsdale, N.
 J.
: Lawrence Erlbaum Associates, 1976.
 Kolers, P.
 A.
 Some Problems of Classification.
 In J.
 F.
 Kavanaugh & I.
 G.
 Mattingly (Eds.
), Language by Ear and by Eye: The Relationships between speech and Hearing, Cambridge: M.
I.
T.
 Press, 1972.
 Newell, A.
 Reasoning, Problem Solving, and Decision Processes: The Problem Space as a Fundamental Category.
 In R.
 S.
 Nickerson (Ed.
), Attention and Performance, Hillsdale, N.
 J.
: Lawrence Erlbaum Associates, 1980.
 O'Neil, H.
 F.
 (Ed.
).
 Learning Strategies.
 New York: Academic Press 1978.
 O'Neil, H.
 F.
 & Speilberger, C.
 0.
 (Eds.
).
 Cognitive and Affective Learning Strategies.
 New York: Academic Press 1979.
 Revlin, R.
 & Leirer, V.
 0.
 The Effect of Personal Biases on Syllogistic Reasoning: Rational Decisions from Personalized Representations.
 In R.
 Revlin & E.
 Mayer (Eds.
), Human Reasoning, Washington, D.
C.
: Winston, 1978.
 Runmelhart, D.
 E.
 Human Information Processing.
 New York: Wiley 1977.
 Shafer, G.
 A Mathematical Theory of Evidence.
: Princeton University Press 1976.
 124 STYLES OF THINKINGt FROM ALGEBRA WORD PROBLEMS TO PROGRAMMD4G VU.
 PROCEDURALTTY' Kate Ehriieh Elliot Solowsy Valerie Abbott Department of Compater Science Yale UniTersitj P.
O.
 Box 2158 New Haven, Connecticut 00520 1.
 ABSTRACT Algebn word problenu are often sorprisingly hard for college stadenta to solTe.
 Howerer, more stndenta are able to solre these problems coneetlj when asked to write a compater program, than when asked to write an equation.
 W e hare also foond that programmers, with the same level of math experience as nonprogrammers, do consistently better on the algebra word problems, after only one semester of an introdactory programming class.
 W e argae that some of the difTicnlty associated with the algebra word problems can be traced to misconceptions aboat what the algebraic expression represents.
 Students often appear to use an algebraic expression as if it were a static description rather than as denoting an active operation being performed by one number to get another nnmber.
 Although programmers may be equally prone to such misconceptions, it seems that experience with programming helps them to overcome these misconceptions, by encouraging them to develop a more active, procedural view of the problem.
 2.
 INTRODUCTION In recent work, Clement and Lockhead [Clement, Loehhead, and Monk, 1080] have demonstrated that there is a class of apparently simple algebra word problems that studenU find very difTicult U> solve correctly.
 A typical problem is shown as Example 1 in Table M .
 W h e n Clement et al gave this problem to a gronp of engineering studenU they found that only 0 3 % of the group gave the correct response of S ̂  OP.
 The most common wrong answer was: OS ̂  P, the reversal of the cotreet answer.
 In another problem, also shown in Table 21, in which there are two integrals, only 2 7 % of the class were able to produce a correct answer.
 These findings are very robust and have been replicated !n a number of studies (e.
g.
 Soloway et al, 1982; Clement et al, 1980; , Kaput, 1979 ).
 Clement and his colleagues (Soloway et al.
, 1982, Clement, Loehhead, and Monk, I980|.
 carried out videotaped interviews with some of these students to try and find the source of the errors They identified two principal kinds of strategies that students were using to solve the problems.
 Some students used a syntactic, word order matching strategy, in which the order of key words, such as 'student' and 'professor* and the numbers from the problem description, were mapped directly onto the order of symbob appearing in the equation.
 Paige and Simon (Paige and Simon, 19e0| have also argued for the weaknesses inheront in this kind of direct trmnalstion strategy.
 Another strategy that students adopted can be characterised as 'static comparison'.
 For instance, one student described the equation in the following manner There's six times as many stndeati, which meaas it's six students to one professor and this (points to SS) is six times as many students as there are professon (points to IP).
 'This work « u mpportcd by tbt National Science Foundation, under NSF Grant IST81I4M0.
 What's wrong with these strategiesf Their main problem is that students seem to have a static, descriptive view of algebra.
 For instance, students who espouse the strategy denoted as 'static comparison' seem to want the algebraic expression to represent directly the relative sites of the objects in the problem.
 In so doing, they treat the variables such as S and P as standing for 'students* or "professois" rather than for the nuTFiber of students or the numier of profeasora.
 But, algebra does not function as a description in the same way as English provides descriptions.
 The correct equation, S ̂  OP does not describe the sizes of the groups, rather it denotes an equivalence relation that would obtain if one of the groups, the professors, were made six times larger.
 In this way, the algebraic expression represents an active operation that is performed on one number to obtain another number.
 3.
 IMPACT OF PROGRAMMING: PROCEDURALITY If the correct conception of algebra is an active, procedural one, then putting students in an environment that encourages them to adopt a more procedural approach should help them to generate correct solutions to the algebn word problems.
 Programming is such an environment.
 Indeed, Papert (Papert, 1971] has claimed for some time that learning to program can enhance problem solving skills.
 In previous research (Clement et.
 aL, 1980, Soloway et al.
, 1982], we found that significantly mora students could solve the problems correctly when the problem was presented in the context of writing a computer program than ia the context of an equation.
 W e have also conducted videoUped interviews with some of the students who were unable to write the equation [Soloway et al.
, 1982].
 In several cases, we found that the same student was able to solve the problem in the context of a computer program but not in the context of an equation.
 even when there were only a few minutes separating the two solutions.
 These results support the claim that it a easier to write a program to solve a certain class of problems that to write an equation.
 4.
 PROGRAMS VS EQUATIONS! THE CONTRIBUTION OF PROCEDURAL WORDING In the study reported In [Soloway et al.
, 1982), the instructions for the two versions of the problem are worded a little differently.
 In particular, the instructions for the program version are themselves more procedural than the instructions for the equation version.
 Thus, it may be that the critical factor in the study was the wording of the instructions rather than any difference between writing an equation or a program.
 If the wording was the critical factor, however, there should be a difference between the two kinds of wording for nonprogrammers as well as programmers.
 In the new study we used three versions of the algebra word problem; these are shown in Table 41.
 The equation and the program version are the ones used in the previous study; the 125 function •ersioa is new.
 W e n n thii study with students who had DO prognmming experience as well as with students who had taken at least one programming course.
 The programmen receired all three Tersions, while the nonprogrammers were giren the equation and the function Tersions of the problem.
 Each student saw only one rersion of the problem.
 The data, which are shown in Table 42, show that the procedural wording of the instructions had no effect on accuracy for the nonprogrammers.
 The programmers, on the other hand, did write more correct equations when giren the procedural instructions than when given the original, equation version.
 As in the previous study, there was also a significant improvement for writing programs over writing equations with nonprocedural instructions.
 The results show that the procedural wording of the instructions only improves peiformaaee if students have had programming experience.
 One implication of these result* is thai proeedoral warding alone is not sufficient to induce people to adopt a mors active riew of algebra; people need experience in a procedural domain such as progiumming.
 6.
 TRANSFER EFFECTS FROM PROGRAMMING TO ALGEBRA The results of the previous study suggest that it is experience with programming rather than the preeedurality of the instructions that is critical.
 In the next study we examined more directly whether programmers do better on the algebra word problems than nonprogrammers, when the problems are presented in the standard non^proeedurai context.
 W e constructed a large diagnostic '«st containing 17 algebra EXAMPLE 1 Givca the foUowiag statemeat: 'There an six times as maay aUdcats as ynltmon at this Uaivenitr* WriU aa eqaatin to repieatat the above statement.
 Use S for the aamber of stadeatt sad P for the aambsr of profaMon.
 • Result: 0 3 % correct • Typical wrong answer OS « P EXAMPLE 2 Girea the foUowiaf statemeat: 'At Miady's restaaraat, for every foar people who order cheesecake, there are Rve people who order stnideL' WriU aa eqaatioa to repreaeat the above statemcat.
 Use C for the namber of cheesecakes ordered aad S for the aombet of stradds ordered.
 • Result: 2 7 % correct • Typical wrong answer 4C — 5S Table 31: EXAMPLES OF ALGEBRA WORD PROBLEMS PROBLEM 'At Mindt't rtttaurant, far even low ptoplt mho orim ekeuteakt tktrt art Jim peopi* vko oritr ttmid.
 • 1.
 E Q U A T I O N Write a mathematical equation to represent the above statemeat.
 2.
 PROGRAM Write a computer pragram which eaa be esad to calealato the aamber of cheesecakes ordered when nppliad with the namber of stmdsli ordered.
 3.
 F U N C T I O N Write a mathematical fvnctioa which eaa be used to caieolate the aamber of cheesecakes ordered when sapplied with the aamber of stnideis ordered.
 Table 41: E X A M P L E S O F W O R D I N G word problems as well a* filler items.
 The test was administered to 28 people with no programming experience and 32 people who had just completed a semester of an introductory programming course.
 The group* were equated for level of math experience and in many other respects had similar academic background*.
 Many of the people taking the programming course had majors in nonscientific subject* such as History or Englbh, while some of the nonprogrammers had majors in fields such a* psychology which includes some math experience is the form of statistics.
 All the problems were presented in a nonprogramming context and none of the problems had procedural wording.
 Over the 17 problems, the nonprogrammer* got an average of 04.
5% of the problem* correct while the ptogrammet* got an average of 7 5 % of the problem* correct.
 This difretenee between the group* wa* significant (t — 4.
7, p < 0.
0006).
 Although the average performance between the two group* differed by only 10%, the significance of the difference refleeu a small but consistent improvement over all the problems for the programming group.
 It may be argued, that although we controlled for level of math experience, and academic background, the programming group as a whole were smarter than the nonprogrammen.
 If this is the ease, we should expect to find a fairly constant rate of improvement over all the problems.
 However, the data do not support that argument.
 Some sense of the kind of advantage conferred by programming experience can be illustrated by examining one set of problems that were included in the test.
 There are three main forms in which the solution equation can be expressed.
 It can be expressed as a multiple , e.
g.
 5C — 4S; as a ratio, e.
g.
 C/S •• 4/5; or with a single variable on one side, e.
g.
 C — 4/5 S.
 The wrong solutions are most often expressed in the form of a multiple, the ratio is the form students seem most familiar with, and the third form is the one appropriate to the equation written in a computer program.
 W e included in the test, a set of problems in which people were given solution fragments in each of these three forms.
 The percent correct completions for the two groups of subjects are shown in Table 51.
 W h e n we compared performance on each version of the problem acroes the two groups, we found that there was no reliable difference between 126 N O N  P R O G R A M M E R S FUNaiON EQUATION CORRECT 82 73 INCORRECT 40 49 Equation «s Function: N.
S.
 PROGRAMMERS FUNCTION EQUATION PROGRAM CORRECT 71 48 77 INCORRECT 32 63 22 a.
 CONCLUSIONS There are a number of reasons why prognnuning maj enhance certain problem aolTing abilities.
 These reasons range from the explicitness required bj the sjmtax of programming languages, through to the practice of 'debugging' and number cheeking that is encouraged in programming.
 Howerer, perhaps the main benefit of programming is that it prorides the student with a model of an actire input/output transformation which functions as a metaphor of change.
 It seems clear that people should be encouraged to derelop sldUs that help them to construct these kinds of models.
 The results of the studies we reported, suggest that these skills are best dereloped in the context of learning to program.
 Referen Equstion ys Function: p < 0.
01 Equation »s Progrta: p < 0.
001 Function «s Prograa: N.
S.
 T»bl« <t.
3i The number of people grrea each problem type who produced a correct and iaeomet solution (•uitipis) ? C = ? S (ratio) ? C NONPROC 36S PROC SOS 68S 78$ Clement, J.
, Lochhead, J.
, and Soloway, E.
 .
 fbstd'v* Effeett of Computer /Vofratmrnnf On StudenW Under$tandint of VariaUe* and Equation: Pioceediagi of the National ACM Conference, Nashville, Tenn.
, 1980.
 Clement, J.
, Lochhead, J.
, and Monk, G.
 Ttauislation OifHcultie* in Learning Mathematics.
 Amcrtean iWa<Aema(iea/ Montkl^, 1980, 88(4), 28^Kaput, J.
 Mathematics and l.
eaming: Roots of Epiatemologieal Status.
 In J.
Lochhead ft J.
 Clement (Eds.
), Copntiv Proce— Inotmction,: Franklin Institute Press, 1979.
 Paige, J.
 and Simon H.
 CognitiTe Processes in Solring Algebra Word Problems.
 In ProUem Solvinf Reatarck, Method and Theorv,: John Wiley and Sons, New York, 19M.
 Papert, S.
 Teaehinf Children to t* Mmthematieimne Vtram* Teaehint Aiout Mathemotie: Technical Report 249, MIT Al Lab, 1971.
 Soloway, E.
, Lochhead, J.
, Oement, J.
 Doe* Compvter Programming Enhance Problem SolTing AbiUtyf Some PositiTe ETidence on Algebra Word Problems.
 In R.
 Seidel, R.
 Anderson, B.
 Hunter (Eds.
), Computer Uteracf, New York, NY: Academic Press, 1982.
 (single Isttsr) ? C =  S T 361 59S TabU Sli EQUATION FRAGMENT: Percent correct responses for each solution type the programmers and the nonprogrammen except on the fragment that had the form of a single letter on the left hand side (x^ — 3.
3S, p < .
10).
 These daU mitigate against claims that the programmers may hare done better because they were smarter.
 Moreover, the data suggest that experience with programming confers quite specific problem solving skills to other domains such as algebra word problems.
 127 Arithmetic Procedures in Everyday Situations Jean Lave University of California, Irvine The ubiquity and unremarkable character of routine activities such as grocery shopping qualify them as apt targets for the study of thought in its customary haunts.
 For the same reasons, such activities are difficult to analyze.
 I approach the task, however, in the conviction that the understanding of problem solving depends on an integrated conceptualization of the culturally crystallized activityinsetting within which problems are realized.
 I have chosen to focus, therefore, on a social institution, the supermarket, which is highly structured in relation to a clearly defined activityinsetting, grocery shopping.
 The Adult Math Skills Project at U.
C.
 Irvine has as its goal to explore arithemetic practices in the daily lives of their users.
 One branch of the project seeks to develop both theory and method for analyzing decisionmaking processes in grocery shopping, including the role of arithmetic in these processes.
 Michael Murtaugh's project, on which I draw heavily here, involved extensive interviewing, observation, and experimental work with twentyfive adult, expert grocery shoppers in Orange County, California.
 Detailed transcribed observations of preparation for shopping, a major shopping trip, and its aftermath provide data for the analysis sketched here (and set out in detail in our recent paper.
 Recounting the Whole Enchilada: The Dialectical Constitution of Arithmetic Practice.
 The Orange County residents vary in age from 21 to 80, in income from $8,000 per family to $100,000, and in schooling from 8th grade to an M.
A.
 Twentytwo are female; all are native speakers of English whose schooling took place in U.
S.
 public schools.
 Certain aspects of activity settings have durable and public properties.
 For example, the supermarket is a durable entity—a physically, economically, politically and socially organized spaceintime.
 The supermarket, in this sense, is called an "arena.
" The supermarket as arena is outside of, yet encompasses, the individual, providing a higher order institutional framework within which "setting" is constituted.
 The setting of grocery shopping is the arena as acted in by the individual.
 The setting is the shopper's edited version of the arena, generated by his or her routine grocery shopping activity in the supermarket.
 As setting, some aisles of the supermarket do not exist as part of a shopper's field of action, while others are finefeatured areas in which the shopper routinely makes several choices and still others serve only as broad cues to a particular, routinely purchased items.
 It is in this sense that it is possible to talk about the dialectical relation of setting and activity.
 A shopper passes the generic products with a sudden comingintofocus of their funny, plain appearance.
 She stops to investigate, realizes there is a tradeoff between the comforts of known products and the possibility of lower prices.
 This creates a new category in her repertoire of moneysaving shopping strategies, which in turn leads her to attend to it on the next trip, and on later trips perhaps, to make a regular check at this aisle before proceeding elsewhere.
 The setting for future shopping trips is thereby transformed into a more extensive routine route, and the activity of grocery 128 shopping is transformed by change in the setting.
 On future visits a review of pricesavino possibilities on a small but diverse set of products will precede consideration of the brand name projects in their usual locations.
 Grocery shopping is composed of repeated processes of decision making which have the effect of reducing numerous possibilities to single items in the cart on the basis of qualitative characteristics which differentiate items.
 Arithmetic problem solving is both an expression of and a medium for dealing with stalled decision processes.
 It Is, among other things, a move outside the characteristics of the product to its characterization in terms of a standard of value, money.
 It brings the particular decision process to an end if arithmetic calculation leads to a decision to purchase a particular item.
 Given these circumstances and the predicament shoppers face, presented with an abundance of goods to choose from but no choice other than to make choices, arithmetic problem solving very often acts as a rationalization of essentially arbitrary "choices.
" Support for this interpretation of the role of arithmetic calculation in routine decision making (as serving to produce rational accounts for choices which are only apparent) comes from Murtaugh's research on decision processes used by shoppers in choosing grocery items.
 He demonstrates that arithmetic, if utilized in the course of choosing a particular grocery item, is employed near the end of the process, when the number of choices still under consideration is no greater than three and rarely greater than two.
 Thus, a partial analysis shows that thirteen shoppers purchased 450 grocery items.
 Of these items.
 185 involved snag repair of some variety, and 79 of these latter Items involved problem solving which utilized arithmetic.
 In all there were 162 episodes of calculating, approximately two calculations per item on which calculation occurred.
 It would be difficult to picture arithmetic procedures as major motivations driving shopping activity.
 Justifying choices just before and after the fact is a more appropriate description of the common role of arithmetic in shopping.
 So far I have said that a "problem" in routine activities is an interruption or snag in individually constituted routine and that arithmetic is often used in a rationalizing capacity to overcome snags.
 A third critical characteristic of problem solving follows from the character of activitysetting relations as a whole (as analyzed in the full version of the paper): The relation between activity and setting is a dialectical one; (arithmetic) problem solving is part of that activityinsetting and thus must conform to the same dynamic.
 It follows from this position that the act1v1tyinsett1ng of grocery shopping is crucial in shaping problemsolving activities.
 The data support this view.
 In the course of our research, shoppers took an extensive paperand pencil arithmetic test, covering integer, decimal, and fraction arithmetic, using addition, subtraction, multiplication and division operations.
 The sample of shoppers was constructed so as to vary in amount of schooling and in time since schooling was completed.
 Problemsolving success averaged 59% on the arithmetic test, compared with a startling 100*—errorfree—arithmetic in the supermarlcet, and this in spite of the fact that a number of problems on the test were constructed to have exactly the same arithmetic properties as problems grocery shoppers successfully solved in the supermarket.
 Subtest scores on the math test are highly correlated with each other, but none correlates significantly with frequency of arithmetic problem solving in the supermarket.
 Number of years of schooling is highly correlated with performance on the math test but is not significantly correlated with frequency of calculation in the supermarket.
 Years since schooling was completed is significantly correlated with math test performance but not with grocery shopping arithmetic.
 However it may be noted that my position is not one of extreme situational specificity.
 Although there is not time to discuss it here, I take the view that any activityinsetting is interelated with interpenetrates, other activitiesinsettings.
 These relations are the basis of the generality, in the sense of spread, or multiple use of, knowledge across situations, including arithmetic.
 But the main point here is to illustrate the dialectical form of arithmetic problem solving in the routine activitysetting of grocery shopping.
 A successful account of problemsolving procedures will explain two puzzles uncovered in preliminary attempts to analyze grocery shopping arithmetic.
 The first is the errorfree arithmetic performance in the supermarket by shoppers who made frequent errors in parallel problems in formal testing situations.
 The other is the frequent occurrence of more than one attempt to calculate during a single decision segment of shopping.
 First it is useful to make explicit what Is dialectical about the process of problemsolving.
 The routine nature of grocery shopping activity and the location of arithmetic at the end of decisionmaking processes about grocery items within the activity of grocery shopping suggests that there must be rich content and shape to a problem solution at the time arithmetic becomes an obvious next step.
 Problemsolving under these circumstances is an iterative process involving moves between what the shopper knows and the setting holds that might help, on the one hand, and what the solution looks like, on the other, since many of the solution's parameters are already in place as the result of the prior process of deciding, up to a point, what to purchase.
 The dialectical process is one of gapclosing between strongly specified solution characteristics and the inputs and procedural possibilities for solving the problem.
 Thus, a change in either solution shape or resources of information leads to a reconstitution of the other: The solution shape is generated as the product of the decision process up to the snag.
 Problem identification changes the salience of setting characteristics.
 This in turn suggests, more powerfully than before, procedures for generating a specific solution; information and procedural knowledge accessed by mind and/or eye make possible a move towards the solution or suggest a change In the solution shape that will draw it closer to the information at hand.
 These basic points are illustrated by a shopping episode in which the shopper, J.
 (a 43 year old woman with 4 children), discusses the price of noodles—noodles last week and this, big packages and little ones, different brands, and so on, as she replaces the family supply.
 She begins by taking a package of noodles off the shelf and putting it in her cart.
 It is the kind she customarily buys.
 Perfection elbow noodles, 32 ounces, $1.
12.
 As she does so she conwents that it is cheaper than American Beauty noodles.
 It is clear from her action of placing the package in the cart that a decision has been made, and the decision prefigures and shapes the course of calculations to come.
 The arithmetic problem J.
 will work on during the rest of the segment is to decide which is the better buy, which gives more for the money: The one she purchased, or one of three sizes of American Beauty Noodles: 24 ounces for $1.
02, 48 ounces for $1.
79, or 64 ounces for $1.
98.
 After a digression about goulash, J.
 and the anthropologist, (M.
), get back to noodles.
 J.
: There's large elbow /noodles/.
 This Is really the too—large economy bag.
 I don't know if I, probably take me six months to use this one I don't know, I just never bought that huge size like that.
 I never checked the price though on it.
 But being American Beauty it probably costs more even in the large size.
 J.
 here has reiterated somewhat more firmly than before her opinion that American Beauty is more expensive than other brands.
 The resolution of the numerical comparison is taking on clearer outlines.
 The next Interchange starts a process of simplification of the arithmetic comparison.
 She transforms large number of ounces into a small number of pounds.
 M.
: That's what, that's 6.
 .
 .
 4 pounds and what did I buy, 2? J.
: It's That this is phrased as a question suggests that she is making a comparable change from ounces to pounds for the 32 ounce package in her cart as she has just made for the 64 ounce package on the shelf.
 The problem now looks like this: Perfection noodles, 2 pounds $1.
12 American Beauty noodles 4 pounds $1.
98 She eventually simplifies the problem to 2 pounds for $1, 4 pounds for $2.
 She concludes that they are equivalent buys, at 50 cents a pound.
 But she does not stop there.
 Her point is to demonstrate a difference in price per pound, so she starts yet another round of calculation with more specific prices, going back to $1.
12 in order to produce a precise enough calculation to demonstrate the difference.
 Simplification does not become an end in itself, then.
 In these calculations it is just one possible step whose relation with the solution shape may lead either to an end to calculating, a return to more complex forms of calculation, or to a change in the solution shape.
 All this goes by so fast that only repeated analysis of transcripts make clear that calculation has taken place at all.
 Meanwhile, in the course of the discussion there is yet another price comparison.
 J.
 looks at two packages of American Beauty spaghetti noodles, and sees what appears to be a justification for not buying a large bag: 129 J.
: But this one, you don't save a thing.
 Here's 3 pounds for a dollar 79, and there's 1 pound for 59.
 Having a solution, "you don't save a thing," confirmed, "Here's 3 pounds for a dollar 79 and 1 for 59," the process of looking at the bags while reading off the information required to justify the conclusion, leads to reassessment of the information: For the "1 pound package" in fact does not weigh, a pound.
 Immediately she adds a second round of calculations: J.
: No, I'm sorry, that's 12 ounces.
 No, it's a savings.
 Two rounds of calculation have just occurred.
 The first produced the conclusion that in both cases the noodles were essentially 60 cents per pound.
 Recognizing the weight error, only a "less than" inference would be required to move to the conclusion that the big bag is in fact a saving.
 And in the second round this is just what she does.
 However, the "only" is deceptive, as is the conciseness of the transcript, if they convey the impression that the arithmetic is simple in paperandpencil, placeholding algorithmic terms.
 The problem in these terms would be to discover if one point seven nine divided by three is equal to point fine nine.
 An active process of simplification is required to transform this set of operations into the form that J.
 achieves.
 This kind of simplifying transformation, which preserves relations and simplifies numerical representations, is characteristic of grocery shopping arithmetic.
 The pattern of moves made in the course of J.
's calculations is something like this: She starts with a probable solution, but inspection of evidence and comparison with the expected conclusion cause her to reject it.
 Given corrected information, she recalculates and obtains a new result.
 This whole process is what is meant by "gapclosing:" the weaving back and forth between the expected shape of the solution and the information and calculation devices at hand, in the course of which each is repeatedly transformed by the other.
 One characteristic of the preceding account has been the need to assign multiple functions to individual moves in gapclosing arithmetic procedures.
 It seems to be the nature of dialectically constituted processes to pose severe problems of description.
 Perhaps one must give up the goal of assigning arithmetic problems to unique locat'1onsin the head or on the shelf—or labelling one element in a problemsolving process as a calculation procedure, another as a checking procedure; or even distinguishing the problem from its answer.
 In such circumstances statement of the problem, solution to the problem, procedure for solving the problem, and checking activity, may be analytically indistinguishable.
 In discussing these implications of a dialectical model of problem solving I have, among other things, been developing an explanation of the multiplecalculation, errorfree arithmetic practiced in grocery shopping.
 Errorfree arithmetic is not errorfree because people do not make mistakes.
 Indeed, multiple calculations to repair initial difficulties, are the rule rather than the exception.
 Typical gapclosing procedures occur in "rounds.
" Dialectical processes of problem solving account for the multiple calculation phenomenon.
 Why is the end product of calculating so extraordinarily accurate? The analysis cannot be presented in complete form here.
 But a major reason is that dialectical processes of problemsolving make possible powerful monitoring by the problem solver, due to the juxtaposition of problem, problemsolving procedure, solution and checking activity.
 I have tried to cover a great deal of ground in a very short time.
 The talk can hardly do more than indicate the nature of the issues taken up in the paper itself.
 But in closing it might be useful to stress the major point of the exercise: the dialectical constitution of problemsolving in any particular activity setting grows out of the encompassing dialectical relation between the activity and setting within which it takes place.
 The nature of the dialectical relation between grocery shopping and the supermarket generate the routiness of the activity in setting in relation to which problems are constituted as snags or interruptions.
 Likewise, the dialectical relation between shopping and market setting generates the overdetermined nature of choice and the rationalizing character of problem solving; and the activ1tyinsetting directly gives the dialectical character to problem solving for it is part of that activityinsetting.
 Arithmetic problem solving is not "the same" everywhere and at all times.
 But this in no way negates the possibility of developing general theory about the constitution and reconstitution of activity in setting.
 130 How novices solve physics problems Eileen Scanlon and Tim O'Shea Open University Milton Keynes Bucks England Abstract  The paper outlines ten claims about the performance of novices solving problems In physics.
 The claims are then evaluated from the literature, and from the results of a study where synchronised audio tape and paper and pencil working records of novices solving kinematics problems were made.
 Some alternative methodologies for investigating these claims are discussed and the future direction of the work indicated.
 Introduction  The longterm objective of this study is to design Instruction to improve physics problem solving.
 Various claims about how novice students go about solving physics problems can be made.
 Here are some of them.
 1.
 Novices solve physics problans more slowly than experts and pause more frequently between the retrieval of successive equations or chunks of equations than experts do.
 2.
 Novices have erroneous ideas about basic physics concepts.
 3.
 Novices make meta statements (comments about the problem solving process).
 4.
 Novices never check back or use real world checking.
 5.
 Novices work backwards.
 6.
 Novices don't apply physical intuition to a problem before actually trying to solve It.
 7.
 Novices don't possess rich Internal representations for complex problems.
 8.
 Novices are not goal directed.
 9.
 Novices use consistent strategies in problem solving.
 10.
 Novices can be taught helpful proble strategies.
 solving These claims will be discussed using two sources of evidence  reports in the literature, and the results of a study of solution protocols in kinematics.
 The claims are stated in order of certainty.
 This paper will take each claim in turn and assess its validity.
 Some are as yet unsubstantiated.
 Future work which might substantiate them will be discussed.
 The literature  Previous anpirical studies of how physics problems are solved have examined the knowledge structures discussed in the basic concepts (Shavelson 1974, Relf 1981) , examined students prior conceptions of the physical world (misconcepts) (Champagne & Klopfer 1980, Gilbert & Osbourne, di Sessa 1981) and examined solution protocols (Larkin et al, 1981).
 The Cyclops study  The study reported here involved the collection of solution protocols and their analysis in terms of problem solving strategies displayed and misconcepts revealed (Scanlon, 1981).
 Some recordings of Open University (OU) first year students attempts to solve physics problems were made.
 The equipment consisted of a sumna graphics bitpad and microphone connected via an interface box to a stereo cassette recorder.
 This equipment based on the OU's Cyclops technology allows recordings of pencil and paper working to be made on one track of the cassette tape while the other track records any words spoken during the process.
 The equipment has been used to record children's mathematical behavior (O'Shea St Floyd, 1981).
 The system combines in a convenient form the students voice with a synchronised dynamic record of what he or she writes.
 This study has established that the system was suitable for recording the mixture of handwriting, diagrams and numbers present in a typical adult physics problem solving protocol.
 The subjects were seven first year Open University students who had Just completed three weeks of study on elementary mechanics.
 Their backgrounds varied from no previous experience of physics to A level physics.
 Open University students are adults returning to study after some work experience.
 In the attempt to attain an understanding of problem solving skills in physics there are advantages in using adult students.
 Skill at solving physics problems is not a natural competence but a learned skill  and one learned with considerable difficulty.
 Adults language competence is fully developed so the notorious difficulty of achieving verbalisation in protocols should be simplest with them (Horowitz 1980).
 The problems selected for the students were simple kinematics problans.
 From the replay of the Cyclops tape the sequence of operations, timing Information on each individual step, and the verbal protocol indicates problem solving decisions made.
 Discussion of the claims 1.
 Novices solve problems more slowly than experts, and pause more frequently.
 Expert and novice protocols have been compared to highlight the differences (Simon & Simon, 1978, Larkin, 1981).
 Experts have been found to be 4 times faster at solving problems than novices.
 The pause times between the retrieval of successive equations or chunks of equations were quite different (Larkin 1979).
 Experts produced streams of equations without pausing while novices paused most of the time.
 In the Cyclops study the students experienced many difficulties with the problems.
 2.
 Novices have erroneous ideas about basic physics concepts.
 Trowbridge (1979) describes students problems with 131 Che concepts of velocity and acceleration.
 The weaker students In Che Cyclops study also had a very hazy notion of acceleraclon and constantly confused it with velocity.
 Velocity they confused vlth speed and average speed.
 See Fig.
 I.
 However, the fact that students have an imperfect understanding of some of the concepts they need to use doesn't seem particularly surprising.
 When their understanding drops below a cerCaln level Its obviously the most Important thing Co worry about.
 If you can't tell acceleration from velocity you're going to have trouble doing problems about either.
 However, what does it mean to understand a concept completely? Wouldn'c some level of understanding be good enough for all practical purposes? We have to solve problems In real life in the absence of complete understanding.
 Some of the 'misconcepcs' research seems also to draw questionnable conclusions.
 In Andy di Sessa's (1980) study of how high school students manipulate a dynaturtle he says reveals mlsconcepts about force and acceleration  but these students score highly on conventional tests.
 It reveals something about Che physics not having got 'into the musculature' but who plays tennis using Hewcon's Laws? 3.
 Novices make meta statements Simon & Simon (1978) observed the difference in the number of meca statements made.
 By meta statements they mean comments made by the students about the problem solving process.
 Experts made fewer meta statanents than novices who made more frequent comments on errors made, the physical meaning of an equation, or overall direction.
 This findlnK is on Che surface surprising but may be to do with the novice voicing uncertainties that an expert doesn't share.
 In the Cyclops study students made many such coDimencs.
 4.
 Novices never check back The weaker students in the Cyclops study made many mistakes due to not carefully reading the problem statement.
 They misread distances for speeds, final speeds for average speeds etc.
 and despite the fact that these mistakes led them into numerous problems never looked back to check.
 Having struggled through to an answer to the problem the novices never checked back to see whether the answer made sense In terms of the original problem statement.
 The better students in the Cyclops study highlighted the behaviour of Che novices.
 They checked back Co various stages  both during the problem to make sure they'd solved a subproblem checked back to see if their answer made sense in terms of the numbers given in the problem.
 They also tried various ways of doing a problem and if something didn't seen to be working out they were prepared Co start again in a different direction.
 They seaned less prepared Just to plod on regardless of whether Che soludon path Chey'd chosen seemed Co be successful or not.
 5.
 Novices work backwards The most contentious difference quoted in the literature is the difference in solution path 'working forward  working backward' (Simon & Simon 1978) .
 The expert works from the information given in the problem, producing equations which can be solved using the Information given.
 The novice starts by generating an equation which contains the unknown he is trying to find and works backward.
 This finding seems strange but may be is explained by the confidence felc by Che expert chat the problem is soluble.
 This behaviour was not observed in the Cyclops study.
 Students mostly started by writing down the equations they knew.
 6.
 Novices don'C apply physical intuition Experts seem to apply Co prior quallCacive analysis or physical InCuidon Co Che problem before accually starting to solve it.
 What seems Co characterise this analysis is the ability to represent the problem physically in terms of some real world mechanisms (Larkln & Reif 1979).
 If novices relied on their physical intuition they might create a false analysis, (as they have erroneous ideas about basic physics concepcs).
 In Che Cyclops study among the novices no connection with the real world in solving the problem was apparent.
 7.
 Novices don't categorise problems into types and don't possess rich internal representation The expert has built up a set of fundamental sets of subroutines for basic types of problems and this classification into problem types takes place very quickly (Chi, Feltovlch i Glaser 1980).
 An investigation of this appears in Chi, Glaser & Rees (1981).
 In answer to the question 'how does an expert construct a more efficient subroutine for a complex problem?' they reply that 'the facility lies in the rich internal representation the expert haa generated' The Cyclops study did not Investigate this claim.
 8.
 Novices are not goal directed An important difference between experts and novices is that experts are confident enough that they will eventually succeed to be willing to try out various approaches.
 In Che Cyclops study.
 Che novices were playing a game of pretending Co solve the probleois.
 However they knew that really they couldn't so it didn't really matter what chey wrote down.
 They appeared to conspire with Che experimenter to pretend chat they were looking for a solution path and made all sorts of meta comments.
 "I see.
 .
 .
 well suppose I try", but Chey were Just trying to get any answer so that the problem wlij.
 go away.
 9.
 Novices use consistent strategies in problem solving Several of the weaker students in the Cyclops study had 'a way of doing problems' The protocols are littered with statements like: "This is how I always do problems" "I always draw a diagram" or "write down all the equations I know" or "write down everything in sentences".
 The last example is very interesting and came from a student who has a great deal of trouble with mathematics.
 She says that she never knows whether something makes sense unless she can write it down in the form of a sentence so this is how she argues her way to a solution.
 The surprising result of the Cyclops study is chat the poorer students did seem to be exhibiting some sort of consistent way of coping with being asked to do physics problems which they didn't know how to do.
 This is ronlniscent of Kathy Larkln's experience of adults doing arithmetic problems.
 They could remember how to do some things  they had 'Islands of Knowledge' (Larkin, 1978), The adults in the Cyclops study had 'Islands of tactics' They were not basing their behaviour on understanding of physics but on some sort of 'coping strategy'.
 Discussion  The first four claims seem incon132 trlvertable.
 The flfch is substantiated In the literature but seems in contradiction to the eighth claim from the present Cyclops study that novices aren't goal directed.
 They only occasionally conspire with the experimenter to pretend Chay are.
 The sixth and seventh claim are also substantiated though vhat 'a rich internal representation' means has yet to be defined or demonstrated.
 Most of these claims are in fact disclaimers  they're statements about vhat the novices don't do.
 The ninth claim is made on the basis of the present study and remains to be fully substantiated  and it is a positive claim.
 The tenth claim is in fact a pious hope.
 Larkin & Relf (1979) have designed instruction based on their models of expert physics problem solvers but the effects of the Instruction have not been extensively tested.
 The Cyclops study will be developed to investigate how best instruction can be designed to improve the performance of novice physics problem solvers.
 tlany of the claims discussed above while well substantiated don't seem to provide many clues about how to do this.
 Correcting erroneous ideas about basic physics concepts is highly relevant and may even be related to the question of physical intuition and rich internal representation.
 (Reif a Heller 1982).
 Also Important are questions of strategy checking back etc.
 To proceed further models must be built which reflect the features of novice problem solving which instruction would be designed to remedy.
 Three options for this modelling are possible.
 construct models based on the means ends knowledge development distinction (e.
g.
 Larkin & Simon, 1981) take an expert system and alter it to generate the types of errors which students make (e.
g.
 Priest 1979) construct models based on the notion of a direct translation model of physics problem solving.
 The first option is one which has already been explored.
 Larkin, McDermott, Simon and Simon (1980) describe two related models  the knowledge development model which simulates expert behaviour and the Means End model for novices.
 These are a development of the Simon and Simon working forward and backward models which solve dynamics (as well as kinematic) problems and are more elaborated to simulate behaviour more closely.
 The similarities between these two methods are more important than the differences.
 Both require an overt statement of goals.
 In the Cyclops study the novice students didn't have goals however.
 These models seem too sophisticated to ever generate the types of error seen in the study.
 A similar objection can be raised to the second option.
 Mecho is a program written in Prolog which solves a wide range of mechanics problems from statements in English (Bundy 1979).
 Both Mecho and also Isaac (Novak 1976) could in principle be altered to generate the types of errors described above (Priest 1979).
 However the behaviour of these novices seem much too inexpert for that to seem psychologically valid.
 We propose to take a direct translation program like STUDENT (Bobrow 1968) which operates In the domain of algebra story problems and alter it to handle these limited physics problems.
 Students in the Cyclops study confused velocity with acceleration, treated any quantities in the problem almost as being completely interchangeable.
 This program would be able to generate such errors and account for many of the errors observed In the study.
 If such a model could generate a large proportion of the errors observed, this would provide strong evidence of the need for instruction to correct the misconcepts.
 Assuming this activity was successful how could it be used to advantage to design some physics Instruction? There are two complementary approachFirstly it is necessary to build confidence.
 The consistency of strategies observed among novices is In fact a weakness which needs to be corrected.
 They were probably suffering from a lack of confidence which would allow them to explore alternative methods of solution.
 They need more opportunities to explore these.
 Secondly misconcepts should be corrected.
 The literature on computer games applied to physics (VJhite 1980) is attractive.
 These provide a way of combining an aid for the exploration of concepts with a way of flexibly exploring how to solve a problem that might be enjoyable.
 The modelling activity described above would provide a basis on which the exploration of concepts in the game would be designed.
 Conclusion  Many claims about how novices solve problems have been made.
 By using synchronised audio tape and paper and pencil working records, it has proved possible to investigate more carefully the extent to which some of these claims are true.
 A stronger test will be to base instructional material directly on the types of misconcepts and affective features associated with this view of novices physics problem solving behaviour.
 Acknowledgement  We are grateful to Jon Slack for helpful comments on drafts of this paper and to Andy di Sessa, Paul Feltovich, Jill Larkin, Fred Reif and Richard Young for helpful discussions.
 Our thanks are also due to Claire Jones for typing this paper.
 References Bobrow, D.
G.
 'Natural language input for a.
 computer problem solving system' in Semantic Information Processing edited by Marvin Minsky MIT (1968) Bundy, A.
 et al Solving mechanics problems using meta level inference in IJCAI  6 pp 10171027 (1979) Champagne, A.
B.
, Klopfer, L.
E.
, Anderson, J.
H.
, 'Factors influencing the learning of classical mechanics', American Journal of Physics 8, 10741975 (1980) Chi, M.
 Feltovich, P.
 & Glaser, R.
 'Categorisation and representation in physics problan solving' Cognitive Science 5, 121152 (1981) Chi, M.
 Glaser, R.
 and Rees E.
 'Expertise in problem solving' in R.
 Sternberg (Eds.
) Advances in the Psychology of Human Intelligence Hillsdale, N.
J.
: Erlbaum di Sessa, A.
 Unlearning Aristolellan physics A study of knowledge based learning DSRE, internal report, MIT, Boston (1980) 133 Gilbert, J.
K.
 Osbourne, R.
T.
 'Identifying science students concepts: the Interview about Instances approach' In W.
F.
 Archenhold (Ed.
) Cognitive development research in Science and Mathematics, Leeds (1980) Horowitz, L.
 'A study of adults solving algebra word problems' unpublished Ph.
D.
 Thesis MIT (1980) Larkin, J.
H.
, McDermott, J.
, Simon, D.
P.
, Simon, H.
A.
, Models of competence in solving physicsproblems.
 Cognitive Science 4, 307345 (1980) Larkin, J.
A.
, Reif F.
 'Understanding 4 teaching problem solving in physics' European Journal of Science.
 Vol.
 1, No.
 2.
 191203 (1979) Larkin, K.
M.
, An analysis of adult procedure synthesis in fraction problems ICAI Report No.
 U B.
B.
N.
 Novak, G.
 Computer understanding of physics problems stated in natural language.
 Tech.
 Report TR NL 30 Report of Computer Science Austin, Texas (1976) O'Shea, T.
 4 Floyd A.
 'Recording childrens' mathematical behaviour' In J.
A.
M.
 Howe, P.
M.
 Ross (Ed.
) Microcomputers in Secondary Education: Issues & Techniques, Kogan Page (1981) Priest, T.
 'A design for an Intelligent mechanics tutor' CAL Research Group Technical Report 29 Open Dniverslty (1981) Reif, F.
 Heller, J.
 'Knowledge structures in physics' unpublished Internal report, SESAME project, University of California (Berkeley) (1981) Reif, F.
 & Heller, J.
 'Cognitive mechanisms facilitating human problem solving in physics: formulation and assessment of a prescriptive model' unpublished Internal report SESAME project University of California (Berkeley) (1982) Scanlon E.
 'Improving problem solving in physics' CAL Research Group Technical Report No.
 22, Open University (1981) Shavelson, R.
J.
, 'Methods for examining representation of a subject matter structure in a students memory' Journal of Research in Science Teaching.
 11(3) 231249 (1974) Simon, D.
P.
, Simon H.
A.
 'Individual differences in solving physics problems' In R.
 Slegler (Ed.
) 'Children's thinking: what develops? Hillsdale N.
J,, Erlbaum (1978) Trowbridge, D.
E.
 and McDermott L.
 'An Investigation of student understanding of the concept of velocity in one dimension' American Journal of Physics 48(12) (1980) White, B.
 'Designing computer games to facilitate learning in physics' unpublished Ph.
D.
 thesis, D.
S.
R.
E.
, MIT (1980) Fig.
 1 Seven types of errors identified in the Cyclops study 2.
 Confusing the meaning of the various terms used (velocity with acceleration, velocity with speed, speed and acceleration with position, average velocity with instantaneous velocity) Incorrect interpretation of the word 'uniform' 3.
 Misreading of items in the problem statement 4.
 Drawing misleading diagrams 5.
 Incorrectly remembering equations of motion to be used 6.
 Substituting the wrong values into the equations of motions 7.
 Misunderstanding the meaning of a variable in an equation 134 ASSOCIATIVE ENCODING AT SYNAPSES, William B Levy, Center for Cognitive Science, Brovm U.
, and Dept.
 of Neurosurgery, U.
 Virginia Med.
 Sch.
, Charlottesville, Virginia The last 10 years has seen publication of several neural models capable of performing concept formation, associative learning and recall, and pattern recognition.
 At the base of all these models is one or another rule for associative synaptic modification.
 Thus the exact modification rule seems to distinguish one model from another.
 Certainly specifying such a rule severely restricts the remaining degrees of freedom left to the modeler.
 Our neurophysiological research has concentrated on establishing the existence of at least one such "synaptic learning rule" and, further, on specifying the properties of this rule sufficiently so that a differentital equation describing the modification rule could be reasonably proposed.
 The simplest form of the equation Is dm^j dt yjCcXi  m^j) mj J is the strength of the synapse formed by the afferent i and the postsynaptic cell j;y.
 is the net excitation of the j^ " postsynaptic cell; c is a positive constant; Xĵ  is the frequency of the i'*' afferent which by definition is nonnegative.
 The exact form of y is not known though it does appear to be a nonnegative function that increases with postsynaptic excitation and decreases with postsynaptic inhibition.
 Often y is assumed to be a linear function of synaptic excitation.
 By performing the Indicated multiplication it is seen that the term ycx corresponds to Hebb's predicted encoding of correlated pre and postsynaptic activity.
 The other term (ym) is needed to account for the erasable aspect of these synapses.
 With the linear assumption for the size of y, the equation predicts a globally asymptotically stable solution in which the value of the synapses on a cell go to the dominant eigenvector of the autocorrelation matrix of the Inputs.
 The initial discorvery of long term potentiation by Bliss and L^o provides the first clear neurophysiological evidence for a cellular analog of memory storage.
 Today this experimental model is an even better analog since long term potentiation in the dentate gyrus of the hippocampus is known to be an associative phenomenon dependent upon the correlated activity of convergent excitatory afferents.
 The combined coactivity of a presynaptic input and sufficient synaptic excitation of a postsynaptic cell produces an Increase of the synaptic strength of the particular synapses Involved in this coactivity.
 Moreover, this potentiation is accompanied, at other converging synapses, by the phenomenon of long term depression an erasurelike process that decreases synaptic strength.
 Those synapses which are convergent to an activated postsynaptic structure but which are themselves Inactive during the postsynaptic activity lose synaptic strength.
 The experiments are performed using anesthetized rats.
 The response studied is the extracellularly recorded monosynaptic response elicited when the entorhlnal cortex is stimulated and the recording electrode is in the dentate gyrus of the hippocampus.
 Both a synaptic waveform and, should enough synapses be active, cell firing are measured.
 It is the synaptic response which corresponds to the synaptic strength of the differential equation.
 This synaptic response takes place almost immediately after stimulation of the entorhlnal cortex so there is no time fof disynaptic circuitry to confuse the interpretation of the response we measure.
 Critical to these experiments is the fact titat both the left and right entorhinal cortices project to both the left and right dentates.
 This arrangement allows the insertion of two quite distant and independent stimulating electrodes.
 Thus one electrode is used to activate a small number of synapses which generate our dependent measure.
 The other stimulating electrode is used to control a very large number of converging excitatory synapses.
 Stimulation with this second electrode quite effectively fires the postsynaptic granule cells in the dentate.
 In most situations the test electrode does not activate enough synapses to fire these cells.
 "Conditioning" stimulation consists of brief, high frequency trains of duration and frequency within the range that has been observed in the entorhinal cortex of behaving rats.
 The initial important observation is that high frequency conditioning stimulation through the test system alone does not alter the test system itself.
 However, when high frequency conditioning of the test system is paired with high frequency stimulation at the other electrode (which is able to produce a powerful postsynaptic response), then long term potentiation obtains in the test system.
 That is, paired conditioning through both stimulating electrodes produces an increased synaptic response when the the synaptic response of the weak test system is measured alone.
 Importantly, high frequency conditioning of the powerful syston alone depresses the size of the synaptic response of the weak test system even though the powerful system through which the conditioning stimulation is delivered is itself potentiated.
 These experiments, then, show that the powerful synaptic activation is permissive for change while the exect type of change that occurs is a function of the actual activity at each particular synapse.
 Although we cannot stimulate and record from a single synapse, the conclusions can be advanced and defined by using logical arguements and the natural advantages of the entorhinaldentate system.
 In particular it should be realized that because of the totally bilateral nature of this system there are four responses that can be measured when recording and stimulating bilaterally.
 In fact the synapses of one weak pathway are totally intermingled with the synapses of the strong pathway which provides the permissive stimulus and in addition are themselves collaterals of the strong pathway terminating in the other dentate.
 From experiments as described above that take advantage of these facts we draw three conclusions.
 1.
 Long term depression occurs at a synapse that is surrounded by many other synapses that have simultaneously undergone long term potentiation.
 Calculations show that one such depressed synapse centered within a cubic micrometer is surrounded by 20 synapses that potentiated.
 2.
 Potentiation and depression can be differentially induced at different synapses of the same granule cell.
 This is deduced from experiments in which electrophysiological convergence is well demonstrated.
 3.
 Potentiation, depression, or no change can occur simultaneuously at sister synapses of one individual afferent.
 Such conclusions lead to the further conclusion that individual synapses are individually modu135 lated.
 In fact by extrapolation we argue that such individual modulation has practically been demonstrated.
 For no matter how small the weak response, so long as it is measureable, it can be potentiated by the proper paired conditioning.
 Concluding that long term potentiation requires convergent coactivity gives rise to several questions including "What is the meaning of coactivity?" Varying the relative time that the conditioning stimulations are delivered through each of the two stimulating electrodes, produces a quantitative definition of coactlvIty.
 Using conditioning trains of 17.
5 msec duration, simultaneous (±0.
5msec) conditioning through the two stimulating electrodes produces the most potentiation of the weak test system.
 If conditioning of the weak test system follows immediately, or later, conditioning of the powerful input, then the test system Is depressed.
 If the weak system is conditioned and then with a delay of 100 msec or more the strong system is conditioned, the test system Is depressed.
 However, if the weak system is conditioned and within 20 msec of the end of this conditioning train the powerful system Is conditioned, then the weak test system is potentiated.
 Thus coactivity Is welldefined to a 37.
5 (20+17.
5) msec window.
 It might be seen that the temporal requirements have some qualitative resemblance to classical conditioning.
 However the result places a.
 very specific contralnc on neural models of associative learning.
 In particular association of external events separated by all but the shortest time requires the use of circuitry that performs as a delay line.
 One final issue concerns the unit of postsynaptic integration which makes a decision about the sufficiency of converging stimulation and then goes on to permit synaptic modification.
 Rather than the cell body as Hebb proposes, our current evidence Indicates that individual dendritic domains or branches can function independently.
 By taking further advantage of entorhinaldentate anatomy.
 It is possible to activate synapses on different parts of the granule cell dendrites in a controlled and specific manner.
 When this is done with minimally sufficient postsynaptic responses, we find that it is possible to Independently potentiate or depress synapses in one of the two dendritic domains.
 At high Intensities, however, the dendritic domains show an interaction for potentiation.
 If this independence is the normal functioning mode,then this adds substantial complexity to models of the nervous system, perhaps increasing the number of functional units tenfold.
 REFERENCES Bliss, T.
V.
P.
 and Umo, T.
,J.
 Physiol.
 232, 331356, 1973.
 Levy, W.
B.
, Brassel, S.
E.
, and Moore, S.
D.
, Neuroscience.
 1982, in press.
 Levy, W.
B.
 and Steward, 0, Brain Res.
 175.
233245, 1979.
 Levy, W.
B.
 and Steward, 0.
 Neuroscience, 1982, in press.
 McNaughton, B.
L.
, Douglas, R.
M.
 and Goddard,G.
V.
, Brain Res.
 157, 277293, 1978.
 Wilson, R.
C.
, Levy, W.
B.
 and Steward, 0.
 Brain Res.
 176.
 6578,1979.
 Wilson, R.
C.
, Levy, W.
B.
, and Steward, O.
, J.
 Neurophyslol.
 46.
 339355, 1981.
 136 NEURAL HARDWARE AND THE PRESUMED AUTONOMY OF PSYCHOLOGY William Bechcel Barnard Ecanow Unlveralty of Illinois Medical Center Two types of arguments are comnonly given In support of the claim that cognitive psychology can predict and explain cognitive processes without troubling Itself with the details of neurophysiology.
 The Justified conclusion of these arguments is often thought to be that artificial intelligence research, which tries to model human thought on electronic hardware, "can be regarded as psychology in a particularly pure and abstract form [since] the same fundamental parameters are under direct experimental control (in the programming), without any messy physiology or ethics to get in the way" (Haugeland, 1981, p.
 31).
 This paper will challenge the validity of both arguments for this claim and propose how features of neurological hardware may have consequences for the performance of human cognition.
 The first argument for the autonomy of psychology originated with Putnam (1975) and has been developed most extensively by Fodor (1974 and 1979).
 Putnam noted that in the case of computers the same programme can be run on very different types of hardware.
 Fodor extended this argument by aotlng that the same hardware can run alternative programmes.
 Thus, reduction of programme states to hardware states or of psychological states to neurophysiological ones is impossible.
 Psychology must thus remain a "special science" seeking its own explanatory scheme.
 The second argtiment for the autonomy of psychology is also designed to establish the additional claim that programming computers is a particularly apt way to learn about human cognitive performance.
 This argument starts with the assumption that all the information humans can employ in their cognitive operations must cross their sensory thresholds and be encoded within them.
 Since It is only this encoded information that the mlndbraln can employ in its information processing, Dennett describes the mlndbraln as a "syntactic engine" Dennett, 1981) .
 This argument then construes thought processes as formal processes in which one manipulates the symbols in which the information is encoded.
 Assuming that the mlndbraln has an effective procedure for these formal processes.
 Church's thesis claims that there is a recursive process for computing it.
 Each formal process can therefore be computed by a Turing machine.
 Invoking the concept of a universal Turing machine (i.
e.
, one that can imitate every specific Turing machine), the argument concludes that thought processes can be modelled on a universal Turing machine.
 Psychology can direct Itself to producing computer or Turing machine models that replicate human thought and not concern Itself with neurophysiology.
 As enticing as these arguments make the prospects of an autonomous psychology seem, they are seriously flawed.
 As Richardson (1979) has argued, even if the mapping between neurophysiologlcal states and psychological states Is manymany, that does not eliminate the possibility of an informative reduction of psychology to neurophysiology.
 All that is required are neurological conditions that are sufficient for determining the psychological states.
 Moreover, if the argument Putnam and Fodor use against the explanatory relevance of neurophysiology works, it also undercuts the simple appeal to programming models to explain cognitive functions.
 Just as the same programme can be run on different hardware, different programmes can account for the same behavior.
 Therefore, even if a programme perfectly mlnics human behavior, one has no assurance that it actually describes how humans manipulate symbols (cf.
 Bechtel, forthcoming).
 The second argument for the autonomy of psychology is Just as flawed.
 This argument moved from claiming that symbol manipulation can be modeled on a universal Turing machine to using actual computer programmes to model that process.
 Haugeland notes what is assumed In making that move: "with one qualification, universal machines can be built, that Is what digital computers are.
 This one qualification is that a true universal machine must have unlimited storage, whereas any actual machine will have only a certain fixed amount" (Haugeland, 1981, p.
 13).
 That qualification, however, has very far reaching consequences.
 Neither our brains nor digital computers come close to having the unlimited resources required by a universal Turing machines.
 With limited resources, however, neither brains nor computers can employ the kinds of algorithms that Church's thesis assures us exist for all decldable processes.
 So the use of Church's thesis and the concept of a universal Turing machine to Jtiatify using computer simllatlon as a way of studying human psychology is unjustified.
 Neither of these responses to the arguments for the autonomy of psychology from neurophysiology shows that psychology might not profitably be pursued in this autonomous manner or that computer modelling might not be the most powerful means of doing that.
 But they do undermine the assumption that artificial intelligence models provide an adequate basis for understanding human cognition.
 While not denying that such models can show us interesting features about cognition, we shall now argue that there is reason to believe that significant differences exist between human cognition and computer models of it.
 Limited resource capacity for problem solving dictates that one cannot always use procedures that guarantee correct results.
 For complex problems one must choose methods that yield correct results much of the time but are fallible.
 There are two fallible ways of using limited resources for dealing with problems whose optimal solution requires greater resources.
 One that has been studied much in recent years has been the use of heuristics (Cf.
 Simon, 1969).
 Heuristics are rules that are simpler than optimal algorithms, produce the same answers as the optimal algorithm much of the time, but that are subject to systematic errors because of the simplifications they use (Wimsatt, 1980).
 Tversky and Kahneman (1974) have developed an empirical research programme to discover the kinds of heuristics humans use in handling certain kinds of judgment tasks.
 A second way of solving the problem of limited resources is to manipulate the hardware of one's system to approximate the performance of a richer hardware system.
 As in the case of heuristics, a simplified hardware system that is developed to approximate a richer one may allow one to reach 137 correcc answers much of Che time, but will do so ac the cost of making errors under certain conditions.
 The hardware system of a Turing machine or a computer is linear and digital—information Is processed by linearly transmitting and modifying Information units which are perfectly distinct and so engender no ambiguity.
 One basis for the analogy between brains and computers is the assumption that the brain also utilizes a linear and digital processing mechanism—the neuron (von Neumann, 19S8) .
 Like the components of computers, neurons transmit electrical impulses linearly down their dendrites and axons with the action potential in Che axon being comparable to a digital binary signal In a computer.
 (Dendritic processes allow for a spectrum of responses, but these functions have been viewed as weighting and gating functions, which are easily replicated in computer hardware.
) In addition to these neuronal processes, which seem comparable to those realized in a Turing machine or computer, though, there is another transmission mechanism In Che bralo.
 This mechanism Involves a form of cransmission quite different than the linear and digital transmission of neurons and may provide a means for the brain to approximate the performance that would require a far richer linear and digital mechanism.
 One can best appreciate this mechanism by considering earlier stages in evolution.
 Long ago Hughling^ Jackson (188A) insisted that to understand the function of the brain one had to attend to Ics evolution.
 The brain is organized in an evolutionary hierarchy in which the lowest and first evolved parts of the brain regulate all bodily activities.
 The later evolved hi^ier centers function by modifying and regulating the earlier evolved lower centers.
 Before there were nerve cells, however, there existed a mechanism for Cransmission between cells.
 According to Oparin's (1965) model, cells originated when water Interacted with macromolecules and electrolytes to form a more fat like substance—protoplasm.
 The water around the molecules becomes structured in mich the sane manner as occurs in Jello and the whole unit behave like an oil drop with respect to the intercellular plasma.
 Ecanow (1982) has proposed chat the same process is responsible for forming multicellular aggregates.
 In these aggregates different thermodynamic states are found in the cytoplasm of che various cells (including a different state In the cellular interface or membrane) and in the Interstitual fluids.
 Already within these early cellular aggregates a mode of signal transmission exisCed.
 The different thermodynamic states of the cytoplasm, membrane, and Interstitual fluids are in dynamic equilibrium wich one another, wich a constant exchange of molecular substances occurring between che differenc scruccural unlcs.
 This exchange allows for a kind of transmission between cells: a change in the thermodynamic conditions in one cell will propagate rapidly to surrounding cells.
 This kind of transmission still occurs even after nerve cells have evolved with their more digicallzed and linearly direcced Cransmission capaciCies.
 This is particularly trxie in places where nerve cells are tightly bound together.
 This tightly organized pattern causes the water in che plasma surrounding Che cells Co become highly structured itself, affecting, in particular, Che solublllcy of Ions in Che plasms.
 Boch Che cells and che surrounding plasma become highly susceptible Co any chermodynamic changes Chac are induced.
 One of che prime causes of Chermodynamic changes is eleccrical activity propagated along neurons.
 Electrical energy alters the physicalchemical structure around the nerve cell.
 Once the change has occurred, the physicalchemical organization elsewhere will modify until equilibrium is once again achieved.
 Not only are these physicalchemical changes initiated by neural activity, they also reciprocally affect that activity.
 Neural activity depends on ion transfer, and this ion transfer is governed by the degree of structuring found at the cellplasma interface.
 One cell's firing changes this structuring around other cells and hence their poCentlal to fire.
 There Is, at this point, reason to believe this physicalchemical transmission mechanism is efficacious in humans.
 Since most anesthetic agents are biochemically inert, it is generally recognized that a physicalchemical mechanism must be involved.
 Following a suggestion from Bernard (1875), Ecanow et.
 al.
 (1979 and Ecanow, 1981) propose that anesthesia involves the formation of a highly structured matrix at the cell surface which becomes nonpolar and fatlike.
 Ion exchange is a polar process and so is blocked in s»ich a matrix.
 This model predicts that substances which decrease the structuring of water, generally polar molecules, chaotropic ions like urea and vitamin C, or increased temperatures, will produce an increase In mental activity.
 These effects have been observed in vivo.
 The insight of this model has been extended to account for the fluctuation between Increased and reduced mental activity found in manicdepressive patients (Ecanow and Klawans, 1974).
 This physicalchemical mode of transmission proposed by Ecanow (1982) differs from neural transmission in propagating three dimenslonally from Che Inlclal sice and in invoking a degree of response ChaC can vary over a continuous spectrtim.
 It is also very rapid.
 We cannot, at this point, make definitive claims as to its direct role in cognition, but we conclude with a speculative suggestion.
 Kandel (1978) has found that long term and short term habituation and sensitization in Aplysia (processes he takes to be forms of memory and learning) result from changing Che amounts of calculm ions (needed for transmitter release) available at the presynaptic cleft.
 Kandel does not account for Che change In calcium avallablllCy chac hablCuadon and sensldzacion produce, but one possible mechanism would be through alternation of the physicalchemical structures near Che presynapclc clefc.
 Such scruccurlng can occur in degrees and so accounc for che gradual "learning" of Chese responses.
 Moreover, such sCrucCures would be appropriately subject to change when new experiences produce neural activity in the area around the presynaptic cleft.
 The physicalchemical transmission mechanism provides the mindbrain with capacities for information processing quite different from the linear and digital capacities of neurons.
 Given che hard" ware llmlcations of the brain, it may well be that this three dimensional analogue mechanism of physicalchemical transmission provides the mindbrain a powerful cool for overcoming resource conscraints.
 The power of this mechanism, however, cannoC be sCudled by modelling with digical compucers that lack such cransmission capacities.
 138 REFERENCES Bechtel, William (forthcoming), "Two Common Error In Explaining Biological and Psychological Phenomena," Philosophy of Science.
 Bernard, Claude (1875), Lecons sur les Aneathetlques.
 Paris: Bailliere.
 Dennett, Daniel C.
 (1981), "Three Kinds of Intentional Psychology.
" In R.
 A.
 Healey (ed.
) Reduction.
 Time and Reality: Studies in the Philosophy of the Natural Sciences.
 Cambridge: Cambridge University Press.
 Ecanow, Bernard (1981), "A Comprehensive Theory of Anesthesia.
" Physiological Chemistry and Physics Journal 13: 2327.
 Ecanow, Bernard (1982), "Interstitial Conduction and the Emergent Mind.
" Journal of Pharmaceutical Sciences 71: viii.
 Ecanow, Bernard and Klawans, H.
 L.
 (1974), "PhysicalChemical Properties of Cellular Constituents and their Contribution to Neuronal Function," in H.
 L.
 Klawans, (ed.
) Models of Human Neurological Diseases.
 Amsterdam, Excerpta Medica.
 Ecanow, Bernard, Gold, B.
 H.
, and Ecanow, C.
 S.
 (1979), "Unified Theory of Anesthesia," Journal of Pharmaceutical Sciences 68: ivv.
 Fodor, Jerold (1974).
 "Special Sciences.
" Synthese 28: 97115.
 Fodor, Jerold (1979), The Language of Thought.
 Cambridge: Harvard University Press.
 Haugeland, John (1981), "Semantic Engines: An Introduction to Mind Design.
" In J.
 Haugeland, (ed.
) Mind Design.
 Montgomery, VT: Bradford Books.
 Jackson, J.
 Hughlings (1884), The Croonian Lectures on the Evolution and Dissolution of the Nervous System.
 London.
 Kandel, Eric (1978), "Small Systems of Neurons," Scientific American 238: 6676.
 Oparin, A.
 I.
 (1965), "The Pathways of the Primary Development of Metabolism and Artificial Modeling of this Development in Coacervate Drugs.
" In S.
 W.
 Fox (ed.
) Origins of Prebiologlcal Systems and of their Molecular Matrices.
 Hew York: Academic.
 Putnam, Hilary (1975), Mind, Language, and Reality: Philosophical Papers, Volume 2.
 Cambridge: Cambridge University Press.
 Richardson, Robert C.
 (1979), "Functionalism and Reductionism," Philosophy of Science 46: 533558.
 Simon, Herbert A.
 (1969), The Science of the Artificial, Cambridge: M.
I.
T.
 Press.
 Tversky, Amos and Kahneman, Daniel (1974), "Judgment Under Uncertainty: Heuristics and Biases.
" Science 185: 1124U31.
 von Neumann, John (1958), The Computer and the Brain.
 New Haven: Yale University Press.
 Wimsatt, William C.
 (1980), "Reductionistic Research Strategies and Their Biases in the Units of Selection Controversy," in T.
 Nickles (ed.
) , Scientific Discovery: Case Studies.
 Dordrecht: Reidel.
 139 The Integrated implementation Qi.
 Imaainal ^a^ Propositional C&i^ Slcuctutes IQ ih& Bcatn John Barnden Computet Science Department Indiana University, Bioomington, Indiana 1.
 intcMugtion I sketch a speculative model (to be presented in greater detail in (11) of the huruan brain's implementation of the temporary data structures appearing in cognition.
 I assume the following working hypothesis: The Representation Hypothesis.
 Much of human cognition is to be explained as the manipulation of data structures, in as literal a sense as the sense in which computers manipulate data structures.
 The model is not committed to any particular data structure 'language' in the brain, but it leads to interesting suggestions concerning such languages.
 The model unifies 'prepositional representation', 'imagery' [2] and perception.
 A background assumption I make is that the temporary data structures in the brain are physically implemented as shortlived patterns of 'neural enhancement'.
 These patterns can cause particular events (e.
g.
 changes in the patterns) to occur in the brain.
 The vague term 'neural enhancement' is intended to encompass possibilities such as higher than normal pulse activity (cf Hebb (3]) and disturbed dendriticpotential microstructure (cf Pribram [4]) .
 To avoid making unnecessary hardware commitments, however, I cast the model at a higher level of description which is intended still to allow relatively easy mappings down to the hardware level.
 It will become clear that the model postulates sharing of the mechanisms used in perception and those used in the implementation of temporary data structures.
 For the purposes of this paper, let us simplify matters by taking monocular vision to be the only sense.
 (A fuller account will be given in [1] .
) The following hypothesis is a proposal about visual mechanism, bearing family resemblances to proposals such as Marr's primal sketches [111.
 Again for simplicity, we assume the retina can be considered to be a 2D rectangular array of (possibly overlapping) receptive fields (finite in number).
 Ihs Vi5;i?n Hyppths?!?.
 a) The brain contains a number of permanent abstract entities called 'perceptual pattern matrices' (PPlls) .
 Each PPM is a 2dimensional rectangular array isomorphic to the retinal array of receptive fields.
 There is a set of 'enhancement types', and at any moment each element of each PPM has a 'degree of enhancement' for each type.
 The 'state' of a PPM is the current pattern of degrees of enhancement over the PPM.
 Retinal stimulation is converted by lowlevel preprocessing into a state of some PPM.
 The enhancement degrees at an element in the PPM for some enhancement types encode the presence of features in the element's corresponding receptive field.
 Examples of such features are line segments, edges, corners, textures, colours, etc.
 b) The possession of more than one PPM allows the brain to maintain very short term iconic memory (cf [12]) of retinal input, and to integrate succesive views.
 NOW it has been suggested that (conscious or unconscious) visual imagery is based on states of retinalike data structures (e.
g.
 Kosslyn [61).
 It has also been mooted that the mechanisms used in visual imagery are shared with visualperception mechanisms.
 Suppose we adopt these suggestions, in the sense of allowing the internal generation and manipulation of states of PPMs.
 If we closely followed the examples used by Kosslyn and others, the PPM states so manipulated would be spatialanalogue images, i.
e.
 would picture physical objects, crude maps, etc.
 I now claim that, assuming the brain can internally generate such images, there is a priori no reason to think that the PPM states it can generate are restricted to be such images.
 For instance, there is no reason to think that the brain cannot generate ('pictures' of) written words, abstract diagrams (perhaps depicting abstract network structures), or other symbolic shapes of nonpictorial, nonlexical form.
 (Once generated, the presence of such PPM patterns is no more bizarre than if the patterns had resulted from seeing words, diagrams, etc.
) These observations suggested to me the central postulate of the model:Iil£ Mill Hypothesis.
 a) Any temporary aata structure considered to reside at some moment in the brain is impiementg'a AS (pact iif) 1 state Qi J Single £££l ̂  && ̂  :issz.
 tsji (2£ (partial) StatSS Ql SevStal PPM?b) There exist processes which examine PPM states and can, if they detect suitable subpatterns, cause PPM state changes.
 These processes together with the PPIls are regarded as a production system [51, with pos140 sible concurrent firing of productions, zhi^ production system congtttUteS lil£ entire machinery Lh& kUlQ M £ IfiX .
Ul£ internal manipulaSj^n 21 tgmpgtscy gat? jtructutea.
 c) One enhancement type is called 'attention'.
 Elements with higher degrees of enhancement of attention receive preferential treatment by PPM manipulation processes.
 A locus of high attention values in a PPM can be slid around in a PPM to effect scanning.
 d) The response by patterndetection processes to PPK patterns is spatially continuous in the sense that the effect of 'spatial' deformations of patterns can be made arbitrarily small by making the deformations sufficiently small.
 e) To a first approximation, the effect of the presence of a pattern in a PPli is independent of the identity of the PPM.
 I) If approximately the same subpattern is simultaneously present within two different PPHs, and the attention enhancement of the elements used by the subpattern in at least one of the PPMs is sufficiently high, then the attention enhancement of both pattern instances can become boosted.
 Thus there may be implicit associations among PPM states.
 (No direct 'pointers' between PPMs are proposed.
) g) There may exist considerably more PPMs than are required by the Vision Hypothesis (for the purpose of receiving preprocessed retinal stimulation, maintaining iconic memory and integrating views).
 h) The issue of consciousness is not addressed by the model.
 There is no assumption that the brain is conscious of any of the PPM states existing at a given time.
 There is no assumption that when the brain is conscious of a visual image it is conscious of a single PPM state.
 It is sometimes suggested that a neural enhancement pattern might be some form of node/link structure representing propositional information.
 Lifting this idea to the abstract level of PPMs, it is quite conceivable that abstract, prepositional information is represented in the form of diagrammed nets.
 That is, nodes are localized groups of contiguous enhanced PPM elements, and links are chains or ribbons of such elements.
 (It is not, however, suggested that net patterns are particularly close to the precise net diagrams to be found in the literature, e.
g.
 [7].
) Nodes and links in a netlike PPM state can be considered to be associated to longterm knowledge by virtue of labels they are adjacent to, in that the labels are subpatterns which can be detected by some productions (see Main Hypothesis, part (b)).
 For example, a node label might be a special pattern which has (for us as theorists) the meaning 'dog': by virtue of suitable productions detecting the subpattern, the brain would take actions consistent with the node's representing a dog.
 It is worth noting that the 'dog' label coula be either a stylized picture of a dog or the word 'dog' itself! It could, however, be a subpattern of nonlexical nonpictorial form.
 The basic actions in the productions of Main Hypothesis part (b) include: movement of subpatterns within and between PPMs, deletion and creation of subpatterns, changes of enhancement degrees (especially of attention), etc.
 The action part of a production is tentatively proposed to have a simple sequential form.
 The productions are thought of as constituting LTM.
 The model allows, as a detail of this LTM, the existence of a longterm store of encoded PPM states: these can be decoded and read into PPMs, and can be encoded from the contents of PPMs.
 Some detection of subpatterns must be primitive in that it is achieved without the need to examine other data structures.
 I propose that, at least, some simple geometrical shapes, some stylized pictures, some words, and some specialized nonpictorial nonlexical graphic items (including nodes and links) can be primitively detected.
 (Much of this ability would arise forn maturation and experience.
) But nonprimitive forms of detection can be proposed.
 For example, by sliding a locus of high attention enhancement around in a PPM, a detection process (perhaps itself made up of production firings) could check for the presence of a piece of network by tracing it out.
 Also, the associative mechanism of Main Hypothesis part (f) allows the matching of two (not necessarily primitively detectable) subpatterns in distinct PPMs, where one of the subpatterns might be taken to be a template (of pictorial, network, orthographic or any other form).
 Note that the PPM production system can construct transformed versions of patterns to facilitate further processing.
 For instance, in the course of visual perception an abstract net representation of a scene could be constructed from a picture of it in a PPM.
 1.
 Selected implications The model unifies unconscious spatial imagery and prepositional representation at the same time as providina an (intermediate level) implementation of prepositional representation.
 A particular consequence of the Main Hypothesis is that abstract symbolic representations, spatialanalogue images constructeo in visual imagery, and images resulting directly from retinal stimulation are just special cases of PPM states.
 (A more popular route to unification  annotating prepositional structures with spatial information [8]  does not address the 141 issue of implementing propositional structures.
) The model can incorporate, in a natural way, hybrid forms of symbolism such as are found in, for instance, maps, cartoons (especially those v/hich include words), road signs, and many forms of semiabstract sketch and diagram.
 Moreover, the internal presence of such hybrid synbolism itiay be closely related to the fact that we deal with it externally with such naturalness, ease and frequency.
 The model may help to explain how the human capacity for abstract cognition evolved.
 That is, assuming that at some stage of primate evolution the Vision Hypothesis held and spatialanalogue PPM states could be internally generated and manipulated, it is plausible that the necessary pattern detection and manipulation operations could have evolved into a form which could deal with more abstract PPM states.
 (See Hinsky [9], Section 6.
5.
4, for another proposal in which abstract symbolic manipulation evolves from perceptual operations.
) I am just embarking on a computer simulation of a simplified, precise version of the model.
 This paper has only sketched a 'model schema' in which many parameters (e.
g.
 number and size of PPt'iS) remain unspecified.
 The first stage in the project is the exercise of developing a diagrammatic version of a simple production system derived from PSG [10].
 Ret'etences [1) Earnden, J.
A.
 'Imaginal Symbolism'.
 In preparation for journal submission.
 [21 Block, N.
J.
 (ed.
).
 ImaSJU HIT Press, 1981.
 [3] Hebb, D.
O.
 Organization ai.
 Behaviour.
 laiey, 1949.
 [4] Pribram, K.
H.
 Lanyuaqes oi.
 i^^ BJLAIR.
 PrenticeHall, 1971.
 [5] Waterman, D.
A.
 and HayesRoth, F.
 PattecnPirected Iniecence systems.
 Academic Press, 1978.
 [6] Kosslyn, S.
H.
 Imaafi AQd lilnd.
 Harvard University Press, 1980.
 [7] Findler, N.
V.
 Associative Networks.
 Academic Press, 1979.
 [8] Waltz, D.
L.
 'Toward a Detailed Model of Processing for Language Describing the Physical World'.
 IJCAI7, 1981.
 [9] Hinsky, M.
 'A Framework for Representing Knowledge.
' In Winston, P.
H.
 (ed.
), uifi psychQlpgy sil Cgmputec Vision McGrawHill, 1975.
 [10] Newell, A.
 'Production Systems: Models Of Control Structures' In Chase, W.
G.
 (ed.
), ^^isij^ IpformajLiAO Processing.
 Academic Press, 1973.
 [11] Harr, D.
 'Early Processing of Visual Information'.
 Phil.
 Trans, fia^.
 £2£.
 Lfiiuiiui, sertes a, 211, no.
 942, 1976.
 [12] Brown, R.
 and Herrnstein, R.
j.
 'Icons and Images'.
 In [2].
 Acknqwledqiiients I am grateful for suggestions and criticism from B.
 Chandrasekaran, G.
 Clossman, R.
E.
 Filman, D.
R.
 Hofstadter, H.
J.
 IntonsPeterson, S.
 Kwasny, J.
T.
 O'Donnell and D.
 Robinson.
 142 PROGHAMMERS" MENTAL MODELS 0? THEIR PHOGRJUMING TASKS: THE IHTERACTIOM OP REALWORLD KHOWLEDGE AHD PROGRAMMING KNOVfLEDGE Hank Kahnay & Marc Elsenatadt The Open University Hilton Keynea, England IHTHODUCTION This paper describes our ongoing research into the behaviour of novice programmers.
 We are interested in the mental processes which occur vhen novices are confronted with a problem statement, and the mechanisms by which they understand the problem, design an algorithm, code it, and (if necessary) debug it.
 Our research is a development of earlier work on problem understanding (Hayes i Simon, 1974), models of programmers' coding processes (Brooks, 19T7), and debugging (Suasman, 1975; Goldstein, 1975; Laubach 4 Eiaenatadt, 1981).
 We investigate students attempting to write recursive inference programs using a LOGOlike databasemanipulation language called SOLO (Eiaenatadt, 1978; Eisenstadt, Laubsch, i Kahney, 1981) Students are presented with a prototypical problem and solution couched in everyday terms in order to simplify the explanation of recursion: "Imagine a chain of 'KISSES' relations, e.
g.
 JOHN KISSES MARY KISSES FRED KISSES JANE, etc.
 A procedure called IB7ECT can propogate PLU all the way through the chain of KISSES relations, so we end up with JOHN HAS PLU, MART HAS PHI, etc.
" The example is explained to the students in great detail, including several pages of text, diagrams, and a workedthrough trace of a sample invocation of IKPECT.
 As one might expect, some students 'get it' (i.
e.
 understand this simple form of tailrecursion and the notion of propogating sideeffects through the data base), and some don't.
 The difference between those who 'get it' and those who don't can be accounted for by differences in (a) the abstractions they make from their first detailed example, and (b) the evaluation rules inherent in the mental models they use to 'run through' trial solutions.
 A SAMPLE PROBLEM AHD SOLUTION We investigated students solving several recursive inference problems, including one based on a realworld example so compelling that we could be 'certain' the nature of the task was perfectly understood.
 Here is a concise summary of the problem: Given a database describing objects piled up on one another as follows: on on on SANDWICH >PLATE >»EWSPAPEE >BOOK ate on on on SANDWICH >PUTE >NEWSPAPEH >BOOK etc has has has 1 > BULLBTHOLE < has Fig.
 2 As it turns out, even our 'crystal clear' example (fleshed out in considerably more detail) causes difficulty— it appears that those students who 'get it' can cope with either 'crystal clear' or 'muddy' recursive inference problems, whereas those who don't are stuck in either case.
 Fig.
 3 below shows the solution eventually produced by subject S8, one of the subjects who 'got it': TO SHOOT /X/ 1 NOTE A / HAS BULLETHOLE 2 CHECK /I/ ON ? 2A If present: SHOOT •; EXIT 2B If absent: EXIT Fig.
 3 sa's solution (the '•' are coreferential) and '?' Below is a summary of the protocol of subject S8 during the course of reading and solving this problem, but before any attempt to writs the code shown in Fig.
 3 Problem statements are underlined.
 The numbers are segments from the actual protocol.
 It has been condensed for expository purposes in this brief paper, but captures the highlights of the protocol.
 A complete version is described in Kahney (1982).
 "On page 80 of Units 2 i£ £ Jli loo^° <^ at a method for making a particular inference 'keep on happening .
̂  2 Is that called 'iteration'? No, 'recursion'.
.
.
 I think this is going to say something about what happens when you keep on applying a function.
.
.
through a database "In this option you are asked to imagine a state of the world in which there are six objects: this hypothetical world is highly structured: the sandwich is lying in the centre of the plate, which is sitting on the newspaper, which is lying on the book .
.
.
" Fig.
 1 write a program which simulates the effect of someone firing a very powerful pistol aimed downwards at the topmost object (SANDWICH), yielding the final database shown below: 4 .
.
.
 well you could also get out things like.
.
.
 sort of making inferences about 'if the sandwich is on the plate which is on the newspaper [then] the sandwich is on the newspaper'.
 "A database representing this state of affairs looks like this LFi"iT T].
 How imagine someone standing beside the table with a .
357 magnum pistol.
^ 143 8 Well, I would expect him to ahoot through all that lot then.
 I don't know why he wants to do It though.
.
.
 S8 began with a working knowledge of recursive procedures.
 At successive sentences SB set up expectations about what would come next and usually was in the position of predicting the information contained in the next sentence or two: she was always Just slightly ahead of the game.
 S8 is apparently using a 'recursion' schema to direct her attention during the reading process to important aspects of the problem statement.
 The first line of the problem statement has clearly triggered off an expectation of recursion [protocol segment Z], with a concomitant expectation of some 'function' to be applied 'through a database' [segment 2].
 The database structure [Plg.
 1 ] is consistent with her expectation of a standard transitivity problem [segment 4], even though this is not the problem to be posed.
 Her realworld knowledge about pistols and the spatial relationship of the objects in the problem combines with her expectations about transitivity problems to yield an expectation about what the protagonist in the problem statement will do [segment d].
 This expectation does not aeah with her knowledge of human motivations and intentions [segment s].
 Figure 4 depicts our representation of S8's internalized schema for recuraion.
 The details of the schema are derived from a variety of sources: transcription tasks, concept rating and sorting tasks, problemsolving tasks, and verbal protocols.
 RECURSITEPROCEPgHE GOAL: (ForBvery x In (ay applieato) do (achieve (my action) x)) ACTION: (a sideeffect 1dE?AULT (a NOTE))) APPLIESTO: (a transitivechain) SUEFACETEMPLATB: TO (namel "(a name)) (a parameter [default: X|) (my action) CHECK (a node) (a relation) (a wildcard) IP PHESE3IT: (a procedure with name •• namel with parameter  '••");EXIT I? ABSEHT: EXIT DONE EVALUATIOHHOLES: 1) (let parameter • the startnode from (my appliesto)) 2) (apply (my action) parameter) 3) (assert "(ACHIEVED ,(my action) .
parameter)) 4) (let parameter  (GetNextNode)) 5) (PorEvery x In (GetHestOfHodes) (assert '(ACHIEVED ,(my action) ,x)) TSIGGERS: "keep on happening"; reapply Figure 4: 38's schema for recursion Bearing in mind that slotnames are displayed against the lefthand margin (e.
g.
 GOAL, ACTION, etc.
), and that the function "my" is a crossreference to a slotfiller (e.
g.
 (my action)) we can paraphrase 38's schema for recursion as follows: The GOAL of a recursive procedure is to perpetrate a side effect on every element of the data structure to which it is applied, i.
e.
 a 'transitive' chain.
 (Knowledge about such structures is contained in S8's THANSITIVECHAIN schema, not depicted here, which indicates that a collection of nodes standing in a particular relation to one another is an essential component of recursive processing— 38 has abstracted this notion, although KISSES is not a transitive relation.
) The ACTION involved is typically the application of a MOTE primitive (which performs a database 'ASSERT').
 The SURFACETEMPLATE depicts raw SOLO code, with its own slots to be filled in during actual coding.
 It is based upon an exempla given in the textbook, and corresponds to rote learning of 'how to do it', rather than understanding of 'how it works'.
 (Subjects like 35, discussed below, have a poorer grasp of recursion and need only have a mental pointer to a place in the textbook where they can find a typical example to copy.
) 'How it works' understanding is reflected primarily in the GOAL and EVALUATIONRULES slots.
 The GOAL slot captures the essence of the 'generator plan' used in the programunderstanding planlibraries ol Waters (1978) and Laubsch a Eiaenstadt (1981).
 Th« EVALUATIONRULES slot depicts 38*3 technique for working through a mental model of the succession ol effects carried out by a body of SOLO code.
 The rules are clearly not sufficient to work as a SOLO interpreter, but rather depict the subject's own naive strategy for convincing herself that the code 'works'.
 The rules behave as follows: (1) instantiate the parameter, pretending that it's the first node in the chain (i.
e.
 SANDWICH); (2) imagine the main action being performed on that node; (3) make a mental note that the action has been achieved; (4) see what node is next in the database, traversing the crucial 'transitive' relation; (5) make a mental note that the action Is achieved on every node reachable along the 'transitive' chain.
 Below we present SB's protocol corresponding to the above evaluation rules, along with the relevant rule listed in square brackets, e.
g.
 [eRI], [ER2], etc.
 These protocol segments were recorded after 38 had written the program, but before she ran it.
 208 TO SHOOT.
.
.
 X, SANDWICH.
.
.
 [ERi] let's say X is a 210 First of all it NOTEs in the database.
.
.
X HAS BULLETHOLE [eR2, ER3] 211 It then CHECKS whether X is ON anything.
.
.
 [eR4] 213 X is ON PLATE so it will do that to PLATE.
.
.
 So that should keep doing that, PLATEs on .
.
.
 something, so on and so on.
.
.
' [eE5] A SECOND SOLUTION Here is the solution eventually developed by subject 35, who didn't 'gat it': TO SHOOTUP /X/ 1 NOTE /X/ HAS BULLETHOLE 2 CHECK A / SHOOTS ? 2A If Present: SHOOTUP •; EXIT 2B If Absent: EXIT Figure 5 Below are extracts from S5'3 protocol.
 Whereas S8 was able to develop the solution 'in her head , S5'3 solution evolved during codewriting: 46 I'm going to follow that example L* intect].
 144 5' [Heads fro« IH7ECT eiaaple la SOLO primer].
.
.
 BOTE.
.
urn.
 X HAS TLH.
.
.
 SAHUVICH HAS BULLETH0L2 54 SAHDWICH 01 PLATE, urn HO'n:.
.
.
ua.
.
.
 63 I've got to get the SHOOT ia somewhera haven't I? 65 CHECK.
.
.
! SHOOTS SAHDWCH.
 I? PHESEHT 3HO0TUP 33 Well, I hope it will go all the way through the sequence and shoot the floor.
 The data base is in and I've copied that program [ IHTECT] exactly.
 S5 has a recursion schema which differs from that of S8 in several respects.
 First, S5's schema does not have a filled SURFACETEMPLATE slot, but rather (a) a pointer to the place in the SOLO primer where a typical recursive procedure, i.
e.
 INTECT, is described, and (b) a method for filling the SUHPACETEMPLATE slot by copying the IlfTECT program's structure and providing arguments from the current problem.
 Second, 35's schema has a restriction that the relationship between objects in the database must be 'active' for recursion to work.
 That is, from the original INFECT teaching problem with JOHB KISSES KAKY KISSES FRKD, S5 had abstracted the rule that a startnode has to 'do' something to a successornode before a sideeffect can be perpetrated on the successornode.
 (S8, on the other hand, had abstracted 'transitivity' from previous study of the INFECT program— neither view, of course, ia perfectly correct).
 For example, 'ON' is not an 'active' relationship between the objects (SANDWICH, PLATE, etc.
) given in the problem statement.
 'ON' is passive and thus does not 'support' 35's notion of recursion.
 'SHOOTS' is an active relation, and S5 is convinced that somehow SHOOTS must be brought into the patternmatching segment of the program in order to make the program work at all [segments 63 and 65 of 35's protocol].
 This conviction precludes solution of the problem, unless careful reanalysis of the example program leads to reformulation of the rule about relationships between database objects.
 35 never relinquishes her belief that an active relationship need exist between the nodes for recursion to work, and her reformulations of the program are all guided by this single important but wrongheaded principle.
 35*3 protocol continues: 156 This one about the BULLETHOLE and this one with the KISSES are different.
 I need to say that the first X, the first parameter does something actively.
.
.
 to the second parameter.
 All I've got is BULLETHOLE.
 In the example it's got KISSES, which is an active thing.
 Although 35 made several subsequent attempts to map the BULLETHOLE problem onto the INFECT framework, the point of view from which the mapping occurred never changed and no solution resulted.
 CONCLUSION Because our programming problems use realworld examples rather than abstract programming tasks, the subjects' knowledge of programming interacts with their realworld knowledge during the reading, coding, and debugging processes.
 We have indicated the way (often Imperfect) knowledge of prograa concepts pervades problem solving even in its earliest stages.
 ling Our subjects develop schemas for recursion which are more or less 'adequate' for solving the problems we devise.
 'This adequacy ranges from that of subject S5 (who can not solve any of the recursion problems we have devised) to that of subject 38 (who can solve many, but not all, of our recursion problems).
 When a problem maps onto an adequate set of schemas in a novice's store of knowledge, the novice can tackle the tasks of problem understanding, method finding, coding, and informal verification in a productive and efficient manner.
 When a problem is mapped to an inadequate set of schemas, the problem statement ia often poorly understood, and becomes embedded in a program constructed as ouch from world knowledge as from the basic elements of the implementation language.
 REPEHENCES Brooks, E.
 Towards a theory of the cognitive processes in computer programming.
 Int.
 Zj_ ManMachine Studies, 9.
, 1977.
 Elsenstadt, M.
 Artificial intelligence project.
 Units 3/4 of Cognitive psychology; a third level course.
 Milton Keynes: Open llnivorsity Press, 1978.
 Elsenstadt, M.
, Laubsch, J.
, 4 Kahney, H.
 Creating pleasant programming environments for cognitive science students.
 Proceedings of the Third Annual Cognitive Science Society Conference, Berkeley, California, 1981.
 Goldstein, I.
P.
 Summary of MYCHOFT; a system for understanding simple picture programs.
 Artificial Intelligence, 6,.
 1975.
 Hayes, J.
E.
 i.
 Simon, H.
A.
 Understanding written problem instructions.
 In Gregg, L.
W.
 (Ed.
), Knowledge and Cognition.
 Hillsdale, H.
J.
: Lawrence Erlbaum Associates, 1974.
 Kahney, H.
 An indepth study of the behaviour of novice programmers.
 Technical Report No.
 829, Human Cognition Research Group, The Open University, Milton Keynes, England, 1982.
 Laubsch, J.
 i.
 Elsenstadt, H.
 Domain specific debugging aids for novice programmers.
 Proceedings of the Seventh International Joint Conference on Artificial Intelligence (IJCAIai), Vancouver, B.
C.
 Canada, 1981.
 Sussman, G.
J.
 A computer model of skill acquisition.
 Now York: American Elsevier,1975.
 Waters, R.
C.
 A method for analyzing loop programs.
 IEEE Transactions on Software Engineering, SE5:3.
 1979.
 145 Natural Problem Solving Strategies and Programming Language Constructa (1) Jeffrey Bonar Computer and Information Science Department University of Massachusetts Amherst, Massachusetts 01003 1.
 Introduction Any Interesting computerized task soon involves programming.
 Experience with statistics packages, word processing, and even microwave ovens shows that we always want our systems to be able to follow a stepbystep specification Involving decisions and repeated actions.
 Even with a very Intelligent computerized assistant, we would like to give It detailed instructions at an appropriate level of abstraction.
 This ubiquity of programming presents a problem, however.
 It is widely known that programming, even at a simple level, is a difficult activity to learn.
 {2) Vfhat is it about this cognitive skill that is so difficult? Is it inherent in prograouning, or directly related to the nature of the programming tools currently used for novices? In this report we will present evidence that current programming languages do not accurately reflect human problem solving strategies developed in a context of stepbystep natural language specification.
 This evidence was gained by studying novice computer programs collected from their terminal sessions [Bonar et al.
 1982], videotaped interviews of novices programming, and written studies focusing on specific aspects of novice programming techniques.
 13) Stepbystep natural language specification provides powerful Intuitions for novice programmers using a prograomlng language.
 We hypothesis that these Intuitions take the form of framelike plans  regular but flexible techniques for specifying how to accomplish a task.
 Prograoalng knowledge also involves framelike plans CSoloway et al, 1982] [Waters, 1979].
 While an individual programming language plan may have many lexical and syntactic similarities to a corresponding natural language plan, the two plans often have incompatible semantics and pragmatics.
 Many novice programmer's misconceptions derive directly from these incompatibilities.
 In this brief report we will show an example of natural language and programming language plans.
 Using those plans we will discuss a transcripts of novice programmers using a natural language plans while attempting a programming language problem.
 We conclude with a discussion of the implications of this work.
 brief (1) This work was supported by the National Science Foundation under NSF Grant SED8112U03.
 Any opinions, findings, conclusions, or recommendations expressed in this report are those of the author, and do not necessarily reflect the views of the U.
S.
 Government.
 (2) Our own conservative estimate from several introductory programming courses is that more than 1)01 of the conscientious students never really understand the rudiments of programming.
 (3) Du Boulay and O'Shea [1981] present an excellent overview of research into how novices learn programming.
 146 2.
 A Mismatch B e t w n a Natural Language Plan and a Program Consider the following problem: Proble 1: Please write a set of explicit instructions to help a Junior clerk collect payroll information for a factory.
 At the end of the next payday, the clerk will be sitting in front of the factory doors and has permission to look at employee pay checks.
 The clerk is to produce the average salary for the workers who come out of the door.
 This average should Include only those workers who come out before a supervisor comes out, and should not Include the supervisor's salary.
 The following natural language specification for this problem, written by one of our subjects, is typical: 1.
 Identify worker, check name on list, check wages 2.
 Write it down 3.
 Walt for next worker, identify next, check name, and so on 4.
 When super comes out, stop 5.
 Add nuober of workers you've written down 6.
 Add all the wages 7.
 Divide the wages by the number of workers There are several natural language specification plans used here.
 Note how steps 1 through 4 specify a loop: steps 1 to 3 describe the first iteration of the loop, indicating repetition with the phrase "and so on".
 Step 1 adds a stopping condition, assimiing that this condition will act as a "demon", always watching the action of the loop for the exit condition to become true.
 The specification also assumes "canned procedures" for counting inputs, step 5, and for summing a series of numbers, step 6.
 Note however, that these two procedures are both denoted with the word "add".
 Now focus on the two actions performed in steps 1 and 2.
 The plan to describe these actions is "get a value (step 1), and process that value (step 2)".
 This plan is nearly universal in this sort of description.
 Unfortunately, many programming languages support a far less natural plan: "process the last value, get the next value".
 To see why this is so, consider a problem analogous to Problem 1 but in a programming language domain: Problem 2: Write a program which repeatedly reads in integers until it reads they Integer 99999.
 After seeing 99999.
 it should print out the correct average.
 That is, it should not count the final 99999.
 In Pascal, a popular novice progranmlng languag*, the correct solution to Problem 2 is: begin Count := Count • 1 Total :s Total • I A««4 Jrî  <cro3sed out> end program ProbleiD_2_Expert; var Count, Total.
 Mew : integer; begin Count :i 0; Total := 0; Read (New); while New <> 99999 do begin Count := Count * 1; Total := Total + New; Read (New) end; if Count > 0 then Writeln ('Average =•.
Total/Count) else Writeln ('Mo data.
') end.
 and a transcript of the subject discussing this progran: S: If I put a nunber in [at the top of the loop], it comes through [the loop body].
 I don't think I want [the inside Read] read again, I want it read up [at the top of the loop] .
.
.
 If I read it [at the bottom of the loop body], what's that going to do for me? It's not going to do anything for me.
 OK, if I come out of the loop, having entered [a value], finish all [the loop body], then if I read in another one [points to Read above the while, traces a flow from that outside Read down through the loop].
 I guess what I need to figure out is how do I get back up here [points to the Read above the while].
 Notice the peculiar while loop construction.
 Because a while loop tests only at the top of the loop, it Is necessary to have a Read both above the loop and at the bottom of the loop.
 Within the loop we see the plan "process the last value, read the next value".
 This plan is part of the knowledge used by experienced Pascal programmers.
 Do novice programmers easily acquire such a plan? Apparently, no.
 First of all, novices want the while to have a demon like structure.
 Consider, for example, the following transcript: S: How do I get [the while loop] to do that over again? See, I guess I don't know, I thought I had it.
 What happens now, how do I get it to go back? .
.
.
 I say to myself, why would it do [the while test] after [the last line of the loop body]? It seems to me that it would do it as soon as the [variable tested in the while condition] changes.
 .
.
.
 I: So how will the while statement behave? S: Again, total guess here, I'm saying the while statement, here's a logical guess everytime [the variable tested in the while condition] is assigned a new value, the machine needs to check that value .
.
.
 The subjects "logical guess" is that the while behaves like a demon and not as a specific testing step among other steps.
 This is oonsistant with English phrases like "while you are on the highway, watch for the Northfield sign".
 Soloway et al [1981a] report that 31X of an introductory programming course had the "while demon" misconception.
 Novices also try to implement the "get a value, process that value" plan, even though they are programming in Pascal.
 Consider, the following novice program fragment.
 var Count.
 Total, I : integer; begin Count := 0 Total := 0 Writeln ('Enter integer') Read (I) while I <> 99999 do The subject wants to put the Read at the top of the loop, making the test in the middle of the loop.
 This allows the "get a value, process that value" plan.
 In a separate study Soloway, et al [1981b] show that a new Pascal looping construct supporting this plan significantly improved novice and intermediate performance with Problem 2.
 3.
 Concluaions The implication of these results is not simply to make syntactic fixes to prograDmlng languages.
 Instead, we are suggesting that the knowledge people bring from natural language has a key effect on their early programming efforts.
 Shneiderman and Mayer [1979] have proposed a model of programmer behavior based on language specific knowledge (which they call "syntactic") and more general programming knowledge (called "semantic").
 Our results suggest that there is a third body of "natural language stepbystep specification knowledge" which strongly influences novice programming behavior.
 Miller [1981], Green [1981], and others have previously looked at stepbystep natural language specifications.
 They concentrated on looking at the suitability of natural language for directing computers.
 Based on the ambiguities and complexity limitations of natural language, they concluded it would be quite difficult to "program" in natural languages.
 Here, we are not contradicting that result, but extending it.
 We are finding that •novice programmers do use natural language, even when they think they are using a programming language.
 There are several implications of this work for progranmlng education.
 We are beginning to explain many novice programming errors through the idea of natural language stepbystep specification plans.
 The quality of these explanations has proved important in the development of a tutor to do intelligent computer assisted instruction of programming [Soloway et al, 1981c].
 In the future, we hope to extend the tutor to understand a stylized form of these natural language plans.
 Finally, what Is the key to cognitively appropriate novice computing systems? Our work suggests that we need serious study of the 147 knowledge novices bring to a computing syatem.
 For most computerized tasks there Is some model that a novice will use In his or her first attempts.
 We need to understand when Is It appropriate to appeal to this model, and how to move a novice to some more appropriate model.
 Acknowledgements  My deepest thanks to Elliot Solouay for his support and guidance.
 I would also like to thank John Clement for his critical oooments.
 Shneiderman, Ben and Richard Mayer (1979) "Syntactic/Semantic Interactions in Programmer Behavior: A Model and Experimental Results", International Journal of Computer and Information Science, 8:3.
 PP.
 219238.
 Soloway, Elliot, Jeffrey Bonar, Beverly Woolf, Paul Barth.
 Eric Rubin, and Kate Ehrlloh (1981a) "Cognition and Programming: Why Tfour Students Write Those Crazy Programs", appeared in proceedings of the National Educational Computing Conference.
 «.
 References Bonar, Jeffrey, Kate Ehrllch.
 Elliot Soloway, and Eric Rubin, (1982) "Collecting and Analyzing OnUine Protocols from Novice Programnera", in Behavioral Research Methods and Instrumentation.
 May 1982.
 Du Boulay, B.
 and T.
 O'Shea (1981) "Teaching Novices Programming", in Computing Skills and the User Interface edited by M.
J.
 Coombs and J.
L.
 Alty.
 Academic Press, New York.
 Green, Thomas (1981) Activity", in "Programming As a Cognitive Human Interaction With Computers, edited by C.
 Smith and T.
 Green, Academic Press.
 Miller, Lance A.
 (1981) "Natural language programming: Styles, strategies, and contrasts", IBM Systems Journal.
 20:2.
 pp.
 184215.
 Soloway, Elliot, Jeffrey Bonar, and Kate Ehrlloh (1981b) "Cognitive Factors in Looping Constructs".
 Computer and Information Science Technical Report 8110, University of Massachusetts, Amherst, May.
 Soloway, Elliot, Beverly Woolf, Eric Rubin, and Paul Barth (1981c) "MenoII: An Intelligent Tutoring System for Novice Programmers", Proceedings of International Joint Conference in Artificial Intelligence, Vancouver, British Columbia.
 Soloway, Elliot, Kate Ehrlloh, Jeffrey Bonar, Judith Greenspan, (1982) "What Do Novices Know About Programming?", To appear In Directions in HumanComputer Interactions, edited by B.
 Shneiderman and A.
 Badre, Ablex Publishing Company.
 Waters, Richard C.
 (1979) "A Method for Analyzing Loop Programs", IEEE Transactions on Software Engineering.
 SE5:3.
 May.
 148 Tacit Programming Knowledge Elliot Solowsy Kate Ehrlleh Cognition and Programming Project Computer Science Dept.
 Yale Universitr New HaTen, Ct.
 08620 1.
 Introduction ' The goals o( the Cognitioi and Prograiiiiiiui( Project at Yale Unhrenity are: • empiricaUy expbre the isaues sarToaadisg progranuniag » what does aa expert programmer kaow, aad how does this compare to what a Bovice does (aad doesn't) lioow [Soloway et aL, 1982a, Ehrlich & Soloway, 1982|, » what makes • programmiag laagnage coostmct 'cogaitiretr appropriate' — aad caa we design sach constructs (Soloway et aL, 1981a| > what is the relationship between algebra kaowledge and programming knowledge [Erhlich et aL, 1982, Soloway et aL, 1982| • build AI baaed computer enrironmeats which can aid the novice programmer ia learning to program (Soloway et aL, 1981b, Soloway et aL.
 1082b|.
 In this short paper, we will deachbe soma teehaiqaaa we employ to investigate the first issue: what do programmers know.
 2.
 P r o g r a n m i i n g P l a n s : T h e Tacit K n o w l e d g e in P r o g r a m m i n g A number of researchers have replicated the ehesa experiments of deOroot (deGroot, 1966) aad Chase t Simoa (Chase aad Simoa, 1V73| in the domain of programming; consistent with those earlier experiments with master aad oonmaatcr cheat player*, it appears that expert programmers also have more kaowledge which is more highly chunked than novice programmers [Shaeidermaa, 1070, Adeboa, 1981, McKeithea, Reitmaa.
 Rneter aad Hirtle, 19811, Building on this work, oar goal in to ideatiiy the tpaeifia kaowledge which expert programmers appear to have aad osa.
 The problem is that experts are oftea oaaware of asiag this sort of knowledge — hence the term toett kaowledge.
 CoUias (CoUias, 1978), Larkia (Larkin et aL, 1980), Risaland [Risslaad, 1978), etc.
 have argued for the importaace of tacit knowledge ia varioas domains; oar objective is to identify the tacit knowledge in programming.
 To this end.
 we have developed a first order theory of the programming knowledge underlying simple looping programs which we feel experU have aad nse.
 Knowledge in this theory is encoded ia terms of plana: stereotypic chunks of knowledge.
 For example, we posit that there are control (low plans and variable plans; ia Figure 1, we would suggest that the body of the program is aa implementatioa of the Running Total Loop Plan: new valnes are successively generated, in thb case by a Read, aad are added to a Rnnniag Total Variable, Sum.
 Also, there is Counter Variable, Coaat, which keeps track of the number of numbers generated.
 Onr approach to programming plans is similar in spirit to that of Rich [Rich, 1980) aad Waters (Waters, 1979).
 Profeica Read (• I set of ifltcfttn aid pnat ott ticir atartgt Stop rtadin̂  nuafecr? vlitn bht floabcr 99999 is sa«a Do NOT lacladf ta« 99999 in tfet aafraftt PROGRAK 8l«tAlp«a(I«PUT/.
 OUrPUT).
 VAR Coaat.
 S».
 Daatar ISTEOEII.
 «>«rat« REAL.
 BEQII Coaat Sai • Coaatar Variatia Plia • 0 <« i • Raaaiii Total Vtrialla I Plaa 0.
 <«« I RaaaiaS Total Loop Plaa « Raadia (Naatar).
 I I I I I I I t I I I I I I  I I 'Tbia wort waj fappoftad ia part by tha Niiioaai Sdaaea roaadatioB, aadtr NSP Glut SEIMIIIMS.
 — — < « WHILE Saatar " 99999 M BECK I « Sia • Saa • Saatar.
 <"I Coaat • Coaat • 1.
 «< I i< Raa«l> (Saabar) ElO.
 Aaarata • Saa / Coaat.
 Vritala (A>ara|a) EM) ngnr* li Examples of Plans How does oae go about testing m theory of this sortf Simply askiag programmers whether or not they use tha Rnaaing Total Loop Plan would not be too Qlnminatiag: the claim is that they are oftea unaware of having aad usiag this type of kaowledge.
 Below we describe techaiqaes which we have fonad useful ia this regard.
 3.
 T h e Ftllintheblank T e c h n i q u e The first technique we have used draws oa work doae ia exploring the reality of scripts in text uaderstaadiag.
 For example Bower, Black aad Tomer fonad that, ia respoase to qnestioas about a story, subjects would TiD ia' from their 'script' kaowledge, iaformatioa which waa not explicitly givea ia the text.
 Similar ia llavar, we give programmers a propam ia which a liaa of code hat beea left oat, aad ask them to fill it in.
 W e purposely do not tell the subjects what the program is supposed to do; onr objective is to have subjects use their experience with previous programming problems in order to recognize what liae of code is moat appropriate ia the particular sitnatioB.
 If subjects dida't have plan structures, we would expect the answers they give to be arbitrary, and thus vary wildly from subject to subject.
 As we discuss below, the answers which novices give typically do vary significantly, while the answers which advanced programmers give do ia fact exhibit a significant degree of consistency.
 We also add aa extra twist to the above design ia order to more precisely home in on plan knowledge.
 W e create two versiona of the test program: in the first version, the information needed to fill in the blank line b more or less unambigions, while the second version contains eott/lt'ets'nf information.
 For example, the programs in Figures 2 and 3 ait both intended to produce the square root of N.
 Since N is in a loop which will repeat 10 times, 10 valnes will be printed out.
 The question is: how should N be setf The technique will be to compare the performance of programmers on the program which does not contain the plan conflict (Figure 2), with their performance on the program which does contain the conflict (Figure 3).
 149 PlwM rampt^u iW ^fiua rmcmtu lim M » w by niOa* ia Ika bUtk IIm (iwlinMd by k ban).
 Fill ia Ut blaak witk a liat »l Paacal nd* wkieb ia roar opiiiaa bait eomplataa Ika pnpam.
 pro«raai Viaitt«lpii>(I>»il/.
 OnCpit).
 Tar « real I laMfar bafia for I • 1 la 10 do I I.
 ir < < 0 tWa < • II VriMli ( SqrtO) ), (• Sqrt IS > liiltii «ad sq«arf root of its argaaait*) n f l O N S i Problem ViolMAlphK Th« iaflaeac* of a liagk P U a In the pfogmn in Fignre 2, N is a New Valoe Variable, since its fnnctioo b mereljr to hold successive values.
 The plan for this type of variable does sot present an overridint constraint on how it ihoald be set in the blank line: a Read(r4) or a N :• N I SomeValne would both be acceptable.
 However, context does provide a strong constraint.
 Notice the If test preceding the S<|rt(N) instantiates the 'juard a portion of a program from improptr data' plan by protecting the Sqrt from negative integers (the Sqrt function can only work on positive integers).
 This test speeifica an important constraint: N should take on valaea that coaid possibly be negative, otherwise the If test would be totally snperfloous.
 Thus, N should PItaaa niaplaM tka piafna ha<WBt (ivM baia* bf lOBaf ia Ika Uaak liw Oadkaaad bj a b«).
 ril ia tka bUak viU a Eaa af Paaeal cada vkkk ia 70V ofiaiaa baat eaasialaa tka laat"" profraa vioittBataCIipit/.
 Oatpit).
 Tar N raal.
 I la(a«ar bctia • • 0 0 for I • I to 10 da I I.
 if » < 0 tka* • • a.
 XriMH ( Sqrt(a) ).
 (• Sqrt IS I tiiltii fitctioa afeicfe ratiris tia sqtirt root of its ir|iaaat*> FIgnrw ai Problem VioletBeta: A conflict between Plans not be set via an assignment statement to some simple funetian of N and/or the index variable I.
 e.
g.
, N : — N + 1 , N:—I, N :  N + l .
 Rather, by setting N via a Read statement, negative values have the possibility of entering the program.
 This argument is based on a principle of tacit coimnnaicatioa which states: intiuda «Niv rMesaeory eoda im a prograsR.
 By including a teat for negative values, an experienced programmer is informing the reader that it ia possible that such number* could be generated; if such numbers could not possibly eater the program, then the inchuioa of thia test would violate this onwrittea rule of communication.
 The blaak line ia the program ia Figure 2 ia strategically placed: we wanted to Bq>lore the degree to which programmers are sensitive to the contextual relationship which obtains between the guard plaa and the initialization aspect of New Value Variable Plan.
 Program VioletBeta in Figure 3 is exactly the same as that ia Figure 2 except that oow N is given * value of 0 before the loop.
 Previously the New Value Variable Plaa waa aeutral with respect to how N should be set.
 However, since N was initialized via an assignment statement to 0, the general rule of relating initialization to update should come into play, aad direct that N be updated via an assignment.
 On the other hand, the If test, which realizes the 'guard plan' and protects the square root operation, still sets up the expectation that N wUI be read in.
 If N will be set via a Read in the loop, the setting of N to 0 initially is superfluous.
 Thus, in Program VioletBeta we have purposely created a situation in which two plans are in conflict: the New Value Variable Plaa expeeU N to be updated via an assignment, since it was initialized via aa assignment, but the guard plan on the Sqrt operation expects that N will updated via a Read, so as to permit negative values to eater the program.
 We felt that novices, with their limited experience, would be more sensitive to the constraint that obtains between a variable's initialization and update, aa compared to the constraint that obtains between a guard plaa and a variable's update.
 Hence, we predicted that the proportion of novices who Read in the value of N would decline when there was a conflict between plans.
 O n the other hand, we felt that more advanced programmers would have had snfflcient experience in both, and know when each is most appropriate, e.
g.
, nonnovices would realize that the test for a negative N should take precedence over the initialiiatioa of N to 0, since the 'guarding' of the input is usually very important to the comet running of the program.
 Thus, we predicted that nonnovices would fill in the blaak with Read(N) equally often in both versions of the problem.
 WVICES ALPHA BETA no coaflict coaflicl 1 1 1 •« 1 1 1 1 1 1 7 1 1 1 1 30 1 1 1 IS 1 1 Catagory t Sat • ¥ia Rasa Catagory 2 Sat • <ia assigaoaat MNWVICES ALPHA BETA ao coaflict coaflict 1 1 1 20 1 1 1 1 1 1 « 1 1 1 1 2t 1 1 1 4 1 1 ctisqaarad • S 20.
 p < 0 OS clisqaaraS < 1.
 I S Tnblnli FOIintheblank Responses The resp< of novices and nonnovices on these programs, shown in Table 1, support our predictions.
 Nonnovice* chose to set N via a Read in the nonconflict case (VioletAlpha), and also chose to set N via a Read in the conflict case (Bete).
 This is consistent with our hypothesis that nonnovices could use contextaal information — the gnard plaa constraint — to override thn variable plan constraint ia the coaflict case.
 In eoatraat, novicea chons Read significantly leas oflea in the eoafUet case U a a ia th* Ba»«oafIiet case (chisqaared— 5.
20, p < 0.
06).
 This is coasisteat with oar hypothesis that novices were more iaflaeaeed by the famiUar variable plaa coaatraiat thaa by the less fsmiliar, coatextaal gnard pba constraint.
 4.
 R e m d i n g T i m e Stntlies W e also wanted to see how reading time was effected by the no conflict/conflict situations.
 Thus, we carried out studies which tracked the time s programmer started reading the program to the time he began to Till in the blank.
 For thn programa in Figures 2 and 3, we found that novice programmers took effectively the same amount of lime to respond in Program VioletAlpha as ia Program VioletBeU (see Table 2).
 In contrast, while the advanced programmers responded quicker than the novices on Program VioletAlpha, they took significantly longer than the novices to respond to Program VioletBeta.
 W e feel these data also support oar hypothesis that Program VioletBeta coatained a conflict between plans, to which oaly the advaaced programmers were aeasitive, whik there was no similar coaflict in Program VioletAlpha.
 150 I I I I 109 I IM I Hooces I I I • ] 1 I I I I n I IM I Hoiloo en I I I p < OS Ntll ktt«m Tims II StCOItfS TablsSi Reading Timet Stadr S.
 Conelading R e m a r k a Tapping into the tacit knowledge which programmen seem to have and use ii a complex task.
 The basii for o u experimental method! rests sqaarety on oar, albeit pieiiminary, theoiy ot programming knowledge.
 That is, we needed the theory in order to create the program* which serre as oar stimulus materials.
 W e are currently working on extending that theory to more complex programming problems and constmctiont.
 We are also carrying ont filtinthoblank stadia and reading time studies with wnplanlike programs, and programs which contain bugs.
 One objective Is these studies is to explore the extent to which programs can be perturbed and still have people recognixe the correct underlying intentions.
 A longer range goal is the developmeat of measares of program complexity based not just on features of the program text itself, bat rather on the cognitive demands which the program make* on the programmer.
 Blvk and Sebrechts [Black ft Sebrechts, 19S1| have argued quite permaaiTely that measures of program complexity based on textoal features (e.
g.
 nnmber of operations, length of Tariabie names) cannot be effectire measure*, in the same way that the old measures of reading eompletity, baaed also on textoal featares, were not effectire measure*.
 Such measure* can capture oaly 'sorface' information.
 In contrast, effective measure* most be baaed on the typo and number of inferences which a programmer must make in order to understand the program.
 By cataloging the types of inferences which programmen do make, we have taken a first step in this enterprise.
 AekaowiadcM ntn We would like to thank Chuck Rich for hi* help in developing the stimulus materials used in this experiment, John Lcddo for raaning the reading time study, and Joost Breaker and Valerie AbboU for their help in analynng the data.
 R e f e r e n c e s Adelson, B.
 Problem Solving and the Development of Abstract Categories in Programming Languages.
 Memory and Cofnition, 1081, 9, 422433.
 Black, J.
B.
 & Sebrechts, M.
M.
 Facilitating homancompater communication.
 Applied Ptyeholinptittiea, 1981, 2, 149178.
 Chaie, W.
C.
 and Simon, H.
 Pereeptioii in Chess.
 Coptitivt Patekolon, 1V73, 4, 5581.
 Collins, A.
 Bxplieatint the Tacit Knowledge in Teaehinj and Uttminf.
 Technical Report 3889, Bolt Beranek and Newman, Cambridge, Mass.
, 1978.
 deGroot, A.
O.
 Thought and Choice in Chett.
 Paris: Moatoa and Company 1005.
 Ehriich, K.
, Soloway, E.
 An Empirical Invtttigation of the Tacit Plan Knowledge in Programming.
 Technical Report 8230, Dept.
 of Computer Science, Yale University, 1982.
 Ehriich, K.
, Soloway, E.
, Abbott, V.
 Styles of Thinking: From Atgehra Word ProUemt to Programming Via Proeedxirality.
 Cognitive Science Society, UniT.
 of Michigan, Mich.
, 1082.
 Larlcin, J.
, McDermott, J.
, Simon, D.
 and Simon H.
 Expert and Novice Performance in Solving Physics Problems.
 Science, 1080, e08, 140150.
 McKeithen, K.
B.
, Reitman, J.
S.
, Rneter, HJI.
, Hirtle, S.
C.
 Knowledge Organitation and Skill Differences in Computer Programmers.
 Cognitive Ptyehoiogy, 1981, 13, 307325.
 Rich, C.
 A Library of Plant with Application* to Automated Analyait.
 Technical Report 294, M I T AI Lab, 1980.
 Riasland, E.
 Understanding Understanding Mathematics.
 Cognitive Science, 1978, 2(4), .
 Shneiderman, B.
 Exploratory Experiments in Programmer Behavior.
 International Journal of Computer and Information Science; 1970, 5,2, 123143.
 Soloway, E.
, Loehhead, J.
, Clement, i.
 Does Computer Programming Enhance Problem Solving Ability? Some Positive Evidence on Algebra Word Problems.
 In R.
 Seidel, R.
 Anderson, B.
 Hunter (Eds.
), Computer Literacy, New York, N Y : Academic Press, 1982.
 Soloway, E.
, Bonar, J.
 and Ehriich, K.
 Cognitive Factort in Programming: A n Empirical Study of Looping Conttruet: Technical Report 8110, Department of Computer Science, Univenity of Masaachusetts , 1981.
 Soloway, E.
, Woolf, B.
, Barth, P.
, and RuKn, E.
 MENOTI: Catching RunTim* Error* in Novie*'* Pascal Program*.
 International Joist Conference on Artificial Intelligence, Vanconrer, B.
C.
, 1981.
 Soloway, E.
, Ehriich, K.
, Bonar, J.
, Greenspan, J.
 What Do Novices Know About Programming? la Directions in HumanComputer Interactions, B.
 Shneiderman and A.
 Badre, Eds.
, Ablex, Inc.
 in press.
 Soloway, E.
, Rubin, E.
, Woolf, B.
, Bonar, J.
 MENOU: A AICAI Programming Tutor.
 Proeeedinsi of the ADCIS Conference, Vancouver, B.
C.
, in press.
 Waters, R.
C.
 A Method for Analyting Loop Programs.
 IEEE Drana.
 on Software Engineering, M a y 1979, SE5, 237247.
 151 THE ROLE OF METAPHORS IN NOVICES LEARNING PROGRAMMING Ann Jones The Open University Milton Keynes, England Abstract Learning a complex skill such as programming requires the developments and use of conceptual models, both of the concepts in the programming language, and the 'behaviour' of the machine.
 The latter has been referred to as the 'notional machine' (du Boulay, B.
, O'Shea, T.
 and Monk, 1981).
 Such a conceptual model, however, must Interact and build upon models and metaphors which students already have.
 It is these metaphors and some techniques for studying them which are discussed in this paper.
 Introduction and Background Behavioural studies of programming are motivated by a diversity of >oals, for example a desire to understand the task better and thus how it can be Derformed more efficientlv: or a concern about the Importance of developing procedural literacy, (for example.
 Shell, 1980, (b)) or an interest in programming as an applied example of a high level skill.
 It is the latter, mainly, which motivates the present study: the overall question, although It is far from simple, can be simply phrased 'What goes on in the mind of the learner prograamxer?' There is now a substantial body of research on programming, although Shell, (1980) argues that many empirical studies of programming have added very little to our knowledge of what it means to learn prograimning, partly because the methodology is fraught with difficulties but mainly because we still know so little about what the task entails: how programming knowledge is organized and how it can be represented.
 There is some agreement that it can be thought of as a collection of units, (or 'frames', 'paradigms' or 'schemas') organised as program fragments with a set of propositions about Its behaviour and rules for combining it with others.
 (Rich 1978, Floyd, 1979.
) There is no evidence, however, that novices have access to such structures; on the contrary, studies of the knowledge organization of experts and novices, in the programming domain, indicate not unsurprisingly, that novices lack such organizing schemas.
 (McKeithen and Reitman, 1981; Adelson 1981).
 It has been argued (du Boulay, O'Shea and Monk, 1981.
) that one of the difficulties of teaching a novice programming Is how to describe at the right level of detail the machine she is learning to control; and as a way of doing this they suggest teaching using the idea of a notional machine  an idealised conceptual computer whose properties are implied by the constructs in the prograomiing language employed.
 The notional machine is similar to the 'transactions' which Mayer uses to describe the workings of a BASIC machine (Mayer, 1979), and also suggests as a basis for teaching BASIC.
 Other studies, (e.
g.
 Miller, 197A) have also emphasized providing novices with carefully thought out metaphors and models to help them learn.
 The gap, however.
 In all this is what the learner herself brings to the situation, and that is, all her past experience and knowledge which will be used to interpret and organize the new material that is to be learnt.
 Although programming has many specialised terms, many words do have everyday 152 meanings and associations which are different from their programming use and may not facilitate the learning process.
 Such words will not necessarily have a shared meaning among novices.
 McKeithen and Reitman (1981), in studying the organization of programming knowledge found that beginners' organizations show a rich variety of common language associations to these programming concepts.
 Botts' study of learning how to use a text editor, (Bott, 1979) suggests that such preassociations are powerful and pervasive, and may not be easily replaced by new metaphors and models.
 The Study The study of novice programmers' Initial metaphors and models is being investigated as part of a larger study of how students learn two very different programming languages: only one of which will be discussed here, a language called SOLO.
 The students using SOLO are taking an Open University Cognitive Psychology course; and SOLO provides an environment for them to manipulate an assertional data base, as a tool for learning and thinking about knowledge representation.
 It was designed to make life easy as possible for total novices by being restricted to a small number of primitives, and Incorporating many user aids, such as a spelling corrector.
 Nevertheless, learning to program in SOLO is by no means trivial, and so it has been necessary to find out what problems the students have so that the programming envlrorment can be tailored to suit their needs.
 (Eisenstadt, Laubsch and Kahrey, 1981).
 In order to build a really foolproof environment it is necessary to understand precisely what the novice really thinks is going on inside the SOLO machine.
 Of course, trying to find out what someone 'really thinks' Is going on is a tall order, and to a large extent this study has been concerned with exploring methodologies which will provide 'windows' into novices ' conceptual models of the SOLO machine.
 Several such windows have been explored: students were asked to actually start learning SOLO in the laboratory and to talk aloud while doing the exercises in the primer, (for this study, the fact that SOLO is learnt at a distance, from a correspondence text, is a great advantage, as the teaching method and techniques used are made explicit and are consistent across students); they are interviewed and asked to talk about some of the concepts before they started; they completed Repertory grids, (Kelly, 1970) and the worked through some very simple exercises.
 The next section will briefly discuss the virtues and problems of some methodologies for specifically exploring the metaphors and models which students bring with them, and some examples of these.
 The Repertory grid Repertory grids are usually used to elicit constructs rather more general Chaa chose concepts used in programming.
 They are a way of finding ouc how a person cacegocizea Che world or some pare of Che world.
 Ocher studies of knowledge structures, e.
g.
 Adelson (1981) have investigated how programs are organised.
 The approach used here however was CO ask sttidents co categorize Che accoal promicives of Che SOLO language, and subjects calked aloud while Chey did cbe exercise.
 In chls exercise chey were shown chree of che SOLO 'words' on cards, and asked if there was a way in which cwo were alike and one was dissimilar; and cold chac chey would Chen cacegorlze Che resc of che cards according to Chis construct.
 This is repeaced until no more constructs can be elicited.
 In doing this I was interested in the constructs a subject would choose, given the freedom to carve up the 'SOLO world' however she wanted, and also whecher, given a construct elicited from che first triple it would be possible co cacegorize Che remaining SOLO cerms in accordance with it.
 For example, one subject started with NOTE (an 'Assert' function), CHECK (a 'retrieve' function) and LIST  which lists procedures.
 She said chat NOTE was Co do with 'Giving (the database) new things' whereas CHECK and LIST have a retrieval function  'chey show you whac's there.
' It's not clear how much sense such constructs have for the rest of the primitives.
 This subject's categorization for this construct was: "Giving new things" "Retrieval" DESCRIBE IF PRESENT NOTE IF ABSENT To (Defining a procedure) CHECK CONTINUE EDIT EXIT PRINT PARAMETER VARIABLE FORCET (delete) In this case, che conscruct does make some sense as a way of categorizing Che SOLO Cerms.
 As might be expected from other related studies (eg Adelson, 1981) many of these beginner programmers used constructs which were Idiosyncratic and related to everyday knowledge as much as to programming knowledge.
 Eliciting such constructs is clearly a hard activity for beginners (as indeed it is for experts), but although subjects found it demanding chey also found ic rewarding as ic forced them to chink about how they organized these concepts which they were not aware of having categorised.
 This thinking it through becomes explicit in their verbalization.
 What seems Co be happening Co Chis is Chat Che sCudenCs are learning while doing Che Cask.
 Whilst this is exciting and can provide rich data it Is also clearly problematic for analysis as Che learner's scace is changing during the exercise.
 Secondly, some students seem Co "chain" concepts; to lose crack of che conscrucc or category and to cacegorize each element or concepts (the primitives) according to its similarity or otherwise, to che previous one.
 The grouping of the constructs for each subject and differences between subjects has not yet been analysed, and so, overall, ic is dlfficulc ac che momenc Co assess how useful Chis cechnique will be.
 before starting co learn about it.
 Information about how a student interprets a certain word before even starting provides a baseline for interpreting their behaviour.
 Some Interpretations are remarkably common, yet unsurprising, (in retrospect!) "Parameter", if it elicited any reply ac all, was "llmlcs", "boundaries" "constraints", • which is not particularly close co ics programming use.
 'Node', on Che other hand, which is a word used in SOLO's semantic network, was for many the biological 'node' of a nerve network;  a not inappropriate metaphor.
 Protocols of students working chrough exercises in the teaching cesc were also caken.
 Consider Che following extract from a CranscripC, which conerns how procedures cake paramenters: "I think of it in relation to a sort of work processor, that if I was doing a lot of letters I would do a letter and put an X in 'Dear X' and Chen each one I'd just print in Fred, Mary.
, so Chat each letter " This metaphor is very useful for a novice thinking about the idea of a procedure caking a parameter.
 It should be stressed however chat chis is someChing Che learner brings with her; no matter what metaphors are offered in the teaching, the student must map what she's learning on to her own experience.
 Normally this is a 'hidden' activity; but part of the aim of this research Is to make it 'explicit' Such information can pay dividends later, as such metaphors may only be useful for a fragment of time, or for learning on particular thing.
 In the above example, the metaphor led to expectations about the way the editor would behave,  that it would be able to delete single words within a line of the procedure, which did not match its actual behaviour, as in fact, whole lines must be deleted, and yet, such beliefs were persistent.
 Both (1978) cites the way in which such expectations can lead to interpretations which are false, yet very pervasive, and how complicated stories are constructed to account for the mismatch between expectation and reality, before Che learner finally discard an inappropriate schema.
 Conclusions In helping novices to learn programming, it is not enough to provide metaphors and models.
 In addition we must study the models and metaphors students already have, and which they bring with them Co Che learning situation.
 This paper has discussed such metaphors and possible methodologies for Investigating them.
 The aexc sCep is Co examine how existing metaphors interact with experience in Che development of conceptual modes of a programming language.
 This is a vital issue in understanding how novices learn programming.
 Acknowledgements I would like to thank Tim O'Shea and Richard Young for help and advice on this paper, and for helpful discussions.
 Concept InCervlews and Talking Chrough Exercises The mosc frulcful technique so far for investigating metaphors has been a combination of concept interviews and students calking aloud while working through che exercises in Che promer.
 In Che 'concept' Interviews, subjects were asked to talk about some of the words used in the SOLO language References Adelson, B.
 Knowledge Structures of Computer Programmers Proceedings of 3rd Annual Conference of Cognitive Science Society, 1981, pp 243248.
 Bott, R.
A.
 A Study of Complex Learning.
 Report No.
 82, University of California, Centre for 153 Human loformatlon Processing, 1979.
 du Boulay, B.
.
 O'Shea, T.
, and Monk, J.
 The black box Inalde the glass box: presenting computing concepts to novices.
 Int J Man Mach Studies, 1981, 14, 237249.
 Elsenstadt, M.
 Artificial Intelligence Project, Cognitive Psychology Course, Open University 1978.
 Elsenstadt, M.
, Laubsch, J.
, and Kahney, H.
 Creating Pleasant Programming Environments for Cognitive Science Students.
 Proceedings of 3rd Annual Conference of Cognitive Science Society 1981.
 Floyd, R,W, "The Paradigms of Programming" Commus.
 ACM 228 (August 1979) 455460.
 Kelly, G.
A.
 A brief Introduction to personal construct theory.
 In Perspectives In Personal Construct Theory (BANNISTER D.
 Ed), London Academic Press, 1970.
 Mayer, R.
 A Psychology of Learning BASIC Communication of the ACM, Vol.
 22, No.
 11, Nov.
 1979.
 McKeithen, D.
B.
 and Reltman, J.
S.
 at al.
 Knowledge Organization and Skill Differences In Computer Programmers.
 Cognitive Psychology, 13, 307325.
 1981.
 Miller, L.
A.
 Programming by non programmers.
 Int J ManMach Studies, 1974, Vol.
 6, 273260.
 Rich, C, and Shrobe, H.
 "Initial report on a Lisp programmer's apprentice", IEEE trnas.
 Softw.
 Eng.
 SE4 (1978) 456467.
 Shell, B.
 The Psychological Study of Programming, Computing Surveys, Vol.
 13, Nol.
 1, March 1980.
 Shell, B(b).
 "Teaching procedural literacy" la Proc.
 ACM Annual Coof.
 1980, pp 125126.
 154 PROGRAMS, THEORIES.
 AND MODELS Paul Thagard Cognltiv* Scltnce Center, University of Michigan, Ann Arbor Univeriity of MichiganDearborn' April, 1982 This paper makes use of the philosophical literature on theories and models to develop an account of the role of Al programs in psychological theorizing.
 It is often said that programs are theories (e.
g.
 Winston 1977.
 P 258) .
 I argue that programs do not constitute theories or models in any precise sense, but that the important contribution of programs to psychological theory can be described by adopting a new conception of theories as definitions of kinds of systems, developing a cognate conception of model, and interpeting AI programs as simulations of models which approximate to theories.
 A program  3 set of instructions which a computer can follow  Is clearly not a theory according to what used to be the standard philosophical view that theories are sets of sentences axiomatlzed In a formal system (see e.
g.
 Hempel 1965.
 PP.
 182183) .
 However, a more plausible Interpretation of theories Is available.
 The alternative conception of scientific theories was originally proposed by P.
 Suppes (1957, 1967) and has been developed by various authors and applied to fields as diverse as physics, biology, and economics (see e.
g.
 Sneed 1971, F Suppe 1972.
 1977: van Fraasseir 1970.
 1972; Stegmueller 1976.
 1979; Beatty I98O; Hausman 198I).
 It has been variously referred to as the "semantic" conception and the "structuralist" view of theories.
 There are important differences among these various accounts, but in what follows I shall eclectically adapt whatever features of the different formulations seem best to apply to cognitive science.
 In order to avoid confusion.
 I shall simply refer to the "new" conception or account of theories.
 Whereas the traditional view of theories took them to be sets of sentences In an axiomatic system, the new account takes a theory to be a k I nd of definition.
 In Suppes' original account, a theory was a definition of a settheoretic predicate, but for present purposes I shall employ a simpler version of the new account due to Giere (1979) For Giere, a scientific theory is a definition of a kind of natural system (p.
 69) He Illustrates his account by applying It to the theory of Newtonian mechanics.
 On the traditional view, this theory might be taken as consisting essentially of Newton' three laws of motion plus the law of universal gravitation.
 On Giere's view.
 Newtonian theory Is a definition of a kind of particle system: "A natural system Is a classical Newtonian particle system If and only If it Is a system of objects satisfying Newton's three laws of motion and the law of universal gravitation.
" (p.
 69)• As a definition, such a theory Is neither true nor false: In Itself, It makes no empirical claim.
 However, it can be used to make empirical claims, for example that the solar system is a system of the kind defined by the theory.
 Giere calls such claims "theoretical hypotheses", but I shall term them simply "theoretical claims".
 A theoretical claim has the form: real system R Is a system of the kind defined by the theory T.
 Whereas a program Is clearly not a set of sentences comprising a theory on the traditional view.
 It Is very tempting to think of a program as specifying a kind of cognitive system and hence as qualifying as a theory on the new conception.
 For example, Kosslyn's imagery programs might be understood as specifying a kind of system for processing information using mental images.
 John Anderson's programs define a different sort of processing system, oriented around propositions.
 In either case, we might make the claim that the real human information processing system is a kind of system specified by the program.
 Such a claim can be empirically evaluated.
 A program Implicitly characterizes a processing system by specifying what knowledge structures are to be used and what procedures are to operate on them.
 Although this makes It appealing to say that a program can be a theory according to the new conception, there are two important reasons for resisting the appeal.
 First, although a program can loosely be said to "characterize" a processing system.
 It can not be said to define a system in the way required by the new conception of theories.
 Second, we would never want to make the theoretical claim that any real system is just like the system produced by the program, since any program contains a host of implementationdependent characteristics which we know to be extraneous to real human cogni tion.
 To handle the latter difficulty, I want to develop the concept of a model This is a dangerous choice of term, since "model" has been used with even more ambiguity and vagueness than has "theory".
 However, the term "model" Is often used in cognitive science in much the way I want to define It, and I hope to give a definition sufficiently precise to distinguish models from theories.
 As Giere and others have pointed out, "model" and "theory" are sometimes used synonymously, but 1 think we can outline two features which generally distinguish models from theories.
 (Cf.
 Kosslyn 1980, Pylyshyn 1978.
) First, models are intended only to have analogies with real systems; they are not expected to characterize them with complete accuracy (cf.
 Hesse, 1963) Second, models are often Intended to have a relatively narrow range of application: we can have models for specific phenomena, whereas theories are usually intended to have wide generality.
 I shall now show how these features of models can be characterized within the general framework of the new conception of theories.
 We will still not be able to say that a program is a model, but the account of models will bring us closer to describing the role of programs in model building and theory construction.
 On my interpretation models are like theories in being definitions of a kind of system, and so are In themselves neither true nor false.
 However.
 as indicated above, we expect models to Include in the definition of a kind of system features which we would not attribute to real systems.
 Models define systems which we know not to be exactly like 155 real world systems.
 Accordingly, the claims which models are used to make must be different from the claims which theories are used to make.
 Recall that theories are used to make theoretical claims that a real system is a system of the kind defined by the theory.
 Since a model contains specifications which are known to be false of the target real systems, it can not successfully be used to generate such theoretical claims.
 For example, a processing model based on the computer metaphor may define a kind of system in which processing Is serial, even though the theorlzer believes that processing in the brain is parallel.
 That discrepancy would be enough to defeat any theoretical claim which said that the brain is a processing system of the kind described in the model.
 We need to be able to use the model to make a weaker claim.
 As Hesse (I963) and Kosslyn (196O) have pointed out.
 the relation between a model and what it models is one of analogy We do not assume that a model exactly describes the target phenomena.
 only that the phenomena are in important respects like what is described in the model.
 Under the new conception, we can say that a model defines a kind of system, but that we only expect the systems so defined to be analogous to real systems.
 Hence instead of a theoretical claim we use a model to make what 1 shall call a "modelling claim", which has the form: a given real system R is very much like the kind of systems defined by model H.
 This is clearly less precise than the identity claim made in a theoretical claim.
 discussed here, but his basic distinctions can be translated into the terms of the current dlscussion.
 When a program is run on a computer, the computer is a simulation of a system.
 In particular, the system simulated is intended to be a system of the kind defined by the model.
 A model defines a kind of system, and the program, when executed, performs like a system of the sort defined.
 The program thus embodies many important features of the model.
 Hence a program can be used indirectly to make claims about the real system about which a modelling claim is made.
 Since the program simulates a system of the kind defined by the model, and since the model can be used to make the claim that the real system is a system of the kind defined by the model, we can use the program to make a siaulation claim: the real system R is analogous to the system S simulated by execution of program P.
 In short, a simulation claim can have the form "program P simulates R".
 However, it must be kept in mind that the claim in both these forms is shorthand for a description of a much more complex relation involving models as definitions of systems.
 In sum, a program can not be said to be a theory or a model, but provides, when executed, a simulation of a system of a kind defined by a model which approximates to a theory.
 REFEREHCES Models are thus less ambitious than theories.
 Not only do they include in their definitions characteristics which real systems are not expected to have, they are likely to define a narrower set of characteristics than would a theory, which would be expected to give a more complete account of the behavior of a system.
 Theories are also expected to apply generally to a number of different kinds of systems, whereas models can be either general or specific (Kosslyn 198O).
 A general model of cognitive processing is one which would be like a theory in having numerous applications, generating numerous modelling claims.
 But models, unlike theories, can be specific in that they are intended to apply only to a particular sort of system, and a modelling claim is made only about that kind of system.
 Construing models as definitions of kinds of systems is clearly compatible with both their general and specific uses.
 All this has been preparatory to asking the central question: are computer programs psychological aodelS^ Since models differ from theories in admitting unrealistic characteristics as part of their system definitions, it is tempting to construe programs at least as models of human information processing.
 But the second impediment remains: a computer program may exemplify a system.
 but it does not define a kind of system, and therefore can not qualify as a model in the precise sense developed above.
 Still, we continue to get closer to being able to specify the role of programs in the construction of psychological theories and models.
 Zeigler between a real sy says that whereas and the real s relation between of simulation.
 models a real sys that a computer Zeigler's notion 156 (1976) usefully distinguishes stem, a model, and a computer, and the relation between the model ystem is one of modeUing, the the computer and the model is one A computer simulates a model which tem.
 Indirectly, then, we can say is a simulation of a real system.
 of model is different from the one Anderson, J.
R.
 (1976), Language, Hemory and Thought.
 Hillsdale, New Jersey: Erlbaum Associates.
 Beatty, J.
 (I9B0), "Optima IDesign node is and the Strategy of Model Building in Evolutionary Biology," Philosophy of Science 47: 532561.
 Giere.
 R.
 (1979).
 Understanding Scientific Reesoeing, New York: Holt, Rinehart and Winston.
 Hausman, D.
 (198I).
 Capital, Profits, and Prices: An Essay in the Philosophy of Ecoaomics, New York: Columbia University Press.
 Hempei.
 C.
G.
 (1965).
 Aspects of Scientific Explanations.
 New York: The Free Press.
 Hesse.
 M.
 (1966) .
 Models and Analogies in Science.
 Notre Dame: Notre Dame University Press.
 Kosslyn, S.
 (I98O).
 Image and Mind, Camoridge: Harvard University Press.
 Moor, J.
 (1978), "Three Myths of Computer Science," British Journal for Philosophy of Science 29: 213222.
 Pylyshyn, Z.
 (1978).
 "Computational Models and Empirical Constraints.
" Behpviorel and Breitt Sciences 1: 9399Suppe.
 F.
 (1972), "What's Wrong with the Received View on the Structure of Scientific Theories?" Philosophy of Science 39: 119.
 Suppe, F.
 (1977).
 The Structure of Scientific Theories (second edn.
), Urbana: University of 1 I I Inoi s Press.
 Suppes, P.
 (1957).
 Introduction to Logic.
 New York: Van Nostrand.
 Suppes, P.
 (1967).
 "What is a Scientific Theory?" in S.
 norgenbesser (ed.
) , Pllilosop/iy of Science Today.
 New York: Basic Books.
 5567.
 van Fraassen, 8.
 (1970), "On the Extension of Beth's Semantics of Physical Theories," Philosophy of Science 37: 325339van Fraassen.
 B.
 (1972).
 "A Formal Approach to the Philosophy of Science," in Colodny (ed.
), Paradigas and Paradoxes, Pittsburgh: Pa.
: University of Pittsburgh Press, 303366.
 Winston.
 P.
 (1977).
 Artificial Intelligence, Reading, Mass.
: Addison Wesley.
 Zeigier, B.
 (1976).
 Theory of Modelling and Simulation.
 New York: Wiley.
 157 On Changing the "Logic" of Proposed Logics of Scientific Discovery S.
C.
 Grover University of Calgary Critics of the concept of a logic of discovery generally hold that discovery Involves Irrational, aesthetic and metaphorlc components which preclude systematic description or reduction to an algorithmizable procedure (e.
g.
 1, 2).
 This paper reconsiders certain of the Issues Involved In this philosophical controversy and discusses the possibilities for computer simulation of Inventive scientific thinking.
 It has become increasingly clear via philosophical analysis and recent work in artificial intelligence, that traditional forms of logic fall short of providing an adequate description of the thinking underlying scientific discovery (3).
 For instance, Cohen (4) has shown that: "tiewton derives his Inverse square law of gravitation by a precise mathematical derivation from, among other things, Kepler's Third Law for planets.
 .
 .
We can show logically that Newton's system contradicts Kepler's Third Law, while Newton coolly derives one from the other" (5, p.
 260).
 Deductive logic does not seem to be the basis then for Newton's creativity in this instance.
 Inductive logic seems often to fare no better as an explanation for inventiveness: ".
 .
 .
most of us cannot conceive that there might be rules that would lead us from laboratory data to theories as complex as quantum theory, general relativity, and the structure of DNA.
 Our shared archetypes of significant science virtually all Involve theoretical entitles and processes which are Inferentlally far removed from the data which they explain" (2, p.
 178).
 Inductive and deductive logic are incomplete models for a logic of discovery also in that often scientists do not begin with "valid" premises or "sound" data.
 Tec, they frequently arrive at theories and findings which are deemed highly significant and legitimate.
 So It was, for example, with Darwin who arrived at the theory of evolution — based on the concept of natural selection — from his monad theory which posited individual primitive life forms that arose spontaneously on a continual basis (6).
 An overrellance on traditional logic may account for some of the limitations in contemporary computer simulations of scientific discovery processes (which are quite impressive nonetheless).
 Thus the Bacon l and 3 programmes must be given data free of noise to manipulate; lest the programmes' Inductive processing be led astray.
 The ultimate consequence of such an approach is that these programmes can rediscover certain known empirical laws, such as Che ideal gas law, but cannot generate new discoveries (7).
 What other forms of logic might then be relevant to the problem of scientific discovery? The sort of logic required to account for, for Instance, reformulations of problems Into useful researchable ones Is what Achlnsteln terms an "evaluative logic" (8).
 Such a logic would include rules for deciding on the plausibility and importance of research problems and "solutions".
 A theory might be considered more plausible if it accounts for more data or for puzzling empirical findings.
 Achlnsteln uses as an example Bohr's notion that the hydrogen atom consists of a nucleus around which a single electron revolves and sometimes Jumps from one stable orbit to another.
 Achlnsteln contends that Bohr's hypothesis was considered plausible since it was useful in explaining the spectral lines present when hydrogen is excited by heat or electricity and emits light.
 Another example is Pauli's "discovery" of the neutrino.
 The concept of the neutrino was initially reluctantly accepted as plausible — despite the absence of empirical evidence for a "neutrino event" — because it could explain the failure of energy equations to balance before and after beta decay (9).
 As the aforementioned examples illustrate, evaluative logic differs in important ways from deductive or Inductive logic.
 It may lead to a concept or model in the absence of direct empirical support as in the case of Pauli's neutrino.
 In addition, evaluative logic is a flexible system which does not lead Inexorably to any particular conclusions(s) as is the case with deductive logic.
 Thus Bohr's theory may have been a plausible one or the most plausible theory advanced at the time, however, the "logic" of the argument did not Inherently preclude other possibilities.
 Does this discussion not simply beg the question of how new Ideas are generated in the first place, and substitute for that question the issue of theory Justification? Gutting (10) holds that a logic of hypothesis generation is intimately linked to an evaluative logic which assesses ideas or models.
 As Gutting points out, the socalled truism that one can think of almost anything is false.
 He gives the following example: "Host people.
 .
 .
even ones with sufficient Intelligence and imagination, could not have thought of the hypothesis of electron spin.
 Only a scientist thinking of the atom in terms of a planetary model could have thought of such a hypothesis.
 On the other hand, the hypothesis is implicit in the model and so likely to occur to anyone who is seriously concerned with developing this model.
 So if the question is raised: Why did Goudsmit and Uhlenbeck think of the spin hypothesis? at least a significant part of the answer lies in a conceptual analysis of the nature of Bohr's model of the atom" (10, p.
 224225).
 Thus discoveries occur given a particular historical and theoretical context.
 Such a context or background knowledge is not currently a significant feature of programmes such as the Bacon simulation attempts.
 It is as if the programme is largely expected to operate in a theoretical vacuum detecting regularities in the data which, as the programme's namesake Francis Bacon held, would "leap out" at the observer (7).
 However, in providing only "sound" data devoid of anomalies only a low level theoretical bias of a sort is built into the system.
 It seems that many attempts at simulating scientific discovery are, perhaps unwittingly, designed so as to be consistent with the notion that "science begins in the nothingness of ignorance" (11, p.
 12).
 However, as Gould points out, theories always abound with the result that "science advances primarily by replacement not by addition" ( U , p.
 12).
 Consider for instance Lavoisier's discovery of oxygen.
 It was his rejection of phlogiston cheml158 cal theory which was a prerequisite for development of the notion of combustion as due to a combination effect rather than a dissociation reaction.
 His contemporary.
 Priestly, did not reject phlogiston theory in the light of Lavoisier's evidence that combustion led to an increase in the weight of a burned compound and not a decrease as phlogiston theory necessitated.
 Priestly simply postulated that phlogiston has a "negative weight".
 This case illustrates Curd's point that: "The factors that justify our inferences to theories in the first place are the same as those that we use to decide which theory to pursue after they have been generated.
" (12, p.
 215).
 What is needed then are programmable rules which capture something of the logic of data and problem assessment given a particular theoretical framework.
 Also, required are higher order sets of rules that reflect on the theoretical assumptions upon which the programme operates.
 To accomplish this might be akin to equipping the programme with a metacognltlve competency.
 Programmes such as InternlstI (13) come closer than others to operating on data given certain background knowledge e.
g.
 a classification scheme for all possible diseases, and thus are more similar to the scientist who also comes to his research problem with a particular frame of reference.
 However, the Internist programmes, like the Bacon programmes, cannot make new discoveries e.
g.
 a new disease is not generatable by Internist I or II.
 Perhaps in part this is because the metacognltlve feature (for a lack of a better term) is absent.
 Fortunately, progress is being made in human research in the understanding of various aspects of metacognltlve competencies (e.
g.
 14, IS, 16).
 Perhaps, the addition of a metacognltlve component in computer simulations of scientific discovery processes will allow for more flexible programmes that make new discoveries, of a sort.
 Should the latter occur, a logic of discovery would not, as Wartofsky now claims, "dissolve the notion of creativity altogether" (1, p.
 8).
 4.
 Cohen, I.
B.
 Newton's Theory versus Kepler's Theory and Galileo's Theory: An Example of a Difference Between a Philosophical and a Historical Analysis of Science.
 In Elkana, Y.
 (edi The Interaction Between Science and Philosophy.
 Atlantic Highlands: Humanities Press, 1974, 299338.
 5.
 Hattiangadi, J.
N.
 The Vanishing Context of Discovery: Newton's Discovery of Gravity.
 In Nicklea, T.
 (ed.
) Scientific Discovery, Logic and Rationality.
 Boston Studies in the Philosophy of Science.
 Vol.
 56.
 Boston: 0.
 Reldel Publishing, 1980, 257265.
 6.
 Perkins, D.
N.
 The Mind's Best Work.
 Cambridge: Harvard University Press, 1981.
 7.
 Langley, P.
 Datadriven discovery of physical Uws.
 Cognitive Science.
 1981, 5, 3154.
 3.
 Achinstein, P.
 Discovery and RuleBooks.
 In Nlckles, T.
 (ed.
) Scientific Discovery.
 Logic and Rationality.
 Boston Studies in the Philosophy of Science.
 Vol.
 56.
 Boston: D.
 Reidel Publishing, 1980, 117137.
 9.
 Gale, G.
 Theory of Science.
 McGrawHill, 1979.
 New York: 10.
 Gutting, G.
 The Logic of Invention.
 In Nlckles, T.
 (ed.
) Scientific Discovery, Logic and Rationality.
 Boston Studies in the Philosophy of Science.
 Vol.
 56.
 Boston: D.
 Reldel Publishing, 1980, 221234.
 11.
 Gould, S.
J.
 The Mismeasure of Man.
 New York: W.
W.
 Norton, 1981, 12.
 Curd, M.
V.
 The Logic of Discovery: An Analysis of Three Approaches.
 In Nlckles, T.
 (ed.
J Scientific Discovery.
 Logic and Rationality.
 Boston Studies in the Philosophy of Science.
 Vol.
 56.
 Boston: D.
 Reidel Publishing, 1980, 201219.
 References 1.
 Wartofsky, M.
W, Scientific Judgment: Creativity and Discovery in Scientific Thought.
 In Nlckles, T.
 (ed.
) Scientific Discovery: Case Studies.
 Boston Studies in the Philosophy of Science, Vol.
 60.
 Boston: D.
 Reidel Publishing, 1980, 120.
 2.
 Laudan, L.
 Why was the Logic of Discovery Abandoned? In Nlckles, T.
 (ed.
) Scientific Discovery, Logic, and Rationality.
 Boston Studies in the Philosophy of Science, Vol.
 56.
 Boston: D.
 Reidel Publishing, 1980, 173183.
 3.
 Grover, S.
C.
 Toward a Psychology of the Scientist: Implications of Psychological Research for Contemporary Philosophy of Science.
 Washington: University Press of America, 1981.
 13.
 Schaffner, K.
F.
 Discovery in the Biomedical Sciences: Logic or Irrational Intuition? In Nlckles, T.
 (ed.
) Scientific Discovery; Case Studies.
 Boston Studies in the Philosophy of Science.
 Vol.
 60.
 Boston; D.
 Reidel Publishing, 1980, 171205.
 14.
 Loper, A.
B.
 Metacognltlve Development: Implications for Cognitive Training.
 Exceptional Educational Quarterly 1980, Vol.
 1, No.
 18.
 15.
 Kendall, C.
R.
, Borkowski, J.
G.
, Cavanaugh, J.
 C.
 Metamemory and the transfer of an interrogative strategy by EMR children.
 Intelligence.
 1980, 4, 255270.
 16.
 Campione, J.
C.
 and Brown, A.
L.
 Memory and Metamemory Development in Educable Retarded Children.
 In Kail, R.
V.
 Jr.
 and Hagen, J.
W.
 (eds.
) Perspectives on the Development of Memory and Cognition.
 New York: John Wiley and Sons, 1977.
 159 A General Model for Simulating Information Processing Experiments Earl Hunt and Pollyanna Plxton The University of Washington Psychologists who study cognition have followed two approaches.
 One Is to Isolate elementary processes of thought and study them In laboratory settings.
 Most of experlaental psychology follows this tradition.
 Alternatively, one can study complex thinking directly, by developing descriptions of the processes of chess playing, mathematical problem solving, medical diagnosis, and the like.
 This tradition Is dominant in Cognitive Science.
 The experimental psychology approach has produced a set of reasonably concise concepts applicable In restricted settings, but it is not clear how these concepts are to be combined during complex reasoning.
 The descriptive approach has produced concepts that describe thought, but the concepts are so flexible that it is often difficult to test them.
 The widely used production notation, for Instance, Is a way of thinking about thinking rather than a testable model of thought processes.
 Our research attempts to unify the two approaches.
 Instead of trying to build up from elementary processes to complex acts, we have taken a "top down" approach.
 We assume that the production notation is an appropriate language for describing thought, and then use it to construct a unified model of information processing that la applicable to several laboratory paradigms.
 If production notation programs ("production systems") can be written to model any thought process, then the mind.
 In general, must be an Interpreter for such programs.
 We have written such interpreter, using concepts derived from experimental psychology In its construction.
 The Interpreter contains sections dealing with the Input of Information over multiple "sensory" channels (Broadbent, 1971), the manipulation of Information in working and long term memory (Baddeley, 1976), the activation of distinct coding systens within long term memory (Posner, 1978), and the execution of information processing steps by a cascade rather than a linear process (McClelland.
 1979).
 Overview of the Model The basic programming construct, a production, is a two part rule, pattern >• action where "pattern" refers to a set of conditions that must be met for a production to be activated, and "action" refers to the steps to be taken when the production's pattern conditions are met.
 Time in the interpreter is divided into cycles.
 Within each cycle the following events take place, functionally in parallel.
 Assimie that stimuli are present In the sensory channels and In working memory and that each production in long term memory has associated with It a number Indicating its "level of activation".
 The Interpreter compares Che stimuli to the pattern half of each production.
 The comparison produces a numerical value that will be called the "strength" of the match.
 A production Is considered "active" If the strength of the match exceeds a threshold associated with the pattern.
 A new activation level is then calculated, which Is monotonically Increasing function related to the difference between the strength of the match and the threshold value.
 (In most of our work, we simply use the difference).
 The activation level is then either Increased or decreased by the activation level of other productions linked to It.
 This process, which constitutes "spreading activation" is referred to as priming.
 Finally, at the end of each cycle all activation levels are reduced ("decayed") to a proportion of their previous values.
 When the activation level of one production exceeds the activation level of all competing productions by a preset criterion, the action half of the production Is initiated.
 The action may be an external response, alteration of an internal parameter in the model, or generation of a stimulus In working memory.
 If no external response is made, "time" is Incremented and the program continues cycling through the set of productions, now using the new stionilus or the old stimulus with new parameters, if they have been altered.
 Firing and cycling continues until an action terminates the program or the program exceeds the allowed processing time.
 The program Imposes psychologically justifiable constraints upon production execution.
 This is done in such a way that production processing will produce the phenomena observed In laboratory studies of mechanistic information processing.
 These constraints are described in more detail in the next section.
 Details of the Program and Model The program, which we call MIND, is written in standard Pascal and contains about 1000 lines of code.
 Production patternaction pairs are currently represented in an Internal symbol code rather than brief English statements.
 A.
 Initialization The input to the program consists of a set of productions, the threshold levels for each production and an association matrix which links the productions to each other in a negative, positive or null manner.
 Other program parameters read during initialization are the decay rate, the decision criterion (DR), an Internal noise scale factor and a maximum processing time.
 Information (a stimulus) is presented over two external classes of sensory channels: visual and auditory.
 Associated with each of these external classes of channels is a special channel which is referred to as an Immediate memory for Information of that class.
 In addition there is a special class of channels referred to as "semantic" channels.
 The semantic channels and the Immediate memory channels are collectively referred to as "working memory" (WM).
 Each production is associated with a channel or channel class.
 Only stimuli from external sources can be placed in the external channels.
 The working memory channels can be written to only by the action side of a production.
 Each pattern in a production Is an ordered string of features.
 A stimulus consists of one or more patterns.
 The Initial stimulus (patterns 160 and pattern features) is read Into the program along with stimulus feature noise levels.
 Noise levels are used when comparing the stimulus features with the production pattern features.
 The initial stimulus is placed in specified external channels• B.
 Response Queue The response queue contains all the actions which have been initiated during the previous program cycle.
 At the beginning of each cycle, the queue is examined and the appropriate action is executed.
 Details of possible actions are explained in section E.
 C.
 Production Activation A match is computed between the pattern part of each production and the stimulus on the appropriate channels.
 A pattern always specifies that it is to be matched to a channel class, and may specify a particular channel within that class.
 The matching function uses Che confusion matrix to weight heavily the most likely pattern matches and to weight lightly the least likely patterns.
 "1", a most likely pattern would be: see "1" • recognize "I" and a least likely pattern would be: see "2" — — recognize "2" Stimulus "7", being somewhat similar to "1", would be an intermediate case.
 Within the pattern part of each production, stimulus features are weighted by their importance for that pattern.
 The strength of the match plus a noise term (a random number that is scaled by the internal noise input parameter) determines the activation level, y[i], of the ith production.
 If the activation level is greater than the threshold level, the production Is considered active and is placed in a set of active productions, {act(y[i])}.
 If it is not greater than the threshold, the activation level is set to zero.
 In this process, all stimuli are compared to all productions in the appropriate channel class.
 D.
 Decision Etule When production activation processing has been completed, all the active productions are searched to identify the highest activation level.
 If this most active production exceeds all the other productions by some decision rule variable, DR (an input parameter), the action half of the production is placed in the response queue.
 E.
 Actions in the Response Queue Actions either: 1.
 Hake an external response.
 A response will terminate production processing.
 2.
 Place an effective stimuli in one of the channels in working memory.
 3.
 Alter an internal parameter of the program (such as altering the threshold level of a production).
 Actions are seen as taking place in stages that extend over time.
 Once the action is initiated, it proceeds, one stage during each time cycle, in parallel with any other actions that may be being executed at the same time.
 Actions can not contain any branches or decision points.
 F.
 Priming After the decision rule has been processed, the activation levels of all the productions are "primed".
 Using the link formed between the productions by the association matrix, y[l] is either increased (when the link is positive), decreased (when the link is negative) or not affected (if there is no link).
 Essentially, a weighted sum of the activation levels of the other productions is added to the ith production's activation level, yCi].
 G.
 Decaying The activation level is also reduced by a delta value, D, another input parameter.
 Delta Is always greater than zero but never greater than one.
 The decay rule is: y[l] • D * y[l] H.
 Time Cycling After the priming and decaying of the activation levels has occurred, time Is Incremented.
 If the time Chen exceeds the maximum processing time specified during initialization.
 Production processing halts.
 Otherwise the program checks the response queue and continues processing the productions.
 Preliminary Results The MIND program has been used Co recreate several of the most reliable findings observed in laboratory studies.
 As the purpose of the simulation experiments was to evaluate the psychological reasonableness of the interpreter, we sought situations in which the production systems to be interpreted were, at the program level, as simple a psychological model as possible.
 The logic of this approach is similar to the logic behind use of very simple programs to test the arithmetic capabilities of computer hardware.
 As is well known, there are probably no situations that dictate Che use of one and only one possible model for human behavior.
 We do feel Chat the laboraCory sicuacions we have studied approach this ideal in varying degrees.
 The approach will be illustrated by a study of Che "choice reaction time" (CRT) paradigm.
 A participant's view is shown in Figure 1.
 The Cask is Co press Che buCCon whose number maCches Che number appearing on Che screen.
 The Cask as shown is a cwo choice cask, four and eighc choice tasks are conscrucced on Che same principle.
 Ic is well known Chac Che Clme Co make a choice in a CRT experimenc is a logarichmic function of the number of alternative stimuli that may appear (Hick's law).
 Figure 2(a) shows a production system for executing a cwo choice CRT cask.
 Figure 2(b) shows the associated production activation network.
 The figure illustrates an important principle that is used in constructing our networks.
 If cwo productions, A and B, are in the same channel class and are mutually exclusive alternative Interpretations of a stimulus, then Che producCions inhibic each ocher.
 However, if produccion A produces, as ics accion, a scimulus chat might trigger produccion B, Chen A primes B.
 The priming relacion may hold for producclons in Che same or in different channel classes.
 Figure 3 presents Che resulcs of a simulad o n of CRT experiments with varying numbers of 161 choices.
 Two results are shown, for two different values of the DR parameter.
 Data from an actual experiment (Taylor, 1982) are also shown.
 The number of cycles required by the MIND program was approximately a linear function of the logarithm of the number of choices, but departed from linearity slightly at the 8 choice point.
 Reaction times from the psychological study showed the same pattern.
 Another characteristic of CRT experiments is the "speedaccuracy trade off".
 For a given individual and condition, the faster a response Is made the more likely an error is to occur.
 When accuracy is plotted against reaction time the function is almost invariably negatively accellerated (Pachella, 1974).
 Figure 4 shows a speedaccuracy curve obtained from MIND by varying the value of the OR parameter, while keeping all other parameters and the number of choices constant.
 The program clearly matched the function found in human data.
 Posner, M.
 X.
 Chronometric explorations of mind.
 Hillsdale, N.
 J.
: Lawrence Erlbaum Associates, 1978.
 Stroop, J.
 R.
 Studies of interference In serial verbal reactions.
 J.
 Experimental Psychology.
 1935, 18, 643662.
 Taylor, J.
 The effects of benzodiazepines on cognition and performance.
 U.
 of Washington Ph.
 D.
 thesis (Psychology).
 1982.
 Welford, A.
 T.
 Motor performance.
 In J.
 E.
 Birren and K.
 W.
 Schaie (ed.
) Handbook of the Psychology of Aging.
 New York: Van Nostran Reinhold, 1977, pg.
 450477.
 FIGURE ) The speedaccuracy tradeoff describes the relation between accuracy and latency for a given individual and condition.
 When one changes either the individuals being tested or the experimental conditions, speed and accuracy are often positively correlated.
 For instance, older people tend to perform more slowly In CRT tasks, and to make more errors (Welford, 1977).
 This result was simulated by holding DR constant constant, and varying the internal noise parameter.
 The results are shovn in Figure 5.
 Again the pattern is similar to that obtained in the laboratory.
 B s s •<—Screen < Keyboard CHOICE DEACTION TASK MIND has been used to simulate a ntsnber of other results from the literature in experimental psychology.
 These include the Stroop phenomenon (Stroop, 1935), the effects of repetition of the same stimulus over trials in CRT paradigms, and interference effects when two tasks are done simultaneously.
 These results will be reported in a larger paper.
 While we do not claim to have modeled the microstructure of all these phenomena perfectly, the initial results are encouraging.
 The ranges of parameter values that are adeqtiate to simulate one task overlap considerably with those required in other tasks.
 This is a particularly encouraging finding.
 It appears that the values of the parameters of this model must be held to a rather tight range if the model la to work at all, but that within this range reasonable results can be obtained.
 Production Rules Visual Channel 1 z 1 >Puf S1 hi Semantics Channel t Z 2 —^ Put 32 in Semantics Semantic S1 S2 > Make response 1 > Maice response 2 Figure 2 (a) SlmulaHon of CRT exparimwit ACKNOWLEDGEMENT: The research reported here was supported by the Office of Naval Research, Contract NQ00148OC0631, to the University of Washington.
 We are glad to thank Dr.
 Marcy Lansman for her constructive coomients and criticisms.
 REFERENCES Baddeley, A.
 D.
 The Psychology of Memory.
 New York: Basic Books, 1976.
 Broadbent, D.
 E.
 Decision and Stress.
 Hew York: Academic Press, 1971.
 McClelland, J.
 L.
 On the time relations of mental processes: An examination ot ŝ atema ot vto«.
aaafea in cascade.
 Psychol.
 ?.
ev .
, V91% , %(>.
 V̂ .
T̂ 'î .
 Pachella, R.
 G.
 The interpretation oi Ttac.
ti.
oQ.
 time in Information proceaaing xeseaxcVv.
 Iti •&.
 'ft.
.
 KanCowitz (ed.
) Human Information Processing: Tutorials in Performance and Cognition.
 Hillsdale, N.
 J.
 Lawrence Erlbaum Associates, 1974.
 DR Ru'« I—>S °  ° y 2 — I 'visual' \ { "^S^ ""̂ '̂i .
 yftr 'semantic* p ̂ 2 Bgure 2(b) Association Network For 2 choice Tast( 162 http://Ttac.
ti.
oQFtgu" 3 figure 5 THtnjI* (nalcitM (UU frw T.
ylor (19»? 4.
03 Ni«»«r of cyclM to dtctslor paint (t«ft ordlint*) or retctlon tin (right ordinate.
 In Mi 11 Utcondl) 4S a function of tne nu«Mr of cnoicts Accurjcy of cKolce (ortlntte) vs.
 nu>*«r of cydts (ADelss*).
 Each point rrprvstnta a different value of the internal noise paraaeter.
 T w choice U»k.
 Figure 4 781 Accuracy of choice (ordinate) vs nunoer of cycles reouired to reach a decision.
 Each point represents a aifferenc «dlue of the (3R paraiwter.
 163 ARCHITECTUREDIRECTED PROCESSING Richard M.
 Young MRC Applied Psychology Unit, Cambridge, England Abstract.
 Certain general characteristics of human cognition may be due to properties of the functional architecture of the cognitive processor.
 While proposed cognitive architectures are almost always "universal" and can be forced to execute arbitrarily chosen computations, nonetheless It Is possible to delineate a class of "compliant" processes that allow the architecture of the processor to influence the course of processing.
 A speculative case is made that such compliant processing is responsible for invariants of human cognition, such as that problem solving occurs as heuristic search in a problem space, that longterm memory search takes place in cycles of retrieval and redescription, and that uncertain information is dealt with by prominence heuristics.
 Compliant processes A central theme in Cognitive Science Is the explanation of features of human cognition in terms of properties of the programs that generate and regulate behaviour.
 The paradigm is to account for the empirical phenomena observed in some domain, e.
g.
 the time taken to decide the truth or falsity of simple propositions, by showing that they derive from properties of the processes responsible for the behaviour.
 For all its undoubted merits, there is a gap at the heart of this approach.
 Although such computational explanations have genuine scientific value, for example by offering a single coherent account for a range of apparently diverse phenomena, there is a need also to try to understand why those particular programs are found but not conceivable others.
 The idea explored in this paper Is that the functional architecture of the processor Itself influences and constrains the kind of programs it can execute, and hence leads to Invariants In the resulting behaviour.
 There is little novelty in this idea: all I hope to do here is to draw together a ntmber of threads from various places.
 The idea derives mainly from the work of Pylyshyn (1980) and especially Newell (1973, 1980).
 Pylyshyn (1980) discusses the notion of the functional cognitive architecture, i.
e.
 the fixed structural properties of the himian cognitive system.
 Building on that notion, we extend it to the properties of the processes that the architecture supports.
 The argument is Inspired by, and is closely similar to, that of Moore & Newell (1974).
 In describing a system called Merlin built round a single processing mechanism, that of assimilation by analogy, they suggest that certain general problem solving methods (Generate and Test, Heuristic Search, etc.
) arise within Merlin aa "natural methods".
 In other words, Merlin exhibits these methods not because it runs a program directing it to do so, but because they arise as consequences of Its single processing technique.
 In a similar way, this paper is proposing that certain general characteristics of human cognition arise as "natural methods" from the functional architecture of the cognitive processor.
 It may be helpful to consider an analogy, both to understand the idea better and also to highlight Its Idlosyncracles.
 Most of us are familiar with the idea that different programming languages lend thanselves selectively to different sorts of pro164 grams for different sorts of tasks.
 It is possible in principle to use LISP for commercial programming and COBOL for list processing, but in practice certain kinds of program fit "naturally" into certain languages and only with difficulty into others.
 Note, however, that this "naturalness" is extremely hard to pin down in a formal definition.
 The notion of architecturedirected processing is somewhat similar.
 It centres on the idea that for a given architecture certain programs will run "naturally", while others can only be coaxed on with a sledgehammer.
 However, architecturedirected processing goes beyond the idea of naturalness, since it allows the architecture to influence the actual selection and sequencing of the steps to be taken.
 To some extent this is also true of programming languages.
 With ordinary sequential flow languages, such as FORTRAN and PASCAL, there is a kind of "default" control structure (i.
e.
 execute the next statement) which the programmer can override when she wants to (by Iterations, Jumps, subroutines, and so on).
 However, In normal practice programmers use this sequential control in order deliberately to specify the order of execution, so to regard it as a default is a little misleading.
 With architecturedirected processing the influence is more pervasive, since at least for certain production system architectures (PSAs) (Newell, 1973, 1980; Anderson, 1976; Waterman & HayesRoth, 1978) the program does not have to specify an order of execution at all.
 Once the repertoire of possible steps has been supplied, the selection and sequencing can be left to the architecture, which appropriate PSAs can perform in a highly flexible manner responsive to the particulars of the task (Young.
 1977, 1979).
 The program can still, of course, specify the control structure where it needs to.
 This freedom leads to the idea that responsibility for the flow of control has been split between the program and the architecture.
 It follows that programs will differ in the extent to which they insist upon a particular control regime.
 Programs that allow the architecture to have largely its own way we will call compliant.
 Not to be taken too seriously, but as a starting point, we can offer a tentative Definition.
 A program is "compliant" to the extent that it allows the selection and sequencing of steps to be determined by the architecture it runs on.
 The examples given below will try to demonstrate that, given an architecture, compliancy leads to the appearance of certain invariants in the generated behaviour.
 It's hard to be precise.
.
.
 In one Important respect this notion of "compliancy" is very similar to the idea of "naturalness" in programming languages, and that is in the difficulty of making it more precise.
 Despite our recognition of the selective suitabilities of different languages for different kinds of programs, it remains the case that the languages are almost always computationally "universal", and therefore formally equivalent in power.
 It follows that any program can, in principle, be written in any of the languages, and that it is hard or Impossible Co capcure the Idea of "naturaloess" in a formally precise way.
 So far as I know, even Che recenc progress In compucadonal complexlcy has nochlng Co say abouc chls Imporcanc pracclcal problem.
 The scory Is similar for compliancy.
 Proposed cognlclve archlceccures are almosc always universal, and chus IC Is possible In principle Co run any program on any archlceccure.
 In mosc cases, of course, Chls will require a noncompllanC program which imposes an alien concrol scruccure.
 Our InceresC is In Che cases where Chls kind of bruCe force Is noc needed.
 The following examples will make clear chac furcher progress depends uoon being able Co specify whac Is meanc by compliancy In more precise cerms.
 I am noc cocally opclmlsdc chaC we will succeed In Chls, buc I can see Cwo avenues worch exploring.
 The flrsc is Co cake advancage of Che face Chac compliancy has Co do specifically wlch flow of concrol.
 There Is a sense In which Che seeps of compllanC programs execuce ac "base level", whereas noncompllanC programs require an extra level of inCerprecadon.
 If chls difference can be cap cured reasonably precisely, chere is some hope of deriving Che consequences of compliancy in a more rigorous way.
 The second possibility depends on achieving some underscanding of Che mechanisms by which new programs are acquired.
 This mighc provide a much stronger basis for placing conscraints on Che kinds of program Che cognlclve processor will run: noC Chac noncompllanc programs are "unnatural", but by showing that only compllanC programs could ever be learned.
 Examples There follow chree examples Co illuscrace how compliant programs lead to Che appearance in behaviour of cercain invariancs dictated by the underlining architecture.
 Two warnings need to be given.
 One is that the difficulty of making the notion of compliancy even moderately rigorous makes it impossible in any strict sense to derive the invariants from Che archiceccure.
 The argtmenCs given, though Intended Co be plausible, have to be regarded as handwaving.
 The other is that these examples are speculative.
 I would not wish Co give Che Impression chat the arguments are summaries of a more complete story already worked out.
 Rather they should be regarded as the goals for a programme of work still Co be undertaken.
 Ex.
1: Problem solving Is carried out by heuristic search in a problem space.
 That assertion can reasonably be taken as the onesentence conclusion of Newell & Simon's (1972) study of human problem solving.
 It arises as a consequence of compliant programs running on PSAs of certain types.
 This is the clearest of the three examples, and Che argument Is essentially due to Newell (personal coomunicatlon).
 Consider a PSA which is like OPS (Forgy & McDermotC, 1977) In Che following respecc.
 Whenever more than one production rule is applicable, the one to fire is determined by Che following principles ("conflict resolucion").
 (1) Recency: rules whose condlcions are sensidve Co more recenc informacion Cake priority over those matching only older information.
 (2) Special case: rules which are special cases of other rules take priority over them.
 (For further details see McDermotC & Forgy, 1978; Forgy & McDermott, 1977).
 Suppose that knowledge of the problem domain is coded by specifying the possible moves that can be taken in circumstances C as rules like: Rule 1: C & <? side condltlona>  <actlonl> Rule 2: C & <? side condltions> ' <action2>, etc.
 Note chac such rules provide a highly compliant representation.
 They impose only local conscralncs on how Chey are used, and Chus have individually, as it were, no opinion abouc Che more global flow of concrol.
 Suppose that C is known.
 Then one of the rules shown will fire, Rulel say.
 If the action Caken leads Co some new informacion and there exist rules responsive to that Information, then by the recency principle it will be one of those rules that fires next.
 And so Ic concinuea, as long as Chere is new informacion and rules Co respond to it.
 Once that is no longer so, processing falls back, say to the rules shown, and one of Che alcernatlve rules at that level will fire; in this case, Rule2.
 In other words, a depthfirst search is performed.
 On the other hand, if at any time a rule which is sensitive to a particular configuration of Information becomes satisfied, then by special case it will be Che one to fire.
 In ocher words, specific knowledge Is broughc Co bear when approprlaCe.
 The upshot of all this is that the principle of recency generates depthfirst search, while special case adds heuristic guidance.
 It is worth emphasising Che concraac between this explanation and virtually all earlier accounts In the cognitive modelling literature (including, for example, Newell & Simon, 1972).
 We have Just argued Chat people solve problems by heuristic search, not because they run a "heuristic search program", but because, in the absence of guidance to the contrary — i.
e.
 with a compliant program — heuristic search is Che natural thing for the PSA to do.
 Ex.
2: Indirect recall from long term memory.
 When Che cues presenced are insufflclenc Co elicit some target information from long term memory directly, both theory (Norman & Bobrow, 1979) and the experiment (Williams & Hollan, 1981) suggest that recall occurs In a series of cycles of alternating retrieval and redescrlptlon.
 Again, this behaviour is a consequence of the conflict resolution principles of a PSA.
 Suppose that the target Information is on the action side of a rule.
 Then by supposition, not all the information on its condition side is yet present (the point is to gather IC so that the rule does fire).
 Whatever information is present, constituting a partial descrlpclon of Che ICem being sought, will trigger some rule or oCher.
 This in Cum will add CO Che description.
 Special case ensures that each item recrieved is relevanc Co the current description; If there is no relevant information, then general procedural heuristics will fire.
 As in problem solving, the recency principle ensures that newly retrieved information is followed up first.
 Ex.
3; Uncertain information is dealt with by "prominence" heuristics (Fox, 1980a), such as representativeness and availability (Tversky & Kahneman, 1974).
 The implied contrast is with rational, nonheurisclc Cechniques such as Che use of Bayes' Cheorem and Che maximisation of expected value.
 For this example we have to move beyond the OPS architecture, to a PSA which assigns different strengths to different items, and thereby recognises a degree of match between the data and a rule.
 Examples are HPSA (Newell, 1980) and the PSYCO architecture used for simulating medical 165 diagnosis (Fox, 1979, 1980b).
 The argument essentially follows those two authors.
 The key issue is the representation of the degree of certainty.
 If it is coded expllctly as simply another component of the data, e.
g.
 (DISEASEIS GASTRICULCER CF  0.
7).
 then It will be treated as part of the information content by whatever rules happen to process it, and no consequences follow from the architecture.
 If, on the other hand, certainty is coded as the strength of the item, (DISEASEIS GASTRICULCER) [0.
7], then the certainty has effects at the level of the architecture (i.
e.
 it appears as an aspect of the form rather than the content of the item), and influences processing at this level.
 What happens of course is that certainty enters as a factor in conflict resolution, with stronger items, other things being equal, being processed before weaker ones.
 The outcome is that processing of uncertain information Is dominated by the data that for whatever reason are more "prominent" in memory (Fox, 1980a).
 Items which are highly familiar, already in working memory, or more closely linked to other relevant items will be the first to come to mind and will carry more than their fair share of responsibility for guiding behaviour.
 McDermott, J.
 & Forgy, L.
 (1978) Production system conflict resolution strategies.
 In Waterman and HayesRoth (1978), 177179.
 Moore, J.
 & Newell, A.
 (1974) How can Merlin understand? In L.
 W.
 Gregg (Ed.
), Knowledge and Cognition, 201252.
 Erlbaum.
 Newell, A.
 (1973) You can't play 20 questions with Nature and win: Projective comments on the papers of this symposium.
 In W.
 G.
 Chase (Ed.
), Visual Information Processing.
 283308.
 Academic Press.
 Newell, A.
 (1980) HARPY, production systems and human cognition.
 In R.
 Cole (Ed.
), Perception and Production of Fluent Speech.
 Erlbaum.
 Newell, A.
 & Simon, H.
 A.
 (1972) Human Problem Solving.
 PrenticeHall.
 Norman D.
 A.
 & Bobrow, D.
 G.
 (1979) Descriptions: An intermediate stage in memory retrieval.
 Cognitive Psychology, 11, 107123.
 Pylyshyn, Z.
 (1980) Computation and cognition: Issues in the foundation of cognitive science.
 Behavioural and Brain Sciences.
 2.
 111169.
 References Anderson, J.
 R.
 (1976) Thought.
 Erlbaum.
 Language.
 Memory and Forgy, C.
 L.
 & McDermott, J.
 (1977a) OPS, a domainindependent production system language.
 Proceedings of the 5th International Joint Conference on Artificial Intelligence.
 933939.
 Forgy, C.
 L.
 S McDermott, J.
 (1977b) The 0PS2 reference manual.
 Technical Report, Department of Computer Science, CamegleMellon University.
 Fox, J.
 (1979) Medical diagnosis: Inference, recall and a theory of skill.
 Unpublished ms.
 Fox, J.
 (1980a) Making decisions under the influence of monory.
 Psychological Review.
 87, 190211.
 Tversky, A.
 & Kahneman 0.
 (1974) Judgement under uncertainty: heuristics and biases.
 Science.
 185.
 11241131.
 Waterman, D.
 A.
 & HayesRoth, F.
 (1978) PatternDirected Inference Systems.
 Academic Press.
 Williams, M.
 D.
 & Hollan, J.
 D.
 (1981) The process of retrieval from very longterm memory.
 Cognitive Science, 5, 87119.
 Young, R.
 M.
 (1977) Mixtures of strategies in structurally adaptive production systems: Examples from serlatlon and subtraction.
 Proceedings of workshop on patterndirected inference systems.
 SIGART Newsletter No.
 63, June, 6571, Young, R.
 M.
 (1979) Production systems for modelling human cognition.
 In D.
 Mlchle (Ed.
), Expert Systems in the Microelectronic Age.
 3545.
 Edinburgh University Press.
 Fox, J.
 (1980b) The PSYCO manual.
 MRC Social and Applied Psychology Unit, University of Sheffield,, England.
 166 Question Answering: T w o Separate Processes • Marc Luria Division of Computer Science Department of EECS University of California, Berkeley Berkeley, Ca.
 94720 1.
 IntroductloQ I have developed a question answering program that will answer questions about simple stories.
 In m y program, questionanswering ia divided up into two separate processes: 1) answering formation and 3) answer expression.
 The program first looks down a causal chain which is formed by the storyunderstanding program and figures out in what part of the chain the answer lies.
 The answer can also be a subset of the chain, sometimes a quite long one.
 The second part of the program takes this long chain and decides what things are important to express to the questioner.
 This answer expresser uses general rules of expression to figure out what it needs to include to make the answer understandable, informative and interesting.
 This solution is diSerent from other questionanswering algorithms (e.
g.
 Winograd 1972, Lehnert 1977) which view question answering as one process.
 These programs gather possible answers, and then choose the "best" answer from among them.
 My system first gets the chain which I consider to be the answer to the question, and then figures out which parts of the chain should be generated into English as the answer.
 The advantage of m y approach is that it allows one to treat the answer as one entity and use the answer expression mechanism to express what people are interested in.
 The resxilting answers are generally more informative and conversationally appropriate than those generated by other algorithms.
 The program works in conjunction with PAMELA, a story understanding program that specialises in goalbased stories.
 (¥Uensky 1977, WUensky 1981.
 Norvig 1982) After a story is initially 'read' by PHRAN, a parser.
 (Arens 1981) it is then passed to this PAMELA and 'understood'.
 The question answering program is passed a database which consists of events, inferences, and most importantly, for m y purpose, causal chains which instantiate events in the story as steps of particular plans and plans for particular goals.
 Contained in this causal chain is the actual 'understanding' of the sequence of events in the story, what caused what, and what goal actors had in mind when they performed a particular act or plan.
 After a question is asked, this question is parsed by the same parser that parsed the story, and then the answer is formulated by looking at the database.
 Finally, the answer is passed to the answer expresser which sends the answer to a natural language generator.
 2.
 Program Ezamplea* The following examples were processed by m y program.
 Story: Susan saved her money from her allowance.
 One day she rode her bike to the bookstore and bought the book that her teacher had recommended.
 Susan did very well on her math test the following week.
 Q: Why did Susan buy the book? A: So that she could study from it and do well on her exam.
 Q: How did Susan do so well on her math exam.
 A; She bought a book that her teacher had recommended and studied from it.
 Q: How did she get the book? A: By riding her bike to the bookstore.
 3w nnding the Best Answer A difficult and important part of answering a question is not in finding an answer to the question, but finding the best answer.
 In a database of causal chains, if one can find an event in the database then there may be many possible answers to a given question.
 Consider the previous story.
 If we ask: Question2: Why did Susan buy the book? The following answers ais obtained by stepping at diSerent on the causal chain.
 Answer2a: Because she wanted to have it.
 AnswerSb: Because she wanted to read it.
 Answer2c: Because she wanted to know math.
 AnswerSd: Because she wanted to do well on her exam.
 Note that the items nearer the top of the goal structure constitute better answers although the best answer would be something like: Answer2e: So that she could study it and do well on her math test However, in a more complicated story, merely look.
 ing to the end of chain might not work quite as welL For example, if in the previous story we added: She put the book on her head and learned the material through osmosis.
 Susan did very well on her math test the following week.
 Clearly, Answer2d is no longer a good ainswer.
 One possible solution including only 'Important' answers.
 Important inferences might include abnormal plans, natural disasters, etc.
 The problem with this was that even though these 'important' inferences definitely should be included in the answer, one should not necessarily stop at that point in the chain and say that this is the answer.
 For example, just stopping at 'important' events in response to question2 one would get: Answer2f: So that she could put it put it on her head.
 An3wer2g: So that she could learn by osmosis.
 which is less desirable than: Answer2h: So that she could learn from the math book by osmosis and do well on her exeim.
 4.
 OividiDc up the Questioa Answering Process My program is able to find these better answers because of the separation of finding the einswer (the subset of the chain) from expressing the answer to the user.
 Instead 1 use the two programs: AnswerFormulator looks down a causal chaia figures out where what parts of the chain are relevant to an answer and returns a chain.
 IntelligentExpresser: takes this causal chain as input, figures out from its general rules of expression what Thi* research was sjxjnaored in part by the Office of Naval Research under contract N0001480C073Z and the National Science Foundation under grant UCS790ee43.
 •At this point the program is not connected to the natural language parser at Berkeley called PHBAN or the generator PEIREO (Wilenaky and Arens, 1980).
 The questions and onswers are therefore translated from.
 the conceptual form I now use.
 167 is important to say so that the questioner will a) understand the answer and b) get the land of information that people are generally interested in, and outputs to a natural language generator, some intermediate form from which it could generate an answer.
 For example, my program would produce answerSe above by the following process.
 First it would find Susan buying the book in the database and then follow the chain, in this case, to where it finds that she did well on her exam.
 This whole part of the chain would be passed to the expression mechanism which would notice that studying the book and doing well on her exam were important parts of the answer.
 In this case, the IntelligentExpresser uses the general conversational rule of not informming someone of something they already know.
 Having the book and reading the book are thereby eliminated because they are stored in the data base as normative purposes for buying and for having a book, respectively.
 This approach also allows one to generate answers that were otherwise problematic to represent in a conceptual form.
 For example, the simple question: Questions: Did Susan go to the bookstore? Answers: Yes.
 she rode her bike there.
 The answer is obviously yes, because this event appears in the database.
 However, 'yes' is something that is dUEcult to represent in conceptual form.
 'Yes' is not really a concept but rather a word that is almost exclusively used in a conversation.
 The answer formation part of m y system looks in the database for concepts similar to going to the bookstore.
 Realizing that riding to the bookstore was similar to going there it would answer: (ride (actor (person (object susanl))) (object (bicycle (object bicycle 1))) (destination (bookstore (object bookstorel)})) This part of the chain and the context in which the question was asked is passed to the answer expression part of the program, that would a) see that this is a simple verify question, b) realize that the concept to be verified was in fact found in the database in a slightly dUIerent form and c) figure out that it should answer 'yes' plus some uitermediate form that represents that it should include the ride concept.
 This same method can be extended to other types of verify questions.
 For example, Question4: Did Susan ride her bike to the bookstore so that she could do well on her math test? Answer4: Yes, she bought a book at the bookstore which she used to study for her exam.
 Questions: Did Susan buy the math book so that she could do well on her math test? AnswerS: Yes, she used it to study for her exam.
 The answer formation part looks to see if a chain with the starting place of 'riding to the bookstore' and ends with 'doing well on her math test', exists in the database.
 This whole chain does exist and includes, she rode to the traokstore was a plan for being at the bookstore, which was a precondition for buying a book, which was a plan for having the book which was a step of reading the book, which was a plan for knowing the math material, which was a goal from doing well on her exam.
.
 The answer expression part of the program gets this chain, realizes it should answer 'yes' and decides how much in addition to the 'yes' it would need to include in the answer.
 Notice how in Answer* it had to include more information from this chain than it had to include in Answers.
 not something that is designed to be used exclusively in questionanswering but would be a system that would be valuable in any context where an interactive natural language system would be Important.
 It diflers from a generator in that it does not merely generate something from a conceptual form Into English, but rather decides what kinds of things are important to be said, which is then passed to a generator.
 Hopefully, this kind of system could be expanded to work on other conversational tasks as well.
 Raferancea Lehnert, W.
, 197B.
 The Process of Quastion Answering: A Computer SirradatioTi of Cognition, Hillsdale, N.
J.
 Lawrence Erlbaum Associates, Inc.
 WUonsky.
 R.
 , 1978.
 Undarstancting CoalBased Stones.
 Technical Report 140, Computer Science Department.
 Yale Univarsity, New Haven, CT.
 WUensky, R and Arens.
 Y.
 1980 P H F A N  a Knowledge Based Approach to Natural Language Analysis.
 University of California at Berkeley.
 Electronic Research Laboratory Memorandum No.
 UCB/ERL M80/34.
 Wilensky, R.
 1981.
 Metaplanning: Representing and using knowledge about planning in problem solving and natural language understanding.
 Cognitive Sciance.
 Vol.
 S.
 No.
 3.
 1981.
 Winograd, T.
 1972 [Mderstanding Natural Language.
 New York.
 Academic Press.
 5.
 Concluaioa This intelligent expression part of the program is 168 Exploded Coiiiieciiuii!.
: Uiicliuiikiiii; Sclieiitutic kiiu\iilcd|;e Sleveii I.
.
 Small Dcpanmeiii oI'Lompuier Sciente The Uiiivcrsiiy of Kouhesler Rochester.
 N e w York 14027 Rack)>rouiid li has been understood for some ume that the organisation of knowledge into event schemata and visual schemata can aid signillcantly in the inferencemaking process.
 If we know that we are in a typical room, to use Minsky's example [1974], then we expect to sec windows, walls that are perpendicular to a ceiling, etc.
 If we know thai we are at a restaurant, to use Schank's example (I975|, then we can expect to be seated by a maitre d'hotel, to be given menus, etc.
 liy classifying situations according lo a small collection of schematic situations, a wide variety of inferences become immmediaiely clear and simple.
 This same kind of schematic reasoning conslituies the heart of several wellknown theories of lowlevel comprehension, especially by Schank 119721, Wilks [19?]), etc.
 By classifying iinguisUc clauses into a small number of semantic categories, such as physical transfers of location ( P T R A N S ) , propelling of objects (PKOI'LL).
 etc.
, a number of inferences are suaighiforward.
 Certain kinds of paraphrase are simple; "buying" and "selling" are represented in almost the same way; "running," "walking," and "biking" have much in c o m m o n in their semanlic representations.
 The schema for abstract transfers of possession (A I R A N S ) leads us to expect exchange of one thing for another from one person to another.
 If any of these are not specifically specified, they can be inferred easily, further, such an abstract transfer probably took place because one person wanted to own something thai had been owned by someone else, the other person probably didn't want it so much anymore, and similar kinds of simple inferences.
 The M A R G I I i system [Schank et al, 1973) exhibited very impressive behavior without using much more than schematic inferences based ou the semantic representation scheme of Conceptual Dependency (CD).
 Unchunkint' Schemata III this short paper, we suggest a framework lor the iliidy III :i(.
heinaUc aspects ol natural l.
iiit.
'ii.
igL u>iii|iaticiibi(>ii spe«.
ifii.
jllv wc puiMu ilie uui i.
l Itliiinni |l')7(i] iii I'K'lt̂ nini; lilt, dyiiaiiiu i.
illici lli.
in .
l.
ili> .
I'liikiiiK <il • '.
 .
" Il .
lui lIlC MM III |i,ll,,l|i 1 1 1 .
 , .
.
 'iMl.
' I knowledge representation facilitates that goal.
 The approach draws from previous work in schematic representation and reasoning [Miiisky, 1974; Schank, 1975), spreading activauon [Quillian, I96«|, parsing [Small, 1980; Marcus, 1979].
 speech recognition (Ixjwerre, 1976), psycholinguistics [Dell, 1980; McClellaiul and Rumelharl, 1980], and computer vision [llallard, 1981; Marr, 197H|.
 By decomposing schematic knowledge into diiluse units and by studying the way these facets o( knowledge are connected (inferentially), we expect to show iinporiani results in several areas:  how a language comprehension system can maintain diffuse loci of control (hypxaiticses) simultaneously, but still conic to a ilcxisioii when required;  how to obtain schematic reasoning (and expectations) from distributed units not a priori committed to representing unique sialic siiuaUons;  how to merge schematic inference mechanisms from the topdown (e.
g.
, scripts) and from the boitomup (e.
g.
, case frames); and " how to relate experimeniai psychological data (e.
g.
.
 reaction tunes on normals and aphasics) to computer models.
 The modelling etTort employs an architecture significantly dilTerent from the typical computer and closer lo that of the human brain.
 W e use a particular spreading activation or aclive semanlic network scheme, called conneciiom^int, which consists of a massive number of appropriately connected computing units that communicate through weighted levels of excitation and inhibition [leldman and Ballard, 1982], While such an architecture does not solve any problems per se, we believe thai a number of questions become easier to sei forth and more straightforward to solve.
 This paper intends only to suggest the directions of our currenl research in addressing several language comprehension issues from the new perspective.
 Some Main Issues In particular, we show how a number of classical problems in the theory of schemata might be approached in a new way.
 Three principal issues are discussed: (1) Comprehension takes place on a number of interacting levels of processing; (2) multiple hypotheses are simultaneously maintdined al a number of ditfiise processing loci; and (3) context atVects proLcvsing in both topdown and hoiloin up iliicLiioiih i ipriiiiieiital psychologists iuc hcgiiuiiiix lo iiiiiIiinI.
iiii! iiici issuer through rcaciioii iiim: .
i.
ii.
i Mi i lili.
,ii.
l .
.
n.
i iif i.
 Iliaii [1980] have identified two processing levels; Dell [I98(i| presents data suggesting interactions within the phonemic level; Swinney [1979] shows ways ui which context Joe\ not affect processing; Seidenberg et al [1980] illustrate an entire time course for processing at the lexical level; and Samuel et ai [1982] present daui suggesting the mechanisms of letter processing and the word superiority effect.
 Multiple Levels of Comprehension While it is sometimes the case that a language understander needs to know the primitive schematic actions that compose a more complex acUon, often he does not.
 The relevant information carried by paruciilar words and expressions is precisely that information that aids the hearer to understand the intended meaning of the speaker.
 This always lakes place in some context and cannot be separated from it.
 In a dialogue, a hearer must iiiierpret the words and expressions in light of the coiiiiiiiiiiicaiive goals of the speaker; in a story, a leader iriiist serve to connect new fragments of text wiih the existing interpretation of story structure.
 Iiiriher, general knowledge about the world must be applied where needed 169 10 the comprehension process (even al ihe level of individual words and phrases), and ihe stoi^ or goal siruciures consuucied musi be coiisirained by u.
 Il seems unusual to consider certain ucuoiis in leniis of their decomposiuons (in the sense ot C D ) into slructurcs of primitive units.
 There are very few coiuexis in which the sentence "Ricic kissed Joanie" would be best understood by focusing on the (nonetheless valid) lati thai "Ricit moved his head to in front of ihe head of Joanic so that they were both facing each other, and then puckered his lips and touched them to Joanie.
" This long descripuon must be represented as the algorithmic (functional) concept underlying kissing.
 This description would be required lo understand the sentence "Joanie caught Kick's cold" occurring next.
 It would certainly not help in undersunding the sentence "Joanie bought herself a new blouse.
" The understanding of this second conceivable utterance requires an entirely different set of relauonships concerning kissing.
 Multiple Stmultaneowi Loci of Control Thus, we need at least two diflereni kinds of associations of kissing to understand sentences in which it is a central action.
 W h e n hearing such a sentence, both of these kinds of associations are acuvated, and either one luu be relevant to undcrsiaiiiling what comes next liiithcriiuiie, the luiMrKI |iu\i<i(i', Id (he kis.
MtlK .
ictloii ti.
iilil linc lo make liiii' "I lu .
illiii <•! iliC'C av>oi uilii>ii\ ilii' |iiiiiiiiiiciil iilic ili> .
11 .
li ! Kiii.
lllil; I 111.
 iiiUii.
 L "I'l.
 ̂  dlilh I care about the flu" would faciliuie undersunding the next sentence in a way more heavily weighed toward the algorithmic association of kissing than the emotional one.
 Likewise, the preceding senieiict: "Kick felt strongly atTected" should facilitate the other associations.
 A n active processing network works through simultanous activity in m a n y processing locations, permituiig a cognitive model to avoid irrevocable allornoue decisions in favor of a mure continuous approach.
 This leads to plausible explanations of subsequent context elTects, indiiding puns.
 Context Effects on Comprehension In building a computer model of language comprehension, we must consider these phenomena.
 Ihe context preceding an utterance must serve to favor certain inierpretations over others.
 As in the example presented here, the competing interpretations need not be incompauble: the context must simply facilitate the comprehension ot subsequent utterances by focusing on one level of imerpreution over others.
 It should take longer for a hearer to understand how Kick could get the (lu from Joanie if conditioned to focus on their emotional involvement, than to understand the same utterance after contextual condidoning to focus on the mechanics of kissing.
 The results of Seidenberg et al [1980) suggest that analogous contextual elTects hold with respect lo lexical access.
 Ihe computer model should make accessible all levels of interpretation of utterances, but should not make everything as easily accessible as everything else.
 W h e n knowledge of the mechanics of kissing are required to understand a fragment of text, it must be available.
 If the text is about some romantic relationship, this knowledge would usually be an obstacle, rather than a help, to understanding, lu such u case, it should be available if needed (though perhaps slowly), but mosUy it should not be involved.
 Ihe Kxploded Connection Scheme W e propose a uniform representation scheme for both 170 high and lowlevel language processing that shares some of the flavor of the schematic approaches, but which incorporates flexibihly through three methods: (1) The use of incredibly large numbers (and wide variety) of schematic situations {units); (2) A focus on the relationships among these situations rather than (Jii ihe siliialions themselves {cunnn turns), and (.
1) The list of iiumciii.
il piUcniial:.
 in vvci(ih (comparatively) the iclcvaiii.
e .
>i .
iiu (.
iiiuiil.
u Mliiniuiii situation to the data {activation levels).
 We call the approach an Exploded ( onncction Si heme (ECS), and are using it to build a iinilied theory of lowand highlevel language comprehension Ihe demenial units of E C S encompass the gamut of traditional elements of comprehension models, from phonemes and morphemes to cases and semaiiuc primitives to concepts and event sequences.
 W e believe that ihcre arc large numbers of each kind of unit, and that reasoning lakes place through the richness of the unit vocabului^ and the connections among the individuals Sumc of our current ideas on the organization of these ex(jludcil units can be found in [Coiirell, 1982].
 What we are arguing for is a highly difliibe active representation of knowledge and its processing.
 Iradiiionul models [Schank et al, 1973; Small, 198(J| represem the meaning of utterances in single, large, complex siriiciuies of some small number of primitive elemenis.
 Large processes then manipulate this knowledge, encoding and decoding the large symbol structures.
 Alternatively, we are suggesting representing meaning in a very large number of (exploded) active processing units, which compute activation as a function of incoming weighted excitation and inhibition.
 The scheme focusses on the complex interactions among diffuse knowledge units and reduces the complexity of individual processes.
 Such processing units that do not manipulate complex symbol structures can interact frequently and tightly.
 The Pair Principle Each unit of a particular type uiggers activauon in other similar units that are likely to come next in meaningful speech.
 This happens at every level of processing, within the level itself and is called the pair principle.
 The principle stales that every element of knowledge U'iggers other elements (of the same kind) that are likely to succeed the given one (temporally or inferenually) in meaningful speech.
 Dell (1980) shows a model for speech production in which connections according to this pair principle lead to plausible explanations of experimental results in production of speech errors, liy adding connections between levels, activity spreads through the network in a way that leads to predictions at every level of processing about what is coming next.
 The spreading activauon model of McClelland and Kumelhart [1980] shows such predictions through grapheme/lexeme interactions.
 The results of Samuel [1980] on word superiority also support this view.
 I xamples ot the pair principle can be sciii at every conceivable level of Liu^ua^e proccsMiii;.
 A plioiiciiie iinii .
tcllvatcs tlloA utiicr liliiilKUie iilill:.
 lli.
it .
 ,ii lolii.
i.
 llii' given one under the rules of the phonological system ot a particular language (or the phonologic rules known lo ilic hearer).
 A highlevel activity unit jciivaicb the unii:, tor other highlevel activiues thai can reasonably come iicxl under the rules of cultural bchavioi ot a society (or analogously, those rules known to the umlcistandcr) An http://lli.
ituclion uiiii iiiLrea;>ê  Ihe poieiuuiU of lypc iiiiils ihui represent (he kinds of (tiings ihai umkl lie itic Labc tiller!> ot' thai puriicular aLiioii.
 The puir iiiMuipIc iiiiilciheb the way we go about connecting uniLs logctlici within particular Icvel;̂  of the coiiiprchenMon nuiJcl Sclieinata At the level of high level aciiviiies the paiiwibc connecuons of units might seem lê i ohvimiN ihan al ihc level of phonemes.
 TTie ioiind paiitrii ol langiiaKes arc wellknown, but not so the cultural regulaiitics luiiher, the differences among individuals may scciii gicater when it comes to their expectations about cvcnii in ihe world ub opposed to their use of sounds.
 W e cuiiicnd thai ihis im not so.
 The restaurant script of Schank 11975| coiistiiuies a good example of the expectations »{ people from oar culture about the highlevel activiues involved in eating at a restaurant.
 Two ftindamental problems .
û e known to exist with scripts: (1) how do you know when one is relevant; and (2) how do you use information from one script in understanding activities in another? Schank [1979| has begun to address these qiiesiions in his recent work on MOFs, or memory organisation packets In our way of viewing language comprehension, the Yale group has shifted slightly m emphasis, they are increasing the number and nature of the schematic situations they recogni/e and they are focusing a hit more on the coiinecuons among situations.
 I'heir restaurant script is now connected to other schemata representing the general notions of visiting a business establishment, preparing and eating a meal, outofhouse social activities, etc.
 W e agree with this shift, and push it to ib logical conclusion, as enumerated above in our three representalion methods.
 A conceivable pair matrix for several example highlevel activiues of restaurantgoing is shown in ligure 1.
 W e can envision additional pair mauices for each activity found on the righthand side of the one showiithe entire set of connections being quite large.
 During the comprehension process, the activation of one activity unit causes concomiunt model activity in those that follow it.
 further, this pairwise triggering does not stop at the units that are only one connection away, but continues (at a smallervalued potential) for a good distance, activating a large iiumher of iiniUi until the ever decreasing value is no Iniigci signiticaiil.
 Enter Restaurant * Get asked how many ^ Gel sealed Sit down *Go to lounge 'Put name on list Give money to maitre d' Sit Down at Restaurant ̂ G et water glasses tilled ,;vOrder drinks *; He given menus VOrder food "Request wine list Figure 1.
 Aciiviiy Pair Relitiions parlies? Likewise, in hii later cxploraiioii ol ihc world ot painting [1977], how does a bchcma driven moilei understand an event in a story that has nothing to do widi painiiiig? An attempted solution wiihiii the single process approach has been to use some sort ol slack mechaiii.
sin for the schematii, such thai one context gets pushed (to use the computer metaphor) and another takes over.
 Again, the problem arises; which .
schema to activate when ihc previous one is pushed? And when is it popped'! T"he soluuon to this classic problem within the lxploded Connection Scheme involves connections among hierarchical levels of active knowledge units' in the model.
 Research in semantic networks has led to interesung epistemologies and computer representations.
 Ihe work of Fahlman [1979] in particular shows how the different levels of descnpiion might be related to each odier in our own scheme.
 The main difference between his Nl'l'l.
 approach and ECS centers on ihe elimmauon of a central controller in favor of multiple competing processing loci, each with a dynamic activation (confidence) level.
 The pair matrix that shows some of the activities involved in going to a restaurant and the activities likely to follow them in everyday circumstances in our culture (lig.
 1) seems specific to that overall activity, i.
e.
.
 resuiurani going.
 I'he events listed are exploded, in ihe sense that ihey describe "entering a resuuraiii" and "being seated al a restaurant," rather than "walking" and "siiiiim down.
" This explosion lllcall̂.
 ilial ihi ik arc .
i l.
wiic iiiinibcr nl differenl uniis .
ill i< pi.
 > i.
iiiig iln .
.
une knnl ̂ l at iiviiy in different contexts.
 If we leave things as such, there are many problems of schemabased models that will cause trouble in our scheme.
 H ow can we reason that "sitting down in a restaurant" could lead next to a "knee spasm," for example? Whether we represent the knowledge as "the sitting down" action of the "restaurant schema" or as the "sitting down in a restaurant" unit in a connected network, the inference is not possible (unless "knee spasms" are explicitly linked to the "sitting down in a restaurant" unit, an unacceptable soluuon).
 Our solution to this problem is to connect every unit in ihe exploded network with a number of units that represent the same event less specifically.
 The meihoil we use, called the hierarchy principlê  involves represeiiUiig events in an ever more specific hierarchy, from coinplciely contextfree actions, such as ingesting, to very particular ones, such as "eating squid at a Spanish restaurant m Georgetown.
" A small set containing a few intermediate kinds of eating is illustrated in Figure 2.
 While it might seem like there are far too many units in this hierarchy to be plausible as a representation of knowledge for comprehension, ii is important to realize that; (1) most ot ihe possible units do not exist in each individual; (2) the hierarchy is a tangled one; and (3) only the units at the highest levels are fairly fixed in the nature of what they represem.
 INGES'f I HUMANEAT EATASNACK I EAfAPRETZEL H U M A N  D I N E HUMANDINI'.
OUI Hierarchy One kind of inference has always been a (iroblLin lor schemabased models of comprehension h.
iied on sialic chunks of knowledge and a single processing focu.
s.
 In the birthday party scenario of Charniak 119721, ̂ '̂în does the model do if something happens not diuvily related to EATOUTFASTFOOD EAlOU'lIANCY EAlOUTMACDONALDS EATOUTUURGERKING Figure 2.
 Hierarchical Aciivtin':! 171 Connections and Spreadint; Activation Let us refer lo the pairwise connections that are based on the temporal order of processing (e.
g.
, phonemes, evenis) as temporal connections, those based on mundane inference as (mundane) inference connections, and those in the hierarchy as hienirchtcul connections.
 Sometimes it is convenient lo cull tuiincctions of the firsl two liiiids /(i//o>v connections.
 Ihc i.
(>iiil'iii.
aiun dI spreading aclivuiiuii .
ilong these dil'tciciH pail.
w.
ivs piovulcs an answci to llic problem with schemabased comprehension mentioned previously.
 The temporal and inferenual order of events now triggers activation in event iiniis in two dimensions, leading in the horuonial direction lo expectation of specific schematic events, and in the verucal direction to nonschematic events of a lessspecific nature.
 Note that the vertical activation causes activation horî ontiilly among these more general activity uniis.
 The restaurantgoing example can be used lo illustrate the nature of this activation.
 W h e n the "being seated at a restaurant" unit becomes active, a number of event units along the follow connection pathways are also activated.
 These include such things as 'being given a inciin," "asking for a wine list," etc.
, as shown in the pair matrix of I'igure 1.
 That activation in turn causes additional activation at a lower level along the next set of follow connections, and so on, until the ever decreasing aclivauon has become essenually zero.
 Simultaneously, however, activation procecils along the hierarchical connecuons as well, likewise decreasing for each new radius of connection.
 Of course, each event unit in the hierarchy has both hierarchical and temporal connections, and activation from hierarchical paths proceeds out along all connections, regarille.
ss of type, thus creating a new set of event pau cxpcciauons.
 The way that "being seated in a restaurant" <,an naturally lead to the comprehension of a "knee spasm" through a combination of hierarchical and temporal pathways is shown in (iguie 3.
 By the decreasing activation idea, the p<iteniial (activation level) of "knee spasm" should be significantly less than that for things like "look:ng at the menu," but that is perfectly consistent with our thoughb on how context strongly affects percepuon of new inputs.
 follow connections (oneway) MOVINGKNEES >~ > KNEESPRAIN ~'~~—* KNEESPASM CHANGINGLEGPOSITIONS hierarchical connecuons (twoway) SnTINGDOWN lUINGSlAflD t BEINGSKATEDATARESTAUllANT Figure 3.
 Schema Interaction rurlticniuire.
 ni cases when siiiiiiili > niilil he inui|iit d .
1 in •iiuic than (jiic way.
 iliis scliciiic kjUs Hi Iiv|m id.
 ,.
 (experimentally tesuble) about the preferred interpretation.
 The role of perception is also importani in the scheme, since the activation level ot units depends on inputs along all dimensions of connectivity in ihe network.
 The potential of a unit can be changed by direct perceptual sumulauon, stimulation t'rom above or below in the isa hierarchy, from previous events along the lollow pathways, or from other sources yet to be ideniitieil.
 Ihe 172 potential represents in a uniform way the stiniulaiioii provided by a combination of all incoming connecuons.
 The construction of our model involves idciiiifying ihe nature of connections and units (which we are now doing) and the nature of the combinauon rules tor each kind of uniL Summary and Conclusions The research program we are coiiimeiicing the construction of a computer model of hmiiaii language comprehension  represents an interdisciplinary etibrt in cognitive science.
 The plan involves cDiinedinK up a large number of iieiuonlevel coinpiiiing uniis lo pioccss cohesive text.
 I'mpirical constraints on ihe oigani/ation ot the active network consist of processing Lvulcnce from psychology, physiological evidence abuui the brain, and computational plausibility.
 I'hus far, we have made some preliminary studies in parsing and .
schcmaiu reasoning, and have a working network sniuilaKjr thai has been applied successfully to some simple problems in high level constraint relaxation.
 In this paper, several issues regarding the organi/aiujii <il schematic knowledge for language comprehension have been described within the connectionisi Iraiiiework.
 W e have suggested mechanisms for (1) obtaining schematic reasoning from diffuse computing units; (2) merging top down and bottomup control in schematic re;isoiiing; (3) maintaining diffuse loci of control yet coordinating global behaviors; and (4) directly relating psychological evidence to computational models in cognitive science.
 Ihe results presented are certainly in a preliminary state, but are leading to interesting simulations and valuable collaborative work.
 References Ballard, D.
H.
, "Parameter networks: Towards a theory of lowlevel vision," Proc, 7th IJCAl, Vancouver, ll.
C, August 1981.
 Charniak, E.
.
 "Ms.
 Malaprop, a language comprehension program.
" Proc.
, 5th IJCAl, 1977.
 Charniak, E.
, "Toward a model of cliildien's Moiy comprehension," Al M e m o 266 .
\\ I .
ih VIII I'l" Coitrel, G.
.
 "Toward Connectionist Parsing", Technical Report, Deparunent of Computer Science, University of Rochester.
 1982 (to appear).
 Dell, G.
S.
, "Phonological and Lexical Encoding in Speech Production", Ph.
D.
 dissertation.
 Department of Psychology, University of loronto, 1980.
 Fahlman, S.
E.
 N E T L , A System for Representing and Using Real Knowledge.
 Boston.
 M A ; M I T Press, 1979.
 Fahlman, S.
E.
, D.
S.
 Touretzky, and W.
 van knggen, "Cancellation in a parallel semanuc network," TR, Computer Science Dept.
.
 CarnegieMellon U.
.
 1981.
 Feldman, J.
A.
, "Badmouthing frames.
" Proc.
, l'lNlj\P.
 1976.
 Feldman.
 lA.
 and D.
H.
 Ballard.
 "Connectionist models and their properties.
" to appear in Cognitive Science 6, 1982.
 Hinton.
 G.
E.
, Review of S.
E.
 1 ahlman, /V/:77.
 A Svuem for Representing and Using RctilH'orU Knunlcdgc AJSli Quarterly, 4243, Winter/Spring 14Sl/«2 Lowerre.
 B.
T.
.
 "The Harpy Speech Reco^jniiion Sysiem", Ph.
D.
 dissertation.
 Departineiii ot ( onipiiier Science, CarnegieMellon University, 1976.
 Marcus, M.
P.
, "An Overview of a I'hcoiy ol Synlaciii.
 Recogiiilion for Natural Language.
 Al M e m o 5Jl, M I T Aniilcial Inieligence Ulxjruiuiy, \')T).
 Marr, D.
, "Represeniing visual uitoiiiiaiiou," in A.
K.
 Hanson and li.
M.
 Riseman (Ixh).
 (umimitr y'luon Systems.
 N Y : Academic Press, I97«.
 McClelland, J.
L.
 and D.
L Kumdhari.
 "An niicKiciivc aclivalion model of the elTect ol Loniext in pcaepiioM: Part 1," Report 8UU2, Center lor Human Intuiinauon Processing, U.
 California, San Dicgo, May 1980, Minsky, M.
, "A framework for represeiuing knowledge," in Winston (Ed).
 The Psychology oj Computer Piston.
 McGrawHill.
 1974.
 Minsky, M.
, "KLines: A theory of memory," Cognitive Science 4, 2.
 117133, 1980.
 Norman, DA.
, "A psychologist views human procciisiiig: H u m a n errors and other phenomena suggest processing mechanisms," Proc, 7th IJCAl, 1097 1101, Vancouver, U.
C.
, August 1981.
 Quillian, M.
R.
.
 "Semantic memory," in Minsky (lid).
 Semantic Information Processing.
 Uoston, M A : M I T Press, 1968.
 Kieger, C.
J.
, "Ihe Importance of Multiple Choice", ProceeJiiiii' TINI.
4P2, Urbana, Illinois.
 1978.
 Rosenfc'Id.
 A.
 U \ llniiiiiicl and S.
W /udicr "Siunc labelling by relaxation operauons," IK!:!: Trans.
 S M C 6, 1976.
 Samuel, A.
G.
, J.
P.
H.
 van Santen, and J.
C.
 Johnston, "Length effects in word perception; W e is belter than I but worse than you or them," J Experimental Psychology: Human Perception and Performance 8.
 1, 91105, 1982.
 Schank, R.
C.
, "Conceptual dependency: A theoiy of natural language understanding," Cognitive Psychology 3, 4, 1972.
 Schank, R.
C.
, N.
 Goldman, C.
 Rieger, and C.
 Riesbeck, "MARGlli: Memory, analysis, response, generation, and inference on English," Proc.
, Jrd IJCAl, 1973.
 Schank, R.
C.
, and RJ'.
 Abelson, "Scripts, plans, and knowledge.
" Proc.
, 4th IJCAI.
 1975.
 Schank.
 Roger C .
 "Reminding and memory organization: A n introduction to MOPs," Research Report 170, Dept.
 of Computer Science.
 Yale U.
.
 1979.
 Seidenberg.
 M.
S.
, M.
K.
 Tanenhaus, and J.
M.
 Leiman, "The Time Course of Lexical Ambiguity Resolution in Context", Technical Report #164, Center for ihe Study of Reading, University of Illinois, 1980.
 Small.
 S.
L.
, "Word Expert Parsing: A Iheoiy of Distributed WordHased Natural language Understanding," Ph.
D.
 disseriation .
iiul IK 954, DeparuTieni of Computer Science, U.
 Maryland, 1980.
 Swmney, D,A.
, "Lexical access during scnicacc comprehension: (Re)LX)nsidera(ion ol context effects," J Verbal Learning and Verbal Ucluivior 18, 645659, 1979.
 I'anenhaus, M.
K.
 and J.
M.
 Leiman, "Lvidencc for multiple stages in die procesing of ambiguous words in syntactic contexts," J Verbal Lctiming and Verbal Beliavior 18, 427440, 1979.
 Wilks.
 Y.
, "Preference ssemanucs," Al M e m o 2(J6, Al I jb, Stanford U, 1973.
 Wilks, Y.
, "Some dioughls on procedural seniaiitics," Cognitive Studies Centre Report 1, U.
 !.
bscx, 1980.
 173 The Context Model: Language Understanding in Context* YigaiArvns Division of Computer Science Department of EECS University of California at Berkeley Berkeley.
 CA 94720 1.
 Introdactiaa This paper describes the language understanding component of the Unix Consultant (UC) system being developed at the Berkeley Artificial Intelligence Research project.
 Hie purpose of UC is to hold a conversation with a naive user of the Unix operating system while he or she is working on the computer, answering questions and solving problems for the user.
 Vcm system has several other components, including the common sense planner PANDORA (Faletti.
 1982).
 and the plan understander PAMELA (Norvig.
 1982).
 Our natural language understanding system contains as a subpart the PHRAN phrasal analysis program nruensky and Arens.
 1980a) (WUensky and Arens.
 1980b) Arens.
 1981).
 PHRAN's knowledge base consists of PattemCoQcept Pairs  pairings of language structures with a conceptual representation of their meaning.
 It operates by matching the pattern parts of the pairs against the input and using the corresponding concept to describe its meaning.
 The current system attempts to deal with the fact that PHRAN by itself unable to deal with reference, and cannot disambiguate unless the linguistic patterns used require a particular semantic interpretation of the words.
 In addition, we wish to account for the fact that the same utterance may be interpreted diflerently in different contexts.
 These inabilities on the part of PHRAN originate in the fact that PHRAN's knowledge is almost entirely of the language, as opposed to knowledge about the entire conversation, more general world Imowledge.
 etc.
 Of course, in order to specify the patterns.
 PHRAN needs at least some information about the semantics of the words appearing in the sentences it analyzes, but this is limited to the semantic categories the objects described by the language belong to (e.
g.
 Persoa Vehicle) and a Conceptual Dependency representation (Schank.
 1975) of the actions.
 In order to bold a meaningful and useful conversation, however, it is clear that such a system must go beyond the (almost) purely linguistic analysis of the sentence to include the effect and the interaction this iuialysis has on our model of the conversation and on our knowledge as a whole.
 The system we are currently constructing has a single mechanism which addresses many of these problems.
 which we call the Context UodeL The Context Model contains a record of knowledge relevant to the interpretation of the discourse, with associated levels of activation.
 There are rules governing how elements introduced into the Context Model are to influence it and the system's behavior.
 PHRAN and the Context Model interact continually.
 PHRAN passes its limited interpretation of the input to the Context Model, and it in turn determines the focus of the conversation and uses it to resolve the meaning of ambiguous terms, of references, etc.
.
 and passes these back to PHRAN.
 Although it too Involves the use of spreading activation and associations among semantic structures for the purpose of understanding text, the Context Model differs substantially in scope from Quillian's work in TLC as described in (Quillian.
 1969).
 TLC was concerned mainly with the determination of the conceptual representation of the input sentence, a task which is handled here mostly by the phrasal analyzer.
 The Context Model groups related entries in it and arrives at a notion of the "TUm research m a spcnsered is part by the Office of H«*b1 Reaeareh under contract N00014aoC073Z and the National Science Fonroiation under grant UCS79oeS4a 174 situation being discussed.
 Alternative situations in which a concept may appear can be ignored, thus enabling the system to have a more directed spreading of activation.
 (Crosz, 1980) develops in great detail a scheme for determining focus of a task oriented dialog and using it to resolve references.
 Grosz's system relies heavily on the inherent temporal structuring of the task  whereas we are trying to develop a more general approach, independent of the type of subject matter discussed.
 Our system must have the ability to shift focus freely according to the user's input, including the ability to store and recall previous contexts into focus.
 The resulting system is able to converse and answer questions, while allowing the user to move in a relatively free manner from one topic to another, as the next example illustrates.
 1.
1.
 Enmple The exchange described below takes place with the UNDC Consultant (UC) system being constructed at Berkeley.
 The purpose of the system is to answer the questions of naive users of the UNDC operating system wtiile they are using the computer.
 See (WUensky, 1982).
 [1] User How do I print the file fetcb.
1 on the line printer? [2] UC: To print the file fetch.
1 on the line printer type 'Ipr fetch.
r.
 (intervening commands and questions) ;3 Usen Has the flle fetch.
1 been printed yet? 4 U C Ihe flle fetch.
1 is in the line printer queue.
 |5 User: How can I cancel it? '8 UC: To remove the file fetch.
1 trom the line printer queue you must type 'Iprm arens'.
 In this example the user first asks a question [l] and receives a reply from the system, llien come several other questions and answers, and then the second part of the example.
 Hie user asks another relatiwly straightforward question and then a more problematic one.
 In order to reply to the last question the system must find the referent of 'it'.
 The language used implies that this must be a command, but the command in question was issued lone ago.
 The system is able to determine the meaning of [5] only because the context of [1] and [2] had been stored and so could be recalled upon the seeing of [3].
 This example will be discussed in more detail in section 3.
 2.
 The CoatAzt Model and Its Hanipulatioa The Context Model is in a constant state of flux.
 Entries representing the state of the conversation and the system's ielated knowledge and 'Intentions' are continually being added, deleted, or are having their activation levels modified.
 As a result the same utterance may be interpreted in a different manner at different times.
 Following are short descriptions of the different elements of the system.
 2.
1.
 Entries The Context Model consists of a collection of entries with associated levels of activation.
 These entries represent the system's interpretation of the ongoing conversation and its knowledge of related information.
 The activation level is an indication of the prominence of the information m the current conversational context, so that when interested in an entry of a certain type the system will prefer a more highly activated one among all those that are appropriate.
 There are various types of entries, and these are grouped into three general categories: 1) ABaertioQS  statements of facts known to the system.
 2) Objects  objects or events which the system has encountered euid that may be referred to in the future.
 3) InUntlooaa) Entries representing information the system intends to transmit to the user (i.
e.
 output) or other components of an understanding system (e.
g.
 goal tracker, planner).
 b) Entries representing information the system intends to determine from its knowledge base.
 2.
2.
 QiuUn The entries in the Context Model are grouped into eluaters representing situations, or associated pieces of knowledge.
 If any one member of a cluster is reenforced it will cause the rest of the members of the cluster to be reenforced too.
 In this manner inputs concerning a certain situation will continue reenforcing the same cluster of entries — those corresponding to that particular situation.
 Thus the system arrives at a notion of the topic of the conversation which it uses to help it choose the appropriate interpretation of further inputs.
 2.
3.
 Reenforcemeot When the parse of a new input is received from PHRAN the system inserts an appropriate entry into the Context Model If there already exists an entry matching the one the system is adding then the activation levels of all entries in its cluster(s) are increased.
 Tbe level of activation decays over time without reenforcement, and urtien it falls below a given threshold the item is removed.
 2.
4.
 Stored Quatan Upon inserting a new item in the Context Model the system retrieves from a database of clusters all those that are indexed by the new item.
 Unification is done during retrieval and the entries in the additional clusters are also inserted into the Model, following the same procedure described here except that they aire given a lesser activation.
 We thus both avoid loops and accommodate the intuition that the more intermediate steps are needed to associate one piece of knowledge with another the less the mention of one will remind the system of the other.
 The system begins operation with a given indexed database of clusters, but clusters representing various stages of the conversation are continually added to it.
 In principle, this should be performed automatically when the system is cued by the conversation as to the shifting of topic, but currently the system user must instruct it do so.
 Upon receiving such an instruction, then, all but the least activated entries in the Context Model are stored as a cluster indexed by the most highly activated among them.
 This enables the sjrstem to 'recall' a situation later when presented with a related input 2.
S.
 Operations on Entries in the Context Model After a new entry is made in the Context Model the process described above takes place and eventually the activation levels stabilize, with some of the items being deleted, perhaps.
 Then the system looks over each of the remaining entries and.
 if it is activated highly enough, performs the operation appropriate for its type.
 The allowed operations consist of the following: 1) Deleting an entry.
 2) Adding another entry.
 3) Transmitting a message to another component of the system (i.
e.
 output to tne user or data to another program, e.
g.
 PANDORA (Faletti.
 1982), for more processing) 4) As part of the UC system, getting information from the UNIX system directly (and inserting an entry corresponding to the result).
 3.
 DetaUs of the Example In [l] the user asks a simple question.
 PHRAN analyzes the question and sends the Context Model a stream of entries to be Inserted.
 Among them are the fact that 'fetch.
r is the name of a file, and that the user asked what is the plan for printing it on the line printer.
 The system records these facts in the Context Model.
 Indexed under the entry representing the user's desire to obtain a goal there is a cluster containing entries representing the system's intent to find a plan for the goal the user has and instructing the system to tell the user of this plan.
 This cluster is instzintiated here with the goal being the particular goal expressed in the question.
 The entry expressing the system's need for a plan for the user's goal leads to the plan in question being introduced also.
 This happens because the system happens to already have this association stored.
 When the system looks over the entries in the Context Model and comes to the one concerning the need to find the plan in question it will check to see if an entry for such a plan already exists, and in our case it does.
 But if no plan were found, the system would insert a new entry into the Context representing its intent to pass the information about the user's request to the planner PANDORA (Faletti.
 1982).
 PANDORA wiU in turn return the plan to be inserted in the Context ModeL So the system finds the plan (issuing the command above) and inserts a new entry instructing the system to output it to the user.
 And eventually that is done hence [2].
 The topic shifts and the previous context is stored (with the operator's aid, as mentioned above), indexed by the most highly activated entries, including the file name, the mention of the line printer, the event of printing the file, ani the conunand issued.
 In [3] and [4] we have an exchange similar to the previous one except that the system actually has to consult the operating system in order to find the answer to the question.
 There is one major addition however — as a result of the existence of the new cluster described above, the system has all this extra information triggered and loaded into the Context Model.
 And this is wtiat makes it possible for the system to determine the referent of 'it' in [5].
 Severed other commands were mentioned and executed more recently, but in the new cluster just loaded many entries match already existing ones causing all — including the command intended for cancellation — to be more h^hly activated.
 4w abartcamings The system is not currently able to determine on its own that the topic has changed and that it must store the current context.
 In addition to linguistic cues, we should be able to use the Context Model too in order to help in such a determination, but this work has not been done yet When it is instructed to, the current system stores essentially a copy of the more highly activated elements of the Context Model when creating a new cluster.
 They are not assumed to have any particular structure or relations among them other than all being highly activated at the same time.
 This causes two problems: 1) As a result it is very difficult to generalize over such clusters (cf.
 Lebowitz, 1980).
 The system may at some point determine a plan for changing the ownership of a particular file, and store a cluster containing it If it is faced with the need to chemge the ownership of another file, however, the system will not be able to use this information.
 In the example above this problem was not encountered because the clusters used were preprogrammed to include variables in place of particular &es.
 2) There is no way to compare two clusters and determine that in fact they are similar.
 Thus we may have many clusters indexed by a certain entry all of which actually describe essentially the same situation.
 Another element missing from the system is a model of the user.
 Certain assumptions are made as to the knowledge the user has of the Unix operating system, but these are built in and cannot be modified according to past interactions.
 Constructing such a 175 model will probably require work beyond the scope of this project.
 S.
 RBferencas Arena, Y.
 (1961).
 Using Language and Context in the Analysis of Text.
 In Pncaadings of the Seventh, IntemaHonai Joint Omference on Artificiai InteUigence.
 Vancouver, B.
C.
 FaletU, J.
 (1982).
 PANDORA  A Program for Doing Commonsense Planning in Complex Situations.
 Submitted to 77m Second /trmuoZ NatioTtai Conference an Artificiai InteUigence, Pittsburgh.
 Grosz.
 B.
, J.
 (1980).
 Focusing and Description in Natural Language Dialogues.
 In Elements of Discovrse Understanding: Prac.
 of a Workshop on ComputatioTuiL Aspects of Linguistu: Stmcture and /Xscourst Setting.
 A.
 K.
 Joshi, I.
 A.
 Sag.
 and B.
 L Webber, eds.
 Cambridge University Press.
 Lebowitz, M.
 (1980).
 Generalization and Memory in an Integrated Understanding System.
 Tech.
 Report 186, Yale University Department of Computer Science.
 Ph.
D.
 Thesis.
 Norvig, P.
 (1982).
 Integrating FrameBased and GoalBased Processing in a Story Understanding Program.
 Submitted to The Second Annual National Conference on Artificial fntelligence.
 Pittsburgh.
 QuilUaa M.
, R (1969).
 The Teachable Language Comprehender A Simulation Program and a Theory of Language.
 In Cbrranunicaiions of the ACM, v.
 12, no.
8.
 Schank.
 R.
 C.
 (1975).
 Conceptual Information Processing.
 American Elsevier Publishing Company, Inc.
.
 New York.
 WUensky.
 R (1982).
 Talking to UNIX in English: An Overview of UC.
 Submitted to 77ia Second Annujal National Conference an Artificial InteUigence, Pittsburgh.
 WUensky.
 R, and Arens, Y.
 (1980).
 PHRAN  a KnowledgeBased Natural Language Understander.
 In Proceedings of the 18th Mnual Meeting of the Association far Computational Linguistics, Philadelphia.
 WUensky, R.
 and Arens.
 Y.
 (1960).
 PHRAN  a Knowledge Based Approach to Natural Language Analjrsia.
 University of Califomia at Berkeley.
 Electronic Research Laboratory Memorandum No.
 UCB/ERL U80/34.
 WUensky.
 R.
 and Morgaa M.
 (1981).
 One Analyzer for Tliree Languages.
 University of California at Berkeley.
 Electronic Research Laboratory Memorandum No.
 UCB/ERL M81/67.
 176 •Tiyigiiign<al inference: A Theory of Inferential DecisionMaking During Understanding Richard H.
 Granger Artificial Intelligence Project Confxiter Science Department University of California Irvine, California 92717 ABSISACT In the course of understanding a text, a succession of decision points arise at which readers are faced with the task of choosing among alternative possible interpretations of what they're reading.
 Careful analysis of a wide range of sample texts reveals that such decisions are often based on ccoplex evaluations of the interpretation being constructed, and sometimes cause the reader to construct and discard a number of intermediate inferences before settling on a final interpretation for a text.
 Itiis paper describes Judgmentcd.
 Inference theory as a proposed scheme of evaluation metrics and mechanisms, derived from examination of inference decisions arising during text understanding.
 A series of programs, ARTHUR, HAOMOUUR and JUDGE are briefly described, which incorporate some of the metrics and mechanians of Judgmental Inference, enabling then to inderstand texts more conplex than those that can be handled by other understanding systems.
 1.
0 Introduction Many national newspapers carried frontpage versions of the following story early this year: [1] A Nicaraguan soldier, who last year made a public statement alleging Cuban, Ethiopian and Nicaraguan military aid to Salva^cian leftist guerrillas, today publicly retracted his story at a State Department news conference.
 Why did the Nicaraguan soldier make the statenents he made, a year ago and now? Why did the State Departjnent hold these two news conferences? It is possible that the State Department had seme reason for holding the news conference, in«pnHfno the Nicaraguan soldier to recant; but most readers assume that the State Department had different intentions that were not fulfilled, for reasons out of their control.
 Indeed, most readers don't even consciously think of the former interpretation, even though it is a logical possible alternative explanation of the events.
 Our analysis of examples like this has led to the identification of decision points at which human under St anders are faced with the task of choosing particular inferential paths from among an curray of possible alternatives.
 These inference decisions are based on ccnplex evaluatrinn metrics for judging the appropriateness of a particular inference, and on mechanisms for constmgfir^ and revising interpretations during understanding.
 Judgmental Inference theory (Granger [1982]) consists of a set of evaluation metrics and mechanisms derived from examination of inference decisions arising during text understanding.
 This paper describes how some of these judgmental metrics and mechanisms are applied during understanding.
 Hie view this work as ccnciatlble with and coorplementary to research that focuses primarily on representational issues in text understanding, such as Schank and Abelson [1977], Wilensky [1980], Cbamiak [1980].
 By examining the occurrences of inference decisions dbring understanding, we intend to provide a look at the me^aoiaiB.
 by which such representations are chosen, constructed, judged, confirmed and/or discarded during the processing of a text.
 2.
0 Illustration of understanders' decisions 2.
1 Evaluating and supplanting inferences Consider the following example: [2] Katfay and Chris were playing golf.
 Kattay hit a shot into the rough.
 She wanted to let her good friend Chris win the game.
 Host readers assmte that the reason Katfay hit her shot into the rough was to increase her opponent's chances of winning, out of friendship.
 Bowever, consider the following: [3] Ken and Carl were playing shot into the rough.
 golf.
 K « hit a 1)113 research was supported in part by Ocean Systems Center under contract Na012381C1078.
 the Naval Prom reading just this twosentence version, people infer that K M and Carl both were playing to win, and that KM's bad shot therefore was acddentad, and will hinder his goal of winning the game.
 However, after readers have read the third sentence that appears in version [2], they appear to have changed this initlca interpretation a great deal.
 It is not just that Kati^ doesn't want to win the game, but also that she probably made her bad shot en purpose, not accidentally.
 Virtually all readers currive at this interpretation by the end of this example, by mippianHna some of their initial inferences with new ones (see Granger [1980]).
 2.
2 Broluation metrics of cohesion and parsimony Why do people arrive at this different interpretation about Katfay'3 action in tfals example? The answer is far from obvious.
 In particular, there is no question of logical consistency here; the interpretation that Katfay hoped to lose the game but that her bad shot was nonetheless accidental is just as logically consistent as the one that people actually infer, namely that her bad shot was intentional, not accidental.
 It turns out that the scope of this phenomenon is very wide: people often arrive at interpretations that appear to involve the supplanting of initial inferences, even when that extra work is not necessary on grounds of logical consistency.
 177 (A large nunber of additional text examples of this pbencmenon are given in Granger [1980] and [1982].
) Ibe decision to reject an initial inference, then, mist depend on an evaluation of the representation based on seme metric other than logical consistency.
 Ckie such evaluation metric that was (iiqplicitly) incorporated into previous theories of inference generation (e.
g.
 Rumelhart [1981], Crotbers [1978], BoMer, Blade and Turner [1979], Schank [1973]) we henre termed the 'cobeaJOI metric*.
 The cobeaion metric requires that every statement in a text be connected to at least one other, resulting in all the pieces of tbe text representation being tied together via either referential, causal or intentional connective inferences.
 Cohesion by itself is not sufficient to evaluate tbe goodness of a text representation, boirever.
 Another evaluation metric, identified in our previous vrorlc (Granger [1980]), measures the narrrimmy of a representation, with respect to the goals that motivate the events in tbe text.
 For instance, consider the following exan^le: [4] Doug went to a gas station.
 got away with $50.
 Be robbed it and (a) Doug went to the gas station intending to get gas, and then he changed his mind and decided to rob tbe station instead; (b) Doug went to the gas station intending to rob it.
 Just as in the 'golf' exanple [3], this exaople can be interpreted in two different ways, both of which are not only logically consistent, but also referentially and causally cohesive, since Doug had to get to tbe gas station before he could rob it, regardless of his intentions in performing those actions.
 Iterefore, tbe cohesion metric does not differentiate between these two alternative interpretations, but people do: tbey universally seen to generate interpretation (b), which consists of a single goal (getting money froa tbe gas station), and in fact they rarely even consciously notice tbe possibility of (a), which consists of two separate goals each explaining one of Doug's actions.
 The evaluation metric of parsimony essentially tests that an interpretation be maximally parsimonious with respect to the nunber of goals used to explain the events in the story; i.
e.
, the fewer separate motives inf^red to account for the story events, tbe better.
 (Note: an evaluation of an unparsimonious interpretation will not always result in the decision to supplant inferences; sometimes readers leave 'loose ends* in their interpretation, to be resolved later.
 See Granger [1982] for a discussion of loose ends.
) 2.
3 Shaping interpretations of behavior We have identified some further evaluations that understanders perform, beyond cohesion and parsimony, which arise when a reader is led to 'doubt' any part of his interpretation of a text.
 Such doubts can be instilled either by information presented in the text, or by 'extratextual' factors (see Granger [1981]) which may steer the reader away from an otherwise plausible interpretation.
 Qeanples of such 'doubtfactors' include the reader's knowledge of the reliability of the 178 text source (e.
g.
, the difference between the New Zork Times and the National Ehquirer); knowledge of an actor's deviousness (e.
g.
, a car aalcwnan vs.
 a priest); relative boredom or interest, i.
e.
, the reader's desire to pursue possible alternative interpretations vs.
 just settling on a default interpretation that's 'good enough'.
 An easy way to induce a doubt factor in a reader is to siiply teit him that his initied interpretation is incorrect; i.
e.
, explicitly ask for a new and different interpretation of a text.
 It turns out that readers are very capable of producing a series of such alternative interpretations of texts when they're continually told their initial interpretation is incorrect.
 For instance, following is a story adnptfid from a newspaper text, along with a series of interpretations informally elicited from a subject: [5] Tbe Pakistani ambassador to tbe United States made an unscheduled stop in Albania en his way home to what an aide of the ambassador described as *a working vacation*.
 (31) Why did the ambassador go to Albania? Al) It looks like he was on vacation — he went to Albania first and then to home, I guess in Pakistan.
 QZ) No, that's not the real reason.
 Why did he go to Albania? A2) Wbll, maybe there was sane anergency reason it said it was unscheduled, so maybe it was that something went wrong and they had to stop there, and then they went on.
 (13) Still not it, but try again; why did he go to Albania? A3) Ok, maybe, well he's an ambassador, so he could have been supposed to go to Albania .
.
.
 so it could have been a meeting, like 'shuttle diplomacy* .
.
.
 but it was supposed to be a secret, so that's wtay they said it was unscheduled.
 These different interpretations of [5] are each based on different interpretations of the actor's reasons for doing what be did.
 It is natural that different behavior interpretations should give rise to different text interpretations; most current theories of text representation focus primarily on representation of the events described in the text, rather than on a more 'syntactic' analysis of the structure of the text itself.
 Our analysis of this and similar examples has revealed a large class of inference evaluations people perform based on their attempts to decide vrtiat kind of behavior an actor has performed, for instance: 1.
 'sisfile* goal pursuit, e.
g.
, 'John was hungry, so he ate a hamburger'; 2.
 'complex* goal pursuit, (i.
e.
, goal interactions; see Wilensky [1979]) — e.
g.
, 'John wanted to see the football game but he also had a paper due the next day' (goal conflict); 3.
 deceptive or intentionally misleading behavior, e.
g.
, 'Clark wanted Lois to think he was drunk, so he smiled and fell off the barstool onto the ground*; 4.
 accidental (nongoaldirected) behavior, e.
g.
, 'Jack smiled and fell off the barstool onto the ground'd); 5.
 ispccBftu reactions to unplanned£or CGntingencies, e.
g.
, "Bill thrw himaelf undec the jeep when he saw the man pull a gun*.
 Our classification scheme foe dividing up the gamut of possible interpretations of behavior (e.
g.
, intentional vs.
 unintentional at the top level, subdividing intentional behaviors into sintple, dec^Jtive, preplanned, iii|)ranptu, etc.
, and unintentional behavior into various types of failures such as skill failure, infonnation failure, etc.
) is described in detail in Granger [1982].
 Vfe call each of these subdivisions an interpretation'shape", since categorizing an actor's behavior into one of these classes will result in a particular shape of the representation graph constructed, and because reinterpreting an actor's behavior results in reshaping the representation.
 Vfe have inplemented two ccnputer programs, ARIHUR and MACARIHUR, which incorporate the evaluation metrics of cohesion, parsimony, and shapes to produce interpretations of texts that cannot be handled by other textunderstanding systems.
 Granger [1982] gives saisple output of the operation of these programs on some of the text examples discussed above.
 3.
0 Additional categories of inference decisions 3.
1 "Suspicious" understanding It is often iiqpossible for an understander to identify the "correct" interpretation shape for an actor's behavior.
 For instance, consider the folIcMing version of a story that was on the front page of a number of national newspapers earlier this year: [6] A report by the New York State Racing and wagering Board released today states wnequivocally that leading jockeys conspired to "fix" at least 13 races in the mld1970's, and that the jockeys have been "patently wbelievable" in denying their involvement in the scheme.
 Qiderstanding [6] requires the recognition that the observed behavior of jockeys can be very difficult to classify as either "accidental" or "deceptive".
 Hence, a jockey (or a jaialai player, boxer, etc.
) may lose a ccnpetition without an observer's being able to tell whether he did it intentionally or accidentally.
 niese are special cases of the general problem of detecting deceptive behavior by using knowledge of 'eovBT stories".
 Some recent work in AI (e.
g.
, Bruce and Newman [1978]) has pointed out that a method of maintaining separate "belief spaces" for different actors is crucial for understanding deception.
 However, understanding deception can also require a great deal more than this; in particular, a more subtle deceiver will typically try to cause observers to infer for themselves some false interpretation of his actions, thereby covering up the real reasons.
 Political propaganda, advertisements for products, and facesaving "white lies" are all examples of this kind of deception.
 The ability to understand (and generate) conplex deceptive behavior such as this depends not only on separate belief spaces, but also on the ability to construct plausible alternative explanations for events.
 "Vhe more plausible the alternative explanation, the more likely the deception is to succeed in misleading understanders.
 A "suspicious' understander is one who can (at least) construct alternative interpretations of events, and then can atten^t to decide among them, typically by gathering additional infonnation.
 Such informationgathering is based on finding a possible motive, i.
e.
, finding a plausible explanation that the "obvious" explanation is intended to cover.
 The JUDGE program, currently under construction, is being designed to make use of knowledge of the shapes of alternative interpretations to detect plausible cover stories in the domain of criminal investigation.
 For more descriptions of cover stories and JQIXS, see Granger [1982], and Granger and Biselt [1982].
 3.
2 Chderstanding accidents Ve have also investigated the types of arrtHanfai behavior that can be described in texts, and the relations between accidental and goaldirected behavior.
 For example reczill Ren, who accidentally hit his golf shot into the rough.
 Although his action of of striking the ball was intentionid, the causal nn«fmw.
 of the ball ending up in the rough was unintended.
 Vfe have classified Ken's problem as a "sliili fatlnre".
 i.
e.
, an intentionallyperformed physical action which results in a nonintended outcome as a result of some physical lack.
 There are a number of other types of intentionaccident pairs like this, such as •information failure", "tooshallow planning", etc.
 For a further discussion of accidents and how to understand them, see Granger [1982], and Neehan [1981].
 4.
0 Conclusions and future research directions 4.
1 Nhat vm're proposing \ie have observed that people's understanding behavior is marked by an ongoing process of making inference decisions.
 Among the decisions understanders implicitly make cure: 1.
 Is the interpretation referentiaOly and causally cohesive? 2.
 Is the interpretation pwrsimnnioua with respect to the actors' intentions? 3.
 Is there reason to doubt or be suspicious of the shape of the initial interpretation? 4.
 Is there reason enough to revise the interpretation (supplant, reahape, etc) or should it be left with "loose ends"? The evaluation metrics and the construction and revision processes of Judgmental Inference theory are derived directly from our observations and aneUyses of some of the classes of inference decisions that readers are faced with during the task of text understanding.
 We view these theories as compatible with and complementary to theories of text representations, since we intend to describe the mechaniau by which such representations are chosen, constructed, judged, confirmed and/or discarded in the process of understanding.
 Our theories have so far beoi incorporated into two working confxiter programs, ASnanR and MACABTHOR, and are currently being used as the design iĵ jetus for a new computer systan called JUDGE, and for a series of psychological and neurophysiological experiments, briefly described belcw, to test the correspondence of our theories to people's actual understanding behavior.
 4.
2 Hinds, brains and processes 179 A nutDbec of researchers In the neurosciences (e.
g.
, Arbib [1979], Geschwind [1980]) have pointed out that brzdn research might help guide parts o£ cognitive science and AI research, and vice versa.
 One particular issue that has been pointed out frequently is that 'there is no evidence for the existence of any allpurpose ccniputer [in the brain].
 Instead, there seems to be a multiplicity of systems for highly special tasks.
' (Geschwind [1980], p.
191).
 Our research on inference decisions has indeed led us away frem viewing human understanding behavior as arising frcn a 'general purpose cooiuter'; we have ended up instead deriving a number of specialpurpose mechanisms, e.
g.
, inference pursuit, evaluation, supplanting, reshaping, which ccnf>rise our 'judgmental inference' model of mderstanding.
 Vis are currently designing a number of psychological and neurological experiments on inference decisions, based on the predictions of our model (see Granger [1982]); as well as attaif>ting to reinterpret sane existing results (e.
g.
, Runelhart [1981], Crothers [1978], Hillyard and Kutas [1980], Blade [1981]), in Ught of the model.
 For instance, we are investigating the issue of when people evaluate their interpretations consciously vs mconaciously; our model currently falls to account for such individual differences.
 He hope to use the data from such experiments to find problems with our theories, and to refine the model, th^eby worlcing eventually towiirds some anall amount of "neurological validity' in our process models of cognition.
 5.
0 References Arbib, H.
A.
 and Caplan, D.
 Neurolinguistics must be computational.
 BetHYloral an^ Biala scienca, 2:449483, 1979.
 Blade, John.
 The effects of reading purpose on memory for text.
 Cognitive Science Technical Report 7, Zale Otiiversity, 1980.
 Bower, Gordon H.
, Join B.
 Blade, and T.
 J.
 Turner.
 Scripts in text coi^ebension and memory.
 rpjnltlvB PaVdlUlWY 11:177220, 1979.
 Bruce, Bertram and Denis Newman.
 Interacting plans.
 Cospltrive Science 2:195233.
 1978.
 Cbcimlak, Eugene.
 Cn the ose of framed knowledge in language coifsr^iensicn.
 Yale Ccn^xiter Science Research Report 137, 1978.
 Crothers, Edward j.
 Inference and Coherence.
 Disconrse ^nt^mom.
 1:5171, 1978.
 edings international Joint Conference on Artificial Intelligence (UCAI), Vlancouver, British Columbia, 1981.
 Granger, R.
B.
 Judgmental Inference: Inferential DecisionMaking During Ohderstanding.
 Ccnfuter Science Technical Report 182, Uiiversity of California, Irvine, 1982.
 Granger, R.
H.
 and R.
 Eiselt.
 'Suspicious' Olderstanding: Detecting Possible Deception by Inferring Alternative Explanations.
 Ccn^ter Science Technical Report 185, Oliverslty of California, Irvine, 1982.
 RUtas, N.
 and S.
A.
 Hillyard.
 Reading Senseless Sentences: Brain Potentials Reflect Semantic Incongruity, science.
 207:2035, 11 Jan 1980.
 Lebcwitz, N.
 Generalization and Memory in an Integrated onderstandlng System.
 Ccnfuter Scinece Research Report 186, Yale Oniversity, 1981.
 McDermott, D.
V.
 and Jon Doyle.
 Nonmtxiotonic logic I.
 ftrtlfidal TntPlUgmcft I3(i,2);4172, 1980.
 Median, J.
R.
 Boy meets goal, boy loses goal, boy gets goal: the nature of feedback between goalbased simulation and understanding systems.
 Computer Science Tedmlcal Report 170, Oiiversity of California, Irvine, 1981.
 RuDBlhart, D.
E.
 Dhderstandlng understanding.
 Tedmlcal Report 100, Center for Hunan Information Processing, Oiiversity of California, San Diego, January 1981.
 Schsnk, R.
C.
 ranminig gn^ ^aaooioa.
' Technical Report 1, Istltuto per gll studi Semantlcl e Cognitivi, Castagnola, Switzerland, 1973.
 Schank, R.
C.
 and Robert P.
 Abelscn.
 scripts.
 Plans.
 fValg and rtrvtorwianriintri Lawrence ErlbauD, Hillsdale, New Jersey, 1977.
 Scbulenburg, D.
 Interpcetiitg Intentional and Oiintenticnal Behavior.
 Technical Report, Oiiversity of California, Irvine, 1982.
 Wilensky, R.
 Oiderstanding GoalBased Stories.
 Research Report 140, Yale Conputer Science Department, 1978.
 Garland Press, New York, 1980.
 DeJong, G.
F.
 Sklinnlng Stories in Real Time: An Experiment in Integrated Understanding.
 Yale Computer Science Research Report 158, 1979.
 Doyle, J.
 A truth maintenance systan.
 ttlHiSia^ lD£smaBS£l2(3), 1979.
 Geschwind, N.
 Neurological Knowledge and Conc)lex B^iaviors.
 Cognitive Science.
 4:185193, 1980.
 Granger, R.
B.
 When expectation falls: Towards a selfcorrecting inference system.
 In Proceedings of the First National Conference on Artificial Intelligence, Stanford Oniversity, 1980.
 Granger, R.
H.
 Directing and redirecting inference pursuit: Extratextual influences on text inter180 STROCTDRKMAPPING: A THEORETICAL FRAMEWORK FOR ANALOGY AND SIMILARITY Dedre Centner Bolt Beranek and Newman Inc.
 50 Moulton Street Cambridge, Massachusetts 02238 This paper describes a theoretical framework in which analogies and other comparisons ar4 defined in terms of structuremappings between domains (Centner, 1979, 1980).
 Different kinds of mappings correspond to analogies, metaphors, literal similarity statements, applications of general laws, and simple chronologies.
 The chief focus is on explanatory analogies, such as are used in scientific modelling (Centner, 1981, 1982; Centner & Centner, 1982).
 Such analogies are fundamentally assertions that partly identical relational structures apply to dissimilar objects across different domains.
 It is generally accepted that the degree of literal similarity perceived between two objects depends on the degree of overlap among their components.
 In Tversky's (1977) elegant contrast model, the similarity between A and B is greater the greater the size of the Intersection (A f\ B) and the less the size of the two 1 complement sets (A  .
 B) and (B  A).
 This account works well for literal similarity, but the mere relative number of shared and nonshared predicates appears to be an inadequate basis for a general account of relatedness.
 For example, consider a simple arithmetic analogy.
 The analogy 3:6::2:4 is no better than the analogy 3:6:;200:400, even though 3 has more features in common with 2 than with 200.
 It is not the overall number of shared versus nonshared features that counts here, but only the relationship "twice as great as.
" I will argue that a general theory of relatedness between domains must be based on the relational structure of the overlapping information.
 The structure of the shared versus nonshared predicates determines whether a given comparison is thought of as analogy, as literal similarity, or as the application of a general law.
 In this paper I first lay out some representational preliminaries; second, provide definitions and examples of each kind of relatedness; and finally, discuss some psychological implications of the framework.
 To give a brief preview: If both the relationships and the object descriptions correspond, the comparison is The negative effects of the two complement sets are not equal: if we are asked "How similar is A to B?", the set (b  A)—features of B not shared by A — counts much more than the set (A  B)• one of literal similarity; if the relationships correspond, but the objects do not, the comparison is analogical.
 The third possibility, that the objects correspond but the relationships do not, represents neither literal nor analogical similarity.
 Such comparisons arise chiefly in chronologies, in which the same entities pass from one configuration into another over time.
 The place of general laws in this framework will also be discussed.
 Preliminary Assumptions 1.
 Domains and situations are psychologically viewed as systems of objects, objectattributes and relations between objects.
 These "objects" may be coherent conceptual bundles or component parts of a larger object, rather than separate concrete objects; the important point is that they function as wholes at a given level of organization.
 2.
 Domains and situations are represented propositionally.
 The format used here is a prepositional network of nodes and predicates (cf.
 Miller S JohnsonLaird, 1979; Rumelhart & Norman, 1975; Rumelhart & Ortony, 1977; Schank & Abelson, 1977).
 The nodes represent concepts treated as wholes and the predicates express propositions about the nodes.
 3.
 The distinction between object attributes and relationships is important.
 In a prooositional representation, the distinction can be made explicit in the predicate structure: attributes are predicates taking one argument, and relations are predicates taking two or more arguments.
 For example, COLLIDE (x,y) is a relation, while RED (x) is an attribute.
 4.
 The distinction between firstorder predicates (taking objects as arguments) and second and higherorder predicates (taking propositions as arguments) is important.
 For example, if COLLIDE (x,y) and FALL (y) are firstorder predicates, CAUSE [COLLIDE(x,y), FALL(y)] is a secondorder predicate.
 5.
 These representations, including the distinctions between different kinds of predicates, are intended to reflect the way people construe a situation, rather than what is logically 2 possible.
 181 6.
 Finally, it is assumed that a comparison "An X is (like a) Y.
" conveys that knowledge is to be mapped from Y to X.
 X will be called the target, since it is the domain being explicated.
 Y will be called the base, since it is the (presumably more familiar) domain that serves as the source of knowledge.
 S t ruc tu re~mapp ing; Interpretation Rules Assume that the hearer's representation of the base domain B can be stated in terms of object nodes b , 1 b , — , b and predicates such as A, R, R'.
 2 n The hearer knows, or is told, that the target domain has object nodes t , 1 t ,.
.
.
,t .
 A Structuremapping cortiparison 2 m m.
<DS the nodes of B onto the nodes of T: Logically, a relation R(a,b,c,) can perfectly well be represented as Q(x), where q1;x) is true just in case R(a,b,c) is true.
 Psychologically, the representation must be chosen to model the wav people think.
 M: b — > t i i The hearer derives inferences about T by applying predicates valid in the base domain B, using the node substitutions dictated by the mapping; M: [R(b ,b )] — > [R(t ,t )] i J i J Here R(b ,b ) is a relation that holds in i j the base domain B.
 Attributes (oneplace predicates) from B can also be mapped into T: [A(b )] > [A(t )].
 i i Finally, higherorder relations, such as R'(R , R ), can also be mapped: 1 2 M: [R (R (b , b ) , R (b , b )) —> 1 i j 2 k 1 tR'(R (t , t ), R (t , t )] 1 i j 2 k 1 Kinds of StructureMappings (1) A literal similarity statement is a comparison in which a large number of predicates is mapped from base to target, relative to the number of nonmapped predicates (Tversky, 1979).
 The mapped predicates include both objectattributes and relational predicates.
 EXAMPLE(1): The X12 Star system in the 182 Andromeda nebula is like our solar system.
 INTERPRETATION: Intended inferences include both object characteristics—e.
g.
, "The X12 star is YELLOW, MEDIUMSIZED, etc.
, like our sun.
" and relational characteristics, such as "The X12 planets REVOLVE AROUND the XI2 star, as in our system.
" Figure 1 shows a representation of our solar system; most or all of the predicates shown would be mapped in a literal similarity comparison.
 (2) An analogy is a comparison in which relational predicates, but not many object attributes, can be mapped from base to target.
 EXAMPLE(2): The hydrogen atom is like our solar system.
 INTERPRETATION: Intended inferences concern chiefly the relational structure: e.
g.
, "The electron REVOLVES AROUND the nucleus, just as the planets REVOLVE AROUND the sun.
" but not "The nucleus is YELLOW, MASSIVE, etc.
, like the sun.
" (see Figure 1).
 If higherorder relations are present on the base they can be mapped as well: e.
g.
.
 The hearer might map "The fact that the nucleus ATTRACTS the electron CAUSES the electron to REVOLVE around the nucleus.
" from "The fact that the sun ATTRACTS the planets CAUSES the planets to REVOLVE AROUND the sunT" (This relation is not shown in Figure 1.
) (3) A general law is a comparison in which the base domain is a named abstract relational structure.
 Such a structure would resemble Figure 1, except that the object nodes would be generalized physical entities, rather than particular objects like "sun" and "planet".
 Predicates from the abstract base domain are mapped into the target domain; there are no nonmapped predicates.
 EXAMPLE(3): The hydrogen atom is an example of a central force system.
 INTERPRETATION; Intended inferences include "The nucleus ATTRACTS the electron.
; "The electron REVOLVES AROUND the nucleus.
" These are mapped from base propositions such as "The central object ATTRACTS the peripheral object.
"; or "The less massive object REVOLVES AROUND the more massive object.
" (4) A chronology is a comparison between two timestates of the same domain.
 The objects at time 1 map onto the objects at time 2.
 This is the only interesting case in which objects are shared but relational structure need not be.
 The two timestates share objectattributes, but in general not relational predicates.
 EXAMPLE(4): Two hydrogen atoms and an oxygen atom will combine to form water.
 INTERPRETATION: The intended inferences that can be mapped from time state 1 to time state 2 concern enduring characteristics of the component objects: "Oxygen HAS ATOMIC WEIGHT 16.
" Neither confIgurational relations nor dynamic relations of the initial system can be mapped into the final system.
 Note that overlap among component objects is not sufficient to produce similarity between systems: Two isolated hydrogen atoms and an oxygen atom do not resemble water, either literally or analogically.
 Figure 1.
 Structuremapping between solar system and hvdroqen atom.
 Ken Porbus and I have observed a subject trying to understand the behavior of water flowing through a constricted pipe.
 His first comparisons were similarity matches, e.
g.
, water coming through a constricted hose.
 Later, he produced analogies such as a train speeding up or slowing down, and iron balls banging into one another and transferring momentum.
 Finally, he was able to state a version of the Bernoulli principle, that velocity increases and pressure decreases in a constriction.
 Literal similarity matches are highly accessible but not very useful in deriving causal principles, because there is too much overlap.
 Analogies are harder to generate, since they require searching the data base for relational matches, not object matches.
 Rowever, once found, an analogy should be more useful in deriving the key principles, especially if the set of overlapping predicates includes higherorder relations such as CAUSE (see 'Winston, 1981).
 Finally, by comparing two or more analogies, the common subparts of the relational structure can be isolated and a general law derived.
 [See Gick and Holyoak (in press) for relevant studies.
] In summary, no treatment of domain relatedness can be complete without distinguishing between object features and relational features: that is, between relational predicates and oneplace attributive predicates.
 Careful analysis of the predicate structures being mapped is central to modelling the inferences people make in different kinds of comparisons.
 To summarize, overlap in relations is necessary for any strong perception of similarity between two domains.
 Overlap in both object attributes and interobject relationships is seen as literal similarity, and overlap in relationships but not objects is seen as analogical relatedness.
 Overlap in objects but not relationships may be seen as temporal relatedness, but not as similarity.
 According to this analysis, the contrast between analogy and literal similarity is a continuum, not a dichotomy.
 Given that two domains overlap in relationships, they are more literally similar to the extent that their objectattributes also overlap.
 A different sort of continuum applies between analogies and general laws: In both cases, a relational structure is mapped from base to target.
 If the base representation includes concrete objects that must be left behind, the comparison is an analogy.
 As the the base domain become and variablelike the object nodes of more abstract comparison is seen as a general law.
 Psychological speculation; The Analo<̂ ical Shift Conjecture.
 People learning a new domain often make spontaneous comparisons with other domains.
 The speculation is that the earliest comparisons are chiefly literalsimilarity matches, followed by analogies, followed by general laws.
 For example.
 References Centner, D.
 The structure of analogical models in science (BBN Report No.
 4451).
 Cambridge, ^4a3s.
: Bolt Beranek and Newman Inc.
, 1980.
 Centner, D.
 Metaphor as structuremapping.
 Paper presented at the meeting of the American Psychological Association, Montreal, September 1930.
 Centner, D.
 Are scientific analogies metaphors? In D.
 Miall (Ed.
), Metaphor: Problems and perspectives.
 Brighton, England: Harvester Press Ltd.
, in press, 1982.
 Centner, D.
, & Centner D.
 R.
 Flowing waters or teeming crowds: Mental models of electricity.
 In D.
 Centner & A.
 L.
 Stevens (Eds.
), Mental models.
 Hillsdale, N.
J.
: Erlbaum, in press, 1982.
 Gick, M.
 L.
, & Holyoak, K.
 J.
 Analogical ocoblera solving.
 Cognitive Psychology, 1980, 12, 306355.
 Gick, M.
 L.
, & Holyoak, K.
 J.
 Schema induction and analogical transfer.
 Cognitive Psychology, in press.
 1S3 Miller, G.
 A.
, & JohnsonLaird, P.
 N.
 Language and perception.
 Cambridge, Mass.
: Harvard University Press, 1976.
 Ruraelhart, D.
 E.
, & Norman, D.
 A.
 The active structural network.
 In D.
 A.
 Norman, D.
 G.
 Rumelhart, & the LNR Research Group, Explorations in cognition.
 San Francisco: W.
 H.
 Freeman & Co.
, 1975.
 Rumelhart, D.
 E.
, & Ortony, A.
 Representation of knowledge.
 In R.
 C.
 Anderson, R.
 J.
 Spiro, & W.
 E.
 Montague (Eds.
), Schooling and the acauisition of knowledge.
 ^Hillsdale, N.
J.
: ErTbaum, 1977.
 Schank, R.
, & Abelson, R.
 Scripts, plans, goals, and understanding.
 Hillsdale, N.
J.
: Erlbaum, 1977.
 Tversky, A.
 Features of similarity.
 Psychological Review, 1977, 84, 327352.
 VJinston, P.
 Learning new principles from precedents and exercises.
 MIT Artificial Intelligence Memo No.
 632, Massachusetts Institute of Technology, Cambridge, Mass.
, May 1981.
 184 Principles of Procedures Qaifxssition Christopher K.
 Riesbeck Ihle Uuversity EHwin L.
 Hitchins Ikvy ParKnnal Reseaxx^ and Cevelcpnent Center Ihis paper addresses the problem of hour to coipoee procedures that students can easily learn and rentenijer.
 The ultimate goal of this endeavor is to develop a set of principles to guide the ccnposition of procedures.
 At present we have built a set of analytic tools and a set of hypotheses about the nature of procedural learning that can be aipirically tested.
 Vfe came to this topic by vgiy of an examination of the instruction in a navy sdncol that teaches students how to solve relative notion problenB with a job aid called the maneuvering board.
 Ihe procedures t a u ^ seoned to us to be confusing.
 Ws began by attaiiJting to ranrite them and as we did so, v« attenpted to be specific about our cai?>laints, and about our attenpted solutions to the problems we saw.
 B: became clear ijimediately that Ehglish lacks the precision required to unandsigucusly represent the procedures.
 ^ order to provide a notation fior the procedures, we developed the Maneuvering Board Siulation language (MABQ,).
 With MABEL we could be specific about the nature of the steps which ccnprise the procedure and also about the relations among the steps in the procedure.
 Ihis specificity permitted us to propose measures on vMch the alternative procedures for accomplishing a particular task could be conparad.
 The naneuvering board is a job aid that represents the motions of ships relative to each other in a way that supports conputationa that predict the consequences of possible future actions {including no action at all) to be taken by the ships.
 Ihe naneuvering board itself is a sheet of p^)er printed with a polar coordinate plot (azimuth grid) and various scales that can be used in plotting ranges and bearings.
 Problans are solved on the maneuvering board by plotting points, and drawing lines and vectors vMch represent aspects of ships' motions (IMA 1975).
 Ih this pi9>er we will deal with a portion of only one of the nany problems that are solved on the naneuvering board, the Closest Boint of Approach (CEA) problem.
 In this procedure, the relative notion of an observed ship is plotted, and the bearing, range, and time of the closest point of approach between the two ships is determined.
 If it is determined that the ships will pass closer to each other than is desired, actions will have to be taken to ensxire a safe separation.
 Those actions will be based on other oonputationa performed on the naneuvering board.
 Qr^ating a representation language The main issue in designing a language is finding the ri^t "grain" (Moore and Cfewell 1974), i.
e.
, the right level of detail.
 A representation language for the naneuvering board that included the pencil ccming in contact with paper fiber and depositing cartoon granules wauld be ciarberscroe and unenlightening, v«*iile one at the same level of abstraction as Ehglish fails to capture ijiportant distinctions.
 The language we have designed vafl built Turdlng to the following constraints: 1) it would not include any appeal to the real warld or to the goals to be achieved.
 Thus, there is no operator for "Find closest point of ^:proach.
" The operators are all within the >orld of the maneuvering board itself.
 2) it would not include any nention of the actual physical tools involved.
 Thus, there is no mention of pencils, parallel rules or dividers.
 We call this language MABEL, for MAneuvering Board Hnulation language.
 The objects in MABEL include points, several types of lines (scales, segments, rays, vectors), circles, nunbers (speeds, distances, times and angles), and turns (left and ric^).
 MABEL has only geometric operators.
 Althouc^ some operators involve fairly complex geanBtric activity (e.
g.
 INTEESBCTdine circle), TSAtBtATECline, point)), not all gecmetric oonstructicns are included.
 T&ak analysis Depend«icy analysis A dependency analysis constructs a graph representing v*at steps of a procedure dqaend on other stepe.
 As a trivial exanple, we can't find the distance from the reference sihip to the closest point of approadi (CEA) until we first find the location of the CFA point.
 Hance we say that the distance detemining step d^iends en the CPA plotting step.
 The dependency analysis reveals the cor*straints on step ordering that are ijiposed by the nature of the task itself.
 It defines the set of procedures ocaiposed of the given steps that can actually produce the desired result.
 Among the members of this set, sane procedures feel nore natural or meaningful than others.
 Che property of procedures that makes them meaningful is the organization of goals and actions.
 Gbalaction analysis Tb make the goal structure of a procedure explicit, we do a goalaction analysis.
 A goalaction analysis creates a tree vAiose top node is the goal to be satisfied.
 Uider this node are other nodes rqjresenting the goals that have to be achieved in order to satisfy the top goal.
 Finally, attached to each goal are the actions to be done once the subgoals are achieved.
 A goal analysis is typically nore specific and therefore more constraining than the dependency analysis.
 Below is a goalaction tree for finding the bearing of the CPA.
 Gbal: bearing of CPA (BC) Goal: Direction of Relative Movement (ERM) 185 •(bal: Line of Maverwit (UM) Qaal: ^Q Action: PL0T(B1, Rl, (Hm) Cbal: M2 Action: PLOT(B2, R2, OlID) Action: RA1((M1, M2) Action: TSArBIATECLCM, P:a:) > L:EEM INTEBSECT(L:I3»1, P:(D •> P:CBM READVALtE(P:nw) »> EPM Action: ADtHEPM, +/ 90) Measuring ObalAction Seguencea A goalaction sequence is a linearization of a goalaction forest.
 The sequence specifies v*ien each goal ifl initiated (i.
e.
, viien v*3r1c en the goal begins) ^ 3 vTien each action is executed (i.
e.
, v4)en the action is perfomBd).
 lb generate a sequence fron a forest, vm select seme goal node in sane tree to be the first one in the sequence.
 After that, vi« can go to any node in the forest and select its goal or action ocnfjonent, subject only to the following ocnstxaints: The goal of a node itust be initiated the action of that node can be done.
 before v«arse than a large EFG because the actions that are pending have to be done in the ri^tt order and this order is opposite to the order in v*uch the goals appeared.
 Distance lb Usage (DTU) is a measure of the distance between the calculation of a result and the first use of that result.
 Ebr a sequence, the QLstance lb Itege is defined to be the maxijiun of the DItb for its actions.
 Distance Ob i;bage should be minimized in sequences.
 The longer usage is put off, the itore intervening results there are, and the more likely that the wrong result will be used.
 Tb illustrate the application of these measures MB present excerpts fron tMO variants of the CPA procedure.
 The first oomes fron the instnoetion manual used in a navy training course (FCTCPAC, 1980), and the amcaia is one of several alternatives we ahve investigated, li the procedure tauc^ in the school the st^>s v*u.
ch acocmplish the parts of the overall soultion are mixed together.
 Below is the portion of the goalaction tree for finding the bearing of the CPA according to the school procedijre.
 Ujwer actions in one tree nust before hi^ier actions.
 be executed EFG If the goalaction sequences are to be converted into cooputer prograns, then the order in Kiuch things are done really doesn't natter, as long as the oonstraints given are satisfied.
 But if the sequences are to becone instructions far people to read, follow, learn, and so on, then the oonstraints fail to take into account the limits of the shorttetni manocy or the organization of longterm inanory.
 Sttuitively, w« can feel that a sequence of instructions that hopped randcmly fron one subgoal to another vculd be very confusing and hard to leazn.
 £i the following paragraphs, w will describe a nucber of measures for sequences.
 Qtch measure is ooncemed with sonething that wb believe raaJces sequences easy or hard to learn.
 Ebr the monent, it is just assimed that these measures ax* the significant ones.
 By malcing eech measure explicit, we hcpe to siaplify the problens of actually testing the leamability of instructions.
 Hgfaer of Tbpleyel Onnln (NTG).
 counts hew many goals are initiated in the sequence without any hi^ierlevel goal preceding them.
 We assixne that the more toplevel goals an instruction text presents, the harder that text is to leam.
 Hence, bfTG should be minimized.
 •Qaal Act: •Gbal Act: •Qjal Act: Gbal Act: Q>al Act: Gbal Act: •Qaal Act: •Qjal Act: : Ml PL0T(B1, Rl, OlID) =•> Ml : M2 PLOT(B2, R2, GRID) > M2 : line of Movenaent (LCM) RAMMl, M2) > LCM .
: (nw) TSAtBIATECLCM, P:<r) > U O M QnXItS£ET(L:a«, P:'GE) » PsEBM READVAUE(P:QW) > EFM .
: Relative Distance REACUAL[E(CCZ>MSEaain' .
.
.
.
)) : Elapsed Tims StB'IRACT(M2time Mltime) : Relative ^seed R£ADVALUE( IinXSSBCT(RAMPLCT.
))) : Bearing of CPA (BC) AOXEBM, +/ 90) > BC (SD 0 ETO idurs does wall on Icseping goal Ihis pro stack depth low and keeping acticns near the the goals they satisfy, but it does so at the eŝ penae of having a largo runber of top level goals making it difficult to remenijer.
 Ihe problon is actually vorse than shown here since the ccnplete solution to the problem has 12 top level goals.
 Here is the procedure rewritten with a mare topdoun organization: niatanee From Goal (CFG), counts for each axrtion how many other actions separate it fron its goal.
 Par a sequence, we define the overall ITG to be the raaxinun of the tF(^ for its actions.
 Distance Prcm "Goal should be minimized in sequences.
 Ihe more actions are delayed, the more likely they are to be forgotten or used incorrectly.
 'aaal Stack Depth ('GBD) counts for each goal in a sequence how rrany unfinished goals precede it.
 An unfinished goal is one vAiose action has not been dene yet.
 The Gbal Stack Cepth for a sequence is defined to be the naxijiun GSD of the goals in the sequence.
 'Cbal Stack Cepth should be mimnii?.
gri in sec[uences.
 It is related to Distance Fran Cbal in that a sequence of unfinished goals causes the actions that are eventually done to be far away frtm their goals.
 A large CSD is even 186 Qsal: Bearing of CPA (BC) Gsal: (DRM) Cbal: line of Mavement (LCM) Goal: Ml Act: PLCrr(Bl, Rl, (XID) > Ml •Qsal: M2 Act: PLCrr(B2, R2, (XID) «> M2 Act: RAV(M1, M2) > IXM ActiTSANSIATEdXM, P:a:) > L:CPM IOTERSH:T(L:nW, P:<2) «> P:ISM RBU7AL(£(P:CRM) => CFM Act: ADD(CIW, +/ 90) »> BC CFG GBD 0 1 2 3 4 3 4 3 2 2 2 1 DTU Ihis procedure has greater ITG and a greater CSD, but has only one top level goal.
 Ê cpanding it to the v*ole CPfi.
 problem, it has only 3 top level goals and the maxima of CFG and GBD do not increase with the wider scope of the problem.
 C^imJTiing Qaalaction Sequences Baaed on the measures given abowe >« suggest the follondng techniques for producing goalaction sequences <3enerate from only one tree in a forest at a time to ndnijnize Distances Ftcin Gbals and (t)&l Stadc Eepths.
 Reorder subsequences to ndnimize Distances to Ibages.
 IJpcoat cejTtain subtrees and generate fran them first to minijnize Qjal Stadc Depths.
 Merge trees to reduce the Msnber of Tbpl£vel 'Qsals.
 Ihe degree to vAiicdi these neasures predict the ease or difficulty of procedure learning and use is, of course, an arpirical question.
 There are ceitainly limits on the ranges of applicability of sane measures, and tradeoffs to be naximized among them.
 Nevertheless an approach of this type prcsnises to be a significant inftrovanait over the current hitorniiss ^jproac^ to procedures corposition.
 References: IMA (Defense Helping Agency, B^idrographic Office), H.
O.
 Publication 217, Maneuvering Board Ntanual.
 Mashington O.
C.
: Defense Mapping f̂ jeticy, 1975.
 PCnCEAC (Fleet Ctntat Ttaining Oaiter, Pacific).
 Maneuvering Board Manued.
, 1980.
 Moore, J.
 and A.
 IfeweU "Haw can MERLIN understand," in L.
 Cieg [ed.
] Kha»rledge and Cbgnition Elrlbaun Associates, 1974, pp.
 253285.
 The views expressed in this paper are chose of the authors and do not necessarily represent the position of the Department of the Navy 187 A computer simulation approach to the study of emotional behavior' Rolf Pfeifer Department of Psychology CarnegieMellon University Pittsburgti, Pennsylvania 15213 Althougfv the importance of emotion in human t>ehavior has long been recognized, only recently has there been serious interest in the problem among cognitive scientists (Abelson, 1981; Bower & Cohen, 1982; Dyer, 1982; Lehnerl.
 1981; Norman, 1980; Mandler, 1975; Pfeifer & Nicholas.
 1982; Simon, 1967; Sloman i Croucher, 1981).
 The present work is an effort to demonstrate that problems of emotion can be approached in an information processing framework.
 A first step in this direction has been taken by developing a computer simulation model capable of exhibiting certain kinds of emotional behavior.
 The model, dubbed FEELER (Framework for Evaluation of Events and Linkage into Emotional (Responses), is used to illustrate tfiree basic areas that a theory of emotion must dead with, namely (a) how emotions are generated, (b) what IS meant by an occurrent emotion, and (c) how emotions influence our behavior.
 It is suggested that models or frameworks like the one to be presented will help to make the theory of emotions more accessible to cognitive psychologists, and that It provides new ways of thinking about emotional processes.
 Underlying assumptions and related work Even though the Schachter & Singer (1962) experiments have been criticized on a number of grounds (see e.
g.
 Izard, 1977, for a summary of the criticisms), their hypothesis that emotional processes employ two separate but interacting systems, seems to be accepted by many theorists in the field (see e.
g.
 Lyons, 1980).
 Stated briefly, the systems are a physiological one, the autonomic arousal system, and a cognitiveevaluative one.
 An occurrent emotion consists of two parts, a pattern of physiological arousal, and a cognitiveevaluative component which, in the individual's belief system, causally links this pattern to an event.
 A physiological pattern alone does not constitute an occurrent emotion.
 The design of FEELER has been influenced by the related work of Abelson (1981), Bower & Cohen (1982), Dyer (1982), Lehnert (1981J, and by Mandler's hypothesis that the psychological events that influence arousal are the ones which interrupt wellorganized behaviors (Mandler, 1975).
 It is assumed that arousal is an important factor in determining the intensity of an emotion (Clark, 1982: Fiske, 1981; Mandler, 1975).
 There have been a number of efforts to include emotions into computer simulation models (Colby, 1981, for example) but in most of them emotion has not been the primary focus.
 G e n e r a l description of the m o d e l Basic architecture.
 FEELER has a production system architecture which is similar to John R.
 Anderson's ACT model (Anderson.
 Kline, & Beasley, 1979).
 but some features have been added.
 As shown in Figure 1 there is a long term memory (LTM, consisting of two parts, namely a network for declarative knowledge (declarative memory) and a memory for procedural knowledge (production memory)), a cognitive working memory and a physiological working memory.
 Two working memories are introduced separately to account for the relative independence of the physiological and the cognitive system and their distinct characteristics (e.
g.
 different decay rates).
 Whenever the term "working memory," or simply "WM " is used without further This research was supported by scholarshtp number 81.
796.
0.
80 of the Swiss National Science Foundation to ttie author and by a grant from the Allred P.
 Sloan Foundauon.
 188 qualification, it refers to cognitive working memory.
 Similarly when just LTKd is used it designates declarative memory.
 •QCOGNITIVE .
 WORKING ^ MEMORY ^ \ <1^ «=k • ^ \ A , DECLARATIVE MEMORY \ PHYSIOLOGICAL "f WORKING MEMORY O V ^ X) PROOUCnON MEMORY Figure 1: Basic architecture of the model The arrows in Rgure 1 depict the rules which are activated from production memory, as indicated by the circles.
 The tails designate which working memory they match against, the heads which memory they act upon.
 The action can consist of adding something to the memory, or in the case of LTM, it can be a process of spreading activation.
 If an element in LTM exceeds a certain activation threshokl, it is automatically added to W M , where it is subject to a decay mechanism.
 For a discussion of spreading activation see e.
g.
 Ratcliff & McKoon (1981).
 The arrow pointing into physiological working memory designates the generation of an arousal pattern.
 Representation of emotional information: Since emotional experiences can be memonzed and the corresponding emotions reexpenenced the respective memory structures have to be defined in LTM.
 Emotional information which is connected to episodic memory structures includes links to the events that are responsible for the occurrent emotion, magnitudes for emotions, and a socalled arousa//mage (Clark, 1982: Mandler, 1975).
 Examples of emotional behavior Emotions generated after interrupt: Consider an example in which the model is executing a plan to take a plane trip.
̂  The interrupt occurs on the way to the airport when the taxi develops a flat tire.
 Arousal is increased by using surprise and importance of the interrupt as multiplicative factors: if either one is small, the increase will be small, if both are large the increase will be large (see Pfeifer, 1982, for details on surprise, importance, and arousal).
 Emotions are generated in this situation by emotion generation rules such as R1.
 Rl is adapted from Weiner's (1982) taxonomy.
 R1: IF current state is negative for self and current state was caused by person^ and person, was in control and the emotional target is person.
, THEN generate anger at person, Since productions only fire if all of their conditions are present in W M .
 there must be a set of auxiliary productions providing the A model of the current environment is constantly maintained in WM.
 conditions, such as R2: R2: IF an interrupt has occurred and emotion is to be determined THEN determine target for emotion Rules like R2 have to do their work for every condition before R1 can apply.
 The phrase "generate anger at person," means that an emotion node is created in W M vtrhich is linked to the current event structure, to the interrupting event, and to the target of the emotion.
 When LTM is updated, which is typically the case shortly after an interrupt has occurred, the intensity of the emotion, which is determined from the level of arousal, Is attached to the emotion node, and an arousal image, consisting in the current version of a simple level indicator, is added to the current event structure.
 Emotions generated after plan completion: If no interrupt had occurred on the way to the airport but instead the model had "arrived" at the airport, rule R3 might have applied: R3: IF a subplan has been completed THEN generate satisfaction about subplan completion Emotions generated from emotions by rules: If anger has been generated, the emotional state of anger as such can lead to the generation of anger again by means of a rule similar to R4'.
 R4: IF angry and person, is entered through perceptual system THEN generate anger at person.
, R4 tries to capture the fact that if a person is angry he or she may generate anger at people who have nothing to do with the original angerproducing situation.
 Emotions generated through memory activation: So far the emotion generation processes have been based on rules.
 Another way in which emotions can be generated is through activation processes in LTM.
 If elements are entered and encoded into W M through perceptual processes, activation is automatically spread through LTM, I.
e.
 through the perceptual process itself, parts of LTM are activated and added to W M .
 If emotional information is attached to these elements the earlier emotions may tie reexperienced: they can become an occurrent emotion.
 Moreover, since events in LTM are interconnected via emotion nodes, events with similar emotloneU qualities can be activated from the current emotional state.
 Goal generation influenced by emotions: Emotions may cause certain behaviors which would not otherwise occur.
 Rule B5, for example, sets up the goal to harm the person (e.
g.
 to insult, hit, yell at) who is held responsible For the individual's current negative state, which lead to the emotion of anger.
 R5: IF angry and emotional target is person, THEN generate the goal to harm person^ R6: IF angry and emotional target is person, THEN generate the goal to reassess the anger reaction Rule R5 corresponds to a more aggressive reaction, R6 to a cautious one.
 R7 is a strategy to get rid of the emotion of anger by setting up a goal which diverts attention from the angerproducing situation and thus gives the anger time to decay.
 R7: IF angry THEN generate the goal to count to ten It should be noted that the goals thus generated do not necessarily have to be pursued.
 This decision Is up to a highlevel conflict resolution mechanism.
 Interpretations biased by emotions: If the action side of Rule R6 were not to set up a goal but simply to make an assumption about the world, tor example "THEN assert that person, has goal to harm self," we may talk about an inference biased by an emotional state.
 Summary and discussion Table i is a systematic account of the possible kinds of rules involved in emotional behavior in FEELER as illustrated by the examples in the last section.
 The classification is based only on whether the rules directly influence emotions (i.
e.
 they include emotions in their action side) or whether they are influenced by emotions (i.
e.
 they include emotions in their condition side).
 Cell (1) contains general inference rules which are typically used as auxiliary rules in the emotion generation process, but they are not particular to a specific emotion.
 Rules in cell (2) are not influenced by the current emotional state but they result in an ACTION SIDE COGNITIVE EMOTIONAL CONDITION SIDE COGNmVE EMOTIONAL COGNITIVE 4 EMOTIONAL R2 R7 R5,R« (1) (3) (5) R1,R3 (2) W R4 (6) Table 1: Summary of rules occurrent emotion.
 Rules in cell (3) represent behavior which Is purely motivated by an emotional state.
 In cell (4) are the rules defining direct interactions between emotions.
 So far interactions between emotions have only been modeled indirectly via the decay mechanism.
 Cells (5) and (6) contain rules representing interpretations or action tendencies influenced by an emotion.
 The rules in cell (6) lead to an emotional state which would not have been caused by the cognitive components alone.
 In summary, a number of ways in which emotions can be generated and influence behavior have been modeled and analyzed.
 The focus in this report was on behavior based on production rules, but it was also seen that network processes participate through spreading activation mechanisms.
 A comprehensive concept of an occurrent emotion must include both rulebased and networkbased processes, as well as their relationship to the physiological patterns of activation.
 The current implementation of FEELER shows a variety of interesting kinds of emotional behaviors which have tjeen described above.
 However, the representational and inference structure needs to be enriched for all aspects of the model and they have to be incorporated in a more coherent system.
 In addition, some issues have been only margineilly addressed or not at all (e.
g.
 learning processes, emotional expression, and highlevel conflict resolution mechanisms).
 Despite its very real limitations FEELER provides a framework for the study of emotion in a cognitive science methodology capable of capturing a wkje range of phenomena.
 Applications to research on mood and to the theory of defense mechanisms are briefly pointed out elsewhere (Pfeifer, 1982).
 Acknowledgments Many discussions with Peggy Clark, Susan Rske, Matt Lewis, David Nicholas, and Herb Simon, have been invaluable to the development of the ideas in this paper.
 I would like to thank in particular Bill Jones, Matt Lewis, Peter Pirolli.
 Barbara Riehle, and Herb Simon tor comments on an earlier draft, and Pat Langley for his assistance with the implementation of the model.
 References Abelson, R.
P, Constraint, construal, and Cognitive Science.
 In 189 Third Annual Conference of the Cognitive Science Society.
 Cognitive Science Society, 1981.
 Anderson, J.
R.
.
 Kline.
 P.
J.
, Beasley, C M .
 A general learning theory and its application to schema abstraction.
 In G.
 Bower (Ed.
), Advances in learning and motivation.
 New York: Academic Press, 1979.
 Bower, G.
H.
 & Cohen, PR.
 Emotional influences in memory and thinking: Data and theory.
 In M.
S.
 Clark & S.
T.
 Fiske (Ed.
), Affect and cognition: The 17th Annual Carnegie Symposium on Cognition.
 Hillsdale, N.
J.
: Eribaum, 1982.
 Clark, M.
S.
 A role for arousal in the link between feeling states.
 judgments and behavior.
 In M.
S.
 Clark & S.
T.
 Rske (Ed.
), Affect and cognition: The 17th Annual Carnegie Symposium on cognition.
 Hillsdale.
 N.
J.
: Eribaum.
 1982.
 Colby.
 K.
M.
 Modeling a paranoid mind.
 The Behavioral and Brain Sc/ences, 1981,4,515560.
 Dyer, M.
G.
 Indepth understanding.
 A computer model at integrated processing for narrative comprehension.
 Doctoral dissertation, Yale University, 1982.
 Rske, S.
T.
 Social cognition and affect.
 In J.
 Harvey (Ed.
), Cognition, social behavior and the environment.
 Hillsdale, N.
J.
: Eribaum, 1981.
 Izard, C.
E.
 Human Emotions.
 New York: Plenum Press.
 1977.
 Lehnert, W.
G.
 Affect and memory representation.
 In Third annual conference of the Cognitive Science Society.
 Cognitive Science Society, 1981.
 Lyons, W.
 Emotion.
 Cambridge.
 UK: Cambridge University Press, 1980.
 Mzmdler.
 G.
 Mind and emotion.
 New YorK: Wiley, 1975.
 Norman, D.
A.
 Twelve Issues for Cognitive Science.
 Cognitive Science, JanuaryMarch 1980, 4(1), 132.
 Reifer, R.
 Cognition and emotion: an information processing approach (Tech.
 Rep.
 436).
 Dept of Psychology, CamegiaMellon University, May 1982.
 C.
I.
P.
 Working Paper.
 Pfeifer, R.
 & Nicholas.
 O.
W.
 Toward computationai models of emotion.
 In Proceedings of the European Conference on Artificial Intelligence.
 AIS8,1982.
 Ratcliff.
 R.
 & McKoon.
 G.
 Does activation really spread? Psychological Review, 1981.
 88(5), 454462.
 Schachter, S.
 & Singer, J.
E.
 Cognitive, social and physiological determinants of emotional state.
 Psychological Reviev», 1962, 69, 379399.
 Simon.
 H.
A.
 Motivational and emotional control of cognition.
 Psychological Revievir, 1967, 7,2939.
 Sloman, A.
 & Croucher.
 M.
 Why robots will have emotions.
 In Seventh International Joint Conference on Artificial Intelligence.
 International Joint Conferences on Artificial Intelligence, 1981.
 Weiner, B.
 The emotional consequences of causal ascriptions.
 In M.
S.
 Clark & S.
T.
 Rske (Ed.
), Affect and cognition: The 17th Annual Carnegie Symposium on Cognition.
 Hillsdale, N.
J.
; Eribaum, 1982.
 190 Where Do Goals C o m e From? Jaime G.
 Carbonell CarneyieMellon University Pittsburgh, PA 15213 A b s t r a c t Theories of rational tiehavior embodied in cognitive models of problem solving, planning, and plan interpretation typically presuppose that the planning agent is given a priori one or more goals to pursue.
 Thereupon, rational behavior consists of planning and carrying out a sequence of ax;tions in order to achieve the most important active goals.
 This paper argues that a complete cognitive model must necessarily incorporate ihe process of acquiring goals whether in reaction to perceptions of external events, in response to internal physiological or psychological states, or by other less direct means.
 An initial categorization is made of various mechanisms that can give rise to goals in an individual planner.
 1 .
 I n t r o d u c t i o n The Al literature abounds with models of problem solving, planning and plan interpretation (e.
g.
, G P S [11], STRIPS [6], N O A H [14], PAM[18], BELIEVER [16], TALESPIN [10], POLITICS [5,3]).
 Although these models differ in terms of the specific cognitive phenomena simulated, in terms of their internal structure, in terms of their representation formalisms, and in terms of their theoretical motivations, it is striking that they all share one central hypothesis: Each and every system Is heavily dependent upon the presence of one or more goals attributed to the active problem solving agents or planners.
 In essence, each planner or problem solver incorporates an implicit theory of rational behavior based upon the assumption that all actions are preformed in service of explicit, realizable goals.
 Therefore, rational behavior tor a planning system consists of formulating a sequence of planned action to achieve a set of goats.
 In the case of story Interpretation, the assumption of rationetlity applies to the characters, and the task of the understander t>ecomes one of divining their goals by reconstructing corresponding plans from sequences of observed events.
 Hence, under these models of planning and plan interpretation, rationality becomes synonymous with intelligence.
 Or, as Newell defines it: Intelligence is the ability to bring knowledge to bear in the pursuit of goals [12].
 Wilensky [19] also articulates the notion that all intelligent action ensues from the pursuit of multiple goals, including the resolution of internal goal conflicts by the spontaneous creation and subsequent pursuit of melagoals.
 The implicit centrality of goals becomes more evident when one considers some attempts at modeling affect or idiosyncratic behavior.
 For instance, Lehnert's affect stales [9] In story intepretation.
 and recent work on modeling emotions [1,13] rely on mechanisms to detect goal frustration or goal achievement.
 My earlier work on modeling ideological belief and certain aspects of liuman personality traits relies even more heavily on the presence, pursuit and attribution of different types of goals to planning agents [2, 5].
^ 2.
 Goat Generators in Integrated Cognitive Models If goaUs are central to all effective Al theories of intelligence, the natural question arises: Where do goals come from? Whereas taxonomies of goals [IS], relations among the goals of an individual (5, 19], ar\d methods of planning to achieve goals are all significant aspects of the study of goals, the key notion of what cognitive, physiological or social mechanisms give rise to goals has been largely glossed over by Al researchers.
 An Al program, whether planner or problem solver, does nothing until an external entity (such as the programmer) provides it with a goal to pursue, whereupon the program singlemindedly strives to find an effective plsin for that goal, and regardless of success or failure, resumes idling indefinitely after the solution attempt Clearly, any complete cognitive model must generate its own goals.
 Philosophical debate on issues of freewill vs determinism notwithstanding, all intelligent beings exhibit some mecisure of internal motivation and ability to respond to unexpected situations in the external environment.
 The type of Integrated cognitive model I envision would contain a goal generator that would monitor continuously the external environment and its internal state as a background process, and hence it would notice if it is getting hungry or tired, or that an external threat is imminent, bringing these issues (perhaps as interrupts) to the attention of the conscious "rational" processor, which then may decide to generate new goals, reprioritize existing goals, or ignore the interrupts.
 Essentially, the continuous monitoring of possible sources of goals necessarily forces one to face the issue of focus of attention, an issue that can be safely ignored only as long as an external entity provides all goals and thereby limits distracting factors.
 In fact, the singleminded pursuit of a small set of externally imposed goals determined a priori obviates the need to refocus attention dynamically as no unforeseen happenings will be noticed.
 Consider a presentday Al planning system deciding, for example, how to stack blocks.
 W h e n faced with an external threat or a greater need, it will not have the sense to abandon or postpone Its present task, generate and pursue a more appropriate goal, and thereby change the current focus of attention.
 Rather than attempting the formidable task of characterizing the space of plausible cognitive models capable of directing their own attention, and responding to changing events by generating their own set of appropriate goals, let us focus on the more tractable subproblem of exploring various mechanisms capable of generating goals dynamically.
* From a psychological standpoint, an obvious source of goals is the internal physiological state of the planning agent: Hunger leads to the goal of satiation of hunger physical exhaustion leads to a desire for rest.
 From an Al standpoint an equally obvious source of goals is the planning system itself generating subproblems, with the associated goal of solving the subproblem.
 For instance, an Al planner may decide that given the externally imposed goal of "satiate hunger", it should first locate food, then transport itself to that location, then ingest the food.
 Each of these steps, if not immediately executable in the external world, generates a subgoal requiring additional planning (e.
g.
, locating food generates the subgoeil of knowing the location of the food, which then may lead to searching or asking, etc.
) There are, however, more complex sources of goals.
 Schank and Abelson postulate a set of themes as goal generators whose internal structure remains a virtual black box.
 For instance, the love theme generates the goal of protecting one's loved ones.
 Unlike other aspects of Schank and Abelson's theory of representation and understanding, their treatment of themes does not provide a very satisfying analysis, in that it neither postulates a computational mechanism for how these themes operate or are In ihis argument I do no( mean to imply that all ttieones of emotion or even theories ot human miellKjence mterê ttng to Al tjractittotiers aie necessarily based on goals and their unrcitnting pursuit.
 I am merely noting that theories precise enough to result in operaiional process models (e g.
 Al proqrams) incorporating signihcant aspects ol human cognition have ttws tar been rl«pendent on goals and ttie implicit principle of rational behavior.
 191 acquired, nor does it attempt exhaustive coverage or broad sampling of cognitively plausible goal generators.
 Here, v̂ e pursue the latter goal with the longer range objective of eventually developing computational mechanisms that give rise to goals In the context of a complete cognitive model.
 3.
 Towards a Taxonomy of Goal Generators Let us again pose the central question: Where do goals come from? However, rather than examining the literature for possible answers as I attempted above, let us enumerate and categorize possible goal generators in humans.
 It appears that the following general categories cover a large range, if not the entire space of goal generatofs: 1.
 Internal physiological state changes 2.
 Mental (e.
g.
, emotional or attitudinal) state changes, possibly accompanied by, or resulting from physiological state changes 3.
 Knowledge state changes 4.
 Perceptions of changes in the external world 5.
 Socially imposed goals or constraints on the individual 6.
 Instrumentality (i.
e.
, goals generated purely in service of other goals) Examining this list, several observations become readily apparent • General coverage is indeed attained, in the sense that goals typically attributed to people can be coerced into a combination of one or more of the categories above.
 • This list is of very little use in developing a process model, as it lacks commitment to any linestructure detail} Generality is not the only metric one should apply in judging the utility of a theoretical concept • The classification itself does not necessarily suggest that a uniform mechanism operates within eacli category giving rise to the set of goals thus grouped together.
 Therefore, if the analysis is to be useful in constructing a predictive, psychologically plausible, process model, the categorization must be motivated more strongly by the processes that operate in generating the classes of goals grouped together.
 Bearing these concerns in mind, let us construct a more detailed categorization motivated by commitment to finerstructure detail of the processes that generate goals, and let us place less emphasis on global genersUity at this stage of the investigation.
 In the taxonomy of goal generators presented below, the hierarchical structure is meaningful, as are the suggested mechanisms, but the order in which the categories are listed is quite arbitrary.
 1 INSTRUI^ENTAUTY a.
 Direct instrumentality •• Given a higher level goal, subgoals ore generated by the planning or problem solving process whenever a step in the plan to achieve the higher level goal is not directly realizable, and hence requires additional directed planning.
 These goals correspond to Schank and Abelson's "delta goals" [IS].
 b.
 Derived or indirect instrumentality  Secondary goals instrumental to the achievement primary goals arise through several mechanisms in addition of strict sut>goal instrumentality, to wit i.
 In the process of planning to achieve more than one pnmary goal, conflicts may arise among active goals of the planner giving rise to meiagoals [19] of resolving the internal goal conflict in order for the planner to achieve all (or the most crucial subset) of his primary goals.
 Typically these conflicts are based on resource limitations, including limitations on the time that the active planner can devote to a particular set of tasks.
 ii.
 In the counterplanning process [4, 5], Instrumental goals of assuring that an adversary cannot (or will not) thwart an otherwise viable plan arise frequently.
 These are not true subgoals, in that they may play no role in achieving the primary goal, but rather may be directed at misleading, diverting or negotiating with potential adversaries.
 Hi.
 Goal subsumption slates [19] arise when a primary goal recurs frequently, or many primary goals share a common instrumental subgoal.
 In essence, a subsumption state facilitates the achievement of many Instances of pnmary or instrumental goals.
 Hence, the achievement of a desired subsumption state t>ecomes a goal in Itself.
 An Instance of a subsumption state is having a steady Income, thus facilitating any goals requiring money, and aiding socialstatus goals as well.
 Similariy, establishing an alliance to aid in future mutual fulfillment of different primary goals, or terminating an adversary relation can be considered subsumption goals [5].
 iv.
 Optimization of a plan, or saving mental effort while planning could be construed as indirect instrumental goals to the primary objective.
 2.
 INTERNAL DRIVES these may be considered psychologically inate goals in an individual a.
 Cyclic physiological drives • these are goals generated In response to internal physiological states that change with a certain periodicity.
 A cognitive model may treat the mechanism that generates basic drives of this sort as a black box.
 Schank and Abelson label these "Sigma goals".
 A partial enumeration of cyclic physiological drives includes: 1.
 Satiation of hunger ii.
 Satiation of thirst iii.
 Desire for rest or sleep iv.
 Desire for sexual activity b.
 Noncyclic physiological drives • these occur primarily in response to adverse changes in the environment, and perhaps should also be considered as black boxes when constructing a cognitive model.
 These goals have no correlate in the Schank and Abelson taxonomy.
 A representative sampling includes: i.
 Selfpreservation (in response to overt threats) ii.
 Protection of one's offspring (again in response to overt threats) iii.
 Seeking warmth (if the external temperature drops) iv.
 Satisfying curiosity (e.
g.
, in response to unexpected external events) V.
 Seeking companionship (in its absence) 3.
 SOCIAL GOALS  These are goals that arise by virtue of interaction with other members of the species.
 a.
 Semiautonomous social dynamics  these goals ^ e reader is referred to (he "World Modeller's Proiect" (8.
7] lor a discussion ol a general expcrimenlal svslem thai simulates a reactive environment in wtiich one may buiU simple pUnmno systems Uul must cope willi ctiaiiges in the environment.
 Such a system is an CKpefimoni.
nl tool that e«pcdiles research and iheds liylil on signilicani problems not herplofore investigated m the appropriate coniext.
 (Such problems include the topic ol this paper.
) 192 Sloman argues convincingly that evaluating a theory bised solely on breadth ot coverage and predictive generality ignoies issues of internal structure and coinmilnient lo detail, which olten dilfcrenliate useful Iheoiics from general truisms (171.
 http://CKpefimoni.
nlappear to require no explicit learning, but arise only if an individual interacts with other members of the species.
 Again, these goals have no direct correlate in Schank and Abelson's taxonomy.
 Types of semiautonomous social goals include: i.
 Simple socieU ambition (e.
g.
.
 become the king of the hill, or the leader of the pack, or the respected medicine man) ii.
 Property ownership, acquisition and protection from others (There can be no meaning to ownership without the notion of restricting access to others of the objects owned.
) iii.
 Protection of others within the social group from external threats (This clearly goes beyond protection of self or biological offspring) iv.
 Protection of the nature and makeup of the social group itself (e.
g.
 from other members of the species who may pose no threat to individuals within the social group, but pose a threat to the established social order) V.
 Jealousy, wanting something merely because another memtjer of the social group has acquired it vi.
 Avoid banishment by the social group b.
 Socially taught or imposed goals  unlike the previous category, these goals vary across social groups within the species, and therefore must be learned by individuals (from observation of more mature members of the social group, or by direct instruction).
 Here I defer to anthropologists or social psychologists to provide a more comprehensive list; the following is meant as an illustrative sample: i.
 Abide by the formal and unwritten laws of the society ii.
 Live according to the ethics and morals adopted or imposed by the society on the individual iii.
 Contribute to the communal wealth and well being (in some societies) iv.
 Seek to attain those qualities that comprise a metric of status in the society (wealth, power, respect, wisdom, notoriety, etc.
 depending on the psulicular society) 4 ENJOYMENT GOALS  these correspond roughly with Schank and Abelson's "E goals".
 a.
 Direct (physiological) pleasurable experience •• these goals overiap substantially with cyclic and other physiological Qoals discussed earlier; the central distinction is based on tne circumstances in which they arise (e.
g.
.
 the motivation to walk into a hot tub or a steam bath dilfers from the motivation to seek shelter in frigid weather, although the resulting goal states overlap in terms of the physical state change sought).
 i.
 Physical exertion for pleasure (as opposed to exertion instrumental to other primary goals), such as exercise, some forms of children's play, etc.
 ii.
 Direct sensual gratification (such as eating lor pleasure in "gourmet" dining, tactile gratification, etc.
) iii.
 Aesthetic gratification (such as enjoying a painting, a sunset, a concert, a good novel, etc.
) b.
 Derived psychological pleasure • satisfaction of most nontrivial goals yields a measure of resultant pleasure, but some goals appear to be caused by no internal or external reason other than experiencing this measure of indirect pleasure.
 For Instauice: i.
 Vicarious pleasure (role playing, identification with characters in movies, novels or sporting events, etc.
) ii.
 Acquisition of knowledge for Its own sake, when the knowledge is not instrumental to any primary goeils, nor is its presence a realistic subsumption state (e.
g.
, assorted trivia, half of the features stories in newspapers and magazines that bear no impact on any conceivable goal of the reader, intellectual curiosity, etc.
) iii.
 Acquisition of objects for their own sake (For instance, most stamp and coin collectors are not primarily motivated by the prospect of making money from their collections, but rather amassing and classifying their precious objects becomes an end in itself.
) 5.
 MENTALLYDERIVED GOALS  these are goals resulting from deliberate reasoning processes, including: a.
 Goals arising from mentally deduced information (as opposed to directly observed information).
 These goals may bear similarity in content with previous goals, but not in their method of inception (such as deciding that the disturbance in the campsite could have been caused by a grizzly bear, and hence activating the selfpreservation goal).
 b.
 Goals arising from the result of purposeful reasoning (such as deciding on a particular career to pursue after much thought).
 These are not instrumental goals, but often longrange personalobjective goals.
 4.
 Concluding Remark The goal categorization above, however imperfect or incomplete, is offered as an initial step towards developing effective models of the goal acquisition process, and thereby eventually creating more complete models of human cognition.
 Subsequent to the postulation of a particular taxonomy motivated by plausible sources of the various classes of goals, I intend to focus on modeling explicitly a planning agent that acquires its own goals £ind refocuses its attention in an interruptdriven manner.
 The World Modellers project offers an amenable environment in which to create progressively more complex, cognitively plausible models that interact with a simulated environment.
 5.
 References 1.
 Bower, G.
 H.
 4 Cohen, P.
 R.
, "Emotional influences in memory and thinking: Data and theory," in Affect and cognition: The 17tti Annual Carnegie Symposium on Cognition, M.
S.
 Clark & S.
T.
 FHske, ed.
, Eribaum, Hillsdale, N.
J.
, 1982.
 2.
 • Carbonell, J.
 G.
, "Towards a Process Model of Human Personality Traits," Artificial intelligence.
 Vol.
 15, No.
 1,2, novemtjer 1980 , pp.
 4974.
 3.
 Carbonell, J.
 G.
, "POLITICS: An Experiment in Subjective Understanding and Integrated Reasoning," in Inside Computer Understanding: Five Programs Ptus Miniatures, R.
 C.
 Schank and C.
 K.
 Riesbeck, eds.
.
 N e w Jersey: Eribaum, 1981.
 4.
 Carbonell, J.
 G.
, "Counterplanning: A StrategyBased Model of Adversary Planning in RealWorld Situations," Artificial Intelligence, Vol.
 16, 1981 , pp.
 295329.
 5.
 Cartsonell, J.
 G.
, Subjective Understanding: Computer Models of Belief Systems, Ann Arbor, Ml: UMI research press, 1981.
 6.
 Rkes, R.
 E.
 and Nilsson, N.
 J.
, "STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving," Artificial Intelligence.
 Vol.
 2, 1971 , pp.
 189208.
 7.
 Hood, G.
 and Carbonell, J.
 G.
, "The World Modelers Project: Constructing a Simulated Environment to Aid Al Resesirch," Proceedings ol ttie Tfiirteenth Annual 193 Pittsburgh Conference on Modeling and Simulation, 1982 , Pittsburgh, PA.
 8.
 Langley, P.
 Nicholas, D.
, Klahr, D.
 and Hood, G.
, "A Simulated World for Modelling Learning auid Development," Proceedings ol the Third Annual Conference ol the Cognitive Science Society, 1981 .
 9.
 Lehnert, W.
G.
, "Affect units and narrative summarization," Tech.
 report 179, Yale Univ.
, Dept.
 of Computer Science, May 1980.
 10.
 Meehan.
 J.
 R.
, The Metanoveh Writing Stories by Computer.
 PhD dissertation, Yale University, Sept.
 1976.
 11.
 Newell, A.
 and Simon, H.
 A.
, Human Problem Solving, New Jersey: PrenticeHall, 1972.
 12.
 Newell, A.
, "The Knowledge Level," Tech.
 report, Dept.
 of Computer Science, CarnegieMellon University, 1981, CMUCS81131.
 13.
 Pfeifer, R.
, "Cognition and emotion: an information processing approach," Tech.
 report 436, Dept of Psychology, CarnegieMellon University, May 1982, C.
I.
P.
 Working Paper.
 14.
 Sacerdoti, E.
 D.
, A Structure for Plans and Behavior, Amsterdam: NorthHolland, 1977.
 15.
 Schank, R.
 C.
 and Al)elson, R.
 P.
, Scripts, Goals, Plans and Understanding, Hillside, NJ: Lawrence Eribaum, 1977.
 16.
 Schmidt, C, Sridharan, N.
 and Goodson, J.
, "The Plan Recognition Problem," Artificial Intelligence.
 Vot.
 11, No.
 2, 1978, pp.
 458a 17.
 Sloman, A.
, The Computer Revolution in Philosophy: Philosophy, Science And l^odels of the Mind, Harvester Press.
 1978.
 18.
 Wilensky, R.
, Understanding GoalBased Stories, PhD dissertation, Yale University, Sept 197a 19.
 Wilensky, R.
, Planning and Understanding, Addison Wesley.
 Reading, MA, 1983.
 194 Surprise and Coherence: Sensitivity to Verbal Humor In Right Hemisphere Patients Hiram H.
 Brownell, Dee Michel, John Powelaon, and Howard Gardner Boston Veterans Administration Medical Center and Aphasia Research Center, Dept.
 of Neurology, Boston University School of Medicine, and Harvard Project Zero Address for correspondence: Psychology Service 116B, Veterans Administration Medical Center, 150 S.
 Huntington Ave.
, Boston, MA 02130.
 Surpriae and Coherence: SenaitiviCy to Verbal Huaor in Kight Heaiaphere Patience Jokes reflect oae of the most intriguing human competences.
 lo this paper, we focua on jokes as a narrative form and examine how they are processed by patients with 'cortical brain damage.
 These results provide empirical support for theoretical components of normal humor processing.
 Jokes have been subjected to considerable analysis by scholars representing several disciplines.
 Despite numerous differences in focus, nearly all formulaCions about jokes stress the importance in humor of incongruity: A feature or features are surprising and unexpected at one level, but follow plausibly when another level or dimension is considered (see Goldstein and HcGhee, 1972; McGhee, 1979, for reviews).
 Take, for example, the following joke: The neighborhood borrower approached Mr.
 Smith on Sunday afternoon and inquired: "Say Smith, are you using your latmmower this afternoon?" "•^es, I am," Smith replied warily.
 The neighborhood borrower then answered: "Fine, then you won't be needing your golf clubs.
 I'll juat borrow them.
" Upon hearing the body of the joke, the listener has an expectation of what will follow plausibly: For example, the borrower will be disappointed, or he will ask to borrow the lawnmower on a subsequent occasion.
 The punchline is surprising at one level precisely because it departs radically from these expectations about the normal course of events.
 What converts the feeling of surprise into a reaction of humor is the fact that, viewed from a different perspective, the punchline does follow from the premises introduced in the body of the joke.
 After all, the borrower does end up asking for a loan, and the wariness by the possessor of the lawnmower the perfect pretext for the second displayed provides request.
 This separable surprise analysis identifies two potentially components of jokes, termed here and coherence, that are utilized in the normal appreciation of verbal humor.
 Assuming for the moment that an individual has an intact understanding of the ordinary meanings and uses of language, he must also possess a schema, or script (cf.
 Abelson, 1981), which covers the normal course of events (in this case, a request to borrow an item from a neighbor).
 Against this background, the individual nust be able to detect discrepancies from the normal course (sensitivity to surprise).
 However, in order to appreciate the joke, mere detection of discrepancy does not suffice; the listener must be able to appreciate the relation among the elements in the body of the joke and keep them sufficiently in mind so that he can attempt to relate them to the punchline (appreciation of coherence).
 Of course, appreciation of jokes requires syntactic and lexicalsemantic skills.
 In view of this account, two questions arise.
 First, can narrative competences such as sensitivity to surprise and the ability to generate a coherent interpretation of the punchline in the light of the joke's beginning be impaired apart from other linguistic abilities? Second, can the two hjrpothesized components of the joke narrative form be distinguished empirically? Patients with unilateral right hemisphere diseaae provide a useful population for studying these issues.
 First, these patients have superficially intact syntactic and semantic capacities and so, unlike aphasic patients who have damage in the left cerebral hemisphere, their difficulties with jokes or other forms of connected discourse cannot be attributed to difficulties in processing individual words or sentences.
 Second, it has recently been suggested by Wapner, Hamby and Gardner (1981) that right hemisphere patients can understand the details of a story but may have difficulty weaving them together into a single coherent interpretation.
 According to this line of analysis, right hemisphere damaged patients should understand the details presented in the body of a joke but may demonstrate difficulty relating the punchline to the body of the joke.
 They should detect when a punchline is at variance with the overt content of the rest of the joke and yet may prove unable to find in the joke a second level of interpretation that integrates the punchline with the body of the joke.
 Right hemisphere damage, then, may selectively impair patients' sensitivity to one of two vital components of verbal humor.
 Method To secure information on these issues, a joke completion task was administered to right hemisphere damaged stroke patients and to a set of matched normal controls.
 The task required a subject to listen to the body of a joke and then to select from a set of four alternatives the correct punchline.
 To illustrate each of the four types of alternative, consider the joke described above: The neighborhood borrower approached Mr.
 Smith on Sunday afternoon and inquired: "Say Smith, are you using your lawnmower this afternoon?" "Yes, I am," Smith replied warily.
 The neighborhood borrower then answered: 195 1) Correcc ending: "Fine, Chen you won't be needing your golf clubs, I'll just borrow chem.
" 2) Nonaequitur ending: "You know, the grass ia greener on the other side.
" Thia latter ending, like the correct punchline, includes an element of surpriae  it does not follow directly froo the joke'a beginning.
 However, unlike the correct ending, the nonaequitur could not be coherently integrated with the premises on a second level to form an acceptable reaolution to the joke's story.
 Thua, the choice of a nonaequitur ending would indicate a preserved sensitivity to the surprise component of humor, but an inability to integrate the body of the joke and ita punchline into a coherent interpretation.
 The nonaequitura were divided into two groups.
 Half were topically unrelated to the body of the joke, and half w«re topically related to the body of the joke, including, for inatance, a word associated with an element of the joke.
 Of this last group, half were coomon sayinga.
 The nonaequitur above, for ejunple, ia a proverb ("The grass is greener on the other side"), in which "grass" in related to "lawnmower".
 Neither of these factors of topical relatednasa or familiarity as a proverb had a significant effect, and they will not be discussed in detail.
 3) Straightforward neutral ending: "Do you think I could use it when you're done?" This ending follows directly from the joke's beginning.
 The straightforward endings complemented the aonsequiturs in that they preserved a coherent sense of story but provided no disconfirmation of expectations; choice of thia incorrect ending would indicate an inaenaitivity to the importance of surprise in humor.
 4) Straightforward sad ending: "Gee, if only I had enough money, I could buy ay own.
" The straightforward sad endings, like the straightforward neutral endings, are coherent but provide no disconfirmation of expectancies; in addition, they reflect oo characters mentioned in the joke in a aad or pathetic fashion.
 Choice of this ending would indicate not only an inaenaitivity to the importance of surpriae in humor, but also an attraction to negatively toned emotional content.
 Results and Discussion Data analysis was perfonaad in two stages.
 First, subjects' proportions of correct choices were examined.
 In this analysis of variance, there was a clear effect of subject group, £ < .
05; Che right hemisphere subjects (mean proportion correct • .
60) performed significantly worse overall than did the normal controls (mean proportion correct > .
81).
 This result provides a clear demonstration that right hemisphere damage, and possibly brain damage in general, results in a humor deficit.
 In the second stage of data analysis, subjects' error patterns were examined more closely.
 On any trial, if a subject did not choose the correct alternative, he might have chosen any of Che three incorrect alternative*.
 Three separate ANOVA's, which as a group were independent of the original analysis of proportion correct, were performed — one for each error type.
 A data point in these analyses consisted of Che (uober of Cimes a subjecc chose a cerCaia Cype of ending from among Che three incorrect alternatives, divided by his total number of errors.
 Neither the straightforward neutral endings nor the straightforward sad endings ANOVA's revealed any effects Chat approached significance, F < 1.
0 for both ending Cypes.
 However, analysis of subjects' choice of the nonsequitur endings 196 (collapsing across the three subtypes of nonsequitur) showed that Che right hemisphere subjects were significantly more attracted to this ending type (mean proportion of total errors " .
50) than were the normal controls (mean proportion of total errors • .
18), £ < .
01.
 Error data from the right hemisphere subjects were further examined using tteats for effects of the three subtypes of nonsequitur endings.
 These tests did not reveal any reliable effects, although within the associated nonsequiturs, the coimnon sayings were marginally (p < .
10) more attractive than the unfamiliar associates.
 In suamary, there are t«ro major results of this experiment.
 First, the right hemisphere patients showed a marked disability relative to control subjects in selecting correct punchlines.
 Second, right hemisphere patients were clearly more attracted to or fooled by the nonaequitur endings than were the normals.
 This pattern of results supports a model of humor processing based on two narrative skills: the ability to detect surprise, and the capacity to establish coherence, in these caaea between the surpriaing ending and the body of Che joke.
 The confusion by right hemisphere patients between the nonsequitur and the correct endings suggests a preservation of the first narrative skill and an ia^airment of the second.
 The right hemisphere patients appreciate that a joke must end in a surprise, and they recognize which endings are surprising: but they cannot establish a second level of interpretation that ties the ending coherently to the body of the joke.
 The present atudy does not establiah whether this impairment ia the reault of right hemisphere damage specifically, or of brain damage in general.
 The obvious control for unilateral right hemiaphere disease  unilateral left hemisphere disease  is of course inappropriate because of the effects of aphaaia.
 Similarly, the study does not conclusively demonstrate a dissociation between narrative competence and linguistic competence; it only suggests that a narrative skill can be ii^aired in the face of intact linguiatic ability at the sentence level.
 Nevertheless, an inability to integrate the body of a joke and ita ending into a coherent interpretation ia conaistent with earlier claima (cf.
 Wapner et al.
, 1981) that right hemisphere patients exhibit an inability to integrate content acroaa parte of a narrative unit.
 BEFBIENCES Abelson, R.
P.
 Psychological status of the script concept.
 Aaerican Psychologist.
 1981, 7, 715729.
 Goldstein, J.
H.
, & McGhee, P.
E.
 (Eds.
) The psychology of humor: Theoretical perspectives and empirical issues.
 New York: Academic Press, 1972.
 McGhee, P.
E.
 Humor: Its origin and development.
 San Francisco: W.
H.
 Freeman, 1979.
 Wapner, W.
, Hamby, S.
, & Gardner, H.
 The role of the right hemisphere in the apprehension of complex linguistic materials.
 Brain and Language.
 1981, U , 1532.
 Language dominance and gesture hand preferences Oebra Stephens The University of Chicago (Cognitive Science Society sponsor: David McNeill) In general, adults gesture only when speaking, and with one hand more than with the other (Kimura, 1973a.
 b; McNeill & Levy, 1982; SousaPoza, Rohrberg S Mercure, 1979).
 <imura (1973a) observed the hand motions of righthanded adults during speech, nonverbal vocalization (humtiing), and during the silent performance of a verbal and a nonverbal task.
 A subject's hands were empty throughout a session.
 She found that most of the hand movements were classifiable either as selftouching (e.
g.
, pushing back hair, adjusting eye glasses) or as "free movements—any motion of the limb which did not result in touching of the body or coming to rest (p.
 46).
" Selftouching occurred frequently during all activities, while free movements (which we shall henceforth call gestures) were limited almost exclusively to the speaking condition.
 Moreover, subjects displayed no hand preference in selftouching, but a righthand predominance in gesturing.
 Kimura (1973b) recorded gestures of both rightand lefthanders during spontaneous speech.
 A subject was classified as sinistral or dextral if he or she wrote and performed at least six of seven other comnon activities (e.
g.
, combining hair, striking a match) with the given hand.
 Language dominance was inferred from left or rightear superiority in the perception of words presented in a dichotic listening task.
 Righthanders with inferred left hemisphere language, as well as lefthanders with inferred right language, gestured primarily with the dominant hand, which is opposite and presumably controlled by the hemisphere dominant for speech.
 Sinistrals with inferred left hemisphere language gestured about equally often with either hand.
 Since all the lefthanders demonstrated a strong left hand preference in performing other activities, the difference between the two groups may reflect discrepant organization of expressive language functions, with greater bilateral representation in the subjects who displayed no hand preference in gesturing.
 Although the dichotic test indicates left dominance in this group, it is, as Kimura points out, primarily a perceptual task; and studies of braindamaged populations suggest that lefthanders are more likely than righthanders to have diffusely organized language functions (e.
g.
, Hecaen & Piercy, 1956; Marcie, 1972; Milner, Branch & Rasmussen, 1964).
 Our own preliminary observations largely confirm Kimura's findings.
 We videotaped each of 23 adults narrating an animated cartoon he or she had just seen, to a listener who had not viewed it.
 Six subjects were participants in a study by McNeill and Levy (1982), the primary purpose of which was not to examine hand preference in gesturing, but to illuminate the ways that speech and various types of gestures represent the speaker's conceptual structures.
 Four of the six subjects in that investigation reported later, by telephone, that they write and perform other common activities with the right hand, and the other two were selfreported lefthanders.
 Subsequently we analyzed the gestures of an additional six dextrals and 11 sinistrals narrating the same cartoon.
 We required each of these 17 subjects not only to report his or her preferred hand for performing nine common activities (e.
g.
, brushing teeth, eating with a spoon), but also to pantomime each action, and to write a short phrase.
 We classified a subject as right or lefthanded on the basis of the hand preferred for writing.
 All 17 subjects reported that they always write with the same hand.
 In more than 99!8 of the cases, reported hand preference for the other nine tasks matched the hand used in pantomiming.
 Right and lefthand preferences on a task were scored respectively as 1 and 1, and the absence of a preference received a zero.
 Thus an overall score of 9 indicates strong dextrality, and a 9 maximum sinistrality.
 The subjects were also administered a questionnaire regarding the handedness of ifrmediate family members (parents, grandparents and siblings).
 Each was assigned an index of familial sinistrality, which we computed using the method described by Levy and Reid (1978, p.
 135).
 Every lefthanded or ambidextrous parent or sibling was weighted as 1, and each lefthanded or ambidextrous grandparent was assigned a weight of .
5.
 The weights were totaled and divided by the number of family members whose handedness the subject reported.
 This index did not correlate with gesture hand preference, or with the measure of general hand preference.
 We classifed almost every gesture (i.
e.
, more than 80%) of each subject either as "iconic" or as a "beat" in accordance with the criteria devised by McNeill and Levy.
 An iconic gesture is one which "seems to bear a formal similarity to some aspect of the situation described by the accompanying speech (p.
 272).
" For example, most of our subjects accompanied a description of a cat climbing up a drainpipe with a gradual upward motion of one hand.
 In this case both speech and gesture describe the direction of the cat's movement.
 A beat, on the other hand, is "small and formless, often quickly made (p.
 273).
" It shows no relation to the speech content but is associated with the discourse structure.
 Two lines of argument led us to suspect that iconics in particular would be generated by the speechdominant hemisphere, while beats might be produced by either.
 First, the former are intimately tied to speech content, while the latter are not.
 McNeill and Levy postulate that in fact an iconic gesture and the accompanying utterance emerge from a common conceptual representation.
 Second, iconics involve sequences of movements, while beats are discrete motions.
 Kimura and Archibald (1974) found that a group of aphasics was impaired in performing manual sequences, but not on tasks requiring single motions.
 Beats are not only simple and largely devoid of content, but insofar as they are associated with discourse structure, are connected to a function that may involve the whole brain performing in an integrated manner.
 This is because discourse planning includes an interrelation of global and sequential planning which could draw on the special skills of both sides of the brain.
 Shown in Table 1 is the index of general hand preference, for the 17 subjects from whom these data were obtained.
 In addition, for each of the 23 subjects.
 Table 1 displays the number of surface grammatical clauses in the narration.
 We define a 197 clause as any linguistic unit containing precisely one subject and predicate, either of which might not be explicitly stated, but inferred from context.
 Finally, the numbers of iconics and beats performed with the left, right, and both hands, respectively, are presented.
 As shown in Table 1, seven of our ten dextrals made iconic gestures primarily with the right hand or with both hands, and much less frequently with the left hand alone.
 Two of the other three performed iconics with the right hand almost exclusively, while the remaining righthander showed a predominance of lefthanded iconics.
 The pattern for beats is more complicated: five subjects show a right hand preference, four a lefthand one, and one performed mostly twohanded beats.
 As Table 1 indicates, three of the 13 sinistrals produced more iconics with the right hand, than with the left or both.
 Four performed a greater number of twohanded than left or righthanded iconics,and the remaining six lefthanders displayed a left hand preference.
 Most sinistral individuals showed the same preference in making beats, as in producing iconics, though the numbers of beats are rather small in many cases.
 For tasks other than gesturing, all righthanders received scores indicating strong dextrality.
 The variation in the scores for lefthanders prompted us to compute the correlation between this index and the respective percentages of left.
 right and twohanded iconics and beats, for this group alone.
 As the hand preference score decreases, signifying an increase in strength of left hand preference, the percentage of lefthanded iconics rises (r = .
67, df = 11, p<.
05), and the percentage of twohanded iconics decreases (r = .
64, df = 11, p<.
05).
 No significant correlations were found for beats.
 For each subject, we divided the total number of iconics, the total number of beats, and the sum of both, by the number of clauses in the narration, thus obtaining measures of the rate at which the two types of gestures were produced, separately and in combination.
 Right and lefthanders produced iconics at about the same rate, but the former performed, on the average, one beat for every four clauses, while the latter made one beat for every six clauses.
 We also wished to determine if hand preference for iconics was associated with aspects of the gestures themselves.
 First, we checked to see if direction of lateral motion varied with gesture hand.
 Most subjects used the left and right hands about equally often to gesture either to the left or to the right.
 Interestingly, though, subjects usually reproduced actions in the direction they were performed in the cartoon, from the watcher's perspective.
 Thus a gesture depicting a cat running to the subject's right was likely to involve a rightward hand motion.
 Second, we searched for systematic differences in the meanings of Iconics performed with the preferred versus the nonpreferred hand.
 Here we noted whether the action depicted in the gesture was that of a major or minor character, and if major, whether the active pursuer (the cat) or the pursued (a bird).
 We hypothesized that the preferred gesture hand would portray the cat's actions, and that the other hand would depict those of the bird and of the minor characters.
 However, either hand was equally likely to describe the actions of any character.
 In addition, we examined the speech accompanying iconic gestures of the preferred and nonpreferred hands.
 We suspected that iconics produced by the nonpreferred hand might appear with dependent clauses, passives, and information not central to the narrative; while the preferred hand would perform iconics accompanying independent clauses, active verbs and statements about Important events in the story.
 Again we uncovered no systematic variations.
 Two major findings thus emerge from our observations of the production of iconics and beats.
 First, in dextrals, preferential gesturing with the right hand consistently occurs for iconics, which are very closely associated with speech content, but not for beats, which bear no formal relation to what is being said.
 This result Is consistent with the finding of SousaPoza et al.
 (1979), that 25 of 28 righthanded males displayed a right hand preference in producing "representational" gestures, but no asymmetry for "nonrepresentational" ones.
 Since iconic gestures, as mentioned previously, involve motor sequences, whereas beats are discrete movements, it is possible that the dominant hand performs more iconics than the nondominant, simply because it possesses greater motor skill; but a contribution of speech laterality cannot be ruled out on the basis of these data.
 Second, for our sinistrals, strength of hand preference on other tasks correlates with hand asymnetry in the production of iconics but not of beats.
 The fact that many of Kimura's strong lefthanders exhibited no gesture hand preference is impossible to evaluate without knowledge of what types of gestures her subjects produced.
 We are now conducting an experiment to determine the strength of association between each of several indices of handedness as well as language dominance, and hand preference in the production of iconics and beats.
 To elicit large nunbers of both types of gesture, we require each subject to view a featurelength film, which he then narrates to a listener who has not seen it.
 Two measures of dominance for receptive language function—a reading test developed by Levy and Reid, and a dichotic listening task—are administered to the narrators.
 Unfortunately, we know of no nonintrusive measure of the lateralization of expressive speech.
 For most righthanders we can safely assume that the left hemisphere is dominant, and has primary control of the right hand.
 However, we cannot make the same assumptions concerning either hemisphere in sinistrals.
 Levy and Reid suggested that lefthanders who write with an inverted posture (with the hand above the line of writing) control fine movements of the writing hand via ipsilateral motor pathways (p.
 136).
 Smith and Moscovitch (1979) found some support for this theory, but it has not been established as fact.
 Therefore, we cannot say which hemisphere controls the preferred gesture hand in a left inverter.
 Despite these unresolved issues, we can ascertain which hand probably is controlled by the speech dominant hemisphere in the performance of at least some activities.
 Numerous researchers have found that if a righthanded subject is required to tap a key with one finger or hand, in isolation and concurrently with speaking, the right hand, but not the left, shows a decrement in tapping rate when the subject is speaking (e.
g.
, Kinsbourne & Cook, 1971; Lomas & Kimura, 1976; McFarland & Ashton, 1975; see Kinsbourne & Hicks, 1978, for a review).
 Kinsbourne and Hicks (1978) 198 interpreted this result to indicate that the speech center or a nearby area also controls the right hand in its performance of the manual activity, and when a limited area subserves two competing functions, a decrement will be observed in the performance of at least one activity.
 In our study, subjects are required to tap silently and when reading aloud for comprehension.
 Hellige and Longstreth (1981) found that for dextrals, reading concurrent with unimanual tapping produces a greater decrement in right hand than in left hand tapping rate, and that the maximal rate reduction occurs when subjects read aloud with the expectation of a comprehension test afterward.
 Finally, we assess the hand preference of each subject in the performance of a number of conrion tasks, and measure his skill on a pegmoving test which involves sequencing of hand and arm movements (Annett, 1970).
 One observer will classify every gesture, and a second one will classify the gestures occurring during a brief segment of each filming session, so that reliability may be computed.
 Hand preference in the production of each type of gesture will be correlated with the indices of language dominance and general hand preference and skill.
 Results will be available by the time of the conference.
 Table 1 Gesture hand predominance in relation to handedness and strength of general hand preference • 1 SukjMl C.
 I.
 s.
 K.
C.
 CO.
 T.
S.
 D.
 H.
H.
 D.
H.
 V.
F.
 l.
<th.
nd.
ra V.
C.
 M.
V.
 S.
M.
 «.
 o.
a.
 J.
I.
 A.
I.
 D.
S.
 o.
e.
 c.
c.
 J.
 K.
C.
 C.
I.
 Hand rra<.
 Scrantcb ^ t i I 5 » 9 3 S 3 H Clau*«« la Kar.
 130 9) 101 l» 1)1 222 90 126 191.
 71 141 11« 92 1*9 228 175 lis 82 202 114 134 130 8t U(t H 9 4 2 3 10 21 4 1 3 16 9 9 7 i 10 26 14 U 49 IB 21 11 11 Haa4 al Icanle Utkc iau 33 21 24 13 27 75 14 26 77 3 37 22 27 13 23 24 4 2 27 21 11 6 9 * 26 24 23 20 39 41 6 1 4 • 10 10 25 27 57 33 25 10 18 IS 15 11 4 :«acura 22 30 21 U 12 31 41 laac Ulkc N 18 14 32 27 27 Back 14 17 U 12 17 10 10 Hellige, J.
 B.
 and L.
 E.
 Longstreth, Effects of concurrent hemispherespecific activity on unimanual tapping rate.
 Neuropsychologia, 1981, ;i9, 395405.
 Kimura, 0.
 Manual activity during speaking~I.
 Righthanders.
 Neuropsychologia, 1973, 11_, 4550.
 Kimura, 0.
 Manual activity during speaking—II.
 Lefthanders.
 Neuropsychologia, 1973, U_, 5155.
 Kimura, D.
 and Y.
 Archibald.
 Motor functions of the left hemisphere.
 Brain, 1974, 97, 337350.
 Kinsbourne, M.
 and J.
 Cook.
 Generalized and lateral i zed effects of concurrent verbalization on a unimanual skill.
 Quarterly Journal of Experimental Psychology, 1971, 23, 341345.
 Kinsbourne, M.
 and R.
 E.
 Hicks.
 Mapping cerebral functional space: competition and collaboration in human performance.
 In M.
 Kinsbourne (Ed.
), Asymmetrical function of the brain.
 Cambridge, England: Cambridge University Press, 1978, 267273.
 Levy, J.
 and M.
 Reid.
 Variations in cerebral organization as a function of handedness, hand posture in writing, and sex.
 Journal of Experimental Psychology—General.
 1978, 107, 119144.
 Lomas, J.
 and D.
 Kimura.
 Intrahemispheric interaction between speaking and sequential manual activity.
 Neuropsychologia, 1976, 14, 2333.
 Marcie, P.
 Writing disorders in 47 lefthanded patients with unilateral cerebral lesions.
 International Journal of Mental Health, 1972, 2 .
 3037.
 McFarland, K.
A.
 and R.
 Ashton.
 The lateralized effects of concurrent cognitive activity on a unimanual skill.
 Cortex, 1975, ]]_.
 283290.
 McNeill, D.
 and E.
 Levy.
 Conceptual representations in language activity and gesture.
 In R.
 Jarvella and W.
 Klein (Eds.
), Language and place.
 London: Wiley.
 1982.
 Milner, B.
, C.
 Branch and Th.
 Rasmussen.
 Observations on cerebral dominance.
 In A.
 V.
 S.
 de Rueck and M.
 0'Conner (Eds.
), Ciba Foundation Symposium on Disorders of Language.
 London: e'hutchill, 1964 Smith, L.
 C.
 and M.
 Moscovitch.
 Writing posture, hemispheric control of movement and cerebral dominance in individuals with inverted and noninverted hand postures during writing.
 Neuropsychologia, 1979, 1 7 , 637644.
 SousaPoza, J.
 F.
, R.
 Rohrberg and A.
 Mercure.
 £ffects of type of information (abstractconcrete) and field dependence on asymmetry of hand movements during speech.
 Perceptual and Motor Skills, 1979, 48, 13231330.
 References Annett, M.
 The growth of manual preference and speed.
 British Journal of Psychology, 1970, 61, 545558.
 ~ Hecaen, H.
 and M.
 Piercy.
 Paroxysmal dysphasia and the problem of cerebral dominance.
 Journal of Neurology, Neurosurgery and Psychiatry.
 1956, 19, 194201.
 199 KNOWLEDGE CONSTRAINTS AND LANGUAGE COMPREHENSION IN APHASIA Victor Rosenthal*, Patrizia Bisiacchi** and Evelyne Andreewsky*** *U.
E.
R.
 de Psychologie, Universite Paris VIII, SaintDenis, France, ** Istituto di Psicologia, Universita di Padova, Italy.
 *** I.
N.
S.
E.
R.
M.
 U84, Hopital de la Salpetriere, Paris, France.
 Introduction You are walking in the street and hear a sentence "Paul didn't want.
.
.
".
 As you neither know who is Paul nor the person talking, you can hardly grasp the problem in its complexity.
 Yet, you have sufficient metapsychological knowledge on wanting, human relations, etc.
.
.
 to have some idea about the meaning of the sentence.
 That is, instead of explicit relevant knowledge, you have normally sufficient tacit knowledge to fulfill the minimal requirements of understanding.
 The controversy regarding the ubiquity of the penetrations of knowledge into mental functions continues to flourish in cognitive psychology (see for instance Pylyshyn, 1981).
 The question might be crucial to some extent, for we are all intuitively tempted to believe that words have mentally encoded independent meanings that are reactivated on each occurrence of a word  and we sometimes have an impression of being able to undergo a linguistic, knowledgeindependent comprehension.
 The trouble is that, in normal conditions, the use of tacit knowledge in the meaningmaking acts is so indissociable from knowledgeindependent contributions that it is impenetrable to our insights, and, until present, unisolatable in experimental designs.
 The findings from psycholinguistic laboratories that were believed to provide evidence for the consulting participation of knowledge in the act of understanding (e.
g.
 the findings on inferential intrusions) could always be interpreted either as compatible with an alternative hypothesis of postunderstanding facultative contributions or as limited to the particular experimental settings from which these findings have arisen.
 In the present discussion we shall consider a twostage model of understanding language in which we assume that related preexisting knowledge is necessarily consulted.
 Our arguments will be mostly based on findings stemming from studies on language comprehension in aphasia.
 The most salient characteristic of aphasic disorders is a deficit (resulting from a brain damage) in the expression and comprehension of language.
 Such a deficit is not equivalent to a uniform decrease of linguistic performance: often aphasic patients suffer from a discrete impairment of a functionally distinct part of the language mechanism.
 As Saffran (1982) stated: "It is not unusual to find that some aspects of language function have been severely disrupted, while others remain relatively intact.
 (.
.
.
) When subsystems that normally operate in concert break down independently, it becomes possible to investigate the residual systems in isolation.
 In some cases, the investigator can exploit specific functional deficits to control processes that may be difficult to manipulate under normal conditions" The analysis of these selective disturbances could lead us to identify the aspects of language that are subserved by functionally distinct mechanisms.
 Aphasic disorders might stand, therefore, for some sort of natural "pseudoexperimentation" as they allow us to observe functional dissociations in the language mechanism which are unconceivable in the psychological laboratories.
 With reference to our topic, cognitive neuropsychology offers the possibility of dissociating tacit knowledge contributions from knowledgeindependent contributions to the understanding of language.
 We shall refer henceforth to any contributions of knowledge by using the broader term knowledge constraints.
 200 Two stages of comprehension: from preunder stand ins to mental scenario In terms of naive rationalism there is a simple correspondence between \/ords and sentence meanings.
 The meaning of a sentence is a function of particular meanings of words and their structural arrangements.
 However, it is easy to demonstrate that there is no direct lexical basis for interpreting a sentence of the kind "can you give me the salt" (see Deloche and Andreewsky, 1981), and we all know simple examples showing that the meaning of a word can considerably differ as a function of the context in which the word is used (see Bransford and McCarrell, 1974).
 Winograd (1980) calls this paradox  the hevmeneutic circle: you have to understand words in order to understand a sentence but in order to understand words you must understand the sentence.
 The hermeneutic circle is intrinsically linked to lexicalsemantic approach to comprehension.
 As long as you believe that words have mentally encoded independent and stationary meanings, and the meaning of a sentence is a combination of particular lexical meanings, the hermeneutic circle may prevent you from accessing any further understanding of comprehension.
 It seems worthwhile to distinguish two stages in the process of understanding (but we make no claim as to exclusiveness of these two stages).
 The first stage involves an introductory preprocessing of a sentence (see also Flores and Winograd, 1981).
 This preprocessing appears to be twofold:  structural analysis of a sentence is done.
 This analysis leads the system to detect and syntactically disambiguate the keywords of a sentence, and globally to extract structuralrelational information concerning the actual "state of affairs" as a consequence of detecting keywords, related knowledge constraints can be selected.
 The selection of knowledge constraints entails preunderstanding.
 (But note that,according to the present approach, words are considered only as abstract clues guiding the selection process) .
 The second stage of processing leads to a mental representation of the sentence content.
 This representation may be conceptualized as a scenario that you put on your mental stage.
 Here the information is no longer linguistic (nor semantic), rather a mental scenario represents events or situations described in sentences and constrained by your knowledge.
 Two complementary procedures appear to be involved in creating and staging a mental scenario.
 The selection of related knowledge constraints allows the system to release appropriate knowledgebased routines which can promptly structure a scenario of the event.
 Their main advantage lies in the fact that they allow systematic processing of every item of information to be avoided.
 This reduces the processing load on the cognitive system, and, as a consequence, increases its capacity.
 Routines based on knowledge constraints cannot, however, supplant systematic processing of actual and specific aspects of situations.
 Casting actors for the parts they really play in an event (e.
g.
 agent, recipient), situating an event in time and space (e.
g.
 past, present,future,precedence, simultaneity), setting up each relevant relation (on time, space, causality, instrumentality), all this requires systematic processing (based in part on structuralrelational information stemming from the preprocessing stage) that follows strictly determined rules (see Rosenthal and Bisiacchi, 1982).
 In short, systematic processing is responsible for the precise and actual "state of affairs" and assumes the role of cognitive controls preventing from an overapplication of knowledge.
 These controls can sometimes be ineffective, as in the case of some common misunderstandings or as in certain artificial experimental tasks yielding knowledgebased intrusions.
 For instance, if you present a subject with a list of sentences such as: "The woman slipped in the staircase" and then test him for the immediate recall, it is very likely that you will notice several reproductions of the sort : 201 "The woman fell in the staircase" (Rosenthal, 1981).
 Two stages of comprehension in the light of neuropsychological investigations evidence for preprocessing Let us suppose the feasibility of limiting our comprehension to the outcome of the preprocessing stage.
 If presented with a sentence, we would have the impression of knowing something about the meaning of the sentence, but would be unable to spell it out accurately.
 This situation is reminiscent of two experimental findings.
 In now classical experiments on subliminal perception (or pattern masking) of individual words, subjects are often found to be unable to report what they saw, but if they are presented subsequently with a list of possible lexical alternatives, they are either capable of recognizing the stimulus or able to point to a semantically related word.
 In some conditions, they produce errors which bear a striking relationship to the stimulus but little other similarity (e.
g.
 "king" for queen, "red" for yellow; see Dixon, 1971).
 That is, the subliminal presentation of a word appears to last long enough for selecting a related knowledge constraint but to be too brief for retaining the morphological pattern of the word.
 In language pathology, similar findings have been reported with respect to the cases of deep dyslexia.
 A deep dyslexic patient cannot read nonsense words and reads function words (prepositions, conjunctions, etc.
.
) very poorly.
 The reading of content words appears to be better preserved with a clear superiority of concrete nouns over the abstract ones, but a patient often produces semantic errors like: "crocodile" instead of aligatOV, "church" instead of cathedral (see Marshall and Newcombe, 1966; Coltheart et al.
, 1980).
 In the last few years, several cases of the auditory analogue of deep dyslexia have been discovered (Goldblum, 1979).
 In repeating words, a deep dysphasic patient performs in a way directly comparable to the way a deep dyslexic performs in reading.
 It has been noted that, in such a patient, the probability of producing semantic errors is inversely 202 related to the typicality of a word (Goldblum, personal communication).
 Clearly, these patients are impaired in the ability to retain the perceptual (visual or auditory) pattern of a word but are able to perform the preprocessing leading to the selection of a related knowledge constraint.
 Accessing knowledge affords preunderstanding, but, since the lexical form is no longer available, a patient asked to reproduce the word would have no choice but to recreate it.
 Hence the factors such as abstractness, typicality, or number of synonyms should be relatively accurate predictors of the subject's performance.
 Evidence for structural preprocessing arises from a study by Andreewsky and Seron (1975).
 They examined the ability of an agrammatic patient to read sentences aloud.
 The word caT in French can be either a noun or a conjunction.
 The patient presented with the sentence: "Le car ralentit car le moteur chauffe" (The bus slows down because the motor overheats) read "car ralentit moteur chauffe".
 That is, he was clearly able to utter car since he produced the first car.
 In addition, when the second car (conjunction) was replaced by an unambiguous noun which he was able to read few minutes before, the patient read the sentence as in the example above.
 Implicitly, his selective ability to read words was determined by a structural analysis of the sentence.
 In general, studies on agrammatic patients force us to distinguish the ability to perform syntactic analyses of a sentence and the ability to use some of this structural information as clues for understanding (see Saffran, 1982).
 In terms of the abovedescribed model, this distinction covers the structural preprocessing and the application of systematic processes during the staging of a mental scenario.
  evidence for knowledgebased routines and systematic processes.
 We have seen in the preceding section that agrammatic aphasics are able to perform structural preprocessing and to access related knowledge constraints.
 It is our impression that their impairment has to be attributed to the representational stage, that is  agrammatic patients preserve the capacity of using knowledgebased routines but often cannot perform systematic processing (Rosenthal and Bisiacchi, 1982).
 Hence their comprehension is more related to their knowledge of the world than to the actual state of affairs.
 In matching sentences to pictures, agrammatic patients perform on the basis of the "standardness of situations" irrespective of the precise characteristics of the situation described (Caramazza and Zurif, 1976; Deloche and Seron, 1981).
 Provided with reversible sentences they assign roles to actors according to greater plausibility.
 When the roles are interchanged violating pragmatic habits (i.
e.
 The patient takes care of the doctor) agrammatic aphasics apply a normative strategy inverting the S0 relation.
 On the other hand, presented with sentences unconstrained by the pragmatic knowledge (e.
g.
 The circle is above the square) they perform on the chance level.
 Posterior Wernicke's aphasics show an opposite tendency in comprehension.
 They are insensitive to the "standardness of situations" (often mismatching both, sentences that describe odd events and those that describe highly plausible events; see Deloche and Seron, 1981) and inclined to overrely on structural information (von Stockert, 1972).
 This suggests that posterior aphasics could be limited in their ability to use knowledgebased routines but retain the ability to apply systematic processes.
 It should be recalled that routines afford the possibility of avoiding systematic processing of every bit of information and thus increase the processing capacity of the system.
 If actually, posterior aphasics suffer from low availability of routines we may predict that their processing capacity should be overall reduced.
 We examined this prediction in an experiment using riddles composed of two descriptors.
 The information contained in both descriptors was necessary to identify the intended item.
 Posterior aphasics, provided with a multiple choice array, performed poorly on this task.
 Most of their errors were responses based on only one descriptor (Rosenthal and Bisiacchi, 1982).
 * * * In short, the reported findings with aphasic subjects provide at least partial support for the twostage model of language comprehension, and illustrate some possible contributions of cognitive neuropsychology to adjacent arts.
 References Andreewsky,E.
 and Seron, X.
 (1975) Implicit processing of grammatical rules in a classical case of agrammatism.
 Cortex XI, 379390.
 Bransford, J.
, McCarrell, N.
 (1974)  A sketch of a cognitive approach to comprehension, in Weimer and Palermo (eds.
): Cognition and the symbolic processes, Hillsdale: Erlbaum.
 Caramazza, A, Zurif, E.
 (1976) Dissociation of algorithmic and heuristic processes in language comprehension.
 Brain and Language, 3, 572582.
 Coltheart, M.
, Patterson, K.
, Marshall, J.
 (1980) Deep dyslexia.
 Routledge, London.
 Deloche, G, Andreewsky, E.
 (1981) From neuropsychological data to reading.
 Draft Deloche, G.
, Seron,X.
 (1981) Sentence understanding and knowledge of the world.
 Brain and Language, 14, 5769.
 Dixon, N.
 (1971) Subliminal perception.
 London: McGrawHill.
 Flores, F.
, Winograd, T.
 (1981) Understanding computers and cognition.
 Draft.
 Goldblum, M.
C.
 (1979) Auditory analogue of deep dyslexia, in Hearing "lechanisms and Speech, Berlin, Springer.
 Pylyshyn, Z.
 (1981) The imagery debate: analogue media vs.
 tacit knowledge.
 Psych Rev.
 88.
 1, 1645.
 Rosenthal, V.
 (1981) Contribution a 1'etude des configurations semantiques dans les activites de comprehension.
 Doctoral dissertation.
 Universite Paris VIII.
 Rosenthal, V, Bisiacchi, P.
 (1982)Representing sentence content in aphasia.
 Psychologica Belgica, in press.
 Saffran, E.
 (1982) Neuropsychological approaches to the study of language.
 Brit £.
 of Psychology, in press.
 von Stockert, T.
 (1972) Recognition of syntactic structures in aphasic patients.
 Cortex, 8, 323334.
 Winograd, T.
 (1980) What does it mean to understand language.
 Cognitive Science, 4, 209241.
 203 A Unified Theory of Cognitive Reference Frames Michael Leyton Department of Psychology University of California, Berkeley The term reference frame is used in a wide variety of studies to describe a remarkably diverse set of phenomena in the field of Human Cognition.
 No unified theory exists.
 This paper elaborates such a theory and applies it to a number of examples in the following main areas: (1) Categorization and Prototypicality (2)Visual Shape Perception; (3) Auditory Reference; (4)Motion Perception; (5)Linguistic Deixis.
 Cognition as the modeling of logical processes In a lengthy study of perceptual organization (Leyton, 1974), I concluded that perception is an attempt to represent the world as a set of logical languages.
 Any such language consists of four components (S,F,A,P) S= a set of primitive symbols F= a set of rules of formation A= a set of axioms P= a set of rules of procedure Essentially, the rules P are applied to the axioms A to produce a further set of formations which are called theorems.
 I argued that perception attempts to distinguish in any environment an axiom set of stimulus formations and derive the other stimuli as theorems generated from A, via perceptual operations P.
 I argued further that because a logical language is equivalent to a machine (Minsky, 1972), perception is inherently an attempt to give a machinelike (or computational) account of the environment.
 Because it seemed to me that perception, as a descriptive mechanism, exhibited, in the above respects, general properties of all descriptive processes, I argued that all information or description is inherently a computational account.
 Although my argument in Leyton (1974) used purely cognitive evidence, in Leyton (198la&b),I arrived at the same conclusion using theoreticalbiological and statisticalmechanical arguments: Perceptual mechanisms were developed to identify, in the environment, machines to which the organism could couple itself to extract work.
 Thus, in claiming that all perception is the description of machines (or computational processes), I was claiming that all perception is inherently the identification of available work.
 The present paper elaborates this view further and shows how it explains cognitive reference phenomena.
 Machines as the basis of description.
 Essentially, any machine M (a stateoutput machine) can be described as fQ= a set of states (i.
e.
 a statespace) M » ' P= a set of inputs .
an action of the input set on the states The inputs can thus be viewed as transformations causing statetransitions.
 I claim that all description (including perception) is an attempt to characterize classes of stimuli as statespaces of machines.
 Thus, in particular, I argue that the properties of any single stimulus are split into two classes (1) those properties denoting state, (2) those 20A denoting the object which is undergoing the state (e.
g.
 a falling rock).
 Thus we have: Preliminary definition A description of a stimulus set S, is a map from the statespace of a machine onto S; that is, a map D: Q •'(5,0) for some machine M=(Q,P).
 (The empty set 0 is included because S might not yeild the entire statespace).
 Example Consider a hexagon.
 There are 12 transformations (rotations and reflections) which map it to itself: e, r^^, r̂ ^̂ , r^g^, r^^^, *'"240' *''300'^300' *• ^"^60* "^120* '"̂ ISO' where e = no transformation (the identity map) r = rotation by n degrees t = reflection In the above view of description,(1) the sides are perceived as the states of a machine, and (2) the statetransitions therefore become the above 12 transformations.
 All twelve transitions map any one side to some otHer side, or to itself.
 The resulting diagram Is exactly the statetransition diagram of the associated finitestate machine.
 For clarity.
 Fig 1 presents only a part of the diagram.
 Most of the 72 perceived connections are omitted.
 The mean1n<p of reference.
 I claim that a viable unified theory of reference frames Is obtained if one assumes c s e.
 \ I Fig 1.
 A statespace description of a hexagon that the brain identifies certain states as initial ones; that is.
 they are viewed as preinput or axiomatic.
 The important result is: Because all other states are then obtained by applying the input operations, P, each state is identifiable by the operation which produced it.
 Thus the machine description of a hexagon is reduced simply to viewing one edge, e.
g.
 the top edge) as a starting point and viewing the others each as equivalent to only the operations which obtained them from the top.
 In consequence, the other sides are referred back to the top one (Fig 2).
 (I proposed this view of reference, in mathematicallogical terms, in Leyton, 1974).
 We therefore have a revised version of what a description is.
 It is a map from the inputs (or statetransitions) onto the stimulus set.
 Thus the individual stimuli are described as follows: 'this stimulus is what I obtained after I applied such and such an act to the initial one'.
 nich is referred to a nonrotated one: / ^J20 nor.
 *5C0 § 4 0 ^ ^ — ^ 720 Fig 2.
 An input description of a hexagon Group or input descriptions.
 The system of statetransitions (or inputs) of a machine obeys a set of conditions which define it to be what iriathematicians call a semigroup.
 We will assume the existence of an extra condition (each input has an inverse input) which makes the system what is called a group.
 The assumption is psychologically important because it allows the object/state splitting of the stimulus properties.
 Thus the input set can be viewed as a group of statetransition functions, or an input group acting on S.
 But our theory of reference states that all description is the identification of stimuli with members of the input group.
 Thus we argue that all description is of this form: Definition: A description of a stimulus set S is the map of the input group G, of a machine,onto S; in fact the map PG •(S.
O) for some machine M=(Q,G) Therefore, because reference acts with respect to the preinput or nontransformed state, it acts here with respect to the nontransformation element (the 'identity' element) which e^ery group contains.
 The structure of reference.
 In the usual reference situation, the statespace is multidimensional; that is, it is the product of several onedimensional component groups.
 In this case reference acts not just with respect to the identity element of the entire group but with respect to the identity elements of each of the 1dimensional component groups.
 In fact, I found (Leyton, in preparation) that reference acts successively across the components.
 For example: a rotated parallelogram which is referred to a straightened one, i.
e.
 a rectangle: which is referred to the nonelongated version 1.
e.
 a square: In the reference process above, the mind first eliminates the group of rotations,i.
e.
 refers back to the identity of the rotation group, then it eliminates the group of shears, i.
e.
 refers back to the identity of the shear group, and finally eliminates the group of elongations i.
e.
 refers back to the identity of the elongation group.
 In fact, I have shown (Leyton, 1982; Leyton, in preparation) that the ordering in which elimination occurs is that of the perceived increasing stability of the successive group dimensions i.
e.
 inputs.
 The above rotation is perceived as less stable than the shear, which is perceived as less stable than the elongation We thus conclude: Reference involves the mapping of an input group of a machine to a stimulus set such that~ the members of the set become viewed as a enerated space of states, identifiable with thi f f nputs that obtained them.
 The reference rqcess successively factors out the dimensional component groups (or machines) in order corresponding to their increasing" perceived stability.
 The reference point in each dimension is the group identity element (i.
e.
 giving the preinput state).
 APPLICATIONS 1.
 Protypicality and reference.
 Rosch (.
1975) has proposed that natural categories  such as colors, lineorientations and numbers  have reference point stimuli  such as focal colors, vertical and horizontal lines,and number multiples of 10  with respect to which other catergory members are judged.
 For example, pink is referenced to red, a leaning object to the vertical, and 99 to the number 100.
 The reverse references do not happen.
 Using the above theory of descriptions, I claim that : A prototype is a stimulus which is labeled by the identity element of the associated" itiput group.
 It is for this reason, for example, that a giraffe is judged as an animal with a long neck, whereas the neck of a more prototypical animal, such as a dog, is not even mentioned.
 In our theory, the giraffe is viewed as needing a transformation to be obtained (in fact being equivalent to that transformation) whereas a dog is not, i.
e.
 the dog is at the initial (axiomatic, preinput) state of the 205 associated dynamical system.
 Again 99 Is obtained by moving 1 down from TOO (i.
e.
 applying the subtraction transformation) whereas IQO is obtained by 'just staying there'.
 2.
 Shape perception 2.
1 Shape and orientation As is now well documented, the perception of shape depends on the assigment of orientation CRock, 1973) A famous example (Fig 3) is the perceived difference between a square and a diamond, which depends on how the perceiver places a reference coordinate system over the same underlying figure.
 o o o .
 o 0 .
 o Fig 3.
 Assigned direction effecting perceived shape.
 Leyton (1974, 1978) and Palmer (1981) have independently proposed a theory of shape perception, in terms of the internal symnetry transformations.
 However, while their view accounts for several important effects, it is clear that it does not account for the effects of orientation on form perception.
 I claim that the present view does, because it maps the input group directly down onto the stimuli, thus identifying the stimuli totally by the transformations (i.
e.
 inputs) which obtain them.
 (Note that internal synmetrles allow a range of alternative symmetrically related descriptions which do not violate interpretation.
) Thus a definite element (or range of elements) has necessarily to be identified as the starting point of the associated machine.
 Furthermore, specific subsets have definitely to be identified with specific component 1dimensional groups.
 A change of interpretation of a figure then becomes an alteration in the elements which perception allows to be labeled by the identity input, or an alteration in the subsets which receive the component groups, or a total change of group.
 For exafi5)le,the main perceived axial structure of a square implies that it is interpretable as generated foom initial parts such as those in Fig 4.
 However, the main perceived axes of a diamond imply that amongst the allowable generators are the stimuli in Fig 5.
 Thus Interpretations change with the set of allowable generators.
 Fig 5 Allowable generators of a diamond.
 2.
2 What is shape? A shape is an interaction between two state spaces: Its Internal state soace (e.
g.
 the input description of the hexagon, given in Fig 2) and its external state space; i.
e.
 what the figure can do (e.
g.
 rotate).
 We have seen that a square and a diamond are distinguished by the mappings of their internal input groups.
 However, I claim that they are distinguished also between their external input groups.
 For a square, the more stable input group Includes the state transitions in Fig 6.
 However, for a diamond.
 It Includes more stably the state transitions in Fig 7.
 Squashing across the corners is not allowed stably for the square.
 I have identified (Leyton, In preparation) that an important aspect of the interaction of the internal (symmetry) state space and the external one is that the axes of symmetry in the former become identified as the axes of flexibility of the latter (i.
e.
 become the ldimens1ona1 component groups in the latter).
 Fige Allowable external inputs of the square o Fig 4 Allowable generators of a square.
 206 Fig 7 Allowable external inputs of the diamond In their external descriptions, figures are also clearly identified as particular members of a state transition group, because reference also exists with respect to the Initial point.
 For example.
 Wiser (1981) found that even if objects such as that in Fig 8 were presented in a nonvertical orientation, they were nevertheless recognized faster when presented again in the vertical orientation than in the initial one.
 Thus her results show that (1) the stimulus properties are clearly partitioned Into those denoting state and those denoting the object Fig 8 From Wiser (1981) undergoing the state and (2) that the state is in fact identified as a transformation with respect to a referent initial state.
 2.
3 Pattern goodness The relation of goodness to reference takes two important forms: Type 1, where a pattern such as Fig 9 is judged as less good, and is referenced to, its completed version; and Type 2, where a pattern such as Fig 10 is judged as less good, and is referenced to its nondeformed version, a square.
 V Fig 9 Fig 10 Our theory explains the two phenomena thus: Type 1: The goodness rating in Fig 9 is clearly based on the fact that the sides are perceived as needing more input transformations.
 That is, the entire machine has not been given.
 That is, a larger set of internal inputs is assumed for the figure.
 Thus, pattern goodness,in this case, is evaluated by the ratio t1 r i.
e.
 the proportion of the internal input group G used in the description map, p .
 Type 2: The goodness rating in Fig 10 is clearly based on the positioning of the figure in an external space of inputs (i.
e.
 of deformations) and referencing 1t to an identity or preinput element (which we have shown, constitutes the prototype).
 We emphasize: Type 1 goodness verifies our postulation of an internal input group, and Type 2 goodness verifies our postulation of an external input group.
 2.
4 The Marr/Nishihara Shape Description Theory.
 Marr and Nishihara (1978) claimed that the perceptual description of shape (e.
g.
 the *ape of animals) is given by viewing the figure as a concatenation of approximately cylindrical modules (Fig 11) with specific relative widths and lengths (Fig 12).
 These are obtained by assigning a collection of objectcentered local reference frames (axes) to the parts of the stimulus configuration.
 The relationship between the frames is given by the coordinate system (p,r,9,i .
((,s) where symbols are as shown in Fig 13.
 By applying our theory, we see that each of the figures in the Marr/Nishihara paper describes one of the points in an input space.
 The generation of a module (Fig 11) by translating a circle through space along an axis and by varying the diameter is the perception of external inputs to the circle.
 (Note that they become internal inputs of the module).
 The relative position of one module to another, as described by their coordinate system (Fig 13), is clearly a state space, where the module positioning is essentially a state under the associated group of transformations along these parameters e.
g.
 lowering arms lengthing legs, waving Fig n Generating a vase.
 Fig 12 An ape.
 A Fig 13 The Marr/Nishihara coordinates for relating two modules (After Marr & Nishihara, 1978).
 the hand, nodding the head, etc).
 Thus the figure is a point in the multidimensional group input space described by the interactions and shapes of the modules.
 The reference points in this space would be the prototypical animals and prototypical positions identified by the theory and techniques of Rosch (1978).
 Recall also that we claimed that an Important interaction between the internal and external groups is that the invariant axes of the former become the component groups (directions of action) of the latter.
 This is clearly evidenced in the Marr/Nishihara description: the central axis of a module i.
e.
 the invariant line under Internal rotation of the module, becomes the direction along which it can be stretched.
 3.
 Audition 3.
 Autitory Streams Auditory input, e.
g.
 a rapid sequence of tones is segregated perceptually into what Bregman and Campbell(1971) call, 'primary auditory streams'.
 These streams are groupings or frames and any tone can be allocated to only one of them.
 Our theory of the situation is as follows: Bregman (1981) himself argued that an auditory stream corresponds to the object in visual perception.
 Leyton (1974) described the grouptheoretic and logical language structure of music.
 In particular, he showed that musical transposition (change) of pitch is modeled by a group.
 This group allows the tones of a melody to be perceived as a single tone (object) Being moved into different states under an input group.
 Therefore, the segregation of auditory stimuli into streams is, in our view, the description of the latter as a disjoint set of machines.
 3.
2 Musical Reference to the tonic.
 If my hypothesis is correct that a stimulus becomes identified not just as a 207 state of an object but as the operation (in an input group) which achieves that state, then there must be a stimulus which is labeled as the identity element of the group.
 This conjecture is amply evidenced by music: the reference point is called the tonic.
 4.
 Relative motion An example T? the following: When a rectangular frame (Fig 14) is moved relative to an observer, and a point inside the frame is fixed relative to the observer, the point (1) Cognition is the attempt to model the environment as a union of machines.
 (2) A reference frame as a machine with initial conditions defined.
 (3) Referencing a stimulus is the process of (i) deciding on an object/state split of its properties and(ii)identifying the state properties with the input needed to obtain the stimulus from the initial conditions of the associated machine The substantiation of this view of reference corroborates also our proposal that description is a mapping of an input group of a machine, onto a stimulus set.
 Fig 14 The induced motion effect is nevertheless perceived to be the moving object (e.
g.
 Rock, 1975).
 Our theory describes the above in this way: the set of possible velocities clearly defines the relevant state space (which is twoJmensional).
 However, the reference judgement enters when one identifies each velocity with the transformation which obtains it from the zero velocity, i.
e.
 it is perceived as an increase (or decrease) of speed by a certain amount.
 This allows it to be referenced back to the '0' or identity element of the input group.
 The latter element is then assigned to perceptually the most stable object in the field, i.
e.
 the rectangular frame.
 5.
 Linguistic deixis Deixis (Buhler, 1934) is a term used to denote those linguistic aspects which locate or point to the object of speech; e.
g.
 'here; 'there', 'this', 'that', 'then'.
 Buhler claimed that these aspects create a coordinate system, centered on the referent (Fig 15).
 ^ > Fig 15 The deictic field The theory, which I have proposed, appears to model Buhler's concept.
 The deictic field clearly is a dynamical view of the space centered at the origin.
 "Put the book in front of my chair" means "One can find the place to put the book by inputing a translation forward from my chair's location".
 Thus, the coordinate system (FiglS) is  as I belive all coordinate systems are labeled by the internal inputs (i.
e.
 transformations) which move location with respect to the origin and axes.
 When an individual gives the pointing gesture, 'there', he is literally translating the deictic input group from himself to another point, such that the axes are properly aligned.
 As with the gravitational frame, these axes are representations of the 1dimensional component groups of the internal input group; i.
e.
 they give discrete labels for movement, not for physical packets of stimuli.
 General conclusions.
 The above presents a largescale view of cognition.
 The view is corroborated by the s&veral examples considered.
 In particular, the examples confirm the following principles 208 References Bregman, A.
S.
Asking the "What For" Question in Auditory Perception.
 In: Perceptual Organization, M.
Kubovy 4J.
R.
 Pomerantz (Eds).
Hillsdale, N.
J.
: Lawrence Erlbaum 1981 Bregman, A,S.
 i Campbell, J.
 Primry auditory stream segregation and perception of order In rapid sequence of tones.
 J.
 Exp.
 Psychol 1971.
 89, 244249.
 Buhler.
 K.
 Sprachtheorie: die Darstellungsfunktion der Spracfiel Jena: Gustav Fischer, m A / Leyton, M.
 Principles of Artistic Method: AlgebraicoLoqical Postulates in the ^ Foundations of the Science of Perception.
 Research Report, Mathematics Institute, University of Warwick, Coventry, England 1974* Leyton, M.
 Artistic Structure: GroupTheoretic, DifferentialGeometric, and MathematicalLogical Factors in Percention.
 Research Report, Matnematics Institute, University of Warwick, Coventry, England, 1978* Leyton, M.
 Artistic Activity and Human Survival: Volume 1.
 Unpublished book.
 T98TP Leyton, M.
 Do Structural and Statistical Evaluations of Information Vary Inversely or Directly.
 Research report.
 1981b* Leyton, M.
 Description, categorization, and reference  a unified theory.
 Seminar given at the Department of Psychology University of California, Berkeley, March, 1982* Marr, D.
 & Nishihara, H.
K.
 Representation and recognition of the spatial organization of threedimensional shapes.
 Proceedings of the Royal Society of London.
 1978, B200, 169294.
 Minsky, M.
 Computation: Finite and Infinite Machines.
 Englewood Cliffs NJ: Prentice Hall, 1972.
 Palmer, S.
E.
 Transformational structure and perceptual organization.
 Proceedings of the 3rd annual conference of the Cognitive Science Society.
 1981.
 Rosch, E.
 Cognitive reference points.
 Cog.
 Psychol.
 1975, 7, 532547.
 Rosch, E.
 Princioles of Cateaorization, In: Cognition ana Categorization, E.
 Rosch 4 B.
B.
 Lloyd (Eds) Hillsdale.
 NJ: Lawrence Erlbaum.
 1978 Rock, I.
 Orientation and Form.
 New York: Academic Press, 1973.
 Rock, I.
 Introduction to Perception.
 New York: Macmillan, 1975.
 Wiser, M.
 The role of intrinsic axes in shape recognition.
 Procaedinqs of the 3rd annual conference of the Cognitive Science Society.
 1981.
 •Copies available from: Michael Leyton.
 Department of Psychology, University of California, Berkeley, CA 94720.
 209 KNOWING.
 UNDEHSTANDING, AND BELIEVING Yutaka Sayakl university of Tokyo 1.
 Learning and Knoiriiig Hom "Learning" in the ordinary sense siaply iaplies the acquisItlon of knowledge, or the change in the state of knowledge.
 However, psychologists have been afraid of being aaked by sceptics, "How do you know that yois: subject has changed his or her state of knowledge?" Their avowed answer foUomt "Trom the subjecx's behavior nay we Infer his or her state of knowledge.
" Tltu3 Bower and Hllgard (1981) defineI "Learning refers to the change In a subject's behavior or behavlar potential to a given situation brought about by " (p.
11) However, if we stick with our ordinary notion of learning, then "T learned" slnply Implies that X has come to know something, B\it then we oust face with a fundaaental problea in epistaaology on the distinction between knowing how and knowing that.
 This distinction has been introduced by Wlnograd (1975), and Ruaelhart and Noman (l98l) in relation to the controversy on the rspcesentation of knowledge, i.
e.
, procedural vs.
 declarative repreeMtations.
 Howev^, the original distinction between knowing how and knowing that was on the nature of knowledge itself, rather than on its reinresentatlm) (Ryle, 19'*9).
 m other words, If we focua upon the kind of knowledge ehaxaeteorised by the subject's perforaance approaching to a certain criterion, then we are priaarlly concerned with subject's knowing how, rather than knowing that.
 On the other hand.
 If we focus upon the other kind of knowledge characterized by the subject's belief in the trutK of a proposition, then we are concerned with his knowing that.
 Although Byle ori^lnarT aade the basic distinction, he was prinarUy concerned with knowing how.
 He specified the subject's Intellectual disposition by his potential tendency of behavior to act properly and correctly under the given situation, not as a result of siaple habit, but as a result of deliberate consideration.
 Thus the state of subject's knowledge that traditional psychologists have been concerned with seeas to correspond to Byle's definition of "knowing how" exclusively.
 2.
 Understanding and Knowing That The nature of "knowing that" has been extensively analyzed by Schoffler (1965).
 According to Scheffler, X knows that Q.
 if and only If (i) Belief conditiont X believes that Q, (2) Evidence condition; X has adequate evidence that Q, (3) Truth condition} 4.
 (Hare, the third condition la purely episteaologlcal, and will not be discussed in the present paper,) Petrls (1965), independently of Scheffler's work, reached at aliiost the saoe conclusion In his analysis of "learning with understanding," to be distinguished froa rote learning.
 He asked the question, "What la to learn a fact or a oethodology with understanding?" Then he proposed first on learning proposition P with understanding 210 such as I X learned with understanding that P if and only if (Pl) X has coae to believe through experience that P, (P2) X has good (Justifying) reasons for believing that P, (P3) P (the truth condition).
 Tlien he exaained if there is any sense in saying, "X learned methodology H with understanding.
" Obviously, there seeas to be sone factual learning about N, such as learning that the rules and principles underlying N are indeed valid and appropriate to attain a goal under given circuastances.
 In order to allege learning of H .
rith nnH«.
«e.
«nriin».
 learning of the principles to be requisite.
 In addition to the learning of principles for M, Petrie requires that the reasons for believing these oethodologlcal principles should Include not only Inductive evidence that they do work, but also that they are only heuristic, i.
e.
, there aay be the better way to attain the saae goal.
 The reason for this cones froa the fact that aethodology must always be Inprovlng.
 Petrie's suggestions aay be further elaborated as follows I If X learned N with understanding, (Ml) X has coae to believe through experience that the basic procedures of M are appropriate under the given clreuastance, (M2) X has good (justifying) reasons for believing the appropriateness of the procedures, (N3) X la trying to dlscovw the better procedures by iaprorlng N.
 Although conditions M1M3 are necessary for learning M with understanding, they are by no means sufficient.
 It still renains true that one could learn all the facts about n without becoaing an expert on M, that is, without learning how.
 In order to becoae a real expert, one aust acquire the automatization of component skills to act smoothly.
 Although such automatization nay occur without understanding, Its foraatlon helps people to obtain the deeper understanding ofthe basic principles than nonautomatized learning of the principles, because of the proper encoding of chunks and the organization of the entire task.
 Moreover, the formation of automatization strenthens the understanding, because one would realize the appropreataness of the procedures together with the points to improve, through the oxcorcise of the present methodology.
 Crosscultural studies on cognition revealed that people's performances on reasoning and probleasolving are quite domain specific," which may be interpreted as the outcome of such Interactive effects between automatization and understanding.
 (Cole and Scrlbner, 197U).
 Recently, a number of authors (Anderson, ot al.
, 1981( Greeno, 1980; Simon, 1980) attempted to clarify the concept of understanding In "meaningful" (instead of "rote") learning within the Informationprocessing framework.
 Ihey regard understanding as the proper use of higher older schema, representing the conceptxial meaning In declarative iotb, froa wilch necessary procaauros are derlvea to solve seeaingly airferent, but conceptually the sane probleaa.
 VanLahn and Brotm (19H0) proposed a aoaal called "planning nets" for the ksovled^e about the purposes of every coaponent of procedural skills, reflecting teloologlc semantics.
 The concept of understanding Inliese aod other studies la cognitive science clearly Indicates the Importance of Condition H2, the process of having good (Justifying) reasons for the parts of proceaural skills.
 Condition N3, Invention of new strategy through experience, has been extensively observed for learning arlthaetlca (Hesnlck, 19B0).
 The process has been slaulatad by ACT production systea (Anderson, et al.
, 198l).
 Adaptive production systea (Anzal and Slaon, 1979) also deals with natural developaent of skills through experience.
 Thus we may conclude that Conditions N2 axtd M3 are properly taken to account In cognitive science.
 Then, what about Condition Ml? Unfortunately, belief condition of "knowing* haa been virtually Ignored In the past studies on cognition (except for beliefs in Interpersonal relations or political judgments, simulated by Colby, 1973, or Abelson, 1973).
 The condition is missing in the discnseion of procedural knowledge, as well as semantic knowledge.
 The treatment of semantic knowledge in cognitive science seems to have been close to HartlandSwann's (195^) interpretation of "knowing that.
" He clalmea that Kyle's 'knowing that" should be interpreted as another kind of "knowing how," that is, "knowing how to answer correctly to the expected questions.
" This proposal was laMdlaiely criticized by Aamerman (195<>) asking, "How do you know that your answer is Indeed 'correct*?" One cam produce "correct answers" without knowing their truthfulness.
 3.
 Wnen and How People Are Convinced We all know that the results of logical reasoning, mathematical deduction, and statistical inference do not always convince ourselves.
 Tveraky and Kahnenann (197+) demonstrated a variety of our "heuristic biases" in probabilistic Judgments, dlffarred from those prescribed by probability theory, i.
e.
, availability, Imaglnability.
 and representativeness.
 Here, we nay extend their notions to people's strategies to convince themselves or others of the truth of logical conclusion, physical descriptions, causal attribution, and the validities of procsdural skills.
 We are eaaily convinced by being shown a "good example" (availability).
 An elaborated episode which stimulates our imagination often makes a plausible explanation, (loaglnablllty).
 Wo often cite proverbs and old sayings, insisting on the alallarlty to the "typical case" (representativeness).
 Obviously, we should not use these blased tendencies to believe, for convincing children of false propositions.
 However, some of them may be quite helpful in our classroom instruction to explain new subject matter, which is quite iinf>inniar at the moment, but is to be examined rationally later.
 In classrooa, however, experienced teachers adopt various strategies to convince children of the trtrth and validity of principles in subject matters.
 "Decomposition Strategy" breakes down the problem into familiar, manipulable, subprobleas.
 "Heductlon Strategy" reduces the problem into a simple case.
 "Transformation Strategy" transforms the problem into different views, keeping the essential part the same.
 We are investigating why and how these strate gles work (or do not work) In a variety of learning, convincing children the reality and truthfulness of the knowledge.
 REraRENCES Ableson, B.
 P.
 The structure of belief systea.
 In Schank k Colby (ada.
) Computair Models of Thought and Language.
 Freeman, 1973.
 Ammeman, R.
 A note on 'Knowing that.
' Analysis.
 17, 3032.
 Anderson, J.
 R.
, Qreeno, J.
 0.
, Kline, P.
 J.
, k Keves, D.
 M.
 Acqxiisition of problemrsolving skill.
 In J.
 R.
 Anderson (ed.
) Cognitive SkUKand Their Acqulaition.
 Erlbaum, 1981.
 Anzal,Y.
 and Simon, H.
 A.
 S o theory of learning by doing.
 Psychol.
 Rev.
.
 1979, 86, 12'*120.
 Colby, K.
 M.
 Simulations of belief systems.
 In Schank Jt Colby (eda), Computer Models of Thought and Language, Freeman, 1973.
 Greeno, J.
 G.
 Analysis o? understanding in problem solving.
 In R.
 H.
 Kluiti6& H.
 Spada (eds.
).
 Developmental Models of Thinking.
 Academic'^ress, 19B0: HartlandSwann, J.
 The logical satus of 'Knowing that'.
 Analysis, 1956, 16, IllU S .
 Fetrie, H.
 G.
 Bote learning and learning with understanding.
 Doctoral dissertation, Stanford University, 1965.
 Hesnlck, L.
 R.
 The role of invention in the development of mathematical competence.
 In KluBS ft Spada (eds.
).
 Developmental Models of Thinking.
 Academic Press, 1980.
 Rumelhart, 0.
 B.
, ft Norman, D.
 A.
 Att«aogleal processes in learning.
 In Anderson (ed.
), Cognitive Skills and Their Acquisition, Erlbaum, 1981.
 Ryle, G.
 The Concept of Hind.
 Hutchlnaon House, 1959: Scheffler, I.
 Conditlona of Knowledge.
 Scott, Foresian, 1903.
 Simon, H.
 A.
 Informatiottprocesaing explanations of understanding.
 In P.
 V.
 Jusesyk ft R.
 M.
 ICLeln (eds.
) The Nature of Thought.
 Erlbaum, 198O.
 Twrsky, A.
, ft Kahnemann, D.
 Judgment nadar uncertainty.
 Science.
 185.
 liaitllil.
 WOf Vinograd, T.
 Frame representations and the declarativeprocedtsal controversy.
 In Bohrow ft Collins (eds.
).
 Representation and Understanding.
 Academic Press, 1975.
 211 KNOWLEDGE AND BELIEF AS LOGICAL LEVELS OF REPRESENTATION Gabriella A1rent1° , Bruno G.
 Bara° , Marco Colombettr 'Un1ta d1 ricerca d1 intelUgenza art1f1c1a1e.
 University d1 Mllano *"Progetto d1 Intel!Igenza artlflclale, PolUecnlco di Mllano We propose a representation system consisting of two interacting subsystems, named Ktheory and Kmodel, which play the respective roles of conceptual and episodic knowledge.
 We define belief a model M used by thought processes not directly, but through a metastructure which predicates a relation of M to other models.
 We claim that from an Intrasystemic point of view the difference between knowledge and belief Is determined neither by the structure and content of a model nor by Its relation to objective truth, but by the logical level of its representation.
 1 .
 THEORETICAL FRAMEWORK A number of different approaches to the distinction between knowledge and belief have been proposed 1n philosophical, AI and psychological literature.
 A first classification of such proposals is based on the distinction between:  the aim of globally classifying a representation systen as either a knowledge system or a belief system (Abelson, 1980);  the aim of attributing the status of knowledge or belief to individual representational items within a system (Hintikka, 1962; Miller and JohnsonLaird, 1976).
 A second classification, independent of the previous one, relies on the criteria used to assign the status of knowledge or belief to a system or to a single Item.
 The main existing approaches are: (i) an observer judges a representation system with respect to the objective reality; all representations are a priori considered as beliefs, and whenever a belief happens to be true it is considered as knowledge (Hintikka, 1962).
 For an AI application of such an approach see Cohen and Perrault (1979).
 and Perrault and Allen (1980); (11) an observer judges a representation system with respect to another representation system; see for example the"nontrarBparent" criteria by Abelson (1980): nonconsensual Ity and different in existence assumptions; (iii) an observer judges a representation system on the basis of its structure; see for example the "transparent" criteria by Abelson (1980): presence of alternative worlds, of evaluative and affective components, of a substantial amount of episodic material, unboundedness, varying degress of certitude; (iv) an observer judges a representation system S with respect to his own representations, assumed as knowledge.
 Whenever the representations of S agree with those of the observer, they are considered as knowledge; otherwise, they are regarded as beliefs.
 See for example the "deictic" definitions of KNOW and BELIEVE in Miller and JohnsonLaird (1976); (v) a system judges his own representations.
 Abelson (1980) accounts for his case by emphasizing the possibility of "awareness of nonconsensual ity".
 Instead, Miller and JohnsonLaird (1976) discuss the relation between KNOW and BELIEVE and the degree of dubiety of a representation.
 Finally, note that the approach implicit in most AI representation systems 1s not to deal with the problem of beliefs, therefore considering all representations straightfowardly as knowledge.
 From a psychological point of view, a human system can have access to external facts only through their internal representations.
 Therefore, the question becomes the ability of humans to subjectively assign to their own representations the status of knowledge or belief (Airenti, Bara, Colombetti, 1982).
 In Section 3 we shall argue that this distinction relies on the logical levels of representations.
 2.
 THE REPRESENTATION OF KNOWLEDGE We propose a knowledge representation system consisting of two interacting subsystems, named Ktheory and Kmodel, playing the respective roles of conceptual and episodic knowledge (Airenti, Bara, Colombetti, 1980, 1981).
 Ktheory Is a theory of the world, and can be conceived as a network of conceptual entitles describing classes of objects, relations, processes, actions, etc.
 (for example: the concept of a book; of x being on y; of x falling from y; of an agent z opening y; etc.
).
 The cognitive system does not deal directly with the world, but with partial representations of it, which constitute what we call Kmodel.
 In fact, there is no way for Ktheory to reference entitles in an external world: in the cognitive system, representations only can be mentioned and used.
 Kmodel contains all episodic knowledge of the cognitive system, i.
e.
 knowledge about particular objects, facts, episodes, etc.
 (for example: the book B Maria Is now reading; the fact that B is presently on desk D; the fall of B from D; Maria's opening of B; etc.
).
 These can only be expressed by means of the conceptual machinery provided by Ktheory.
 We assume that the essential feature of Ktheory is the ability to generate models for insertion and subsequent manipulation 1n Kmodel.
 For example, the concept of a "book" is a structure In Ktheory allowing the cognitive system to construct models of books whenever needed by a thought process.
 Kmodel contains the representation of the perceived world, which is continuously changing through time and space.
 As Kmodel is intended to capture the cognitive system's subjective experience, it does not only represent the perceived world, but also any possible imagined world.
 This corresponds to saying that any imagination process must produce data which belong to Kmodel , and thus satisfy Ktheory.
 So Ktheory determines the set of worlds 212 which are possible for the cognitive system, I.
e.
 the spectrum of all its possible subjective experience.
 This leads to conceiving Kmodel as a set of models of Ktheory, each representing parts of a possible external world  presently perceived or remembered or imagined.
 The partition of knowledge into Ktheory and Kmodel is logical rather than functional.
 This is reflected by the fact that Kmodel, as noted above, collects data used by different thought processes.
 Actually, all data Involved by perception, imagination, illusions, dreams, plan formation and execution, language comprehension, etc.
, are introduced through different thought processes, but share the same logical structure.
 We emphasize that models are used by such thought processes as data; In these cases the system Is not concerned with problems of existence of entitles or truth of facts represented in a model.
 3.
 THE LOGICAL STRUCTURE OF BELIEFS On the basis of our previous definitions of Ktheory and Kmodel, we assume a constructional standpoint.
 That is, the sole reality for the cognitive system is what is constructed by its thought processes using Ktheory.
 It follows that the position which, according to Hintikka's approach, defines as knowledge a belief satisfied by the real world, cannot be applied.
 In a constructional approach, in fact, Kmodel necessarily satisfies the part of Ktheory used to build it.
 For instance, if Margaret assumes in her Ktheory that seawater is sweet (I.
e.
 unsalty).
 In all models produced by her the sea will be sweet, regardless of the objective truth of this fact.
 From a subjective point of view it is appropriate to say that Margaret knows that the sea Is sweet.
 Now suppose that Margaret happens to taste seawater.
 Let us assume that Margaret Is able to distinguish between sweet and salty water, and that her Ktheory represents the two tastes as mutually exclusive when attributed to the same object.
 We suggest that the relevant possibilities In this case are: (1) since the construction of the model of salty seawater would be conflicting with the previous models, either the new model is not constructed at all, or the new model is constructed but the discrepancy is not appreciated (in this case Margaret maintains her theory about the sweetness of seawater); (11) the model is reinterpreted (Margaret may think that her perception of a salty taste depends on a particular kind of salty rocks); (111) the discrepancy between the two inconsistent models is appreciated and faced by assigning to the discrepant models that status of beliefs (Margaret acknowledges the existence of two contradictory models).
 Our hypothesis on case (ill) is that the coexistence In Kmodel of two contradictory models makes the thought processes unable to use them straightforwardly.
 To face this situation the system introduces in Kmodel a structure, which refers to the two models and represents the conflict between them (see Fig.
 1).
 As such a structure predicates a relation between the two models, it can be considered at a metalevel with respect to them.
 It is by using this metastructure that thought processes handle the conflict.
 The possible outcomes of such processes are: the old model is privileged and the new one is discarded; the reversed situation, i.
e.
 the new model is privileged and the old one is discarded; a situation of uncertainty, where both models are maintained.
 We define belief a model M used by thought processes not directly, but through a metastructure which predicates a relation of M with other models.
 Such metastructures are necessarily used by the system whenever two models cannot be interpreted simultaneously, i.
e.
 cannot be predicated at the same time of the same thing.
 This definition of the term "belief" seems to be the most appropriate within a subjective, constructional approach to the human mind.
 The difference between knowledge and belief Is reduced to the different use that thought processes make of a representation, assumed either as absolute or as relative to other representations.
 Whenever the system does not directly manipulate a model M of the world, but reasons on it through a second level representation, M assumes the role of belief.
 Note that both structure and content of M remain the same when used as knowledge or as belief.
 4.
 DISCUSSION Referring to the first classification introduced in Section 1, we have discussed the problem of attributing the status of knowledge or belief to an individual representational item within a cognitive system.
 Many researchers who deal with this problem commit themselves on the assumption that the difference between knowledge and belief can be defined in terms of the objective truth of a fact.
 That human beings cannot have access to an ultimate, absolute truth Is a trivial statement.
 As Miller and JohnsonLaird (1976) point out, it Is not acceptable, either from a psychological or a linguistic point of view, to assume that ".
.
.
knowledge is simply justified true belief and that one cannot be said to know something that is false".
 From our psychological standpoint, we have therefore assumed a different position and focussed on the Internal structure of knowledge and belief.
 We have shown that our definition of belief is significant In the case a system has to deal with conflicting models of the world.
 The idea of a second level structure seems not to be restricted to such a case, but it can be applied whenever the system evaluates properties of a model.
 Among these are the degree of certainty of facts and the existence in the world of the entities represented in a model.
 In fact, both existence and degree of certainty are not part of a model, but are predicated on it.
 Our treatment of beliefs opens a problem about the thought processes manipulating Kmodel.
 The two possibilities are:  thought processes treat in a uniform way both the models of the world and the metastructures mentioning them; an analogous approach is taken by Wilensky (1981) in his work on planning and metaplanning;  there exist a type of thought processes specialized in manipulating metastructures; In this case the two levels of representation would reflect Into two corresponding levels of thought.
 REFERENCES Abelson R.
P.
, 1980.
 Differences between belief and knowledge systems.
 Cognitive Science Technical Report No.
 1, Yale University.
 Airenti G.
, Bara B.
G.
, Colombetti M.
, 1980.
 A semantic memory model as a basis for a problem 213 solving system, Italian Journal of Psychology.
 VII, 2.
 Alrenti G.
, Bara B.
G.
, Colombetti M.
, 1981.
 An artificial intelligence approach to the study of cognitive processes, URIA Internal Report, University d1 Mllano.
 Airenti G.
, Bara B.
G.
, Colombetti M.
, 1982.
 A two level model of knowledge and belief, in Trappl R.
, ed.
.
 Proceedings of the 6th European Meeting on Cybernetics and System Research, North Hoi 1 ana, Amsterdam (in press;.
 Cohen P.
R.
, Perrault C.
R.
, 1979.
 Elements of a plan based theory of speech acts.
 Cognitive Science.
 3, 3.
 Hintikka J.
.
 1962.
 Knowledge and belief, Cornell University Press, Ithaca, N.
Y.
 Miller G.
, JohnsonLaird P.
N.
, 1976, Language and perception, Cambridge University Press, Cambridge.
 Perrault C.
R.
, Allen J.
F.
, 1980.
 A plan based theory of indirect speech acts, American Journal of Computational Linguistics.
 6, 34.
 Wilensky R.
, 1981.
 Metaplanning: representing and using knowledge about planning in problem solving and natural language understanding.
 Cognitive Science.
 5.
 3.
 K'Mcl*.
! .
 ^ H ^ » ^ U ^ t ^ ^ ^ , Figure 1.
 The metastructure representing a conflict between two models.
 ACKNOWLEDGMEMT This research has been supported by a grant for the year 1982 of the Consiglio Nazlonale delle Ricerche, Comitate d1 Medicina.
 Gruppo d1 Sclenze del Comportamento.
 214 Kapresencaciveneaa Reconaldered Maya Bartfillel Hebrew University People's ceadency Co rely on represencaClvenesa (R) when making Judgments of the probability (P) of various events can result in two major Iclnds of fallacies.
 Those that are inherent In the very substitution of P by R, and those that accompany the reliance on R as a side effect.
 Ay the first I mean fallacies that result from the fact that the logic of similarity differs from the logic of P.
 Thus, adding detail to the description of some event enriches it, and may thereby enhance its Judged similarity to some criterion (Tversky, 1977).
 But this adding of detail also makes the event more specific, hence necessarily less probable.
 Kahneman & Tversky (K&T7 showed, e.
g.
, that Ss consider it more likely for Bjom Borg to lose the first set in a tennis match and then win the entire game than merely to lose tne first set, though the latter event includes the former.
 Fallacies that are sideeffects of R are those that result when the outcome of Judgment by R is not modified or integrated with other relevant considerations.
 £arly studies of P Judgments United certain common Judgmental errors Co R causally.
 In particular, people's tendency to neglect the effects of base rate, sample size and data reliability was seen aa resulting directly from the fact that these factors do not affect R.
 Later studies cast some doubt on this link, for the following reasons.
 a.
 These factors are sometimes ignored even in Rfree tasks.
 Consider, e.
g.
, the Suicide Problem (BU, 1980) A study of suicide among young adults found that the rate of suicide is 3 times higher aioong singles that among marrieds in this age group.
 Uhat would be the proportion of singles in a sample of suicide deaths of young adults? The common response to this problem is 7SZ.
 b.
 In Rfree tasks, these factors sometimes exhibit a systematic effect on judgments of P.
 E.
g.
, Ss Judge it more likely that a large sample would provide an accurate estimate of the population mean than a small sample, ceteris paribus (Bii, 1979).
 c.
 This effect Is sometimes manifest even in the presence of R.
 In one version of the Tom W.
 prediction task, subjects were lead CO expect either high or low predictive accuracy.
 While both groups gave essentially Che same predictions, Che low expected accuracy group expressed less confidence in their predictions.
 Thus, data reliability was not altogether ignored, though it wasn't properly combined with the R considerations either.
 Rather, it was translated into an expression of confidence in those considerations (KiT.
 1973; BH, 1981).
 As a result of such findings, K.
&T recently moderated their formulation of the R heuristic, saying: "The magnitude of R biases and the impact of variables such as sample size, reliability and base rate depend on the nature of the problem, the characteristics of the design .
.
.
", etc.
 It is illustrative to consider the role which normative statlcstical theory assigns these three neglected factors.
 Take a prototypical statistical problem, that of reconstructing the parameters of some population on the basis of a sample of data.
 In the case of pure estimation, statistical theory teaches us that many "essential characteristics" of samples are unbiased estimators of corresponding population parameters.
 Hence estimation reflects R.
 So does the statistical notion of goodnessofflt.
 When, on the other hand, altfimacive hypotheses compete, as in hypothesis testing, it Is a notorlaus fact that classical statistical theory (but not Bayeslan statistics) has no place for prior probability considerations.
 Yet these play the role that the base rate plays in prediction tasks such as Tom W.
 As to sample size and data reliability, their role in both estimation and hypothesis testUg lies in determining the width of a given confidence interval, but not the cenral value around which it la constructed.
 Analogously, these factors typically seem to effect Ss confidence in their predictions though not the predictions themselves.
 In the Bayeslan approach, P measures an internal state of uncertainty.
 Through the subjective filter all sources of uncertainty can be passed and integrated, and thus there IS no caj.
1 for higher order Fs.
 Psychologically speaking, however, people seem to distinguish between variants of uncertainty (IC&I, 1982), and so may hold 2nd order F distributions (e.
g.
, confidence) over 1st order P distributions (e.
g.
, propensities) that are, subjectively, nonlntegrable.
 It is compatible with points a.
, b.
 and c.
 above to hypothesize that R may be a heuristic for assessing Isc order Ps, and that factors which do not affect R may still influence 2nd order Ps.
 Whether they affect the ultimate P value may depend on the integrabillty of 1st and 2nd order considerations (BU.
 1982).
 It should be apparent that the attempt at drawing analogies between the intuitive treatment of variables and the one formalized by normative theories is in no way an apologia for people's fallacies, which are genuine and worrisome.
 Cohen (1981) claimed that since the "presence of fallacies in reasoning is evaluated by referring to normative criteria which ultimately derive their credentials from a systematlzation of the Intuitions that agree with them", people's deeply rooted statistical intuitions cannot.
 In principle, be fallacious.
 The point Is moot, however, since clearly the output of defensible intuitions may Itself be indefensible.
 So far, I have tried to make the case that R Is hot just a fundamental feature of lay Judgments under uncertainty, but of normative statistical theory as well.
 A world not governed by & might well be unthinkable.
 Just try to Imagine a breakdown of the "law of averages".
 Physically uniform coins fall on Heads much more often than on Tails; well shuffled decks of cards yield Hearts more frequently than other suits; repeated independent measurements yield skewed, blmodal distributions; etc.
 Such a world, to rephrase Einstein, can only be the creation of a God who Is not only subtle, but malicious as well.
 Even thou^ R may be essential to everyone's basic metaphysics, in particulars an 215 Ideal staclaclclan, IS, may apply R more astutely Co statistical Inference problems Chan a layperson, L.
 We will now consider some such parclculars, Che idea being Co show how refining R by simple, quallcacive, scaClsclcal principles can lead Co more appropriate solutions than R "In che raw".
 1.
 Predlcclng sample feacures by R.
 Often Che besc predlcclon for an as yec unobserved sample Is Chac It will resemble an already observed one, or che populaclon chac is ICs source.
 Clearly, however, Ic is coo much co expecc every feacure of che past sample to be repeated In che future one.
 Yec, sophlsclcaced respondents b«Ua«a4 thac, having ob talned a Just significant result in an experiment with 20 Ss, Che chances of now obcainlng a sl.
gnlflcanc result on a new aanple of 10 is 85Z (KAT, 1971).
 Result significance, however, is a somewhat arbitrary notion.
 Since it depends on Che sample size as well as the Q^an, expecting the sample mean to replicate (which is reasonable) should lead Co more uncercalnty about that mean's significance, since sample size was halved.
 Other respondents expected a sample (n>SO) from a population with mean100 Co have such a mean as well.
 They held on to that expectation even %rhen told that Che flrsc observation was 150.
 It is impossible for both Che unknown portion of che sample (n49) to repeat Che populaclon mean, and for Che sample aa a whole CO do so (K4T, 1972).
 In some school, program A consists of 65Z boys, while program B of 45Z boys.
 Ss expected classes belonging to Program A to resemble che program's con^oaitlon more than the other program's.
 The similarity of some class' proportion of males to 65Z versus 4SZ should be evaluated In terms of standard devladons.
 Ss seemed to evaluate it In terms of which sex was the majority, thus expecting a class of 53Z boys Co belong co Program A.
 11.
 Features of Gestalta versus feacures of data points.
 The acacidCleal prsperdea of samples are co^lecely decermlned by Che individual daca points of which chey are comprised.
 Feacures that accrue to the sample as a whole, but not co ics constituents (e.
g.
, its mean) are significant insofar as the individual data points are unknown or discarded.
 Thus, a sample whose mean is near the population mean is more likely, ceteris paribus, than one with a more deviant mean.
 But this order may be upturned ^ e n che specific data points are given.
 L seems co find ic difflculc CO Ignore che emergent properties of samples as Gestalts, even when they are completely specified.
 IS, on che ocher hand, woula ignore thses emergent properties when specific data points are available, dence, unlike L, IS, believing that deads and Talis.
 are equally likely outcomes for the toss of a fair coin, would consider any fully specified sequence of fixed length comprised of equlprobable outcomes to be equiprobable.
 Similarly, IS would Judge the P of a sai^le of ' fixed size drawn from a normal dlscrlbutlon to depend on the magnitude of the standardized deviation between che sample poincs and Che populaclon mean, rather Chan on its dlreccionallcy.
 (L's errors are documented in K.
&T, 1972, Ba.
 1980b).
 Clearly, che BJom Borg example ac Che beginning of this paper can also be understood in terms of emergent properties.
 The P value of wholes is derivable from their parts.
 The R value may not be.
 Summary.
 The reliance on R as a JudgmenCal heuristic is frequnCly Justifiable, and seldom avoidable.
 Tbe modification of R consiaeratlons by other considerations of relevance, and the refinement of the domain of R, its mecrlc, etc.
 is a goal to be sought.
 Inasmuch as the various Judgments of R embody mucn of our substantive knowledge regarding che issue being Judged, R can not be eliminated from che probabilistic reasoning process, but the different logic of R and P poses obstacles that must be watchad ouC for.
 References ba, 1979.
 The role of sample size in sample evaluation.
 OBhP.
 Bh, 1980.
 The base rate fallacy in probability Judgmencs.
 Acca Psychologies.
 BU, 1980b.
 Uhac feaCures moke samples appear represencacive? JEP:HP&P.
 BU, 1981.
 Represencativeness reconsidered.
 unpublished manuscript.
 OR report, Eugene.
 BH, 1982.
 Ideal evidence, relevance, and second order probabilities.
 Erkenntnls.
 Cohen, 1981.
 Can human Irrationality be experimentally demonstrated? BfiSS.
 'lUT, 1971.
 Law of small numbers.
 Subjective probability: A Judgment of represencaciveness.
 K&T, 1973.
 On che psychology of predlcclon.
 Varlancs of uncercaincy.
 Judgmentsof and by represents^.
 tiveness.
 (all these can be found in Kahneman, Slovlc & Tversky.
 Judgmenc under uncercalnty, '^' ^982) K&T, 1972.
 K4T, 1982.
 ^TiK.
 1982.
 216 