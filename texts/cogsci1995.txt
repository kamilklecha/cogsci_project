UntitledAnchors, Cases, Problems, and Scenarios as Contexts for Learning Cindy E Hmelo and N Hari Narayanan (Organizers) EduTech Institute and College of Computing Georgia Institute of Technology Atlanta, G A 303320280 c e h , n a r a y a n @ c c .
 g a t e c h .
 e d u Abstract The constructivist paradigm, which views learning as an active process in which students participate by engaging in activities that facilitate the construction of internal representations, is fast gaining currency as an innovative and effective way to overhaul classroom instruction.
 One way to promote constructivist learning is to firmly embed the acquisition of knowledge in realistic and stimulating contexts that challenge students to explore a variety of issues and employ a variety of their skills.
 This symposium will focus on four approaches (anchored instruction, casebased reasoning, goalbased scenarios, and problembased learning) designed to contextualize learning in this fashion.
 They do so in different, yet related ways.
 Examples of these approaches, ways in which they are similar and different, and important concerns regarding their effects on student learning and performance will be some of the issues that panelists will address.
 The panelists in this symposium are: Ray Bareiss, Institute for the Learning Sciences, Northwestern University; Cindy Hmelo, Janet Kolodner, and Hari Narayanan, EduTech Institute, Georgia Institute of Technology; Vimla Patel, Center for Cognitive Science, McGill University; and Susan Williams.
 School of Education and Social Policy, Northwestern University.
 Introduction Research on human cognition during recent years has begun to reveal the different ways (and contexts) in which humans acquire new knowledge and skills, and transfer previously learned knowledge and skills to new situations.
 This, in turn, has had the effect of undermining the traditional view of classroom instruction as a vehicle for transmitting facts from the teacher to the students (Brown, Collins, & Duguid, 1989; C T G V , 1990, 1993).
 It is being replaced by the view of learning as an active process; a process in which students, instead of being passive recipients, participate in the learning process by engaging in activities that facilitate the construction of internal representations and integration of new knowledge with the old.
 This signifies a fundamental paradigm shift in education from the traditional transmission model to a more learnercentered approach (Brown et.
 al.
, 1993).
 This paradigm shift is of critical importance not just to the education community, but to the cognitive science community as well, primarily because it is research on cognition, and on technologies that support and amplify human cognitive processing, that will both drive this paradigm shift and provide the tools to implement and assess it in the nation's classrooms.
 Therefore, our goal in this symposium is to expose the broader cognitive science community to the significant issues and problems in this area.
 Contextualizing Learning One way to promote constructivist learning in classrooms is to firmly embed the acquisition of knowledge skills and strategies as well as facts in realistic and stimulating contexts that challenge students to explore a variety of issues and engage a variety of their skills.
 A number of terms — such as anchored instruction, casebased learning, goalbased scenarios, learningbydoing, learningtolearn, problembased learning, self learning and reflective learning — have come into use, denoting different facets of this new view of learning.
 W e will focus on four facets in this symposium: the use of anchors, cases, problems and scenarios to facilitate learning and transfer.
 Anchors, cases and problems have all been proposed as contexts for learning (Barrows, 1985; C T G V , 1990; Kolodner, 1993; Williams, 1993).
 All three have the c o m m o n characteristic of being rich situations that can afford generative problemsolving.
 Learning from cases may afford several advantages.
 First, the learners will encode knowledge in a context that is similar to the one in which it will ultimately be used, enhancing the likelihood of appropriate retrieval and transfer.
 Second, the learners may construct mental models of the underlying domain knowledge that include conditions under which the knowledge is applicable.
 Third, learning from cases may provide the learner with a library of specific instances from which to reason.
 Some forms of casebased learning explicitly promote selfdirected learning skills as well.
 Several variations on the use of cases to enhance learning have been developed for diverse populations.
 Anchored instruction has been used widely in middle school mathematics mailto:narayan@cc.
gatech.
eduinstruction to promote the development of mathematical problemsolving skills and strategies.
 Problembased learning (PBL) is being used in medical schools in the U S and internationally to help students integrate biomedical science with clinical skills as well as facilitate the development of clinical reasoning strategies.
 Goalbased scenarios (GBS) provide frameworks for creating computerbased learning environments that promote learning while students pursue a set of specified goals (Schank, et al.
 1993).
 However, some researchers are more cautious in embracing these new approaches, arguing that these in fact may lead to more fragmented knowledge (Patel, Green, & Norman, 1993 but see Hmelo, 1995 for an alternative view).
 They have raised concerns about the deleterious effects that integrating fundamental and practical knowledge may have on the efficiency of reasoning, and about the adequacy and variety of reasoning strategies that students acquire (Patel, Arocha & Lecessi, 1995).
 In light of the increasing interest in applying these methodologies to disciplines other than medicine and to broader student populations, the strengths and limitations of these approaches as well as how to effectively implement them, supported by technology, in classrooms have all become issues that merit further research and discussion.
 This symposium aims to stimulate both discussion and additional research on these aspects.
 In particular, the speakers will address questions such as the following: • What makes for an effective anchor, case, problem, or scenario? In what ways are these similar or different? • H o w do these promote learning, integration, retention and transfer? H o w can these be used in the classroom most effectively? • Are there any disadvantages to using grounded instances in learning? If so, how can they be remedied? • H o w can technology be used to enhance, scaffold, and contextualize learning? What form should computerbased learning environments to support these approaches take? In the following sections we provide brief summaries of the four approaches that will be covered in the symposium: anchored instruction, casebased reasoning, problembased learning and goalbased scenarios.
 Anchored Instruction In anchored instruction, learning is situated in rich, multimedia contexts that afford opportunities for problem finding, exploration, and discovery.
 In this approach, rather than beginning with a set of facts to be learned, students are introduced to a videobased problem, one that will provide challenges to them as they attempt to solve it.
 The multimedia presentation of the problem presents a situation as one would see it in the world, though it is orchestrated so that it has embedded in it all the data that students need to solve the problem.
 As in the real world, the presentation does not make clear which of the presented material is relevant to problem solving and which is incidental.
 Students must learn to differentiate between relevant and irrelevant data.
 The goal is to have students find and define problems, generate subgoals, and think about them over an extended period of time.
 The problems used in this approach use a narrative format to present information and create a meaningful context for problem solving (CTGV, 1990).
 The problems that are used are much more complex than typical math word problems on the premise that students cannot learn to deal with complexity unless they have had the chance to experience it.
 CaseBased Reasoning Casebased reasoning (CBR) addresses both problem solving and learning within a single framework a framework built around the notion of using past experiences to solve current problems (Kolodner, 1993).
 The central idea in casebased reasoning therefore is that cases, in the form of interpreted and encoded descriptions of previous problems and their solutions, are the primary generators of inferences, suggesting current solutions to problems, pointing the way out of quandaries, allowing potential failures and errors to be anticipated and avoided, and focusing attention.
 As cases are used in interpreting and solving new problems, new cases are generated and stored in the memory  this is the learning component of CBR.
 A case typically has the following characteristics: • it describes a previously experienced episode of problem solving; • it is an interpreted and encoded knowledge structure; • it contains a rich variety of information, including  a description and important features of the problem that was solved,  the solution that was arrived at, and its important features, a process description of the solution process, decisions that were made, and their justifications (rationale),  outcomes that resulted from carrying out the solution,  evaluation of the success/failure of the solution in terms of its outcomes, and  aspects found to have led to the success or failure based on this evaluation.
 A case is indexed by the deep features of the problem, the solution, and its outcomes so that it can be retrieved based on similar problems or similar solution strategies that are being considered, or the expected outcomes.
 Cases can provide not only solutions that can potentially be adapted to fit a new problem, but also enable a learner to hypothesize the results of implementing a similar solution and provide warnings about potential pitfalls to avoid and successful avenues to pursue.
 In many domains, there is no well developed causal theory or the causal theory may be irregularly applicable across the variety of cases that a problemsolver may encounter.
 It is in these domains that cases can serve as valuable resources for both problemsolving and learning.
 ProblemBased Learning Problembased learning (PBL) is an educational methodology in which students learn by solving problems and reflecting on their experiences.
 In problembased learning, students face a problem situation with some high level goal that needs to be addressed, and learn by solving authentic realworld problems.
 Because the problems are complex, students work in groups, where they pool their expertise and experience and together grapple with the complexities of the issues that must be considered.
 Coaches guide student reflection on these experiences, facilitating the learning of the cognitive skills needed for problem solving, the full range of skills needed for collaboration and articulation, and the principles behind those skills.
 Because students direct their learning, skills needed for lifelong learning are also acquired, for they must manage their learning goals and strategies as they cope with problems set for them.
 Experience in medical and business schools shows that problembased curricula serve to enhance learning facts and concepts at a range of levels and to promote the learning of critical problem solving and collaboration skills needed for the workplace (Hmelo, 1994; Norman & Schmidt, 1992).
 The classical method of P B L was developed in medical schools (Barrows, 1985).
 Instead of the traditional lecturebased format, students learn biomedical science through solving problems.
 This form of P B L includes among its goals (1) developing scientific understanding through cases, (2) developing clinical reasoning strategies, and (3) developing selfdirected learning skills.
 In this approach, small groups of five to seven students and a facilitator meet to discuss a patient case.
 The students receive an initial scenario and then must question the facilitator to get additional case information.
 At several points in the case, the students pause to reflect on the data they have collected so far, to generate questions about the data, and to hypothesize about underlying causal mechanisms for the patient's problems.
 The students must also identify issues that they do not understand and need to learn more about.
 After considering the case with their naive knowledge, the students independently research the learning issues they have identified.
 They then share what they learned, reconsider their hypotheses and/or generate new hypotheses in light of their new learning.
 A significant transformation occurs as a result of the learning processes in PBL.
 The original problem which consists only of clinical data and some related background information becomes transformed into a case  comprising relevant symptoms from among those originally given to the students, the solution in terms of diagnostic hypotheses, an elaborated causal model that provides an account of how the hypothesized diseases give rise to the observed symptoms, conditions of applicability of this model, associational knowledge that links symptoms to hypotheses both positively and negatively, and connections to relevant and applicable scientific knowledge.
 W h e n the problem corresponds to an actual clinical case, the students also learn the outcomes of the diagnoses  the therapy plan, whether their diagnoses were accurate or not, and why.
 These correspond to the components of a case as defined in C B R  the problem and its features, the solution and its features, rationale, outcomes, and evaluative information in terms of the success or failure of the solution and the reasons behind it.
 Thus, what develops in P B L is an interpreted and encoded representation of an episode of problem solving as a case in memory.
 GoalBased Scenarios The motivating principle behind the development of goalbased scenarios as an educational framework as well as a framework for designing computerbased learning environments is that better learning can be achieved by presenfing students with problems in their domains of interest along with welldefined goals and the means for achieving these goals.
 Thus, a G B S is a learningbydoing task that requires a careful selection of materials to be taught, the goals students will pursue, the environment in which students will work, the subtasks that in the pursuit of their goals the students will engage in, and the resources that will be made available to the students.
 The scenarios are constructed and the goals are specified in such a way as to motivate students to accomplish the goals, and to enable them to acquire the necessary skills during this process of goalaccomplishment.
 Goalbased scenarios scaffold the acquisition of skills, by providing opportunities for the practice of skills in the pursuit of goals that also serve to illustrate the potendal ufility of these skills to students.
 The main components of a G B S , therefore, are a clear and concrete goal to be achieved, a set of target skills to be learned and practiced, and a task environment in which students will work.
 A G B S consists of a mission context and a mission structure.
 The mission context outlines the thematic aspects of a G B S by stating the goal students will pursue (called the mission) and the premises under which they will work (called the cover story).
 The mission structure describes the means by which students will pursue the mission, including the nature of the task involved (called the mission focus this may be, for instance, design.
 diagnosis, discovery, etc.
) and the activities students can undertake in pursuit of the mission (called scenario operations).
 Guidelines on how to effectively design a G B S are given in (Schank, et al.
 1993).
 Like the other approaches, GBS's are designed to allow students to learn within an realistic context.
 Summary This symposium is being organized around a set of four innovative approaches to learning, and the central issues and concerns that surround their deployment in classrooms.
 W e will illustrate the different approaches with concrete examples, and then discuss their similarities and differences as well as the important issues and concerns regarding their use.
 The symposium will be structured as a series of short illustrations and presentations, followed by an open discussion involving the audience.
 These proceedings should be of considerable interest to the broad cognitive science community because the issues that we will address have been derived from fundamental research on human cognition and artificial intelligence.
 It will touch upon issues such as learning from instances, analogical transfer, casebased learning and reasoning, situated cognition, and problem solving; issues that have been at the center of cognitive science research.
 Furthermore, what we are concerned with is the application of cognitive science research on learning and instruction to the real world problem and national priority of improving education.
 References Hmelo, C.
 E.
 (1995).
 Problembased learning: Development of knowledge and reasoning strategies.
 To appear in the Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society, Pittsburgh, PA.
 Kolodner, J.
 L.
 (1993) CaseBased Reasoning.
 San Mateo, CA: Morgan Kaufmann Publishers.
 Norman, G.
 R.
, & Schmidt, H.
 G.
 (1992).
 The psychological basis of problembased learning: A review of the evidence.
 Academic Medicine, 67, 557565.
 Patel, V.
 L.
, Groen, G.
J.
 & Norman, G.
R.
 (1993).
 Reasoning and instruction in medical curricula.
 Cognition and Instruction, 10, 335378.
 Patel, V.
 L.
, Arocha, J.
 F.
 & Lecessi, M.
 (1995).
 Reasoning and instruction in medical curricula: effects on resident performance.
 Paper presented at the Annual Meeting of the American Educational Research Association, San Francisco, CA.
 Schank, R.
, Fano, A.
, Bell, B.
 & Jona, M.
 (1993).
 The design of goalbased scenarios.
 The Journal of the Learning Sciences, 3(4), 305346.
 Williams, S.
 M.
 (1993).
 Putting casebased instruction into context: Examples from legal and medical education.
 The Journal of the Learning Sciences, 2(4), 367427.
 Barrows, H.
 S.
 (1985).
 H o w to design a problembased curriculum for the preclinical years.
 New York: Springer.
 Brown, A.
 L.
, Ash, D.
, Rutherford, M.
, Nakagawa, K.
, Gordon, A.
, & Campione, J.
 C.
 (1993).
 Distributed expertise in the classroom.
 In G.
 Salomon (Ed.
), Distributed Cognitions: Psychological and Educational Considerations (pp.
 188228).
 Cambridge, M A : Cambridge University Press.
 Brown, J.
 S.
, Collins, A.
, & Duguid, P.
 (1989).
 Situated cognition and the culture of learning.
 Educational Researcher, 18, 3241.
 Cognition and Technology Group at Vanderbilt.
 (1993).
 Anchored instruction and situated cognition revisited.
 Educational Technology, 33, 5270.
 Cognition and Technology Group at Vanderbilt.
 (1990).
 Anchored instruction and its relationship to situated cognition.
 Educational Researcher, 19(6), 210.
 Hmelo, C.
 E.
 (1994).
 Development of independent thinking and learning skills: A study of medical problemsolving and problembased learning.
 Unpublished doctoral dissertation, Vanderbilt University.
 Production System Models of Complex Cognition John R.
 Anderson Carnegie Mellon University Department of Psychology Pittsburgh, PA 15213 ja@cmu.
edu Bonnie E.
 John Carnegie Mellon University Computer Science & Psychology Dcpts.
 & HumanComputer Interaction Institute Pittsburgh, PA 15213 bejQcs.
emu.
edu Marcel A d a m Just and Patricia A.
 Carpenter Carnegie Mellon University Department of Psychology Pittsburgh, PA 15213 just@psy.
cmu.
edu carpenter@psy.
emu.
edu David E.
 Kieras and David E.
 Meyer University of Michigan Electrical Engineering and Computer Science DepL Ann Arbor, MI 48109 kierasQeecs.
umich.
edu Abstract There have been a number of production system models which have recently made substantial advances in modeling higherlevel cognition.
 These type of model offers only comprehensive approaches to the modeling of higher level cognition.
 This symposium will involve presentations by four exemplars of this approach to cognitive modeling (ACT, CAPS, EPIC, and SOAR).
 The presentations will try to illustrate the range of applications to which such models are appropriate, what the similarities and differences are among the various architectures, and what some of the interesting research questions are within each architecture.
 The A C T  R Theory ACTR (Anderson, 1993) is a model of human cognition which assumes that a production system operates on a declarative memory.
 It is a successor to previous ACT productionsystem models (Anderson, 1976, 1983) and continues the emphasis on activationbased processes as the mechanisms for relating the production system lo the declarative memory.
 Different traces in declarative memory have different levels of activation which determine their rales and probabilities of being processed by the production rules.
 A C T  R is distinguished from the prior A C T theories in that the details of its design have been strongly guided by the rational analysis of Anderson (1990).
 Essentially, A C T  R is a production system tuned to perform optimally given the statistical structure of the environment.
 According to the A C T theories, knowledge is divided into declarative knowledge and procedural knowledge.
 In ACTR, declarative knowledge is represented in terms of chunks which are schemalike structures, consisting of an isa slot specifying their category and some number of additional slots encoding their contents.
 Below is a graphical display of a chunk encoding the addition fact that 3+4=7.
 fact 3 + 4 isa addend 1 addend2 sum additionfact three four seven According to A C T , procedural knowledge, such as mathematical problemsolving skill is represented by productions.
 For instance, suppose a child was at the point illustrated below in the solution of a multicolumn addition problem: 531 + 248 9 Focused on the tens column, the following production rule might apply from the simulation of multicolumn addition (Anderson, 1993); PROCKSSCOLUMN IF the goal is to write out an answer in column cl and dl and d2 are digits in that column and d3 is the sum of dl and d2 T H E N set a subgoal to write out d3 in cl.
 The first clause in this production matches the current goal to process the tens column; the second clause matches the digits in the tens column; and the third clause matches a fact or chunk from longterm memory.
 According to the A C T  R theory, an important component of the time for this production to apply will be the time to retrieve the longterm memories required to match the production rule.
 So, in this case where 3 and 4 are in the mailto:ja@cmu.
edumailto:just@psy.
cmu.
edumailto:carpenter@psy.
emu.
eduhttp://umich.
educurrent column, the lime to match the last clause will be determined by the level of activation of the chunk encoding 3 + 4 = 7.
 The next subsection will explain how activation determines match time.
 The presentation will describe an ACTR model of memory span to illustrate the activation computations, limitations on capacity, and role of activation in partial matching.
 T h e S o a r Unified T h e o r y of Cognition Soar is a symbolic cognitive architecture that implements goaloriented behavior as search through a problem space.
 Complete discussions of Soar describe a hierarchy from an abstract knowledge level down to a hardware, or wetwaredependent technology level (Polk & Rosenbloom, 1994), but the two middle levels arc of primary interest when comparing Soar to other cognitive architectures.
 The problemspace level describes deliberate, goaloriented behavior; the architecture level implements the problemspace level and is concerned with the mechanisms of memoryretrieval and learning.
 At the problemspace level.
 Soar can be described as a set of interacting problem spaces, where each problem space contains a set of operators that are applied to stales to produce new states.
 A task, or goal, in a problemspace is modeled by the specification of an initial stale and one or more desired states.
 W h e n sufficient knowledge is available in the problem space for a single operator to be selected and applied to the current state, then behavior of a Soar model is strongly directed and smooth, as is skilled human behavior.
 W h e n knowledge is missing, either search in additional problem spaces may be necessary to locate the knowledge, or decisions must be made without the knowledge, leaving open the probability of errors, and thus, errorrecovery activities.
 This produces more complex branching and backtracking performance, as displayed in human problemsolving behavior.
 The architecture level is itself a hierarchy.
 At the lowest level, Soar consists of perceptual and moior modules that provide the means of perceiving and acting upon an external world.
 At the next level, associations, in the form of symbolic productions, match the contents of workingmemory (comprised of the inputs of perception, the output parameters for the motor modules, and purely internal structure) to retrieve additional information from longterm memory.
 In contrast to most classical production systems.
 Soar's associations match and fire in parallel, are limited in their action repertoire to the generation of preferences for the activation of workingmemory structure, and automatically retract these preferences when their conditions no longer match.
 Associations repeatedly fire and retract until no further associations are eligible to do so, then Soar's decisionlevel process weighs all the active preferences and chooses a new problemspace, operator, or state.
 Whenever the activations are not sufficient to allow a unique choice, the architecture responds by setting a subtask to resolve this impasse, and the entire process recurs.
 If the recursive processing adds new preferences that are active in the original task, Soar's architectural learning mechanism (called chunking) creates a new association between those workingmemory structures in the original task that led, through a chain of associations in the subtask, to the new preferences in the original task.
 Thus, chunking effectively transfers knowledge from the subtask space to the original task space.
 Chunking straightforwardly produces speedup, but can also inductively acquire new knowledge (Rosenbloom, Laird & Newell.
 1991).
 Using an estimate of 50 msec per decision cycle.
 Soar has been used to model human performance in many different realtime tasks, from visual search, to naturallanguage comprehension, to planning and problemsolving tasks.
 The presentation will emphasize the contribution of architectural constraint on integrating individuallydeveloped models in the service of highlevel tasks that require these component capabilities.
 3 C A P S Simulation Systems for M o d e l i n g a LimitedCapacity W o r k i n g M e m o r y 3CAPS is a CapacityConstrained, Concurrent, Activationbased Production System which instantiates a capacity theory of working memory (Just & Carpenter, 1992).
 The theory proposes that a major constraint in immediate processing in language comprehension, problem solving, and spatial reasoning is the amount of activation available to simultaneously perform cognitive compulations and actively maintain intermediate and final products.
 3CAPS instantiates the capacity theory in a symbolic processing environment (a production system) that incorporates several activationbased, connectionist mechanisms.
 First, the representations are graded, in that each representational element has an associated activation level ihai changes when a production either increments or decrements ii, or when there is a global deallocation of activation.
 An element can enable a production to fire only if its aclivaiion level is above some threshold.
 Second, the processing is graded in that the productions do ihcir work gradually, over several cycles of the production system, by incrementally propagating activation from source elements to output elements, until the target elements reach threshold or some other process intervenes.
 Third, all satisfied productions can fire in parallel.
 The model's assumptions include: 1.
 There is a limited amount of activation to support bolh information maintenance and computations.
 The demand for activation differs among tasks.
 10 producing cognitive performance differences in response times and error rales.
 Individuals differ in the amount of the activation resources that they possess, accounting for some of the systematic individual differences in cognitive performance.
 2.
 In the event of activation demand exceeding the supply, activation is partially deallocated both from the processing function (producing a slowing of processing because the productions will require more cycles to propagate a given amount of activation), and from the maintenance of previously computed partial products (producing forgetting).
 3.
 Capacity utilization, some measure of the proportion of the resource pool that is being consumed in a given time interval, is determined conjointly by the size of an individual's resource pool and by the demand of a given tiisk.
 Capacity utilization can be measured in the models as the proportion of the resource pool that is in play.
 In experimental studies, capacity utilization may correspond to workload or effort, and may be manifested in physiologically based measures of performance, such as brain activation, pupillary response, and ERPs.
 Moreover, these capacity utilization effects can be evaluated as they are engendered by lask effects and by individual differences.
 The 3CAPS system can be used for modeling diverse tasks such as sentence comprehension (Just & Carpenter, 1992), story comprehension (Goldman & Varma, 1995), and humancomputer interaction (Huguenard, Lerch, Junker, Patz, & Kass, 1993) and in aphasic comprehension (Miyake, Carpenter, & Just, 1994).
 The presentation will describe recent 3CAPS models that illustrate the effects of individual differences and capacity constraints.
 T h e E P I C Architecture Computational Models of H u m a n Performance EPIC (Executive ProcessInteractive Control) is a computational framework for constructing models of human informationprocessing and performance which couples perceptualmotor mechanisms with a productionsystem representation of procedural skill.
 EPIC has a productionrule cognitive processor surrounded by perceptual and motor peripheral processors whose properties are based on the current research literature.
 W c are pursuing two lines of work with EPIC: One is detailed analyses of multimodal, highperformance humancomputer interaction situations, the other is understanding executive processes in human muliiplcia.
sk performance.
 Our key principles can be summarized as follows: 1.
 Our computational models are built in terms of a detailed general architecture that covers human perceptual, cognitive, and motor mechanisms, and which is required to be accurate and applicable across uisk domains.
 2.
 A central role is given to cognitive strategies for task execution, which we represent using production systems.
 3.
 Executive processes for coordinating multiple titsks are treated simply as additional strategies, and likewise are represented with sets of production rules.
 4.
 EPIC does not assume an inherent centralprocessing bottleneck.
 W e attempt to explain performance limitations in both single and multipletask situations in terms of the strategic effects of the task instructions, limited working memory capacity, and perceptualmotor constraints.
 Thus unlike the heavy emphasis on purely cognitive processes in many modeling efforts, we have undertaken a detailed and explicit consideration of how perceptual and motor mechanisms interact with cognitive mechanisms to determine human abilities and limitations.
 Our presentation provides a brief description of the EPIC architecture and a summary of how we have applied EPIC to humancomputer interaction problems and complex dualtask performance.
 References Anderson, J.
 R.
 (1976).
 Language, memory, and thought.
 Hillsdale, NJ: Eribaum.
 Anderson, J.
 R.
 (1983).
 The architecture of cognition.
 Cambridge, M A : Harvard Unviersity Press.
 Anderson, J.
 R.
 (1993).
 Rules of the mind.
 Hillsdale, NJ: Eribaum.
 Goldman, S.
 R.
, & Varma, S.
 (1995).
 CAPing the constructionintegration model of discourse comprehension.
 In C.
 A.
 Weaver, S.
 Mannes, & C.
 R.
 Fletcher (Eds.
), Discourse comprehension: Essays in Honor of Walter Kinl.
'ich.
 (pp.
 337358).
 Hillsdale, NJ: Eribaum.
 Huguenard, B.
 R.
, Lerch, F.
 J.
, Junker, B.
 J.
, Patz, R.
, & Kass, R.
 (1993).
 Modeling working memory failure in phoncbascd interaction.
 Working Paper, Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, PA.
 Just, M.
 A.
, & Carpenter, P.
 A.
 (1992).
 A capacity theory of comprehension: Individual differences in working memory.
 Psychological Review.
 99, 122149.
 11 http://muliiplcia.
skMiyake.
 A.
.
 Carpcnier, P.
 A.
, & Just, M.
 A.
 (1994).
 A capacity approach to syntactic comprehension disorders: Making normal adults perform like aphasic patients.
 Cognitive Neuropsychology, 11,61\1\1.
 Polk, T.
 A.
 & Roscnbloom, P.
 S.
 1994.
 Taskindependent constraints on a unified theory of cognition.
 In F.
 Boiler & J.
 Grafman (Eds.
), Handbook of Neuropsychology, Volume 9.
 Amsterdam, Netherlands: Elsevier.
 Rosenbloom, P S.
, Newell, A.
, & Laird, J.
 E.
 (1991).
 Towards the knowledge level in Soar: The role of the architecture in the use of knowledge.
 In K.
 VanLchn (Ed.
), Architectures for Intelligence.
 Hillsdale, NJ: Erlbaum.
 12 Using Highdimensional Semantic Spaces Derived from Large Text Corpora (A Symposium at the 1995 Annual Cognitive Science Meeting) Curt Burgess Department of Psychology 1419 Life Sciences Building University of California, Riverside Riverside, C A 925210426 curt@cassandra.
ucr.
edu G a r y Cottrell Institute for Neural Computation Computer Science and Engineering Dept.
 0114 University of California, San Diego La Jolla,CA 920930114 gary@cs.
ucsd.
edu Abstract Attempting to derive models of semantic memory using psychometric techniques has a long history in cognitive psychology dating back at least to Osgood (1957).
 Many others have used multidimensional scaling on human judgements of similarity (e.
g.
, Shepard, 1962, 1974; Rips, Shoben, & Smith, 1973; Schvaneveldt, 1990).
 Recently, a small group of investigators have been using large corpora, 1 million to 500 million words, to develop cognitively plausible highdimensional semantic models without the need for human judgements on stimuli.
 These models have become increasingly better at explaining a wide range of cognitive phenomena as they move beyond simple cooccurrence statistics.
 Introduction Forty years ago at the University of Colorado (May 1214, 1955), a symposium was convened to discuss "Contemporary Approaches to Cognition" (Bruner, 1957).
 A smaller more specialized meeting such as this was crucial, according to Karl Muenzinger (1957), since the annual meeting of the A P A had grown too large.
 Issues under debate included the tenability of structural vsassociationist accounts of cognition.
 It was at this meeting that Charles Osgood (1957) presented the beginnings of his theory of highdimensional semantic space which was derived from his semantic differential measuring technique.
 He notes that this was a line of research that simply would not have been possible without the latest in highspeed computing (ILLIAC, the Illinois digital computer).
 Forty years later at the University of Pittsburgh (July 2225, 1995), a symposium was convened to discuss contemporary approaches to cognition.
 A smaller more specialized meeting such as this was crucial, according to Curt Burgess and Gary Cottrell, since the annual meeting of the fill in your professional meeting name here— had grown too large.
 Issues under debate included the tenability of structural vs.
 associationist accounts of cognition.
 It was at this meeting that a small group of investigators presented the beginnings of their approaches to developing highdimensional semantic space which was derived from methods from computational linguistics and cognitive science.
 It was noted that this was a line of research that simply would not have been possible with the latest in highspeed computing.
 How times have changed.
.
.
 Highdimensional semantic space models are beginning to account for a wide range of phenomena: synonym judgements, semantic constraints in parsing, various semantic priming effects, lexical ambiguity retrieval, the typicality effect, lexical/semantic access, as well as other memory and languagebased data.
 These highdimensional semantic models have implications for theories of concept and language acquisition, as well as information storage.
 Furthermore, there is a close linkage between applied and theoretical aspects of knowledge representation, particularly as it involves information retrieval and storage systems.
 One advantage of the corpusbased research discussed in this symposium is the ability to rely on computationally intensive procedures to build largescale semantic representational systems.
 These models acquire conceptual representations without supervision with the resulting semantic systems becoming increasingly plausible from a cognitive perspective.
 Over the last 30 years, the range of phenomena to be dealt with has expanded, the methodological tools have become more sophisticated, the representational structures are richer, and there has been a sharp rise in interdisciplinary efforts.
 Times have changed.
.
.
 At this symposium, we ask those in attendance to do what Charles Osgood once requested .
.
.
 "imagine a hypothetical semantic space of some unknown number of dimensions" (Osgood, 1971, pg.
 7).
 Symposium Participants The following papers were presented in this symposium: The Promise of Highdimensional Semantics Curt Burgess, University of California, Riverside Constructing Highdimensional Semantic Spaces: Mysteries Revealed Kevin Lund, University of California, Riverside Hyperspace Analogue to Language (HAL): A General Model of Semantic Memory Curt Burgess, University of California, Riverside 13 mailto:curt@cassandra.
ucr.
edumailto:gary@cs.
ucsd.
eduWords and their Contextualizations Corpusbased Representations of Context Hinrich Schuetze, Center for the Study of Language and Information, Stanford University Latent Semantic Analysis as a Model of Memory and Knowledge Representation Thomas Landauer, University of Colorado Lexical Access with Internet Semantics Dan Clouse & Gary Cottrell, University of California, San Diego Highdimensional Semantics: Lost in vector space? Gary Cottrell, University of California, San Diego References Bruner, J.
 (Ed.
).
 (1957).
 Contemporary approaches to cognition.
 Cambridge, M A : Harvard University Press.
 Muenzinger, K.
 Introduction (pp.
 14).
 In J.
 Bruner (Ed.
), Contemporary approaches to cognition.
 Cambridge, M A : Harvard University Press.
 Osgood, C.
E.
 (1957).
 A behavioristic analysis of perception and language as cognitive phenomena (pp.
 75118).
 In J.
 Bruner (Ed.
), Contemporary approaches to cognition.
 Cambridge, M A : Harvard University Press.
 Osgood, C.
E.
 (1971).
 Exploration in semantic space: A personal diary.
 Journal of Social Issues, 27, 564.
 Shepard, R.
N.
 (1962).
 The analysis of proximities: Multidimensional scaling with an unknown distance function.
 I.
 Psychometrika, 27, 125140.
 Shepard, R.
N.
 (1974).
 Representation of structure in similarity data: Problems and prospects.
 Psychometrika, 39, 373421.
 Rips, L.
J.
, Shoben, E.
J.
, & Smith, E.
E.
 (1973).
 Semantic distance and the verification of semantic relations.
 Journal of Verbal Learning and Verbal Behavior, 12, 120.
 Schvaneveldt, R.
W.
 (1990).
 Pathfinder associative networks: Studies in knowledge organization.
 Norwood, NJ: Ablex.
 Smith, E.
E.
, Shoben, E.
J.
, & Rips, L.
J.
 (1974).
 Structure and process in semantic memory: A featural model for semantic decisions.
 Psychological Review, 81, 214241.
 14 Brain Imaging and its impact on the development of Cognitive Science Walter Schneider (Organizer) Learning Research & Development Center University of Pittsburgh, P A 15221 schneider@vms.
cis.
pitt.
edu Abstract This symposium will address the new data and challenges presented by recent advances in brain imaging methodology.
 It will include tutorials on the available techniques: Positron Emission Topography (PET), Functional Magnetic Resonance Imaging (fMRJ) and combined fMRI & high density Evoked Response Potentials (ERP).
 The impact of these techniques on the physiological interpretation of human working memory will be illustrated.
 In the last five years there have been major advances in brain imaging methodology that provide the ability to look into the brain to identify the biological processes underlying cognition.
 Noninvasive techniques now allow tracking of neural activity by monitoring blood flow (PET, fMRI), specific chemical reactions (PET) and high speed electrical changes (ERP).
 The combinations of all of these techniques allow tracking of: the size and extent of processing with millimeter resolution, the nature of some of the chemical reactions, and the time course of the network cortical activity.
 Availability and limitations of each methodology will be discussed.
 Temporal resolution of fMRI is in the seconds range.
 By combining techniques w e can create millimeter and millisecond maps of cortical function detailing the biological network interactions.
 The implications of such maps to the understanding of network cognitive processing will be commented upon.
 There will be five speakers and a panel discussion.
 Abstracts of the five talks are presented below.
 P E T mapping activity and chemistry of cognitive function.
 Cameron S.
 Carter (Western Psychiatric Institute & Clinic University of Pittsburgh) & Mark Mintun (University of Pittsburgh Medical Center).
 Positron emission tomography, or PET, allows the in vivo human brain imaging of a variety of regional physiological variables.
 While cerebral blood flow and cerebral metabolic rate of glucose are the most c o m m o n measurements made, more complex studies to quantitative the distribution of various receptors, the occupancy of receptors with neurotransmitters, and the rate of synthesis and release of neurotransmitters are increasingly common.
 A n understanding of P E T methodology and its limitations and potential applications requires an understanding of the three basic components of positron emission tomography.
 The first component involves the instrumentation required for imaging the radioactivity distribution within the brain.
 The basic principles of coincidence detection, which makes P E T unique compared to other in vivo radioisotope imaging, will be presented.
 The dramatic impact of the recently developed threedimensional acquisition schemes will also be reviewed.
 The second component of P E T is radiochemistry.
 The principles and limitations of using radiotracers to probe regional neurochemistry and brain function will be presented.
 Finally, the study design and data analysis component which allows the P E T measurements of radioactivity to be interpreted in physiologic terms will be introduced.
 Focus will be on studies to detect regional brain changes to cognitive task and drug intervention.
 This methodology will be contrasted with the techniques required to quantitate receptor physiology.
 Functional M R I : Methods and Applications.
 Keith R.
 Thulbom ( M R Research Center, University of Pittsburgh Medical Center).
 The use of functional MRI to probe the hemodynamic response of the human brain to changing neuronal activity during cognitive processing is a promising tool for cognitive neuroscience.
 To reach its full potential, the M R I technology must be integrated with different 15 mailto:schneider@vms.
cis.
pitt.
eduneuropsychological methodology.
 This requires an interdisciplinary team of investigators and the opportunity to design optimally the technology for this application.
 The newly instituted M R Research Program at the University of Pittsburgh Medical Center has provided this environment.
 The two M R scanners at 1.
5 and 3.
0 Tesla have been designed for fMRl at high spatial and temporal resolution.
 The routine performance of high quality fMRl studies has been achieved through the use of a customized control system for presentation of audiovisual stimuli in concert with image acquisition, physiological monitoring and task performance measures.
 This system will be described, and results of its use in probing various sensory and cognitive functions will be described.
 ERP and flVIRI multimodality constraints of activity  Providing temporal as well as spatial data on cognitive function.
 Michael Worden , Walter Schneider (University of Pittsburgh) HighDensity EventRelated Potential (HDERP) recording provides excellent temporal information (in the 10 m s range) indexing cortical information processing but is limited in the spatial information which it supplies.
 Functional Magnetic Resonance Imaging (fMRl) provides highresolution spatial information (approximately 1 m m inplane resolution) about active brain areas but little information about the time course of activity in these areas.
 W e combine these techniques such that the strengths of one technique constrain the shortcomings of the other.
 W e use scalp electrical data to determine the timecourses of activation for the functional regions identified with fMRl.
 Using a multiframe visual targetsearch paradigm, evoked potentials are recorded using a sixtytwo channel E R P recording array.
 Discrete areas of cortical activation are identified using fMRl scanning on a conventional 1.
5 Tesla M R I scanner while the subject performs the identical paradigm.
 This provides information on the number of active generators as well as detailed anatomical information about the configuration and orientation of the generators.
 The areas of cortical activation determined with fMRl are used to model the potential fields which are recorded under the same paradigm using H D  E R P Electrode locations and skull landmarks are digitized for each subject to permit coregistration of the E R P data with the fMRl data.
 The analysis includes an assessment of the goodnessoffit of forwardsolution models for early visual components constrained by fMRIdefined areas of activation.
 Using the combined techniques w e measure human attentional processing.
 P E T studies of verbal working m e m o r y Edward E Smith, John Jonides, and Robert Koeppe (University of Michigan).
 Subjects performed various verbal working memory tasks while being scanned.
 Our results indicate that verbal working memory contains two components: a storage component that is partly mediated by structures in lefthemisphere posterior parietal cortex, and a rehearsal component that is mediated by structures in frontal cortex that are known to be involved in explicit speech, including, among others, Broca's area.
 Functional IMRI Studies of Working Memory and Prefrontal Cortex Jonathan D.
 Cohen (Carnegie Mellon University & Western Psychiatric Institute & Clinic University of Pittsburgh) & Todd S.
 Braver (Carnegie Mellon University).
 Prefrontal cortex (PFC) has long been implicated in a variety of higher cognitive functions, including working memory.
 In this presentation, w e describe a series of studies using fMRl to examine the role of PFC in working memory.
 All studies used a sequential letter memory task, which required that subjects continually update and maintain information about the identity and sequential order of letter stimuli.
 The first three studies established: a) the ability of fMRl to detect activation of PFC during this task; b) the comparability of these findings to those using a different neuroimaging method (PET); and c) the testretest stability of findings within individual subjects.
 The fourth experiment parametrically manipulated memory load, demonstrating a monotonic increase in the area and intensity of activation as a function of load.
 The final experiment varied the type of information that had to be maintained in working memory (letter identity vs.
 spatial location), in an effort to determine whether representations are supported by different regions of prefrontal cortex.
 Taken together, these studies demonstrate the usefulness of fMRl for studying the neural basis of higher cognitive processes and, in particular, provide new, more detailed evidence concerning the involvement of PFC in working memory.
 16 P a p e r Presentations Modeling the Perception of S p o k e n W o r d s M.
 Gareth Gaskell Centre for Speech and Language, Psychology Department, Birkbeck College, Malet Street, London W C I E 7 H X g.
gaskell@psyc.
bbk.
ac.
uk Abstract We present a new distributed connectionist model of the perception of spoken words.
 The model employs an internal representation of speech that combines lexical information with abstract phonological information.
 W e show how a single distributed representation of this type can form the basis for the perception of words and nonwords alike.
 The model is tested against lexical and phonetic decision data from MarslenWilson and Warren (1994).
 These experiments examined the integration of cues to place of articulation diuing lexical access and showed a pattern of results which proved difficult to accommodate in previous models.
 The use of a single, late, phonological representation allows this pattern of results to be simulated and has the potential to incorporate many other properties of the human system.
 Introduction This paper describes a new approach to the perception and recognition of spoken words.
 This departs from previous approaches by postulating a fundamentally different relationship between speech input, lexical representations of meaning and form, and the listener's perceptual experience of speech.
 The conventional approach, standard across essentially all current theories and models, assumes a processing architecture where speech is first analyzed in terms of some form of prelexical phonological unit (such as strings of phonemes or syllables) constituting a separate level of perceptual and computational representation.
 This prelexical level forms the input to the mental lexicon and is the basis for the listener's perceptual experience of the speech stream.
 W e argue, instead, that there is no such prelexical level, that the speech input, analyzed in featural terms, is mapped directly onto combined phonological and lexical representations, and that the listener's perceptual representation of speech is an abstract postlexical product of the system.
 Evidence for the abstractness of the phonological percept comes from a series of studies of phonological variation (Lahiri & MarslenWilson, 1991; Gaskell & MarslenWilson, 1994).
 These indicate that subjects have relatively little awareness of the surface form of speech.
 Instead, they base phonological judgments on the abstract representation of speech that underlies surface variations.
 Evidence that the phonological percept is a late product of the perceptual system comes from studies of the integration of phonological cues in speech perception.
 In particular, lexical and phonetic decision data in MarslenWilson and William D.
 MarslenWilson Centre for Speech and Language, Psychology Department, Birkbeck College, Malet Street, London W C I E 7 H X w.
 m a r s l e n  w i l s o n g p s y c .
 b b k .
 a c .
 u k Warren (1994; henceforth MW94) argue against the prelexical integration of phonetic cues into segmental or similar units.
 Here we describe a distributed connectionist model that operates on these premises.
 The model's behavior in simulations of lexical and phonetic decision closely mirrors human performance in the M W 9 4 experiments.
 This success, contrasting with the failure of localist models to account for these data, is based on the use of a single, postlexical level of phonological representation, providing the basis for the listener's perceptual experience of words and nonwords alike.
 This model, it also turns out, provides a successful framework for explaining a wide range of properties of human spokenword recognition (Gaskell & MarslenWilson, in preparation).
 Experimental Background MarslenWilson and Warren examined the integration of featural cues to segment identity in words and nonwords.
 They created crossspliced monosyllabic words and nonwords that contained conflicting cues to the place of articulation of the final consonant.
 For example, subjects might hear a token consisting of the initial consonant and vowel of jog, followed by the final consonant burst of job.
 The vowel transitions here point to a final velar consonant (the [g] from jog), which conflicts with the place information in the burst, indicating a labial consonant (the [b] from job).
 The purpose of the experiments was to examine the effects of these conflicts between cues as a function of the lexical status of the stimuli involved, and of the task the subjects were performing.
 As summarized in Table 1, triplets of monosyllables containing either one word and two nonwords or two words and one nonword were crossspliced to produce six types of stimulus.
 These varied in terms of the presence or absence of mismatching cues and in the lexical status of the pre and postsplice components.
 In a lexical decision experiment, where subjects make a timed judgment as to whether the stimulus is a word or not, there were interference effects for all mismatch conditions except N3N1, where the stimulus as a whole formed a nonword, and where both pre and postsplice components derived from a nonword.
 Surprisingly, a very similar pattern was found in a phonetic decision task, where subjects make a timed forcedchoice judgment as to the identity of the final consonant of the stimulus (e.
g.
, between "g" and "b").
 There were again strong interference effects for all 19 mailto:g.
gaskell@psyc.
bbk.
ac.
ukhttp://ac.
ukmismatch conditions, but a greatly reduced effect for m m .
 Table 1: MW94 experimental contrasts Lexical Status Code Example Word Sequences Word! + Wordl Word2 + Wordl NonwordS + Wordl Nonword Sequences Nonwordl + Nonword 1 Word2 + Nonwordl NonwordS + Nonwordl WlWl W2W1 N3W1 NlNl W2N1 N3N1 jfib + jot jog +job jfid + job smob + smob smog + smob angd + smob Note: The underlined sections represent the segments spliced together to create the stimuli.
 We drew two main conclusions from these results.
 First, that lexical decisions and phonetic decisions were based on the same processing substrate, and second, that this substrate supported a complex pattern of interactions between the featural and lexical aspects of speech.
 A further simulation study using the localist T R A C E model indicated that these results could not readily be modeled by a processing system of the classical sort, where lexical effects on phonetic decisions are accounted for in terms of topdown interactions from the lexical level to an independent prelexical phonemic level.
 W e proposed instead a processing architecture of the type developed here, where the computational substrate for lexical and phonetic decisions is the same distributed representation, simultaneously encoding the mappings from speech input onto a phonological representation and from speech input onto a representation of lexical (or semantic) identity.
 Modeling Assumptions Our model is based on a small number of assumptions about the perception of speech.
 These are partly drawn from previous models of speech perception (e.
g.
, Morton, 1969; McClelland & Elman, 1986; MarslenWilson, 1987) and partly based on a functional analysis of the perceptual system.
 The principal assumptions are: 1) Lexical knowledge is represented in a fully distributed fashion.
 2) Different forms of lexical knowledge (e.
g.
, phonology, semantics) are represented at the same level and accessed simultaneously.
 3) Speech input maps directly and continuously onto lexical representations.
 4) The lexical access process operates with maximal efficiency by extracting the most informative lexical representation at all points during the perception of speech.
 The value of distributed representations in the modeling of cognitive functions is well documented (e.
g.
, Hinton, McClelland & Rumelhart, 1986; Hinton & Shallice, 1991).
 W e envisage the lexical entry for a word to be a distributed pattern representing the semantic, syntactic, morphological and phonological specification of that word.
 These representations can be conveniently described in microfeatural terms (e.
g.
, Plaut & Shallice, 1993).
 W e also assume that units of lexical representation are not duplicated, in that the goal of lexical access—the activation of a single complete lexical representation—fills the representational space.
 This view of the lexical access process differs radically from currently popular models of word recognition such as T R A C E and Cohort, which view the process of selection between candidates as a parallel localist process of competition.
 Instead of mapping speech input onto many localist representations, w e shall explore the possibility that lexical selection operates on a single distributed level of representation.
 Our model also differs from standard models in the ordering of different forms of information.
 Generally, phonological knowledge is seen as more "lowlevel" than semantic or syntactic knowledge.
 Almost all models suppose that a prelexical segmental (or similar) representation of speech is computed and that lexical access operates by matching this to phonological representations of words in an input lexicon.
 Thus, phonological representations are seen as the key to the lexical entries of words.
 Our model contains no such intrinsic ordering, with different forms of knowledge corepresented at the same level of the system.
 W e are not trying to claim that the goodness of fit between the speech stream and stored representations does not rely on phonological information, but w e propose that internal representations of phonological form are highly abstract and that no segmental representation of speech mediates in the lexical access process.
 By this view, the perception of a word and the perception of a wordlike nonword (or an unfamiliar word) differ only in the degree to which different types of information are accessed.
 The perception of a word leads to the activation of all forms of lexical knowledge whereas the perception of a nonword leads only to the retrieval of phonological information, which is abstracted by the same process as that operating on words.
 The assumption of maximal efficiency implies that at all points our model must derive the most informative output available from its analysis of incoming speech.
 Thus, if it is possible to isolate a single lexical match to the current input (i.
e.
, at the word's uniqueness point), the relevant information about that word should be extracted.
 At other points, where more than one lexical entry matches the speech presented so far, the output of the model should reflect this ambiguity and activate the stored knowledge about these candidates.
 Thus, the network should simultaneously entertain multiple hypotheses about the lexical identity of incoming speech, as do the majority of current models of speech perception.
 However, the distributed nature of the lexical representations used in our model places limitations on the effectiveness of the parallel evaluation of multiple candidates.
 Our model assumes that speech is mapped more or less directly onto distributed representations of lexical knowledge, implying that multiple lexical candidates can only be evaluated by their influence on this level of representation rather than at some independent stage of competition (as assumed in models such as T R A C E and Cohort).
 Since different lexical candidates will generally have different lexical representations, this suggests that they will interfere, producing a lexical "blend" of the various candidates.
 20 N e t w o r k Architecture To allow the network to generalize over patterns of phonetic features spread across time, the model is based on a simple recurrent network architecture (Elman, 1990; Norris, 1990).
 The network is trained on the mapping between a stream of phonetic features and an internal representation of words.
 The featural input is passed through a set of 200 hidden units, which have access via recurrent links to the state of the hidden units at the previous timestep.
 The hidden units are also connected to two sets of output units, representing the phonology and the lexical (or semantic) identity of the words contained in the speech stream (see Figure 1).
 From the perspective of the M W 9 4 results, this is the crucial property of the model, since it means that the same substrate (the hidden unit weight space) is simultaneously coding both the phonological mapping and the lexical mapping.
 Our hypothesis is that this will allow the model to simulate the experimental results, in a situation where the same phonological output layer represents both words and nonwords.
 For the purposes of this initial model, lexical/semantic identity was distributionally represented by an arbitrary vector of 50 zeros and ones.
 The phonological output was based on a slight adaptation of the Plaut & McClelland (1993) monosyllabic word representation.
 This is a compact phonemic representation of monosyllabic words, divided into 3 groups of units corresponding to syllable onset, rhyme and coda.
 Within each group, phonemes are represented by single units.
 This representation provides a basis for decisions involving the form of speech.
 The use of phonemes here is a representational convenience.
 W e assume that a segmental representation of speech emerges as a product of the interaction between orthographic and phonological knowledge in literate speakers of alphabetic languages (MarslenWilson & Warren, 1994; Morals, Bertelson, Cary & Alegria, 1986; Read, Zhang, Nie & Ding, 1986).
 Auditory input to the network was represented segment by segment on a set of 13 binary input units.
 Eleven of these encoded the phonetic features of the current input segment using the Jakobson, Fant and Halle (1952) feature system.
 To simulate the coarticulatory spread of place information between consonant and preceding vowel, we added two further feature units.
 These were set to zero for all segments except vowels immediately preceding nasal or stop consonants.
 For these vowels, the two features represented the place of the following consonant, mirroring the diffuse and grave feature values for that consonant.
 Consistent with evidence for the relative weakness of the vowel transition cues to place (e.
g.
, Warren & MarslenWilson, 1987) these cues were made probabilistic during training: cues were correct (i.
e.
, agreed with the place of the consonant) 7 0 % of the time, with the remaining 3 0 % of vowel cues consistent with either of the other two places of articulation used in the stimulus triplets.
 The network was trained to perform the joint phonological and semantic mapping for a set of 36 monosyllabic words drawn from the M W 9 4 test words.
 These comprised the unspliced words required to create 24 spliced triplets (12 word triplets and 12 nonword triplets) for testing.
 All words ended with a single consonant which was either a nasal (/n/, /m/, or /ng/), a voiced stop (/d/, /b/ or Igl) or an unvoiced stop (/t/, /p/ or /k/).
 These were presented as input to the network in the form of sequential bundles of phonetic features.
 To maintain a more realistic learning environment for the network, a number of other words were added to the training corpus.
 Firstly, a set of 71 words were added to simulate the competitor environment for the test words.
 These were all close cohort competitors, sharing initial C(C)V segments with the target words but diverging on the final consonant cluster.
 This gave the lest words an average of 3.
5 close competitors (range 010).
 In addition, the token frequencies of the training set were manipulated, reflecting the skewed distribution of word frequencies in English (Zipf, 1965).
 Test words were all given a token frequency of 20 within the training corpus.
 The cohort competitors were then assigned random frequencies between 1 and 40, with a mean frequency of 20.
 A further 2998 monosyllables, taken from the simulations of Plaut and McClelland (1993), were added to the training corpus, with a token frequency of 1.
 This corpus was presented to the network 50 times during training.
 O n each cycle, the 13 input nodes were activated with the phonetic pattern of one segment of a word and the network was trained, using backpropagation, to produce the correct semantic and phonological patterns I Phonology] Lexica Semantics Hidden Layer Context Layer Current Features OUTPUT HIDDEN UNITS INPUT (phonetic features) Figure 1.
 Network Architecture 21 for thai word.
 The network was then tested on a set of stimuli designed to simulate the test conditions of M W 9 4 (see Table 1).
 The W l W l and N l N l baseline stimuli all contained vowel place cues that matched the place of the following segment.
 All other stimuli contained mismatching cues to the place of articulation of the final consonant.
 For example, the W 2 W 1 stimuli contained place information in the vowel conforming with the W 2 word combined with the final consonant of W l .
 Only the word tokens had been presented to the network during training.
 The test words were presented to the network in a random order, with each test item preceded by two filler words.
 The phonological and semantic activations were recorded at each timestep.
 Results Lexical Decision Following other researchers we assume that output error scores correlate with response times in a cascaded processing system.
 W e also assume that a lexical decision response depends predominantly on the lexical/semantic rather than phonological output of the model.
 Error scores at the semantic output can be transformed into word activation values using the function: W 2 W 1 than N 3 W 1 tokens.
 The model therefore predicts that both mismatching tokens should delay the recognition of the target to an equal extent.
 word activation = 25XK.
 isl 25 (where t = training value and o = output value for the Jth unit).
 This gives an activation value between 1 and 1, where 1 represents a perfect fit between the semantic output and the training pattern for that word and 0 is the expected activation value for an output pattern chosen at random.
 In a distributed representational system the competitor environment of a word can be directly reflected in this activation value.
 A semantic output which is similar to the training pattern for one word implies that it must also be dissimilar to the semantic patterns for all words which are not semantically related to that word.
 So, for example, no two unrelated words can have an activation of 0.
9 at the same time.
 For this reason, there is no need to use relative activations to define a lexical decision criterion.
 The upper graph in Figure 2 illustrates the activation of the semantic pattern of W l for each of the members of the word triplets (averaged across all items).
 The stimuli for each condition are identical up to word position 1, where the coarticulatory information in the vowel is presented.
 At word position 0, the final consonant is presented.
 The W l W l condition is the baseline for comparison of effects of mismatch.
 Here, as featural information is presented, the activation of W l rises, to a peak at the end of the word of 0.
71.
 This figure does not represent perfect activation of the word, but implies that W l is by far the most active candidate.
 Both crossspliced tokens result in reduced activation of the W l target, mainly on presentation of the mismatching coarticulatory information in the vowel.
 Furthermore, the patterns for the mismatching tokens are highly similar, with slightly more mismatch for 0.
6 W1W1 6 0.
4 W2W1 0.
2 N3W1 3 2 1 Word Pos 5 0.
6 •• W2N1 2 Word Pos Figure 2.
 Semantic activations of W l for the word triplets (above) and of W 2 for the nonword triplets (below).
 The xaxis represents the position within the current stimulus (0 = final segment).
 To examine the predictions for the nonword stimuli in a lexical decision task, we need to examine the activation of the semantic pattern for W 2 , the only word member of the stimulus triplets (lower graph.
 Figure 2).
 Unsurprisingly, W 2 is best activated by the W 2 N 1 token.
 However, the activation of W 2 on presentation of this token does not rise above 0.
4.
 Therefore, the model would predict a majority of "No" responses to these stimuli.
 In addition, the increased activation of W 2 for this condition would predict "No" responses should be slower than for the baseline (NlNl) and N 3 N 1 conditions.
 The data from the lexical decision simulation were transformed to provide a comparison with the M W 9 4 data (see Figure 3).
 In each case the simulation results were summed over the points during presentation of the word for which the conditions differed (i.
e.
, on presentation of the final 2 segments).
 For the case where activation was assumed to be negatively correlated with response time (i.
e.
, the "Yes" responses) these activations were negated.
 For both word and nonword conditions, the pattern of 22 activations produced by the network closely matches the pattern of response times found in M W 9 4 .
 0.
8 560 8! 0.
9 W1W1 W2W1 Condition N3W1 •Simulation •&Experiment| 0.
75 0.
65 0.
55 N1N1 W2N1 N3N1 Condition »• Simulation sExperiment! Figure 3.
 Comparison between lexical decision experimental data and network simulation for word (upper graph) and nonword (lower graph) stimuH.
 Of particular interest is the finding that, like humans, the model shows no inhibitory effects when presented with two nonwords spliced together.
 This is because phonetic featural information is mapped directly onto lexical representations.
 The N l N l and N 3 N 1 conditions are equivalent in terms of the degree to which they match W 2 phonologically: both contain information in the vowel transition and the following burst which deviates from the place of articulation of the W 2 final consonant.
 Since there is no intermediate segmental level it does not matter that for the N 3 N 1 condition the two sources of information conflict with each other segmentally—these cues are only integrated in the parallel mapping onto the phonological level.
 Thus, these conditions predict similar levels of inhibition of a lexical decision response.
 Phonetic Decision The translation from localist phonemic output values to predictions of phonetic decision responses is straightforward: The network's predictions should depend on the relative activations of the wordfinal phoneme nodes involved.
 These are the three segments in the coda output group that share the manner and voicing of the ambiguous segments, but vary in place of articulation.
 For example, the network's response to the stimulus token jog, constructed from the onset of job and the final burst of jog, would depend on the activations of the /b/, /g/ and /d/ nodes in the coda group of the phonological output units.
 Therefore the difference between the activation of the target segment and its most active triplet competitor was used as a correlate of experimental response time (see Figure 4).
 A s before, this measure is s u m m e d over the output for the final two segments of the input to provide a comparison with the experimental data.
 575 .
i 0.
6 0.
8t 5 2 5 | ^1.
2W1W1 W2W1 Condition N3W1 ^ Simulation •& Experiment | 0.
3 • 0.
2 • N1N1 W2N1 Condition N3N1 •©• Simulation Q Experiment Figure 4.
 Comparison between phonetic decision experimental data and network simulation for word (above) and nonword stimuli (below).
 Comparison of the two graphs shows a strong effect of lexical status on the network response.
 The responses to the word sequences ranged between 1.
2 and 0.
3, compared to 0.
2 to 0.
4 for the nonword sequences.
 This is consistent with the finding in the experiment that responses were slower for the nonword than the word sequences.
 The patterns within the two sequence types are quite similar.
 Compared to the baseline conditions, the patterns involving nonword onsets (i.
e.
, N 3 W 1 and N 3 N 1 ) produce mismatch effects but these mismatch effects are weaker than for the mismatching conditions with word onsets (i.
e.
, W 2 W 1 and W 2 N 1 ) .
 This pattern of results fits the response time data for the nonword sequences very well (since the 23 mismatching effect of the W 2 N 1 stimuli was roughly twice that of the N3N1 stimuli), although it underestimates the effect of mismatch for the N 3 W 1 condition.
 Again, it is interesting that the mismatching tokens composed of two nonwords (N3N1) show less of an inhibitory effect than the W 2 N 1 condition.
 Here the difference can be explained in terms of the interaction between lexical/semantic and phonological levels.
 As the lexical decision simulation shows, the W 2 N 1 tokens activate the W 2 representation more strongly than the N3N1 tokens.
 This biases the phonological activations in favor of an output which is coherent with this word and thus inhibits activation of the "correct" phonemic nodes.
 Discussion In both lexical and phonetic decision simulations, the predictions of the network closely follow the pattern of responses found in the M W 9 4 data.
 In the lexical decision simulation the network shows strong inhibitory effects for consonant place mismatches involving words (i.
e.
, in the W 2 W 1 , N 3 W 1 .
 and W 2 N 1 condiuons) but little effect of mismatch involving only nonwords (in the N3N1 condition).
 In the phonetic decision simulation all mismatching stimuli show inhibitory effects on responses, but the strength of these effects depends on the lexical status of the components of the stimuli.
 The model achieves our objective of providing a basis for phonological perception which is not prelexical and is strongly influenced by lexical activations, but still allows the form of nonwords to be identified and to be influenced by lexical factors.
 Indeed, the influence of lexical competitors is slightly too strong in the current model, although this is more likely to reflect properties of the training corpus than the choice of architecture.
 The fact that these results can be accommodated by our model is an important validation of this approach.
 Although this research is at an early stage we expect to model many other properties of the speech perception system in a similar manner.
 In particular, the use of a distributed lexical representation provides a straightforward explanation of many time course effects in lexical access.
 Effects such as the multiple activation of lexical candidates, frequency and competition effects in lexical access, and priming of associatively and semantically related words can be explained in terms of the interference caused by semantic "blending" of outputs (cf.
 Joordens & Besner, 1994) in a fully distributed lexical representation (Gaskell & MarslenWilson, in preparation).
 Acknowledgments This research was supported by U K M R C , S E R C and E S R C grants awarded to Lorraine Tyler and William MarslenWilson.
 W e thank Mary Hare for valuable advice.
 References Elman, J.
 (1990).
 Finding structure in time.
 Cognitive Science, U , 119211.
 Gaskell, G.
, & MarslenWilson, W .
 (1994).
 Inference processes in speech perception.
 In Proceedings of the 16th Annual Conference of the Cognitive Science Society Hillsdale.
 NJ: Erlbaum.
 Gaskell, G.
, & MarslenWilson, W .
 (in preparation).
 Integrating Form and Meaning: A Distributed Model of Speech Perception.
 Hinton, G.
 E.
, McClelland, J.
 L.
, & Rumelhart, D.
 E.
 (1986).
 Distributed representations.
 In D.
 E.
 Rumelhart & J.
 L.
 McClelland (Eds.
), Parallel Distributed Processing: Explorations in the Microstructure of Cognition, vol.
 J: Foundations.
 Cambridge, M A : MIT Press/Bradford Books.
 Hinton, G.
 E.
, & Shallice, T.
 (1991).
 Lesioning an atlractor network: Investigations of acquired dyslexia.
 Psychological Review, 98(1), 7495.
 Jakobson, R.
, Fant, G.
, & Halle, M.
 (1952).
 Preliminaries to Speech Analysis.
 Cambridge M A : M I T Press.
 Joordens, S.
, & Besner, D.
 (1994).
 When banking on meaning is not (yet) money in the bank: explorations in connectionist modelling.
 Journal of Experimental Psychology: Learning, Memory and Cognition, 20, 10511062.
 Lahiri, A.
, & MarslenWilson, W .
 D.
 (1991).
 The mental representation of lexical form: A phonological approach to the recognition lexicon.
 Cognition, 38, 245294.
 MarslenWilson, W .
 D.
 (1987).
 Functional parallelism in spoken word recognition.
 Cognition, 25, 71102.
 MarslenWilson, W.
, & Warren, P.
 (1994).
 Levels of representation and process in lexical access.
 Psychological Review, 101(4), 653675.
 McClelland, J.
 L.
, & Elman, J.
 L.
 (1986).
 The T R A C E model of speech perception.
 Cognitive Psychology, 18, 186.
 Morais, J.
, Bertelson, P.
, Cary, L.
, & Alegria, J.
 (1986).
 Literacy training and speech segmentation.
 Cognition, 24,4564.
 Morton, J.
 (1969).
 The interaction of information in word recognition.
 Psychological Review, 76, 165178.
 Norris, D.
 (1990).
 A dynamicnet model of human speech recognition.
 In G.
 T.
 M.
 Altmann (Ed.
), Cognitive Models of Speech Processing.
 Cambridge, M A : MIT Press.
 Plaut, D.
 C , & McClelland, J.
 L.
 (1993).
 Generalization with componential attractors: Word and nonword reading in an attractor network.
 Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society Hillsdale, NJ: Lawrence Erlbaum.
 Plaut, D.
 C , & Shallice, T.
 (1993).
 Deep dyslexia: a case study of connectionist neuropsychology.
 Cognitive Neuropsychology, 10(5), 377500.
 Read, C , Zhang, Y.
, Nie, H.
, & Ding, B.
 (1986).
 The ability to manipulate speech sounds depends on knowing alphabetic writing.
 Cognition, 24, 3144.
 Warren, P.
, & MarslenWilson, W .
 D.
 (1987).
 Continuous uptake of acoustic cues in spoken wordrecognition.
 Perception and Psychophysics, 41, 262275.
 Zipf, G.
 K.
 (1965).
 The psychobiology of language: An introduction to dynamic philology.
 Boston: HoughtonMifflin.
 24 Eye M o v e m e n t s Accompanying Language and Action in a Visual Context: Evidence Against Modularity Michael SpiveyKnowlton Department of Brain and Cognitive Sciences University of Rochester Rochester, N Y 14627 spivey@psych.
rochester.
edu Kathleen Eberhard Department of Brain and Cognitive Sciences University of Rochester Rochester, N Y 14627 eberhard@psych.
rochester.
edu Michael Tanenhaus E>epartment of Brain and Cognitive Sciences University of Rochester Rochester, N Y 14627 mtan@psych.
rochester.
edu Julie Sedivy Department of Linguistics University of Rochester Rochester, N Y 14627 sedivy@psych.
rochester.
edu Abstract It is commonly assumed that as a spoken linguistic message unfolds over time, it is initially processed by modules that are encapsulated from information provided by other perceptual and cognitive systems.
 W e were able to observe the effects of relevant visual context on the rapid mental processes that accompany spoken language comprehension by recording eye movements using a headmounted eyetracking system while subjects followed instructions to manipulate real objects.
 Under conditions that approximate an ordinary language environment, incorporating goaldirected action, the visual context influenced spoken word recognition and mediated syntactic processing, even during the earliest moments of language processing.
 Introduction It is often claimed that early stages of language comprehension are comprised of informationallyencapsulaied modules devoted to processing particular subdomains of the linguistic input without influence from other perceptual and cognitive systems (e.
g.
, Ferreira & Chfton, 1986; Fodor, 1983).
 In contrast, constraintbased approaches assume that "correlated constraints" from various information sources are immediately integrated during the processing of linguistic input (MacDonald, Pearhnutter & Seidenberg, 1994; McClelland, 1987; SpiveyKnowlton & Sedivy, in press; Tanenhaus & Trueswell, in press).
 The temporary ambiguities that arise because language unfolds over time have provided the primary empirical testing ground for evaluating these contrasting theoretical perspectives, with the strongest evidence for information encapsulation coming from studies in which potentially relevant constraints that are introduced by a prior linguistic context appear to have delayed effects (cf.
 Ferreira & Clifton, 1986; Rayner, Garrod & Perfetti, 1992).
 However, the "context" in such studies is frequently rather impoverished, consisting of a few sentences that precede the target sentence.
 In addition, the subject's task is often vague, with no welldefined behavioral goal.
 Under these conditions, the context may not be perceived as relevant by the comprehender, and even if it is, it must be stored in memory, thus it may not be immediately accessible when the ambiguity is first encountered.
 Moreover, because the context is introduced linguistically, it is always possible to preserve modularity by expanding the scope of the linguistic module.
 The research presented here explores temporary ambiguity resolution during the comprehension of spoken language under conditions in which: 1) there is a strong test of modularity because the context comes from a completely different perceptual modality: vision, 2) the context is immediately relevant because an action must be carried out that directly relates the utterance to the context, and 3) the context, because it is visual, is copresent with the Unguistic input, and thus can be interrogated when the ambiguity is first encountered.
 W e make use of an experimental paradigm w e have recently developed in which the listener follows spoken instructions to manipulate real objects in a display, while w e record their eye movements to those objects, timelocked with corresponding referents in the spoken instruction  all under conditions that approximate an ordinary language environment (SpiveyKnowlton, Sedivy, Eberhard & Tanenhaus, 1994; Tanenhaus, SpiveyKnowlton, Eberhard & Sedivy, in press a, in press b).
 With this methodology, w e are able to observe the effects of visual context on early moments of comprehension, and tap into partial incremental interpretations that are often observable only in eyemovement patterns (not in hand movements or subjects' intuitions).
 W e describe experiments on ambiguity resolution within individual words (Experiment 1) and across syntactic relationships (Experiment 2), that reveal early commitments to interpretations based on partial input, and immediate integration of relevant visual information with linguistic information in both word recognition and syntactic parsing.
 25 mailto:spivey@psych.
rochester.
edumailto:eberhard@psych.
rochester.
edumailto:mtan@psych.
rochester.
edumailto:sedivy@psych.
rochester.
eduM e t h o d Before reaching for an object, people typically move their eyes to fixate it (Ballard, Hayhoe & Pelz, in press; Epelboim, CoUewijn, Kowler, Erkelens, Edwards, Pizlo, & Steinman, 1994).
 Thus, when we instruct a subject to "pick up the candle," she makes a saccadic eye movement to the candle, and our methodology allows us to measure the time elapsed from the beginning of the word "candle" to the initiation of the saccade, as well as record any intermediate fixations to other objects.
 Eye movements are especially informative about early moments of processing because saccades are relatively automatic (devoid of strategic influences) and almost entirely ballistic.
 Thus, an initial misinterpretation of the spoken input, from which the listener rapidly recovers, is still observable as a brief fixation of the "incorrect" object.
 Eye movements were monitored by an Applied Scientific Laboratories (ASL) eyetracker mounted on top of a lightweight helmet.
 The camera provides an infrared image of the eye at 60Hz.
 The center of the pupil and the corneal reflection are tracked to determine the orbit of the eye relative to the head.
 A scene camera, mounted on the side of the helmet, provides an image of the subject's field of view.
 Gaze position (indicated by crosshairs) is superimix)sed over the scene camera image and recorded onto a Hi8 V C R with framebyframe playback.
 Accuracy of the gaze position record is about a degree over a range of +/ 20 deg.
 The video record was coordinated with the audio record for all data analysis.
 Subjects were seated at arm's length from a 3' by 3' table workspace that was divided into 25 squares (see Figure 1), and were given spoken instructions to move everyday objects around.
 A black cross in the center square served as a neutral fixation point, where the subject's gaze was directed at the onset of an instruction set.
 N o more than one object was placed in any square, so that noise in the gaze position signal was never enough to mistake a fixation of one object for another.
 The majority of instructions did not involve the experimentally relevant objects.
 Experiment 1: Ambiguity Within Words Background In a classic set of experiments, MarslenWilson and colleagues demonstrated that, to a first approximation, recognition of a word occurs shortly after the auditory input uniquely specifies a lexical candidate.
 For polysyllabic words, this is often prior to the end of the word.
 For example, the word "elephant" would be recognized shortly after the "phoneme" HI.
 Prior to that, the auditory input would be consistent with the beginnings of several words, including "elephant", "elegant", "eloquent" and "elevator".
 Thus, recognition of a spoken word is strongly influenced by the words that it is phonetically similar to, especially those words that share initial phonemes.
 MarslenWilson referred to the set of lexical candidates that is activated in the same phonetic environment as a cohort (for review, see MarslenWilson, 1987).
 Evidence from several experimental paradigms indicates that these candidates are partially activated as a word is being processed.
 For example, crossmodal lexical priming experiments demonstrate that semantic information associated with cohort members is temporarily activated as a word unfolds.
 The prior context of the utterance and subsequent input provide evidence that is used to evaluate the competing alternatives.
 While current models differ in how they account for these data, nearly all models incorporate the idea that the time it takes to recognize a word depends on a set of potential lexical candidates.
 (See Cutler, in press, for a recent review.
) This experiment had two goals.
 The first goal was to determine how closely timelocked eye movements to a target object would be to the name of the object in a spoken instruction.
 The second goal was to determine whether the presence of a "competitor" object with a similar name would influence eyemovement latencies to the referredto object.
 A visuallymediated "cohort competitor" effect would provide strong evidence that lexicallybased information associated with multiple lexical candidates is partially activated during spoken word recognition.
 In addition, it would demonstrate that relevant visual context affects even the earhest moments of language processing.
 Procedure Eight naive subjects participated in this experiment.
 They were given instructions to pick up an object and then put it in the square above or below another object.
 A sample instruction set is given below: (1) Look at the cross.
 Pick up the candle.
 N o w hold it over the cross.
 N o w put it above the mouse.
 3' 3' lion candy mouse pin cushion fork + hammer candle box Figure 1.
 Example display in which both members of the cohort pair are present in the workspace.
 (The words in this figure indicate locations of actual objects on the table.
) 26 W e used four pairs of objects with names that were phonetically similar until late in the word: candy/candle, car/carton, penny/pencil, and doll/dolphin.
 Each critical object appeared with its "cohort competitor" on some trials and with only distractor objects on other trials.
 Itach subject was exposed to two of the four cohort pairs.
 For instructions involving cohort members, the objects were always in one of the central eight squares (excluding the square with the cross).
 Figure 1 shows the workspace at the beginning of the instruction set given in example 1.
 The instructions and the positions of the objects were varied to prevent strategies.
 In particular, we avoided creating any contingencies that would have resulted in predictable instructions.
 Results On all of the critical trials, the movement of the hand to pick up the target object was preceded by a saccade to that object.
 On 3 3 % of the trials, fixation of the referredto object was preceded by a saccade launched to an "incorrect" object.
 For uials without such "false launches", the mean saccade latency for the "pickup" instruction was 487ms from the onset of the target word (e.
g.
, "candle").
 Saccade latencies were reliably longer when the display contained a "cohort competitor" (530 ms) than when it did not (445 ms); F(l,7)=9.
27, p<.
02.
 The average duration of a target word was 3(X)ms.
 If we assume that the interval between the onset of programming a saccade and the initiation of the saccade is about 200ms (Matin, Shao & Boff, 1993), then we can estimate that the programming of a saccade to the target object began an average of 55ms before the end of the word in the competitorabsent condition.
 More false launches were made when a competitor was present than when it was absent, but this difference was not reliable (37% compared to 29%).
 Of the false launches in the competitorpresent condition, 6 1 % were to the competitor object.
 In contrast, in the competitorabsent condition, only 2 5 % of the false launches were to the object that occupied the same square as the competitor object in its corresponding competitorpresent display.
 This difference was reliable in an analysis for six subjects; F(l,5)=14.
90, p<.
02.
 (Two subjects did not make any false launches in the competitorabsent condition and thus were excluded from the analysis.
) Discussion Three critical results emerged from this experiment.
 First, eye movements to the target object were closely timelocked to the linguistic expression that referred to that object.
 Thus, the eye movements provide an informative measure of ongoing comprehension.
 Second, the latency with which the saccades to the target object were launched provides clear evidence that activation of lexical representations begins before the end of a word.
 The high rate of false launches to competitors lends further support to the idea that multiple lexical candidates are activated early on in recognition.
 Third, the names of the possible referents in the visual context clearly influenced the speed with which a referent in the speech stream was identified.
 This demonstrates that the instruction was interpreted incrementally, taking into account the set of relevant objects present in the visual workspace.
 Experiment 2: Ambiguity In Syntax Background Clearly, the place where the modularity hypothesis has found the most purchase is in the realm of syntactic processing (cf.
, Ferreira & Clifton, 1986).
 The strongest evidence for the modularity of syntactic processing has come from studies using sentences with brief syntactic ambiguities in which readers have clear preferences for particular interpretations that persist momentarily even when preceding linguistic context supports the alternative interpretation (e.
g.
, Britt, 1994; Ferreira & Clifton, 1986).
 In this type of experiment, the context is typically comfHised of a few sentences preceding the target sentence.
 However, when the context is a visual display that is immediately relevant to the linguistic input (because an action is expected), and storing the context in memory is unnecessary (because the visual context is copresent with the spoken input), syntactic parsing may indeed show immediate effects of context.
 If so, this would provide definitive evidence against the encapsulation of syntactic parsing.
 Procedure We used instructions containing the temporary syntactic ambiguity with perhaps the strongest syntactic preference in EngUsh, as illustrated by the examples in (2).
 (2) a.
 Put the saltshaker on the envelope in the bowl.
 b.
 Put the saltshaker that's on the envelope in the bowl.
 In sentence (2a), the first prepositional phrase (PP), "on the envelope", is ambiguous as to whether it modifies the noun phrase ("the saltshaker") dius specifying the Location of the object to be picked up, or whether it denotes the Goal of the event, i.
e.
 where the saltshaker is to be put.
 As they are processing this sentence, readers and listeners initially interpret the first prepositional phrase as specifying the Goal, resulting in momentary confusion when they encounter the second preposition ("in").
 In example (2b) the word "that's" disambiguates the phrase as a modifier, serving as an unambiguous control condition.
 Six naive subjects were presented with six instances of each type of instruction (ambiguous and unambiguous) illustrated in example 2, with a onereferent visual context that supported the Goal interpretation or a tworeferent context that supported the Locationbased modification interpretation.
 In the onereferent context for this example, the workspace contained an saltshaker on a envelope, another envelope, a bowl, and an apple.
 Upon hearing the phrase "the saltshaker", subjects can immediately identify the object to be moved because there is only one saltshaker and thus they are likely to assume that "on the envelope" is specifying the Goal of the putting event.
 In the tworeferent context, however, the apple was replaced by a second 27 saltshaker which was on a napkin.
 Thus, "the saltshaker", could refer to either of the two saltshakers and the phrase "on the envelope" provides modifying information that specifies which saltshaker is the correct referent.
 Results Strikingly different fixation patterns between the two visual contexts revealed that the ambiguous phrase "on the envelope" was initially interpreted as a Goal in the onereferent context, but as a modifier in the tworeferent context.
 In the onereferent context, subjects looked at the incorrect Goal (e.
g.
, the irrelevant envelope) on 5 5 % of the trials shortly after hearing the ambiguous PP, whereas they never looked at it during the unambiguous instruction; t(5)=4.
11, p<.
01.
 In contrast, when the context contained two possible referents, subjects rarely looked at the incorrect Goal ( 1 7 % of the trials), and there was no difference between the ambiguous and unambiguous instructions.
 The statistical interaction between Context and Ambiguity was reliable; F(l,5)=8.
24,p<.
05.
 Figures 2 and 3 sununarize the most typical sequences of eye movements in the ambiguous and unambiguous instructions for the onereferent and the tworeferent contexts.
 In the onereferent context (Figure 2), subjects first looked at the target object (the saltshaker) 500ms after hearing "saltshaker", then looked at the incorrect Goal (the rightmost envelope) 484ms after hearing "envelope".
 In contrast, with the unambiguous instruction, the first look to a Goal did not occur until 471ms after the subject heard the word "bowl".
 Example 3 indicates the ̂ proximate timing of saccades with the speech stream via subscripted indices of the eye movements in Figure 2.
 v " ^.
 v : Figure 2.
 Typical sequence of eye movements in the onereferent context for the ambiguous and unambiguous instructions.
 Dashed arrows show the intermediate saccades to the incorrect Goal and back to the referent object that occur only in the ambiguous instruction.
 (See examples 3a and 3b for the temporal relationship between eye movements and words in the speech stream.
) (3) a.
Put the saltshaker on thei envelope in2 the bowl.
3 4 b.
Put the saltshaker that's ion the envelope in the bowl.
4 In the tworeferent context, subjects often looked at both saltshakers, reflecting the fact that the referent of "the saltshaker" was temporarily ambiguous.
 Subjects looked at the incorrect object on 4 2 % of the unambiguous trials and on 6 1 % of the ambiguous trials.
 In contrast, in the onereferent context, subjects rarely looked at the incorrect object ( 0 % and 6 % of the trials for the ambiguous and unambiguous instructions, respectively).
 The threeway interaction among Context, Ambiguity, and Type of Incorrect Eye movement (object vs.
 Goal) revealed the bias toward a Goal interpretation in the onereferent context and toward a Locationbased modification interpretation in the tworeferent context; F(l,5)=18.
41, p<.
01.
 In the tworeferent context, the timing of eye movements relative to the speech stream was nearly identical for ambiguous and unambiguous instructions.
 This indicates that subjects were interpreting the PP ("on the envelope") as an NPmodifier (instead of as a Goal) equally quickly in both ambiguous and unambiguous instructions.
 28 Figure 3.
 Typical sequence of eye movements in the tworeferent context.
 Note that, in this context, the eyemovement pattern did not differ for the ambiguous and unambiguous instructions.
 (See subscripted indices in examples 4a and 4b for the temporal relationship between eye movements and words in the sp)eech stream.
) (4)a.
Put the saltshaker on thei envelope 2in the bowl.
3 b.
Put the saltshaker that's ion the envelope 2in the bowl.
3 In addition to examining the effects of one versus tworeferent contexts on syntactic processing, w e examined the effects of a "threeandone" referent context, i.
e.
, instead of having one additional referent, there were three additional referents.
 So, in place of the saltshaker on a napkin in Figure 3, there were three saltshakers in that square.
 W e did this to examine whether the presupposition of uniqueness associated with the definite determiner the (cf.
 Heim, 1982) in "Put the saltshaker" would bias the subject toward the lone saltshaker (on the envelope).
 Indeed, such a bias was observed in saccade latencies to the target saltshaker, which resembled those of the onereferent context.
 This is because subjects rarely looked at the three saltshakers.
 However, unlike the onereferent condition, the ambiguous PP "on the envelope" was still interpreted as a modifier instead of a Goal.
 This is seen in the eyemovement pattern, which resembled the tworeferent condition: subjects rarely looked at the incorrect Goal.
 Thus, with both ambiguous and unambiguous instructions, this 3andl referent context elicited an overall eyemovement pattern and timing similar to that for the unambiguous instruction in the onereferent context.
 Discussion It is clear from these results that the relevant aspects of the visual scene influence even the initial moments of syntactic analysis.
 W h e n an object referred to in the speech stream is unique in the visual input, further specification of it is deemed unnecessary, resulting in a bias toward interpreting an ambiguous PP as describing the event and not the object.
 In contrast, the visual presence of multiple referents (e.
g.
, two saltshakers) biases the listener toward interpreting the ambiguous PP as describing which object is being referred to, instead of where to put it} Crucially, this effect of visual context is observed at the earliest measurable point in processing.
 General Discussion Our results demonstrate that, in natural contexts, people seek to establish reference with respect to their intended actions during the earliest moments of linguistic processing.
 Moreover, referentially relevant nonlinguistic information immediately affects h o w the linguistic input is initially structured.
 Given these results, approaches to language comprehension that assign a central role to encapsulated linguistic subsystems are unlikely to prove fruitful.
 More ^ Grain and Steedman (1985) develop a theory of syntactic ambiguity resolution in which referential context of this sort (but in hnguistic form) plays a central role.
 29 promising are theories in which grammatical constraints are integrated into processing systems that cotwdinate linguistic and nonlinguistic information as the linguistic input is processed (e.
g.
, MacDonald et al.
, 1994; McClelland, 1987; SpiveyKnowlton & Sedivy, in press; Tanenhaus & Trueswell, in press).
 In this view, even the earliest computations on language input are richly contextualized with respect to accompanying plans, actions and relevant entities in the environment (cf.
 Clark, 1992; also Carpenter & Alterman, 1994).
 These results are especially relevant for the growing interest in computational approaches to integrating language and vision (cf.
 McKevitt, 1994).
 Finally, our results show that, with welldefined tasks, eye movements can be used to observe the rapid mental processes that underlie spoken language comprehension during goaldirected action in natural contexts.
 This paradigm can naturally be extended to explore questions on topics ranging from spoken word recognition to conversational interactions during cooperative problem solving.
 Acknowledgments Thanks to Dana Ballard and Mary Hayhoe for encouraging us to use their laboratory, to Jeff Pelz for teaching us how to use the equipment, and to Kenzo Kobashi for assistance in data collection.
 Supported by NIH resource grant 1P41RR09283; NIH, HD27206, to M K T , an N S F Fellowship to M S  K and a Canadian S S H R C fellowship to JCS.
 References Ballard, D.
, Hayhoe, M.
 & Pelz, J.
 (1995).
 Memory representations in natural tasks.
 Journal of Cognitive Neuroscience, 7, 6882.
 Britt, M .
 A.
 (1994).
 The interaction of referential ambiguity and argument structure in the parsing of prepositional phrases.
 Journal of Memory and Language, 33, 251283.
 Carpenter, T.
 & Alterman, R.
 (1994).
 A taxonomy for planned reading.
 Proceedings of the 16th Annual Conference of the Cognitive Science Society.
 Chomsky, N.
 (1965).
 Aspects of the theory of syntax.
.
 M I T Press: Cambridge, M A .
 Clark, H.
 (1992).
 Arenas of language use.
 U.
 of Chicago Press: Chicago, IL.
 Crain, S.
 & Steedman, M .
 (1985).
 On not being led up the garden path.
 In Dowty, Kartunnen & Zwicky (eds.
), Natural Language Parsing.
 Cambridge U.
 Press: Cambridge, M A .
 Cutler, A.
 (1995).
 Spoken word recognition.
 In J.
 Miller & P.
 Eimas (Eds.
), Handbook of Cognition and Perception.
 Academic Press.
 Epelboim, J.
, Collewijn, H.
, Kowler, E.
, Erkelens, C , Edwards, M.
, Pizlo, Z.
, Steinman, R.
 (1994).
 Natural oculomotor performance in looking and tapping tasks.
 Proceedings of the 16th Annual Conference of the Cognitive Science Society.
 Ferreira, F.
 & Clifton, C.
 (1986).
 The independence of syntactic processing.
 Journal of Memory and Language, 25, 348368.
 Fodor, J.
 A.
 (1983).
 Modularity of mind.
 M I T Press: Cambridge, M A .
 Heim, I.
 (1983).
 The semantics of definite and indefinite noun phrases.
 GLSA: Amherst, M A .
 MacDonald, M .
 Pearlmutter, N & Seidenberg, M .
 (1994).
 The lexical nature of syntactic ambiguity resolution.
 Psychological Review , 101, 676703.
 MarslenWilson, W .
 (1987).
 Functional parallelism in word recognition.
 Cognition, 25, 71102.
 McClelland, J.
 (1987).
 The case for interactionism in sentence processing, in M .
 Coltheart (Ed.
) Attention & Performance XII Erlbaum: Hove, England.
 McKevitt, P.
 (1994).
 (Ed.
), Artificial Intelligence Review, Special Volume on the Integration of Language and Vision Processing, Vol.
 8, No.
13.
 Rayner, K.
, Garrod, S.
 & Perfetti, C.
 (1992).
 Discourse influences during parsing are delayed.
 Cognition, 45, 109139.
 SpiveyKnowlton, M .
 & Sedivy, J.
 (in press).
 Parsing attachment ambiguities with multiple constraints.
 Cognition.
 SpiveyKnowlton, M.
, Sedivy, J.
, Eberhard, K.
 & Tanenhaus, M .
 (1994).
 Psycholinguistic study of the interaction between language and vision.
 In AAAI94 Workshop Notes on the Integration of Natural Language and Vision Processing.
 Tanenhaus, M .
 & Trueswell, J.
 (1995).
 Sentence comprehension.
 In J.
 Miller & P.
 Eimas (Eds.
), Handbook of Cognition and Perception.
 Academic Press.
 Tanenhaus, M.
, SpiveyKnowlton, M.
, Eberhard, K.
 & Sedivy, J.
 (in press a).
 Using eye movements to study spoken language comprehension.
 In T.
 Inui & J.
 McClelland (Eds.
), Attention & Performance XVI: Integration in Perception and Communication.
 Tanenhaus, M.
, SpiveyKnowlton, M.
, Eberhard, K.
 & Sedivy, J.
 (in press b).
 Integration of visual and linguistic information in spwken language comprehension.
 Science.
 30 Using noncognate interlexical homographs to study bilingual m e m o r y organization Robert M.
 French Universite de Lî ge Service de Psychologic du Travail 4000 Lifege, Belgium french@cogsci.
Indiana.
edu Abstract Noncognate FrenchEnglish homographs, i.
e.
, identical lexical items with distinct meanings in French and in English, such as pain, four, main, etc.
, are used to study the organization of bilingual memory.
 Bilingual lexical access is initially shown to be compatible with a parallel search through independent lexicons, where the search speed through each lexicon depends on the level of activation of the associated language.
 Particular attention is paid to reaction times to "unbalanced" homographs, i.
e.
, homographs with a high frequency in one language and a low frequency in the other.
 It is claimed that the independent duallexicon model is functionally equivalent to an activationbased competitiveaccess model that can be used to account for priming data that the duallexicon model has difficulty handling.
 Introduction Is bilingual memory organized in distinct lexicons corresponding to each language or, rather is it organized in a more homogeneous fashion, comparable to monolingual memory except with twice as many words? A "separate storage" duallexicon model has a certain intuitive appeal, in particular, because proficient bilinguals will, in general, report little interlexical interference.
 However, numerous studies of monolingual memory involving priming by ambiguous words (Posner, 1978; Swinney, 1979; etc.
) seem to cast doubt on intuitive notions of contextual modularity.
 For example, the word "bank" in a financial context will facilitate words like "money," "robbery", and "teller.
 However, words outside of the currently active context, like "river," are also primed.
 The existence of extracontextual facilitation within a single language might mean that a similar phenomenon occurs between languages, where the "context" is the currently active language.
 In the monolingual case, it appears that activation initially spreads along the pathways emanating from the "prime" (e.
g.
, "bank") to all associatively and semantically related lexical items.
 Then, in a second phase, the meanings that are inappropriate to the currently active context are suppressed (Gernsbacher, 1990, 1991).
 In light of these findings, it would seem reasonable to ask whether the same thing might be occurring in bilingual memory.
 In other words, if bilingual memory were organized as monolingual Clark O h n e s o r g e Department of Psychology University of Wisconsin Madison, W I 53706 s a n s o u c i @ m a c c .
 w i s e .
 e d u memory seems to be, activation would initially spread to related lexical items in both languages and then those items not in the currently active language context would be inhibited.
 Evidence for this type of memory model comes largely from interlexical priming studies.
 Numerous studies over the years (Kolers 1966; Meyer & Ruddy, 1974; Beauvillain & Grainger, 1987; Altarriba, 1992; etc.
) have demonstrated crosslingual priming effects.
 O n the other hand, there have been a number of studies (Grosjean, 1982, 1989; Grosjean & Soares, 1986; Macnamara & Kushnir, 1971; Gerard & Scarborough, 1989; etc.
) that seem to support a more compartmentalized languagespecific view of bilingual language organization.
 And finally, a recent study (Neumann, McCloskey, & Felio, 1994) seems to show that interlingual excitatory priming disappears whereas inhibitory priming does not.
 The present paper provides a tentative account for these seemingly divergent results.
 Noncognate bilingual homographs We conducted a lexicalaccess experiment using adult FrenchEnglish bilinguals.
 Since much work has been done with monolinguals using homographs to investigate crosscontextual priming, we decided to use bilingual (French/English) homographs in a similar manner.
 (Homographs are words like "bank" that have one meaning in a one context and a different meaning in another.
) In our study, "context" refers to an entire language, rather than a situation within a single language.
 It was important to select noncognate bilingual homographs.
 The word table, for example, exists in both French and English, but it means essentially the same thing in both languages.
 W e wanted only ordinary words that could be read in both languages, but whose meanings were completely different in their respective languages.
 These were words such as fin, pain, main, store, four, once, bride, pour, stage, grave, etc.
 Gerard & Scarborough (1989) used noncognate SpanishEnglish homographs to support the hypothesis that "lexical information is represented in languagespecific lexicons and that word recognition requires searching the languageappropriate lexicon.
" They used the notion that the logfrequency of a word in the printed language 31 mailto:french@cogsci.
Indiana.
edumailto:sansouci@macc.
wise.
edu(Scarborough, D.
, Cortese, C .
 & Scarborough, H.
, 1977; M c C a n n , Besner, & Davelaar, 1988) is a consistent predictor of the time required to recognize that word.
 They considered noncognate bilingual homographs, such as red ("net" in Spanish), that had a high frequency in one language and a lower frequency in the other.
 SpanishEnglish bilinguals were asked to look for words in a list of words/nonwords in a single target language.
 Mixed into the singlelanguage list of words were the noncognate bilingual homographs.
 The authors reasoned that "if recognition depends on lexicalretrieval processes shared at least in part by both languages (i.
e.
, c o m m o n encoding processes and access to c o m m o n lexical entries), then homographicnoncognate latencies m a y depend on the overall familiarity (overall frequency of usage) of these spelling patterns in both languages" rather than the frequency of use in the currently active language.
 Their results clearly show that word frequency in the currently active language — and not the overall frequency of usage in both languages — predicts homograph recognition time, thus lending support to the languagespecific duallexicon hypothesis.
 LI interlexical links ^ L2 nceptual^^ j ^ links I 1 Concepts Figure 1.
 A hierarchical model of bilingual m e m o r y (From Kroll & Stewart, 1990) By contrast, studies in which targets were primed by noncognate bilingual homographs indicate that the priming effects are not restricted to one lexicon.
 (Note: Gerard & Scarborough (1989) were not considering reaction times to primed lexical items.
) But crosslanguage priming should not occur, or only occur very weakly, if there were independent languagespecific lexicons.
 Altarriba (1992) has suggested that in some of these studies interlanguage priming can be attributed to the use of a long interval between the presentation of the prime in one language and the subsequent presentation of the target in the second language.
 She suggested that even a 300 ms primetarget interval "might have been long enough to permit the translation of the prime or the use of other strategies on the part of the subjects.
" In other words, if bilingual memory were organized as in Figure 1 (Kroll & Stewart, 1990), a 300 ms primetarget delay could be long enough to permit translation of the prime via the concept area.
 However, even after taking Altarriba's criticism into account, there are still studies in which crosslanguage lexical priming was observed.
 In particular, Beauvillain & Grainger (1987) presented the prime for only 100 ms with a 50 ms delay before the target presentation, i.
e.
 well below the 300 ms conceptual translation threshold referred to by Altarriba W e suggest that lexical access of unprimed target words can be modeled by a parallel search of two independent lexicons where the speed of the search through each lexicon is a function of the activation of the corresponding language.
 Since a model with two separate lexicons should have difficulty accounting for interlexical priming data, we show that this kind of model is functionally equivalent, at least in the case of lexical access to unprimed target words, to an activationbased competitiveaccess model of lexical access.
 This latter model would seem better at accounting for interlexical priming effects.
 Experimental design Participants The participants were 48 bilingual males and females recruited from the University and surrounding community.
 Virtually all were in daily contact with both French and English and judged themselves highly fluent in both French and English.
 The pool was drawn up of professors and graduate students in the French department, translators, and native French speakers having lived for many years in the U S , etc.
 Twentyfive of the subjects were native French speakers.
 The 24 participants for each of the two conditions of the experiment were randomly selected.
 Stimuli The critical stimuli were 45 noncognate bilingual homographs (i.
e.
, words like pain, main, but, son, or, pour, as, seize, etc.
).
 All of the homographs chosen had completely different meanings in French and English.
 The frequency of appearance of these words in printed French ranged from 1 to 10,198 occurrences per million words (Baudot, 1992).
 In printed English, they ranged from 0 to 7250 occurrences per million words (Kucera & Francis, 1967).
 The remainder of the stimulus set, the "filler" stimuli used to set the context, consisted of a total of 645 letter strings: 300 French words, 300 Frenchbased nonwords, and, to balance the 45 homographs, 45 nonwordhomographs produced by altering one letter of a set of bilingual cognate homographs (e.
g.
, "silence" ^ "sirence").
 In other words, there were altogether 345 French words and 345 nonwords.
 All stimuli were presented in all capital letters in a 24point Chicago font.
 Procedure The experiment consisted of two conditions, an AllFrench condition, where the participants saw only French words/nonwords, and a Mixed condition, where they saw a mixture of half French and half English words/nonwords.
 32 AllFrench Condition Participants did the experiment individually in 45minute sessions in which they responded to 450 experimental trials.
 The experiment was run on PsyScope (Cohen, J.
 et al, 1993) on a Power Macintosh computer.
 The instructions were written in French and were read from the computer screen at the beginning of the experiment.
 Participants were seated approximately 20" in front of the computer monitor.
 The instructions indicated that they would see letter strings and were to classify them as words (if they were real words in French or in English) or nonwords.
 Included in the list of lexical items was the critical set of bilingual noncognate homographs, such as, fin, pain, main, son, four, etc.
 Reaction time to these homographs was the critical dependent variable.
 Of particular interest were "unbalanced homographs" whose printedword frequencies were high in one language and low in the other.
 After reading the instructions, the participants initiated a block of 40 practice trials.
 Upon completion of the practice block, they began the experimental trials.
 On each trial a letter string was presented and remained on the screen until a response was made.
 After a 500 ms interval the next stimulus was presented.
 Feedback, in the form of a beep, indicated when a word/nonword had been misclassified.
 Participants responded to a total of 450 letter strings: 180 French words, 180 Frenchbased nonwords, 45 cognatebased nonwords, and the 45 critical homographs.
 Mixed Condition Identical to the AllFrench condition, except that the "filler" stimuli consisted of an equal mixture of French and English words and nonwords.
 The word/nonword lexical decision task was the same as in the AllFrench condition.
 W e were particularly interested in the times required to recognize homographs — and, especially, "unbalanced" homographs — in this condition compared to the AllFrench condition.
 Summary of Results The AllFrench condition of the experiment confirmed the conclusions of Gerard & Scarborough (1989) — namely, that bilinguals' reaction time to noncognate interlexical homographs is better predicted by their logfrequency in the currently active language rather than their summed logfrequency over both languages.
 In the AllFrench context, we found the homographs' French logfrequency was a better predictor of recognition time (r(43)=0.
55, p < 0.
01) than the summed logfrequency (r(43) = 0.
41, p < .
01).
 It is to be noted that English logfrequency of the homographs did not predict reaction times in the AllFrench condition (r(43) = 0.
1).
 In the Mixed condition participants were exposed to equal proportions of French and English words/nonwords.
 The key results involved two sets of "unbalanced" homographs, i.
e.
, homographs whose printedword frequencies were significantly different in the two languages.
 The first subset consisted of 6 homographs with a low frequency in French and a high frequency in English (mean logfrequency in French = 1.
1, a = 0.
2; mean logfrequency in English = 2.
8, o = 0.
7).
 W e called these LF/HE homographs.
 The second subset consisted of 10 homographs with a high frequency in French and a low frequency in English (mean logfrequency in French = 2.
4, c  0.
4; mean logfrequency in English = 1.
0, a = 0.
27).
 W e called these HF/LE homographs.
 High frequency in both languages was defined as belonging to the 1000 most common words of the language; low frequency was defined as words whose rank was greater than 3000 in both languages (Kucera & Francis, 1967; and Baudot, 1992).
 W e used a 2(AnFrench, Mixed) x 2(LF/HE, HF/LE) design for the experiment.
 The data were submitted to a 2x2 mixed A N O V A with the Context variable having two levels, AllFrench and Mixed, and the Homographtype variable including two different types of homographs, LF/HE and HF/LE.
 Context was a betweensubjects variable and Homographtype was a withinsubjects variable.
 Both main effects and their interaction were significant.
 Our major focus was on the Context x Homographtype interaction (F(l,46) = 21, p < .
01) and its derivative simple effects — namely: • For LF/HE homographs, a significant decrease in mean reaction time (from 912 to 710 ms; F(l,46) = 11.
5; p < .
01) when the context is changed from AllFrench to Mixed; • For HF/LE homographs, no significant difference in reaction time between the Mixed context from the AllFrench context (F(l,46) = 0.
4, p > 0.
1).
 These reactiontime results are given in Figure 2 below.
 1000 r 750 500 LF/HE HF/LE Homograph type Figure 2.
 Changes in mean reaction time for the two different types of "unbalanced" homographs in the AllFrench context versus the Mixed context.
 Explanation of the results We suggest that these data are compatible with a model based on a differentially active, parallel search through two independent lexicons.
 W e then argue this model is itself compatible with a "singlelexicon" activationbased competition model of lexical access.
 AllFrench QMIxed 742 733 33 In general, only one of a bilingual's lexicons is active.
 But, under some circumstances, people do fully activate both lexicons — in particular, when translating, especially simultaneously, from one language to another.
 Let us start by considering the ramifications of a duallexicon model with parallel search.
 In the AllFrench condition, we attempted to activate only French by presenting participants with words and nonwords exclusively in French.
 English would, however, have remained somewhat active, however, if only because the lexical decision task required identification of words in French O R in English.
 Participants would therefore have been primed to see words in English, thereby activating their English lexicon.
 In the Mixed condition we attempted to fully activate both of the participants' lexicons.
 Parallel search through both lexicons, with the speed of the "search demons" in each lexicon depending on how active that lexicon is (Figure 3), would predict the following differences in recognition times as one goes from the AllFrench to the Mixed contexts: • faster reaction times for LF/HE homographs; • very little change in reaction times for HF/LE homographs.
 Figure 2 indicates that the reactiontime data for unbalanced homographs agrees with the predictions of this model.
 A n example will help explain why reaction times improve for LF/HE homographs (Figure 3) when going from the AllFrench context to the Mixed context.
 In the AllFrench context, the Frenchlexicon "search demon" will reach "ride" (= "wrinkle" in French) before its weakly active, thus slowermoving Englishlexicon competitor.
 In the Mixed context, however, both French and English lexicons are fully active and, as a result, the search speed of the two search demons will be about the same.
 Because the English logfrequency for "ride" is higher than the French logfrequency, the English search demon will now arrive at "ride" before the Frenchlexicon search demon.
 Since the distance traveled by the fullyactive English demon through the English lexicon in the Mixed context is less than the distance traveled by the fullyactive French demon through the French lexicon in the AllFrench context, the recognition time for "ride" will be shorter in the Mixed Context condition.
 Similarly, this "searchdemon" metaphor helps explain why reaction times to HF/LE homographs remain essentially unchanged when going from the AllFrench to the Mixed context (Figure 4).
 Consider the HF/LE homograph "champ" (= "field" in French).
 In both the AllFrench context and in the Mixed context, the French lexicon is fully active.
 Thus, in both cases, the French "search demon" will beat the English demon to the lexical item "champ".
 French fully active English only I slightly active • French fully active English fully active "ride" 'Tid?' high frequency FR lexicon ENG lexicon low frequency I • "ride" ride" AllFrench context FR lexicon ENG lexicon M i x e d context Figure 3.
 Duallexicon, parallelsearch model.
 Recognition time decreases for a HE/LF homograph in going from AllFrench to Mixed context.
 French fuDy active English only I sightly active • ^ high frequency French English fully active fuDy active "champ 'champ" "champ FR lexicon ENG lexicon low frequency * A champ AllFrench context FR lexicon ENG lexicon M i x e d context Figure 4.
 Duallexicon, parallelsearch model.
 Recognition time remains the same for LE/HF homograph in going from AllFrench to Mixed context.
 Another way of describing this model is by saying that word recognition time is predicted by: maxC^FRApR ,/engAeng) where /fr is the French logfrequency of the word; ApR is the activation of the French context; /eng is the English logfrequency of the word; Aeng is the activation of the English context.
 Thus, in the AllFrench context Aeng will be low, and reaction times will be predicted largely by French homograph frequency.
 This was shown in the AllFrench condition to be the case.
 In the Mixed context, Aeng will be approximately equal to Afr, since both the English and French lexicons are assumed to be fully active.
 In this case, the maximum between /fr and /eng should predict reaction 34 time better than either French or English logfrequencies alone.
 The data tend to support this prediction.
 In the Mixed context, there was a correlation of r = 0.
62 between mean reaction time and the maximum French or English logfrequencies for the homographs.
 This compared to r = 0.
51 for French logfrequencies alone, and r = 0.
42 for English logfrequencies.
 Finally, this model explains why, even in the AllFrench context, certain extreme LF/HE homographs will still be recognized by some bilinguals as English words.
 This is because, even though the activation of English (Aeng) niay be low, it is not completely zero; in addition, /eng is very high.
 Consequently, for extreme LF/HE homographs, the product /engAeng may still exceed /frAfr and the bilingual will recognize the homograph as a word in English.
 The data supported this conclusion.
 The LF/HE homograph i/(= "yew tree" in French) had, by far, the lowest French logfrequency of all LF/HE homographs.
 The mean reaction times for LF/HE homographs in the AllFrench context was 912 ms (a=51).
 And yet, the mean reaction time in the AllFrench context for if, rather than being slower than the mean, as would have been expected, was, in fact, 0.
8 S D /a^rer than the mean.
 An activationbased competition m o d e l of bilingual m e m o r y The duallexicon, differentially active, parallel search model of bilingual accounts for our unprimed lexicalaccess data.
 However, the interlexical priming data reported by Beauvillain & Grainger (1987) would be harder to explain with this model.
 W e suggest that an activationbased competition model might be more appropriate to explain both unprimed and primed lexical access data.
 This activationbased model is consistent with the predictor, the max(/"FRAFR ,/engAeng).
 described in the previous section.
 The key intuition is as follows.
 Recognition time for a word in a monolingual lexicon is predicted by the printedword logfrequency of that word.
 In approximate Hebbian terms (Hebb, 1949), each new encounter with the word would cause a (logarithmic) recruitment of new cells to the cellassembly associated with the word.
 In the case of a bilingual, the same type of recruitment would presumably go on, except that each "recruit" would be associated with the language context in which it was recruited.
 Consider the word "ride", which means "wrinkle" in French.
 Each time bilinguals see the word "ride" in English, a small number of units, each associated with the "English" context, are added to the representation of RIDE.
 Similarly, every time the word "ride" is encountered in a French context (which is considerably rarer than in English), a small number of units, each associated with the "French" context, are added to the representation of RIDE.
 The overall picture might look something like Figure 5.
 In normal language use, only one of the multiple meanings of ambiguous words is perceived.
 The contextually irrelevant meanings are suppressed (Gernsbacher, 1990).
 In a similar fashion, only one meaning of a bilingual homograph is perceived at a given time.
 This argues for a model in which the two languagedependent interpretations compete in a winnertakesall competition.
 In addition, the inhibitory mechanism suggested by Neumann, McCloskey, & Felio (1994) supports this interlexical competitive mechanism whereby the more active meaning suppresses the less active interpretation of a particular homograph.
 "RIDE English units Figure 5.
 A n activationbased competitiveaccess model of bilingual m e m o r y in the AllFrench context In this model, each group of units will be differentially activated according to the amount of activation coming from the languages with which they are associated.
 If the French context is fully active and the English context is only weakly active (as in the AllFrench context), the set of "French" units comprising "ride" will most likely have more overall activation than the larger, but less active set of English units making up the representation.
 T h e more active French units will therefore inhibit the English units and, as a result, "ride" will be perceived in its French meaning of "wrinkle.
" (This is just another w a y of saying that w h e n /frAfr exceeds /engAeng .
 the former will win the competition and determine the activation of the entire representation.
 This is what occurs in the parallel search model.
) T h e advantage of this activationbased description of bilingual m e m o r y is that it fits into an established framework of automatic spreading activation in which interlexical priming could be more easily explained.
 Just as activation in a monolingual English lexicon initially spreads automatically from "bank" to all of its related items in a contextindependent manner, the activationbased description of bilingual lexical access could be used to explain the type of crosslingual priming reported by Beauvillain & Grainger (1987).
 Conclusion We have attempted to show how a simple duallexicon model using differentially active, parallel search can account for word recognitiontime data in bilinguals.
 It is claimed that two factors — word logfrequency and the degree of language activation — predict word recognition times.
 35 Recognition times for noncognate bilingual homographs, such as pain, pour, main, as, etc.
 were used to study the effect of modifying the language context from an essentially monolingual one to a mixed halfFrench/halfEnglish context.
 Finally, we suggest that an activationbased, competition model is functionally equivalent to the duallexicon model and would seem well suited to account for both recognition times for both unprimed stimuli as well as interlexically primed stimuli.
 Acknowledgments The authors would like to thank Jim Friedrich, Morton Ann Gernsbacher, Virginia Marchman, and John Theios for their contribution to this research.
 W e would also like to thank all the FrenchEnglish bilinguals, in particular, the many members of the University of Wisconsin French department, who took part in this research.
 Bibliography Altarriba, J.
, (1992).
 The Representation of Translation Equivalents in Bilingual Memory.
 In Cognitive Processing in Bilinguals.
 J.
 Harris (ed.
).
 Amsterdam: Elsevier.
 Baudot, J.
 (1992).
 Frequneces d'utilisation des mots en frangais ecrit contemporain.
 Montreal, Quebec: Les Presses de I'Universite de Montreal.
 Beauvillain, C.
 & Grainger, J.
 (1987) Accessing Interlexical Homographs: Some Limitations of a Languageselective access.
 Journal of Memory and Language, 26, 658672.
 Cohen, J.
, MacWhinney, B.
, Flatt, M.
, & Provost, J.
 (1993).
 PsyScope: A new graphic interactive environment for designing psychology experiments.
 Behavioral Research Methods, Instruments & Computers, 25(2), 257271.
 Gerard, L.
 & Scarborough, D.
 (1989) Languagespecific lexical access of homographs by bilinguals.
 Journal of Experimental Psychology: Learning, Memory, and Cognition.
 Vol.
 15, No.
 2, 305315.
 Gernsbacher, M.
, (1990) Language Comprehension as Structure Building.
 Hillsdale, N.
J.
: Lawrence Erlbaum.
 Gernsbacher, M , (1991) Cognitive processes and mechanisms in language comprehension: The structure building framework.
 In The Psychology of Learning and Motivation.
 Vol.
 24, Bower, G.
 (ed.
).
 N e w York, N Y : Academic Press.
 Grosjean, F.
 (1982) Life With Two Languages.
 Cambridge, M A : Harvard University Press.
 Ch.
 5, 228288.
 Grosjean, F.
 (1989).
 Neurolinguists, Beware! The Bilingual is Not T w o Monolinguals in One Person.
 Brain and Language, 36,315.
 Grosjean & Scares, 1986 "Processing Mixed Language: Some Preliminary Findings" In Language Processing in Bilinguals.
 Jyotsna Void (ed.
) Hillsdale, NJ: Lawrence Erlbaum, Inc Hebb.
 D.
 O.
 (1949) The Organization of Behavior.
 New York, N Y : Wiley & Sons.
 Kroll, J, & Stewart, E.
 (1990).
 Concept mediation in bilingual translation.
 Paper presented at the 31st Annual Meeting of the Psychonomic Society, New Orleans.
 Kolers, P.
 (1966).
 Interlingual Facilitation of Shortterm Memory.
 Journal of Verbal Learning and Verbal Behavior.
 5, 3\43\9.
 Kucera, H.
 & Francis.
 W.
, (1957) Computation Analysis of Presentday American English.
 Providence, RI: Brown University Press.
 McCann, R.
, Besner, D.
, & Davelaar, E.
 (1988) Word Recognition and Identification: Do Wordfrequency Effects Reflect Lexical Access? Journal of Experimental Psychology: Human Perception and Performance.
 14(4) 693706.
 Macnamara, J.
 & Kushnir, S.
 (1971).
 Linguistic Independence of Bilinguals: The Input Switch.
 Journal of Verbal Learning and Verbal Behavior, 10, 480487.
 Meyer, D.
 & Ruddy, M.
 (1974).
 Bilingual wordrecognition: Organization and retrieval of alternate lexical codes.
 Paper presented at the meeting of the Eastern Psychological Association, Philadelphia.
 Neumann E.
, McCloskey, M.
, & Felio, A.
 (1994).
 Primed lexical decision tasks: Crosslanguage positive priming disappears, negative priming doesn't.
 N I M H , Laboratory of Socioenvironmental studies Tech.
 Report.
 Scarborough, D.
, Cortese, C , & Scarborough, H.
 (1977) Frequency and repetition effects in lexical memory.
 Journal of Experimental Psychology: Human Perception and Performance, 3, 117.
 Swinney, D.
 (1979) Lexical access during sentence comprehension: (Re)consideration of context effects.
 Journal of Verbal Learning and Verbal Behavior.
 18, 645659.
 36 Semantic a n d Associative Priming in a Distributed Attractor N e t w o r k David C.
 Plaut Department of Psychology Carnegie Mellon University, and Center for the Neural Basis of Cognition Pittsburgh, PA 152133890 plaut@cmu.
edu Abstract A distributed attractor network is trained on an abstract version of the task of deriving the meanings of written words.
 When processing a word, the network starts from the final activity pattern of the previous word.
 Two words are semantically related if they overlap in their semantic features, whereas they are associatively related if one word follows the other frequently during training.
 After training, the network exhibits two empirical effects that have posed problems for distributed network theories: much stronger associative priming than semantic priming, and significant associative priming across an intervenmg unrelated item.
 It also reproduces the empirical findings of greater priming for lowfrequency targets, degraded targets, and highdominance category exemplars.
 Introduction In a variety of lexical tasks, including naming and lexical decision, subjects are faster and more accurate to process a word, such as butter, when it is preceded by a semantically related word, such as bread (see Neely, 1991, for a review).
 Such findings of semantic priming are taken by many theorists as reflecting fundamental properties of the organization of knowledge in the human cognitive system.
 Broadly speaking, two classes of theories of semantic m e m ory have been put forth to account for semantic priming in lexical tasks.
 Spreadingactivation theories (e.
g.
, Anderson, 1983; Collins & Loftus, 1975; McNamara, 1992a, 1992b, 1994) propose that semantic memory consists of a network of interconnected nodes, each representing a particular concept.
 Processing a word involves activating the concept node in semantic memory corresponding to its meaning.
 This activation is assumed to spread along links to other, related concepts, thereby facilitating the subsequent processing of those concepts.
 B y contrast, compoundcue theories (e.
g.
, Dosher & Rosedale, 1989; M c K o o n & Ratcliff, 1992; Ratcliff & McKoon, 1988, 1994) propose that, in processing a word, semantic memory is accessed using a cue consisting of the word conjoined with the context in which it occurs (e.
g.
, the preceding word).
 Semantically related words cooccur more frequently than do unrelated words, and so the compound cues for related words tend to have greater familiarity than do those for unrelated words.
 In many general models of memory retrieval (e.
g.
, Gillund & Shiffrin, 1984; Hintzman, 1986; Murdock, 1982), greater familiarity gives rise to faster and more accurate processing, resulting in semantic priming.
 Recently, a third type of theory has been proposed to account for semantic priming, based on distributed connectionist networks (Kawamoto, 1988;Masson, 1991,1995;McRae, de Sa, & Seidenberg, 1993; Sharkey & Sharkey, 1992).
 In such networks, each concept is represented, not by a particular unit, but by a particular pattern of activity over a large number of processing units.
 Related concepts are represented by similar (i.
e.
, overlapping) patterns of activity.
 Each unit can be thought of as encoding a particular semantic feature that participates in many concepts (Smith & Medin, 1981), although these features need not correspond to verbalizeable attributes of any concept.
 In processing a word, units cooperate and compete across weighted connections until the network as a whole settles into a stable pattern of activity that represents the meaning of the word.
 If the network starts from this pattern in processing a subsequent word, it will be faster to settle for a related than for an unrelated word because many of the units will already be in their correct states.
 Distributed network theories bear an interesting relationship both to spreadingactivation theories and to compoundcue theories.
 Although, in some sense, activation "spreads" among units in a distributed network, this spread is not between concepts but between features.
 For a given pattern of activity, the degree to which any concept is "active" depends on its overlap with the current pattern.
 After settling into the meaning of a word, related meanings are active simultaneously (to the degree that they are similar)—no additional spread of activation is required.
 Thus, distributed network theories provide a more natural interpretation of the finding that, while the degree of relatedness influences the magnitude of priming, it does not influence its time of onset, which is essentially instantaneous (Lorch, 1982; Ratcliff & M c K o o n , 1981).
 In some ways, distributed network theories are more similar to compoundcue theories, in that the processing of a word is sensitive to the context in which it occurs (as reflected in the current state of the network).
 However, conjunctions need not be represented explicitly, so that processing can depend on properties of contexts independent of their cooccurrences with target words.
 Thus, for instance, distributed network theories can account naturally for the finding that different neutral contexts (e.
g.
, unrelated words, neutral words like READY, and nonwords) have equivalent effects on betweentrial priming, even though their familiarities as compounds with target words are very different (McNamara, 1994).
 Unfortunately, two sets of empirical findings appear to pose problems for distributed network theories of semantic priming.
 The first relates to findings that different types of relations among words influence priming in different ways.
 In particular, one can distinguish an associative relation among words (e.
g.
, as measured by free association norms; Post37 mailto:plaut@cmu.
eduman & Keppel, 1970) from a purely semantic relation (i.
e.
, having similar meanings, such as category coordinates).
 Associatively related word piiirs are typically also semantically related (e.
g.
, breai>butter) but many semantically related word pairs are not associatively related (e.
g.
, BREADcake).
 In the few studies that have studied priming among words that are semantically but not associatively related (e.
g.
, Fischler, 1977; Seidenberg, Waters, Sanders, & Langer, 1984), the priming effect is much smaller than that found for associatively related words, particularly in lexical decision, and the effect was completely absent under conditions which prevent expectancies and postlexical checking (Shelton & Martin, 1992).
 Furthermore, unlike semantic priming, jjssociative priming is highly asymmetric; for example, bei>pan produces strong priming whereas panbed produces little if any (particularly in naming; see Neely, 1991).
 Similar dissociations between semantic and associative effects have been demonstrated using crossmodel priming in sentence contexts (Moss & MarslenWilson, 1993) and in the degeneration of semantic memory in Alzheimer's disease (Glosser & Friedman, 1991).
 These data are problematic for distributed network theories (e.
g.
, Kawamoto, 1988; Masson, 1995) because they typically employ only a single, symmetric manipulation— pattern overlap—to encode word relatedness.
 There is no opportunity for different types of relations among w o r d s — semantic and associative—to behave differently.
 The second set of findings that has challenged distributed network theories is that associative priming can span an intervening unrelated item, such as in the word sequence breadDCX5BUTTER, although it is very weak under these conditions (Joordens&Besner, 1992;McNamara, 1994).
 In a distributed network, if the entire network settles completely to the meaning of the intervening word dog, then the pattern of activity representing the meaning of bread will be completely eliminated, leaving no opportunity for it to facilitate the processing of butter.
 Masson (1995) considered the possibility that the intervening word might be processed only panially, leaving residual semantic activation from BREAD to influence BUTTER.
 Using a Hopfield (1982) network, he simulated the small priming effect across unrelated words in a naming task by basing the network's response on the activity of phonological units which were updated more frequently than semantic units.
 Unfortunately, the simulations used a very small vocabulary (only three pairs of semantically related items), and no independent justification was provided for why phonological and semantic units should behave differently.
 The current paper presents a distributed network model of priming that addresses the challenges posed by associative vs.
 semantic priming and by priming across an unrelated item.
 The model differs from previous ones in two main ways.
 First, whereas semantic relatedness among words is encoded by the degree of overlap of their semantic feature representations, an association from one word to another is encoded directly in the likelihood that the one follows the other during training (see Moss, Hare, Day, & Tyler, 1994, for a similar approach).
 Second, a more powerful learning procedure is used—continuous backpropagation through time (Pearlmutter, 1989).
 This procedure has the critical properties that unit states change gradually over time in response to input, and that learning is sensitive to the entire trajectory from the initial activity pattern to the final activity pattern.
 The model jUso replicates a number of basic findings in the priming literature, including greater priming for lowfrequency targets, degraded targets, and highdominance category exemplars.
 Simulation M e t h o d Task.
 Given that semantic and associative priming have been demonstrated in a wide range of lexical tasks, the current work investigated priming in a general version of the task of understanding words: an abstract version of the task of mapping from written words to their meanings.
 The semantic representations of words were generated artificially but with considerable structure.
 Eight different random patterns were generated over 100 semantic features, in which each unit had a probability of 0.
1 of being active.
 These patterns served as the "prototypes" for eight separate semantic categories.
 Sixteen category exemplars were generated from each prototype pattern by randomly altering some of its features (Chauvin, 1988).
 Eightof these were typical or highdominance exemplars in which relatively few features of the prototype were changed (each feature had a probability of 0.
2 of being resampled with a probability of 0.
1 of being active).
 The remaining eight were atypical or lowdominance exemplars in which many more features were altered (resampling probability of 0.
4).
 The effect of this manipulation is simply to make all exemplars in a category cluster around the prototype, with highdominance exemplars more similar to the category prototype than lowdominance exemplars.
 Words will be considered semantically related if they were generated from the same prototype.
 The resulting 128 semantic representations were randomly assigned orthographic representations consisting of patterns of activity over 20 orthographic units.
 These patterns were generated randomly such that each unit had a probability of 0.
1 of being active, with the constraint that every pattern had at least two active units, and all pairs of patterns differed in the activities of at least two units.
 N o attempt was made to model orthographic relatedness among words; the orthographic patterns simply guaranteed that the written forms of words were fairly sparse and were discriminable from each other.
 For the current purposes, the critical property of this artificial task is that, although there are systematic relationships among word meanings, there is no systematic relationship between the written form of a word and its meaning.
 Within each dominance class of each category, half of the words were designated as highfrequency and the other half as lowfrequency.
 Each word was also assigned a single associated word, under the constraints that 1) every word was the associate of some other word; 2) associated words were never semantically related (i.
e.
, in the same category); and 3) there were no mutual associations among word pairs (i.
e.
, no two words were each other's associate).
 The frequency of a word and its association influenced how it was selected for presentation during training, as described below.
 Network Architecture.
 The network used to perform the task is depicted in Figure 1.
 The 20 orthographic units are fully connected to 100 hidden units which, in turn, are fully connected to the 100 semantic units.
 The semantic units themselves are fully interconnected (without selfconnections) and 38 c 100 semantic units E 3 I 100 hidden units I J ^ 20 orthographic units ^ Figure 1: The architecture of the network.
 Arrows represent full connectivity between or within groups of units.
 also send connections back to the hidden units.
 Thus, the hidden and semantic units interact in processing a given orthogr^hic input.
 Including the bias terms for the hidden and semantic units, the network has a total of 32,100 connections.
 The weights on these connections were initialized to random values between ±0.
25.
 The states of units in the network change smoothly over time in response to influences from other units.
 For the purposes of simulation on a digital computer, it is convenient to approximate continuous units with finite difference equations, in which time is discretized into ticks of some duration r.
 Thus, the input to unit j at time t is given by ^ = T'£^'^w,j+ilr)x^^^ (1) where s, is the state of unit i and Wij is the weight from unit i to unit j.
 According to this equation, a unit's input at each time tick is a weighted average of its current input and that dictated by other units, where r is the weighting proportion.
 A relatively large value of r is used during most of training (0.
2 in the current simulation), when minimizing computation time is critical, whereas a much smaller r is used during testing (e.
g.
, 0.
01), when a more accurate approximation of the underlying continuous system is desired.
 The state Sj of unit j at time t is simply the standard logistic or sigmoid function of its current input.
 , m _ ( [t]\ _ 1 (2) where exp() is the exponential function.
 Training Procedure.
 The network was trained in the following way.
 A word was presented to the network by clamping the states of the orthographic units to its assigned representation, distorted by a slight amount of random gaussian noise (with mean 0.
0 and S D 0.
05).
 O n most trials, all other units retained the inputs and states they had at the end of processing the previous word.
 However, for the very first word, and with a probability of 0.
01 throughout training, these units were given reinitialized inputs of 0.
0 and states of 0.
2.
 Then, for every time tick t of duration r = 0.
2 over a total of 4.
0 units of time, units in the network updated their states according to Equations 1 and 2.
 (Note that the absolute time scale of the network is arbitrary.
) A continuous version of backpropagation through time (Pearlmutter, 1989) was used to calculate changes to the connection weights that would reduce the discrepancy (measured using crossentropy; see Hinton, 1989) between activations of the semantic units over the last 2.
0 units of time and their correct activations for the presented word.
 This temporally extended error signal pressures the network to settle to the correct pattern as quickly as possible.
 After each word presentation, the weights were updated immediately (with a learning rate < = 0.
005 and momentum a = 0.
8) and the next word was chosen and presented.
 With a probability of 0.
2, the next word chosen was the associate of the previous word.
 O n the remaining trials, the probability that words were selected for training depended on their assigned frequency, such that highfrequency words were twice as likely to be trained as lowfrequency words.
 After 50,000 word presentations, r was reduced from 0.
2 to 0.
05, and after 3000 more presentations it was reduced to 0.
01 for a final 2000 presentations.
 At this point, the network was completely accurate in settling into the semantic representation of each word, regardless of the preceding context.
 Testing Procedure, The reaction time (RT) of the trained network in processing a word was defined as the time it took the network to settle to the point where no semantic unit changed it state by more than an output change tolerance of 0.
001.
 Priming in the network occurs because this settling time is influenced by the nature of the preceding prime word(s) processed by the network.
 Typically, when testing the network, words are presented in primetarget pairs.
 First, the network is initialized to inputs of 0.
0 and states of 0.
2.
 Then the prime word is presented (with no noise) and processed for some duration (the stimulus onset asynchrony, or S O A ) .
 At this point, the target replaces the prime and the settling time of the network in response to the target is measured.
 I»rimes can either be semantically related, associatively related, or unrelated to the target.
 To obtain the most reliable estimates of R T means for these various conditions, the R T for each word as target is measured when preceded by every other word as prime.
 For each item, its R T when preceded by each of the 15 other words in its category is averaged to yield a semantically related R T mean.
 Similarly, its RTs when preceded by the 111 words that are neither semantically nor associatively related yields an unrelated R T mean.
 Finally, the item's R T when preceded by the single word for which it is the associate is used as the associatively related R T value.
 These R T means were calculated at S O A s of 0.
25, 0.
5, 1.
0, 1.
5, 2.
0, 2.
5, 3.
0, and 4.
0.
 The manipulation of S O A is intended primarily to illustrate effects in network—direct comparisons with empirical results are problematic because longer S O A s are thought to introduce contaminating effects from subjectgenerated expectancies and postlexical checking (Balota & Chumbley, 1984; Seidenberg et al.
, 1984).
 Results and Discussion As in other distributed network models (e.
g.
, Masson, 1995), the distribution of R T values produced by the network in response to targets takes the form of a skewed gaussian, similar to that found in empirical studies (e.
g.
, Ratcliff & Murdock, 1976).
 For instance, in processing the 128 words in a neutral context (i.
e.
, units initialized to inputs of 0.
0 and states of 0.
2), the network produces RTs with mean 2.
26, S D 0.
294, and skew 0.
361.
 The network settles faster for highfrequency words (mean 2.
17) than for lowfrequency words (mean 2.
36; Fi i25=16.
35, p<.
001), as is typically found in wordrecognition studies (e.
g.
, Forster & Chambers, 1973).
 39 Kffect of Prime Duration on Associative I'riming 0.
45 0.
00 •O 0.
40 h 0.
30 SS 0.
25 t 0.
20 ° °  0.
15 \c C 0.
10 a.
 ^ i ) Low Frequency ligh Frequency 0.
0 0.
5 1.
0 1.
5 2.
0 2.
5 3.
0 3.
5 4.
0 Prime Duration (Stimulus Onset Asynchrony) Figure 2: Effect of the duration of the prime on associative priming for low and highfrequency targets.
 Effect of Prime Duration on Semantic Priming 0.
10 • — • High dominance A — A Lyow dominance i2 o.
ox a 0.
06 CO = 0.
03 0.
5 1.
0 1.
5 2.
0 2.
5 3.
0 3.
5 4.
0 Prime Duration (Stimulus Onset Asynchrony) Figure 3: Effect of the duration of the prime on semantic priming for high and lowdominance targets.
 However, w e are more interested in differences in R T s as a function of primetarget reiatedness.
 Thus, the remainder of the paper will report data on analyses of differences between related vs.
 unrelated R T means, first for associatively related words and then for semantically related words.
 Associative Priming.
 For each word (e.
g.
, butter), the difference between the mean R T s for unrelated primes (e.
g.
, D O G ) and the R T for its associated prime (e.
g.
, BREAD) at each S O A was computed.
 Positive differences reflect associative priming—faster settling for related than unrelated primes.
 These difference scores were entered into a 2x2x8 A N O V A over items, with target category dominance (high vs.
 low) and frequency (high vs.
 low) as betweenitem factors and the eight values of S O A as a withinitem factor This analysis revealed a strong effect of associative priming, with a R T difference of 0.
250 between unrelated versus related primes (Fi i24=271.
0, p<.
001).
 T he degree of priming was affected strongly by S O A , with greater priming at longer S O A s (F7,868= 154.
8, p<.
001).
 It was also influenced by the frequency of the target, with lowfrequency targets showing greater priming (mean 0.
324) than highfrequency targets (mean 0.
176; Fii 24=23.
88, p<.
001), as found in empirical studies (see Neely, 1991).
 Furthermore, frequency interacted reliably with S O A such that the difference in priming between low and highfrequency targets increased with longer S O A s (F? 868=13.
61, p<.
001).
 B y contrast, there was no main effect of target category dominance ( F < 1 ) , nor did this factor interact with frequency or S O A .
 Accordingly, the data were collapsed across target category dominance.
 Figure 2 presents the mean associative priming found across S O A for low and highfrequency targets.
 Associative priming occiu"s in the network because, during training, it was pressured to learn to m a k e a rapid transition from the meaning of the prime to the meaning of its associated word m u c h more frequently than transitions to the meanings of other words.
 Highfrequency targets benefit less from this extra support because semantic units are already being driven more strongly than for lowfrequency words; due to the asymptotic behavior of the logistic activation function, any additional input to a unit yields diminishing changes in its activation as it approaches the extremes of 0.
0 or 1.
0.
 A n equivalent analysis with the associated primes and targets reversed revealed no significant backward associative priming nor any interactions ( F < 1 for all comparisons).
 Semantic Priming.
 A similar analysis was performed on the differences in R T s for unrelated primes versus semantically related primes (e.
g.
, breadcake).
 The pattern of results is quite different from that for associative priming.
 Semantic priming is m u c h weaker (mean 0.
044; Fi ,24=29.
96, p<.
001), and it interacts with target category dominance (means: high 0.
062, low 0.
027; Fi,i24=4.
67, p=.
033) rather than frequency ( F < 1 ) .
 Furthermore, the change in semantic priming over S O A (F7,868=22.
82, p<.
001) is very different than for associative priming (see Figure 3 and compare with Figure 2, noting the scale difference).
 In particular, semantic priming peaks at very short S O A s then gradually declines as the prime is processed more fully.
 At intermediate S O A values, such priming m a y even be too weak to detect experimentally (as in the Shelton & Martin, 1992, study).
 W h y does semantic priming behave so differently compared with associative priming? Early on in processing a semantically related prime, units m o v e towards a pattern that is similar to the pattern for the target, and this benefits subsequent processing of the target as long as units are still within the linear range of the logistic activation function.
 However, with additional processing, units are driven to more extreme values, including those that differ between the prime and target patterns.
 In order to identify the target accurately, all of these differences must be cortected.
 The time it takes for processing of the target to accomplish this is influenced by the number of units the prime and target have in c o m m o n (as indicated by the effect of category dominance, matching the empirical findings), but this influence is relatively weak.
 As the prime is processed more fully, the time it takes to change the states of incortect units is relatively independent of the number of other, cortect units, so that semantically related 40 Effect of Target Degradation on Associative Priming 0.
70 0.
65 OLow FrequeDcy High Frequepcy 2 0.
60 : ^ 0.
55 t i 0.
45 S 0.
40 &.
 0.
25 0.
00 0.
05 0.
10 0.
15 Target Degredation 0.
20 Figure 4: Effect of the degree of degradation of the target ciative pruning for low and highfrequency targets.
 on assoAssoclative Priming Spanning Unrelated Item 0.
025 • ^ 0.
020 u 1 0.
015 CO 0.
010 00 .
5 i; 0.
005 0.
000 O OLow Frequency —•Hifth Frequency 0 0.
000 0.
001 0.
005 0.
002 0.
003 0.
004 Output Change Tolerance Figure 5: Effect of output change tolerance on the magnitude of associative priming across an intervening unrelated item for lowand highfrequency targets.
 primes provide almost no advantage over unrelated primes.
 Target Degradation.
 Empirical studies have found that priming is increased if targets are degraded visually (e.
g.
, by reducing contrast; see Neely, 1991).
 To investigate this effect in the model, the orthographic input patterns for targets were reduced in visual contrast by scaling the input values towards the neutral value of 0.
2 by varying amounts (0.
05, 0.
10, 0.
15, and 0.
2).
 For example, for a normal input of 1.
0 and a degradation of 0.
05, the presented input value would be 1.
00.
05(1.
00.
2) = 0.
96.
 Reaction times to degraded targets were measured when preceded by each word as a prime with an S O A of 2.
0.
 The differences between R T s for targets preceded by their associatively related prime and their mean RTs when preceded by unrelated primes were entered into an 2x4 A N O V A over items, with target frequency as a betweenitem factor and target degradation as a withinitem factor.
 Priming was influenced reliably by word frequency (means: low 0.
242, high 0.
489; Fi,i26=20.
41,p<.
001), replicating the effect found with nondegraded targets.
 M o r e importantly, there was greater priming for more highly degraded targets (F3,378=6.
683, p<.
001; see Figure 4).
 The interaction of frequency and degradation was not reliable (F3 378=1.
519, p=.
209).
 Thus, the network replicates the empirical finding that target degradation increases associative priming.
 Priming Across Intervening Unrelated Items.
 The final experiment tested the conditions under which associative priming spanned an intervening unrelated item (e.
g.
, breai>DOGBUTTER).
 Such priming is observed empirically when items are processed relatively briefly.
 For example, Joordens and Besner's (1992) subjects named each stimulus item under a very short (300 msec) intertrial interval, producing naming latencies about 150 msec faster than in typical naming studies.
 These testing conditions can be approximated with the model by having it process the prime, the intervening item, and the target using a lessstringent criterion for the degree to which the output must settle before the network responds.
 Accordingly, the magnitude of associative priming across an unrelated item was investigated across increasing values of the output change tolerance: 0.
001 (the original value), 0.
0015, 0.
002,0.
003, and 0.
004.
 To get a good estimate of the associatively related R T means, each association was tested with every other word in the corpus that was unrelated associatively and semantically to both the prime and target as the intermediate item.
 The R T means for unrelated primes were based on presenting every unrelated word as prime five times, each with a different randomly selected unrelated word as the intervening item.
 Responses in which the state of any semantic unit was not on the correct side of 0.
5 (no more than 1.
3% of trials in any condition) were considered errors and were excluded fiom the calculation of the means.
 The differences in R T means between related and unrelated primetarget pairs were then subject to a 2x5 A N O V A over items, with target frequency as a betweenitem factor and output change tolerance as a withinitem factor.
 Figure 5 shows the degree of priming across an unrelated item for high and lowfrequency targets.
 There is a small but reliable overall priming effect (mean 0.
012, Fi,124=33.
5, p<.
001) which is influenced both by frequency (Fi 124=7.
91, p=.
006) and by output change tolerance (F4,496=7.
77, p<.
001), and these factors interact (F4,496=2.
61, p=.
035).
 Thus, the network exhibits significant associative priming across an intervening unrelated item, particularly under conditions which encourage fast responding (as found by Joordens & Besner, 1992).
 Conclusions The current paper presents a distributed attractor network trained with recurrent backpropagation on an abstract version of the task of deriving the meanings of written words.
 In the task, semantically related words are defined to overlap in their semantic features, whereas associatively related words are defined to follow each other often during training (also see Moss et al.
, 1994).
 The network exhibits two empirical effects that have posed problems for distributed network theories: much stronger associative priming than semantic priming (Shelton & Martin, 1992), and significant associative priming across an intervening unrelated item (Joordens & 41 Besner.
 1992).
 It also reproduces the empirical findings of greater priming for lowfrequency targets, degraded targets, and highdominance category exemplars (see Neely, 1991).
 One phenomenon it fails to reproduce, however, is mediated priming (e.
g.
, UONSTRIPES, via tiger).
 Thus, on the current approach, mediated priming must be attributed to weak direct associative or semantic priming (McKoon & Ratcliff, 1992).
 Nonetheless, the current simulation demonstrates that distributed network theories of semantic memory can account for a wide range of empirical findings on semantic and associative priming.
 Acknowledgments I thank Marlene Behrmann for helpful comments on this paper.
 Financial support for this research is provided by the National Institute of Mental Health (Grant MH47566) and the McDonnellPew Program in Cognitive Neuroscience (Grant T8901245016).
 References Anderson, J.
 R.
 (1983).
 The architecture of cognition.
 Cambridge, M A : Harvard Press.
 Balota, D.
 A.
, & Chumbley, J.
 I.
 (1984).
 Are lexical decisions a good measure of lexical access? The role of word frequency in the neglected decision stage.
 Journal of Experimental Psychology: Human Perception and Performance, 10, 340357.
 ChdM\\n,Y.
 (\9%%).
 Symbolacquisitionin humans and neural(PDP) networks.
 PhD thesis.
 University of California, San Diego.
 Collins, A.
 M.
, & Loftus, E.
 F.
 (1975).
 A spreadingactivation theory of semantic processing.
 Psychological Review, 82,407428.
 Dosher, B.
 A.
, & Rosedale, G.
 (1989).
 Integrated retrieval cues as a mechanism for pruning in retrieval from memory.
 Journal of Experimental Psychology: General,!, 191211.
 Fischler, I.
 (1977).
 Semantic facilitation without association in a lexical decision task.
 Memory and Cognition, 5, 335339.
 Forster, K.
 I.
, & Chambers, S.
 (1973).
 Lexical access and naming time.
 Journal of Verbal Learning and Verbal Behaviour, 12, 627635.
 Gillund, G.
, & Shiffrin, R.
 M.
 (1984).
 A retrieval model for both recognition and recal.
 Psychological Review, 91, 167.
 Glosser, G.
, & Friedman, R.
 B.
 (1991).
 Lexical but not semantic priming in Alzheimer's disease.
 Psychology and Aging, 6(4), 522527.
 Hinton, G.
 E.
 (1989).
 Connectionist learning procedures.
 Artificial Intelligence, 40, 185234.
 Hintzman, D.
 L.
 (1986).
 "Schema abstraction" in a multipletrace memory model.
 Psychological Review, 93,411428.
 Hopfield, J.
 J.
 (1982).
 Neural networks and physical systems with emergent collective computational abilities.
 Proceedings of the National Academy of Science, USA, 79, 25542558.
 Joordens, S.
, & Besner, D.
 (1992).
 Priming effects that span an intervening unrelated word: Implications for models of memory representation and retrieval.
 Journalof Experimental Psychology: Learning, Memory, and Cognition, 180), 483—491.
 Kawamoto, A.
 (1988).
 Distributed representations of ambiguous words and their resolution in a connectionist network.
 In S.
 L.
 Small, G.
 W.
 Cottrell, & M.
 K.
 Tanenhaus (Eds.
), Lexical ambiguity resolution: Perspectives from psycholinguistics, neuropsychology, and artificial intelligence.
 San Mateo, C A: Morgan Kaufmann.
 Lorch, R.
 F.
 (1982).
 Priming and search processes in semantic memory: A test of three models of spreading activation.
 Journal of Verbal Learning and Verbal Behaviour, 21, 468492.
 Masson, M.
 E.
 J.
 (1991).
 A distributed memory model of context effects in word identfication.
 In D.
 Besner, & G.
 W.
 Humphreys (Eds.
), Basic processes in reading (pp.
 233263).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Masson, M.
 E.
 J.
 (1995).
 A distributed memory model of semantic priming.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 27(1), 323.
 McKoon, G.
, & Ratcliff, R.
 (1992).
 Spreading activation versus compound cue accounts of pnming: Mediated priming revisited.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 18(6), 11551172.
 McNamara, T.
 P.
 (1992a).
 Priming and constraints it places on theories of memory and retrieval.
 Psychological Review, 99(4), 650662.
 McNamara, T.
 P.
 (1992b).
 Theories of pnming I: Associative distance and \ag.
 Journalof Experimental Psychology: Learning,Memory, and Cognition, 18(6), 11731190.
 McNamara, T.
 P.
 (1994).
 Theories of priming EI: Types of primes.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 20(3), 507520.
 McRae, K.
, de Sa, V.
, & Seidenberg,M.
 S.
 (1993).
 Modeling property interactions in accessing conceptual memory.
 Proceedings of the 15th Annual Conference of the Cognitive Science Society (pp.
 729734).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Moss, H.
 E.
, Hare, M.
 L.
, Day, P.
, & Tyler, L.
 K.
 (1994).
 A distributed memory model of the associative boost in semantic priming.
 Connection Science, 6(4), ̂ \7>ATl.
 Moss, H.
 E.
, & MarslenWilson, W.
 D.
 (1993).
 Access to word meanings during spoken language comprehension: Effects of sentential semantic context.
 Journalof Experimental Psychology: Learning, Menwry, and Cognition, 79(6), 12541276.
 Murdock, B.
 B.
 (1982).
 A theory for the storage and retrieval of item and associative information.
 Psychological Review, 89,609626.
 Neely, J.
 H.
 (1991).
 Semantic priming effects in visual word recognition: A selective review of current findings and theories.
 In D.
 Besner, & G.
 W.
 Humphreys (Eds.
), Basic processes in reading (pp.
 264336).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Pearlmutter, B.
 A.
 (1989).
 Learning state space trajectories in recurrent neural networks.
 Neural Computation, 7(2), 263269.
 Postman, L.
, & Keppel, G.
 (1970).
 Norms of word associations.
 New York: Academic Press.
 Ratcliff, R.
, & McKoon, G.
 (1981).
 Does activation reaUy spread? Psychological Review, 88,454462.
 Ratcliff, R.
, & McKoon, G.
 (1988).
 A retrieval theory of priming in memory.
 Psychological Review, 88, 385408.
 Ratcliff, R.
, & McKoon, G.
 (1994).
 Retrieving information from memory: Spreadingactivationtheories versus compoundcuetheories.
 Psychological Review, 101,177184.
 Ratcliff, R.
, & Murdock, B.
 B.
 (1976).
 Retrieval processes in recognition memory.
 Psychological Review, 83, 190214.
 Seidenberg, M.
 S.
, Waters, G.
 S.
, Sanders, M.
, & Langer, P.
 (1984).
 Pre and postlexical loci of contextual effects on word recognition.
 Memory and Cognition, 12, 315328.
 Sharkey, A.
 J.
, & Sharkey, N.
 E.
 (1992).
 Weak contextual constraints in text and word priming.
 Journal of Memory and Language, 57(4), 543572.
 Shelton, J.
 R.
, & Martin, R.
 C.
 (1992).
 How semantic is automatic semantic priming? Journalof Experimental Psychology: Learning, Memory, and Cognition, 18{6), 11911210.
 Smith, E.
 E.
, & Medin, D.
 L.
 (1981).
 Categories and concepts.
 Cambridge, MA: Harvard University Press.
 42 Evidence for Subitizing as a StimulusLimited Processing P h e n o m e n o n Tony J.
 Simon School of Psychology Georgia Institute of Technology Atlanta GA 303320170 tony.
 s iinon@psych.
 gatech.
 edu Angel Cabrera School of Psychology Georgia Institute of Technology AUaniaGA 303320170 angelSpsy.
skiles,gatech.
edu Abstract We present an experiment where subject's subitizing performance for linear dot arrays was analyzed using Differential Time Accuracy Functions.
 This technique uses accuracy and reaction time data to decompose overall response latency into stimuluslimited and poststimulus processing.
 Our results show that subitizing is a phenomenon produced by the effects of increased numerosity on stimuluslimited processes alone.
 They also suggest that the familiar guessing strategy for the largest arrays in reaction time measures of subitizing results from a reduction in poststimulus processing.
 Subjects appear to extract the perceptual characteristics of all arrays but presumably fail for the largest and therefore default to guessing.
 Existing theories of subitizing are evaluated in light of these results.
 Introduction The phenomenon known as subitizing has been implicated as a foundational capability in the develoiMnent of numerical and mathematical competence (Geary, 1995; Simon & Klahr, 1995).
 Yet, despite its investigation by psychologists for more than 100 years (e.
g.
 Jevons, 1871) a definitive information processing account remains to be developed.
 Subitizing describes the ability of adults and children to very rapidly and accurately enumerate a small number of discrete entities.
 The number of items is typically in the range of 35.
 Beyond that number, enumeration proceeds at a much slower rate and with considerably more errors (Atkinson, Campbell & Francis, 1976; Chi & Klahr, 1975; Svenson & Sjoberg, 1983).
 Thus, a satisfactory account of subitizing must adequately explain 2 aspects of the phenomenon.
 One is the reason for the very rapid rate of processing for small numerosities, which is evident in a slope of around 40 to 1(X) milliseconds per item.
 The other is the limit or span of subitizing.
 which is defined by a sharp discontinuity in performance that occurs when subjects reach the maximum number of items they can enumerate in this way.
 Despite the lack of consensus cm a detailed explanation of subitizing, there is considerable agreement on a higher level of analysis.
 Subitizing is assumed, if only implicitly, to comprise 2 broad phases of processing (Klahr & Wallace, 1976; Trick & Pylyshyn, 1994; van Oeffelen & Vos, 1982).
 The first involves some kind of object individuation processing.
 Target items must be located, their features integrated and spatial locations determined.
 The second involves assigning a quantitative label, either to the entire set of objects at once, or iteratlvely to a subset of them, thus requiring subsequent summation.
 W e will refer to this as the enumeration phase, although the term is used in an atheoretical sense and no particular enumeration strategy is implied.
 The first of these two phases must employ domainindependent processes because object identification or individuation is not a task that is specific to enumeration.
 However, the second phase is certainly enumerationspecific.
 This distinction has been expanded on by the research of Trick & Pylyshyn (1993, 1994), w h o have linked the first phase to early attentional processing.
 A number of theories have attempted to explain subitizing's slqje and limit by appealing to one or other of these phases as the locus of the characteristic subitizing performance profile.
 There is not space here to review them in detail, but w e shall briefly present the key aspects of three theories to contrast their accounts of subitizing.
 Theories of Subitizing The first detailed processing account of subitizing, developed by David Klahr (Klahr, 1973; Klahr & Wallace, 1976), had the primary goal of explaining the subitizing slope.
 The theory was stated in the form of a production system model in which rules "unpack" clusters of objects before the size of the group can be determined.
 The basic process is the aeation of symbols in "Semantic Short Term Memory" ( S S T M ) from what might be referred to as "signals" in "Visual Short Term Memory" ( V S T M ) , which contains the output of iconic processing.
 The quantitative symbols created in S S T M name a particular set size of objects that has been recognized in V S T M by quantityspecific productions.
 Being a serial system, the more objects there are in V S T M , the longer the recognition takes.
 Thus the cycle time of production firing, assumed by Klahr & Wallace to be 45 ms, accounts for the subitizing slope.
 Therefore, Klahr & Wallace's account of the subitizing slope is that it comes from processes that deal directly with the physically present stimuli represented in V S T M , "an exQ° emely shortterm memory ahead of S T M in the visual chain" (1976, p.
43).
 However, no data were collected that could be used to directly evaluate the proposed model.
 Mandler & Shebo's (1982) primary goal was to explain the subitizing limit in terms of "canonical pattern" recognition.
 They claimed that, during childhood, w e learn 43 that collections of 1 to 3 objects fall into regular configurations: 1 is a singleton, 2 a line and 3 a triangle.
 Our recognition of these patterns results in a subitizing limit of 3 objects with a flat response profile.
 Explaining subitizing in terms of patternrecognition means that Mandler & Shebo also load their account on perceptual processes.
 Since this account assumes that recognition of each canonical pattern happens as a single event, no slope is predicted by this account.
 The subitizing limit is predicted to be the limit of canonical patterns, i.
e.
 3 items.
 While Mandler & Shebo's theory does attempt to account for both the subitizing limit and slope, the theory is challenged by a lot of data.
 In particular.
 Akin & Chase (1978) found subitizing slopes and varying spans using block stimuli, many of which were similar to Mandler & Shebo's dot patterns.
 The most recent account of subitizing is the FINST theory (Trick & Pylyshyn, 1993; 1994).
 This account primarily aims to explain the subitizing limit as a sideeffect of the object individuation process in early vision.
 In this respect, the theory shares much in c o m m o n with Klahr & Wallace's, since objects must be individuated before they can be enumerated.
 The main difference is that, in the FINST theory, object individuation takes place in parallel in the preattentive stage of vision.
 Here, object markers, or FINSTs, are attached to targets in the visual field for later processing, such as enumeration.
 Thus the subitizing slope prediction is exacUy the reverse of Klahr & Wallace's.
 Since FINSTs are assigned in parallel, the slope can only arise from post stimulusdependent processing.
 Trick & Pylyshyn (1994) state that "the response choice rather than the variable binding accounts for the subitizing slope" (p.
 89).
 However, like Klahr & Wallace's account, there are no data that can be used to prove or disprove the operation of the FINST mechanism.
 The limit of subitizing is predicted to be the limit of the number of FINSTs that can be assigned.
 This is claimed to be 4 but no reason is given as to why it is not 5 or 3 or why it could not vary within or between individuals.
 In this paper w e present an analysis of subitizing performance that focuses on what we will call stimuluslimited processing.
 The label comes from Salthouse's (1981) definition of stimuluslimited and responselimited processes.
 Stimuluslimited processes are those which are assumed to operate when "the subject's processing [is] presumably controlled by the duration of the stimulus, and the subject [has] an unlimited time to respond" (Salthouse, 1981.
 p.
 44).
 Responselimited processes are assumed to be those that operate when "stimuli [are] presented until the subject [makes a] response and it [is] the occurrence of the response that limited the information processing" (Salthouse.
 1981.
 p.
 44).
 The methods that w e have used to assess subitizing performance fit Salthouse's defmition of tasks for measuring stimuluslimited processing, and we think that they provide insight into subitizing for the following reason.
 While the slimuluslimited/responselimited distinction does not necessarily imply a decomposition of subitizing into object individuation and enumeration phases, it seems reasonable to assume that objectindividuation processes would be stimuluslimited in nature.
 This is because the quality of the representations that perceptual processes are able to create would be limited to information that could be extracted while the stimuli were available for inspection.
 Therefore, limited exposure, masked stimuli, like those we presented should enable us to examine the effects of increasing numerosity on stimuluslimited processes.
 If subitizing is based on object individuation processes, one would predict an increase in stimulusUmited processing with numerosity, as did Klahr & Wallace.
 However, if the phenomenon is due to response selection, as Trick & Pylyshyn propose, then increasing number should not affect stimuluslimited processing in a significant manner.
 Therefore, we believe that analyzing the stimuluslimited characteristics of subitizing will provide one way to determine which existing account offers the best prospects of progress towards a fully specified information processing account of subitizing.
 Differential TimeAccuracy Functions Our methodology of individual subject analysis based on Time Accuracy Functions (TAFs) has been described in detail elsewhere (Simon, Cabrera & Kliegl.
 1993).
 However, a brief description is required here in order to explain our results.
 Prior to each experiment we use pilottesting to generate a diagnostic range of presentation times for each of the numerosities 2 through 8.
 Such a range comprises 10 presentation times where the shortest produces close to chance performance and the longest produces close to perfect enumeration.
 Nine of the times are separated by the same increment and a tenth "dummy" time is added with a larger increment.
 This provides maximal overlap with ranges for other numerosities, thereby reducing the chance that subjects can detect a numerosity on the basis of presentation time alone.
 From each subject's responses (based on 1400 trials) we generate a T A F showing the accuracy profile with respect to presentation time.
 In our earUer work (Simon et al.
.
 1993), this relationship was then modeled using a negatively accelerated exponential function.
 Subitizing produces very steep functions, rising from chance to nearperfect detection with minimal additions of presentation time.
 Other enumeration strategies.
 used for larger numerosities, are reflected in shallower to almost linear functions.
 Figure 1 presents TAFs from a subject in the current experiment w h o subitized the numerosities 2 through 4.
 The analysis that allows reaction time decomposition into stimuluslimited and poststimulus components is described in detail by Cabrera & Simon (1995).
 In summary, individual subject T A F s are taken as input to analyses whereby Differential Time Accuracy Functions (DTAFs) are computed to produce measures of stimuluslimited processing.
 Each T A F is interpreted as the cumulative probability distribution of the time a subject needs to successfully complete a given task.
 By differentiating this distribution with respect to time, the corresponding probability density function can be ccmputed.
 From this we can estimate, among other things, the mean (or mathematical expectation), and the standard deviation of process duration.
 The mean represents the maximum likelihood estimator for the duration of the stimuluslimited processes.
 44 r N.
5&6 / N.
7&8 500 1000 1500 Presentation Time (ms) 2000 Figure 1: Time Accuracy Functions from Subject # 29 The standard deviation reflects the complexity of these processes.
 A small standard deviation is indicative of a unitary, simple process whereas a large standard deviation is taken to indicate the combination of several separate processes.
 W e will refer to these measures as the subject's mean duration and standard deviation of duration.
 These measures do not account for the entire reaction time of the subject, but only for the time it takes to extract the perceptual information that is needed.
 The rest of the operations that occur correspond to what we call poststimulus processes.
 W e assume these to be independent of, and sequentially related to stimuluslimited processes.
 Therefore, subtracting mean duration from total response time gives an estimate of poststimulus processing for the task in question.
 It is important to note that these poststimulus processes are not the same as responselimited processes.
 As Salthouse (1981) makes clear, responselimited processes cannot be measured unless the subject has control over presentation time by virtue of terminating it with a response.
 This was not the case in the experiment reported here.
 Therefore, we define poststimulus processing as the mental activity that takes place subsequent to stimuluslimited processing.
 W e are interested here in 2 main questions.
 First, are the slopes achieved by combining stimuluslimited and poststimulus measures together similar to previous reaction time slopes? If they are, this would provide evidence that our analyses produce credible data for the study of subitizing.
 Second, what are the relative contributions of stimuluslimited and poststimulus processes to the subitizing and postsubitizing slopes? In other words, we should be able to determine whether the subitizing slope is produced primarily by stimuluslimited processes, by poststimulus processes or by some combination of both.
 W e shall report data from an experiment where subjects were shown dots in linear arrays of varying numerosities for a range of presentation times.
 A number of stimulus configurations have been used in subitizing studies, all of which have their strengths and weaknesses.
 Our larger research project is examining the effects on processing of presenting a range of these.
 The linear arrays used in this experiment have the benefit of removing cues to number such as subjective grouping or familiar patterning, and they are similar to those used in previous experiments (Atkinson, Campbell & Francis, 1976; Atkinson, Francis & Campbell, 1976; Svenson & Sjoberg, 1983).
 Yet, they have the disadvantage that linelength may provide numerosity cues.
 However, a control study that we have carried out provided evidence that linelength alone is a very weak cue to absolute numCTOsity.
 Method Materials All experiments were carried out using an Apple Macintosh Ilfx computer with 13 inch highresolution R G B display.
 Stimulus presentation and data collection were controlled by the Cedrus Superiab software package.
 The stimuli were 9point helvetica type font letter Os arranged without typed spaces between them.
 They appeared as black circles on a white background centered horizontally and vertically on the screen.
 The longest row (N=8) was 5/8 inch in length.
 The mask that was employed was a row of 16 identical letter Os that was 1 1/8 inches length.
 Response time measures were collected by means of a voiceactivated relay.
 Subjects Twentyeight undergraduate students who enrolled in introductory psychology classes volunteered as subjects in return for extra credit and completed the procedure.
 There were 17 males and 11 females.
 All had normal or corrected vision.
 Procedure Instructions were presented to subjects on the computer and were read in a selfpaced manner.
 A n experimenter was on hand to answer any questions that arose at this point or after completing 10 trials sampled from the task itself.
 These were employed to show subjects what they could expect to experience during the experiment Stimuli were presented at eye level, 30 inches from the subject and subtended less than 2 degrees of visual angle, to ensure foveal presentation.
 Each trial began with the presentation of a fixation arrow for 1250 milliseconds.
 The head of the arrow pointed to the location where the center of the stimulus to be presented would appear.
 At the offset of the stimulus arrow, a stimulus was presented for its jMedetermined presentation time and then was masked.
 Any response emitted by the subject was not recorded until the mask appeared.
 However, once the stimuli were masked, the timer was stopped by the subject's spoken the numerical response.
 At this point the subject typed the same number he or she had just spoken.
 This was stored by the Superiab program which used it as a signal to begin the next trial.
 Subjects were instructed to respond as quickly as possible without sacrificing accuracy.
 Trials were presented in blocks of 70 (7 numerosities each with 10 presentation times) with trials randomized within each block.
 At the end of every block the subject could rest and continue the experiment when s/he was ready.
 The program requested that the subject take at least a 2 minute break after blocks 8 and 16.
 The presentation times that provided diagnostic ranges for this experiment were determined during pilot testing and are shown in Table 1 45 Table 1: Diagnostic Ranges of Presentation Times in Milliseconds Time Tl T2 T3 T4 T5 T6 17 T8 T9 TIO increment N=2 35 45 55 65 75 85 95 105 115 250^ 10 N=3 35 48 61 74 87 100 113 126 139 300d 13 N=4 35 70 105 140 175 210 245 280 315 500d 35 N=5 75 150 225 300 375 450 525 600 675 850d 75 N=6 75 175 275 375 475 575 675 775 875 llOOd 100 N=7 200d 350 600 850 1100 1350 1600 1850 2100 2350 250 N=8 200^ 350 625 900 1175 1450 1725 2000 2275 2550 275 ^ Dummy time Results Mean duration of stimuluslimited processes was calculated for each individual subject for all 7 numerosities (28).
 These were then subjected to a single factor (numerosity) repeated measures analysis of variance.
 Results showed a significant increase of mean duration F(6, 162) = 164.
07 p<.
001.
 This demonstrates that, as numerosity increased, the mean duration of stimuluslimited processing also increased.
 W e then carried out regression analyses on stimuluslimited and poststimulus processes.
 Poststimulus processing times were computed based only on correct trials.
 In order to compare our fmdings to those of previous studies w e carried out regressions independently on the numerosities 24 (to represent the subitizing range) and 58 (to represent the range in which counting and other processes are executed).
 Within the subitizing range the results were as follows.
 The slope for stimuluslimited processes was 59.
7 m s per item, r = .
6, F(l.
 82) = 123.
0 p<.
001, while the regression for poststimulus processes was not significant, r = .
08, F(l, 82) = 0.
55 n.
s.
 This suggests that all of the impact of increasing numerosity within the subitizing range was found in stimuluslimited i^ocesses alone.
 Outside the subitizing range a different pattern of results was found.
 The slope for stimuluslimited processes was 227.
6 m s per item, r = .
6, F(l, 110) = 157.
8 p<.
001.
 The regression for poststimulus processes was also significant, with a slope of 130.
3 m s per item, r = .
5, F(l, 110) = 37.
2 p<.
001.
 W h e n stimuluslimited and poststimulus processes are combined additively, as discussed by Cabrera & Simon (1995), w e find a striking resemblance in our results to those from previous studies.
 Total processing showed slopes of 59.
7 milliseconds per item in the subitizing range and 357.
9 milliseconds per item outside the subitizing range.
 These times are precisely in the range found by traditional reaction time measures of subitizing.
 This suggests that our methodology, which controls presentation time and hence response latency, does not interfere with subject's response patterns, even for the rather long presentation times associated with the larger numerosities.
 These results appear to provide 2 kinds of evidence that our methodology and analyses are useful tools for the study of subitizing.
 First, our estimates of overall reaction time agree with those from traditional reaction time studies showing slopes of 40 to 120 m s per item and 250 to 370 m s per item inside and outside the subitizing range 46 20001750150012501000750500250— Q .
 — Stimuluslimited •  o "  Poststimulus —A Total Processing |1>—̂ .
.
.
Q'̂  Numerosity Figure 2: Total and Decomposed Process Times respectively (Trick & Pylyshyn, 1994).
 Second, and more importantly, the results reveal which class of processes produce the subitizing slope.
 Figure 2 shows a plot of the duration of stimuluslimited processes, poststimulus processes, and overall processing duration inside and outside the subitizing range.
 As can be seen, the subitizing slope is solely a phenomenon of stimuluslimited processes.
 There is a 59.
7 millisecond slope for those processes in the subitizing range and no slope for the poststimulus processes in the N = 2  4 range.
 These latter processes only begin to play a role outside the subitizing range, but in the current study only provide 3 6 % of the overall slope.
 Discussion The experiment reported here produced results based on aggregated data that are very similar overall to those reported from previous studies.
 The slopes inside and outside the subitizing range produced by combining those of stimuluslimited and poststimulus processes are exactly of the expected magnitudes.
 More importantly, the deccwnposed processes show that the subitizing slope is solely a function of increased stimuluslimited processing as numerosity increases in the subitizing range.
 Outside the subitizing range these processes still comprise 2/3 of the slope, but now poststimulus processes play a role also.
 These results support the subitizing model i^oposed by Klahr & Wallace (1976), that increased numerosity generates the characteristic response time slope by affecting those processes that operate on the perceptual characteristics of the available stimuli.
 It is still unclear IMecisely what these processes are.
 However, our research is pnx:eeding with a similar assumption to that of Trick & Pylyshyn; that object individuation processes are likely to be involved.
 Nevertheless, our results counter Trick & Pylyshyn's model, which suggests that response selection processes are responsible for the subitizing slope.
 Such selection processes would surely fall into the poststimulus and not the stimuluslimited class.
 In other words, Trick and Pylyshyn's model would predict poststimulus ivocesses to show a slope in the subitizing range, ratho* than stimuluslimited processes.
 Figure 2 depicts exactly the opposite picture.
 The results also counter Mandler & Shebo's model, which predicts no slope at all within the subitizing range.
 Furthermore, our results ̂ pear to reveal new piece of evidence.
 A typical finding in reactioa time measurements of subitizing is that response latency for the largest numerosity often decreases, especially when subjects know what that numerosity is.
 The generally accepted explanation is that subjects employ a guessing strategy when many objects are presented.
 It is assumed that they do not attempt to quantify the larger arrays, but simply respond with the highest possible number.
 Hence the decision not to quantify the stimulus objects is reflected in lowered response time (as well as more errors).
 Our data show that, for the subjects w e tested, this account is not strictly accurate.
 It can be seen from the Figure 2 that stimuluslimited processing increases with every numerosity increase, and very markedly for the largest numerosities.
 Thus, it appears that our subjects did try to quantify all the arrays that were presented, even the very largest ones.
 Presumably, they ran out of presentation 47 time before object individuation could be completed for the array containing 8 dots and decided against investing resources in enumerating an array that they had failed to examine completely.
 Simply guessing the largest number is still likely to produce a correct response on some trials.
 This account is consistent with the dip in duration of poststimulus processes for the last numerosity.
 Further studies which considerably lengthen presentation times for the largest numbers should provide data that would enable the evaluation of such an hypothesis.
 W e believe that the D T A F analysis we have presented is a very promising one for the investigation of the subitizing phenomenon.
 The results presented here are still rather preliminary, and further research is in progress on studies using other stimulus types.
 However, our data do suggest that subitizing linear arrays is entirely a function of increased stimuluslimited processing in response to increases in numerosity up to 4 items.
 In order to properly study the role of poststimulus processes in these tasks, further research is needed where a selfterminated presentation time design is used.
 This would enable the examination of what Salthouse (1981) called responselimited processes.
 However, if our present results are found to be stable, then we abeady have a prediction for such studies.
 Responselimited processes are presumably not those primarily involved in object individuation and so would be predicted to only show effects of increased numerosity outside the subitizing range.
 Ack nowledgements W e would like to thank Christa Dell, Alan Kersten, Reinhold Kliegl, Jonah Lunken & Sandeep Vaishnavi for their input.
 References Akin, O.
 & Chase, W .
 (1978) Quantification of threedimensional structures.
 Journal of Experimental Psychology: Human Perception & Performance 4, 397410.
 Atkinson.
 J.
, Campbell, F.
W.
 & Francis, M.
R.
 (1976) The magic number 4 plus or minus 0: A new look at visual numerosity judgements.
 Perception 5, 327334.
 Atkinson, J.
, Francis, M.
R.
 & Campbell, F.
W.
 (1976) The dependence of the visual numerosity limit on orientation, colour, and grouping in the stimulus.
 Perception 5, 335342.
 Cabrera, A.
 & Simon, T.
J.
 (1995) Timeaccuracy data analysis: Separating stimuluslimited and poststimulus processes.
 Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Chi, M.
T.
H.
 & Klahr.
 D.
 (1975) Span and rate of apprehension in children & adults.
 Journal of Experimental Child Psychology 19,434439.
 Ckary, D.
C.
 (1995) Reflections of evolution and culture in children's cognition: Implications for mathematical development and instruction.
 American Psychologist 50, 2437.
 Jevons, W.
S.
 (1871) The power of numerical discrimination.
 Nature 3, 281282.
 Klahr, D.
 (1973) Quantification processes.
 In W.
 Chase (Ed.
) Visual Information Processing.
 N e w York: Academic Press.
 Klahr, D.
 & Wallace, J.
G.
 (1976) Cognitive Development: An Information Processing View.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Mandler.
 G.
 & Shebo, B J.
 (1982) Subitizing: An analysis of its component processes.
 Journal of Experimental Psychology: General 111,122.
 Salthouse, T.
A.
 (1981) Converging evidence for informationprocessing stages: A comparativeinfluence stageanalysis method.
 Acta Psychologica 47, 3961.
 Simon, T.
, Cabrera, A.
 & Kliegl.
 R.
 (1993) A new approach to the study of subitizing as distinct enumeration processing.
 Proceedings of Fifteenth Annual Meeting of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Simon, TJ.
 & Klahr, D.
 (1995) A computotional theory of children's learning about number conservation.
 In T.
J.
 Simon & G.
S.
 Halford (Eds.
) Developing Cognitive Competence: New Approaches to Process Modeling.
 Hillsdale, NJ: Lawrence Erlbaum & Associates.
 Svenson, O.
 & Sjoberg, K.
 (1983) Speeds of subitizing and counting processes in different age groups.
 Journal of Genetic Psychology 142, 203211.
 Trick, L.
M.
 & Pylyshyn, Z.
W.
 (1993) What enumeration studies can show us about spatial attention.
 Evidence for limited capacity preattentive processing.
 Journal of Experimental Psychology: H u m a n Perception & Performance 19, 331351.
 Trick, L.
M.
 & Pylyshyn, Z.
W.
 (1994) Why are small and large numbers enumerated differently? A limitedcapacity preattentive stage in vision.
 Psychological Review 101, 80102.
 van Oeffelen, M.
P.
 & Vos, P.
G.
 (1982) Configural effects on the enumeration of dots: Counting by groups.
 Memory & CognUion 10, 396404.
 48 A capacity approach to kinematic illusions: T h e curtate cycloid illusion in the perception of rolling motion Matthew I.
 Isaak Department of Psychology University of Calgary misaak@acs.
ucalgary.
ca Abstract When a wheel rolls along a flat surface, a point on its perimeter traces a cycloid trajectory.
 However, subjects perceive the point's path not as the cycloid, but as the curtate cycloid, containing loops where the point contacts the surface.
 This is the curtate cycloid illusion.
 I hypothesize that the illusion occurs because the cognitive system does not have sufficient activation, or capacity, to both maintain an updated representation of the wheel's translation and compute its instant centers, the point about which the wheel is rotating at a given instant.
 This hypothesis is supported by showing that illusion susceptibility is decreased when the competing instant center demand is reduced, either by giving subjects practice at instant center computation (Experiment 1) or by eliminating the contour containing the instant centers subjects are most likely to compute (Experiment 2).
 Experiment 3 demonstrates that heightened instant center demands have less effect on illusion susceptibility when they are confined to irrelevant portions of the wheel's contour.
 A general form of the capacity account may explain illusions in the perception of many kinematic systems and point the way toward theoretical unity in the study of the perception of motion and events.
 Our visual experience is filled with kinematic events, such as swinging pendulums and rolling wheels.
 Our perception and understanding of these events is as fallible as our perception of such static stimuli as the MullerLyer lines.
 For example, as a wheel rolls on a flat surface, a point on its perimeter follows a cycloid trajectory (top panel.
 Figure 1).
 Most subjects, however, draw or select the looped curtate cycloid (bottom panel.
 Figure 1) to represent the perimeter point's path (Isaak & Just, in press; Proffitt, Kaiser, & Whelan, 1990).
 This is the curtate cycloid illusion, or CCI.
 I survey previous approaches to kinematic illusions, introduce a capacity approach, then examine a c^acitybased account of the CCI called the instant center hypothesis.
 V y Y Cycloic V J ( ) Curtate Cycloid Figure 1: Stylized cycloid and curtate cycloid uajectories Previous A p p r o a c h e s to K i n e m a t i c Illusions The investigation of kinematic perception and comprehension has not been matched by the development of a unifying theory able to explain performance across stimuli, tasks, and subjects.
 Perceptual and cognitive researchers have worked in relative isolation from each other, using widely discrepant tasks and stimuli and grounding their explanations in vastly different schools of psychology.
 Perceptual vector analysis (Johannson, 1986) states that objects' motions are perceived not only with respect to a static background, but also with respect to other objects' motions.
 The trajectories of a point on a rolling wheel's perimeter and one at its center may be described by a relative vector specifying the perimeter point's rotation about the wheel's center and a co m m o n translational vector representing the viewerrelative motion of both points.
 Johannson (1974) has not yet explained the susceptibility of many subjects to the CCI or the intersubject variability in it.
 Coding theory (Restle, 1979) states that any motion may be desaibed by different combinations of five parameters.
 The description with the fewest parameters gives rise to the perceived motion.
 Although coding theory can explain the CCI by claiming that the curtate requires fewer parameters for its description than does the cycloid, it does not explain how this variability depends on subject's spatial ability (Isaak & Just, in press).
 Naive physics researchers (e.
g.
, McCloskey, Caramazza, & Green, 1980) identify errors subjects make in understanding a kinematic system, then propose heuristics or mental models that might have produced the errors.
 One emerging result is that the neglect of some of a system's motion parameters leads to illusions or misconceptions.
 Naive physics theories have begun to explain the CCI by stating that a rolling wheel's translation is neglected in favor of its rotation (Proffitt et al, 1990).
 One problem with this approach is that plausible heuristics or models are often generated posthoc to explain the results of a given study.
 Thus new models and heuristics tend to emerge with each new study.
 A Capacity Approach to Kinematic Event Perception Capacity theory is a general theoretical approach which suggests that the performance of cogniUve tasks is constrained not only by the stimulus, but also by the amount of processing resources subjects have available and by the way subjects distribute the resources across the task environment.
 To date, capacity theory has been applied 49 mailto:misaak@acs.
ucalgary.
camost fruitfully in linguistic domains, such as reading and speech perception.
 For example, the amount of processing resources subjects have available has been shown to influence the resolution of syntactic ambiguity (MacDonald, Just, & Carpenter, 1992).
 The capacity framework is an intuitively plausible theoretical lens through which to view language processing, because the sequential, serial nature of language imposes a continuous load on attentional and memorial processing resources.
 Language, however, is not the only type of stimulus that occurs through time.
 Kinematic events also occur through time.
 To perceive and understand these events, observers must not only process and store the kinematic system's successive momentary states, but also integrate the states over time.
 Capacity theory suggests that a system's momentary states are processed, stored, and integrated in woricing memory using a finite supply of activation (Just & Carpenter, 1992).
 Because the supply is finite, an increase in either the storage or the processing requirements of one aspect of a motion causes the deallocation of activation from other aspects, which may be processed more slowly or lost from working memory.
 C^acity theory also proposes that individuals vary in the supply of activation.
 Highcapacity individuals, with more activation, are less prone than lowcapacity persons to processing slowdowns or the displacement of items from working memory when a task involves storing and computing multiple items.
 An Instant Center Account of the CCI The general capacity framework may be applied to the CCI by developing a specific, capacitybased process account of the illusion.
 The cycloid and curtate cycloid trajectories are distinguished mainly by their bottom portions: The curtate cycloid contains a loop, whereas the cycloid does not.
 Whether the trajectory contains a loop reflects how the wheel pivots when the perimeter point contacts and leaves the surface.
 To accurately derive the trajectory, the wheel's pivoting must be correctly processed when the point contacts the surface.
 Here, the point is the wheel's instant center, the point about which the entire wheel is rotating at that instant.
 One way subjects can correctly represent the bottom portion of the point's trajectory is to derive an instant center when the point contacts the surface.
 The CCI may arise when activation is deallocated from updating translation to computing the wheel's instant centers when the point contacts and leaves the surface.
 This deallocation begins only when the dot contacts the surface and continues until the dot reaches approximately seven or eight o'clock in its rotational path.
 Three experiments investigated the instant center hypothesis.
 Susceptibility to the CCI was assessed by the degree to which a normally rolling wheel's translation was exaggerated in the attempt to make a perimeter dot follow a cycloid.
 Because the dot is afready following a cycloid, subjects w h o exaggerate its translation must perceive the wheel as undertranslating and the dot's path as the curtate cycloid.
 E x p e r i m e n t 1: Instant C e n t e r Practice R e d u c e s Susceptibility to the C C I Experiment 1 compares the effects on CCI susceptibility of practice at computing instant centers to the effects of experience with a task that does not involve instant center computation.
 Practice should reduce the demand imposed by instant center computation, increasing the activation available to update translation and reducing susceptibiUty to the CCI.
 Thirtysix subjects viewed rolling wheels or tumbling batons.
 Trials occurred in blocks in which either only wheel or only baton uials were viewed.
 There were four block sequences, each viewed by nine subjects: wheelwheelwheel ( W W W ) , batonbatonbaton (BBB), batonbatonwheel ( B B W ) , wheelbatonwheel ( W B W ) .
 Because continued experience with rolling wheels allows subjects to practice instant center computation, they should be less prone to the CCI on the third than on the first block of the W W W sequence.
 By contrast, they should be as prone to the CCI on the third as on the first block of the W B W sequence.
 The bottom portion of the path of a dot at one end of a tumbling baton may be derived by assessing the dot's horizontal displacement along the surface.
 If there is no displacement, the baton's franslation/rotation ratio is 1:1, but if the dot slips forward or backward, the translation/rotation ratio is greater than or less than one, respectively.
 Method White wheel rims or batons (9.
3°  of visual angle) rolled or tumbled across a black computer screen.
 A small dot speared on the inside of the wheel's rim or at one end of the baton.
 The objects rolled on a white band (width = 7.
6°  of visual angle) extending the width of the screen.
 Subjects viewed 33 trials arranged in three blocks of eleven.
 The object's translation/rotation relationship was 1:1 on five of the trials in each block, overtranslating on three, and overrotating on three.
 O n 1:1 trials, the wheel's rotational velocity was 0.
38 rev/s, and its translational velocity was 5.
65 cm/s (10.
7°/s).
 O n overrotating trials, the wheel's rotational speed was increased by factors of 1.
15, 1.
20, or 1.
25.
 O n overtranslating trials, its translational speed was increased by factors of 1.
25,1.
35, or 1.
50.
 Subjects were shown a drawing of a cycloid and were instructed to change the motion until the dot's path matched the drawing if they did not think the dot was already following the cycloid.
 Subjects used a mouse button to move a pointer along a horizontal scale that controlled the wheel's translation/rotation ratio.
 The scale appeared in the top center of the screen and was 8.
0 cm (14.
9°) long .
 The pointer was positioned at the scale's midpoint at the beginning of each trial.
 The scale's extremes were labeled "more spin" and "more slide".
 Moving the pointer from the point where the wheel's rolling was normal toward the "spin" extreme maintained a translational velocity of 5.
65 cm/s, but increased the wheel's rotational velocity.
 Moving the pointer from the normal point toward the "slide" extreme kept the rotational velocity at 0.
38 rev/s, but increased the wheel's translational velocity.
 Subjects could make as many adjustments as they wished.
 50 Results and Discussion As expected, a practice effect occurred in the WWW condition (see Figure 2): Subjects performed more accurately on the third (mean = 1.
11:1) than on the first block (mean = 1.
21:1), t(8) = 2.
52, p < .
05.
 Also as predicted, subjects' performance in the third block of the W B W condition (mean = 1.
19:1) was not reliably better than their performance in the first block (mean = 1.
22:1), t(8) = 0.
94, p > .
05.
 To determine whether {he W W W practice effect reflected decreasing susceptibility to the CCI or merely increasing strategic or motoric facility with the adjustment task, I examined the sensitivity with which subjects discriminated cycloid from curtate cycloid trajectories in the first and final blocks of the W W W and W B W conditions.
 Hits were defined as 1:1 trials on which subjects' final ratio selections ranged from 0.
95:1 to 1.
05:1.
 False alarms were defined as overrotating trials on subjects selected ratios less than 0.
90:1.
 Here, subjects did not adequately adjust the motion of overrotating wheels toward 1:1, suggesting that they saw the dot's curtate cycloid path as the cycloid.
 Subjects more sensitively discriminated curtate cycloid frcm cycloid trajectories in the final block (mean d = 1.
15) of the W W W condition than in the initial block (mean d = 0.
17), t(8) = 2.
63, p < .
05.
 By contrast, subjects did not discriminate curtate cycloid from cycloid trajectories more sensitively in the final block (mean d = 0.
38) of the W B W condition than in the initial block (mean d = 0.
12), t(8) = 1.
19.
 p > .
05.
 S 1.
251 c 1.
20 i Q 1 1.
10I 1.
05 ^ 1.
00f 0.
95 c WBW W W W 1 1 First Block Final Block Trial Block Figure 2: Final translation/rotation ratio in Experiment 1 as a function of the trial block and block sequence.
 Experiment 1 yielded one main conclusion: Practice at adjusting the trajectory of a dot on a rolling wheel's perimeter reduces the instant center demand for activation, freeing resources to cumulate the wheel's translation and reducing susceptibility to the CCI.
 The practice effect contradicts Proffitt et al.
's (1990) suggestion that experience does not affect illusion susceptibility.
 That decreases in susceptibility to the CCI were found across a brief experimental session suggests that the CCI is more likely the result of temporary computational demands than the reflection of fundamental perceptual biases.
 Continued practice may reduce these demands.
 E x p e r i m e n t 2: Instant Centers are Computed W h e n the Dot Contacts the Surface I claimed that the CCI arises when subjects compute instant centers besides the dot.
 The additional instant centers that are most likely computed are those immediately trailing the dot (Isaak & Just, in press).
 The portion of the wheel's contour trailing the dot is thus implicated in the CCI because it contains these additional instant centers.
 If trailing contour were absent, subjects would be less Ukely to compute trailing instant centers and would be less prone to the CCI.
 Subjects viewed three types of rolling wheels: wheels in which the 45°  of arc trailing the dot were deleted, wheels in which the 45°  of arc leading the dot were deleted, and intact wheels.
 The CCI should be least apparent for wheels with deleted trailing arc.
 Method The method resembled Experiment 1 except as follows: Fifteen subjects viewed a random sequence of the three types of wheels.
 Each of the wheel types appeared on eleven of the experiment's 33 trials.
 The rolling motion was normal on five of the trials for each wheel type, overtranslating on three, and overrotating on three.
 Results and Discussion A main effect of stimulus type was found, F(2, 26) = 9.
01, p < .
01.
 Subjects were less prone to the CCI on trailingdeleted (mean = 1.
02:1) than on intact (mean = 1.
10:1), F(l, 26) = 17.
36, p < .
01 or leadingdeleted wheels (mean = 1.
08:1), F(l, 26) = 7.
76, p < .
01 (see Figure 3).
 Subjects were equally prone to the CCI on leadingdeleted and intact wheels.
 o Pi I •i 1.
25 n 1.
201.
151.
10^ 1.
05 H 1.
00 •^ 0.
95 Intact Wheel LeadingDeleted TrailingDekted Stimulus Qiaracteristics of W h e e l Figure 3: Final translation/rotation ratio in Experiment 2 as a function of the wheel type.
 Experiment 2 yields two conclusions.
 First, the CCI arises when acUvation is diverted from translation cumulation to instant center computation when the dot 51 contacts the surface.
 W h e n w e reduce the likelihood that these instant centers will be computed, activation is released, allowing the cumulation of translation and reducing susceptibility to the CCI.
 Second, the cognitive conditions responsible for the CCI are shortUved.
 Instant centers are computed only when the dot is between 6 o'clock and about 7:30 in its rotation about the wheel's center.
 If instant centers were computed before the dot contacted the surface, deleting leading contour should have improved performance, as the leading contour contains the wheel's instant centers before the dot hits the surface.
 N o improvement was found.
 If instant centers were computed after the dot passed 7:30 in its rotation, eliminating 45** of trailing arc should not have reduced susceptibility to the CCI as substantially as it did.
 The reallocation of resources from translation cumulation to instant center computation does not occur for a large portion of the total time that rolling motion is viewed, but rather for oneeighth or less of the total time on task.
 Experiment 3: Instant Center Computation I m p a i r s Translation C u m u l a t i o n Experiment 3 tests the notion that instant center cconputation consumes the activation allocated to translation processing rather than that dedicated to rotation processing.
 The wheel's rotation or translation was exaggerated during either the top or bottom portion of the dot's trajectory (from 11:30 to 2:30 or from 5:30 to 8:30, respectively, in its rotation around the wheel's center).
 The wheel's motion was normal when the dot was not passing through the selected portion of its path.
 Translational distortions should influence performance more when they occur in the bottom than in the top of the dot's path, and should influence performance more than rotational distortions should.
 Method Eighteen subjects viewed 27 randomly ordered trials.
 Distortions exaggerated the wheel's rotation on nine trials and its translation on nine.
 There was no distortion on the remaining trials.
 Rotational distortions decreased the wheel's translation/rotation ratio to 0.
75:1, 0.
80:1, and 0.
85:1 on three trials each.
 Translational distortions increased the ratio to 1.
25:1, 1.
35:1, and 1.
50:1 on three trials each.
 The distortions occurred during the top or bottran or throughout the dot's path; six different subjects participated in each of these conditions.
 Results and Discussion As predicted, there was an interaction between the nature of the distortion of a rolling wheel's motion and the location of the distortion in the dot's path, F(4, 102) = 4.
62, p < .
05.
 Subjects more accurately adjusted translational distortions when they occurred in the top (mean = 1:20:1) than when they occurred in the bottom of the dot's path (mean = 1.
26:1), F(2.
 102) = 4.
89, p < .
05 (see Figure 4).
 Rotational distortions were adjusted equally accurately regardless of location.
 These results demonstrate that instant center computation consumes the activation allocated to cumulating translation rather than that allocated to rotational processing.
 Overall, subjects were more prone to the CCI when the distortions occurred in the bottom of the dot's trajectory (mean = 1.
06:1) than when they occurred in the top of dot's path (mean = 1.
03) or throughout the dot's path (mean = 1.
01:1), F(2, 102) = 3.
86, p < .
05.
 The deallocation of activation to instant center computation occurs only when the dot is in the bottom of its trajectory.
 1.
30 n DC c o O C o CO s • Translational Distortion D Rotational Distortion Bottom Top Location of Distortion Figure 4: Final translation/rotation ratio choice in Experiment 3 as a function of the type and location of the distortion.
 General Discussion A capacity framework was used to develop an instant center account of the CCI.
 Although three experiments supported components of this account, a capacity view of the CCI was not explicitly contrasted with such approaches as perceptual vector analysis, coding theory, and naive physics.
 In my view, capacity theory does not directly oppose these approaches, but is instead a broader framework capable of incorporating aspects of the other approaches.
 Capacity theory may be instantiated as a comprehensive hybrid symbolic/connectionist model of mind in which productions manipulate the activation levels of representational elements.
 By contrast, perceptual vector analysis, coding theory, and naive physics may be seen as narrower hypotheses about the particular productions or representational elements likely to be important in a capacity model of kinematic thinking.
 The computation of perceptual vectors, for example, may be instantiated in productions manipulating the activation of direction perception units.
 Similarly, heuristics used in understanding a kinematic system may be coded as productions in a capacity model.
 Finding General Mechanisms of the Neglect of Motion Parameters The instant center hypothesis may be viewed as a taskspecific component of a more general capacity account of kinematic illusions, which runs as follows: The accurate perception of many kinematic events requires the correct 52 selection and efficient coordination of object and observerrelative frames of perceptual/cognitive reference.
 At critical points during the event, such as at motion discontinuities (Gilden, 1991), additional processing demands compel subjects to focus primarily on one reference frame, such as the objectrelative frame, depleting die supply of activation and leading to a breakdown in the coordination of the reference frames and perhaps to the neglect of one of the motion parameters.
 Because attending to objectrelative motions entails attending only to the portion of the display subtended by the object, whereas attending to observerrelative motions may entail attending to the entire field, object and observer relative frames may correspond respectively to distributed and focused modes of attention, or to wide and narrow settings of the attentional zoom lens.
 Generally, subjects are adept at shifting between the objectand observerrelative firames, as moving between the narrow and wide attentional zoom lens settings typically requires less than 100 m s (Eriksen & St.
 James, 1986).
 Sudden events, however, such as stimulus onsets (Yantis & Jonides, 1984) and, perhaps, motion discontinuities, may capture attention in one or the other of the frames, causing the attentional zoom lens to become stuck on one setting.
 The processing that might have occurred through the other setting or frame is thus neglected, causing illusions or errors.
 Extending the Capacity Account A capacity account may be extended to kinematic systems other than rolling wheels.
 I suggest that capacity theory is most likely to explain illusions in events in which a) systematic errors are made on one kinematically relevant dunension, and b) the dimension on which the errors are made is itself kinematic, such as translation, rather than a static attribute such as mass distribution.
 The relative arrivaltime configuration (Law, Pellegrino, Mitchell, Fischer, McDonald, & Hunt, 1993) fits these criteria.
 T w o objects are seen moving at a constant velocity toward a destination, and the task is to state which object will arrive at its destination first.
 The correct answer depends on the relative velocity and distancetotarget of the two objects.
 Subjects neglect the relative velocity and base their answers primarily on relative distance.
 Capacity limitations might underlie the neglect of relative velocity, which becomes apparent only over time and thus entails integrating successive representations (Law, et al.
, 1993).
 Relative distancetotarget, by contrast, is apparent at each instant in time and requires no integration to process.
 The capacity account may be generalized not only to kinematic systems other than rolling wheels, but also to populations other than college students, such as older adults.
 A reduction in capacity has been posited to account for agerelated declines in cognitive performance (Salthouse, 1988).
 The decline in capacity may be more pronounced in spatial than in verbal tasks because older adults have accumulated a lifetime of experience with verbal materials, but usually have had Uttle contact with spatial materials (Tubi & Calev, 1989).
 Salthouse and Mitchell (1989) found that age impaired the integration of new computations with old products more than the simple maintenance of products.
 I have suggested that such integrative processes are more strongly impUcated in the perception of kinematic properties that change over time than in the perception of momentary kinematic states.
 Accordingly, Scialfa, Guzy, Leibowitz, Garvey, & Tyrell (1991) found that older adults were less sensitive than their younger counterparts to vehicular accelerations and decelerations, but were equally accurate at estimating absolute velocity.
 Together, these suggestions imply that older adults may be more susceptible to the CCI than younger adults, and that older adults m a y be more impaired relative to younger adults at processing a rolling wheel's û anslation than at processing its rotation.
 Implications for tiie Relationship between Perception and Cognition I stated earlier that perceptual and cognitive researchers in the field of kinematic event perception have worked in relative isolation from each other.
 The current research may be seen as containing elements of both the perceptual and cognitive approaches to kinematic event perception.
 Reflecting a cognitive influence, the research investigated the influence of a higherlevel variable, working m e m o ry capacity, on susceptibility to the CCI.
 Reflecting a perceptual influence, susceptibility to the CCI was assessed by examining how well subjects adjusted a wheel's motion so that a perimeter dot followed a cycloid: This procedure resembles the nulling procedure used in psychophysical research, in which illusion magnitudes are quantified by requiring subjects to adjust a test stimulus so that it matches a standard stimulus along some dimension.
 Because the present research examines the effects of cognitive factors on lowerlevel perceptual processes, it makes the implicit claim that lowlevel perceptual processes, often thought to be relatively immutable within subjects and invariable across subjects, m a y in fact be susceptible to substantial topdown influences.
 In the exUeme, this claim suggests tliat the phenomena usually studied by psychophysicists such as illusions of form, luminance, or motion, may be subject to modulation by the factors usually considered the province of cognitive scientists.
 Although there has been relatively little investigative interaction between psychophysicists and cognitive scientists, several pieces of evidence, primarily from the psychophysical literature suggest that cognitive variables may influence susceptibility to dynamic illusions usually thought to reflect lowlevel perceptual and neural processes.
 Studies by Chaudhuri (1990) and Shulman (1991) demonstrate that attention m a y modulate the motion aftereffect.
 The motion aftereffect occurs when a static or ambiguously moving stimulus appears to m o v e in a direction opposite to the motion of a stimulus to which the subject has been adapted.
 The neural locus of the motion aftereffect is thought to be in M T (Chaudhuri, 1990).
 Chaudhuri found that the magnitude of the aftereffect was reduced when subjects' attention was displaced from fixation.
 Shubnan's subjects attended to either of two simultaneously presented squares rotating in depth.
 The rotation of a subsequent, ambiguously rotating square then appeared opposite in direction to the motion of the square to which 53 subjects had attended previously.
 These results suggest that processing in M T niay be amenable to attentional influence.
 Hikosaka, Miyauchi, and Shimojo (1993) presented a new illusion, the linemotion illusion, in which a line segment, although presented all at once, appeared to spread from one extremity if attention was selectively drawn to thai extremity.
 Hikosaka et al.
 suggested that attention acts to accelerate visual processing at particular locations, making stimuli appearing at that location seem to occur slightly before stimuli appearing at other locations.
 This hypothesis implies that attention may influence processing in lowlevel motion detection areas of the brain, such as VI.
 These studies demonstrate that basic perceptual phenomena, such as aftereffects of adaptation to motion, may be subject to cognitive mediation, just as the current research showed that susceptibility to the CCI may depend on the supply of processing resources subjects have available.
 The discovery of the cognitive mediation of such processes adds both clarity and further complexity to the intricate picture of such processes yielded by traditional perceptual and psychophysical investigations.
 For example, the discovery that attention may modulate motion aftereffects might suggest either that the brain areas implicated in motion processing contain inputs from brain areas implicated in attention, or that attention exists at every level of processing  even VI  as a pattern of activation across processing units.
 Although the current research differs from the above examples in that it derives more from a cognitive than a psychophysical perspective, it joins these other investigations in showing that the relatively unexplored perception/cognition interface may prove a vital thread for future investigators attempting to delineate the rich t̂ )estry of processes comprising our perception and comprehension of such seemingly basic components of the world around us as light, form, and motion.
 Acknowledgments I thank Patricia Carpenter, Marcel Just, and Lynne Reder for their comments, and Brock Organ and Lisa Vaughan for their programming expertise.
 This work formed part of a Ph.
 D.
 dissertation submitted to the Department of Psychology, Carnegie Mellon University.
 The research was supported by an APA Dissertation Research Award and an NSERC PGSB scholarship to Matthew I.
 Isaak, and by Contracts N0001492J1209 from ONfR and MH00662 from NIMH to Marcel Just of Carnegie Mellon University.
 References Eriksen, C.
 W.
, & St.
 James, J.
 D.
 (1986).
 Visual attention within and around the fleld of focal attention: A zoom lens model.
 Perception and Psychophysics, 40, 225240.
 Chaudhuri, A.
 (1990).
 Modulation of the motion aftereffect by selective attention.
 Nature, 344, 6062.
 Gilden, D.
 L.
.
 (1991).
 On the origins of dynamical awareness.
 Psychological Review, 98, 554568.
 Hikosaka, O.
, Miyauchi, S.
, & Shimojo, S.
 (1993).
 Focal visual attention produces illusory temporal order and motion sensation.
 Vision Research, 33, 12191240.
 Isaak, M.
 I.
 & Just.
 M.
 A.
 (in press).
 Constraints on the processing of rolling motion: The curtate cycloid illusion.
 Journal of Experimental Psychology: Human Perception and Performance.
 Johannson, G.
 (1974).
 Vector analysis in visual perception of rolling motion: A quantitative approach.
 Psychologische Forschung, 36, 311319.
 Johannson, G.
 (1986).
 Relational invariance and visual space perception: On perceptual vector analysis of the optic flow.
 Acta Psychologica, 63, 89101.
 Just, M.
 A.
, & Carpenter, P.
 A.
 (1992).
 A capacity theory of comprehension: Individual differences in working memory.
 Psychological Review, 99, 122149.
 Law, D.
 J.
, Pellegrino, J.
 W.
, Mitchell, S.
 R.
, Fischer, S.
 C.
 McDonald.
 T.
 P.
, & Hunt, E.
 B.
 (1993).
 Perceptual and cognitive factors governing performance in comparative arrivaltime judgments.
 Journal of Experimental Psychology: Human Perception and Performance, 19, 11831199.
 McCloskey, M.
, Caramazza, A.
, & Green, B.
 (1980).
 Curvilinear motion in the absence of external forces: Naive beliefs about the motion of objects.
 Science, 210, 11391141.
 MacDonald, M.
 C , Just, M.
 A.
, & Carpenter, P.
 A.
 (1992).
 Working memory consuaints on the processing of syntactic ambiguity.
 Cognitive Psychology, 24, 5698.
 Proffitt, D.
 R.
, Kaiser.
 M.
 K.
, & Whelan, S.
 M.
 (1990).
 Understanding wheel dynamics.
 Cognitive Psychology, 22, 342373.
 Restle, F.
 (1979).
 Coding theory of the perception of motion configurations.
 Psychological Review, 86, 124.
 Salthouse, T.
 A.
 (1988).
 The role of processing resources in cognitive aging.
 In M.
 L.
 Howe and C.
 J.
 Brainerd, eds.
 Cognitive development in adulthood: Progress in cognitive development research in adulthood.
 New York: Springer Verlag.
 Salthouse, T.
 A.
, & Mitchell, D.
 R.
 D.
 (1989).
 Structural operational capacities in integrative spatial ability.
 Psychology and Aging, 4, 1825.
 Scialfa, C.
 T.
, Guzy, L.
 T.
, Leibowitz.
 H.
 W.
.
 Garvey, P.
 M.
, & Tyrell, R.
 A.
 (1991).
 Age differences in estimating vehicle velocity.
 Psychology and Aging, 6, 6066.
 Shulman, G.
 L.
 (1991).
 Attentional modulation of mechanisms that analyze rotation in depth.
 Journal of Experimental Psychology: Human Perception and Performance, 17, 726737.
 Tubi, N.
, & Calev, A.
 (1989).
 Verbal and visuospaUal recall by younger and older subjects: Use of matched tasks.
 Psychology and Aging, 4, 493495.
 Yantis, S.
, & Jonides, J.
 (1984).
 Abrupt visual onsets and selective attention: Evidence from visual search.
 Journal of Experimental Psychology: Human Perception and Performance, 10, 601621.
 54 A m o d e l of scan paths applied to face recognition Keiji Yamada NEC Corporation Info.
 Tech.
 Res.
 Labs, 411, Miyazaki, Miyamae, Kawasaki, 216, JAPAN yamada@pat.
cl.
nee.
co.
jp Garrison W .
 Cottrell' Institute for Neural Computation Department of Computer Science & Engineering University of California, San Diego garyOcs.
ucsd.
edu Abstract We develop a model of scan path generation based on the output of low level filters.
 The highest variance of Gabor jet filters computed over orientations are used as the object of attention.
 These points are held in a feature map which is inhibited as attention points are visited, creating a new attention point elsewhere.
 Scan paths generated this way can be used for recognition purposes where "singleshot" methods, such as PCA, would fail because the image is not registered.
 Introduction In previous work, we have used a parallel processing approach to the problem of face recognition (Cottrell & Metcalfe, 1990).
 In that work, the network was presented with the entire face, and (after learning) was able to recognize individuals holistically in a oneshot operation.
 However, there is ample evidence that when people are memorizing a face, they use a sequential sampling process, during which several points on the image are fixated, often repetitively.
 The sequence of points is called a scan path, and is often repeated during recognition (Noton & Starks, 1971; Noton, 1971).
 In this paper, w e describe a system that uses an easily computable function of lowlevel features to decide which points on a face are "interesting".
 The basic idea is to compute a set of features (Gabor filters) in parallel across the image, and then select those points for inspection with the highest variance in the filter outputs across orientations.
 B y sequentially selecting these points, followed by inhibition of them in a neurally plausible way, w e are able to qualitatively simulate human scan paths.
 There is a major computational advantage to this kind of approach.
 If w e can determine these fixation points in parallel from lowlevel features, and then memorize the vectors between them, w e can then use this stored information to recognize a new instance of the person's face without major worries about translation invariance.
 Indeed, our algorithm works for members of our face data set that were thrown out in the original neural net experiments because the subjects (college sophomores) could not hold still in the frame.
 In what follows, w e present our very primitive model of scan path generation, based only on lowlevel features of the image, followed by its use as a recognition system.
 W e should emphasize at the outset that this is /lor a neural net system, but we are working towards making it one.
 'Corresponding author Figure 1: Examples of scan paths from D.
 Noton[1970].
 See text for explanation.
 Attention a n d scan path W e first present a necessarily truncated description of data concerning scan paths in humans.
 Noton (1971) has reported that during memorization of an object, about 2 0 % of the eye movements are within the same path, caWed the scan path.
 The scan path that appears in the object memory phase is repeated about 2/3 of the time when the same object is recognized.
 A typical scan path comprises ten eye fixation points (Noton & Starks, 1971).
 Some examples are in Figure 1.
 Figure 1(a) is an object drawing used in the experiments (Noton & Starks, 1971).
 Scan paths appear when a subject is memorizing the drawing (Figure l(b, c)).
 Similar scan paths appear while the subject is identifying the drawing (Figure 1 (d, e)).
 Figure 1(f) shows an ideal scan path generated based on the previous results.
 55 mailto:yamada@pat.
cl.
nee.
co.
jpSelective attention Scan paths are ultimately a function of selective attention.
 Many models for selective attention have been proposed.
 For example, Broadbent's model is an early selection model.
 Attention filters information at the sensory level.
 In this model, the capacity of channel from the sensory level to the perceptual level is strictly limited.
 Late selection models have been proposed by Blum(1961), Deutch and Deutch(1963), and Norman(1968).
 In these models, almost all sensory data are transmitted to higher levels and are processed at the conceptual level.
 After the processing, an attentional controller decides what should be recycled to the conceptual level.
 The "cognitive unit" that has the maximum output value is selected and attended.
 In the former model, information captured by a sensor is filtered in the sensory level.
 Hence, limited sensory information is transmitted through a sensory filter to be perceived and the other information is filtered off.
 O n the other hand, in the latter model, all sensory information is transmitted to higher processing levels but only a portion of this reaches consciousness.
 These are two extremes, and there are empirical results which are inconsistent with both of them.
 In order to resolve these inconsistencies, Treisman (1969; 1985) has proposed a model in which all information captured at the sensory level is transmitted to higher level.
 At each level, the intensity of some information signal is facilitated and the other is inhibited.
 Selective attention is gradually carried out at the higher level of processing.
 While Triesman's model has changed over the years in response to new data, it is illustrative of the approach taken in our model.
 Our model may be thought of as one level in the hierarchy of selective attention.
 Thus, eye movement and associated scan paths are presumed to be phenomena of selective attention in the visual system.
 Many models for eye movement have been proposed for use in visual recognition (Koch & Ullman, 1985; Phaf et al.
, 1990; Rimey & Brown, 1990; Ullman, 1984; Whitehead & Ballard, 1992; Wolfe, 1994).
 Rimey & Brown (1990) use a hidden Markov model to store a path of eye movements and to reproduce the eye movement path when a remembered image is given.
 In this method, attention points are not automatically selected from a given image, but are selected by a system operator.
 A h m a d & Omohundro (1990) proposed a method that searches clusters in feature maps.
 In their method, it is assumed that "strong" feature points are collocated in feature maps and attention is fixed at the clusters.
 Eye movement is controlled by searching clusters of strong feature points in order.
 This method can use several kinds of feature maps to select attention points and control eye movement.
 However, this method assumes that feature points cluster.
 Therefore, when feature points are scattered over feature maps, this method would select a wide area as an attention point.
 Improvements are necessary in order to better select attention points from such feature maps.
 Scan path model Assumptions of the model We assume that: 1.
 One attention point is selected at a time.
 2.
 Information is hierarchically filtered to reduce the amount of information amount gradually.
 This is not modeled here.
 3.
 Strength of attraction of attention points is measured as complexity of figure contours.
 This is modeled as the variance across orientations among Gabor filter responses centered at a point.
 4.
 This pointwise attention strength forms a feature map.
 5.
 In the selective attention process, the unit with the highest activity in the feature map should be selected as an attention point.
 6.
 For movement of attention to the next point, selfinhibition in the feature map is necessary.
 7.
 In order for movement of attention to circulate, the inhibited activity of attention points recovers after some interval.
 Conditions for scan path generation W e believe that two kinds of problems have to be resolved for modeling scan paths.
 One is the problem of selecting attention points, the targets of the eye movements.
 A sequence of attention points must be generated from scattered feature points.
 The second problem is how eye movement forms the closed loop of the scan path.
 That is, as a first approximation, attention point sequences should be periodic.
 This latter is performed in our model by inhibiting feature points in the neighborhood of the last fixated point, with a decay on this inhibition.
 Thus after some interval, the fixation points recover to attract attention again.
 It is this behavior that causes the circulation of eye movement in our model.
 It remains to be said how attention points are chosen in the first place.
 W e preprocess the face in parallel by laying a grid of Gabor filters (a 2d convolution of a Gaussian with a sine wave) of various resolutions and rotations over the image (Daugman, 1988; Gabor, 1946).
 The particular filter we use is: n i x ) = iexp(f0x)exp(^^^^; where (1) (2) (̂  = K{cos9,sin6) '^ = T Thus 9 is the orientation of the sine wave and k is the resolution parameter of the filter with a wave length A.
 77 is a coefficient for normalization with respect to the frequency, a (in our model) is simply set it to the constant tt, and we vary A to get different frequencies.
 This filter is convolved with an input image and generates a filter response at a point x with respect to an orientation 0 and a wave length A.
  I G{4>xh) = / Iix)'¥i4>, xo  x)dx (3) W e calculate a norm value of this filter response \G{<f>, x)\ as one element of the feature vector at that point: M(0,x*o) = lG(^,ib)| (4) 56 When multiple scales and orientations are used, we get a feature vector of these responses for every point.
 This is basically the "Gabor jet" used by von der Malsburg and colleagues (Buhmann et al.
, 1991).
 W e define the allcnlioiKil field as the activity of units in a feature map.
 This activity, the attraction value for attention, is defined as the variance of the Gabor filter outputs over the multiple orientations at a particular resolution.
 W e denote this V'(\, jq).
 Note we assume a particular resolution of filter must be chosen based on the size of the object in the image for the purposes of attention selection.
 In our experiments here, we simply selected A = 8.
 Thus, we model the lowlevel attentional attraction by the activity of the units in V.
 Then the scan path is generated as follows: 1.
 The point f^, corresponding to the unit in the attentional field with the highest potential value is selected as the focus of attention point.
 2.
 Once a point is visited, it is inhibited via a offcenteronsurround mask, given by: /F(x;,r') = (l+aexp(^^^^))(l/3exp(1^^^5^)) A^ B^ (5) By multiplying values of this filter with the potential values around the attention point, potential values V'{k, x) at the next time step are obtained.
 3.
 The attentional field recovers via a discrete approximation to a continuous recovery process: V'{k, x)[t + 1] = (1  6)V'{k, x)[t] + 6V{k, x) (6) 4.
 Go to step 1.
 This model bears resemblance to that proposed by Koch & Ullman(1985).
 Our model can be seen as an instantiation of their ideas in a particular domain.
 Scan path generation experiments Scan path generation experiments were carried out on face images, from a database collected by Cottrell & Metcalfe (1990).
 W e used facial images of 35 people, with 8 expressions each (see Figure 2).
 W e used Gabor filters with 8 orientations and 6 scales to calculate 48 element filter responses at each pixel.
 W e computed the variance of the 8 filters at each scale separately.
 Figure 3 shows potential values at each scale converted to gray levels.
 The values of A used are given across the top of the Figure.
 For the IF filter (Equation 5) and the recovery process (Equation 6), we tried the following parameters: Q e {0.
1,0.
25,0.
5,1.
0} P = 1 A = sR B = 3sR s e {0.
5,1.
0,2.
0} 6 e {0.
02,0.
05,0.
10} where R is \/2(t/k in Equation 1.
 A mechanism of controlling the scale to be used is beyond the scope of this paper.
 In the following experiments, we use the fourth scale from the left in Figure 3, that is, A = 8, for the scan path generating experiments.
 Following the method outlined above, we generate a sequence of points.
 W h e n a sequence of points longer than 5 is repeated, we define that as a scan path.
 Thus, if no sequence of attention points is repeated, no scan path is detected.
 W e allow some jitter: A n attention point within 4 pixels of a previous attention point is regarded as the same attention point.
 Experimental results and discussion As described above, faces of 35 people are sampled.
 8 kinds of expressions are used for each person, resulting in 280 face images.
 A n example is shown in Figure 4.
 The upperleft corner image shows a generated scan path.
 The first image to its right is the original potential field used for selecting the first point.
 One can clearly see the inhibition and recovery of points in this potential field as they are scanned.
 Each subsequent image shows the current selected attention point along with the previous nine points.
 The image sequence proceeds from left to right and top to bottom.
 As noted above, we did a parameter search through three parameters of our inhibitory surround (width, decay of inhibition, and strength).
 Table 1 shows the fraction of images that resulted in scan paths by our criterion for the various values of a, s, and b.
 Table 1.
 Percent of scan path generation Q S 0.
5 0.
5 0.
5 1.
0 1.
0 1.
0 2.
0 2.
0 2.
0 8 0.
02 0.
05 0.
10 0.
02 0.
05 0.
10 0.
02 0.
05 0.
10 0.
10 0.
0% 0.
0% 0.
0% 0.
0% 0.
0% 2.
5% 16.
4% 43.
6% 73.
6% 0.
25 0.
0% 0.
0% 0.
0% 0.
0% 0.
0% 4.
6% 16.
4% 44.
3% 73.
2% 0.
50 0.
0% 0.
0% 1.
1% 0.
0% 0.
0% 6.
4% 18.
2% 41.
1% 76.
1% 1.
00 0.
0% 0.
0% 6.
4% 0.
0% 0.
4% 20.
7% 18.
2% 45.
4% 82.
9% In the case when the range parameter for facilitation and inhibition, s is 0.
5, few scan paths are generated.
 A n attention point is selected, potential values near the point are facilitated, and attention does not move to points far from the previous point.
 When the parameter s is larger, more scan paths are generated.
 When the time constant parameter 6 is too small, it takes too long for inhibited potential values recover.
 Therefore, it is hard for attention to return to previously selected points.
 The larger parameter a is, smaller the width of the ring area where potentials are facilitated.
 That is, the distance between two successive attention points stabilizes.
 However, scan path generation does not depend very strongly on this parameter.
 When s = 2.
0 and b — 0.
1, scan paths are generated for about 7 3 % to 8 3 % of face images.
 The average length of scan paths in this case is about 40.
 Examples of scan paths which are generated from face images of 15 people are shown in Figure 5.
 The name of an image is of the form id.
sex.
emotion, followed by a number indicating the length of the scan path.
 Note this is the total number of points in the path, since many points are repeated.
 Forfiveoutof the thirty five images, no scan path is generated (marked N50).
 57 ^ u n Q S M a L H u a n Figure 2: Example faces (from Cottrell & Metcalfe, 1990).
 F a c e recognition using scan paths We now employ our scan paths for object recognition.
 Our approach is as follows: W e first changed the inhibition parameters slightly in order to get a wider range of points from a face.
 Then, w e use one image of each of the 35 subjects in order to obtain a stored scan path.
 W e allowed ourselves the freedom to alter parameters if the settings did not result in a scan path, until w e did have a scan path for every face.
 Obviously in the future w e would prefer to use an adaptive algorithm for this.
 W h e n storing these scan paths, in order to reduce processing time, w e only stored the top 20 unique points, and the vectors to the next point.
 N o w for recognition, when w e encounter a new face, w e first extract the top K attention points.
 W e then compare these to the first attention points in the stored images.
 W e do this by computing the cosine of the angle of the vectors of Gabor filter outputs subtracted from 1 to give a dissimilarity value.
 Using a threshold^, w e accept as possible recognition candidates all stored images whose dissimilarity is less than ̂.
 Then, for each possible recognition candidate, w e search the input image for the best fit of the next point along the stored scan path.
 To do this, w e recall the stored trajectory from the matched point, and find the best match to the next point within a 5x5 patch of pixels centered at the end of that vector in the input image.
 If the summed dissimilarities for all points along the trajectory are less than ̂ , w e have a match.
 If more than one stored scan path matches, w e take the lowest one.
 The 280 face images that were used for scan path generation simulation were used for the face recognition experiments.
 One face image for an individual is used in the face memorizing phase.
 Other 7 faces for an individual are used for recognition test.
 The number of recognition target categories is 35, one for each individual.
 The results of this procedure for various values of the threshold parameter are shown in Table 2.
 In Table 2 we also show the effect of varying the number of Gabor filter resolutions used, from all 6 (48 total filter values) down to 1.
 W e see that for this task, it is important to use the whole Gabor jet for matching points.
 Table 2.
 Face recognition rates using scan paths No.
 of A's 6 6 6 5 5 5 3 3 3 1 1 1 thresh 1.
2 1.
0 0.
8 1.
0 0.
8 0.
6 0.
8 0.
6 0.
4 0.
6 0.
4 0.
2 Hit rate (%) 96.
7 94.
3 90.
2 93.
1 85.
7 70.
6 89.
0 81.
2 60.
4 82.
9 79.
2 56.
3 Reject rate (%) 2.
4 4.
9 9.
8 5.
7 13.
9 29.
4 9.
4 18.
0 39.
6 1.
2 14.
7 43.
7 Error rate (%) 0.
8 0.
8 0.
0 1.
2 0.
4 0.
0 1.
6 0.
8 0.
0 15.
9 6.
1 0.
0 Conclusion In this paper, w e explored a model of scan path generation based on an easily computed value of lowlevel features, i.
e.
, the variance of a set of Gabor filters at various points in an image.
 W e found that the scan paths generated by our algorithm qualitatively matched human scan paths.
 W e also found that the scan paths were useful for recognition.
 Given stored scan paths, individuals may be recognized by match58 Image No.
 Original 32 16«sqrt(2> 16 Uaue length 8 image 1.
1.
3 2.
1.
3 3.
2.
2 4.
2.
1 Figure 3: Variance of Gabor jets at difference scales.
 ing the stored features to those found by traveling along the trajectory given by the stored scan paths.
 This technique is relatively insensitive to changes of facial expression.
 Like von der Malsburg's work, we find that one image is enough for recognition.
 Unlike von der Malsburg, we are able to recognize an image without a relaxation process, and we use only the top 20 "most exciting" feature points to do it.
 However, we have not yet explored recognition of multiple orientations with our model.
 Acknowledgements This work was performed while the first author was a Visiting Scholar in the lab of the second author, funded by NEC Corp, in 19901991.
 We thank the reviewers for Cognitive Science 1995 for being more open than the 1993 reviewers to the novelty of our work.
 References S.
 Ahmad and S.
 Omohundro (1990) A network for extracting the locations of point clusters using selective attention.
 International Computer Science Institute TR#90011.
 G.
Blum (1961) A model of the mind, Wiley: New York.
 J.
 Buhmann, J.
 Lange, C.
 v.
d.
Malsburg, J.
C.
 Vorbriiggen and R.
P.
 Wurtz (1991) Object Recognition with Gabor Functions in the Dynamic Link Architecture: Parallel Implementation on a Transputer Network.
 In B.
 Kosko, (Ed.
), Neural Networks for Signal Processing.
 Englewood Cliffs, NJ: Prentice Hall, pp.
 121159.
 Cottrell, G.
W.
 & Metcalfe, J.
 (1991) EMPATH: Face, gender and emotion recognition using holons.
 In R.
P.
 Lippman, J.
 Moody, & D.
S.
 Touretzky (Eds), Advances in neural information processing systems 3, pp.
 564571, San Mateo, CA: Morgan Kaufmann.
 J.
G.
 Daugman (1988) Complete discrete 2D Gabor transforms by neural networks for image analysis and compression, IEEE trans, on Acoustics, speech, and signal process.
 36.
 J.
A.
Deutsch and D.
 Deutsch (1963) Attention: Some theoretical considerations.
 Psychological review 70, pp.
8090.
 D.
Gabor (1946) Theory of communication, J.
 lEE 93, pp.
429457.
 C.
Koch & S.
 Ullman (1985) Shifts in selective visual attention: Towards the underlying neural circuitry.
 Human neurobiology 4, pp.
 219227.
 D.
A.
Norman (1968) Toward a theory of memory and attention.
 Psychological review 75, pp.
522536.
 D.
 Noton and L.
 Starks (1971) Eye Movements and Visual Perception, Scientific American 224, pp.
3443.
 D.
Noton (1971) Scanpaths in Eye Movements during Pattern Perception.
 Science 171, pp.
308311.
 R.
H.
 Phaf, A.
H.
C.
 Van der Heijden, and RTW.
 Hudson (1990) SLAM: A Connectionist Model for Attention in Visual Selection Tasks.
 Cognitive psychology 22.
 R.
D.
 Rimey and C M .
 Brown (1990) Selective Attention as Sequential Behavior: Modeling Eye movements with an Augmented Hidden Markov Model.
 U.
 of Rochester CS TR327.
 A.
 Treisman (1969) Strategies and models of selective attention.
 Psychological review 76, pp.
242299.
 A.
 Treisman (1985) Preattentive processing in vision.
 Computer vision, graphics, and image processing i7, pp.
 156177.
 S.
 Ullman (1984) Visual routines.
 Cognition 18, pp:97159.
 S.
D.
Whitehead and D.
H.
 Ballard (1992) Learning to Perceive and act.
 U.
 of Rochester, Computer Science Technical Report.
 Jeremy Wolfe (1994) Guided Search 2.
0 A revised model of visual search.
 Psychonomic Bull.
 & Rev 1 2:202238.
 59 Scan path t=0 t=l t=2 t=3 t=4 t=5 t=10 t=15 t=20 t=25 t=30 t=35 m t=40 t=45 t=50 t=55 t=56 Figure 4: Generation of a scan path.
 See text for explanation.
 1.
1.
5 16 1.
2.
5 89 2.
1.
5 72 1 ^ 2.
2.
5 75 3.
2.
5 76 I 5.
1.
5 16 5.
2.
5 12 6.
1.
5 22 6.
2.
5 20 7.
1.
5 7 t i 8.
2.
5 36 9.
1.
5 N50 9.
2.
5 N50 10.
1.
5 35 10.
2.
5 6 Figure 5: Example scan paths.
 60 T h e A C T  R Theory and Visual Attention John R.
 Anderson Carnegie Mellon University Department of Psychology Pittsburgh.
 P A 15213 ja@cmu.
edu Michael Matessa Carnegie Mellon University Department of Psychology Pittsburgh, P A 15213 matessa(a)cmu.
edu Scott Douglass Carnegie Mellon University Department of Psychology Pittsburgh.
 P A 15213 sd3n<a) andrew.
cmu.
edu Abstract The ACTR productionsystem theory (Anderson, 1993) has been extended to include a theory of visual attention and pattern recognition.
 Production rules can direct attention to primitive visual features in the visual array.
 When attention is focused on a region, features in that region can be synthesized into declarative chunks.
 Assuming a time lo switch attention of about 200 msec, this model proves capable of simulating the results from a number of the basic studies of visual attention.
 W e have extended this model to complex problemsolving like equation solving where we have shown that an important component of learning is acquiring more efficient strategies for scanning the problem.
 Theories of higherlevel cognition typically ignore lowerlevel processes such as visual attention.
 They simply assume that lowerlevel processes deliver some relatively highlevel description of the stimulus situation upon which the higherlevel processes operate.
 This certainly is an accurate characterization of our past work on the ACTR theory (e.
g.
.
 Anderson, 1993).
 The typical task that ACTR has been applied to is one in which the subject must process some visual array—the array may contain a sentence to be recognized, a puzzle to be solved, or a computer program being written.
 W e have always assumed that some processed representation of this visual array is placed into working memory in some highly encoded form and w e modeled processing given that representation.
 The strategy of focusing on higherlevel processes might seem eminently reasonable for a theory of higherlevel cognition.
 However, the strategy creates two stresses for the plausibility of the resulting models.
 One suess is that by assuming a processed representation of the input the theorists are granting themselves unanalyzed degrees of freedom in terms of choice of representation.
 It is not always clear whether the success of the model depends on the theory of the higherlevel processes or the choice of the processed representation.
 The other stress is that the theorist may be ignoring significant problems in access to that information which may be contributing to dependent variables such as accuracy and latency.
 For instance, the visual input may contain more information than can be held in a single attentional fixation, and shifts of attention (with or without accompanying eye movements) may become a significant but ignored part of the processing.
 For these reasons w e have been encouraged to join the growing number of efforts (e.
g.
, Kieras & Meyer, 1994; Wiesmeyer, 1992) to embed a theory of visual processing within a higherlevel theory of cognition.
 The choice to focus on vision is largely strategic—reflecting the fact that most of the tasks that A C T  R has modeled involved input from the visual modality.
 To be more exact, most tasks have involved processing input from a computer screen and so w e have developed a theory of the processing of a computer screen.
 It is important to define our approach to the problem from the outset: W e require a theory of visual attention and perception which is psychologically plausible but it is not our intention to propose a new theory of visual attention and perception.
 Therefore, we have embedded within A C T  R a theory which might be seen as a synthesis of the spotlight metaphor of Posner (1980), the featuresynthesis model of Treisman (Treisman & Sato, 1990), and the attentional model of Wolfe (1994).
 What this model does is to provide us with a set of constraints which w e then can embed within the A C T  R theory of higherlevel cognition.
 We have implemented the spotlight metaphor of visual attention where a variablesized spotlight of attention can be moved across the visual field.
 W h e n the spotlight fixates on an object, it's features can be recognized.
 Once recognized, the objects are then available as declarative structures, called chunks, in ACTR's working memory and can receive higherlevel processing.
 The following is a potential chunk encoding of the letter H: object isaH leftvertical rightvertical horizontal barl bar2 bar3 61 mailto:ja@cmu.
eduhttp://andrew.
cmu.
eduW e assume that before the recognition of the object, features (e.
g.
, the bars) are available as part of an object but that the object itself is not recognized.
 In general, w e assume that the system can respond to the appearance of a feature anywhere in the visual field and recognize the objects.
 However, it cannot respond to the conjunction of features that define a pattern until it has moved its attention to that part of the visual field and recognized the pattern of features.
 Thus, in order for the A C T  R theory of higherlevel processing to "know" what is in its environment, it must move its attentional focus over the visual field.
 In A C T  R the calls for shift of attention are controlled by explicit firings of production rules.
 Consequently, it will take time to encode visual information and w e are forced to honor the limited capacity of visual attention.
 A basic assumption is that the process of recognizing a visual pattern from a set of features is identical to the process of categorizing an object given a set of features.
 Anderson and Matessa (1992) provide a rational analysis of h o w to perform such categorization without commitment to a particular cognitive architecture.
 That theory provides us with the mechanism for assigning a category (such as H ) to a particular configuration of features.
 W e have implemented this mechanism within the A C T  R for translating stimulus features into chunks like the above which can be processed by the higherlevel production system.
 The best way to illustrate how this theory functions is to describe how it functions in particular tasks.
 In the following section w e will first describe how the theory would apply in modeling data from the classic Sperling Task which will give us some estimate of time to move visual attention.
 Then w e will discuss an application of this to the subitizing task which shows how this time estimate plays out in a slightly more complex situation.
 W e will then turn to discussing movement of visual attention in a higherlevel task—solving equations.
 Sperling T a s k Sperling (1960) reported a classic study of visual attention.
 In the wholereport condition he presented subjects with brief presentations of visual arrays of letters (3 rows and 4 columns) and found that on average they could report back 4.
3 letters.
 In the partialreport condition he gave subjects an auditory cue to identify which row they would have to report.
 Then he found that they were able to report 3.
3 letters in that row.
 As he delayed the presentation of the auditory cue to 1 second after the visual presentation he found that subjects' recall fell to about 1.
5 letters.
 Since subjects' recall at a second's delay fell to about a third of the whole report level, the obvious interpretation was that they were able to report as many items from the cued row as they happened to encode without the cue.
 This research has been interpreted as indicating that subjects have access to all the letters in a visual buffer but they have difficulty in reporting ihcm before they decay.
 W e will use .
8 seconds as our estimate of the duration of that buffer in our simulation.
 W e represented the letters in the visual array as sets of features grouped in unidentified objects.
 Depending on the situation, one of the following two productions would apply: Encode Screen IF one is encoding digits without a tone and there is an object on the screen that has not be attended T H E N move attention to that object Encode Row IF one is encoding digits and there is a lone and a row corresponds to the tone and there is an object in the row that has not be attended T H E N move attention to that object These productions call for attention to be moved to unattended objects.
 W h e n the production moves attention to the location of that object, the letter would be recognized and a chunk created to encode it.
 This chunk creation also allows A C T  R to know it has attended to that object (and so avoid return visits).
 The actual recognition of the letter is done by the categorization component external to the productions.
 If no tone is presented, encodescreen will encode any letter in the array; whereas, if a tone is present, encoderow will encode letters in the cued row.
 Thus, the number of letters encoded is essentially equal to the number of productions that can fire in .
8 seconds.
 After the visual array disappears, the simulation can report only those letters that had been encoded because only these have a chunk representation in working memory.
 We get the justoverfour letters reported in the wholereport procedure (as found by Sperling) by setting the time per attentionswitching production rule to .
2 seconds.
 This was a mean time for a production to apply; w e added a stochastic component to these times producing itemtoitem variability in times.
 Because of this stochastic component the model averaged slightly over 4 letters reported in .
8 seconds.
 To see this, suppose that the array was just available for .
2 seconds and half of the times for the production were under .
2 seconds and half were above.
 For those under, the model would get a second look and so encode a second letter (the assumption is that the letter is encoded as soon as attention fixates).
 For those over, there would be just one letter reported.
 So the average number reported would be 1.
5 letters.
 Performance in the partial report condition was in a certain sense suboptimal because attention would not switch as soon as the tone sounded but rather as soon as the next production fired after the tone sounded.
 Thus, if the tone sounded at .
3 seconds and the next production fired at .
4 seconds the subject would only have .
4 (.
8  .
4) 62 seconds lo scan the appropriate row.
 Even when the tone occurred immediately at the offset of the array the first attentional fixation would be at a random location on the array and the second would be set to the target row.
 Sperling reports performance somewhat lower in the partial report condition than would be expected il the subject could report as many terms from the target row as the full array.
 Our simulation reproduces this effect in a parameter free way.
 Subitizing We have taken the 200 msec estimate of the time to switch visual attention from the Sperling task and used it to model a number of other tasks which involve deploying visual attention and we will describe here its application to subitizing (see the recent discussion by Simon, Cabrera, & Kliegl, 1993).
 Figure 1 illustrates the classic result obtained in this task where there is an increase in latency with number of digits to be identified.
 However, there is an apparent discontinuity in the increase with the slope being much shallower until 3 or 4 items and then getting much steeper.
 There is about a 50 msec slope until 3 or 4 items and approximately a 250 msec slope afterwards.
 Figure 1 also shows the results from the ACTR simulation.
 2000 1500 .
 2500^ e I 1000 I 500 0 10 Number of Items Figure 1: Data from a subitizing task compared to predictions of the ACTR theory.
 The basic organization of the model is to assume that there are special productions that recognize 1, 2, 3, and familiar configurations of larger number of objects (such as five on a die face) and that there is a production which can count single objects.
 This is the basic model of the subitizing task that has been proposed by researchers such as Mandler and Shebo (1982).
 The following are two of the productions used in modeling the task: RecognizeTwo IF the goal is lo count the objects starting from a count of 0 and there is an object at position 1 and there is an object at position 2 T H E N move attention to their pattern and the count is 2.
 CountOne IF the goal is to count the objects starting from a count of m and there is an object on the screen that has not be attended and n is the successor of m T H E N move attention to that object on the screen and increment the count to n.
 Faced with an array of objects, the largest patternrecognition production (like recognizetwo above) will apply and directly recognize the count of those objects.
 After that point it is necessary to add further objects into a running count and this is done by countone above.
 While one could count multiple additional objects and add them into the existing count, the simpler model that w e have implemented simply counts up by ones.
 The basic latency model for this task is one which takes the 200 msec from the Sperling task as the time for shift of attention and 50 msec as the time to match each nongoal element in a production rule beyond the first.
 The A C T  R model assumes that production firing increases with number of production condition elements.
 The basic latency will be determined by the productions above plus the time for response generation.
 Small arrays will be handled by productions like recognizetwo with each object matched taking an additional 50 msec to match.
 The countone production, which determines the perelement time (beyond 3) for larger arrays, is basically the production from the Sperling task plus a retrieval of the successor of the count.
 Each firing of it should take 250 msec, reflecting the 200 msec to shift attention plus 50 msec to retrieve the successor of the count.
 Equation Solving Figure 2 shows a screen image that we have been using in our research on equation solving.
 W e have done extensive research on how subjects solve such equations and much more complex ones (Anderson, Reder, & Lebiere, submitted; Lebiere, Anderson, & Reder, 1994).
 This early work involved simulations which assumed that subjects were operating on an internal representation of the equation which came as an encoding of Uie visual presentation of the screen.
 More recenUy, we have been interested in modeling how subjects might actually go about encoding information from the screen.
 W e have assumed that subjects first encode the symbols from the equation through a scanning process driven by productions like: EncodeSymbol IF the goal is to solve an algebra equation and the leftmost unattended object is at a location T H E N move attention to that location.
 This production embodies a lefttoright encoding strategy in which subjects encode each symbol from the equation and then are able to apply some procedure like: 63 Multiplybothsides IF the goal is to solve an algebra equation and the equation is of the form X/C = D T H E N set a subgoal to multiply C by D.
 However, in observing our own behavior solving this equation we noted that we often did not bother to scan the whole equation but rather focused on just the meaningful pans of the equation — the C and D in X/C = D.
 (This occurred in the context of an experiment where all the problems were division problems.
) Therefore, we have begun a research program to study just how subjects do scan such equations.
 algebra Figure 2 Our initial research has involved using a restricted interface like the one illustrated in Figure 3.
 Here the subject has a movable window with which to examine the equation.
 To move the window, the subject just moves the mouse.
 W e analyzed subject movements into periods where they spend at least 200 msec, on a meaningful symbol of the equation.
 If we represent these simple equations as X/C = D, then the five meaningful regions are X, /,C,=, and D.
 The spacing and size of the window are such that only one region at a time can be fixated.
 algebra Figure 3 We found evidence for at least two scanning patterns.
 One involved a nearexhaaustive, linear scan of the equation in which the subject fixated the symbols in the sequence X, /, C, =, D.
 If we use this strict definilion then subjects engage in this scanning pattern (with over 200 msec fixations on each symbol) on just 8 % of the problems.
 However, if we use a more liberal scoring definition in which we require the subject to fixate C, D, and two of X, /, and D in any order with any number of repeat visits that percentage rises to 4 3 % .
 The second strategy was indicated by the subject just visiting the C and D.
 This occurred 3 5 % of the lime.
 These percentages are for the first day of the experiment.
 Subjects were in the experiment for three days.
 By the third day the first strategy had dropped from 4 3 % to 1 1 % by the libera! scoring method while the second strategy had risen from 3 5 % to 67%.
 Thus, there is a very definite shift over the course of the experiment to a more efficient scanning strategy.
 This raises the issue of what the nature of the learning might be in this task.
 Subjects get much faster over the course of the three days, taking 4.
06 seconds to solve the simple equations on day 1 but 2.
66 seconds on day 3.
 W e broke this time up into two components.
 There is the time spent when not fixating the equation and the time spent fixating the equation.
 The nonfixation time includes the time before the first equation fixation when the subject is perhaps organizing a strategy and the time after the last fixation when the subject is typing out the answer.
 This nonfixation time decreases from 1.
84 seconds on day 1 to 1.
34 seconds on day 3.
 The fixation time decreases from 2.
22 seconds to 1.
32 seconds.
 W e analyzed the fixation time into time per fixation and separated these out into fixations before the last and fixations after the last.
 The prelast fixations appear to be relatively constant and average .
42 seconds on day 1 and .
36 seconds on day 3.
 So there is little speed up in the duration of these fixations.
 The last fixation takes much longer—.
94 seconds on day 1 and .
92 seconds on day 3.
 The longer time for the last fixation (almost always on d) presumably reflects the time for the subject to make the calculation.
 Thus, the reason why subjects are spending less fixation time is not a reduction in amount of time per fixation but rather a reduction in the number of fixations—from about 4.
2 on day 1 to 2.
8 on day 2 Thus, we have discovered that an important component of the learning (indeed the majority of the time savings) that is going on in this experiment is due to improved strategies for scanning the equation.
 This is very different than the typical explanation of speed up in A C T which attributes it either to stronger and more rapid productions or to compositions of existing productions (Anderson, 1987).
 This serves to illustrate the important contribution that study of visual attention can make to our understanding of the nature of learning.
 This research indicates that an important component ot skill development is learning where critical information is to be found in the visual interface.
 The ACTR theory does have strategy learning mechanisms which can model the transition between strategies (Anderson, 1993; Lovett & Anderson, in press) and we are currently in the process of trying to model this transition.
 Concluding Remarks In the introduction we described two motivations for developing a theory of visual processing in ACTR.
 One was to model the informationprocessing limitations in accessing information from the screen.
 This paper has been mainly devoted to describing that—showing how we can model classic allentional paradigms and gain insight into the performance and improvement of complex 64 cognitive skills.
 The other motivation was to eliminate magical degrees of freedom in going from a description of an experiment, to a cognitive model of how it is performed.
 W e have accomplished this also.
 The same experimental software that runs subjects interacts with the ACTR system.
^ W e have developed the experimentrunning system that can be "toggled" so that it will either administer an experiment to a real subject or interact with the ACTR simulation.
 When it is toggled to interact with ACTR, ACTR can "see" the screen in terms of this feature representation and the experimental program will read key presses, mouse movements, and mouse clicks issued by ACTR.
 Thus, it becomes possible for anyone to build a simulation to interact with the same experimentrunning software that subjects interact with (provided that software is written in LISP on the Macintosh).
 References Anderson, J.
 R.
 (1987).
 Skill acquisition: Compilation of weakmethod problem solutions.
 Psychological Review.
 94,192210.
 Anderson, J.
 R.
 (1990).
 The adaptive character of thought.
 Hillsdale, NJ: Erlbaum.
 Anderson, J.
 R.
 (1993).
 Rules of the mind.
 Hillsdale, NJ: Erlbaum.
 Anderson, J.
 R.
 & Matessa, M.
 (1992).
 Explorations of an incremental, Bayesian algorithm for categorization.
 Machine Learning, 9.
 275308.
 Anderson, J.
 R.
, Reder, L.
 M.
 & Lebiere, C.
 (submitted).
 Working memory: Activation limitations on retrieval.
 Cognitive Psychology.
 Kieras, D.
 E.
 & Meyer, D.
 E.
 (1994).
 The EPIC architecture for modeling human informationprocessing and performance: A brief introduction.
 EPIC Report N o 1.
 (TR94/ONREPIC1).
 University of Michigan.
 Lovett, M.
 C.
 & Anderson, J.
 R.
 (in press).
 History of success and current context in problem solving: Combined influences on operator selection.
 Cognitive Psychology.
 Lebiere, C , Anderson, J.
 R.
, & Reder.
 L.
 M.
 (1994).
 Error modeling in the ACTR production system.
 In J*roceedings of the Sixteenth Annual Conference of the Cognitive Science Society, 555559.
 Hillsdale.
 NJ: Erlbaum.
 Mandler.
 G.
 & Shebo.
 B.
 J.
 (1982).
 Subitizing: An analysis of its component processes.
 Journal of Experimental Psychology: General, 111, 122.
 McClelland.
 J.
 L.
 & Rumelhart, D.
 E.
 (1981).
 An interactive model of context effects in letter perception: I.
 An account of basic findings.
 Psychological Review, 88, 375407.
 Posner, M.
 I.
 (1980).
 Orienting of attention.
 Quarterly Journal of Experimental Psychology.
 32.
 325.
 Simon, T.
, Cabrera, A.
, & Kliegl, R.
 (1994).
 A new approach to the study of subitizing as distinct enumeration processing.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, 929934.
 Hillsdale, NJ: Erlbaum.
 Sperling, G.
 (1960).
 The information available in brief visual presentations.
 Psychological Monographs.
 74.
 129.
 Treisman, A.
 M.
 & Sato, S.
 (1990).
 Conjunction search revisited.
 Journal of Experimental Psychology: Human Perception and Performance.
 16,459478.
 Wiesmeyer, M.
 D.
 (1992).
 An operatorbased model of covert visual attention.
 PhD Thesis, The University of Michigan, Ann Arbor.
 Wolfe, J.
 M.
 (1994).
 Guided search 2.
0: A revised model of visual search.
 Psychonomic Bulletin & Review, 1.
 202238.
 1 W e have taken advantage of standards for Macintosh LISP dialogue windows to create a default visual interface module which represents alphanumeric characters in terms of a standard set of features (those used in the McClelland & Rumelhart, 1981, modeling), and encodes all other elements in the window in terms of their default Macintosh encodings.
 It is possible for users to change the feature representation according to their preferences, but the default provides a firstorder representation from which everyone can work 65 MetaCognitive Attention: Reasoning about Strategy Selection Ruediger Oehlmann Department of Computing Science University of Aberdeen Aberdeen.
 AB9 2UE, SCOTLAND, UK oehlmann@csd.
abdn.
ac.
uk Abstract Both human learners and CaseBased Reasoning systems have applied metacognitive strategies such as selfquestioning to improve the learning process.
 Whereas casebased reasoning systems do not allocate attention to reasoning strategies in order to facilitate strategy selection, previous work on attention in human thinking has focused on the selection of domain objects.
 W e describe a computational model of metacognitive attention which integrates metacognitve approaches in casebased reasoning with the concept of attention which is applied to the reasoning process itself.
 An example of our implementation, lULJAN, will illustrate the process of allocating metacognitive attention.
 Introduction People who are confronted with several reasoning tasks at the same time have to make a decision about the task they want to address first.
 For example, a surprising observation can lead to reasoning about its effect or explaining its cause.
 Reasoning about an agent's reasoning processes has been studied in metacognition.
 This term refers to the "active monitoring and consequent regulation" of an agent's cognitive processes (Flavell 1976).
 That is, the term metacognition describes two distinct but related issues: the issue of knowledge about cognition and the issue of regulating cognition.
 The notion of knowledge about cognition includes awareness of the resources available to the agent with respect to the demands of the agent's reasoning process; for example, the availability of analogous knowledge during an analogical mapping task.
 The process of regulating cognition involves selfregulating mechanisms such as planning, monitoring, and selfquestioning (Brown, 1975; Wong, 1985).
 Such metacognitive skills should be improved with growing experience.
 Reasoners should be able to reuse such experience when they select reasoning strategies.
 In Artificial Intelligence systems, experience related to a given domain and the abiUty to be reminded of previous experience have been modeled by the paradigm of CaseBased Reasoning, where previous experience is usually represented as cases (see Kolodner 1993 for an overview).
 Important stages of the casebased reasoning approach are the retrieval of a previous case which contains a previous problem and its solution, and the adaptation of this case to obtain a solution for the current problem.
 If this approach is applied to plans rather than to problem solution pairs, w e refer to it as casebased planning (Hammond et al.
, 1993).
 Often casebased reasoning systems use memories indexed in terms of prediction failures which occurred during the reasoning process.
 W h e n the system generates a wrong prediction, the case on which the prediction was based is annotated with a characterization of the failure situation (Schank, 1986).
 The annotation is used as an index during future case retrieval.
 As a result, the prediction failure can be avoided in the future.
 Recent research in casebased reasoning has addressed the issue of guiding the reasoning process by introspection (Fox & Leake.
 1994; R a m & Cox, 1994; Oehhnann et al.
 1995).
 Earlier research has stressed the importance of allocating attention for the human reasoning process.
 Whereas previous investigations of metacognitive aspects of casebased reasoning did not address the active selection of reasoning strategies by focusing attention, work on attention addresses the selection task.
 However, the selection process is often limited to the domain level.
 For example, Ohlsson (1984) proposes an attentional heuristic which selects objects about which no inference has been made at a given state of the reasoning process.
 In a similar spirit, Bacon (1995) characterizes metaknowledge about the process of focusing attention on particular domain objects.
 In contrast to this domain related view, w e will describe a computational model which w e refer to as metacognitive attention.
 The model integrates the idea of metacognitive regulation of the reasoning process with the concept of attention.
 In particular, w e will present an operational characterization of metacognitive attention in terms of intention, situation, and resource.
 In the remainder of this paper, w e present an example involving the chime of a mechanical clock followed by a toplevel view of our implementation lULIAN.
 W e then describe our approach to strategy selection based on metacognitive attention, and w e explain the knowledge structures used by these iMocesses.
 Finally, w e discuss our approach and indicate options for future work.
 Example We will motivate the idea of changing the viewpoint by describing a problem involving a mechanical clock.
 In addition to the mechanism for moving the hands, the clock has a chime.
 The main relations of the chime mechanism 66 mailto:oehlmann@csd.
abdn.
ac.
ukare indicated in Figure 1.
 W e assume that the learner attempts lo understand how the hammer movement is initiated.
 In addition, we assume that several wheels have already been studied.
 Hammer Lever Wheel Second Intermediate Hammer Wheel Hammer First Intermediate Hammer Wheel Pin Wheel Two Wing Wheel Large Intermediate Hammer Wheel Small Pin Wheel Lever Hammer Spring Wheel Round Lever Lever Small Lever Hands Lgggnd; .
̂ y,.
 Wheel drives neighboring wheel by direct contact.
 Small lever moves into the orbit of the pin wheel.
 Hammer lever wheel presses the distant end of the hammer down and moves the hammer.
 One lever moves another lever Wheel moves lever Figure 1: Relations in the Clock Example The reasoner knows that the wheels transfer the force of the hammer spring wheel to the pin wheel.
 The movement of one wheel drives the movement of the neighboring wheel.
 The reasoner attempts to identify a chain of consequences responsible for the hammer movement and asks an appropriate question.
 At this point, the reasoner does not know the answer and performs an experiment.
 The reasoner attempts to enable the movement of the pinwheel by moving the clock hands into the appropriate position and observes tne movement of the twowingwheel This process leads to an important observation: a lever is moved into the orbit of the pinwheel, touches the pin, and interrupts the movement of the pinwheel.
 The unexpected obsCTvation enables the reasoner to pursue two different reasoning strategies.
 One strategy involves a change of the viewpoint and subsequently a change of the reasoner's view.
 Rather than reasoning about the consequences of the moving pinwheel, the reasoning process focuses now on the consequences of the stopping pinwheel.
 (Oehhnann, et al.
, 1994).
 This strategy can be viewed as reasoning about the effect of a surprising observation.
 The other strategy involves reasoning about the cause of the surprising observation: the reasoner attempts to explain why the lever moved into the orbit of the pinwheel.
 Both strategies are based on the same surprising observation and have a high degree of interestingness; therefore the reasoner has to decide which strategy to apply first, i.
e.
 how to direct the metacognitive attention.
 W e will describe the details of this process in the over next section.
 The lULIAN System The lULIAN system uses the planning of selfquestions, answers, and experiments to model reasoning about plans and actions.
 The main task of the system is the generation of new explanations to revise an initial theory.
 Figure 2 shows the main modules of the system: question planner.
 answer planner, experiment planner, hypothesis formation, and introspection planner The figure also indicates that the lULIAN system represents an integration of casebased reasoning and casebased planning rather than a single casebased reasoner: the hypothesis formation module is a casebased reasoner whereas the other modules are implemented as casebased planners.
 The Question Planner module accepts a problem description as input, generates a question about the problem, and transfers control to the Answer Planner.
 If a question cannot be answered, the Question Planner, the Answer Planner, and the Experiment Planner can be used to generate additional questions, answers, and experiments which help the lULLAN system to recover from this situation and to provide the knowledge needed to generate the answer Before an experiment is performed, the Hypothesis Formation module hypothesizes the experimental result.
 W h e n the actual result is generated, the Hypothesis Formation module determines an expectation failure as the difference between the hypothesis and the actual result.
 If an expectation failure has been detected, the exploration process is initiated.
 At its simplest, the process of question and answer generation is based on the Question Planner and the Answer Planner which generate a question about the problem and attempt to answer it.
 If a question cannot be answered.
 Question Planner, Answer Planner, and 67 Experiment Planner can again be used to generate additional questions, answers, and experiments in an attempt to provide the missing knowledge.
.
 (^ProblenT) Question Planner I Initial Theory Answer Planner Introspection Planner Hypothesis Formation Experiment Planner ("• \ V ( Explanation Revised A Theory J Figure 2: The lULIAN System During this process of questionbased reasoning and experimentationbased activity, questions focus on objects of the domain to be investigated such as pinwheel and smalllever (see Figure 1).
 In addition, the Question Planner generates Questions which focus on the system's reasoning process.
 If the system asks such a question, using an answer plan to generate a sentence is not sufficient because the answer planner needs additional metaknowledge which is not available to it.
 Acquiring this knowledge is the task of the introspecUon planner (Oehhnann, 1992; Oehlmann, et al.
 1995).
 The basic knowledge structures of the lULIAN system are experiments and plans which are used as cases.
 An experiment consists of two components: an experimental setting (e.
g.
 a descripdon of a mechanical clock with wheels, springs, and hands) and the result of an experiment such as the statement that "the hammer of the chime is moving when the large hand is in upright position.
" Experiments are represented by objects and relations between objects.
 Objects are represented as Memory Units^ ( M U ) which contain an object frame and a content frame (Figure 3).
 The context frame describes the context in which the object occurs represented by a set of relations.
 The content frame contains several sets of intentional descriptor values referred to as views, whereas 1.
 M U s are similar to the Universal Index Frames (Schank & Osgood, 1990).
 general information about the object is stored in the object frame.
 Question plans are used to apply casebased planning techniques to the generation of single questions.
 For example, the quesUon "What does the P I N  W H E E L turn?" can be built by combining the substructures "What", "does", "the OBJECTl", and "turn.
" OBJECTl is a variable which is instantiated with the siring "PINW H E E L " during plan execution.
 A question plan has two main parts: a set of descriptors used for indexing the plan and a sequence of steps.
 A plan is retrieved by matching its index with the current situation; this is characterized by the goals the system pursues in asking the question.
 If plan execution fails, the usual explanationbased repair mechanisms are employed, (see Hammond, 1989).
 It is an important advantage of the casebased planning approach that new questions can be learned by modifying previous question plans.
 Answers are generated in a similar way; however, steps in answer plans may have particular actions which retrieve knowledge from the library of experiments needed to form an answer.
 For example, an answer to the question "What does the P I N  W H E E L turn?" may be generated by executing the following steps: the first step retrieves the object pinwheel and identifies an object which shares the relation haseffect@turns with the object pinwheel.
 This object is twowingwheel and is stored in the answer plan.
 The following steps instantiate two variables with the objects pinwheel and twowingwheel and combine these variables with the substrings "The", "turns", and "the.
" The resulting sentence is "The P I N  W H E E L turns the TWOWINGWHEEL.
" The casebased planning approach to generating questions and answers is highly flexible because it only depends on the current situation and the goals the system is attempting to pursue.
 Moreover, new plans can be generated by adapting existing plans to new situations.
 A n introspective answer is a sentence generated as response to a question about the reasoners internal knowledge and its internal processes.
 A n answer plan which has to generate an introspective answer contains special steps.
 Executing such a step results in a call of the introspection planner.
 This planning process provides the information needed by the answer planner which can then complete the answer.
 A n example of an introspection plan will be discussed in the next section.
 Introspection plans address different metacogniUve tasks such as assessing goals, reasoning strategies, resources needed to perform a given reasoning strategy, failures which occurred during previous reasoning strategies, and conditions which have to be satisfied in order that a strategy can be executed.
 In addition, the lULIAN system uses experimentation plans to perform experiments.
 Experimentation plans describe the steps which have to be executed in order to perform an experiment.
 The experimental setdng and the 68 result of plan execution are stored as a new case.
 The same basic plan structure used for question and answer plans has been employed for experimentation plans, although the index vocabulary differs (Oehlmann et al.
, 1993).
 Context Frame OblOb2 0b3 Objl — rell — Obj2 rell — rel3 Obi3 — rel2 — Content Frame viewl view2 view viewer agent prebelief task goal Object Frame object setting expectation type Figure 3: Memory Unit MetaCognitive Attention In this section, we describe our approach to strategy selection in terms of metacognitive attention.
 W e will exemplify our approach by elaborating the clock example described above.
 The strategies mentioned in the example are changing the viewpoint based on a surprising observation and explaining a surprising observation.
 W e have argued elsewhere that similar to a physical viewer observing an object from a given viewpoint, the reasoner can consider objects from the perspective of different goals and beliefs (Oehlmann et al.
, 1994; Ohlsson, 1990; Schank & Osgood, 1990).
 The current viewpoint is characterized by goals associated with the pinwheel.
 It is part of the initial reasoning strategy to identify the effect of the motion of the pinwheel on the neighboring wheel.
 The strategy changing the viewpoint attempts to identify the effect caused by stopping the pinwheel.
 In contrast, the strategy explaining a surprising observation focuses on the causes of the smalllever movement: the movements of the large lever and the round lever which control the movement of the small lever (Figure 1).
 The process of attaching metacognitive attention to the reasoning suategies is based on elements of the index vocabulary such as cognitive goal, cognitive need, context, strategy projection, and strategy resources.
 The cognitive goal refers to the objectives of the understanding process.
 The objective is related to strategies used in the understanding process and generated as a sequence of questions and answers.
 In contrast, the descriptor cognitive need is related to gaps in the ctirrent knowledge the reasoner attempts to fill.
 A reasoning strategy is focusing on one or more objects.
 Usually, some knowledge related to these objects is already available.
 This knowledge forms the context.
 The descriptor strategy projection indicates whether the result of the strategy can be ah^eady anticipated or whether it requires a substantial amount of inference.
 Finally, the descriptor strategy resources describes knowledge structures needed to perform a given reasoning strategy.
 The reasoner can select a strategy by acquiring values for these index descriptors.
 The values are determined by generating a sequence of introspective selfquestions and answers (Oehhnann, et al.
, 1995).
 Intention Assessment: 1.
 Assesses the cognitive goals and select questions which m a y (partially) address these goals.
 2.
 Assesses the cognitive need and select questions which may (partially) address this need.
 Situation Assessment: 3.
 Assesses the context related to the focus of all questions under consideration and select the question related to the poorest context.
 4.
 Attempts to project the outcome of the potential strategies.
 Resource Assessment: 5.
 Assesses the resources needed to perform the potential strategies.
 Figure 4: The Metacognitive Attention Process The reasoner begins the process of attaching attention by identifying two questions.
 Each of these questions indicates the begin of a reasoning strategy.
 To identify these questions the following introspective question is asked: Question 0: What are the qjesticns I ccnsider? The question plans used to generate these questions can be identified on the basis of the question goals and reasoning goals the reasoner pursues.
 Answer 0: I ocnsider the questicns: "Viiat is the effect of t±e PINVHEEL being blocked?" and "Vty dbes the a^ALLIB/ER blocks the PINIaHEEL?" After identifying questions which lead to potential reasoning strategies, the reasoner attempts to evaluated these questions in terms of the descriptors given above.
 All the following questions refer to the set of questions identified in Answer 0.
 The next question focuses on the descriptor cognitive goal.
 69 Question 1: Vhat qjesticn is related to the cxirrent cognitive goal? Obviously, a reasoning strategy related to the hammer serves the cognitive goal of understanding the hammer movement better than a reasoning strategy which explains the lever movement.
 Answer 1: The qjesticn "V̂ Jat is the effect of the PINVHEHLi being blocted?" is related to the current oognitive gcal CCIBEiaUEICEaffinKINS.
 The next question focuses on the cognitive need.
 Question 2: Vhat questicn is related to the current ODgnitive need? Answer 2: The question "What is the effect of the PPJWHKFTi being blocked?" is related to the current cognitive need ESNTIFYEFFEXTT: :NEIC3ffiOURIN3WHEELS.
 N o w the reasoner investigates the context of the objects pinwheel and smalllever.
 Question 3: Vtat qiesticn focus is sLfported ty a richer ccnt:ext? Answer 3: The qjesticn "Viret is the effect of the PINVMTTi being blocked?" has the richest ccntext.
 This answer is given because the reasoner knows the relations between the pinwheel and its neighboring wheels.
 However, the relations between the smalllever and another levers are unknown at this state.
 N o w the reasoner attempts to anticipate the results of the two strategies in question.
 If the surprising observation would have supported the initial reasoning strategy of checking the consequences of the wheel movements, the result of this strategy could be easier hypothesized.
 In this situation the reasoner would prefer to explain the suri«ising observation, because it understands this issue less than the hammer movement.
 Question 4: Vhat can I project about the cause of the noving lever and the effect of the stxfping pinvheel.
 The current situation is characterized by a surprising observation which contradicts the initial reasoning strategy.
 Therefore an ̂ propriate prediction cannot be made.
 Answer 4: I dD not hssjB arr/ knowlet^ vhich vould allcw ne to nake these predicticns.
 Fmally, the reasoner attempts to evaluate the questions to asked in terms of the resources necessary to perform the strategies.
 Question 5: Vhat are the questicns for vhich the r^cessary resources are available? Answer 5: The previous case needed for the qjesticn: •Hat is the effect of tte PINMIEEL being blocked?" and a previous e>plaraticn vhidi can be ad^±ed to answer the qjesticn "Wty does the ayMlrL£VER blacks the PINV«EEL?" are available.
 While the assessment of context and projection do not prefer any of the questions under consideration, the assessment of cognitive goal and cognitive need lead to the selection of a question which in turn leads to the strategy changing the viewpoint.
 Plans for Metacognitive Attention The process of metacognitive attention described in the previous section can be supported by inuospection plans which we have described elsewhere (Oehhnann et al.
, 1995).
 However, we have extended the Introspection Planner which now addresses all the stages of the metacognitive attention process given in Figure 4.
 An introspection plan has two main components: a header and a sequence of steps (Figure 5).
Important elements of the header are the slots name, planninggoal, and failures.
 I N T R O S P E C T I O N P L A N Name: contextassessment Planning Goal: assesscontext::goalneeded Failures: None Binding List: ((object! PINWHEEL) (object2 SMALLLEVER)) Intermediate Result 1: None Intermediate Result 2: None Intermediate Result 3: None Planning Steps: L Planning Step Action: checkrelations OBJECTl 0BJECT2 2.
 Planning Step Action: checkrelationobjects 3.
 Planning Step Action: compareobjectgoals 4.
 Planning Step Action: compareobjectneeds Figure 5: Introspection Plan The plan identifier is stored in the name slot.
 The slot planninggoal contains the goals the system attempts to satisfy by executing the plan; the slot failures characterizes planning failures which have occurred before.
 The two slots planninggoal said failures form the index of the introspection plan, i.
e.
 these slots are used for plan retrieval.
 In addition, the header includes the slots bindinglist and intermediateresult.
 The bindinglist contains pairs of variable names and their values.
 If an action of a planning step contains variables, the bindinglist is used to instantiate them.
 The intermediateresult slots are used to store a result which has been generated by a given planning step and which will be used by subsequent steps.
 A step has four slots: name, precondition, goal, and actiorr.
 The name slot serves as an identifier for a given step.
 In the slot precondition, the conditions are described which have to be true before the action given in the action slot can be executed.
 The slot goal lists the specific goals 70 the system attempts to satisfy by executing the action described in the action slot The value of the action slot is a list with a function name as first element.
 The remaining list elements are the arguments which, together with the n:unc, form a function call.
 If the function has no arguments, the action list contains the function name as a single element The introspection plan described in Figure 5 is executed as part of the generation of Answer 3 in the previous section.
 The answer has to assess the context of the objects pinw/iee/ and smalllever.
 The first planning step identifies the relations which form the context of the two objects, Then those objects are identified which are part of the relations.
 The last two steps evaluate the context with respect to the goals and the needs the reasoner attempts to address.
 The context which addresses the goals and needs best and the related questions are selected.
 Discussion We have identified the need for selecting reasoning strategies by metacognitive attention.
 This need arises from surprising observations which can be addressed by different reasoning strategies.
 Our novel approach to strategy selection is characterized by an integration of the concept of regulating cognition by selfquestioning which has been explored in CaseBased Reasoning and the idea of attention which has been explored in domains of human thinking.
In addition, we have presented an operational characterization of metacognitive attention in terms of assessing intention, situation, and strategy resources.
 The criteria considered in every group of assessments are sufficiently abstract to be applied to different strategy selections.
Currently, metacognitive attention is only used to select a strategy.
 Using introspection plans enables the reasoner to store the process of allocating attention as experience.
 However, the result of this process should be stored as metacognitive knowledge which could be used during metacognitive reasoning.
 Future woik will therefore focus on the representation of the attention focus itself rather than the process of allocating attention.
 References Bacon, W.
 (1995).
 WhatEveryone Knows about AttenUon.
 In Proceedings of the AAAl Spring Symposium on Representing Mental Models and Mechanisms, (pp.
 16).
 Brown, A.
 (1975).
 The Development of Memory: Knowing, Knowing about Knowing, and Knowing H o w to Know.
 In H.
 W.
 Reese (Ed.
), Advances in Child Development and Behavior (Vol.
 10).
 N e w York: Academic Press.
 Flavell, J.
 (1976).
 Metacognitive Aspects of Problem Solving.
 In L.
 Resnick (Ed.
), The Nature of Intelligence.
 Hillsdale, NJ: Lawrence ErIbaum Associates.
 Fox, S.
 & Leake, D.
 (1994).
 Using Introspective Reasoning to guide Index Refinement in CaseBased Reasoning.
 In Proceedings of the 16th Annual Conference of the Cognitive Science Society, (pp.
 324329).
 HUlsdale, NJ: Lawrence ErIbaum Associates.
 Hammond, K.
, Converse, T.
, & Marks, M .
 (1993).
 Towards a Theray of Agency.
 In S.
 Minton (Ed.
), Machine Learning Methods for Planning, (pp.
 351396).
 Hammond, K.
 (1989).
 CaseBased Planning: Viewing Planning as a Memory Task.
 N e w York: Academic Press.
 Kolodner, J.
 (1993).
 CaseBased Reasoning.
 San Mateo, CA: Morgan Kaufmann.
 Oehbnann, R.
 (1992).
 Learning Causal Models by SelfQuestioning and Experimentation.
 In Proceedings of the AAA/ Workshop on Communicating Scientific and Technical Knowledge, (pp.
 7380).
 Oehlmann, R.
, Edwards.
 P & Sleeman, D.
 (1994).
 Changing the Viewpoint: ReIndexing by Introspective Questioning.
 In Proceedings of the Annual Conference of the Cognitive Science Society, (pp.
 675680).
 Oehlmann, R.
, Edwards, R & Sleeman, D.
 (1995).
 Introspection Planning: Representing Metacognitive Experience.
 In Proceedings of the AAAI Spring Symposium on Representing Mental Models and Mechanisms, (pp.
 102110).
 Oehhnann, R.
, Sleeman, D.
 & Edwards, R (1993).
 Learning PlanTransformations from SelfQuestions: A M e m oryBased Approach.
 In: Proceedings of the 11th National Conference on Artificial Intelligence, (pp.
 520525).
 Cambridge, M A : AAAIMTT Press.
 Ohlsson, S.
 (1984).
 Attentional Heuristics in Human Thinking.
 In Proceedings of the 6th Annual Conference of the Cognitive Science Society, (pp.
 273  276).
 Ohlsson, S.
 (1990).
 The Mechanism of Restructuring in Geometry.
 In: Proceedings of the 12th Annual Conference of the Cognitive Science Society, (pp.
 237244).
 Ram.
 A.
 & Cox, M .
 (1994).
 Introspective Reasoning Using MetaExplanations for Multistrategy Learning.
 In: R.
 Michalski & G.
 Tecuci (Eds.
) Machine Learning: A Multistrategy Approach, 4 (pp.
 348377).
 San Mateo, CA: Morgan Kaufmann.
 Schank, R.
 (1986).
 Dynamic Memory.
 A Theory of Reminding and Learning in Computers and People.
 Cambridge, U K : Cambridge University Press.
 Schank, R.
 & Osgood, R.
 (1990), A Content Theory of Memory Indexing, Technical Report No.
 2, Northweste m University, Institute for the Learning Sciences.
 Wong, B.
 (1985).
 SelfQuestioning Instructional Research.
 A Review.
 Review of Educational Research, 55, 227268.
 2.
 Note that Figure 5 shows a reduced version of the original plan.
 In particular, the slots precondition and goal in the planning steps are omitted.
 71 CaseBased Comparative Evaluation in T R U T H  T E L L E R Bruce M.
 McLaren University of Pittsburgh Intelligent Systems Program Pittsburgh, Pennsylvania 15260 bmin@cgi.
 com Abstract Casebased comparative evaluation appears to be an important strategy for addressing problems in weak analytic domains, such as the law and practical ethics.
 Comparisons to paradigm, hypothetical, or past cases may help a reasoner make decisions about a current dilemma.
 W e are investigating the uses of comparative evaluation in practical ethical reasoning, and whether recent philosophical models of casuistic reasomng in medical ethics may contribute to developing models of comparative evaluation.
 A good comparative reasoner, we believe, should be able to integrate abstract knowledge of reasons and principles into its analysis and still take a problem's context and details adequately into account.
 TRUTHTELLER is a program we have developed that compares pairs of cases presentmg ethical dilemmas about whether to tell the truth by marshaling relevant similarities and differences in a context sensitive manner.
 The program has a variety of methods for reasoning about reasons.
 These include classifying reasons as principled or altruistic, comparing the strengths of reasons, and qualifying reasons by participants' roles and the criticality of consequences.
 W e describe a knowledge representation and comparative evaluation process for this domain.
 In an evaluation of the program, five professional ethicists scored the program's output for randomlyselected pairs of cases.
 The work contributes to context sensitive similarity assessment and to models of argumentation in weak analytic domains.
 Introduction Casebased comparative evaluation appears to be an important strategy for addressing problems in weak analytic domains.
 Such domains require the construction of arguments or explanations to justify decisions but cannot support the use of deductive methods or formal proofs to derive correct answers.
 Comparison to paradigm, hypothetical, or past cases can help a reasoner make decisions about a problem situation.
 For instance, in the legal domain, lawyers form arguments, at least in part, by analogizing to previously adjudicated cases and hypotheticals (Ashley, 1990).
 Practical ethical reasoning — and, m particular, truth tellmg — is another weak analytic domain in which such a comparative evaluation model ( C E M ) could prove useliil.
 A reasoner faced with an ethical dilemma could select paradigmatic, hypothetical, and past cases, compare them to the problem, construct arguments identifying the cntical reasons justifying their importance by drawing analogies to the cases, and evaluate the competing arguments to resolve the dilemma.
 Medical ethicists have recently revived a casebased (i.
e.
, casuistic) approach to practical ethical reasoning in which problems are compared to past or paradigmatic cases (Strong, 1988, Jonsen and Touimin, 1988).
 For instance, one ethicist proposed the following steps when one is faced with a moral problem: 1.
 Identify middlelevel principles and rolespecific duties pertinent to the situation.
 2.
 Identify alternative courses of action that could be taken.
 3.
 Identify morally relevant ways in which cases of this type can differ from one another (i.
e.
, factors).
 Comparing with other cases of the same type also helps identify factors.
 Kevin D.
 Ashley University of Pittsburgh Intelligent Systems Program Pittsburgh, Pennsylvania 15260 ashley9vins.
cis.
pitt:.
edu 4.
 For each option, identify a paradigm case in which the option would be justifiable.
 Paradigms can be actual or hypothetical cases.
 Identify the middlelevel principle which would provide that justification.
 5.
 Compare the case at hand with paradigm cases.
 Determine which paradigms it is "closest to" in terms of the presence of morally relevant factors (Strong, 1988).
 Computationally realizing a model like the above is interesting because it addresses important goals that casebased reasoning (CBR) has not yet modeled such as: (I) symbolically comparing problems and paradigmatic cases in terms of the underlying principles, reasons, and actions and (2) adequately accounting for a problem's specific contextual circumstances in deciding how to resolve conflicting reasons and principles.
 A key problem in decision making with principles, reasons, and cases is this: humans find it hard to integrate different kinds of knowledge which vary from the very abstract (principles) through an intermediate range (reasons) to the very specific (cases).
 Cognitive psychological evidence has shown, for instance, that gender and developmental differences affect a reasoner's ability to account for contextual features in applying general principles in moral decision making (Gilligan, 1982; Johnston, 1988).
 Some people are better than others at resolving ethical dilemmas, a process which requires one to take into account the problem's particular factual circumstances, qualify reasons based on then criticality and the participants' roles, relationships and interests, and consider possible alternative actions.
 Although AI / C B R programs have illustrated a variety of techniques for modeling comparative evaluation (see, for example, Bareiss, 1989; Golding and Rosenbloom, 1991), to our knowledge, a knowledge representation and inference technique has not been developed which integrates reasons, principles, and cases.
 Like (Edelson, 1992), w e represent principles which apply to cases at various levels of abstraction.
 In C A B A R E T (Rissland and Skalak, 1991), the circumstances also included the arguer's viewpoint and various argument moves associated with broadening or restncting a statutory predicate.
 In (Rissland, Skalak, and Friedman, 1993), legal rules, theories, standard stories, and family resemblance have been integrated into case retrieval and argumentation.
 W e , however, intend for our program to use principles and to reason about reasons differently from these programs.
 In particular, we are attempting to enable a program to use case comparison to decide whether principles and reasons apply more or less strongly in one case than another.
 In this paper, we report on our progress toward developing a C E M in the domain of practical ethics.
 T R U T H  T E L L E R (TT) is a program we have developed to compare pairs of cases presenting ethical dilemmas about whether to tell the truth.
 TT's comparisons point out ethically relevant similarities and differences (i.
e.
, reasons for telling or not telling the truth that (1) apply to both cases, (2) apply more strongly in one case than another or (3) apply only to one case).
 In developing the knowledge representation for symbolic case comparison, we have adhered to an approach of repeated development 72 and formative evaluation (Ashley and McLaren, 1994).
 Although T T does not implement Strong's C E M , it provides the kind of case comparison that would be essential to compare a problem and a paradigmatic case (Step 5 in Strong's procedure.
) TT's Case Comparison Method Havmg accepted as input representations of two cases to be compared, TT's case comparison method proceeds in four sequential phases: (1) The Alignment Phase.
 Aligning reasons means building a mapping between the reasons in two cases.
 The initial phase of the program "aligns" the semantic representations of the two input cases by matching smiilar reasons, actor relations, and actions, by marking reasons that are distinct to one case, and by noting exceptional reasons in one or both of the cases.
 (2) The Qualification Phase.
 Qualifying a reason means identifying special relationships among actors, actions, and reasons that augment or diminish the importance of the reasons.
 Heuristic rules strengthen and weaken individual reasons and actions.
 Attributes such as altruism, selfishness, and high criticahty are applied as qualifiers to reasons and actions.
 Also, the ahgnment links between reasons, relations, and actions of the two opposing cases are tagged with qualilymg information based on the participants' roles, reason types, and untried alternatives.
 (3) The Marshaling Phase.
 Marshahng reasons means selecting particular reason similarities and differences to emphasize in presenting an argument that (1) one case is stronger than the other with respect to a conclusion, (2) the cases are only weakly comparable, or (3) the cases are not comparable at all.
 Marshaling serves rhetorical criteria for deciding how to integrate facts, reasons, and justifications into a convincing output.
 (4) The Interpretation Phase.
 The fmal phase of the program generates the comparison text by interpreting the activities of the first three phases.
 The purpose of this phase is to generate prose that a nontechnical human evaluator can understand.
 The program employs various knowledge structures to support its algorithm including semantic networks that represent the truth telling episodes, a relations hierarchy, and a reasons hierarchy.
 Ail structures are implemented in L O O M (MacGregor, 1990).
 Each truth telling episode includes representations for the actors (i.
e.
, the truth teller, truth receiver, and others affected by the decision), relationships between the actors (e.
g.
, familial, professional, sellercustomer), the truth teller's possible actions (i.
e.
, telling the truth, not telling the truth, or taking some alternative action) and reasons that support the possible actions.
 The relations hierarchy is a taxonomy of approximately 80 possible relationships among the actors in a truth telling episode.
 Relationships include familial, commercial, and acquaintance relations.
 More abstract relationship types include hightrust, minimaltrust, and authority relations.
 The reasons hierarchy represents possible rationales for taking action.
 Based on the formulation in (Bok, 1989), the hierarchy employs, at its top tier, four general reasons for telling the truth or not: fairness, veracity, producing of benefit, and avoiding harm.
 All other reasons are descendants of one of these toplevel reason types.
 Each reason also has three other facets, criticality, if altruisric, and if principled, each of which is important to ethical decisionmaking.
 An Example of TT's Case Comparison Method We now illustrate TT's case comparison method by tracing an example output of the program.
 W e guide the reader through the four phases, focusing on the underlined portion of the comparison text of Figure 1.
 TRUTHTELLER is comparing the following cases: CASE 1: Victor is a young lawyer nmning his own business.
 A client requires a complex legal transaction that Victor has never done before.
 Should Victor tell the client about his inexperience in this matter? C A S E 2: Terry coaches a little league team.
 Halfway through the season Terry discovers that the star player, Sammie, is three months over age.
 Should Terry ignore this information? TRUTHTELLER'S analysis: Victor and Terry are faced with similar dilemmas.
 They abstractly share reasons to both tell the truth and not tell the mith.
 The episodes abstractly share one reason to tell the truth.
 Victor and Terry share the general reason to provide fairness.
 Victor has the reason to provide sales information so that a consumer can make an informed decision for Victor's client and to disclose professional inexperience for Victor's client, while Terry has the reason to enforce rules of a game that have been violated by Sammie for the players on other teams.
 The two cases also abstractly share a reason to not tell the truth.
 Victor and Terry share the general reason to produce benefit.
 Victor has the reason to enhance professional status and opportunities and to reaUze a fmancial gain for himself, while Terry has the reason to attain a competitive advantage for Sammie's teammates, Sammie and himself However, these quandaries are distinguishable.
 Arguments can be made for both Victor and Terry having a stronger basis for telling the truth.
 On the one hand, one could argue that telling the truth is better supported in Victor's case.
 The reason 'to provide fairness', a shared reason for telling the truth, is stronger in Victor's case, because it involves a higher level of tmst and duty between VJQtor and Victor's ffljent, On the other hand, one could also argue that Terry has a more compelling case to tell the truth.
 First.
 Terrv mav tell the truth to provide an example of honesty for children for the players on othgr teams.
 Sammie's teammates and Sammie.
 Additionally, the shared reason for not telling the &uth 'to produce benefit' is weaker in Terry's case, because the competitive advantage to Terry and the team is probably small.
 Third.
 Terrv's motivations for tellmg the truth appear to be fiiUy principled (i.
e.
 'Qne should make a special effort to be truthfill when a child may be influenced towards honesty.
'.
 'The rules of a game should be followed.
').
 However.
 Victor's motivations are not all principled (e.
g.
 Victor has the unprincipled reason 'to establish goodwill for future benefit').
 Finally, Teny appears to have purely altruistic reasons for telling the truth, thus strengthening his case to tell the truth.
 On the other hand, Victor has selfish motivation to tell the truth.
 Victor may tell the tmth to establish goodwill for fiimre benefit.
 Figure 1: TT's Output Comparing Victor's and Terry's Cases The program starts by accepting semantic representations of each of the cases.
 Figure 2 depicts the semantic representations of the Victor and Terry cases.
 In Terry's case Terry is the truth teller, since it is he who is confronted with the decision to tell the truth or not.
 The league authority will hear the truth, should Terry decide to divulge it, and thus is the truth receiver.
 Finally, Sammie, Sammie's teammates, and the players on other teams are affected others, since they would be affected in some way by disclosure.
 The semantic representation also contains a set of possible actions that the truth teller could take and reasons supporting or justifying each of the actions.
 One of the possible actions is always to tell the truth and another is some version of not telling the truth, for instance, telling a lie or keeping silent (i.
e.
, not disclosing informa73 HMliulh HMTrulh VKlor.
 Iha ^Victor's Ctoni Ha»PD*«tbl»Action SupporlMtBy ^ TalMh* Truth SupporlMtBy T«rrv •• Allomay Of GoodwillFoc^uluraewiWil Ha»««n«lKl«y: Viclor Victor'fi0»»on2: Unknown  Fulur •Harm Haaeanaliciwy: Vklofi CtenI Victorfi»»BOfi3: Right To0iKk>«jr«0fCon Ml m»rInfo Ha»BanWkiary: Vklor'i Cliant VictorRmm3on4: Right To01»clo»or»0f Prof •• MonalI n*Kp«r ianc* Ha*B«nWiciwy: Vklor'i CImM Victorft9MsonS: FinancirfB«n*fH Ha»6«nWKiary: Viclor VietorRmu»on6: BarwfM ToProf«»MonalStatui H**6«nWki«y: Viclor H m Truth TaHar laUndat^^amaAulhonlyOf HasTnKh Tarry, tha Authofriy Swnmia'* TaamrrMtat HavOpponanl Playar* On Olhar Taams Haa4>o«tiNaAclion TaHlhaTnilh Supporlad^y rarryAaasonl: Oiaplay Honai(y^orChil<ten HaaBanaAciwy: Sammia, Sanvnia't Taamrr Playara On Olhar Taams rarfy/?aa«on2; FairnaMayHutaaOt AGama Haa6anaficiary: Playara On Othar Taama rany/)aaaon3: Compal Hi vaAdvanI aga HasBanaficiary: Tarry, Sammia, Sammia'• Taammalat TmrryRmm»on4: AvotdEmolionriDJaIra** Haaeanaficiiry: Sammia Figure 2: Representation of Victor's C a s e (left) and Terry's C a s e (right) Victor's Case Terry's Case VlctofRaaaonl: Goo(twt(tForFiri uraBanai It Ha*Banaltclary: Victor ReasonDistinctionForCa9e2 TarryRaa aon 1: DIapta yHoTMal yForChlldr«n Haaeanaflctarv: Sarrarta, Sammia'a Taammala: VictorHaaaon3: UnlmownFulura^la rm HaaBanaitclary: Victora CtlanI \R£astmInCase2Only TeUlheTnith Playara On Othar Taai VlctorHaaaon3: RightToDlac(oauraOfConaumarlnlo Haa6ar>afictary: VIctor'a Cliant ̂  \Funx/PhncipleiiActionlnCase2'Onl\/ ̂  AbstractReason* Match (Fairness) V)ctornaa»on4; RIghlToDlacloauraOIProf aaator>atlrMX partartca V^HaaBarwfielary: VJctofa giant TarryRaa aon2: FalmaaaByHulaaOtAGama HaaBanaflctary: Playara On Olhar Taama '' I R£asonlnCaseiIsStTonger ll HighDuti/Expectation HighTrustLxpectation Principled AuerageCri ticalitî  Altruistic — — Allgnmcnl fUUa QuillHotlon I l| M.
r.
h.
lkdtorCM.
 1 I ^ MM.
h.
lkdforC«.
 3 ArtrageDutyExpeLtatiim Arrtra^TrustExpectation PrincipUd AverageCriticttUty Altruistic * Reiion linked lo (1.
 .
 supported by) « prindpic Figure 3: A Portion of the Victor and Terry Comparison after Alignment, Qualification, and MarshaUng tion).
 In both Victor's and Terry's case, the choice is between telling the truth and remaining silent.
 Other episodes in TT's case base involve outright lying.
 There is also the possibility that an alternative action could be taken, although not so in Victor's or Terry's case.
 For instance, in some cases the truth teller m a y have the option to approach an affected other before either telling the truth or lying to the truth receiver' In our knowledge representation actions are supported by reasons; a reason is treated as a rationale for taking an action.
 For example, a rationale for Victor^s telling the truth is to protect his client's right of disclosure.
 O n the other hand, a rationale for Victor's silence is the possibility of financial gain.
 Notice that rationales do not need to be selfless or principled; in fact, one of the goals of this work is to imbue the program with the capability of distinguishing between ' Consider the following case.
 "Rick's father is having an affair.
 Rick's mother is unaware of it.
 Should Rick tell his mother?" Before Rick "blows the whistle" on his father, he could discuss the issue with him.
 selfless and selfish reasons and between principled and unprincipled reasons for action.
 The program first performs the Alignment phase.
 The dashed lines in Figure 3 depict alignments between the Victor and Teiry representations.
 At the top of the diagram, Terry's reason 'display honesty for children' is determined to have no counterpart in the Victor representation (i.
e.
, it is a clear distinction); thus it is "misaligned" and labelled as a reason distinction.
 Moving downward, the 'tell the truth' actions of each case are aligned with one another, since they represent the same action.
 Finally, at the bottom of the diagram, Victor and Terry have reasons that abstractly match and are thus aligned with one another (i.
e.
, Victor has two right of disclosure reasons, while Terry has the reason to uphold the rules of a game).
 These reasons match in the reason hierarchy at the level of * fairness.
' The program next commences the Qualification phase.
 The italicized text in Figure 3 represents the qualifications that are applied to the comparison.
 The first step is to qualify the individual objects to 74 reflect the strength of reasons (or actions) relative to a case itself, irrespective of its comparison to the other case.
 For instance, the reason "right to disclosure of professional inexperience' is tagged (1) as having high duty and trust expectations, since it involves a relationship between a professional advisor and a client, (2) as being principled, because an ethical principle supports the reason (Notice the '*' in the upper right region of the reason.
 This connotes a principle link.
 The particular principle in this case is 'In a situation in which a professional is being depended upon, information regarding the inexperience of that professional should be disclosed.
'), (3) as having average criticality, since no comment was made in the stoiy about critical consequences, and (4) as being altruistic, since the reason is to the benefit of Victor's client and not to Victor himself The corresponding reason in Terry's case (i.
e.
, 'fairness by rules of a game') is tagged likewise, with the exception that its trust and duty levels are labelled as average, since the relationship between Terry and the players on the other teams is not one that would typically involve a high level of trust or duty.
 The second step of Qualification is to qualify alignments to reflect relative differences between reasons (or actions) across the cases.
 In Figure 3 there are three alignment qualifications.
 The first one is the reason distinction misalignment which is tagged as being a reason found only in case 2.
 Second, the alignment between Victor's 'tell the truth' action and Terry's 'tell the truth' action is tagged as being fully principled, and thus stronger, on Terry's side, since both of Terry's reasons for telling the truth have associated ethical principles, while one of Victor's rationales, the 'goodwill for fiiture benefit' reason, is unprincipled (Notice there is no "*" associated with this reason in Figure 3).
 Finally, the abstract reason match at the bottom of Figure 3 is tagged as stronger for Victor.
 This is so because of the high trust and duty involved with Victor's 'right to disclosure' reasons as opposed to the average trust and duty involved with Terry's 'fairness by rules of a game' reason^ Next, the program begins the Marshaling phase.
 Its first marshaling task is to assign the case comparison to one of five possible comparison contexts.
 The five comparison contexts are defined as follows: \.
ComparableDilemmas/ReasonSimilarity, if the cases present similar dilemmas, i.
e.
, the reasons supporting both telling the truth and not telling the truth are similar either tn an identical or abstract way, 2.
 ComparableDilemmas/CriticalitySimilanty, if the cases are similar due to the critical nature of possible consequences, 3.
 ComparableReasons, if the cases share a similar reason or reasons for either telhng the truth or not telling the truth but not for both possible actions, 4.
 IncomparableDilemmas/ReasonDifference, if the cases do not have any reasons supporting like actions that are similar, and 5.
 IncomparableDilemmas/CriticalityDifference, if the cases are incomparable due to a difference in the criticality of the possible consequences.
 The Victor/Terry comparison is classified as an instance of the ComparableDilemmas/ReasonSimilarity comparison context, since it has abstract reasons to both tell the truth and not tell the truth.
 After classifying the comparison, the program marshals information that is appropriate to the classified context.
 There are two general categories of information that are marshaled, the comparison focus (i.
e.
, information that is to be the initial focus of comparison and is ' A Reason X is said to be stronger than a Reason Y iff Reason X has a higher criticality than Reason Y O R Reason X has at least one qualifier (i.
e.
 trust, duty, altruism, principled) that is stronger than Reason Y's A N D Reason X has no quahfier that is weaker than Reason Y's.
 typically the most important information to draw attention to) and the distinguishing information (i.
e.
, information that contrasts to the comparison focus).
 For instance, for die ComparableDilemmas/ ReasonSimilarity comparison context the program marshals the similar reasons and relations as the comparison focus and then, to distinguish the cases, marshals the information that supports arguing the relative merits of telling the truth in the two cases.
 N o w let us return to Figure 3 to explain h o w the data in the figure is marshaled.
 Marshaled information is enclosed in a box with a number 1 or 2, corresponding to whether the information was marshaled in support of an argument for case I (Victor's case) or case 2 (Terry's case).
 Only the marshaled distinguishing information is depicted in the diagram.
 It is interesting to note, however, that the abstract reason match in Figure 3 is actually marshaled as part of both the comparison focus and the distinguishing information.
 This is so because the reason match is a similarity, but qualification has also revealed it as giving rise to a distinction at a more detailed level.
 Note that the qualifier ReasonInCase1IsStronger strengthens the case for Victor telling the truth, relative to Terry.
 This marshaled data corresponds to the underiined text in paragraph four of Figure 1 (the sentence beginning "The reason 'to provide fairness'.
.
.
"), the paragraph that argues Victor's truthtelling strengths.
 The remaining marshaled information in Figure 3 supports the argument that Terry has a more compelling case to tell the truth.
 Terry's reason to 'display honesty for children' is marshaled as a strength of Terry's case relative to Victor's, because it is a misaligned reason distinction (i.
e.
, it provides a justification for Terry to tell the truth that is unshared by Victor).
 This corresponds to the underiined sentence in Figure 1 beginning "First,.
.
.
" Finally, the program marshals the qualifier, FullyPrincipledActionInCase2Only, fiom the aligned acrions in Figure 3.
 This also supports Terry's case relative to Victor's, since it shows a strength for telling the truth that exists for Terry but not Victor.
 This final marshaled information corresponds to the text beginning "Third,.
.
.
" The final phase of the program, Interpretation, generates the natural language depicted in Figure 1 by traversing subgraphs of an augmented transition network ( A T N ) ( M c K e o w n , 1985).
 Each comparison context is represented by a different subgraph in the A T N .
 A s the program traverses the A T N it generates rhetorical predicates, the basic units of discourse.
 Each rhetorical predicate essentially maps to a sentence in the comparison text.
 TT's sensitivity to comparison context is illustrated by contrasting the output of Figure 1 with the output of Figure 4.
 The comparison text in Figure 4 is an example of the context IncomparableDilemmas/CriticalityDifference.
 In this context, the program first focuses attention on the critical difference between the cases (i.
e.
, the possible consequences), rather than on the similarifies, as was done in the comparison of Figure 1.
 Also, there is no reason to argue the relative merits of telling the truth in this particular comparison, as was done in Figure 1, since the cases are not comparable.
 Instead, the program contrasts the two cases by reciting the less critical reasons associated with Victor's case.
 T R U T H  T E L L E R is comparing the following cases: C A S E 1: Victor is a young lawyer running his own business.
 A client requires a complex legal transaction that Victor has never done before.
 Should Victor tell the client about his inexperience in this matter? C A S E 2: Josh encounters a man w h o m he recognizes from the newspaper as a murdereratlarge.
 The paper stated that the murderer had killed two of his three exwives.
 Josh's neighbor, Judy, is the final exwife of the murderer.
 The man asks Josh where Judy lives.
 75 Should Josh tell the murderer where Judy lives? TRUTHTELLER'S analysis: The possible consequences of the quandaries faced by Victor and Josh are qualitatively different.
 The consequences of Josh's decision are life critical.
 Thus, the dilemmas are difficult to compare.
 Josh has the reason to not tell the truth because Judy's life is in peril.
 In addition.
 Josh has the reason to not tell the truth because Judy's family would be quite distressed if the murder occurs.
 Victor's reasons for both telling and not telling the U'uth are far less critical than Josh's reasons.
 On the one hand, Victor may tell the truth to provide sales information so that a consumer can make an informed decision.
 In addition, Victor may tell the truth to disclose professional inexperience for Victors client.
 Third, Victor may tell the truth to establish goodwill for future benefit for himself Finally, Victor has the reason to tell the truth to avoid an unknown future harm for Victors client.
 On the other hand, Victor has the reason to not tell the truth to enhance professional status and opportunities for himself.
 Additionally, Victor may not tell the truth to realize a financial gain for himself.
 Figure 4: TT's Output Coitiparing Victor's and Josh's Cases To summarize, the extended example shows how TRUTHT E L L E R generates context sensitive case comparisons using alignment, qualification, and marshaling.
 It "reasons about reasons" by aligning cases according to similarities and differences, and qualifying cases in various ways including tagging reasons as altruistic, principled, cntical, high trust, high duty, etc.
 and tagging alignments with relative strengths.
 The comparison context dictates the strategy the program employs to marshal the relevant similarities and differences.
 Fmally, the interpretation phase uses the marshaled information to generate a comparison text.
 The Evaluation Our goal was to obtain some assurance that T T generated case comparisons that expert ethicists would regard as appropriate.
 Our experimental desip for this formative evaluation was to poll the opinions of five expert ethicists as to the reasonableness, completeness, and context sensitivity of a relatively large sampling of TT's case comparisons.
 W e divided the evaluation into two parts.
 The first experiment presented the experts with twenty comparison texts T T generated for pairs of cases randomly selected.
 W e also added two comparison texts generated by humans (a medical ethics graduate student and a law school professor).
 The evaluators were informed that some texts were generated by humans and some were generated by a computer program; however, they were not told specifically which or how many comparisons were by humans and which were done by the program.
 The second experiment presented the experts with five comparison texts in which T T compared the same case to five different cases.
 For each experiment, the evaluators were instructed: "In performing the grading, w e would like you to evaluate the comparisons as you would evaluate short answers written by college undergraduates.
 .
.
.
 Please focus on the substance of the comparisons and ignore grammatical mistakes, awkward constructions, or poor word choices (unless, of course, they have a substantial negative effect on substance.
)" W e also instructed the experts to critique each of the comparison texts.
 In the first experiment, w e instructed the experts to assign three grades to each of the twentytwo comparison texts, a separate grade for reasonableness, completeness, and context sensitivity.
 The scale for each grading dimension was I to 10, to be interpreted by the evaluators as follows: for reasonableness, 10 = very reasonable, sophisticated; 1  totally unreasonable, wrongheaded; for completeness, 10 ̂  comprehensive and deep; 1 ̂  totally inadequate and shallow; for context sensitivity, 10 = very sensitive to context, perceptive; 1 = very insensitive to context.
 The results of the first experiment were as follows.
 The mean scores across the five experts for the twenty T T compansons were R = 6,3, C = 6.
2, and C S = 6.
1.
 Figure 5 shows the maximum, minim u m and mean scores per comparison for all three of the dimensions.
 By way of comparison, the mean scores of the two humangenerated comparisons were R ^ 8.
2, C ' 7.
7 and C S ^ 7.
8.
 Not surprisingly, one of the human comparisons, number 16, attained the highest mean on all three dimensions (R = 9; C  8.
8; C S  8.
8).
 T w o of the program generated comparisons (numbers 2 and 14), however, were graded higher on all three dimensions than the remaining human comparison (number 22).
 In the second part of the evaluation, w e wanted to focus on the program's sensitivity to context.
 To achieve this, w e asked the experts to grade five additional T R U T H  T E L L E R comparisons.
 These comparisons all involved one case  the Victor case  repeatedly compared to a different second case (i.
e.
, a onetomany comparison).
 The T T comparisons discussed in this paper (i.
e.
.
 Figures 1 and 4) were included in the second part of the experiment.
 For this part of the evaluation, the experts were asked to grade all five comparisons as a set, assigning three scores, one for each of the three dimensions (i.
e.
, reasonableness, completeness, and context sensitivity).
 The results of the second part of the evaluation were as follows.
 The mean across the five experts was R = 6.
7; C  6.
9; C S = 7.
0.
 Notice that the program fared better on the context sensitivity dimension than on the other two dimensions.
 This contrasts to the first part of the experiment in which the mean C S score was the lowest of the three dimensions.
 Also, notice that the scores of all three dimensions were improved slightly over the first experiment.
 Discussion and Conclusions Our results should be viewed in light of our goals and the experimental design in this formative evaluation.
 W e solicited expert opinions about the adequacy of T R U T H  T E L L E R 's comparison texts in order to assess whether our knowledge representation and reasoning techniques were appropriate to the domain task and to obtain cntiques identifying areas for improvement.
 Our primary intention was to determine if TT's comparisons were at least "within range" of that of humans and to determine the ways in which our model could be improved.
 W e interpret the results as indicating that T R U T H  T E L L E R is somewhat successful at comparing truth telling dilemmas.
 W e included the two humangenerated texts as a calibration of the experts' scores; w e are encouraged that some of the program's grades were higher than those assigned to texts written by post graduate humans.
 O n the other hand, our experiment does not involve an adequately sized sampling of human comparisons nor did w e present the experts with outputs in which T R U T H  T E L L E R and humans generated comparison texts for the same pairs of cases.
 Quite simply, we felt it was premature to adopt this kind of experimental design for a formative evaluation.
 The second part of the experiment attempts to address whether T R U T H  T E L L E R is competent at marshaling comparisons in a context sensitive manner.
 W e believe that the higher scores in the second part of the experiment arc due, at least in part, to a keener appreciation of the program's task; that is, it was easier for the evaluators 76 '̂"" I y '̂'", ̂/'' "'•'• •̂  .
 .
 4 Hums u ^ H ••.
V' —t 1—t 1—t— 1 2 3 4 5 6 7 B 6 10 1 1 1 2 13 14 1b 16 1/ 18 19 20 21 2? |"'"~""Mean Across Evalualois I Comp«rl«oni 'A'As,^K.
.
/ 1 2 3 4 5 6 7 8 9 10 I I 12 13 14 15 16 17 18 19 20 21 22 \'"^^"\tem Agoss Evatualofs] Comparitont Hum.
n1 Human2 1 2 3 4 5 6 7 8 9 10 11 I 2 13 14 15 16 17 18 19 20 21 22 |.
w.
ww»orMĝn Actoss Evalualors] Comparitont Figure 5: Max, Min, and Mean Values for R (top), C (middle), and C S (bottom) Scores m Experiment #1 to recognize TT's sensitivity to context in the onetomany experiment.
 W e have shown a flavor of this by providing and discussing two of the five comparisons (i.
e.
, Figures 1 and 4) from the onetomany the experiment.
 Figures 1 and 4 illustrate two points on the range of comparisons that the program can draw upon in comparing the same case to other cases.
 W e also mvited the evaluators to critique the texts.
 The evaluators were in general agreement about some points (i.
e.
, some comments appeared multiple times, across multiple evaluators).
 For instance, several evaluators questioned TRUTHTELLER's lack of hypothetical analysis (i.
e.
, the program makes immutable assumptions, eschewing "what if analysis.
).
 Addressing this would require a program imbued with a more elaborate representation of reasons, actions, and actors.
 W e are considering modifying cases to consider "factors" in a heuristic manner, similar to that done in (Ashley, 1990).
 The evaluators also had the tendency to question abstract reason matches.
 For instance, one evaluator questioned the program making an abstract connection "producing benefit' between the reasons 'to enhance professional status' and 'to realize a financial gain.
' This points, perhaps, to disagreement about the structure of the reason hierarchy (e.
g.
, Is there a more specific connection between these reasons, such as 'Gaining selfish job benefits'?).
 It may also be that, when reflecting on ethical dilemmas, humans typically think in terms of exact matches of reasons or principles.
 W e need to determine under what circumstances, if any, an abstract match is interesting or important.
 It is clear that our representation and comparative analysis could benefit from consideration of the evaluators' critiques, such as those above, and we plan to carefiilly review these before developing the next iteration of the program.
 In conclusion, the evaluation confirmed that T R U T H  T E L L E R makes mostly reasonable comparisons (although not as good as humans), can make comparisons over a range of cases, and is sensitive to comparison context.
 Further, w e believe that the evaluation has shown that TT's AI / C B R knowledge representation and marshaling process provides a solid foundation for the development of a comparative evaluation model in the truth telling domain.
 W e intend to work on developing a C E M like those proposed by Sfrong and Jonsen/Toultnin.
 Acknowledgements This work is supported by the Andrew W.
 Mellon Foundation.
 W e are grateful to Dr.
 Reidar K.
 Lie, Dr.
 James L.
 Nelson, Dr.
 Carson Strong, Dr.
 Matt Keefer, and Mr.
 Ross Parham for participating in our formative evaluation.
 References Ashley, K.
 D.
 (1990).
 Modeling Legal Argument: Reasoning with Cases and Hypotheticals.
 M I T Press, Cambridge.
 Based on doctoral dissertation, University of Massachusetts, 1987.
 Ashley, K.
 D.
 and McLaren, B.
 M.
 (1994).
 A C B R Knowledge Representation for Practical Ethics.
 In the Second European Workshop on CaseBased Reasoning.
 Chantilly, France.
 To be Published in M.
 Keane, editor.
 Lecture Notes in Artificial Intelligence, Springer Verlag: Beriin.
 Bareiss, E.
 R.
 (1989).
 ExemplarBased Knowledge Acquisition A Unified Approach to Concept Representation, Classification, and Learning.
 Academic Press, San Diego, C A , 1989.
 Based on doctoral dissertation, University of Texas.
 Bok, S.
 (1989).
 Lying: Moral Choice in Public and Private Life.
 Random House, Inc.
 Vintage Books, N e w York.
 Edelson, D.
C.
 (1992).
 W h e n Should A Cheetah Remind You of a Bat? Reminding in CaseBased Teaching.
 In the Proceedings of AAAI92, (pp.
 667672).
 San Jose, C A .
 Gilligan,C.
(1982).
 In A Different Voice.
 Harvard University Press.
 Golding, A.
 R.
 and Rosenbloom, P S.
 (1991).
 Improving RuleBased Systems through CaseBased Reasoning.
 In the Proceedings ofAAAI9L Johnston, D.
 K.
 (1988).
 Adolescents' Solutions to Dilemmas in Fables: T w o Moral Orientations — T w o Problem Solving Strategies.
 In Gilligan C.
 et al (Eds.
), Mapping the Moral Domain (pp.
 4972).
 Cambridge, M A : Harvard University Press.
 Jonsen A.
 R.
 and Toulmin S.
 (1988).
 The Abuse of Casuistry: A History of Moral Reasoning.
 University of C A Press, Berkeley.
 MacGregor, R.
 (1990) The Evolving Technology of ClassificationBased Knowledge Representation Systems.
 In John F.
 Sowa, editor.
 Principles of Semantic Networks: Explorations in the Representation of Knowledge.
 Chapter 13.
 Morgan Kaufrnann Publishers, Inc.
, San Mateo, CA.
 McKeown, K.
 R.
 (1985).
 Discourse Strategies for Generating NaturalLanguage Text.
 In Artificial Intelligence 27, 141.
 Elsevier Science Publishers B.
 V.
 (NorthHolland).
 Rissland, E.
 L.
 and Skalak, D.
 B.
 (1991).
 C A B A R E T : Rule Interpretation in a Hybrid Architecture.
 In the Journal of ManMachine Studies.
 34, 839887.
 Rissland, E.
 L.
, Skalak, D.
 B.
, and Fnedman, M .
 T.
 (1993).
 BankXX: A Program to Generate Argument through CaseBased Search.
 In Fourth International Conference on Artificial Intelligence and Law, Vrie University, Amsterdam.
 Strong, C.
 (1988).
 Justification in Ethics.
 In Baruch A.
 Brody, editor, Moral Theory and MoralJudgments in Medical Ethics, (pp.
 193211).
 Kluwer Academic Publishers, Dordrecht.
 77 http://Hum.
n1Opportunistic Reasoning: A Design Perspective Marin D.
 Simina College of Computing Georgia Institute of Technology Atlanta, G A 303320280 m a r i n i c c .
 g a t e c h .
 e d u Janet L.
 K o l o d n e r College of Computing Georgia Institute of Technology Atlanta, G A 303320280 j l k @ c c .
 g a t e c h .
 e d u Abstract An essential component of opportunistic behavior is opportunity recognition, the recognition of those conditions that facilitate the pursuit of some suspended goal.
 Opportunity recognition is a special case of situation assessment, the process of sizing up a novel situation.
 The ability to recognize opportunities for reinstating suspended problem contexts (one way in which goals manifest themselves in design) is crucial to creative design.
 In order to deal with real world opportunity recognition, we attribute limited inferential power to relevant suspended goals.
 W e propose that goals suspended in the working memory monitor the internal (hidden) representations of the currently recognized objects.
 A suspended goal is satisfied when the current internal representation and a suspended goal "match".
 W e propose a computational model for working memory and we compare it with other relevant theories of opportunistic planning.
 This working memory model is implemented as part of our IMPROVISER system.
 Introduction During a mechanical engineering project a group of students were asked to design and implement a mechanical device for the quick and safe transportation of a fragile cargo (some eggs).
 The students went to a H o m e Depot (a hardware store), where they started by choosing springs for the launching component.
 During the design process they made the following observations: Andy: .
.
.
 hey, when I compress the spring it bends; this weakens the force of the springs .
.
.
 Mary (wrapping her hand around the spring): .
.
.
 yes, we have to enclose it in a tube .
.
.
 Bill: .
.
.
 the tube should be collapsible, otherwise the spring cannot be compressed .
.
.
 The students began proposing mechanisms that fit this description.
 One of them suggested a telescope, but it was rejected by the group because it was expected to be costly and it did not fit in the available budget.
 Another student proposed a collapsible camping tube, which unfortunately has a wrong shape.
 The designers were unable to think of where in the store they might look for a useful collapsible tube, so they moved to another part of their problem.
 They started thinking about load protection.
 Since sponges are a good way to provide cushioning, they decided to go to the store's bathroom section.
 During the search for sponges, one of the students saw a toilet paper holder and exclaimed: Mary: Look! A collapsible tube! The whole group agreed that the toilet paper holder fulfilled the requirements of their previously suspended problem.
 The above example illustrates a rather mundane, but common, experience in doing design.
 The students started by structuring the initial problem (launching, cushioning) and then they tried to elaborate the subcomponents, one at a time.
 W h e n they were stuck with one subproblem, they suspended it, and they approached another related subproblem.
 When they saw the toilet paper holder, however, they recognized that an opportunity to address the suspended subproblem had presented itself in the environment.
 What processes are responsible for recognizing such opportunities? H o w can a cognitive architecture handle this kind of processing? What constraints are there, if any, on the workings of these processes? W e are studying these problems in the context of developing a cognitive model for creative design.
 Our computer program, I M P R O V I S E R (Wills & Kolodner 1994b), was extended in order to help us answer the above questions.
 Our exploration of creative design (Kolodner & Wills 1993a) suggests that the conceptual phase, in which the problem is framed, plays a key role in designing.
 In this phase, which is interspersed throughout the design process, the problem situation is assessed and the given problem is reformulated and restructured.
 While one can organize the subgoals involved in conceptual design in a hierarchical structure, the processing of these subgoals seems far more unstructured.
 Designers often begin by proposing a shallow hierarchical set of subgoals as they initially formulate the way they will solve a problem (e.
g.
, the artifact we are designing has these n parts or mechanisms; we need to design each one).
 They continue by addressing each of the subgoals, one at a time.
 It is here where the organized reasoning breaks down.
 When the designer fails to solve one subproblem, he/she seems to suspend it and approach another related subproblem (as in the example above).
 Sometimes the next subproblem is simply a notyetconsidered sibling subgoal (as when the student designers moved from designing their spring launch mechanism to the cushioning for the eggs); sometimes the opportunity to go back to a suspended subgoal is recognized (as when the toilet paper holder was seen).
 W h en we consider the incremental and recursive nature of this reasoning process, we can identify one way of recognizing that a previouslysuspended subgoal might be successfully addressed.
 During consideration of a new subproblem, the designer has to consider interactions with related subproblems, some of which have been suspended previously.
 This may 78 mailto:jlk@cc.
gatech.
eduprovide a fresh view of the suspended problem and a new way to redescribe it.
 Redescription or new insights about a subproblem gained during reasoning trigger the goal scheduler to unblock the suspended subproblem, allowing alreadyknown solutions to be recalled or new means of solving it to be recognized.
 This means of unblocking a suspended goal is completely under the control of the reasoner, which knows which subproblems have been part of its most recent reasoning.
 But recognizing in the toilet paper holder the opportunity to address a suspended goal requires additional mechanisms that scan the environment and recognize when the environment is providing new insights into suspended goals.
 If the number of suspended goals, the complexity of the environment, or the amount of newness in the environment is high, such a mechanism could easily be overwhelmed.
 The mechanisms that provide this capability must be able to deal with such complexity.
 Opportunity Recognition T h e Problem The prerequisite for opportunistic behavior is the existence of suspended goals (problems), goals that cannot be pursued in the current context and are postponed.
 An essential component of opportunistic behavior is opportunity recognition, recognition of those conditions that facilitate the pursuit of some suspended goal.
 But opportunities seem to appear when they are not expected.
 The student designers, for example, had not previously thought about a toilet paper holder functioning as a collapsible tube.
 Recognizing the opportunity meant both noticing the toilet paper holder and recognizing that its mechanism (which is hidden) included a collapsible tube.
 More than a simple matching mechanism is needed.
 Birnbaum (1986) suggests two central problems that must be addressed by a theory of opportunistic behavior: (1) how to detect opportunities and (2) how to "activate" the goals to which they pertain.
 A n important issue here is identifying how much and what kind of processing is required in order to recognize the presence of the features that constitute an opportunity.
 A Critical Review HayesRoth & HayesRoth (1979) proposed the first significant cognitive model of opportunistic behavior.
 Their model of opportunistic planning was inspired by protocols of subjects planning a hypothetical day's errands.
 But they were most concerned with planning methods and gave little attention to recognition processes.
 In fact, the experimenter always mentioned opportunities to the subjects when they overlooked them, and the subjects never tried their plans in the real world, so they never really dealt with genuine opportunities and the problem of recognizing them.
 Birnbaum (1986) gave more attention to recognition issues.
 He proposed the mental notes model, in which whenever a goal cannot be immediately satisfied, it is indexed in terms of the unmet preconditions that prevented its satisfaction.
 However, as he points out, if the goal is indexed too specifically, then there will be many cases in which it will not be recalled even though an opportunity for its satisfaction is present, and if the goal is indexed in terms of more abstract features, we cannot assume that the agent will automatically generate the abstract description that will activate the goal.
 In order to solve the above dilemma within the framework of the mental notes model, Birnbaum suggests' spending some effort, when the goal is formed, to determine the range of situations in which it might easily be satisfied  for example, by constructing several incomplete plans for the goal in order to identify the relevant preconditions  and then indexing the goal in terms of the features that might arise in such situations.
 Birnbaum & Collins (1984) also suggest an active goal framework, where all the goals have the ability to examine the current situation and to initiate inference to test their own relevance.
 Patalano, Seifert and H a m m o n d (1992) criticize the use of active goals proposed by Birnbaum & Collins, claiming that this approach to opportunistic behavior is an unlikely explanation of human cognitive processes because of its computational demands.
 However, Patalano, Seifert and H a m m o n d do pick up on Birnbaum's indexing scheme, calling it predictive encoding.
 Predictive encoding stresses the importance of encoding blocked goals in memory in such a way that they will be recalled by conditions favorable for their solutions.
 Their experimental results show evidence of this process.
 However, the predictive encoding hypothesis seems incomplete, because it does not enable a cognitive agent to recognize opportunities other than those which it is able to anticipate.
 In particular, it does not enable an agent to recognize novel opportunities, which by their very nature, cannot be easily anticipated.
 Recognition of the toilet paper holder as a collapsible tube, for example, is novel in that this is not the way a toilet paper holder is generally thought of.
 Similar issues caused Birnbaum & Collins (1984) to conclude that if an opportunity is to be detected at all, inferential resources must be allocated to the goal recognition task.
 R a m & Hunter (1992) suggested a balance between backward chaining at the time of goal suspension and forward chaining at the time of opportunity recognition.
 In A Q U A , a set of utility metrics have been proposed in order to make a tradeoff between predictive encoding and active goals.
 Unfortunately, these utility metrics are very specific to story understanding.
 This suggests that we need active goals in order to recognize novel opportunities, but we need to control their power and number to make them computationally feasible.
 W e need predictive encoding, but w e also need more powerful inferential capabilities.
 W e hope that an analysis of the example presented previously can provide insight in formulating a mechanism with these properties.
 A Possible Solution W h y did the students fail to remember the toilet paper holder when they were trying to decide where they might find a collapsible tube, and what allowed them to recognize it as appropriate when they saw it? One possible reason why the toilet paper holder was not recalled and considered while thinking about collapsible tubes is that the probe that had been constructed (i.
e.
, the item description used for remembering) was incompletely specified.
 Consequently, they retrieved items that fulfilled primary but 'Birnbaum credits Dehn (1989) with this idea.
 79 not secondary characteristics of the probe (e.
g.
, a telescope costs too much and a camping cup has a wrong shape).
 After every retrieval and evaluation of a new device, the probe was respecified, taking into consideration the initially ignored constraints (e.
g.
, w e want something like a telescope, but cheaper).
 This process was suspended, however, before the toilet paper holder was recalled.
 But why was the probe inadequate for retrieving such a c o m m o n object as a toilet paper holder? Our explanation is that the toilet paper holder is routinely associated with what its purpose is in the bathroom (holding toilet paper rolls) rather than with how this function is achieved (by means of a collapsible tube with a spring inside).
 It is not a particularly interesting device, and even though w e see it every day, most of it is hidden by the roll of paper.
 Research shows that it is quite difficult to overcome such functional fixedness (Mayer 1970), which associates everyday objects with their obvious function (holding a paper roll in the case of the toilet paper holder).
 Routinely, w e ignore other potential uses that can be derived from the structure and behavior of such everyday objects.
 Once w e have specified desired criteria in a probe, it is easy to check them against a specific object.
 But if those criteria are different than those used to describe an object in memory, recall won't happen.
 Case Index: Perceivable Properties: Probe Description: Case Content: C2 Functional Properties: Use Hold Paper Roll I I I I I I .
1 L.
 RigidTube: Shape = Cylindrical LengthVariabiliiy = varies RadiusVariability = constant Structural Properties: Pans.
 Cylinders CI and C2; Spnng S FitsInside(Cl,C2) CI: Solidity(Hollow) C2: Solidity(Hollow) Composition of Cylinders (C1C2) Solidity(Hollow) Length = Length(S) + delta Shape = Cylindrical Enclosed(S, C1C2) Behavioral Properties: States: Steady.
 Squeezed.
 Rest Steady: Length(S) < RestLength(S) Ungth(ClC2) = Width(WallFixture) Squeezed: L.
ength(ClC2) < Width(WallFixture) LengihCC/C2j < LengthfC2j Rest: Length(ClC2j > Width(WallFixture) Length! S) = RestLength(S) Figure 1: The many representations of a toilet paper holder Figure 1 shows this mismatch.
 The collapsible tube, as described after manipulating the springs (see the Probe DESCRIPTION in Figure 1), has the structural property that its shape is cylindrical and the behavioral property that its length can vary.
 The toilet paper holder, on the other hand, is indexed in memory by a combination of its Functional Properties and Perceivable Properties, shown as INDEX in Figure 1.
 Thus, w e cannot retrieve the Case Content, namely the Structural Properties and Behavioral Properties of the toilet paper holder by using the Probe Description.
 What facilitates recognition of the opportunity in the environment, i.
e.
, recognition that the toilet paper holder can fulfill the role of collapsible tube? O n the store's shelf, one can see the shape of the device.
 Recognition procedures perceive that it is a collapsible tube, which matches the description from the retrieval probe and presumably the label that designates what needs to be encountered to unblock the suspended goal.
 But what processes direct recognition procedures to attend to the toilet paper holder on the store's shelf? And what mechanisms allow matching of something in the environment to a goal that is no longer active? W e know that memory search is incremental and that when our memories can't retrieve what w e are asking them for, w e redescribe what we are looking for and try again.
 But when w e aren't making headway, w e postpone additional retrieval until more information is gathered and pursue other retrieval strategies or subgoals (Williams & Hollan, 1981, Norman & Bobrow, 1979, Kolodner, 1984).
 Similarly (and implied by predictive encoding), w e suspend reasoning subgoals and subproblems that depend on postponed retrieval strategies and unmatched probes, marking them with criteria that, if encountered, predict that they should be reopened (Patalano, Seifert and H a m m o n d 1992).
 W e propose that when an active subgoal (subproblem) is suspended, the subgoal and its criteria remain in working memory's working store for some limited time.
 W e further propose that goals suspended in the working memory continuously monitor the environment, looking for matches in the environment to the specified criteria.
 Furthermore, we suggest that there are only a small number of these active goals.
 A computational model will provide more detail on these limitations.
 A Memory Model The Memory Architecture The major component of our computational model (presented in Figure 2) is a working memory ( W M ) , which communicates with both longtime memory (LTM) and perceptual processes and keeps track of recent reasoning context.
 As Barsalou (1992) suggests, the working memory mediates between shortterm memory ( S T M ) and the activated part of L T M .
 But w e add significantly to Barsalou's conception.
 First, w e give the W M a structure.
 Second, the structure integrates components of S T M with activated portions of L T M and with perceptual mechanisms and stores.
 Third, this integrated component acts as a buffer for L T M .
 It is the place where LTM's components are manipulated and adapted.
 Fourth, we add a control unit (matcher), which can match (1) the current artifact being reasoning about or (2) all the suspended problems against the L T M representation of the current item presented to the Recognizer 80 yes no Working Memory LTM Focal Store thisproblemdx thisSBFspec thissketchyspi'c Matcher yes/no Working Store L Solved Problems SBFspec problemctx D Suspended Problems sketchyspec problemctx • background cues L J problem[^ r ^ rtvc I—I I—I ctxs slinky campingcup irrigationtube textiletubbing TPH .
 Z V allproblemctxs yes 2 Control Visual Recognizer |r Figure 2: The M e m o r y Architecture The working memory that emerges has three parts: (1) Focal Store (FS), ( 2 ) W M Control unit (the only part of the control unit currently relevant is the Matcher), and (3) Working Store (WS).
 The Focal Store (FS) holds three items: (1) the current goal of the reasoner (thisPROBLEMCONTEXT), (2) the current object, artifact or idea being reasoned about (thisSKETCHYSPEC, which is similar to the PROBE DESCRIPTION in Figure 1), and (3) the representation of the current item presented to the Recognizer, module (THISSBFSPEC), which is retrieved from L T M according to the specification generated by the Recognizer.
 The working store is more interesting and has four parts.
 1.
 A connected graph of related unsolved subproblems, represented as subgoals and the contexts in which they are applicable, called problem contexts (represented as small rectangles in the figure).
 This graph might be a subset of a problem decomposition stored in L T M when the problem was previously considered, it may have been created during the reasoning session, or it may be a combination of the two.
 The goal of the reasoning session is to find a solution for the whole group of related problems.
 2.
 Background cues, which provide a history of concepts, descriptions, features, and objects that have been considered during reasoning 3.
 A list of Suspended Problems, each represented by a problem context that includes the relevant subgoal, the context in which it is being considered, and the stillincomplete solution description (SKETCHYSPECS).
 More specifically.
 the representation of suspended subproblems is modeled after the content of problem contexts in design.
 A problem context in design, and a suspended subproblem in working memory, includes (1) a set of goals and partially ordered constraints that solutions should satisfy; (2) a set of options, or alternatives for achieving those goals^ ; and (3) a set of relationships describing h o w the options satisfy the constraints.
 These sets are incomplete and contain as much as has been considered so far in addressing the goals.
 4.
 A list of Solved Problems, consisting of problem contexts for which solutions (SBFSPECs) have been found.
 These problem contexts have the same structure as do suspended subproblems, but their solution descriptions are complete.
 This working memory structure, in effect, keeps track of the part of L T M activated during a reasoning session.
 At most, then, the retention time of working memory is a few hours, requiring only a limited capacity (more work is needed before speculating on how big).
 The working store accommodates several subproblems (PROBLEMCTXs), which ideally are related, at the same time.
 These subproblems are approached one at a time, and if the current one cannot be solved, it is transferred to the list of Suspended Problems.
 Solved problems are transferred to the Solved Problems queue.
 A suspended problem is characterized by a non elaborated specification (SKETCHYSPEC), which In our example the options set included a telescope, a camping cup and a slinky.
 This initial set of options was gathered by probing the L T M with a set of indexes relevant to the context goals.
 81 ( ^ L T M ^ Task Scheduler Opportunity Recognition problemctxs GoalOriented Scheduler Solved Problems problemctx SBFspee Suspended Problems problemctx sketchyspec Update Mechanisms Figure 3: The Processing Algorithm cannot be used as a successful index in the L T M .
 A problem is considered solved when the Matcher module recognizes that something in the environment or created on the fly fulfills the requirements formulated in a SKETCHYSPEC.
 The whole system is monitored by a global Control module, which is responsible for the flow of problem contexts between working memory, L T M , and the recognizer module, which perceives the world.
 W h e n a reasoning session ends, the control module makes sure that relevant information from the W M updates the structures in L T M .
 The Processing Algorithm Mediation between working memory, longterm memory, and perceptual processes are key to working memory's functioning.
 Four control components (see Figure 3) are important to using working memory well: (1) The task scheduler loads a graph structure (a set of related subproblems) in the Working Store.
 (2) The goaloriented scheduler uses the graph structure and the sets of suspended and pending problems to choose what to do next.
 A m o n g other things, it suspends subproblems when no headway is being made; it reinstates them when their indexes (specs) are matched.
 (3) Opportunity recognition procedures notice opportunities to reinstate suspended goals and send messages to that effect to the scheduler.
 This is accomplished by having perceptual functions (the object recognizer is the only one of these in the scheme presented) focus their attention based on the sketchy specs recorded in suspended subproblems.
 For example, the object recognizer seeks to identify objects whose descriptions partially match the sketchy specs associated with suspended subproblems.
 W h e n such an object is seen, the recognizer asks inference procedures if they can quickly determine if the object has other properties specified in the sketchy spec.
 If so, the opportunistic component notifies the goal scheduler that a suspended goal ought to be reinstated.
 (4) Update mechanisms update the structures in L T M based on recordings in WM.
 W h e n a new problem is approached, a hierarchical structure is proposed for it.
 Sometimes the structure is already recorded in memory; sometimes it is on paper; sometimes it must be constructed  we don't consider that issue right now.
 As a next step, a small group of related subproblems is brought into focus and loaded into W M .
 It is essential that this group is kept small, because potentially all of its components may become active during reasoning and the computational demand should be limited.
 Exactly how this choice of subproblems is made must still be discovered; one option is to bring in only the most connected set of related subproblems and only up to some small threshold.
 In our example, we assume that the full problem (design of a quick transportation device) has been considered previously and that there are a set of subproblems recorded in memory.
 In the session we focus on, two subproblems are brought to attention and loaded in W M : the launching device problem and the cushioning material problem.
 The graph structure in W M has the full problem at the top and these two subproblems hanging off of it as sibling subproblems.
 One of the subproblems is chosen for focus, and it is loaded into the Focal Store as the current problem (thisproblemCTX).
 Here, the launching device problem is chosen first.
 Reasoning procedures work on this problem until it is solved, in which case it is put into the solved problems queue, or until no progress can be easily made, in which case it is added to the queue of suspended problems.
 W h e n the need for a collapsible tube emerged in solving the launching device problem, no useful device was recalled from L T M , nor was one seem immediately on the shelves of the store.
 Thus, this subproblem is suspended.
 The description created of the collapsible tube (the probe in Figure 1) is used as the SKETCHYSPEC for this suspended problem.
 W h e n a subproblem is suspended, a new problem is chosen to work on.
 Here, the cushioning subproblem is selected, and reasoning procedures begin working on it.
 At the same time, perceptual functions are scanning the environment, looking particularly for things that partially match sketchy specs of suspended problems^ In our case, the object recognizer notices the toilet paper holder on the shelf of the În fact, the sketchy specs are related with the visual images of the options considered so far (telescope, camping cup and slinky in our example).
 Priming processes recognize some of these options when the visual recognizer is scanning the environment (sometimes spuriously).
 Indirectly, the associated sketchy specs are remembered.
 82 store.
 The T P H matches the collapsible tube specification because it is cylindrical and a rigid tube.
 This is enough of a partial match to the recorded sketchy spec that it asks inference procedures whether the T P H also has variable length.
 A simple scan of the full representation of a T P H (i.
e.
, the one in L T M that includes behavioral and structural information) supplies a positive answer (we know that a T P H has to be compressed in order to be assembled to provide support).
 When a subproblem becomes unblocked due to new information becoming available, the goal scheduler unblocks the suspended problem and asks reasoning mechanisms to proceed in reasoning about it.
 This is what happens with the launching device problem.
 Status and Open Issues The working memory model discussed here is implemented as part of the IMPROVISER system (Wills & Kolodner 1994a, 1994b).
 Our original intent was to extend IMPROVISER to allow it to handle and maintain multiple pending problem contexts.
 However, we soon realized that handling multiple problem contexts was a memory problem and that the mechanism that would allow that could also be used to explain at least some cases of opportunity recognition.
 W e suspect that this approach will also provide us with ways of explaining forgetting during a long reasoning session and the "freshness" that reasoners feel when coming back to a problem after letting it rest for several hours or days.
 But more exploration is needed before we have good explanation for either of these phenomena.
 Indeed, we don't yet have a full explanation of the constraints on memory in handling multiple contexts and in maintaining control of the active goals involved in opportunistic recognition.
 W e do believe, however, that we have proposed a framework within which these questions can be answered quite nicely.
 W e look forward both to continued computational modeling and continued experimentation on people to answer these questions.
 Acknowledgements This research was was funded in part by N S F Grant No.
 IRI8921256 and in part by O N R Grant No.
 N0001492J1234.
 Special thanks to Linda Wills for helpful discussions about the IMPROVISER system.
 W e thank Ashwin Ram, Hari Narayan, Linda Wills and our anonymous reviewers for their comments on this research.
 References Barsalou, L.
 (1992).
 Cognitive Psychology.
 Lawrence Erlbaum Associates.
 Birnbaum, L.
 (1986).
 Integrated Processing in Planning and Understanding.
 PhD thesis, Yale University.
 Birnbaum, L.
 & Collins, G.
 (1984).
 Opportunistic Planning and Freudian Slips.
 Proceedings of the Sixth Conference of the Cognitive Science Society.
 Lawrence Erlbaum Associates.
 Dehn, N.
 (1989).
 Computer StoryWriting: The role of Reconstructive and Dynamic Memory, PhD thesis, Yale University.
 Grimson, W.
E.
L.
 (1990).
 Object Recognition by Computer: The Role of Geometric Constraints.
 M I T Press.
 Hammond, K.
, Converse, T, Marks, M .
 & Seifert, C M .
 (1993).
 Opportunism and Learning.
 Machine Learning, 10 (pp.
 279309).
 HayesRoth, B.
 & HayesRoth, F.
 (1979).
 A cognitive model of planning.
 Cognitive Science 3 (pp.
 275310).
 Kolodner, J.
 (1984).
 Retrieval and Organizational Strategies in Conceptual Memory: A Computer Model.
 Lawrence Eribaum Associates.
 Kolodner, J.
 (1993).
 CaseBased Reasoning.
 Morgan Kaufmann (pp.
 369382).
 Kolodner, J.
 & Wills, L.
 (1993a).
 Casebased Creative Design.
 AAAI Spring Symposium on Al and Creativity.
 Stanford, CA.
 March 1993.
 Kolodner, J.
 & Wills, L.
 (1993b).
 Paying Attention to the Right Thing: Issues in CaseBased Creative Design.
 AAAI CaseBased Reasoning Workshop (pp.
 1925).
 Mayer, N.
R.
F.
 (1970).
 Problem Solving and Creativity: In individuals and Groups.
 Brooks/Cole Publishing Company, (pp.
 162175).
 Norman, D.
A.
 & Bobrow, D.
G.
 (1979).
 Descriptions: A n intermediate stage in memory retrieval.
 Cognitive Psychology \\ (pp.
 107123).
 Ram, A.
 & Hunter, L.
 (1992).
 The Use of Explicit Goals for Knowledge to Guide Inference and Learning.
 Journal of Applied Intelligence, 2(1) (pp.
4773).
 Patalano, A.
, Seifert, C.
 & Hammond, K.
(1993).
 Predictive Encoding: Planning for Opportunities.
 Proceedings of the Fifteenth Conference of the Cognitive Science Society.
 Lawrence Eribaum Associates (pp.
 800805).
 Smith, S.
M.
 & Blankenship, S.
E.
 (1991).
 Incubation and the persistence of fixation in problem solving.
 American Journal of Psychology, Vol.
104, No.
 1 (pp.
 6187).
 Williams, M .
 & Hollan, J.
 (1981).
 The process of retrieval from very long time memory.
 Cognitive Science 5 (pp.
 87119).
 Wills, L.
, Kolodner, J.
( 1994a).
 Towards More Creative Casebased Design Systems.
 Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI94).
 Seattle, WA.
 Wills, L.
, Kolodner, J.
( 1994b).
 Explaining Serendipitous Recognition in Design.
 Proceedings of the Sixteenth Conference of the Cognitive Science Society.
 Lawrence Eribaum Associates (pp.
 940945).
 83 Combining Rules and Cases to Learn Case Adaptation David B.
 Leake Computer Science Department Indiana University Bloomington, IN 47405 leakeQcs.
Indiana.
edu Abstract Computer models of casebased reasoning (CBR) generally guide case adaptation using a fixed set of adaptation rules.
 A difficult practical problem is how to identify the knowledge required to guide adaptation for particular tasks.
 Likewise, an open issue for C B R as a cognitive model is how case adaptation knowledge is learned.
 W e describe a new approach to acquiring case adaptation knowledge.
 In this approach, adaptation problems are initially solved by reasoning from scratch, using abstract rules about structural transformations and general memory search heuristics.
 Traces of the processing used for successftil rulebased adaptation are stored as cases to enable future adaptation to be done by casebased reasoning.
 When similar adaptation problems are encountered in the future, these adaptation cases provide task and domainspecific guidance for the case adaptation process.
 W e present the tenets of the approach concerning the relationship between memory search and case adaptation, the memory search process, and the storage and reuse of cases representing adaptation episodes.
 These points are discussed in the context of ongoing research on DIAL, a computer model that learns case adaptation knowledge for casebased disaster response planning.
 Introduction The fundamental principle of casebased reasoning (CBR) for problemsolving is that new problems are addressed by retrieving stored records of prior problemsolving episodes and adapting their solutions to fit new situations.
 In most casebased reasoning systems, the case adaptation process is guided by fixed case adaptation rules.
 Practical experience developing C B R systems has shown that it is difficult to establish appropriate case adaptation rules (e.
g.
, Allemang, 1993; Leake, 1994).
 In defining adaptation rules, a key problem is the classic operationality/generality tradeoff that was first observed in research on explanationbased learning (e.
g.
, Segre, 1987): Specific rules are easy to apply and are reliable, but only apply to a narrow range of adaptation problems; abstract rules span a broad range of potential adaptations but are often hard and expensive to apply because they do not provide task and domainspecific guidance.
 In those C B R systems that do perform case adaptation, specific rules are often used, requiring that the developer perform difficult analysis of the task and domain to determine which rules will be needed.
 In practice, the problems of defining adaptation rules are so acute that many C B R applications simply omit case adaptation (e.
g.
, Barletta, 1994).
 This paper presents a new method by which a casebased reasoning system can learn adaptation knowledge from experience.
 The method models a progression from case adaptation using general adaptation rules to case adaptation by a casebased reasoning process that reflects both (1) the specific adaptation problems the reasoner has encountered and (2) the reasoner's idiosyncratic memory organization and domain knowledge.
 The approach is motivated both by pragmatic considerations and cognitive modeling concerns.
 The pragmatic benefits of learning from experience to refine case adaptation knowledge are simplified knowledge acquisition, improved efficiency of adaptation, and improved quality of the results of adaptation.
 The benefits from a cognitive modeling perspective are in providing an account of how human abilities for adapting cases might develop and improve.
 In our approach, two types of general rules are provided as the initial basis for case adaptation: rules describing structural transformations (i.
e.
, characterizing ways to transform case structure, such as adding or substituting particular components of a case), and rules about h o w to search memory for the information needed to apply a transformation (e.
g.
, that can be used to provide general guidance about h o w to search for appropriate items to substitute after a substitution transformation has been selected).
 As adaptation problems are solved successfully using these rules, two types of cases are stored to enable future casebased reasoning about the adaptation process itself.
 Memory search cases encapsulate information about the steps in the memory search process.
 Adaptation cases encapsulate information about the adaptation problem as a whole and h o w it was solved, including both the transformation used and the memory search process followed.
 Storage and reuse of these two types of cases facilitates future case adaptation in two ways.
 First, when a new adaptation problem is similar to a previously solved problem, the previous adaptation case is retrieved and used to suggest a transformation and memory search plan that were effective in the past.
 Second, even when a new adaptation problem is different from previouslysolved problems, prior memory search cases can help to guide the memory search needed for the new problem.
 This approach to case adaptation models h o w casebased reasoning systems can make the transition from adaptation by general rules (which may be unreliable and hard to apply) to adaptation that reflects specific lessons acquired with adaptation experience.
 Experience also facilitates the solution of novel adaptation problems, because the rulebased adaptation process can apply prior memory search cases when solving new adaptation problems.
 W e begin with a brief discussion of the evidence for developmental changes in human case adaptation ability and an 84 outline of the background for our approach.
 W e then identify and discuss key issues in the context of an implementation of this approach to learn to improve case adaptation during casebased reasoning for disaster response planning.
 Perspective Human development of case adaptation: Multiple psychological studies have shown evidence for human casebased reasoning both in the early phases of learning a domain and after achieving expertise (see Kolodner (1993) for an overview of these results).
 However, the development process for knowledge used to guide the application of prior cases has received less study.
 Centner (1988) has shown that as children develop, a shift occurs in how they adapt stories to fit new characters.
 In Centner's experiments, children first acted out stories, using toys to play the roles of the characters, and then were asked to act out the same stories but using different toys representing new characters.
 Although both older children (810 years old) and younger children (57 years old) were influenced by the transparency of the object mappings between toys when they choose which characters to substitute into particular roles of the stories, considerations of structural features helped the older children to make better substitutions.
 Our research models how criteria for deciding which adaptations to favor may be learned from experience.
 Computer models of adaptation learning: Some G B R systems have capabilities for learning specialpurpose case adaptation rules.
 For example, C H E F (Hammond, 1989), a casebased planner, augments a static library of domainindependent plan repair strategies by learning ingredient critics for suggesting adaptations appropriate to particular ingredients.
 The resulting learning is useful, but in a limited context.
 Another approach is to rely on an external source to provide a library of adaptation cases to be reused (Berger, 1995; Sycara, 1988).
 This approach is also useful, but does not address how to generate the cases used.
 Our aim is a general model of how an adaptation system can acquire adaptation cases for reuse as it solves novel adaptation problems.
 Combining Rules and Cases to Learn Adaptation Our approach begins with adaptation based on general rules.
 As novel adaptation problems are solved, the adaptation component stores information about successful adaptation episodes in a library of specific adaptation cases for future use.
' Unlike abstract adaptation rules, adaptation cases encapsulate the system's experience on specific adaptation and memory search problems and reflect the system's specific task, domain, and memory organization.
 W h e n no relevant cases are available, rulebased adaptation is used.
 Thus our method models how a reasoner can shift between rulebased and casebased case adaptation as appropriate to respond to familiar or novel adaptation problems.
 'Useful information could also be obtained by failuredriven learning from failed adaptation attempts.
 That process is a future research direction.
 T h e computer model A project to investigate this adaptation learning method is now being conducted at Indiana University with Andrew Kinley and David Wilson.
 W e are investigating the process in the context of adaptation of response plans for natural and manmade disasters.
 Human disaster managers are trained by studying casebooks of disasters and responses, and it has been observed that they frequently report that their new solutions are based on response plans for similar previous episodes (e.
g.
, Rosenthal et al.
, 1989).
 Our computer model, D I A L (for Disaster response with Introspective Adaptation Learning), starts with a library of disaster response cases.
 As it generates disaster response plans, it learns both new cases and strategies for adapting its cases to fit new situations.
 The entire D I A L system includes a schemabased story understander that processes inputs in a conceptual representation, a response plan retriever/instantiator, a simple evaluator for candidate response plans, and an adaptation component to adapt retrieved plans when problems are found.
 All components except for the adaptation component are based in a straightforward way on previous systems (e.
g.
, the understander is based on previous understanding systems such as S A M (Cullingford, 1978), and the casebased planner is based on previous casebased planners such as C H E F (Hammond, 1989)).
 Consequently, further discussion will focus only on the case adaptation process.
 DIAL'S adaptation process dial's adaptation component receives as input an instantiated disaster response plan and a description of a problem in that plan to repair by case adaptation.
 Its processing combines reasoning from scratch with casebased reasoning, in the following sequence of processing steps: 1.
 Casebased adaptation: D I A L attempts to retrieve cases representing adaptations that have applied to similar adaptation problems in the past.
 If it is successful, the adaptation case is reapplied.
 Otherwise, rulebased adaptation is initiated.
 2.
 Rulebased adaptation: Based on the problem type, the system selects a transformation (e.
g.
, substitution), and generates a knowledge goal (Ram, 1987) for the information needed for the transformation.
 Introspective planning (Hunter, 1990) is done to search for the needed information.
 Search terminates when the information is found or when a preset limit on the allowed number of plan steps is exceeded.
 3.
 Evaluation: The adaptation is evaluated by a human user who inputs to the system whether the adaptation is acceptable.
 If not, other adaptations are tried.
 If no plans succeed with a given resource limit, rulebased adaptation is continued with an increased limit.
 (This gives preference to shorter memory search plans.
) 4.
 Storage: W h e n the results of adaptation are successful, the resulting response plan, the adaptation case, and the m e m ory search plan are stored to be available for future use.
 The following sections describe the rulebased adaptation and casebased adaptation processes.
 This is followed by a description of processing for an implemented program example.
 85 Rulebased adaptation In order to reason about adaptation problems, a uniform framework is needed for characterizing case adaptation.
 DIAL'S rulebased case adaptation process is based on a characterization of the case adaptation process as involving two parts: structural transformations and memory search to find the information needed to apply the transformations.
 In accordance with this view, case adaptation knowledge can be treated as having two parts, abstract transformations and memory search strategies.
 This characterization of adaptation knowledge follows the principle of the adaptation strategies developed by Kass (1994).
 The aim of adaptation strategies is to achieve both operationality and generality by extending traditional adaptation rules to contain domainindependent strategies for searching memory to find the domainspecific information required by particular adaptation problems.
 Kass's adaptation strategies were static; they were handcoded rather than learned.
 However, his basic framework suggests a view of how to learn adaptation knowledge.
 In this view, learning specifics about case adaptation knowledge can be seen as learning the memory search information needed to operationalize general structural transformations (additions, deletions, and substitutions).
 Viewing adaptation learning in this way provides a broadlyapplicable framework for characterizing case adaptations: it is well known that a small set of transformations is sufficient to characterize a wide range of adaptations (Carbonell, 1983; Kolodner, 1993).
 The resulting learning can have a significant effect on adaptation performance, because in general, a large amount of domainspecific reasoning may be required to find the information to apply those transformations.
 The following sections discuss how DIAL'S rulebased adaptation process finds the information needed to apply general transformations when solving novel adaptation problems.
 This process involves selecting a transformation to apply, generating knowledge goals for the information needed to apply the transformation, and using a planning process to guide search through memory for the needed information.
 Selecting transformations and generating related knowledge goals: W h e n D I A L uses rulebased adaptation to process a novel adaptation problem, it first selects a transformation to apply.
 It then performs memory search for the information needed to apply the transformation.
 The current implementation uses a very simple scheme for selecting transformations: candidate transformations for repairing particular types of adaptation problems are indexed directly under elements in the vocabulary that the system uses for describing types of adaptation problems.
 Given a problem description as input, DIAL'S rulebased adaptation process retrieves the transformations associated with the problem description and attempts to apply them.
 W h e n reasoning from scratch, D I A L has no guidance about which to favor; the transformations associated with the problem category are applied in an arbitrary order until a successful adaptation is found.
 However, when an entire successful adaptation case is stored, the combination of a particular transformation and particular memory search strategy that were previously successful will be retrieved and reapplied.
 Consequently, the learning process involves learning about combinations of transformations and memory search strategies that are applicable to particular types of problems.
 The following example illustrates this process of transformation selection.
 Consider a casebased disaster planner that attempts to reapply a response plan for a chemical spill, but finds that one part of the retrieved plan is inapplicable: the retrieved plan used city buses to evacuate victims, but the city faced by the current spill has no bus system.
 The problem of an unavailable filler suggests using a substitution transformation to replace bus transportation by a different alternative.
 Once a transformation has been selected, memory search is needed—in the transportation example, it is necessary to find a form of transportation to substitute.
 This is addressed by first representing the needed information as a knowledge goal, and then reasoning introspectively about possible plans for searching memory to find the needed information.
 Representing knowledge goals: Knowledge goals have previously been investigated largely in context of opportunistically recognizing needed information as it becomes available.
 Representations of knowledge goals developed for this task describe the desired information in a single concept specification (Ram, 1987)—a pattern to be matched against new information, and a description of how the information will be used.
 That type of description is sufficient for its intended purpose of representing questions to be compared to new input information.
 However, work on D I A L suggests that when knowledge goals are used to guide active memory search, descriptions of knowledge goals must include two additional facets as well.
 The first of these is what w e call a comparative specification.
 The comparative specification describes how to choose between multiple items in memory that match the concept specification.
 The comparative specification is needed because, in a rich memory, a number of candidate items may satisfy the requirements for retrieval.
 For example, in searching for a substitute method of transportation for an evacuation, a comparative specification might provide the additional information that the method found should be the one yielding the highest evacuation rate.
 The second type of additional information needed in knowledge goals for active memory search is what we call search prioritization information.
 Rather than only representing the search target as a complete pattern to match, DIAL'S knowledge goals include a component representing information about where it is believed that relevant information could be found, i.
e.
, about how to seek the information.
 There are generally many ways of searching for a single concept, involving focusing on different parts of the concept at different points in the search.
 As a simple example, suppose that the search goal is to find the union ttiat someone (say John) belongs to.
 One strategy is to search for unions in memory, and then, for each union, to retrieve information about its members to see if John belongs to it.
 A better strategy might be to search for information about John's job, and then to search for likely unions given his employment.
 Part of DIAL's memory search planning involves determining how to break up a concept specification into a sequence of specific concepts to examine in memory.
 Successful stored memory search cases reflect information about which ways of prioritizing goals have proven effective.
 Finally, information is needed about the level of 86 resources to commit to the memory search process.
 Thus DIAL'S knowledge goals include a concept specification, a comparative specification, search prioritization information, information about the amount of effort allowed in the search, and how to use the information that is found.
 The planning process: DIAL'S memory search process is modeled on the query reformulation process first used in C Y R U S (Kolodner, 1984).
 It differs from C Y R U S , however, in applying the process within the framework oi knowledge planning (Hunter, 1990).
 In this knowledge planning framework, similar to the introspective reasoning and learning framework proposed by Kennedy (1995), a planner reasons introspectively about explicitly represented knowledge goals and how to satisfy them using internal "mental" operators.
 For example, two operators that can be used to guide memory search are "To find a cause for an actor's state, search for an action performed by the actor that could cause that state"; 'To find actions performed by an actor, check the actor's habitual actions.
" Such rules are similar in flavor to the types of rules investigated in research on query transformation for information retrieval, and our aim of learning to refine memory search shares the goal of recent work in information retrieval that studies how to learn which retrieval strategies are most useful (e.
g.
, Baudin, Pell, & Kedar, 1994).
 DIAL'S adaptation component is provided with a set of general memory search heuristics and basic local knowledge about its memory organization (e.
g.
, as information on how to retrieve abstractions, on the relationships between schemas and their subparts, etc.
).
 W e note that some of these rules are relatively unguided "weak methods" of memory search (e.
g.
, ascending and descending abstraction hierarchies to find related nodes), whose results are then filtered by constraints from the knowledge goals being satisfied.
 However, as is described in the following section of casebased adaptation, the aim is to generate much more effective knowledge: successful results of this relatively unguided process form the basis of specific adaptation cases that are stored to provide more precise guidance in similar future situations.
 In order to be able to reason about memory search, a system must be able to reason about the meanings of its own memory links.
 Rather than simply being names, DIAL'S memory links are structures associated with information about the relationships that hold between the linked objects, making it possible to reason about the meanings of the links in terms of those relationships.
 This allows the system to decide which links to follow to satisfy knowledge goals that were not anticipated when a memory was originally organized.
 The planning process used by D I A L is inspired by Firby's (1989) R A P S model of reactive planning.
 The choice of a reactive model to guide memory search may seem surprising; reactive planning models are often advocated as a way to plan in dynamic and imperfectlyunderstood worlds, while the "mental" world is modeled as entirely under the reasoner's control and available for examination.
 However, a central difficulty with guiding the memory search process is that the general rules used to suggest memory search paths are not guaranteed to be correct in any particular instances, and in a rich memory, the costs of exhaustive examination of the information are prohibitive.
 Consequently, there are strong reasons for using a planning model that defers commitment to particular details of a plan and that is robust when problems arise.
 learning by storing adaptation cases W h y use C B R for adaptation learning? Once a novel adaptation problem has been solved successfully, the question arises of what should be learned from the results of problemsolving.
 Our first effort at modeling the adaptation learning as operationalizing abstract transformations was the program A L (Adaptation Learner) (Leake, 1994a).
 AL's process for performing adaptations from scratch was similar to the process described above.
 After A L formed an appropriate memory search plan, it performed explanationbased generalization (EBG) (e.
g.
, Mitchell et al.
, 1986) to form a new general memory search rule for future use.
 One of the lessons learned from A L was that E B G is in fact inappropriate for learning the memory search task.
 E B G depends on a correct domain theory—to apply E B G to the m e m ory search task, it requires a domain theory accounting for each piece of information in memory and how each piece of information is organized.
 Unfortunately, the memory search problem is precisely the problem of how to search memory effectively without such a theory.
 Memory search must apply heuristics to find needed information in an idiosyncratic m e m ory whose contents and organization may not be characterized precisely.
 Consequently, chains of memory search rules that work in one instance may not apply to other problems that appear to be within the scope of those rules.
 Because casebased reasoning about adaptation retains the specifics of particular problems, it enables the lessons from memory search during prior adaptation episodes to be reused more effectively.
 Representing case adaptation episodes After completing rulebased case adaptation, D I A L stores two types of information about the adaptation episode, in two types of cases.
 Adaptation cases encapsulate an entire adaptation episode: the response plan that was retrieved, the problem that required adaptation, and the entire memory search plan used to retrieve the needed information.
 These cases suggest effective combinations of transformations and memory search strategies for particular adaptation problems.
 The second class of cases, memory search cases, stores information about the memory search process alone.
 These cases form building blocks for more effective memory search when novel adaptation problems are being solved.
 A n open question concerns the tradeoffs in making subparts of the memory search cases accessible as separate cases, along the lines of Redmond's (1992) snippets.
 Reapplying stored adaptation knowledge The flexibility of C B R systems to address new problems comes from their ability to adapt prior cases to apply to new situations.
 However, a conflicting concern is the potential cost of adapting the current case compared to retrieving and applying a different case, or simply generating a new solution from scratch.
 D I A L controls this cost in two ways.
 First, the amount of memory search effort allowed when adapting adaptation cases is limited (this limit is implemented as a limit on the number of search rules applied).
 Second, the adaptation that is done for the memory search 87 cases themselves is very limited.
 DIAL'S adaptation of m e m ory search cases is restricted to operations such as extracting a subplan that addresses only the knowledge goal of interest from a memory search plan that addressed more knowledge goals, adding filtering steps to check the results of plans that address the desired knowledge goals but omit needed constraints, and adding local search for other nearby memory nodes when the result of memory search fails to satisfy some of the needed constraints.
 A n important question to address is how additional search knowledge affects overall processing cost(Minton, 1988).
 An extended program example In the current implementation, DIAL'S initial case library contains two disaster response plans: a response plan for an air quality disaster and a response plan for an industrial chemical spill.
 Starting from this case library, the system has been tested on four stories exercising different parts of its adaptation mechanisms.
 To illustrate its processing, we consider one of these in more detail.
 The stories and episodes are based on case studies from INvironment, a newsletter for indoor air quality consultants.
 The example we consider involves the following story: At Beaver Meadow Elementary School in Concord, N e w Hampshire, students have been complaining of symptoms like unusual fatigue, eye irritation, respiratory problems, and allergic reactions from being inside the building.
 DIAL'S understander identifies the situation as involving an air quality problem, a type of disaster, and its retriever attempts to retrieve and apply a response plan for a similar disaster.
 The response plan it retrieves as most similar addresses the following episode: A & D Manufacturing in Bangor, Maine, has recently come under pressure from workers and unionrepresentatives to correct perceived environmental problems in the building.
 Workers have been affected by severe respiratory problems, headaches, fatigue, and dizziness.
 Many of the steps in the retrieved response plan for the A & D factory disaster—investigating the extent of the risk, moving the victims to a new location, etc.
—apply to the school problem as well.
 However, in the factory response, one of the steps is to notify the employees' union.
 Simple instantiation suggests notifying the union of the new victims—the schoolchildren—as well.
 The evaluator detects that schoolchildren do not have unions, and initiates case adaptation to repair the problem.
 (The problem is detected by a patternbased anomaly detection process that compares new rolefillers in the response plan to standard expectations.
 This evaluation and problem characterization process is similar to that described in Leake, 1992).
 DIAL'S adaptation component receives two inputs describing this situation: the response plan for the A & D Manufacturing problem, instantiated to apply to the new situation, and a description of the problem for adaptation to repair: that the step notifying the students' union is not reasonable, because students do not belong to unions.
 Because D I A L starts with no adaptation cases, adaptation of the response plan must be done starting from scratch, using the rulebased process.
 The first step necessary is to select a transformation to apply.
 The problem of schoolchildren being inappropriate members of a union is an instance of the problem category "role/filler mismatch.
" (For a description of possible problem types, see Leake, 1992.
) The two transformations associated with "role/filler mismatch" are to either substitute a new filler (e.
g.
, consider notifying the union of some other group), or to substitute a different concept in which the children play a role with relevant similarities (e.
g.
, notifying another group relevant to the children).
 Many adaptations based on these two transformations are possible, but a c o m m o n suggestion from readers of the story is that a reasonable substitution is to notify the children's parents.
 The point of DIAL'S adaptation process is both to generate this answer (as one of many candidates) and to learn from its success that this is a reasonable adaptation to apply to similar future problems.
 Substituting a new role corresponds to a knowledge goal to answer the question "who should be notified instead?" To specify the knowledge goal, D I A L first determines the constraints on reasonable substitutions.
 To find the constraints, it must hypothesize the factors that were important in the relationship between workers and their union in the A & D manufacturing problem.
 D I A L infers constraints to consider by formulating different possible "views" (Wilensky, 1986) of the relationship between the union and the workers in the original episode.
 Each of these views suggests aspects of union membership that might have been relevant and consequently are potential candidates for aspects to preserve when making the substitution.
 One candidate relationship involves representation: being represented by the union.
 This suggests generating the knowledge goal of finding representatives of the children.
 Memory search for representatives of children locates "parents" as a possibility.
 This is not the only candidate—other groups such as "student government" are also considered, but are rejected in the evaluation phase.
 In the future, the resulting successful adaptation (replacing the union by parents) will be retrieved and reapplied.
 The effects of learning and the ability to reuse adaptation cases are demonstrated by DIAL's processing of the following stories.
 One, involving a chemical spill at a school, prompts retrieval of the stored case from a prior chemical spill story and its response plan.
 However, the previous plan cannot be applied in its entirety because it (like the A & D plan) involves notifying the students' union.
 However, the stored adaptation case from the Beaver M e a d o w school example can be reapplied in a straightforward way.
 This example illustrates the benefits of learning not only domain cases (here, disaster response cases) but also adaptation cases: Learning adaptation cases increases the effectiveness of applying existing cases to new problems.
 Another implemented example shows how D I A L can reuse a stored adaptation case in a more flexible way.
 In that example, the story being processed involves an air quality problem on a military base.
 The most similar prior case is the A & D air quality disaster.
 However, when D I A L attempts to apply the response plan from that case, there is a problem similar to the problem that arose when generating the response plan for the Beaver M e a d ow school disaster: soldiers do not have unions.
 In this situation, the learned adaptation case (substituting parents for unions) does not apply directly.
 Nevertheless, the problem is similar, and D I A L uses the prior case as 88 a starting point for future reasoning, reusing the initial part of its search chain.
 Because representation was relevant in determining whom to substitute in the adaptation for the students, the previous case suggests searching for representatives in the current situation.
 DIAL searches its memory for representatives of soldiers and finds "commanding officers" as a possible group to notify.
 This demonstrates the ability to perform some adaptation of adaptation cases.
 More study is needed to identify appropriate adaptation strategies and their utility in terms of both the cost of adaptation and the quality of the results produced.
 Conclusions Providing appropriate case adaptation knowledge is a difficult problem in developing casebased reasoning systems.
 Our research addresses that problem with a method for learning specific adaptation knowledge.
 DIAL builds a library of adaptation cases from specific episodes of applying general adaptation rules.
 The adaptation cases provide more effective guidance to adaptation by allowing reuse of successful adaptation strategies for the system's particular domain, task, and memory organization.
 Our current research presents a new answer to the question of how specific case adaptation knowledge is acquired.
 It has developed methods for generating knowledge goals for case adaptation, a representation for the needed knowledge goals, and answers to questions about the nature of adaptation knowledge and how it may be reapplied.
 The next phases of the research include extending and testing the model on additional examples, investigating the role of failuredriven learning, and evaluating the effects of case learning on the quality and efficiency of the case adaptation process, especially as the number of adaptation and memory search cases grows.
 Acknowledgments This work was supported by the National Science Foundation under Grant No.
 lRl9409348.
 Andrew Kinley and David Wilson made very helpful comments on a draft of this paper.
 References Allemang, D.
 (1993).
 Review of the first European workshop on case based reasoning.
 CaseBased Reasoning Newsletter, 2(3).
 Electronic newsletter of AKCBR.
 Barletta, R.
 (1994).
 A hybrid indexing and retrieval strategy for advisory C B R systems built with ReMind.
 In Proceedings of the Second European Workshop on CaseBased Reasoning, pp.
 4958 Chantilly, France.
 Baudin, C , Fell, B.
.
 & Kedar, S.
 (1994).
 Using induction to refine information retrieval strategies.
 In Proceedings of the twelfth national conference on artificial intelligence, pp.
 553559 Seattle, W A .
 Berger, J.
 (1995).
 Using past repair episodes.
 Manuscript.
 Carbonell, J.
 (1983).
 Learning by analogy: formulating and generalizing plans from past experience.
 In Michalski, R.
, Carbonell, J.
, & Mitchell, T.
 (Eds.
), Machine Learning: An Artificial Intelligence Approach.
 Tioga Publishing Company, Cambridge, M A .
 Cullingford, R.
 (1978).
 Script Application: Computer Understanding of Newspaper Stories.
 Ph.
D.
 thesis, Yale University.
 Computer Science T R #116.
 Firby, R.
 (1989).
 Adaptive Execution in Complex Dynamic Worlds.
 Ph.
D.
 thesis, Yale University.
 Computer Science Department T R 672.
 Centner, D.
 (1988).
 Metaphor as structure mapping: the relational shift.
 Child Development, 59,4759.
 Hammond, K.
 (1989).
 CaseBased Planning: Viewing Planning as a Memory Task.
 Academic Press, San Diego.
 Hunter, L.
 (1990).
 Planning to learn.
 In Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, pp.
 261268 Cambridge, M A .
 Kass, A.
 (1994).
 Tweaker: adapting old explanations to new situations.
 In Schank, R.
, Riesbeck, C , & Kass, A.
 (Eds.
), Inside CaseBased Explanation, chap.
 8, pp.
 263295.
 Lawrence Erlbaum Associates.
 Kennedy, A.
 (1995).
 Using a domainindependent introspection mechanism to improve memory search.
 In Proceedings of the 1995 AAAI Spring Symposium on Representing Mental States and Mechanisms Stanford, CA.
 Kolodner, J.
 (1984).
 Retrieval and Organizational Strategies in Conceptual Memory.
 Lawrence Erlbaum Associates, Hillsdale, NJ.
 Kolodner, J.
 (1993).
 CaseBased Reasoning.
 Morgan Kaufman n, San Mateo, CA.
 Leake, D.
 (1992).
 Evaluating Explanations: A Content Theory.
 Lawrence Erlbaum Associates, Hillsdale, NJ.
 Leake, D.
 (1994a).
 Towards a computer model of memory search strategy learning.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, pp.
 549554 Atlanta, G A .
 Leake, D.
 (1994b).
 Workshop report: the AAAI93 workshop on casebased reasoning.
 AI Magazine, 15(1), 6364.
 Minton, S.
 (1988).
 Learning Search Control Knowledge: An ExplanationBased Approach.
 Kluwer, Boston.
 Mitchell, T.
, Keller, R.
, & KedarCabelli, S.
 (1986).
 Explanationbased generalization: a unifying view.
 Machine Learning, 7(1), 4780.
 Ram, A.
 (1987).
 A Q U A : asking questions and understanding answers.
 In Proceedings of the Sixth Annual National Conference on Artificial Intelligence, pp.
 312316 Seatde, W A .
 Morgan Kaufmann Publishers, Inc.
 Redmond, M .
 (1992).
 Learning by Observing and Understanding Expert Problem Solving.
 Ph.
D.
 thesis, Georgia Inst, of Technology.
 T R # GITCC92/43.
 Rosenthal, U.
, Charles, M.
, & Hart, P.
 (Eds.
).
 (1989).
 Coping with crises: The management of disasters, riots, and terrorism.
 C.
C.
 Thomas, Springfield, IL.
 Segre, A.
 (1987).
 On the operationality/generality tradeoff in explanationbased learning.
 In Proceedings of the Tenth IntemationalJoint Conference on Artificial Intelligence Milan, Italy.
 Sycara, K.
 (1988).
 Using casebased reasoning for plan adaptation and repair.
 In Kolodner, J.
 (Ed.
), Proceedings of the CaseBased Reasoning Workshop, pp.
 425434 Palo Alto.
 D A R P A , Morgan Kaufmann, Inc.
 Wilensky, R.
 (1986).
 Knowledge representation—a critique and a proposal.
 In Kolodner, J.
 & Riesbeck, C.
 (Eds.
), Experience, Memory and Reasoning, chap.
 2, pp.
 1528.
 Lawrence Erlbaum Associates.
 89 TimeAccuracy Data Analysis: Separating Stimuluslimited and Poststimulus Processes Angel Cabrera School of Psychology Georgia Institute of Technology AUanta, G A 303320170 phone: (404) 853 0192 angel@psy.
gatech.
edu Tony J.
 Simon School of Psychology Georgia Institute of Technology AUanta, G A 303320170 phone: (404) 894 2681 tony.
s imonSpsych.
gatech.
edu Abstract Timeaccuracy functions are obtained by measuring the accuracy of a subject's responses at various levels of stimulus presentation time.
 Unlike reaction time (RT) measurements, which convey information about the entire set of processes taking place between the onset of the stimulus and the production of a response, timeaccuracy functions (TAFs) focus on a subset of those processes, namely stimuluslimited processes.
 Stimuluslimited processes are responsible for the extraction of the perceptual information that is necessary for the elaboration of a response.
 Poststimulus processes take care of selecting and executing the response based on the information extracted by stimuluslimited processes.
 This paper presents a method of analysis that allows us to (a) extract estimates of the duration and variance of stimuluslimited processes from individual TAFs and (b) combine these estimates with RT data in order to induce the duration and variance of poststimulus processes.
 The method is illustrated with data from a subitizing (speeded enumeration) task.
 Introduction The relationship between speed and accuracy of responding conveys information about the dynamics of mental processing at a level of detail beyond the scope of reaction time measurements (Wickelgren, 1977; Meyer, Irwin, Osman & Kounios, 1988).
 Consider for instance the three hypothetical speedaccuracy curves in Figure 1.
 Curves like these represent the relationship between the time available to Uie subject to deliberate a response and the average accuracy of the responses in different experimental situations.
 In most cases, accuracy starts out at a low (chance) level for small values of time and then increases monotonically as more time becomes available.
 In the asymptotic region, accuracy no longer depends on time, but on factors such as task difficulty, individual capacity, or amount of noise in the stimuli (Norman and Bobrow, 1975).
 Imagine that tiie Uiree curves in Figure 1 are Uie Uue speedaccuracy functions of three cognitive processes an experimenter is trying to differentiate.
 The three curves show some important differences.
 Performance in task A increases gradually with time, whereas, in tasks B and C, it changes dramatically from chance to asymptote within a few milliseconds.
 In addition, accuracy in tasks A and B reaches a higher asymptote than it does in C.
 What would the experimenter find by running a typical R T task? By simply looking at the figure, it seems that all three tasks take about the same amount of time to reach asymptote.
 If subjects are instructed to emphasize accuracy, it is likely Uiat average RT of correct trials would be somewhere around tj ms in all three cases, and therefore, no significant differences among the tasks would be found.
 Further analysis of the subject's errors would probably reveal a difference between task C and tasks A and B, but A and B might still remain indistinguishable.
 time Figure 1.
 Hypothetical timeaccuracy functions Speedaccuracy tradeoff research How then can we assess the correspondence between speed and accuracy in order to capture tiiose differences that seem to escape RT data? Several meUiods have been used in the past to induce subjects to trade accuracy for speed (Wickelgren, 1977): verbal instructions, differential reward of speed and accuracy, external signals that indicate when a response must be produced, etc.
 Speedaccuracy curves can also be estimated by partitioning all the responses (correct w incorrect) into uniform RT intervals and then computing the percent of correct responses witiiin each interval.
 The strengtiis and limitations of each of these methods have been discussed elsewhere (e.
g.
 Wickelgren, W77).
 In any case, no matter what meUiod is used, speedaccuracy designs treat both speed and accuracy as dependent measures.
 90 mailto:angel@psy.
gatech.
eduTimeaccuracy functions A different way of dealing with speedaccuracy dependencies involves measuring accuracy as a function of the time during which the stimulus is directly available to the subject (Lohman, 1986; Loftus, Duncan & Gehrig, 1992; Kliegl Mayr & Krampe, 1994; Simon.
 Cabrera & Kliegl, 1993).
 Kliegl and his colleagues refer to this presentation time manipulation method as the "cognitive psychophysics" approach for its resemblance to the general psychophysical paradigm in which performance is analyzed as a function of the available amount of some relevant resource (Norman and Bobrow, 1975).
 Here the relevant resource is the time during which the subject has access to the perceptual inforaiation needed to produce a response, and performance is the subject's accuracy in that task.
 The difference between this approach and more traditional speedaccuracy research is more important than it may initially ̂ pear.
 In timeaccuracy research "presentation time is under experimental control, whereas in speedaccuracy tradeoff research response latency is a dependent variable" (Kliegl, Mayr & Krampe, 1994.
 p.
 136).
 This conu^t is not only methodological: it affects the kinds of substantive inferences that can be drawn from the results.
 Speedaccuracy tradeoff data, Uke RTs, convey infonnation about the entire sequence of processes taking place from the onset of the stimulus until the production of the response.
 In contrast, the shape of a timeaccuracy function obtained through the psycophysical method is only descriptive of a subset of those processes, namely those subprocesses that rely on the physical availability of the stimulus.
 Stimuluslimited vs.
 poststimulus processing Like Salthouse (1981).
 we will refer to the processes that require direct access to the stimulus as "stimuluslimited".
 In addition, we will define "poststimulus" processes as those processes that rely on the result of stimuluslimited processes and that, consequently, do not operate until stimuluslimited processes end (spontaneously «• otherwise).
 W e have suggested that the transition region of a timeaccuracy function reflects dynamic characteristics of stimuluslimited processing.
 W e also know that RTs convey information about the entire set of processes including both stimuluslimited and poststimulus stages.
 If we can somehow extract information from the TAFs in a form that is directly comparable with R T information, we could infer the properties of poststimulus processing by subtraction d la Donders (1868) or through more sophisticated deconvolution techniques (Smith, 1990).
 For this stage decomposition to be possible, we must assume that (a) the two stages are connected in series, (b) the duration of each of the two stages is a random variable with certain probability distribution, and (c) that the duration of the two stages is statistically independent from each other.
 These assumptions are c o m m o n to most of the stage decomposition techniques used in cognitive psychology (Sternberg, 1969; Salthouse, 1981).
 Although the seriality and independence assumptions have been the center of a great deal of controversy (see Townsend & Ashby, 1983), there is a significant body of findings that has shown the concept of processing stage to be useful in understanding human cognition (Salthouse, 1981).
 Resolving this debate is beyond the scope of this paper.
 Rather, we are making these assumptions from a systems identification standpoint.
 The usefulness of the assumptions will be indicated by the kinds of empirical distinctions they ultimately lead to.
 As w e will show later (see also Simon & Cabrera, 1995) some of our own data in the doniain of subitizing indicates that the stimuluslimited / poststimulus distinction may capture important conceptual differences.
 Analysis of timeaccuracy functions Timeaccuracy functions have been analyzed in the past by fitting mathematical functions (typically negatively accelerated exponential curves) to the data.
 The functions so obtained are then compared with one another (l>etween or within subjects) in terms of either the parameters resulting frwn the curve fitting procedure (Kliegl, Mayr & Krampe, 1994; Simon, Cabrera & Kliegl, 1993) or the predicted presentation time for some prespecified level of accuracy (Wickelgren, 1977; Lohman, 1986).
 These parametric techniques have several limitations.
 First, the choice of a particular mathematical model may be hard to justify theoretically.
 More often than not, models are justified in a posthoc fashion based on goodnessoffit measures and not on a priori theoretical grounds (c.
f.
 Kliegl, Mayr and Krampe, 1994).
 Second, the resulting parameters are difHcult to interpret outside the specific family of mathematical functions being considered, and consequently, they can not be compared to R T data or even to parameters from other mathematical functions.
 H o w can we extract information about stimuluslimited processing from a timeaccuracy function (TAF) in a form that can later be used in comparisons with R T data? There are at least two main ways in which timeaccuracy functions can be interpreted (Wickelgren, 1977; Meyer et al.
, 1988).
 One of them consists of assuming a decision process that gradually and stochastically builds a response tendency starting as soon as the stimulus is presented.
 W h e n presentation time is experimentally restricted, subjects are forced to produce a premature response based on incomplete information.
 This translates into the typical timeaccuracy patterns in which accuracy increases monotonically and asymptotically with presentation time.
 Under this approach then, TAFs represent diagrams of information (or response activation) accumulation (e.
g.
 McClelland, 1979).
 The second interpretation (the one that will be adopted here) assumes an underlying discrete, allornone process with a randomly distributed termination time.
 In other words, it assumes that there is a minimum amount of presentation time T necessary for a stunulus to be processed successfully, and that this amount of time is a random variable with a certain distribution.
 If the presentation time for a given trial / is less than T, the stimulus can not be processed, and a random response is produced.
 However, if t is greater than T, the stimulus can be processed successfully and the accuracy of the response only depends on the capacity limitations of the subject or the noise in the 91 stimuli.
 Saying that T is a random variable amounts to saying that the exact duration of the underlying allornone process is not fixed across trials.
 This means that any given value of presentation time can be too short in some trials and yet long enough in other trials which will lead to random performance in some trials and to asymptotic performance in other trials.
 The allornone interpretation of stimuluslimited processes might initially seem counterintuitive.
 Even though, based on the data alone, both interpretations are equally valid (see Meyer et al.
, 1988), it can be argued that some amount of partial information can be extracted even when presentation time is too short for a fully confident response to be possible.
 W e have two reasons to assume the allornone interpretation.
 The first reason is an analytical one and will hopefully become clear in the next section.
 The second reason is an empirical one: this assumption leads to results that could be critical in understanding the phenomenon of subitizing.
 Whether this empirical advantage will generalize to other areas of cognition or not, remains an open question.
 Difference TimeAccuracy Functions The analysis problem under this interpretation can be stated as: "given A(r), the observed accuracy for each value of presentation time t, obtain an estimate of Fit), the cumulative probability distribution of the underlying rand«n variable T.
" Let us refer to the asymptotic level of A(f) as Amax< and to the chance level as Arand Since F(t) = P(t<T), the observed timeaccuracy function A(t) will be related to F(0 according to: A{t) = F{t)A^, + [lF(t)]A„„„ (1) In other words the observed accuracy will depend on the probability of t being above or below T, times the level of accuracy reached in each case (Afnax and Arand) Given A{t) we can then obtain F(0 as p/f\ _ Mi)~^rand •̂tnax ~ ̂  (2) rand Once w e have an estimate F(t) of the cumulative probability distribution of the underlying T, it is straightforward to derive T s probabiUty density function/Tr) as the derivative of F(f), f{t) = —j^.
 In practice, we may at not have an analytical expression for F(t) but a set of samples for different values of time F(ti).
 In this case, we can obtain the probability function p(ti) through simple subtraction: P(t,)F \ A n f   f ] (3) where Ar represents the size of the interval between consecutive samples.
 The functions//) orp(r,) so obtained will be referred to as Differential TJmsAccuracy Funciions (DTAFs).
 Figure 2 shows the D T A F (marked as •  • ) , obtained from a hypothetical discrete logistic T A F (marked as**).
 By interpreting D T A F s as estimates of probability distributions, we have access to the whole spectrum of stochastic techniques normally used in analyzing R T distributions (Townsend & Ashby, 1983).
 The most immediate computations D T A F s can address are estimates of central tendency and variance of stimuluslimited termination time.
 For instance, w e can obtain the mathematical expectation or mean of Tas i and its variance as (4) (5) 500 600 700 t(ms) 800 900 Figure 2.
 Logistic T A F and its corresponding DTAF.
 The median of T is the point of intersection of F{t) with the .
5 constant line.
 Computing the median from the D T A F is equivalent to using psychophysics' typical 5 0 % criterion, which estimates the amount of resource necessary to complete a task as the value of resource for which performance reaches 5 0 % of the asymptote.
 The mode of T corresponds to the peak of y(0, which in turn corresponds to the inflation point of F(t).
 Although in the hypothetical curve in Figure 1, mean, median and mode are the same, this is not necessarily so for other distributions.
 The median and the mode tend to be more robust to the presence of noise and outUers in the data dian the mean, but the mean offers two important advantages: (a) it is the maximumlikelihood estimate of T, and (b) stage duration means are additive under the seriaUty and independence assumptions.
 For D T A F analysis to be feasible, the original TAFs must be monotonic and nondecreasing (otherwise, we could obtain distributions with negative values of probability!) What this constraint really means is that accuracy must increase or remain constant as time increases.
 Foriunately, this is the case with most tasks of interest in cognitive science (Norman & Bobrow, 1975).
 In real situations, even 92 when monotonicity is to be expected, errors of measurement may induce small violations.
 It is the experimenter's responsibility to decide, based on theoretical grounds, whether to consider these irregularities as random errors of measurement or as reflection of some unexpected underlying pattern.
 In the flrst case, the irregularities can be smoothed out prior to further analysis through curve fitting, convolution or any other method.
 Poststimulus processing The most important advantage of the DTAF procedure is that it produces results that are given in terms of process duration or termination time.
 This has the key advantage of allowing results from timeaccuracy designs to be compared and combined with duration estimates obtained through other methods.
 In particular, they can be combined with R T data, in order to estimate the time characteristics of poststimulus processes.
 Remember that we defined stimuluslimited and poststimulus processes as two independent and serial stages.
 It can be shown (e.
g.
 Townsend & Ashby, 1983) that the distribution of the duration of the serial combination of two independent stages can be obtained as the mathematical convolution of the distributions of the two stages.
 Furthermore, the mean duration of the combined process is equal to the sum of the mean duration of the individual stages, and so is the variance.
 The additivity property of serial stages allows us to interpret mean R T as the sum of the mean duration of stimuluslimited processes plus the mean duration of poststimulus processes, and the same thing for the variances.
 In other words, we can estimate the mean duration and variance of poststimulus processes as the difference between the mean and variance of the observed RTs and the estimates of mean and variance of stimuluslimited processes obtained through D T A F analysis.
 The fact that the estimates of mean and variance for the whole process are obtained very differently than the mean and variance of the stimuluslimited subprocesses does not preclude us from being able to combine and compare them with one another because they represent the same underiying construct: process duration.
 Subitizing: A case study To illustrate the whole procedure, we have selected some data from one subject in one of the experiments w e are carrying out in our ongoing research on subitizing (Simon, Cabrera & Kliegl, 1993; Simon & Cabrera, 1995).
 Subitizing refers to the ability of humans to identify the numerosity of small sets of objects rapidly an accurately.
 This phenomenon is important for its implications in the understanding of visual attention (Trick & Pylyshyn, 1994) as well as the development of basic numeric ability (Geary, 1995).
 According to Trick and Pylyshyn's metaanalysis (1994), enumerating 1 to 4 objects takes an average of 40 to 120 ms per item, whereas enumerating more than 5 objects requires between 250 and 370 m s per item.
 As w e discuss elsewhere in this volume (Simon & Cabrera, 1995), all the different attempts to explain the phenomenon of subitizing split the process of number judgments into two separate stages, although they vary in the nature of the subprocesses attributed to each of the stages.
 Roughly speaking, the first stage would be responsible for the perception and encoding of the stimulus while the second stage would be responsible for response choice and execution.
 Impending on the exact roles that are attributed to each of the two stages w e can make different predictions about bow the number of objects in a display should affect the duration of each of the stages.
 Unfortunately, the R T data that has been collected so far is not powerful enough to assess the effect of numerosity on each of the two processing stages.
 Simon, Cabrera & Kliegl (1993) reported some results from a timeaccuracy study that showed a discontinuity between small and large number of objects very similar to the one found in R T studies.
 Our goal now is to assess the effects of numerosity on stimuluslimited and poststimulus stages.
 Our preliminary results show that numerosity mainly affects stimuluslimited processes within the subitizing range but affects both stimuluslimited and poststimulus for larger numerosities (Simon & Cabrera, 1995).
 Here is an illustration of how the method is actually applied.
 Subjects are presented with a row of letters "o" in the center of a computer screen for a period of time that is varied from trial to trial.
 Subjects are asked to enumerate the letters in the display and to produce a verbal response as fast as they can that is timed by using a voiceactivated relay.
 Response times as well as accuracy of the responses are recorded for every trial.
 Throughout the whole session, subjects are presented with rows of 2 to 8 items at ten different levels of presentation time 20 times each.
 Average accuracy for each numerosity at each of the ten levels of presentation time is used to build the T A F s (one per numerosity).
 The ten levels of presentation time are not the same for all numerosities.
 They are actually selected based on pilot data so that accuracy ranges from chance at the lowest presentation times to perfect at the largest.
 Figure 3 shows seven T A F s obtained from one subject for numerosities 2 to 8 under presentation times varying overall from 35 to 2500 ms.
 Each of these seven curves are our raw A(r/)'s.
 Notice h o w almost every A(/,) shows some small violations of monotonicity even though there is a clear increasing trend of accuracy with time.
 There are several methods to smooth out those irregularities from the raw A(/,)'s.
 These include exponential or logistic curve fitting and kernel filtering techniques.
 T o avoid having to make the assumptions those techniques rely on, w e opted for a very simple algorithm that flattens out any irregular segment to the average of the neighboring points (Cabrera, 1994).
 These adjusted versions of the i4(r,)s are then rescaled according to Equation 2 to obtain estimates of the F(f,).
 In the case of subitizing, most subjects reach perfect accuracy provided enough presentation time, so w e considered A m a x = 1.
0.
 Since our subjects were informed that numerosity varied between 2 and 8, w e assumed that Arand  1^7.
 Figure 4 shows the effect of smoothing and rescaling one of the raw TAFs.
 93 From each F(r,) w e compute a pUi) ( D T A F ) by subtraction of consecutive values of F(//) (Eq.
 3) and then extract the mean and variance of stimuluslimited processes from the resulting D T A F s (Eqs.
 4 & 5).
 Figure 5 shows the resulting means with their corresponding confidence intervals (±aj) as a function of numerosity.
 By subtracting these values from the means and variances of the R T data, w e obtain the means and variances of poststimulus processes (Figure 6).
 The data from this one subject illustrate how numerosity affects stimuluslimited and poststimulus processes differently (see Simon & Cabrera, 1995, for further details).
 Conclusions Reaction time data convey information about the entire set of processes taking place from the onset of the stimulus until the production of a response.
 The relationship between accuracy of responses and the amount of time during which the stimulus is physically available to the subject conveys information about the subset of processes responsible for the extraction of information from the stimulus, namely stimuluslimited processes.
 By combining R T and timeaccuracy data w e can then estimate some of the characteristics of the remaining processes (poststimulus processes).
 W e have shown h o w the stimuluslimited / poststimulus distinction can help us understand the nature of cognitive processes at a level of detail that escapes more traditional R T designs.
 In particular, it has helped us identify the processing stages that are involved in the estimation of numerosity.
 a problem with interesting implications in visual attention and basic mathematical ability (Simon & Cabrera, 1995).
 One of the advantages of this method is the fact that it does not rely on specific parametric assumptions about the form of the data.
 Experimental manipulations often have effects on the shape of TAFs, and these effects may make it hard for a simple mathematical model to fit all the data across conditions.
 In our earlier subitizing studies (Simon, Cabrera & Kliegl, 1993) a two parameter exponential model achieved very good fits for numerosities up to 5 but very poor fits thereafter, which forced us to discard portions of data that would otherwise be perfectly valid.
 D T A F analysis does not make specific assumptions about the shape of the data and can therefcxe be applied no matter what the shape of the T A F is (with the only constraint of monotonicity).
 A second strength of D T A F analysis is its applicability to individual data.
 Several researchers (Siegler, 1987; Ashby, Maddox & Lee, 1994) have emphasized the need to extract as much information as possible at the individual level.
 500 1000 1500 2000 Presentation Time (tns) 2500 = 7 * »__.
 » •»» 500 1000 1500 2000 Presentation Time (ms) 2500 Figure 3.
 Original TAFs for numerosities 2 to 8.
 Figure 4.
 R a w A(r/) (*) for 7 items and its corresponding F(ti) (0) after smoothing and rescaling to the [0,1] interval.
 1400 1000 I i 500 ^ 0 ^  ^ ^ ^ I K i I 1 [ y / y , 1 • 4 6 Number of Items 2500 ̂  2000 ̂  1500^ lOOOl 4 6 Number of Items Figure 5.
 Duration of stimuluslimited subprocesses as a function of niunerosity.
 Figure 6.
 Duration of poststimulus subprocesses as a function of numerosity.
 94 As information theorists well know, any kind of data manipulation can only eliminate information, or, at the very best, keep it constant.
 If relevant information about individual processing is filtered out through premature data aggregation, it is unlikely that further analyses will be able to recover it.
 At some point of course, aggregation is necessary in order to generate meaningful conclusions from the data.
 But it is crucial to devote as many resources as possible to the early stages of analysis and to defer aggregation aaoss subjects to the final stages.
 The D T A F method is particularly well suited for this.
 Finally, the methodology presented here links T A F paradigms with all the stochastic techniques that, in the past, were exclusive to response latency data (Townsend & Ashby, 1983).
 Here we saw how statistical estimates obtained from T A F and R T distributions can be combined in order to address questions about the internal structure of cognitive processes.
 Convolutional analysis, statistical dominance and other stochastic constructs are perfectly aH5licable to DTAFs in the same way as they are used in the context of R T distributions.
 Wickelgren (1977) argued that theories of information processing could no longer ignore speedaccuracy tradeoff data, yet general theories of cognition still rely fundamentally on response latencies to assess their edacity to account for human performance (e.
g.
 Newell, 1990).
 Response latencies yield a single point of a speedaccuracy or timeaccuracy function.
 Many important processing differences that are reflected in the patterns of dependency between time and accuracy can not be detected by R T designs.
 Speedaccuracy data in general, and timeaccuracy functions in particular, raise new challenges for cognitive thenists and model builders.
 Acknowledgments The first author was funded by a MEC/Fulbright Scholarship from the Spanish Ministry of Education and Science and the U.
 S.
 Infwmation Agency.
 Throughout this research we have received invaluable insights from Chris Hertzog, Reinhold Kliegl and Tim Salthouse.
 Our kindest thanks to Christa Dell, Alan Kersten, Jonah Lunken and Sandeep Vaishnavi for their collaboration in this project.
 References Ashby, F.
, Maddox, W.
 & Lee, W.
 (1994).
 On the dangers of averaging across subjects when using multidimensional scaling or the similaritychoice model.
 Psvchological SfleniS^.
 144151.
 Cabrera, A.
 (1994).
 Controlling time and measuring time: A towstage model of cognitive processing of visual stimuli.
 Cognitive Science Report Series, GITCS1994/34.
 Georgia Institute of Technology.
 Donders, F.
 C.
 (1909).
 O n the speed of mental processes.
 (English translation of original 1868 anicle.
) Acta Psvchnlogica.
 30.
 412431.
 Geary, D.
 C.
 (1995).
 Reflections of evolution and culture in children's cognition: Implications for mathematical development and instrucUon.
 American Psvchologist.
 5Q.
 2437.
 Kliegl, R.
, Mayr.
 U.
 & Krampe, R.
 T.
 (1994).
 Timeaccuracy functions for determining process and person differences: An appUcation to cognitive aging.
 Cognitive Psychology.
 26.
134164.
 Loflus, G.
 R.
.
 Duncan, J.
, & Gehrig, P.
 (1992).
 O n the timecourse of perceptual information that results from a brief visual presentation.
 Journal of Experimental PsYCbolosy; Human Perception and Performance.
 1&.
 530549.
 Lohman, D.
 F.
 (1986).
 The effect of speedaccuracy tradeoff on sex differences in mental rotation.
 Perception and Psvchophvsics.
 22.
 427436.
 McClelland, J.
 L.
 (1979).
 O n the time relations of mental processes: an examination of systems of processes in cascade.
 Psvcholngical Review.
 86.
 287330.
 Meyer, D.
 E.
, Irwin, D.
 E.
, Osman, A.
 M .
 & Kounios, J.
 (1988).
 The dynamics of cognition and action: Mental processes inferred from speedaccuracy decomposition.
 Psycbolosical Review.
 95.
 183237.
 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M A : Harvard University Press.
 Norman, D.
 A.
 & Bobrow, D.
 (1975).
 O n datalimited and resourcelimited processes.
 Cognitive Psychology.
 7.
4464.
 Salthouse, T.
 A.
 (1981).
 Converging evidence for informationprocessing stages: A comparativeinfluence stageanalysis method.
 Acta Psvchologica.
 47.
 3961.
 Siegler, R.
 S.
 (1987).
 The perils of averaging data over strategies: An example from children's addition.
 loiuoal of Experimental Psychology: Cieneral.
 I M 250264.
 Simon, T.
 J.
, Cabrera, A.
 & Kliegl, R.
 (1993).
 A new a(T)roacb to the study of subitizing as distinct enumeration processing.
 In Proceedings of the Fifteenth Annnal Conference of the Cognitive Science Society, HiUsdale, NJ: Lawrence Erlbaum.
 Simon, T.
, & Cabrera, A.
 (1995).
 Evidence for subitizing as a stimuluslimited phenomenon.
 Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society.
.
 Hillsdale, NJ: Lawrence Erlbaum.
 Smith, P.
 L.
 (1990).
 Obtaining meaningful results from Fourier deconvolution of reaction time data.
 Psvchological Bulletin.
 IQg.
 533550.
 Sternberg.
 S.
 (1969).
 The discovery of processing stages: Extensions of Donders' method.
 Acta Psvchologica.
 30.
 276315.
 Townsend, J.
 T.
 & Ashby, F.
 G.
 (1983).
 The Stochastic Modeling of Elementary Psvchological Processes.
 N e w York: Cambridge University Press.
 Trick, L.
 & Pylyshyn, Z.
 (1994).
 W h y are small and large numbers enumerated differently? A limitedcapacity preattentive stage in vision.
 Psychological Review.
 101.
 80102.
 Wickelgren, W .
 A.
 (1977).
 Speedaccuracy tradeoff and informaUon dynamics.
 Acta P.
svrhnlnpira 41,6785.
 95 Cognitive Science and T w o Images of the Person Andrew Brook Carleton University Ottawa.
 ON.
, Canada KIS 5B6 University of Oxford Oxford, England 0X1 4 A W abrookQccs.
carleton.
ca Abstract A certain indecisiveness and lack of common purpose seems to be a feature of cognitive science at the moment.
 W e are in this paper that it can be explained in part by cognitive science's lack of success so far in connecting its scientific, computational image (better, images) of cognition to what we experience of people in ordinary life: in society, law, literature, etc.
 Following Sellars (1963), we call these two ways of representing cognizers the scientific image and the manifest image.
 The scientific image sees persons, and also artificial cognitive systems, as vast assemblages of postulated units of some kind.
 In the manifest image by contrast, persons are seen as unified centre of representation, deliberation and action, able to reach focused, unified decisions and take focused, unified actions.
 Since the manifest image is the murkier of the two, more of the paper is devoted to it than to the scientific image.
 The manifest image is richer and more diverse than might at first be thought.
 Key words: philosophy/foundations; explanation.
 Cognitive science has had less impact outside its boundaries than might have been expected given the huge range of discoveries it has made and the considerable resources expended on research into cognition in the past few decades.
 As a number of speakers at last year's workshop on Cognitive Science Education observed, cognitive science is still far from having a unified research programme and it is now forty years old.
 (Compare the neurosciences.
 Though much newer as a selfidentified activity, their major international organization has over ten times the members of the Cognitive Science Society and its members don't spend time writing papers like this.
) Even people within cognitive science often do not know how to take or to assess many of its claims.
 Part of the reason for all this, I think, is that so far the findings of cognitive science have not made much connection to persons as we experience and conceive of them in everyday life.
 A n example.
 In the last decades, we have developed many marvellous inference and decision systems.
 N o w ask, what do these systems tell us about the activity of m e and other people making a decision: the effort to think the situation through and reach a decision, then the effort (the same or a different kind of effort?) to adhere to the decision in the face of some unforeseen complication or  a different kind of case  against a strong desire to do otherwise? Very little; the operating principles of inference systems, etc.
, make almost no contact with decisionmaking as we find it in persons.
 The point can be generalized.
 So far, cognitive science has had very little impact on social policy, interpersonal relationships, rules and structures for regulating interpersonal practice, the law, and so on.
 Where it has had an impact, moreover, it has generally not in the way we might expect, by telling us important things about what social actors are like, but as new and powerful prosthetics, in something like the way word processors have had an impact on writing.
 (Education is a partial exception, and one could think of others.
) One reason, I think, is that most people have no idea how to apply the various conceptions of the human cognizer of cognitive science to the human person, no idea how to use them to understand themselves or others.
 Note that the problem is not just to do with introspection.
 H o w to apply cognitive science's notions of a cognitive system to others is as much a mystery as how to apply it to ourselves.
 To forestall a possible misunderstanding, let me make clear that I a m not setting the stage for some new form of mysterianism.
 (Flanagan calls philosophers like Nagel and McGinn who urge that consciousness, subjectivity or whatever is somehow beyond the ken of rational modelling N e w Mysterians.
) To the contrary, if there is a problem here, it is a problem, something to be solved, not a mystery to be venerated.
 Veneration is not one of my favourite attitudes.
 Some philosophers have taken up aspects of the issue, if perhaps not the issue as a whole, Charles Taylor in particular.
 Sellars' Two Images So we seem to have two conceptions of persons and no good way to connect them.
 Sellars took a large first step towards getting these two conceptions clearer thirty years ago, in "Philosophy and the scientific image of man" (1963).
 He called the two conceptions the manifest image and the scientific image.
 The manifest image is the image of the human person of ordinary moral, social, and interpersonal life.
 The scientific image is the image of the person as a postulated system of smaller units of some kind, the image we find in cognitive science.
 The leading theory in this image nowadays is that persons are a vast assemblage of neurons tied together in complex biochemical and informational relationships.
 Sellars treats them in concert with a similar pair of images of the rest of the natural world but we will consider them in isolation here; he urges that the two images are radically different from one another.
 'The' scientific image is in fact more than one image.
 A number of scientific images of the person have had an effect on our conception of persons, including: the neurological picture, the computational informationprocessing picture, and more recently the connectionist, distributedrepresentation picture.
 If we extend our considerations to include historical ones, the number is even larger; four of the more important were 96 Descartes' neural hydraulics, the neuron and its quantities of energy of Freud's Project for a Scientific Psychology, behaviourism's stimulusresponse model, and the conditionaction picture of classical production systems.
 However different these various pictures may be among themselves, they are also quite similar in one way: they all postulate an unobservable unit, much smaller than the person, out of which persons are built.
 Since they all differ from the manifest image in this respect, no harm is done by talk of ̂ the' scientific image.
 (Sellars views behaviourism as a manifestimage theory.
 Since I think the manifest should be largely confined to the intentional, a point to which w e will return, I think he is wrong about this, but it is a relatively minor point.
) The scientific and the manifest images are structured quite differently.
 In the manifest image, the basic unit is the whole person.
 The building block in the manifest image is nothing less than the human person, a being that can observe, make decisions, identify itself with things, enter into relationships with others, govern itself by standards, and so on.
 Taking a whole person as the basic unit is characteristic of much of social science and virtually all of practical, interpersonal or social activity.
 Both start from persons as a unit and focus on what moves these units, how they relate to other such units, how they relate to things in the nonpersonal world, and so on.
 More generally, the manifest image starts with the person as manifest in everyday life.
 The scientific image by contrast takes as its basic building block unobservable entities and unobservable processes of one kind or another, both postulated to explain features of the manifest (p.
 19).
 The assumption is that the large basic unit of the manifest image consists of assemblies of the smaller basic unit of the scientific image, usually vast numbers of them.
 The two images just delineated are images of the human person as a whole, of all its essential aspects.
 As Sellars conceives it, there is more to the manifest image than just taking the whole person as the basic unit of investigation.
 For Sellars, the manifest image of something is simply everything contained in the way w e think about that kind of thing in everyday life.
 Indeed, it is more than this; Sellars also includes anything w e could discover about the thing without postulating simpler, unobservable components as units out of which it is composed.
 With persons, this works out in the following way.
 W e have been able to discover a great deal about what is correlated with what in people.
 Anger is correlated with insults, contentment with good relationships, adult disturbance with childhood traumata, etc.
 Many of these discoveries go well beyond what was contained in our original commonsense conception of the person.
 The manifest image w e now have of persons thus includes not only the way it presents itself to us in everyday life but also everything w e have been able to discover about persons by studying patterns of correlations.
 To be sure, Sellars does not always honour the richness of his own conception.
 In particular, sometimes he seems to equate the manifest with the observable (p.
 19).
 Even if w e include the introspectible in the observable as Sellars does (p.
 19), this characterization is too restrictive.
 There is a great deal in our manifest image of persons that is not observable or introspectible, very straightforward things like character and levels of ability, for example.
 Neither is observable or introspectible, yet both are clearly aspects of our manifest image of the human person.
 So what does characterize this image? Taking up a hint from the last paragraph, w e might think that the manifest image is the arena of psychological explanation in the language of intentionality.
 The scientific image would then be characterized as the arena of mechanistic, i.
e.
, nonteleological explanation.
 The idea at the heart of psychological explanation is the familiar one that objects of perception, desire, fantasy, belief, memory, etc.
 can have meaning for people.
 A s a result, people can think and feel and do things for reasons, not just as the result of mechanistic causes.
 Reasons in turn have intentionality; they are about something, have an object.
 Psychological explanations in terms of reasons are very different from standard mechanistic explanations and part of the difference between the two images is clearly captured by this difference, but there is more to the manifest image than this.
 Mechanistic explanations of a kind also play a role in the manifest image, namely patterns of correlation.
 They are not postulational, so they are manifestimage, yet they are clearly not intentional either.
 The difference between the kinds of explanation does not exhaust the difference between the two images.
 Fortunately, Sellars has a better suggestion: the manifest image is the framework in which w e encounter ourselves (p.
 6).
 That is to say, it is the framework within which w e experience, reflect on, relate to, and interact with ourselves and one another.
 This suggestion provides something that our previous explorations left out.
 The distinction between the two kinds of explanation was focused on psychological content and attitudes, and modes of explaining them.
 A large part of our manifest image of persons, however, is an image of the thing that has this content, takes up these attitudes ~ it is an image of a subject and agent.
 Moreover, as represented in the image, the subject and agent has a very particular character.
 Our job is now to describe this part of the manifest image.
 Features of the Manifest Image Probably the most important feature of our conception of the person, the basic unit of the manifest image, is that persons are originators of action, where by "action' w e mean not just behaviour but behaviour that is a result of the formation of an intention and the taking of a decision.
 O n a first pass, this being seems to have three prominent features: (1) Persons are subjects and agents  centres of representation, imagination, reflection, and desire, originators of intentions and decisions.
 (2) Persons can guide themselves by reasons, things that motivate and so provide reasons for and against a belief or feeling or course of action in such a way that action ensues only as a result of decision, not simply by the unfolding of causal influences.
 (3) A m o n g the most important motivators or reasons for action are emotions  fears, feelings of affection, feelings of gratitude, resentments, hostilities and biologicallybased desires  hungers, lusts, feelings of discomfort, etc.
 All three features are distinctive of our image of the human person and it seems likely that all of them are also essential to it.
 What exactly w e take to be built into any of three is a bit mysterious, but here are some candidates.
 97 /.
 Making an effort.
 Sometimes it is easy to reach a decision, but sometimes it taices effort  effort to understand a situation, effort to figure out what to do, effort, sometimes, to resist temptation and keep to a decision ('I really should reread three more pages of this paper but I would so much like to quit for the night'), and even effort to overcome obstacles, both human and nonhuman.
 Moreover, sometimes, try as hard as we might, w e do not manage to do what w e decided to do.
 What is making an effort like? Are all the exertions of effort just sketched of one kind or a number of different kinds? What is the agent who makes these various efforts like? It is hard to say.
 2.
 Unity of focus.
 Making choices requires something else that is central in our manifest image of the person.
 I will call it unity of focus.
 To see what it is like, start with the better known unity of consciousness (UC).
 One form of U C is a matter of being aware of a whole group of representations at the same time; another consists of being aware of oneself as the c o m m o n subject of those representations.
 W e can define it more formally as follows: The unity of consciousness (UC) =df (i) a representing in which (ii) a number of representations and/or objects of representation are combined in such a way that to be aware of any of these representations is also to be aware of other representations as connected to it.
 (See Brook 1994, Ch.
 3).
 Clearly U C is an important part of the manifest image of persons.
 However, I think a kind of unity found on the volitional side is even more central to what we conceive a person to be, what I call unity of focus.
 W e conceive of persons as beings able to focus their intentional resources on courses of action.
 They can focus on a number of considerations at the same time and weigh up their implications.
 They can focus on a number of alternative courses of action at the same time, and assess them against one another in the light of desires, moral beliefs, wishes for other people, etc.
 They can bring these considerations together to form an intention and choose a course of action.
 And they can focus their intentional resources on carrying out that course of action, against obstacles, conflicting desires, and so forth.
 The unity of focus involved in all these activities seems to be something more than just a unified Yield' of consciousness.
 It has often been remarked that when we think of persons within the manifest image, there is a powerful inclination to think of them as being or containing a grand unified homunculus, a little being who is the centre of consciousness, agency, responsibility, and so on.
 It seems likely that what I a m here calling the unity of focus is one of the phenomena that contributes most strongly to this inclination.
 W e will return to the problem of the homunculus briefly below.
 3.
 Reference to Self.
 Persons can refer to themselves using indicators that have semantic properties different from those found in virtually any other indicator.
 Shoemaker's term for this form of reference is selfreference without identification, which he characterizes in the following way: M y use of the word F as the subject of [statements such as "I feel pain' or I see a canary'] is not due to m y having identified as myself something [otherwise recognized] of which I know, or believe, or wish to say, that the predicate of m y statement applies to it.
 (1968, p.
 558) That is to say, I a m aware of myself, as myself, without inferring this from any other feature of myself If so, that the referent is myself is something I know independently of knowing anything else.
 If so, I must be able to refer to myself as myself independently of 'noting any quality' in myself as Kant put it (1781, A355).
 If so, finally, the firstperson pronouns are semantically quite unusual.
 4.
 Anticipating a future as one's own.
 I have a striking ability to imagine a future person as myself, to imagine me having the experiences and doing the actions that I suppose he or she will have or do, even when I suppose at the same time that I a m connected to that person by all manner of unusual connections and/or lack of connections.
 Williams explored this phenomenon in a series of interesting thoughtexperiments in (1973),esp.
Ch.
 3.
 All of (1) to (4) seem to be either parts of our manifest image of the person or natural extensions of it.
 T w o things are striking about the resulting conception of the person.
 One is its central importance in practical and especially interpersonal and social life.
 The other is how little anybody in philosophy, cognitive science or anywhere else has managed to say about it.
 In particular, little progress has been made with capturing any of (1) to (4) in any kind of postulational, mechanistic model, whether neuronal, computational, connectionist or otherwise.
 And that is one reason, I would argue, why cognitive science has had less impact on activities that revolve around the manifest image of the person than might have been expected.
 The same gap may explain something of the somewhat fragmented and scholastic state of the functionalist model of the mind.
 In much the same way as we do not know how to map manifest image phenomena onto any mechanistic model, we do nt know how to map manifest phenomena onto any of the models of the current flavours of functionalism.
 Dennett and Fodor: Two Approaches to the Manifest Image Dennett and Fodor between them have the two most prominent strategies for addressing the problem at the moment.
 It is helpful to consider their approaches in the context of something specific, so let us return to one of the features of the manifest image mentioned earlier about which more needs to be said, our inclination to think of persons in it as being or containing a homunculus at the centre of our representational world.
 It is likely that this picture probably underiies all the other aspects of the manifest image mentioned above.
 Dennett's approach to the manifest image is to eliminate the problem by eliminating the image, at least as anything worth taking seriously.
 His book on consciousness (1991) is a most thoroughgoing attempt to undermine our conviction that something of substance corresponds to the manifest image.
 With respect to our specific inclination to think of ourselves and others in terms of a grand homunculus, Dennett attempts, via a variety of ingenious thoughtexperiments, to eliminate any urge to think that there might be something that accords with this inclination.
 His approach, oversimplified a bit, is to urge that the problem is our sense that there is a problem.
 There is no problem.
 W e think there is only because w e misinterpret phenomenology in certain natural ways, phenomenology being the way w e appear to ourselves and to others.
 I do not think this move will take us far.
 Here is why.
 In my view, Dennett's approach merely shifts the problem.
 The puzzle now becomes the phenomenology itself: what could produce 98 such a thing as a sense that I am a homunculus? H o w could we have been led so astray  how could a conception of such profound, even ineliminable social importance as our manifest conception of the person be at it core nothing more than a huge mistake? (This in outline is all I think most eliminative strategies achieve; they just shift the puzzle.
) By contrast, Fodor is wilUng to mechanize the manifest image, or try.
 His approach is to chip away at the edges: sort out a syntax module here, a vision module there, and postpone the rest to a better day.
 The problem with this approach is that, while the chips are eminently worth knocking oif and we have learned a great deal about the abstract and in the case of vision even the neural structure of some encapsulated, nonconscious subsystems by doing so, the central person, the big homunculus, is not touched and remains as much a mystery as ever.
 All Fodor's and others' discoveries about the various nonconscious cognitive subsystems in a person have done is to shrink the range of the unified subject and agent, shrink the homunculi.
 They have done little or nothing either to discharge it or to tell us what it is like.
 Fodor seems to be beginning to worry about this himself; his latest book (1994) contains a number of uneasy references to the centrality of consciousness and his inability to say anything informative about it.
 W h y do we need to reduce' the homunculi? W h y not adopt Dennett's strategy and just ignore it or explain it away? For this reason.
 O n the one hand, we cannot dispense with it; w e could as soon dispense with the language of love, law, psychology, motive, feeling, and representation.
 O n the other hand, as the Churchlands and others have pointed out, the manifest image does not take us very far.
 In fact, it works at all only so long as the person being explaining is functioning well.
 Introduce any amount of cognitive or emotional damage or breakdown and the manifest image instantly claws the air', as Paul Churchland puts it (1984, p.
 46).
 And so on.
 Abandoning the manifest image is not one of our options (on this point I do not agree with the Churchlands) but abandoning the drive to capture it in mechanical models that illuminate and help us understand it is not an option either.
 With respect to the two images, most researchers in cognitive science right now are either manifest image extenders or manifest image ignorers.
 There are few manifest image reducers around.
 Philosophers are prominent in the first group: they spend most of their time trying to find ways to capture manifest image phenomena in extensions and developments of the same kind.
 These folk worry hardly at all about how their ideas might be realized in a computational system.
 The second group is made up of most of the rest of cognitive science  the researchers who spend their time developing ever deeper and broader postulational models.
 These folk give little thought to how their models can capture manifest image phenomena.
 Sometimes one finds both sides in a single researcher, yet totally disconnected.
 I am thinking of cognitive psychologists I have known, for example, who work with almost nothing but a postulational model in their labs, but delight in playing around with notions such as the unity of consciousness outside it.
 W h a t is Missing? What is missing on both sides is an effort to bring the two images together, to find postulational, computational accounts that illuminate phenomena of our everyday experience of ourselves and others.
 And that, I contend, is one reason why cognitive science has not made more progress.
 In the absence of robust roots in experience, we not only do not know how to assess a model, we do not even know how to take it.
 As Dennett once said on a related issue, clearly a meeting of minds is in order.
 References Brook, A.
 (1994).
 Kant and the Mind.
 Cambridge University Press.
 Churchland, P.
 (1984).
 Matter and Consciousness.
 Bradford Books/MIT Press.
 Dennett, D.
 (1991).
 Consciousness Explained.
 Little, Brown.
 Flanagan, O.
 (1984).
 The Science of the Mind.
 Bradford Books/MIT Press.
 Fodor, J.
 (1983).
 The Modularity of Mind.
 Bradford Books/MIT Press.
 (1994).
 The Elm and the Expert.
 Bradford Books/MIT Press.
 Freud, S.
 (1895).
 Project for a scientific psychology.
 Standard Edition of the Complete Psychological Works of Sigmund Freud, trans and ed J.
 Strachey.
 Hogarth Press and Institute of PsychoAnalysis.
 Kant, I.
 (1781).
 Critique of Pure Reason.
 Trans.
 Norman K e m p Smith as: Immanuel Kant's Critique of Pure Reason.
 Macmillan, 1963.
 Sellars, W .
 (1963).
 Philosophy and the scientific image of man.
 In: Science, Perception and Reality, pp.
 140.
 Routledge and Kegan Paul.
 Shoemaker, S.
 (1968).
 Selfreference and selfawareness.
 J.
 of Phil.
 65 no.
 20 (1968), pp.
 555567.
 Taylor, C.
 (1985).
 Philosophical Papers, 2 vols.
 Cambridge University Press.
 Williams, B.
 (1973).
 Problems of the Self Cambridge University Press, esp.
 Ch.
 3, The self and the future.
 99 Is Cognitive Science Truly Interdisciplinary?: T h e Case of Interdisciplinary Collaborations Christian D.
 Schunn Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 schunn+Qcmu.
edu Takeshi Okada Learning and Research Development Center University of Pittsburgh Pittsburgh.
 PA 15260 takeshi+@pitt.
edu Kevin Crowley Dcpiutment of Psychology University of Cjilifomia Santa Cruz, C A 95064 c r o w l e y @ z z y x .
 u c s c .
 e d u Abstract The field of cognitive science is inherently multidisciplinary.
 However, it is unclear to what extent truly interdisciplinary work occurs in cognitive science.
 That is, is cognitive science merely a collection of researchers from different disciplines working separately on common problems? Data gathered from a recent cognitive science conference are presented.
 Interestingly, a significant proportion of interdisciplinary collaborations were found.
 Analyses were also conducted on the impact of same vs.
 different backgrounds on the structure of collaborations, and It was found that interdisciplinary collaborations involved more equally distributed contributions among the authors than did intradisciplinary collaborations.
 I n t r o d u c t i o n What is cognitive science? In their article, "Foundations of Cognitive Science," Simon and Kaplan (1989) define cognitive science as "the study of intelligence and intelligent systems, with pjuticular reference to intelligent behavior as computation (p.
 1).
" Other definitions might include the particular class of problems that cognitive scientists study (e.
g.
, memory, reasoning, problem solving, language processing, etc.
).
 Whatever the definition of the particular content areas under investigation, it is clear that cognitive science is inherently interdisciplinary.
 In fact, the journal Cognitive Science has the following subtitle: " A multidisciplinary journal of artificial intelligence, linguistics, neuroscience.
 philosophy, psychology".
 Similarly, the bulletin board Netnews.
sci.
cognitive has the following definition in its first post: "Cognitive science is an interdisciplinary investigation of cognition, involving cognitive psychology, artificial intelligence, computer science, humancomputer interaction, philosophy of mind, philosophy of science, linguistics, neuroscience, cognitive c'lnthropology and other disciplines.
" Thus, at its core, cognitive science is defined as being interdisciplinary.
 However, there are two senses in which a field m ay be interdisciplinary, and it is unclear in which sense cognitive science is interdisciplinary.
 In the first sense, reseju'chers from vjirious disciplines work on related issues, and publish in the .
same journals, but they do not work together on the sjune reseiU"ch projects, nor do they use methodologies from multiple disciplines on the same projects.
 For example, a computer scientist might present a model of language processing at a cognitive science conference without regitfd to hum;ui data or linguistic theory.
 Conversely, a psychologist might present data from a language processing experiment at a cognitive science conference without discussing its relation to linguistic theory or computational models of language processing.
 In both cases, scientists from different areas are working on related problems, and are presenting at the same conference.
 However, they are.
 working on separate projects, and they are using separate, disciplinespecific methodologies.
 W e call this type of work weakly interdisciplinary.
 In the second sense of interdisciplinary, researchers from various disciplines work together on the same projects or they use methodologies from multiple disciplines on the same research projects.
 For example, a computer scientist and a psychologist might present a simulation of language processing and an experiment designed to test the predictions of the simulation in humiui subjects.
 Alternatively, a psychologist might present data from psychological experiments of language processing, but also discuss the implications of the experiments for current models of language processing.
 W e call this type of work strongly interdisciplinary.
 W h e n there is a significant proportion of strongly interdisciplinary work in an field, the field becomes more than just the sum of its constituent disciplines.
 W e take the goal of cognitive science to involve strongly interdisciplinary work.
 In the informauon to authors section of the journal of Cognitive Science, it is made clear that "Reports written for multidisciplinary audiences are given the highest priority.
" However, desire does not equal reality: departments can often be insular; receiving training from other departments during graduate studies can often be difficult because of bureaucratic barriers or a lack of introductory courses; and communication across deparunents is often minimal.
 Thus, more evidence needs to be gathered to demonstrate that cognitive science is as it was created to be—strongly interdisciplinary.
 As partial evidence that cognitive science involves some strongly interdisciplinary work, many institutes and departments of cognitive science have been created over the last 15 years, supposedly providing a research environment supportive of interdisciplinary work.
 However, the majority of work in cognitive science is not conducted at such places.
 Of articles published in the last two years in the journal of Cognitive Science, only 9 % (3 of 35) articles involved authors from departments or institutes of cognitive science.
 For the Annufil Meeting of the Cognitive Science Society of the last two years, only 1 1 % (22 of 165 for the 1994 meeting, c'md 15 of 157 for the 1993 meeting) of the papers involved work conducted at departments or institutes of 100 mailto:crowley@zzyx.
ucsc.
edu"Z o 200, u ^ 150 i t 501 r—, rn T r"T I S3 84 85 86 87 T e o s .
a a o U o e 60| 504030 20100 18 89 90 91 92 93 94 95 Year # of Authors • O v s O o * one O  Q .
.
O' .
^o^.
a .
o—o ,.
o  o 83 84 85 86 87 88 89 90 91 92 93 94 95 Year o o — a — *two three four five+ Figure 1: The total number of submitted papers and posters for each Annual Meeting of the Cognitive Science Society, and the percentage of papers at each author level.
 cognitive science.
 Thus, despite the existence of departments of cognitive science, the majority of cognitive science researchers still reside within the more traditional departments, Jind are consequently subject to problems of insularity from other work conducted in other discipUnes.
 Another test for the presence of strongly interdisciplinary work is the existence of interdisciplinary collaborations.
 Collaborations in general have formed an increasingly importcuit role in the sciences over the last 100 years (Thagard, 1994).
 Over the somewhat briefer history of cognitive science, collaborations have also grown in frequency.
 Figure 1 presents the percentage of multiauthor papers and posters presented at each Annual Meeting of the Cognitive Science Society for the last thirteen years (as well as the total number of papers and posters presented).
^ W e only present data from 1983 on, since 1983 is the first year in which submissions were reviewed.
 From the figure, it is evident that the period from 1983 to 1995 represents a significant growth period in cognitive science—the number of papers in the conference grew approximately fourfold over the thirteen yefus.
 In that time, proportion of multiauthor papers grew gradually by twenty percent.
 The decrease in single author papers (and therefore increase in multiauthor papers) was statistically significant (/(11)=4.
4, p<.
002).
 Moreover, over the thirteen yeius, the model number of authors has gone from one author to two authors.
 Thus, collaborations, for whatever reason, are a dominant feature of work in cognitive science.
 ' These figures included submitted papers and posters only.
 Symposia and invited papers were not included Although there are a significant number of collaborations in cognitive science, it is unclear how many of them are interdisciplinary.
 The growth in the number of collaborations in cognitive science could simply reflect the growth in intradisciplinary collaborations that is occurring in each of the component disciplines rather than a growth in interdisciplinary collaborations.
 Since the majority of the research was conducted in traditional departments rather than interdisciplinary insUtutes, it would not be surprising if there were few interdisciplinary collaborations—physical proximity is a strong factor in the occurrence of collaborative research (Kraut, Egido, & Galegher, 1990).
 The primary goal of the research presented in this article is to assess the presence of interdisciplinary collaborations in cognitive science.
 However, another reason for being interested in interdisciplinary collaborations is the role they play in science in general.
 Various researchers in the psychology of science have argued that interdisciplinary collaborations are more likely to be successful than intradisciplinary collaborations.
 For example, Dunbar (1994; Dunbar & Baker, in press) found that microbiology laboratories were more likely to make progress on the problems they were investigating when the laboratories were composed of researchers from different backgrounds than when the laboratories were composed of researchers from the same background.
 Dunbar argued that having different backgrounds provided a larger database of experience that could be applied analogically to the current problems under study.
 Similarly, in a review of several historical cases, Okada (1994) argued that highly successful collaborations in science typically involved researchers from different backgrounds (see also Okada, Schunn, Crowley, Oshima, Miwa, 101 Aoki, & Ishida, 1995).
 Thus, a secondary goal of the research presented here is to investigate further the impact of interdisciplinary collaboration on the research project.
 The prim;u7 goal is about cognitive science in particuku", Jind the secondary goal is about the nature of scientific collaborations in general.
 The methodology used in our study involved a questionnaire given to conference presenters.
 T o gather information about backgrounds of collaborators, w e did not wish to rely on a simple analysis of affiliations listed in the conference proceedings—departmental affiliations are not necessarily good indicators of training backgrounds, especially in the case of multidisciplinary departments iind institutes.
 Instead, w e gathered infonnation about the training backgrounds of the members of collaborative research projects.
 This information was gathered through interviews with authors of multiauthor papers presented at a recent Cognitive Science Society meeting.
 There is one further factor that deserves some discussion: not all collaborations are of the same type.
 Of particular relevance to our study, not all collaborations involve equalstatus individuals.
 Instead, some collaborations involve employer/employee and teacher/student collaborations.
 It may be that the nature of these differentstatus collaborations is unlike that of the equalstatus collaborations.
 In particular, these collaborations are less likely to be interdisciplinary, since students usually work with professors from their own department.
 T o investigate the potential role of these different types of collaborations, w e added professional level to all of the analyses.
 Methods Overview The study consisted of two methods of data collection.
 The first method involved short interviews with the first authors of posters during the poster session.
 The second method involved questionnaires sent to the first authors of papers and panel posters.
^ Subjects were asked about the backgrounds of each of the authors of the presented work, and about the professional status of each author.
 Subjects were also asked about the role each of the authors played in the various stages of the research presented at the conference.
 Participants All participants were paper and poster presenters at the 16th Annual Meeting of the Cognitive Science Society held in Atlanta, G A on August 1316, 1994.
 Permission to conduct the study was obtained from the conference organizers.
 There were 29 multiauthor posters in the traditional poster session.
 All first authors were contacted by electronic mail to ask for permission to interview them during the poster session.
 Twenty (69%) of the first authors responded.
 iUl in the jiffirmative.
^ However, due to time restrictions, only 17 of the interviews were conducted.
 There were 83 papers and panel posters with multiple authors.
 All fû st authors were sent a short questionnaire by Einail.
 Fiftythree (64%) were completed and returned.
 Procedure Poster interviews.
 The first authors of multiauthor poster presentations were contacted in advance of the conference by Email.
 Participants were given a brief description of the purpose of the study.
 They were also informed the study was not an official activity of the conference, and they were under no obligation to participate.
 Further, they were infonned that all responses would be kept confidential.
 At the conference, participants were approached during the poster session when they had a spare moment.
 The interviews were approximately five minutes in length.
 During the interview, the participants were asked questions about each of the authors of the poster.
 The fust question inquired about which area was the primary background or training of each author (e.
g.
, computer science, linguistics, psychology, medicine, philosophy, etc.
.
.
).
"* The second question inquired about the professional status of each author as the presented research was being conducted (e.
g.
, research assistant, undergraduate, graduate, postdoc, faculty, clinician, etc.
).
 The third and final question was about the role each author played in the research project.
 In particular, the participants were asked which authors had played a major role in each of the following categories: (a) selecting the research question; (b) designing the study or simulation; (c) providing the materials for the study or simulation; (d) running the studies or simulations; and (e) writing the paper.
 Email questionnaires.
 The first authors of multiauthor papers and panel posters were contacted one month after the conference by Email.
 A s with the poster interviews, the participants were given a brief description of the purpose and nature of the study.
 Further, they were also informed that the study was not an official activity of the conference, that they were under no obligation to participate, and that all responses would be kept confidential.
 At the end of the mail message, they were presented with a questionnaire version of the questions given in the poster interviews.
 Participants were asked to complete the questionnaire, and respond by Email.
 Coding Since there were only two papers with more than 4 authors, only the data for the first 4 authors of each paper were coded.
 Responses to the background questions were classified into the following categories (with frequencies): cognitive psychology (86), computer science (54), linguistics (11), educational psychology (5), engineering (4), philosophy (3), ^ This particular conference involved special panel poster sessions in addition to the traditional poster session.
 In these special sessions, thematic groups of presentations were presented together, and were followed by a discussant.
 ^ In four cases, it was the second author who presented the poster and granted permission for the interview.
 ^Here we focus on the case of interdisciplinary collaborations.
 W e will consider the case of collaborations involving collaborators with different backgrounds within the same discipline in the discussion.
 102 medicine (3), mathematics (3), cognitive engineering (1).
 W h e n two background disciplines were listed, the first discipline listed was used.
 W h e n cognitive science was (lie first discipline listed, the secondary discipline listed was used.
 Responses to the professional status questions were classified into one of four levels (with frequencies): research assistant/undergraduate (10), graduate (63), postdoctoral fellow/junior researcher (15), faculty/senior researcher/clinician (86).
 These professional status levels were used to determine whether collaborations were equal status or different status collaborations.
 For the research roles question, an author was considered to have made a contribution to one of the categories if they were listed in that category, unless some note added that they had made only a minor contribution to that category.
 Then, the number of research roles to which each author contributed was tabulated.
 For example, if author A chose the research question, designed and ran the experiment, and wrote the paper, whereas author B provided the materials, and helped write the paper, then author A would be counted as having contributed to 4 roles and author B would be counted as having contributed to 2 roles.
 The distribution of number of roles assigned to authors (independent of authorship order) is presented in Table 1.
 The mean number of roles assigned to each author was 2.
8 (SD=1.
5).
 Table 1: The frequency of number of roles assigned to each author independent of authorship order.
 # of roles 0 1 frequency | 11 27 31 38 44 22 Results & Discussion Overview The results are divided into two sections.
 In the first section, we assess the frequency of interdisciplinary collaborations.
 In the second section, we assess the structure of different collaboration types.
 Three variables are considered in both sections: testing format (interview/Email), professional level (same/different), and background (same/different).
 Frequency of Interdisciplinary Collaborations D o interdisciplinary collaborations occur ftequently in cogninve science? Overall, 4 7 % (33 of 70) of the collaborations at the conference were interdisciplinary (i.
e.
, had authors from at least two disciplines).
 If only the first 2 authors are considered, 4 0 % of collaborations were interdisciplinary.
 These percentages in conjunction with the overall rate of collaborative research imply that interdisciplinary collaborations represent approximately 3 2 % of all contributions (i.
e.
, individual and collaborative combined).
 Another method of assessing the frequency of interdisciplinary collaborations is to use the departmental affiliations listed in the papers.
 Using this measure, 3 7 % (41 of 112) of all the collaborative contributions to this conference involved interdisciplinary collaborations.
 This number is likely to be an underestimate of interdisciplinary collaborations given that some sets of collaborators listed interdisciplinary institutes as their primary affiliations.
 However, despite potential biases, this measure provides a similar order of magnitude estimate for the frequency of interdisciplinary collaborations in cognitive science.
 What was the frequency of interdisciplinary collaborations across the various constituent disciplines? To answer this question, w e analyzed how often each discipline was paired with each other discipline.
 For simplicity, only the first two authors were considered.
 All of the interdisciplinary collaborations involved either cognitive psychologists or computer scientists.
 Table 2 presents the frequency of each discipline combination (the middle two columns), as well as the frequency of intradisciplinary collaborations for comparison (the rightmost column).
 The order of authorship is not represented.
 Interestingly, all of the disciplines except for cognitive psychology had at least as many or more interdisciplinary than intradisciplinary collaborations.
 Did interdisciplinary collaborations occur equally often for same level (peer) collaborations than for different level collaborations? One might expect same level collaborations are more likely to be interdisciplinary than different level collaborations.
 Surprisingly, the effect of professional level (same/different) on the frequency of interdisciplinary collaborations was not significant (x^(l)<l, p > .
 5 considering all authors, and x^(l)<l, P>4 considering only the first two authors).
 That is, there was an overall high level of interdisciplinary collaborations, both for equal status and different status collaborations.
 However, there was a trend towards a greater number of interdisciplinary collaborations in equallevel collaborations than differentlevel collaborations (see Table 3).
 Table 2: Interdisciplinary and intradisciplinary collaborations among the disciplines (between first and second authors).
 Discipline Cognitive Psychology Computer Science Educational Psychology Linguistics Philosophy Medicine Cognitive Engineering Engineering Interdisciplinary Co^ Psychology 13 3 2 1 1 1 0 Collaborations w/ C o m p u t e r Science 13 0 3 2 1 0 1 Intradisciplinary Collaborations 24 14 1 2 0 0 0 1 103 i | 4) w 3 n 2.
5 0 .
 1.
5 1 5 I 2 4 ^ 3 e 2 Different ;kgrounds Same Backgrounds Same Background Different Background First Author Second Author Figure 2: (a) The mean absolute difference in number of roles, and (b) the me;ui number of roles to which the first and second authors contributed as a function of whether the authors were from the siune or different backgrounds (with SD).
 Table 3: Frequency of inter & intradisciplinary collaborations for same & different level collaborations (with column percentages).
 Background Same Different Same Level Different Level 7 (50%) 7 (50%) 35 (62%) 21 (38%) Finally, we analyzed whether the results were consistent across the two testing formats.
 It was also surprising that there were more interdisciplinary collaborations in the interview condition than in the Email condition (x^(l)=4.
96, p<.
03 considering all authors, and x^(l)=8.
7, p<.
005 considering only the first two authors).
 In the Email condition, 4 0 % of the collaborations involved at least two disciplines, whereas 7 1 % did in the interview condition.
 It is likely that these differences are due to the type of presentation format rather than method of data collection.
 That is, the interviews involved posters from the general poster session, whereas the Email questionnaires involved panel posters and papers organized into thematic groups.
 Thus, the interdisciplinary collaborations were less likely to be classifiable into a simple category, and so they were more likely to be assigned to the general poster session.
 However, whatever the cause of the condition differences, there was a fairly high overall percentage of interdisciplinary collaborations.
 The Effects of Interdisciplinary Collaborations One would expect interdisciphnary collaborators to be more likely to have important independent contributions to the research project, since they are bringing nonoverlapping knowledge to the research project.
 By contrast, in the case of intradisciplinary collaborations, the collaborators are not as likely to bring nonoverlapping knowledge to the project.
 Since the rewards of research are linked to authorship order, there is some pressure for one of the collaborators to lake a primary role.
 As a result, w e would expect interdisciplinary collaborators to contribute more equally to the research project than intradisciplinary collaborators, since equal Table 4: Mean (and SD) number of roles assigned to each author as a function of authorship order.
 Order 1 # of roles I 3.
9 (.
8) 2.
2(1.
4) 1.
9(1.
2) 2.
0 (.
6) contribution is more likely to be necessary (because of nonoverlapping knowledge) in the interdisciplinary case.
 To test these hypotheses, we used the number of roles to which each author contributed as a measure of degree of contribution.
 As expected, overall there was an effect of authorship order on the number of roles (F(3,170)=36.
0, pK.
OOOl), with the first author contributing to the greatest number of roles (see Table 4).
 To test the influence of collaboration makeup, we computed an A N O V A on the mean absolute difference in the number of roles to which the first and second authors contributed as a function of whether the first and second authors were from the same or different backgrounds (see Figure 2a).
^ Intradisciplinary collaborations had a significantly greater difference in the number or roles than interdisciplinary collaboraUons (F(l,68)=3.
9, p<.
05).
 confirming our expectations.
 To test whether these results also held across testing fomiats (interview or Email), and professional level (same status vs.
 different status), further A N O V A ' s were conducted.
 There were no significant main effects of testing format (F(1,62)<1, p>.
9) or professional level (F(1,62)<1, p>.
9) on the mean difference in number of roles.
 Furthermore, there were no significant interactions of background with testing format (f(l,62)<l, p > A ) , background with professional level (F(1,62)<1, p>.
6), or testing format with professional level (F(1,62)<1, p > J ) .
 Thus, the main effect of background held across both types of collaborations and data collection methods.
 ^ The 3+ author case is difficult to analyze, since it is unclear which pairings of background types and role differences to include.
 However, since the first two authors are likely to be the primary contributors to the project, using only the first two authors is likely to be a good first approximation.
 104 However, the preceding analyses do not indicate whether the first authors contributed less in the interdisciplin;iry collaborations, or whether the second authors contributed more in the interdisciplinary collaborations.
 To investigate this issue, a 2 (same background/different background) X 2 (first author/second author) A N O V A was conducted on the number of roles to which each author contributed (see Figure 2b).
 The background similarity by author order interaction was statistically significant (F(l,68)=7.
1,p<.
01)—there was no effect of background similarity on first author contributions, whereas there was an effect on second author contributions.
 Thus, the interdisciplinary collaborations involved an increased presence of the second authors.
 General Discussion The primary goal of this study was to investigate the presence of strongly interdisciplinary work in cognitive science.
 W e found that there are, in fact, a significant proportion of interdisciplinary collaborations in cognitive science.
 Interestingly, there was almost as high a proportion of interdisciplinary teacher/student collaborations as interdisciplinary peer collaborations.
 While a simple survey of this type can not be conclusive, it is very suggestive: not only does cognitive science expose people to work from other disciplines, it involves strongly interdisciplinary work, suggesting that cognitive science is more than just the sum of its constituent disciplines.
̂  The secondary purpose of this study was to investigate the impact of the diversity of backgrounds among collaborators on the structure of the collaboration.
 Various researchers (e.
g.
, Dunbar, 1994; Okada, 1994) in the area have hypothesized that collaborations among scientists with differing background knowledge are more likely to be successful than collaborations among scientists with the same background knowledge.
 W e have found that interdisciplinary collaborations tend to be more balanced.
 In particular, we found that second authors tended to contribute more to interdisciplinary collaborations than to intradisciplinary collaborations.
 The findings of this study must be approached with caution due to the following methodological concerns: 1) we have used a very short and simple questionnaire; 2) data was only collected from the first authors; 3) relying on data from responses via Email may have biased the results (either in favor of Email literate researchers and/or in favor of researchers with an interest in interdisciplinary collaborations); and 4) number of roles to which an author contributes is a crude measure of intellectual input.
 However, as a first pass, this study has provided some suggestive and interesting data.
 Furthermore, a simple analysis of departmental affiliadons found a similar order of magnitude of interdisciplinary collaborations.
 W e are currently seeking to replicate and extend our findings using more detailed investigations of collaborations.
 For example, in one study, we are focusing on famous collaborators, and are using indepth interviews with both members of the collaborations.
 In another study, we are using more detailed questionnaires about ongoing collaborations (e.
g.
, Okada, Schunn, Crowley, Oshima, Miwa, Aoki, & Ishida, 1995).
 In particular, we will be interested in whether background factors will predict future collaborations and collaborative success.
 There is one further important issue that w e have neglected thus far: what consntutes different backgrounds.
 While we have focused on the case of interdisciplinary collaborations, intradisciplinary collaborations may also involve collaborators with different backgrounds.
 These withindiscipline training differences can result from studying different problems (e.
g.
, categorizafion vs.
 language processing), or being trained at schools with different general approaches (e.
g.
, casebased vs.
 rulebased reasoning).
 Thus, the same background/different background dimension is actually a continuum of background overlap.
 Further research is necessary to determine whether these within discipline differences have a similar impact on the structure of the collaboration.
 Acknowledgements This research was supported by a grant from the Mitsubishi Bank International Foundation to all three authors, and by a F C A R graduate fellowship to the first author.
 W e would like to thank to Ashwin R a m for his assistance in the project, and to Beth LitUeton and two anonymous reviewers for comments made on earlier drafts of this paper.
 W e would also like to thank all those that participated in this study.
 References Dunbar, K.
 (1994).
 How scientists really reason.
 Scientific discovery in realworld laboratories.
 In R J.
 Sternberg, & J.
 Davidson (Eds.
) Mechanisms of Insight.
 M I T Press.
 Dunbar, K.
, & Baker, L.
 (in press).
 Goals, analogy and the social constraints of scientific discovery.
 Behavioral and Brain Sciences.
 Kraut, R.
 E.
, Egido, C , & Galegher, J.
 (1990).
 Patterns of contact and communications in scientific research collaboration.
 In J.
 Galegher, R.
 E.
 Kraut, & C.
 Egido (Eds.
), Intellectual teamwork: Social and technological foundations of cooperative work.
 Hillsdale, NJ: Erlbaum.
 Okada, T.
 (1994).
 Collaborative concept discovery in a scientific domain.
 Unpublished dissertation.
 Psychology Department, Carnegie Mellon University.
 Okada, T.
, Schunn, C.
 D.
, Crowley, K.
, Oshima, J.
, Miwa, K.
, Aoki, T.
, & Ishida, Y.
 (1995).
 Collaborative scientific research: Analyses of historical and interview data.
 Paper to be presented at the 1995 Meeting of the Japanese Cognitive Science Society.
 Simon, H.
 A.
, & Kaplan, C.
 A.
 (1989).
 Foundations of cognitive science.
 In M.
 I.
 Posner's (Ed.
), Foundations of cognitive science.
 Cambridge, M A : M I T Press.
 Thagard, P.
 Collaborative knowledge.
 In the Proceedings of the 16th Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Erlbaum.
 "Whether this strong presence of interdisciplinary work is entirely representative of the work that is conducted or just of the work that is published remains to be seen.
 105 A 4Space M o d e l of Scientific Discovery Christian D.
 Schunn Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 schunnQcmu.
edu David Klahr Depiirtment of Psychology Carnegie Mellon University Pittsburgh, PA 15213 klahr@cmu.
edu Abstract An extension of Klahr and Dunbar's (1988) Dual space model of scientific discovery is presented.
 W e propose that, in addition to search in an experiment space and a hypothesis space, scientific discovery involves search in two additional spaces; the space of data representations and the space of experimental paradigms.
 That is, discoveries often involve developing new terms and adding new features to descriptions of the data, and the also often involve developing new kinds of experimental procedures.
 The 4space model was motivated by the analysis of human performance in a discovery microworld.
 A brief description of the data is presented.
 In addition to the general 4space framework, a description of the component processes involved in each of the four search spaces is also presented.
 O v e r v i e w One fruitful characterization of scientific discovery is to view it in terms of search in two problem spaces: a space of hypotheses and a space of experiments (Klahr & Dunbar, 1988; Simon & Lea, 1974).
 This characterization can be used to classify discovery models into three groups.
 First, there are those that address the processes of hypothesis generation and evaluation (e.
g.
, the B A C O N models (Langley, Simon, Bradshaw, & Zytkow, 1987), C O P E R (Kokar, 1986), and E C H O (Thagard, 1988)).
 Second, there are those that address the process of experiment generation and evaluation (e.
g.
, D E E D (Rajamoney, 1993), and D I D O (Scott & Markovitch, 1993)).
 Third, there are those that address both processes (e.
g.
, K E K A D A (Kulkami & Simon, 1988), S T E R N (Cheng, 1990), and S D D S (Klahr & Dunbar, 1988)).
 Based on our analysis of subject performance in a complex computer microworld, we have extended the 2space framework to a 4space framework.
 In the new framework, what was previous conceived as the hypothesis space has now been divided into a data representation space and a hypothesis space.
 In the data representation space, representations or abstractions of the data are chosen from the set of possible features.
 In the hypothesis space, hypotheses about causal relations in the data are drawn using the set of features in the current representation.
 Similarly, the old experiment space is now divided into an experimental paradigm space and an experiment space.
 In the experimental paradigm space, a class of experiments (i.
e.
, a paradigm) is chosen which identifies the factors to vary, and the components which are held constant.
 In the experiment space, the parameters settings within the selected paradigm are chosen.
 W e made these changes as we began to scrutinize the human performance data from several discovery microworlds in preparation for the computational implementation of the 2space model.
 It became clear that, during the course of their investigations of the domain, subjects often acquired new data representations, and developed new kinds of experiments.
 Furthermore, representation and paradigm selection appear to require different mechanisms from those necessary for hypothesis and experiment selection.
 Our goal is to produce a model of processing in all 4 problem spaces.
 This model will consist of separate components corresponding to processing in each of the four problem spaces.
 However, as indicated in Figure 1, processing within each space is dependent upon the current state of the search in the other spaces.
 For example, experiment space search depends upon the available experimental paradigms as well as the current hypothesis.
 The arrows between the four spaces are those implied by the processes that we have found to exist—others connections may also exist.
 Given these strong interdependencies, there is great advantage to implementing each of the components in a unified model.
 Paradigm >, Space ̂ y ' Representation Experiment Space Hypothesis Space Figure 1: Information flow between the 4 search spaces.
 Before presenting the details of the model, we will provide a brief description of the task and data that lead to the new model.
 The Discovery Task The task that contributed the data for our model design is a complex computer microworld called MilkTruck (Schunn & Klahr, 1992, 1993), in which subjects conducted experiments to discover the action of a complex mystery function.
 In the microworld, a "milk truck" executed a sequence of actions associated with a dairy delivery route.
 At any of 6 different locations along its route, it could beep its horn, deliver milk or eggs, or receive money or empties.
 A program consisted of a sequence of up to 14 actionlocation pairs.
 After the route had was entered, the subject 106 mailto:klahr@cmu.
edu1 Program •=^D) ih ^ 6 1 2 3 2 k a 1 Trace | 1 | •=3)) M fffl 1 3 2 1 Program •=^D) ® f ^ •^31 IS ® a 6 3 6 2 3 1 3 5 5 P Trace 12 | if<!̂ ) (̂  ® ^ >:<l̂ ) ® a 3 6 1 2 3 3 5 Figure 2: T w o example programs and outcomes.
 pressed 'RUN' and the milk truck executed its route on the screen.
 The milk truck went to each location on the programmed route in the order that it was programmed, and animated icons demonstrated what transpired at each location.
 In this task, subjects were given a great deal of external memory support.
 As subjects entered their programs, the steps were displayed on the screen in the program listing.
 Also, as the route was completed, a trace listing displayed in program format what transpired during the run (see figure 2).
 The subjects were also given access to all previous programs and traces.
 The subject's task was to discover the function of a mystery command called 8 (delta), which was a complex function with three arguments: a number (1  6), a triangle (white or black), and a Greek letter (a or P).
 W h e n 5 was not used, the trace listing was identical to the program listing.
 However, 5 could change the order of delivery, and the resultant route execution and its associated trace would then be discrepant from the program listing.
 The effect of 8 was to reorder the execution of part of the program according to the values of its three arguments (see Table 1).
 Table 1: For the last N steps in the program, 6 reorders the execution sequence of the program by.
.
.
 ^ (increasing) ^ (decreasing) a (item) P (house) .
Item in mcreasmg keypad order.
 .
house in increasing number order.
 .
.
.
item in decreasing keypad order.
 .
.
.
house in decreasing number order.
 The subjects were Carnegie Mellon University undergraduates.
 Subjects typically took part in a single, 1 hr session.
 Following an introduction to the basics of the MilkTruck domain, the syntax of 8 was described, and the goal of discovering the effect of 8 was presented to the subjects.
 In the discovery phase, subjects designed, conducted, and analyzed experiments with the goal of in the data in subjects' Early in the experimental discovering the role of 5 and its arguments.
^ The subjects worked at the discovery task until they had solved it, or they wished to give up.
 The Data Data was collected from over 100 subjects across various conditions.
 Both keystroke and verbal protocols were collected.
 Here, we present a very brief description of the characteristics of subjects' behavior that led us to the creation of the 4space model.
 In particular, w e will focus on the evidence which suggested the addition of the experimental paradigm and data representation spaces.
 Data motivating the details of the experiment and hypothesis space processes can be found elsewhere (e.
g.
, Schunn & Klahr, 1992,1993, 1995).
 The primary evidence for activity representation space involved changes descriptions of experimental outcomes.
 sessions, subjects typically described outcomes in terms of series of movements of single steps.
 For example, with program 2 of figure 2, subjects early on in the discovery session would describe this outcome as follows: the third step moved to the fourth position, the fourth step moved to the fifth position, and the fifth step moved to the third position.
 Later in the sessions, subjects began to give descriptions for, and hypothesize about, the same kinds of experimental outcomes in terms of movements of segments of the program.
 For example, with program 2 of figure 2, subjects later on in the session would describe this outcome as follows: the last five steps were reorganized by increasing house number.
 While one might argue that these changes were merely redescriptions or reorganizations of the same features, subjects also added completely novel features to their descriptions (e.
g.
, the number of times the milk truck changed directions during the route; the number of times the milk truck driver jumped up and down at the end of the route).
 This kind of evidence led us to hypothesize that subjects changed the way in which the basic data was used by adding and deleting features to their data representations.
 The primary evidence for activity in the experimental paradigm space derived from subject statements about their plans for experiment selections and changes in these plans over the course of the problemsolving session.
 Initially, subjects had very few kinds of experiments from which to select.
 Their typical programs simply involved selecting a small number of houses and items without further constraints or forethought (e.
g.
, program 1 of figure 2).
 Later in the session, subjects began to develop more complex kinds of experiments.
 For example, a subject might design a program of the following type: a long program with two more steps than the 6 number argument, houses and items all different and not in order (e.
g.
, program 2 of figure 2).
 Subjects also developed multiprogram paradigms.
 For example, a subject might decide to conduct a sequence of five programs with the Same base program, varying only the ' In this context, a program is an "experiment" and a statement about how the parameters work is a "hypothesis".
 107 6 number pjirameter.
 Subjects leiirned to generate these complex, very deliberately chosen experiments quite rapidly, indicating that their were choosing experiments from a newly compiled database of experiment types.
 The Model The 4space model consists of more than just the four search spaces; there are also the constituent search processes within each space (see Table 2).
 A brief description of the processes that we have found to occur within each of the spaces is presented below (iUthough there are likely to be many more than this).
 These descriptions also serve to further illustrate the relationships between the four spaces.
 Table 2: The component processes within each of the search spaces of the 4space model.
 Space Experimental Paradigm Experiment Data Representation Hypothesis Process hypothesis testing analogy error analysis rep/ hyp change theory orientation complexity management risk regulation noticeinvariants analogy bruteforce search piecemeal induction representational mapping popout T h e Experimental Paradigm Space On occasion, making an important discovery involves finding a new method for gathering data—a new experimental paradigm.
^ It is unlikely that his new method for gathering data is some new domaingeneral induction method (e.
g.
, Mill's inductive cannons); instead it is likely to be a method unique to that field of inquiry (e.
g.
, changing the temperature in a particular order, instructing subjects in a particular way).
 These developments are typically not new instruments being developed (although they can be); rather they iire typically new methods for using the same insuiiments.
 The issue at hand is how such new methods are created.
 Our model includes several domaingeneral heuristics for the creation of such new methods.
 Paradigms are primarily created in the service of testing a hypothesis.
 The hypothesis embodies a set of assumptions ^The most popular use of the term "paradigm," typically associated with Kuhn (1970), refers to a much larger entity than we are considering.
 In fact.
 Kuhn used the word "paradigm" in two senses (which he acknowledges in the postscnpt of the second edition): the large scale paradigm of a whole field, and the smaller scale experimental paradigms that are used in particular experiments (e.
g.
, the pairedassociates paradigm, or Sperling's iconic memory paradigm).
 W e will use the term to refer to experimental paradigms of the second, smaller, kind.
 about what features of the experiinent are of interest.
 An experiinental pjiradigin is created that emphasizes the features of interest.
 For exjunple, to test the hypothesis that the number of steps in the route matter, the subject would create a paradigm in which the number of steps was an explicit feature of the p<uadigm.
 The corollary of this p;uadigm creation process is that p;iradigms Jire also created to deemphasize features which are hypothesized not to matter (either by holding those features constant, or by removing them entirely from the experiment).
 Paradigms can :ilso be created through analogy to other paradigms.
 For example, subjects in the MilkTruck task developed the pjuadigm of holding delivery item constant from the paradigm of holding house number constant.
 These analogous, exjunple paradigms can be ones acquired through observation, or ones generated by oneself in other situations.
 Paradigms may also be created by analyzing the cause of failed experiments.
 For exmnple, if an experiment produces an ambiguous outcome, a new paradigm can be created to disainbiguate the outcome.
 In the MilkTruck domain, many subjects ran one experiment in which two steps in the program were identical (e.
g.
, program 2 of figure 2 ) — subjects noticed that this kind of experiment produces an ambiguous outcome and rarely ran that kind of experiment again.
 Furthermore, these new paradigms may be created through an error analysis of thought experiments rather than actual experiments.
 The Experiment Space Many costs and risks are associated with conducting experiments (e.
g.
, mental effort, money spent, and potential loss of face for a failed experiments), and one practical goal of experimentation is to minimize these costs and risks.
 Experimentation also has theoretical goals related to the acquisition of information about the world.
 For example, it is desirable to design experiments relevant to the question at hand, with easilyinterpreted and unambiguous results.
 H o w are these often conflicting goals achieved in particular experiments? In our model, the theoretically oriented processes of experiment selection are achieved using two main heuristics: the examination heuristic and the discrimination heuristic.
 The examination heuristic selects experiments which directly demonstrate the hypothesized effect.
 For example, a hypothesis about the behavior of acids in the presence of water leads to the selection of an experiment involving water.
 This tendency produces what has been called the + H test bias (Klayman & Ha, 1987) in rule discovery tasks: rules of the form "X's are a member of the concept" will lead to the selection of X's, rather than things that are not X's, to test the rule.
 The discrimination heuristic selects experiments which can discriminate among competing hypotheses under consideration.
 This heuristic is used only when multiple hypotheses are being considered.
 Therefore, there is no bias to select highly discriminating experiments (experiments which discriminate among many potential hypotheses) in the absence of multiple, specific, active hypotheses.
 However, risk regulation does take into account expected information content.
 108 The practical goals of experiment selection iire met through processes of complexity management and risk regulation.
 These experiments selection processes derived from the following phenomena in the MiikTruck domain.
 Firstly, using verbal protocol data, it was found that subjects choose shorter experiments when they were confused (unsuccessful at explaining experimental outcomes), and they choose longer experiments when they were highly confident (successful at explaining experimenud outcomes).
 Secondly, using computer keystroke timing data, it was found that when recent experiments were easy to design (indexed by quick keystrokes), subsequent experiments were more likely to be longer.
 Conversely, when recent experiments were difficult to design (slow keystrokes), subsequent experiments were more likely to be shorter.
 Complexity management involves regulating experiment design £uid interpretation complexity, where complexity is defined relative to the current state of understanding and experimental expertise.
 For example, longer experiments are more difficult to generate when few operators for generating long experiments exist, and the longer experiments are more difficult to interpret when the knowledge of relevant dimensions is small.
 Risk regulation involves choosing experiments based on their perceived probability of producing an informative outcome.
 In many cases, this involves choosing between experiments which have a low probability of being successful, yet would be very informative if they are successful, and experiments which have a high probability of being successful even though they contain little potential information.
^ For example, conducting experiments which vary few features from the previous experiment are likely to behave exactly as predicted, whereas experiments in which many features have been varied have the potential of producing very novel results yet carry the risk of producing uninterpretable results.
 Complexity management and risk regulation are often in opposition.
 For example, more complex experiments are more likely to be informative, but are also much more difficult to generate and interpret.
 These two factors are combined to produce an expected utility, which determines the final experiment choice.
 The balance between complexity management and risk regulation varies with expertise.
 For example, with experience, longer programs become more easily generated and interpreted, and so, all subjects in the MiikTruck domain wrote longer programs towards the end of the problemsolving session.
 The Data Representation Space How does one choose or change a data representation? Finding the gener^d solution to these questions is a difficult task because there is no known universal language for describing data representations, nor is there a known universal generator of representations.
 As a partial solution to these questions, w e present three heuristics used for selecting representations from a previously existing repertoire.
 ^ A successful experiment is one that can be meaningfully predicted or postdicted.
 In our model, data representation change occurs through the following mechanisms: Notice Invariants, Analogy, and Bruteforce search.
 Notice Invariants works as follows.
 Experience with experimental outcomes within a domain leads to the noticing of certain regularities.
 N e w representations are chosen which emphasize these regularities.
 This behavior is exemplified in the MiikTruck task as subjects begin to notice that the first part of the program rarely changes.
 They then change their data representations to include changing and unchanging segments of the program.
 Analogy produces representations by analogy to previously understood phenomena.
 For example, such analogies might include: computers are like programmable calculators, and atoms are like the solar system.
 The features used in the analogical source are applied to the analogical target.
 This process is similar to a categorization process.
 One kind of situation that triggers this process is the occurrence of salient, expectationviolating events, which force the recategorization of objects and events.
 Bruteforce search is a process of searching haphazardly through the set of possible representations of objects in the environment (i.
e.
, by considering each object, and all the features and feature clusters of each object).
 This is the method by which subjects in the MiikTruck domain tended to add features to their data representations.
 The order of search may be constrained by the salience or availability of the possible representations.
 The process of bruteforce search typically occurs when the individual believes that the current representation may not include the causallypredictive features.
 The Hypothesis Space In our model, the fundamental character of search in the hypothesis space is the piece by piece construction of hypotheses.
 This process, called piecemeal induction, was the method by which all subjects in the MiikTruck domain developed their hypotheses.
 In the first stage of piecemeal induction, a hypothesis is generated (either from memory or from data).
 Then, a scoping processes determines the generality or scope of the hypothesis.
 For example, a subject in the MiikTruck domain might hypothesize that the 5 key reorders the last N steps only when a black triangle is selected (in contrast to concluding that the 8 key reorders the last N steps no matter which triangle is selected).
 The dimensions used to form the scope are chosen from the current data representation.
 O n each dimension, the most general scope value is preferred in the absence of counterevidence.
 With one or more particular hypotheses as input, abstraction processes generate more general hypotheses.
 For example, in the MiikTruck domain, subjects often abstract the hypothesis that the last N steps of the program are reordered from the particular hypotheses that there is no change with N=l, and the last two steps are changes with N=2.
 The number of particular cases that are sufficient to warrant a generalization is dependent upon expectations about the variability in the domain of study (which can be modified with experience).
 109 There ;ire m;iny candidate inechaiiisins for the generation of hypotheses.
 In the domains that we have studied, two main processes have been found: representational mapping, and popout.
 Representational mapping is mapping of objects (e.
g.
, the triangles in the MilkTruck task) onto actions or parts of actions (e.
g.
, the order direction of the step rearrangement), where both the object and the actions (and action parts) are already in the current representation.
 Representational mapping is similar to a memory search.
 The representations in memory are seiirched for correspondences.
 The more complex the mapping (i.
e.
, greater number of predicates), or the less salient the tobemapf)ed feature, the lower the probability that the mapping will occur.
 Representational mapping uses two heuristics: uniquefunction, and sametype.
 The uniquefunction heuristic favors mapping objects with no other known function onto actions or components of actions with no other known cause.
 The sametype heuristic favors mapping objects onto things of the same dimensionality.
 For example, binary object factors (e.
g.
, black and white triangles) tend to be mapped onto inherently binary output factors (e.
g.
, forward and reverse order).
 N o actuaJ experimental outcomes are necessary for representational mapping, since representational mapping can work with abstract schemata as well as particular objects.
 Therefore, this mechanism is typically used for generating initial hypotheses in the absence of evidence.
 Popout occurs through automatic, categorization processes.
 W h e n certain evidence presents itself, certain relationships are uniformly entertained.
 For example, exact similarity (whether coincidental or not) is automatically noticed.
 This automatic process is dependent upon representational factors.
 For example, if a feature is not encoded, no similarity involving that feature can be noticed.
 Comparison to Previous Work The details of our model are similar in many respects to other discovery models.
 The search space with the greatest degree of similarity is the hypothesis space.
 In particular, our piecemeal induction processes are very similar to the quantitative and qualitative rule induction processes of the B A C O N models (Langley, et al.
, 1987).
 F A H R E N H E I T (Zytkow, 1987) is the intellectual precursor of our scoping processes.
 The popout mechanism w e use is a very generic computational principle.
 Many production systems models have domainspecific productions which immediately recognize and hypothesize about certain kinds of relations and correspondences.
 For example, K E K A D A (Kulkami & Simon, 1988) immediately recognizes mixed or additive effects given certain kinds of data.
 In another domain, S T E R N (Cheng, 1990) immediately recognizes power functions in quantitative data.
 Turning to experiment space processes, there are no models of discovery that explicitly address the issue of complexity management.
 In contrast, several discovery systems have methods for ordering the experiment space search such that experiments likely to produce useful information are considered first.
 For example, A M (Lenat & Brown, 1984) focuses attention on concepLs that produce novel results.
 In a similar fstshion, D I D O (Scott & Markovitch, 1993) uses a curiosity heuristic which favors experiments testing the maximally uncertain part of the hypothesis.
 However, DIDO regulates whether experiment outcomes are considered further or ignored rather than regulating which experiments iire conducted.
 The exiUTiination principle is implicit in many models (e.
g.
, LIVE (Shen, 1993), A M (Lenat & Brown, 1984), E U R I S K O , D I D O (Scott & Markovitch, 1993).
 and D E E D (Rajamoney, 1993)), but explicit only in IE (Shrager, 1985).
 The discrimination principle is also taken from Shrager's IE model.
 However, there are similar principles in several other systems, including D E E D (Rajamoney, 1993), and ABDSoar (Johnson, Krems, & Amra, 1994).
 Very few discovery systems create new experimental paradigms, and fewer still have considered this search space explicitly.
 S T E R N (Cheng, 1990) is one of the few such models.
 It has only one very simple paradigm creation mechanism.
 The most important difference between the paradigm construction in S T E R N and our model is that S T E R N creates new paradigms in order to try something new, whereas our model creates new paradigms because some feature of the new paradigm is desired.
 Data representation change also has rarely been modeled.
 However, Kaplan's S W I T C H (1989) presents a few heuristics for representation change, and they are different from the three heuristics explicitly postulated here (e.
g.
, change grain size on failure, and pursue hot ideas).
 Furthermore, there are several programs capable of proposing new intrinsic properties, which might be construed as one form of data representation change.
 For example, B A C 0 N .
 4 (Langley et al.
, 1987) discovers the intrinsic property gravitational mass from the properties of force and distance by searching for constant relations among factors.
 There are also several kinds of conceptual hierarchy discovery programs that discovery new categories (i.
e.
, new representations) by searching for feature invariance (e.
g.
, Fisher's C O B W E B (1987)).
 However, there has been little previous treatment of the process by which features and objects are deleted from the data representation nor of the process of adding completely novel features (rather than creating new features by combining existing features).
 Conclusion We have presented a general framework for understanding scientific discovery: the 4space model of experimental paradigm, experiment, data representation, and hypothesis.
 This framework is a significant extension to the experiment and hypothesis space focus of the great majority of previous models of discovery, and we expect it to be applicable to many discovery domains.
 W e also have outhned the way in which searches in these four spaces interact.
 These interdependencies make it advantageous to consider all four spaces.
 In particular, previous models of discovery may have been trying to solve the difficult problems of data representation and experimental paradigm search in the process of dealing with hypothesis and experiment space issues, and may have been 110 confounding separate issues in the process.
 By considering these issues as conceptually distinct factors, and by studying their interrelations, we may gain further insight into the modeling of scientific discovery processes.
 The discovery task may be more computationally tractable by considering the experimental paradigm and data representation spaces explicitly.
 For example, rather than trying to consider all possible experimental paradigms while designing an experiment, it is easier to simply select from a small set of currently available experimental paradigms, and make the small number of decisions available in the selected paradigm.
 This set of experimental paradigms may be modified with experience in the discovery domain.
 Similarly, rather than trying to develop hypotheses using a very complete data representation containing all possible objects and features, simply select from the small number of objects and features in the current data representation.
 This data representation is also modified with experience in the domain.
 Thus, in both cases, very large search spaces are converted into several, much smaller search spaces.
 As of yet, we have not discussed the control processes that coordinate search between the four spaces.
 Part of this coordination is driven by the sequential structure of the task: fust experiments are created and run, then they are analyzed.
 The remainder of this coordination is driven by the logical relationships between the four spaces: experimental paradigms must be selected/created before experimental details are selected; and data representations must be selected before hypotheses are evaluated and modified.
 However, there are some exceptions to this simple scheme: occasionally experimental paradigms are evaluated for their effectiveness immediately after an experiment is conducted; and new data representations are occasionally created in response to a failure to develop a new hypothesis using the existing representation.
 While our model has some features in common with other discovery models (although there are many novel features), the details of our model derive from detailed, onUne human performance data.
 This is in contrast to the majority of the existing discovery models that are motivated primarily by Artificial Intelligence goals or by historical analyses.
 It is interesting to note the similarities in underlying processes between our model and these other models despite the different modeling goals.
 The goal of our future computational work will be to pursue the complete implementation of our model, and assess the tractability of our theoretical model, as well as its generalizability to other domains.
 Furthermore, we wish to match our model more precisely to the empirical data obtained from our studies with the MilkTruck task.
 Acknowledgments This work was supported by graduate scholarships from la Formation de Chercheurs et I'Aide k la Recerche and the Natural Sciences and Engineering Research Council to the first author, and by grants from N I C H H D and the A.
W.
 Mellon foundation to the second author.
 References Cheng, P.
 C.
H.
 (1990).
 Modeling scientific discovery.
 Unpublished doctoral dissertation.
 The Open University, Milton Keynes.
 Kaplan, C.
 A.
 (1989).
 SWITCH: A simulation of representational change in the Mutilated Checkerboard problem (Tech.
 Rep.
 No.
 477).
 Pittsburgh: Carnegie Mellon University, Department of Psychology.
 Klahr, D.
 & Dunbar, K.
 (1988).
 Dual space search during scientific reasoning.
 Cognitive Science, 12, 148.
 Klayman, J.
 & Ha, Y.
W.
 (1987).
 Confumation, disconfirmation, and information in hypothesis testing.
 Psychological Review, 94(2), 211228.
 Kokar, M.
 M.
 (1986).
 Determining arguments of invariant functional descriptions.
 Machine Learning, 1(4), 403422.
 Kuhn, T.
 S.
 (1970).
 The structure of scientific revolutions, 2nd edition.
 Chicago: University of Chicago Press.
 Kulkami, D.
 & Simon, H.
A.
 (1988).
 The process of Scientific Discovery: The strategy of Experimentation.
 Cognitive Science, 12, 139176.
 Langley, P.
, Simon, H.
 A.
, Bradshaw, G.
 L.
, & Zytkow, J.
 M.
 (1987).
 Scientific discovery: Computational explorations in the creative process.
 Cambridge, M A : MIT Press.
 Lenat, D.
 B.
, & Brown, J.
 S.
 (1984).
 W h y A M and EURISKO appear to work.
 Artificial Intelligence, 23, 26994.
 Rajamoney, S.
 A.
 (1993).
 The design of discrimination experiments.
 Machine Learning, 12,185203.
 Schunn, C.
 D.
, & Klahr, D.
 (1992).
 Complexity Management in a Discovery Task.
 In Proceedings of the 14th Annual Conference of the Cognitive Science Society.
 Schunn, C.
 D.
, & Klahr, D.
 (1993).
 Self Vs.
 OtherGenerated Hypotheses in Scientific Discovery.
 In Proceedings of the 15th Annual Conference of the Cognitive Science Society.
 Schunn, C.
 D.
, & Klahr, D.
 (1995).
 Complexity management and risk regulation in discovery learning.
 In preparation.
 Scott, P.
 D.
, & Markovitch, S.
 (1993).
 Experience selection and problem choice in an exploratory learning system.
 Machine Learning, 12,4967.
 Shen, WM.
 (1993).
 Discovery as autonomous learning from the environment.
 Machine Learning, 12, 143165.
 Shrager, J.
 C.
 (1985).
 Instructionless learning: Discovery of the mental model of a complex device.
 Unpublished doctoral dissertation, Carnegie Mellon University, Pittsburgh.
 Simon, H.
 A.
, & Lea, G.
 (1974).
 Problem solving and rule induction: A unified view.
 In L.
 W .
 Gregg (Ed.
), Knowledge and cognition.
 Hillsdale, NJ: Erlbaum.
 Thagard, P.
 (1988).
 Computational philosophy of science.
 Cambridge, M A : MIT Press.
 Zytkow, J.
 M .
 (1987).
 Combining many searches in the F A H R E N H E I T discovery system.
 In FYoceedings of the Fourth International Workshop on Machine Learning.
 Irvine CA, 28187.
 Ill Angle, Distance, Shape, and their Relationship to Projective Relations KlausPeter Gapp Cognitive Science Program Department of Computer Science University of Saarbriicken P.
O.
Box 151150 D66041 Saarbriicken, Germany gapp@cs.
unisb.
de Abstract The semantics of spatial relations have been intensively studied in linguistics, psychology, and cognitive neuroscience.
 Angle, distance, and shape are widely considered to be the key factors when establishing spatial relations.
 In this work an empirical study shows that previous theories overemphasize variation and we clarify the interdependencies between angle, distance, and shape with respect to the acceptability of projective relations.
 It turned out that the angular deviation plays the key role for relations of this class.
 The degree of deviation was dependent upon the extension of the reference object perpendicular to the canonical direction of the relation.
 There was no major effect due to the distance.
 However, distance interacted with the angular deviation if the located object was very close to the reference object.
 The experimental results can now be used as a theoretical framework for validating existing computational models of projective relations for their cognitive plausibility.
 Introduction M a n y research disciplines are concerned with problems related to the domain of space.
 One major point of interest are spatial relationships.
 In the last couple of decades the semantics of spatial relations have been intensively studied in many areas of cognitive science.
 The fundamentals can be found in linguistic and psycholinguistic literature (e.
g.
, Clark, 1973; Herskovits, 1986; Lakoff, 1987; Miller & JohnsonLaird, 1976;Talmy, 1983) and in cognitive neuroscience (e.
g.
, Kosslyn, 1980, 1994).
 Establishing a spatial relation requires a located object (LO), one or two reference objects (RO), and a certain frame of reference which determines the use of the relation depending on the prevailing context: intrinsic, extrinsic, or deictic (cf.
Garnham, 1989;Levelt, 1984; Rock, 1973;RetzSchmidt, 1988).
 In a deictic or viewercentered frame, objects are represented in a retinocentric, headcentric, or bodycentric coordinate system based on the viewer's perspective of the world (CarlsonRadvansky & Irwin, 1993).
 In an intrinsic or objectcentered frame, objects are coded with respect to their intrinsic axes.
 In an extrinsic or environmentcentered frame, objects are represented with respect to salient features of the environment.
 In order to talk about space, horizontal and vertical coordinate axes must be oriented with respect to one of these reference frames so that linguistic spatial terms such as right^ or above can be assigned (Miller & JohnsonLaird, 1976).
 ' In the following text only the English expressions for the German prepositions are used.
 Slight differences between the German and the English may appear Spatial relations are mainly divided into two classes: topological (at, near, etc.
) and projective, or directional, (in front of, to the right of, etc.
) relations.
 Where it is necessary to localize objects more precisely, some languages,such as German, usually use more than one spatial relation.
 Normally, no more than two relations are combined, e.
g.
 the L O is in front of and to the right of the RO.
 The use of such combinations is very c o m m o n in German, because they involve direct combinations of the simple terms.
 For instance, rechts vor means the same as to the right and in front of in English.
 Thus, to get a combined localization expression using two prepositions, one has only to combine the elementary expressions appropriately (cf.
 Gapp, 1994b).
 Following Landau and Jackendoff (1993), people do not take into consideration every detail of the objects involved when applying spatial relations.
 They propose that these kinds of relations depend mainly on the boundedness, surface, or volumetric nature of an object, and on its axial structure (see also Herskovits, 1986; Talmy, 1983).
 Hence, the process of establishing spatial relations considers only the essential shape properties of objects.
 Spatial relations are fuzzy (cf.
 Freeman, 1975), i.
e.
 the region where a relation is applicable cannot be defined by sharp boundaries (see also (Herskovits, 1985, 1986)).
 Attempts by speakers to reduce this vagueness can be seen in the use of linguistic hedges like exactly in front of or just behind, and has therefore to be accounted for when defining a spatial relation's semantics (cf.
 Kochen, 1974; Kay, 1979, 1983; Lakoff, 1972, 1987).
 W e restrict our investigations in this work to how people evaluate the applicability of projective relations and their compositions.
 In existing theoretical and practical approaches three essential factors were considered in establishing projective relations: the angular deviation of the located object from the canonical direction implied by the relation, the distance between the located object and the reference object, and the reference object's shape (cf.
 Gapp (1994a) for more details).
 Hypotheses W e propose that the cognitive system accounts only for the angular deviation between the located object and the relation's direction, and not for the distance, when establishing projective relations.
 However the proximity of a located object to a certain referent plays an important role in object localization tasks, e.
g.
, answering a question like "Where is object A ? " (cf.
 Gapp, 1994c).
 This corresponds to the findings of Logan and Sadler (in press).
 They propose that people de112 mailto:gapp@cs.
unisb.
decide whether a relation applies by fitting a spatial template to the objects that represents regions of acceptability for the relation in question.
 Logan and Sadler define three main regions of acceptability: one reflecting good examples, one reflecting lessthangoodbutneverthelessacceptable examples, and one reflecting unacceptable examples (Figure la).
 acceptable » acceptable unacceptable (a) (b) Figure 1: Spatial template layout for above (a) and square grid setup (b).
 Good and acceptable regions are not distinct, they blend into one another gradually.
 However Logan and Sadler do not specify how this blending is achieved.
 This may be due to the nature of their empirical data.
 Subjects were presented with a spatial relation̂  and a diagram containing an O (the R O ) in the center of an invisible 7 x 7 grid, and an X (the L O ) in one of the surrounding positions (Figure lb).
 The task was to evaluate the "goodness of fit" of the relation to the object configuration presented.
 However, using this square grid layout makes it difficult to investigate angular dependency.
 Alternatively a radial ordered test setup for the located object would be better at measuring the proposed angular effect.
 W e propose furthermore that the extension of the R O in each dimension influences the scale of the angular deviation and consequently a relation's degree of applicability (DA).
 In Figure 2, for example, even though object L is in the same absolute position compared to R for all configurations (a,b,c), the applicability of the relationship <right L R > increases from (a) to (c).
 This effect becomes increasingly relevant, the more that the extensions of two ROs differ.
 B right I II (a) (b) (c) Figure 2: R O ' s extension influences the applicability of a projective relation.
 E x p e r i m e n t s W e restrict our account in this paper to the subset of projective relations and their compositions.
 Experiments were conducted to clarify the following open questions: 1.
 How does the angular deviation influence the applicability of a projective relation? 2.
 H o w is the distance between the located object and the reference object related to a relation's applicability? 3.
 H o w does the reference object's shape influence the applicability? 4.
 Are there distinctions between the applicability regions of in front of/behind, right/left, and above/below? 5.
 H o w is the region of applicability for a composition of two projective relations structured? Is there a weighting towards one relation? Two experiments were designed using different reference frames: a horizontal 2 D frame (bird'seye view) and a vertical 2 D frame.
 Subjects were presented a spatial relation (preposition) and two objects on a computer screen.
 The task was then to evaluate how well the preposition described the relationship between the located object and the reference object.
 Method Subjects.
 The subjects were 20 graduate and undergraduate students from 10 different academic areas (7 female, 13 male, aged from 20 to 33) who were each paid D M 13.
 for a 1 hr session.
 Apparatus and stimuli.
 The stimuli were displayed on a Hewlett Packard HP98754A 19" color monitor controlled by a H P 9000/720 workstation.
 In the experiment with the horizontal reference frame w e used the relations in front of, behind, right, left, and their compositions, and in the experiment with the vertical frame of reference the relations above and below were used instead of in front of and behind.
 A design with four independent factors — R O , relation, angle, and distance — varied within subjects was carried out.
 To investigate the shape's influence five different reference objects were used: Three squares (of 10 x 10, 30 x 30, and 50 X 50 pixels) and two rectangles (of 30 x 50 and 50 x 30 pixels).
 The LOs were represented by a 10 x 10 pixels square.
 The color of the L O (red) and the R O (green) made them distinguishable.
 The LOs occupied fixed positions arranged radially around the R O (Figure 3).
 A scene consisted of a relation, a located object and a reference object.
 The initial scene definitions were made in the first quadrant (Figure 4) using the relations right, behind (above), and right and behind (right and above).
 All of these relations were valid to a certain degree.
 To avoid sequence effects in the experiment, the single scenes were randomly mapped to one of the four quadrants, i.
e.
 the coordinates of the L O and the relation were constantly transformed.
 But relations changed only in their dimension, i.
e.
 right to left, in front of to behind, above to below, and vice versa.
' T h e result w a s a grid of 6 4 different test positions for the L O , with four different angles (0° , 22.
5", 4 5 ° , 67.
5° ) ^The relations used were: above, below, left of, right of, over, under, next to, away from, near to, and far from.
 ^This is valid because of the symmetry of the relations in one dimension.
 In the following text only the first relation will be used as a simplification.
 113 and relative distances (130, 240, 350, and 460 pixels) in each quadrant (Figure 3).
 The grid layout was slightly different for each of the five R O s because an additional offset to the distance had to be added for the larger R O s so as to keep the distance between the L O and the R O constant.
 •J> ••ii>».
t  i.
l.
/i • • • ai> SVATIAi.
 RUATION HORIZONTAL TUT noWUMUrr 1 • • 2 2 1 • • 1 •.
 '• i™3 • A •0: Il«li iJ J 1 IMPWWt ' 4 \ •"*•• ;/ u_1 fltuKt {ttam 1 8TWW \vm I aMM.
 \ mt Figure 3: Radial grid layout.
 Figure 4: Definition grid.
 Figure 5: 2 D experimental layout.
 Results Angle and Distance.
 M e a n D A s across all the subjects were computed for each combination of relation, angle, distance and reference object.
 The standard error of the mean was 0.
17.
 The means of the D A s for the middle sized square reference object across all angles/distances are plotted in Figures 6 and 7.
 The D A decreased linearly with the angular deviation for all tested projective relations.
 However the distance had no significant effect on the evaluation.
 A projective relation was fully applicable (DAproj = 1 0), if there was no angular deviation.
 The degree of applicability got closer to 0.
0 as the angle approached 90° .
 The reference frame was indicated by a description of the four main directions at the borders of the display (cf.
 (1) in Figure 5).
 It was kept fixed throughout the whole experiment.
 Depending upon the chosen quadrant for the located object, the reference object was placed at fixed positions in the corner of the diagonally opposite quadrant (cf.
 (2) in Figure 5).
 Procedure.
 There were 244 experimental trials (204 horiz.
 and 40 vert.
).
 The experiments started with the horizontal and ended with the vertical experiment.
 The trials were randomly ordered for each subject.
 The program paused every 70 trials to allow the subjects a brief rest.
 Separate instructions for each experiment were displayed on the screen.
 Subjects were told they would see two objects, a red object and a green reference object.
 Additionally a spatial preposition (or composition) was given (cf.
 (3) in Figure 5).
 The task was to evaluate with a sliding scale (cf.
 (4) in Figure 5), h o w well the preposition describes the relationship between the two objects, taking the given reference frame into account.
 The vertical sliding scale was used to indicate no applicability at its lower end and full applicability at the upper end.
 The scale was set to 0 at the beginning of each trial.
 Three lines indicated the 0.
25,0.
5 and 0.
75 positions.
 There was also an additional digital display with the degrees of applicability ranging from 0.
00 to 1.
00 (cf.
 (5) in Figure 5).
 In the introduction to each experiment all spatial configurations were displayed in a quick run through and, in addition, the subjects were given ten test trials to familiarize themselves with the environment.
 right (horiz) right (vert) behind obove =5 0,80 • ^ 070 • 0.
60 • 0.
50 0.
40 22.
5 45 Anguiar Deviation 1.
00 0.
90 2 070 a < 0.
60 I 0.
50 2*0.
40 0.
30 0.
20 Figure 6: M e a n D A s (angles).
 —•— right — o — right —•— behind —' (horiz.
) (vert.
) • 17̂^ .
= 3— above 1  0 130 240 350 Distance (pixels) Figure 7: Mean DAs (distances).
 460 114 These conclusions were supported in a 2 (relations: right, behind) x 4 (angles) x 4 (distances) multivariate analysis of variance (MANOVA), with repeated measurements of the mean DAs.
 The predominant effect of the angle was highly significant, F(3,608) = 521.
82, p < 0.
001, M S ^ = 13.
83, in the horizontal experiment, as well as in the vertical experiment, F(3,608) = 487.
15, p < 0.
001, M5e = 14.
27.
 There was no significant dependence on the distance in either experiment (F < 1).
 However, there was a significant interaction between angle and distance, F{9,608) = 1.
97, p < 0.
04, MSe = 0.
5, caused by an unexpected phenomenon.
 If the angular deviation was below 45°  subjects rated the applicability of a projective relation slightly higher if the located object was very close to the reference object, than if the located object was further away.
 The closer the located object was positioned to the reference object the greater the reduction in applicability.
 The reverse effect was noticed above 45°  (cf.
 Figure 8).
 The mean DAs of the angular deviation 22.
5°  and 67.
5°  for the relations right and behind across the three square reference objects are plotted in Figure 9.
 Using only these two angles in the M A N O V A yielded a highly significant interaction, F(3,608) = 9.
5, p < 0.
001, MSe = 0.
33, between angle and distance.
 • 0,75 / • 0,76 • reference objects' extensions, a difference in the ratings consistently appeared, depending upon the extensions of the reference objects.
 As shown in Figure 2, the extension of the reference object perpendicular to the projective relation's direction, significantly influenced the degree of applicability.
 The dependency from the reference object was confirmed by a M A N O V A using the three differently shaped reference objects.
 The result was a highly significant interaction between relation and reference object, F(l,912) = 13.
48,p < 0.
001, MSe = 0.
45.
 o.
eo T square R 0,«0 67.
5 Angular Deviation Figure 10: Extension effect: right.
 behind 0,76 0,78 REFO , f i ^ 0,37 'o,36 0,32 0,24 Figure 8: M e a n s at 22.
5°  and 67.
5° .
 right (22,5°) right (67,5») behind (22,5°) behind (67,5°) 240 360 Distance (pixels) Figure 9: Slight distance effect.
 Extension of the reference object.
 The mean DAs of right and behind across subjects a n d the three differently shaped reference objects (middle sized square, vertical a n d horizontal aligned rectangles) are plotted in Figures 1 0 a n d 11.
 A l though there w a s only a very slight difference b e t w e e n the square rect (vert.
) rect.
 (hort.
) R 0,65 • 0,45 0,35 •67,5 Angular Deviation Figure 11: Extension effect: behind.
 R e g i o n s o f applicability.
 T h e r e w e r e slight differences b e tween the angular dependence of the three main directions in front of/behind, right/left, and above/below.
 A s plotted in Figure 6, the in front of/behind direction w a s rated highest, followed by the above/below direction.
 Compositions.
 Mean DAs of the angular deviation of right a n d behind and right a n d above ( R O : middle square) across subjects were computed and plotted in Figure 12.
 There w a s a slightly lower weighting for right in both compositions.
 However, the difference between right and above (0.
5) w a s less than the difference between right and behind (0.
9).
 There w a s also a small distance effect (angle: ± 22.
5° ) with the s a m e characteristics measured for elementary projective relations at an angular deviation of 67.
5°  (cf.
 Figure 13).
 115 0.
90 •55 0.
85 right & behind right & above 0.
60 as 22,5 Angular Deviation Figure 12: Angular effect.
 0.
78 * 0.
76 t 0.
74 • 0.
72 •• 0.
70 0.
62 right & behind " right & above 240 350 Distonce (pixels) 460 Figure 13: Slight distance effect at ± 2 2 .
 5 °  (compositions).
 Discussion The data from the experiments showed clearly the characteristics of the evaluation process for projective relations.
 The applicability of a relation was strongly affected by the angular deviation.
 There was no significant dependence on the distance.
 This correlates to the findings of Logan and Sadler (in press).
 However, w e are now able to give a reliable description of how people evaluate the acceptability of a projective relation.
 This was possible through an experimental design which allowed the independent examination of angle and distance.
 In the evaluation of composite projective relations the right/left axis was rated lower than the other two.
 This corresponds to the phenomenon that the subjects rated the in front of/behind and the above/below axes higher than the right/left axis.
 This slightly higher rating might be due to the fact that the in front of/behind and the above/below axes are easier to perceive (cf.
 Bryant, Tversky, & Franklin, 1992).
 The dependence of the D A upon the extension of the reference object was obvious even though the rectangular reference objects were only twothirds longer/higher than the related square reference object.
 The larger the extension of the reference object perpendicular to the canonical direction of the relation, the larger the relation's region of applicability in this perpendicular direction.
 This validates our proposed hypothesis in Figure 2c that the located object L is considered to be more to the right of the reference object R than in Figures 2a and 2b.
 A n exact prediction of how the reference object's extension scales the angular deviation, e.
g.
 linear or logarithmic, requires further investigation with additional, differently shaped reference objects.
 The slight distance effect for positions of the located object very close to the reference object at angles below 45°  also seems to be dependent upon the extension of the reference object: the larger the reference object the greater the effect.
 The effect should therefore disappear if one presumes a pointlike reference object.
 This gives rise to the following explanation of the effect: the angles used for the definition of the radial grid setup were measured from the reference object's center of gravity, despite the reference object's extension (cf.
 Figure 14).
 N o w consider Figure 15.
 If one uses the nearest point of the reference object from the located object (the corner c in the example) for measuring the angle, then the angles differ in the same way as the degrees of applicability did in the experiments.
 That is, a' < a" < a'" < a"" < a and |a'o"| > \a" a" versa.
 |, if a < 45°  and vice dx R O REL Figure 14: Angles measured from the RO's center of gravity.
 BEL Figure 15: Angles measured from the nearest corner of the reference object.
 This leads to the conclusion that in a computational model a certain offset has to be subtracted from the coordinates of the located object before the angular deviation is considered.
 The offset again depends on the extension of the reference object and additionally on the frame of reference because in deictic use the extension of the reference object perpendicular to the relation's direction is not necessarily equal to the perpendicular extension in intrinsic use (cf.
 Gapp, 1994a).
 In the example the offset is exactly half of the reference object's extension in each dimension (^, ^ ) .
 Conclusion and Future Work Increasingly sophisticated computational models of spatial relations have been developed in the last couple of decades.
 However, none of these have been empirically validated to prove their correctness.
 W e therefore designed empirical studies to clarify the interdependencies of angle, distance and shape when establishing projective spatial relations.
 The experimental findings made clear that the angular deviation is the crucial point when establishing projective relationships.
 The scale of the angle becomes influenced by 116 the extension of the reference object in each dimension.
 At angles between (0° ,45° ) and (45° , 90° ), and in particular at 22.
5°  and 67.
5° , the extension of the reference object also caused a slight distance effect if and only if the located object was very close to the reference object and the corresponding angle was measured from the reference object's center There exists a slight tendency to rate the in front of/behind and the above/below regions higher than the right/left region.
 This effect is also reflected in the evaluation of composite projective relations.
 With the help of these results it is now possible to test existing computational models for their cognitive plausibility.
 In future work we intend to try to validate the computational model we presented in Gapp (1994a).
 This model accounts for all the crucial hypotheses verified in this work.
 First results were very promising for a positive validation of the models cognitive plausibility.
 Furthermore, we will also investigate the distance and shape interdependencies for the class of topological relations and extend our model to cope with more complex environments, introducing contextual dependencies and intervening objects.
 Acknowledgements The research is being supported by the German Science Foundation, through the Cognitive Science Program at the University of Saarbriicken.
 The author would like to thank Werner Engelkamp and Wolfgang Wahlster for their support, advice, and criticism.
 Thanks also to the VITRA group, in particular Bernd Andes, Anselm Blocher, and Jochen Miiller for implementing parts of the experimental testbed and to my very helpful colleagues in the Cognitive Science Program.
 The clarity of this paper was improved thanks to comments from Marc Gurman, Stephen Hirtle, Gordon Logan, Patrick Olivier, and the two anonymous reviewers.
 References Bryant, D.
 J.
, Tversky, B.
, & Franklin, N.
 (1992).
 Internal and external spatial frameworks representing described scenes.
 Journal of Memory and Language, 31, 7498.
 CarlsonRadvansky, L.
 A.
, & Irwin, D.
 E.
 (1993).
 Frames of reference in vision and language: Where is above? Cognition, 46.
 223244.
 Clark, H.
 H.
 (1973).
 Space, time, semantics, and the child.
 In T.
 E.
 Moore (Ed.
), Cognitive development and the acquisitation of language (pp.
 65110).
 N e w York: Academic Press.
 Freeman, J.
 (1975).
 Themodellingof spatial relations.
 Computer Graphics and Image Processing, 4, 156171.
 Gapp, K.
P.
 (1994a).
 Basic meanings of spatial relations: Computation and evaluation in 3d space.
 Proc.
 ofAAAI94, Seattle, W A , 13931398.
 Gapp, K.
P.
 (1994b).
 A computational model of the basic meanings of graded composite spatial relations in 3d space.
 Proc.
 oftheAGDM'94 Workshop, Delft, The Netherlands, 6679.
 Netherlands Geodetic Commission.
 Gapp, K.
P.
 (1994c).
 From vision to language: A cognitive approach to the computation of spatial relations in 3d space.
 Proc.
 of the I *' European Conf.
 on Cognitive Science in Industry, Luxembourg, 339358.
 Garnham, A.
 (1989).
 A unified theory of the meaning of some spatial relational terms.
 Cognition, 31, 4560.
 Herskovits, A.
 (1985).
 Semantics and pragmatics of locative expressions.
 Cognitive Science, 9(3), 341378.
 Herskovits, A.
 (1986).
 Language and spatial cognition, an interdisciplinary study of the prepositions in english.
 Cambridge, London: Cambridge University Press.
 Kay, P.
 (1979).
 The role of cognitive schemata in word meaning: Hedges revisited.
 Technical report.
 Linguistics Department, U C B , Berkeley, CA.
 Kay, P.
 (1983).
 Linguistic competence and folk theories of language: Two english hedges.
 Proc.
 of the 9 "" Annual Meeting of the Berkeley Linguistic Society, Berkeley, CA, 128137.
 Kochen, M .
 (1974).
 Representations and algorithms for cognitive learning.
 Artificial Intelligence, 5, 199216.
 Kosslyn, S.
 M.
 (1980).
 Image and mind.
 Cambridge, M A , London: Harvard University Press.
 Kosslyn, S.
 M.
 (1994).
 Image and brain.
 Cambridge, M A : M I T Press.
 Lakoff, G.
 (1972).
 Hedges: A study in meaning criteria and the logic of fuzzy concepts.
 In P.
 M .
 Peranteau, J.
 N.
 Levi, & G.
 C.
 Phares (Eds.
), Papers from the 8"^ regional meeting of the Chicago linguistics society (pp.
 183228).
 Chicago, IL: University of Chicago, Department of Linguistics.
 Lakoff, G.
 (1987).
 Women, fire, and dangerous things, what categories reveal about the mind.
 Chicago: Chicago University Press.
 Landau, B.
, & Jackendoff, R.
 (1993).
 "what" and "where" in spatial language and spatial cognition.
 Behavioral and Brain Sciences, 16, 217265.
 Levelt, W.
 J.
 M .
 (1984).
 Some perceptual limitations on talking about space.
 In A.
 J.
 van Doom, W A.
 van de Grind, & J.
 J.
 Koenderink (Eds.
), Limits in perception (pp.
 328358).
 Utrecht: V N U Science Press.
 Logan, G.
 D.
, & Sadler, D.
 D.
 (in press).
 A computational analysis of the apprehension of spatial relations.
 In M .
 Peterson, P.
 Bloom, M .
 Garrett, & L.
 Nadel (Eds.
), Language and space.
 Cambridge, M A : M I T Press.
 Miller, G.
 A.
, & JohnsonLaird, P.
 N.
 (1976).
 Language and perception.
 Cambridge: Cambridge University Press.
 RetzSchmidt, G.
 (1988).
 Various views on spatial prepositions.
 AIMagazine, 9(2), 95105.
 Rock, I.
 (1973).
 Orientation and form.
 N e w York and London: Academic Press.
 Talmy, L.
 (1983).
 H o w language structures space.
 In H.
 Pick & L.
 Acredolo (Eds.
), Spatial orientation: Theory, research and application (pp.
 225282).
 N e w York, London: Plenum.
 117 A n A p p r o a c h to the Semantics of s o m e English Temporal Constructions Ian Pratt Dq)artment of Computer Science University of Manchester Manchester M13 9PL.
 U K iprattScs.
man.
ac.
uk David S.
 Br6e E)q)artlnent of Computer Science University of Manchester Manchester M13 9PL.
uk dbree@ OS.
man.
ac.
uk Abstract This paper outlines a general framework for giving the meanings of temporal prepositions (and some related adverbials) in English.
 The framework takes the form of a method for translating English sentences involving these adverbials into an expressively limited temporal logic, whose operators permit only restricted quantification over subintervals of a given interval.
 W e illustrate our approach with reference to the temporal adverbials one Monday, every Monday, on Monday, in July, for five minutes and in two hours.
 W e pay special attention to sentences containing multiple temporal adverbials.
 In particular, we show how some of our Unguistic intuitions concerning the acceptability of combinations of temporal adverbials prevent us from entertaining sentences that are either logical falsdioods or logically equivalent to simpler sentences.
 Introduction This paper outlines a goi^al framework for giving the meanings of tanporal prqx)sitions (and some related adverbials) in English.
 W e cannot set out the theory in its entirity here; instead, w e illustrate die main features of our approach by discussing the semantics of the temporal adverbials one Monday, every Monday, on Monday, in July, for five minutes and in two hours.
 W e shall be paying particular attention to sentences which combine several temporal adverbials.
 Exanqjles of such sentences are: (1) John was in the office for diree hours evoy Thursday (2) Kwiksave will be open for 6 hours evoy Sunday until 23rd May.
 Certain combinations, however, produce peculiarsounding saitences.
 For example.
 (3) * Mary worked on the papa one day within two days (4) * John drove to Aberdeen for 30 minutes for 2 hours would count as nonsense for most native English speakas.
 Our approach to the semantics of temporal prepositions aims to explain w h y some combinations of these temporal adverbials are acceptable whaeas others are not.
 A temporal logic based o n subintervals Consider the sentence (5) John drove to Aberdeen one Monday.
 Three temporally significant componaits can be identified in this sentence: (i) the tense and aspea of the verb, (ii) the temporal adverbial one Monday, and (iii) the underlying tenseless saitence.
 John drive to Aberdeen.
 TTie function of vexbtaise and aspect is a vast and still imperfectly understood topic.
 which w e cannot address in this paper.
 W e content ourselves with the observation that one part of that function is to constrain the general segment of time under discussion by locating it relative to the time of utterance or time of referaice.
 W e shall call this segment of time the interval of interest, and denote it by h\ w e have nodiing more to say on how it is determined.
 The fimction of the temporal adverbial one Monday is to locate the rq)orted event more precisely in time; w e will concern ourselves with this function in some detail below.
 To this end w e employ a predicate [Monday\{I), which we take to be true of all and only those intervals which coincide exacdy with Mondays (starting at (X):(X) hours and ending at 24:00 hours).
 Fmally, the function of die imderlying tenseless sentence is to describe the type of event or state located in d m e by the other components.
 Again, w e shall assume that [John drive to Aberdeen]{J) is a predicate true of all and only those intervals over whidi John drives to Aberdeen (starting when John sets off and ending when he arrives).
 Sentoice (5) states diat.
 at some time in the intaval of interest, there is a Monday sudi diat.
 sometime within that Monday, John drives to Abadeen.
 That is: (6) 3/(7 C /o & [Monday]{I) k 3J{J C l t [John drive to Aberdeen]{J))).
^ For convenience, we distinguish between predicates such as [Monday]{I), whidi arise from temporal adverbials.
 and thosesudias[JoAn drive to yl6er(/een](J).
whicharisefrom the underlying tenseless sentence.
 W e call the former temporal restrictions and the latter atomic formulae; however, both are in reality just predicates of intervals.
 W e can reformulate die truthconditions in (6) more elegandy using a tenq)oral logic by means of two familiar notational conventions.
 First, if (/> is an atomic formula, then.
 118 http://ac.
ukhttp://M13http://9PL.
ukhttp://ac.
ukrather than writing (̂( J ) , w e instead write |= j </>.
 Secondly.
 we introduce a temporal operator o with the semantics: (7) Let (^ be a formula and t{J) a ten^wral restriction.
 Then |=/ o(t, (j)) if there exists a J C / such that t(J) and ̂ j <i>.
 TTien (6) can be rewritten as the following assertion in temporal logic: (8) \=j, o{[Monday], o(true, {[John drive to Aberdeen])).
 where true is die trivial temporal restriction satisfied by every interval.
 In this paper w e show how to translate English sentences involving a variety of temporal adverbials into assertions in this temporal logic.
^ N o w consider the sentences (9) John drove to Aberdeen every Monday.
 (10) John drove to Aberdeoi on Monday.
 Sentence (9) states that, for every Monday in the interval of interest, sometime within that Monday, John drives to Abodeen.
 Sentence (10), by contrast, can be taken to assert that there is a unique Monday in the interval of interest, and that, sometime within that Monday, John drives to Aberdeen.
^ W e can formalize these truthconditions by introducing two further operators ioto our ten^wral logic: (11) Let (̂  be a formula and r a temporal restriction.
 Then t=/ n(r, <f>) if, for all J C / such that t{J), \=j <̂ .
 (12) Let <^ be a formula and r a tenqxjral restriction, llieii N / •(t, <ji)ifthereisauniqueJ C / such that r( J), and there is a 7 C / such that t{J) and \=j 0.
 ^Abandoning the predicate calculus in favour of variablefree languages (in our case, a temporal logic), in order to provide a more natural treatment of the truthconditions of English sentences.
 is not a new strategy.
 See, for example, Suppes (1976).
 Like many othw authors who have discussed temporal adverbials in English (e.
g.
 Richards al.
 1989), we have concwitrated on truthconditional aspects of meaning.
 W e do not intend to dismiss accounts of other dimensions of cognitive function, or to play down nontruthconditional phenomena such as polysemy (Lakoff 1987), (Herskovits 1986) (Rice 1992).
 W e just intend to concentrate on truthconditions.
 A rathw different formal approach to temporal aspects of English is taken by Hwang and Sdiubert (1992), who use their own representation language, based on structures called tensetrees.
 Our approach, by contrast, avoids such complex representations, restricting itself instead to standard constructions in modal logic.
 W e claim that our approach has the advantages of accessibility, clarity, and amenability to standard techniques of formal analysis.
 In fairness, however, it should be noted that Hwang and Schubert are concerned to model aspects of discourse structure which we have deliberately overlooked.
 ^This is not entirely proper, since it is plausible to take the existence of a unique Monday in the interval of interest to be presupposed rather than asserted.
 Since, however, we are not concerned with presupposition in this pap^, we shall take a small liberty here and ignore the difference.
 This simplification will clarify the explanation of important phenomena regarding the iteration of temporal pr^ositions, and its removal is routine.
 Tlie trudiconditions of (9) and (10) are then, respectively: (13) t=/„ D{[Monday], o{tiue, {[John drive to Aberdeen]))(14) |=/„ •{[Monday], o(true,([JoAn drive to Aberdeen]))The operators o, D and • are the only ones we shall be concerned with in this paper.
 In order to give the semantics of prqxjsitions such as before, after, by, until, and since (which all concern the direction of time), additional operators are needed.
 These words lie beyond the scope of the present paper; but they do not affect the central features of our approach.
 One of these features is that our temporal logic only permits (restricted) quantification over subintavals of a given interval, a feature which limits its expressive power.
^ Assembling the pieces In the previous section, w e gave the truthconditions of English sentences by translating them into a temporal logic.
 In this section, w e describe how such translations can be produced systematically.
 A computer implementation of this translation process (for die full range of English temporal prqwsitions) exists, and all of the translations from English to our ten:q)oral logic given in this paper are transcriptions of program output.
^ Recall sentence (5) and its truthconditions (8).
 W e can generate the formula in (8) from (5) by means of the following process: Translation step 1: Decompose the original soitence (5) into the underlying teoseless sentence John drive to Aberdeen and the temporal advabial one Monday.
 (Remember, w e are ignoring verbtense and aspect in this papa.
) Translation step 2: M a p the components identified in step 1 to special datastructures, which w e shall call operatortriples.
 In this case, the relevant mappings are (15) John drive to Aberdeen i> (o, true, [John drive to Aberdeen]) (16) one Monday I—> (o, [Monday], J) (We shall explain these operatortriples presently.
) Translation step 3: Order the triples generated in step 2 in some way, but so that the operator triple genaated by the tenseless sentence is last: QV) {o, [Monday],.
) {o, true, [John drive to Aberdeen]) *One fascinating question concerns the relationship between our temporal logic and KLONElike languages (Brachman and Schmolze 1985).
 The idea is that temporal restrictions and formulae be regarded as concepts, and C as the only relation.
 This question is, at the time of writing, unresolved.
 For a good survey of systems of temporal logic, see Gabbay, Hodkinson and Reynolds (1994).
 *The program runs under LPA Prolog version 4.
5, and is available on request from the first author.
 119 (Note: in the sequel w e shall introduce restrictions on the orderings of operatortriples considered here.
) Translation step 4: Fuse the list of operator triples to produce a formula, by matching the last operator in each triple with the first operator in the triple immediately to the right.
 In this case, (17) yields: (18) o{[Monday], o{tTne, [John drive to Aberdeen])) This fusion process is subject to the constraint that distinct operators cannot be matched.
 For example, two triples of the form (o, Ti, •) and (o, t2, •) caimot fuse (in that order) because • and o are distinct.
 (N.
B.
 the symbol' ' in the first triple of (17) is a 'wildcard', able to match with any operator.
) This constraint is important in explaining some restrictions on the iteration of temporal prepositions.
 Thus, temporal adverbials and the underlying tenseless sentence are mapped independently to operator triples, which are then reordered and fused together to produce a formula of temporal logic.
 This scheme allows us to give the meanings of tenyx)ral advabials in terms of mappings to operator triples.
 For exan:q)le, w e can give the meanings of expressions of the form one X , every X , on X and in X with the mappings: (19) oneX^{o,[X],.
) (20) every X^(p,[X],.
) (21) onX ^ {•^[X],.
) if X denotes a specific day (22) in X • , [X], _) if X denotes a daypart, month.
 year, century etc.
"" The above approach works for saitences containing several temporal adverbials.
 Thus, (23) John drove to Aberdeen one Monday in July can be decomposed into the underlying tmseless sentence John drive to Aberdeen, together with the temporal adverbials one Monday and in July.
 These three components generate, by means of the mappings (15), (19) and (22), the triples {•,U«/J/],) (24) {o,[Monday],_) (o, true, [John drive to Aberdeen]).
 The triples (24) can then be fused to generate the truthconditions (25) h/o •{[J^h], ^{[Monday], o(true, [John drive to Aberdeen]))).
 The straigth of this approach emerges when we consider unacceptable sentences like: ® Clearly, the qualifying conditions in mappings (21) and (22) require refinement; but that is a matter of detail which we can ignore here.
 An extensive study of these and similar restrictions for various languages can be found in Bree and Pratt (1995).
 (26) * John drove to Aberdeen on Monday one July.
 Here, decomposition and mapping produce the operator triples {oAJnly],.
) (27) {; [Monday],.
) (o, true, [John drive to Aberdeen]).
 If these triples are ordered as in (27), fusing would produce the formula <>([July],•([Monday],o(tTae, [John drve to Aberdeen]))) which will be logically false, since no July contains a unique Monday.
 O n the other hand, if we transpose the first two triples in (27), fusing would produce the formula •{[Monday],o{[Juiy\,o{trVie, [John drive to Aberdeen]))) which is also logically false, since no Monday contains a July as a subinterval.
 Thus, in rejecting (26) as unacceptable, our linguistic intuitions are filtering out a pointless combination of adverbials.
 Accordingly, w e modify step 3 of die translation process so that only those orderings of operatortriples are considered that are 'sensible', given the temporal restrictions they contain.
 Deciding whether a particular ordering is saisible in this sense requires a certain amount of commonsense calendrical knowledge concerning the length and firequency of the various temporal restrictions.
 This knowledge can be efficiently stored in a semantic network in which the nodes are die various types of temporal restrictions that can arise, and die links indicate die relations of containment and unique occurrence.
 The program used to generate the truthconditions given in diis paper employs just such a semantic tttwork to eliminate unwanted orderings of the operator triples, and thus to reject sentence (26) as untranslatable.
 The details are routine and need not be given here.
 The temporal prepositions/or and (with)in Sentence (5) reports the occurrence of an event — diat of John's driving to Aberdeen — something widi a definite point of completion.
 W e follow common practice in taking events to have the property: (28) If 1=/ (^ and J C / then ^t^ <^ (Remember: c denotes proper subset.
) By contrast, the sentence (29) Mary worked on the program on Monday reports the holding of a state: something that is true at all times throughout some interval.
 W e follow (reasonably) common practice and say that 4>isa state if it has the property (30) If h/ ^ and J c / dien ^=j </.
.
 120 Properties (28) and (30) are not exhaustive; however, w e claim that nearly all sin:y)le English tenseless sentences (not involving quantification, negation and other logical constructs) describe either events or states, as w e have defined them.
^ A test to distinguish between states and events is provided by the temporal prq)ositions/or and within.
 The former likes to combine with states, the latter, widi events: (31) Mary worked on the paper for four hours every day (32) The ferry sank (with)in 2 minutes (33) * TTie ferry sank for 2 minutes (34) * Mary worked on the paper (with)in four hours every day.
 The distinction between events and states allows us to refine the mapping of the underlying tenseless sentence.
 A tenseless sentence describing an event, such as The ferry sink, will get mapped to a triple as follows: (35) The ferry sink >—>• {o, true, [The ferry sink]) However, a tenseless sentence describing a state, such as Mary work on the paper will get mapped to one of two triples as follows: (36) Mary work on the paper i+ (o, true, [Mary work on the paper]) (37) Mary work on the paper >>• (•,true, [Mary work on the paper]) Why the difference? Because it follows from the property (28) of events, that if «!> is an event, the formula Q(true, (p) is false at every (nonpoint) interval; thCTefore a mapping of die form (•, true, <f>) could not be used to construct any useful formula.
 N o such restriction applies to states.
 The meanings of for and (with)in can now be given by means of the mappings: (38) (with)inX ^{o,[X],o) 09) for X^{o,[X], a).
 In addition, we take the temporal restriction [four hours] to be true of all and only those intervals whidi are 4 hours long, regardless of when they start (similarly with [2 minutes]).
 With the aid of these mappings, the translation process outlined in the last section can be applied to sentences (31) and (32) to give the mtuitively correa truthconditions: ^This claim is controversial, and most writers on the subject of aspectual class would distinguish additional possibilities.
 See, e.
g.
 Allen (1984).
 Most obviously, it might be objected that the state of Mary's working on the program does not hold over very short intervals or over short pauses (head scratchings, tea breaks).
 Our reply is that it is open to the semantic theorist to claim that tenseless sentences describing states are true over such intervals, a position we believe to be (surprisingly) defensible.
 See Herweg (1991) for an interesting discussion of states and events.
 (40) t=/o 0{[day], o{[four hours], D(true, [Mary work on the paper]))) (41) |=/o 0{[2 minutes], o(true, [The ferry sink])).
 This account immediately yields the prediction that sentence (33) is unacceptable: translation step 2 would produce triples of the form (o, r, •) and (o, true, <^).
 which cannot fiase because the operators clash.
 The imacceptability of sentence (34) also becomes clear on our account.
 Applying the translation process yields: (42) h/„ D{[day], o{[four hours], o(true, [Mary work on the paper]))) But it follows from the definition of a state that (42) is logically equivalent to the simpler (43) \=io 0([day],o{tTXi.
e, [Mary work on the paper])) so that the prepositional phrase becomes redundant.
 Again, w e see our linguistic intuitions functioning so as to filter out logically useless combinations.
 Of course, irregular sentences such as (33) can, imder certain circumstances, be given sensible interpretations.
 The circumstances include cases where a sentence normally describing an event is reinterpreted as a process, either by cancelling the implied point of completion or by taking the evait to be repeated, for example: (44) Mary painted the house for three hours (45) The hamster pressed the button with ijs snout for three hours.
 In sentence (44), the implication is that Mary did not complete painting the house; in sentence (45).
 the implication is that the hamster repeatedly pressed the button.
 This phenomenon of' coercion' of tenseless sentences from one aspectual class to another is discussed in some detail by Moens and Steedman (1988).
 In this paper, w e have pretended that the aspectual class of underlying tenseless sentences can be determined unambiguously and independently of tense, aspect and temporal adverbials.
 Of course this pretense is just that  a pretense  and has been made merely to bracket an issue which has been discussed elsewhere.
 If some starred sentences in this paper seems to make sense in some circumstances, that is probably because w e have ignored aspectual class shifts of this kind.
 It is.
 however, worth noting where our accoimt parts company with that of Moens and Steedman.
 Moens and Steedman introduce a basically Vendlerian system of 5 aspectual classes: states, processes, culminated processes, points and culminations.
 They claim {ibid.
 p.
 20) that/oradverbials can only be used with process expressions; and they fjoint out that those 121 sentences such as The ferry sink, which cannot easily take/oradverbials, are precisely those that cannot easily be coerced into processes.
 The basic problem in evaluating Moens and Steedman's claim is the lack of any formal definition of process.
 For exany)le, on the face of it.
 the sentence (46) They were married for four years combines a/oradverbial with a state, not a process.
 Is a state sometimes a process? Or is it that a state is being coerced into a process? If so.
 what is the difference in meaning between a state and the process into which it is coerced? The account of the difference between states and events (including processes) on p.
 17 leaves the matter unclear.
 More seriously, consider the sentences: (47) Mary telephoned John one day (48) Mary telephoned John every day.
 Note that only the latter can be combined with a/oradverbial whose argument is a duration longer than a day: (49) * Mary telq)honed John one day for 2 weeks (50) Mary telqjhoned John every day for 2 weeks It would seem, then, that sentence (48) would have to report a process, and sentence (47) a nonprocess.
 More generally, one might suppose, universal quantification always (sometimes?) results in processes and existential quantification always (sometimes?) in nonprocesses.
 Is this generalization correct? W e do not know, because Moens and Steedman provideonly vaguedefinitionsoftheaspectualclasses.
 Withsuch d^nitions.
 it is sometimes difficult to extract firm predictions from their approach.
 Our q)proach, by contrast, handles sentences (49) and (50) unproblematically.
 Sentence (50) translates to (51) |=/o o([two weeks], 0([day], o(true, [Mary telephone John]))) in the way described above.
 Soitence (49), on the other hand, caimot successfully be translated.
 Translation step 2 produces triples of the form (o, [two weeks], •) and (o, day, _ ) , which cannot fuse (in the only sensible order) because the operators clash.
 Note that this explanation of the unacceptability of sentence (49) is essentially the same explanation as that given for the unaccq)tability of sentaice (33).
 Tlius, w e do not need to worry about the definition of "process" in deciding whetha /oradvCTbials can be used.
 The only relevant considaation is whether the sentencefragment governed by such an adverbial can sensibly be universally quantified.
 If the sentencefiagment in question is an existentially quantified expression like Mary telephone John one day, then universal quantification is ruled out explicitly.
 If the sentencefragment in question is a basic toiseless sentaice reporting an event (in our sense), such as The ferry sink, then universal quantification is ruled out because it would automatically result in a false statement.
 Similar remarks apply to the sentences (52) * Mary telephoned John every day within two weeks (53) * Mary telephoned John one day within two weeks The former will be not be translated because of an operator clash: the latter would result in the translation (54) |=/„ o{[two weeks], o([day], o(true, [Mary telephone John]))) which can immediately be seen to be logically equivalent to the simpler sentence (55) h/o ^([c/ay], o(true, [Mary telephone John]))) .
 Note that this explanation of the unacceptability of sentences (52) and (53) is essentially die same explanation as that given for the unacceptability of sentence (34).
 Hie only aspectual class distinction we require is between events and states as defined above.
 Note, incidentally, how our account correctly handles the amusing pair of sentences (56) Mary worked on the paper evoy day for four hours (57) Mary worked on the paper every day for four months which diffa only by the substitution of months for hours.
 The correct translations (58) N/c ^{[day], o{[four hours], •(true, [Mary work on i.
he paper]))) (59) t=/o o{[four months], Di[day], o(true, [Mary work on the paper]))) are produced automatically by our scheme, because translation stq) 3 is now constrained to consider only 'sensible' orderings.
 In particular, any operatortriple containing the restriction [four months] must be ordered to the left of any operatortriple containing die restriction [day]; and any operatortriple containing the restriction [day] must be ordered to die left of any operatortriple containing the restriction [/oar hours].
 Conclusions In diis paper, w e have shown how a small collection of English temporal adverbials can be systematically mapped to a restricted temporal logic.
 Our translation scheme specifies die contribution diese adverbials make to the truthconditions of 122 sentences in which they figure, and thus yields an account of their meaning.
 Only a small part of our translation scheme.
 the full version of which can deal with all English temporal prqx)siti(His.
 has been presented here; however, we have been able to convey two of its essential and novel features: (1) The translation process allows the iteration of ten̂ )oral adverbials within a sentence, and fails (or produces easily detectable redundancies) for many sentences which soimd unacceptable.
 TMs enables us to see our linguistic intuitions as performing the useful logical function of filtering out useless adverbial combinations.
 (2) The tenqx>ral logic used to give the truthconditions of sentences has limited expressive power.
 In particular, the operators only allow quantification over subintervals of a fixed interval.
 T M s observation helps us chart the expressive power of the English tempcnal adverbials covered by our account.
 References Allen.
 James F.
 (1984).
 Towards a general theory of action and time.
 Artificial Intelligence 23,123154.
 Brachman.
 R.
 and J.
G.
Schmolze (1985) An overview of the K L  O N E knowledge representation system.
 Cognitive Science 9(2), 111216.
 Bree.
 D.
S.
 and Pratt J.
 (forthcoming 1995).
 There exists ausefiil set of universal temporal features.
 In Proceedings of the workshop on time, European Conference on Cognitive Science, St.
 Malo.
 Gabbay.
 Dov M.
,Ian Hodkinson and Mark Reynolds (1994).
 Temporal Logic: Matiiematical Foundations and Computational Aspects \ol.
 1.
 Oxford: Clarendon Press.
 Herskovits.
 A.
 (1986).
 Language and Spatial Cognition: An Interdisciplinary Study of the Prepositions in English.
 Cambridge: Cambridge University Press.
 Herweg, Michael A.
 (1991).
 A critical examination of two approaches to aspect.
 Journal of Semantics 8.
363402 Hwang, Chung Hee and Lenhart K.
 Schubert (1992) "Tense trees as the 'fine structure' of discourse" in Proceedings of the 30th Annual Metting of the Association for Computational Linguistics Newark.
 D E Lakoff.
 G.
 (1987) Women, Fire and Dangerous Things.
 Chicago: University of Chicago Press.
 Moens.
 Marc and Mark Steedman (1988) "Temporal Ontology and Temporal Reference" Computational Linguistics 14(2).
 1528.
 Rice, Sally A.
 (1992) Polysemy and Lexical Rq)resentation: The case of Three English Prqxwitions.
 In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, N.
J.
 Lawrence Erlbaum.
 Richards.
 B.
.
 Inge Bethke, Jaap van der Does and John Oberlander (1989) Temporal Representation and Inference.
 London: Academic Press.
 Suppes, R (1976) Elimination of quantifiers in the semantics of natural language.
 Revue International de Philosophie 1178,243259.
 123 Material O b j e c t Transfer a n d C o m m u n i c a t i o n of Ideas Analogy of Naive Theories and its Linguistic Manifestation Arthur Merin Institute of Language and Computation (IMS) University of Stuttgart Azenbergstr.
 12, 70174 Stuttgart, Germany arthur@ims.
uniStuttgart.
de Abstract Analogies between material object exchange and communication abound in figures of speech, e.
g.
 "exchange of ideas" But, as transfer of information entails no loss of it to the donor, the obvious analogy fails.
 To explicate, I consider first a formal, minimal naive theory O T M of object location/possession and transfer.
 Failure of the obvious analogy translates as absence of any intuitable model of communication related to O T M by an isomorphism which maps people ("possessors") to people, and objects ("possessions") to ideas ("propositions", "infons").
 Isomorphisms to a counterintuitive model M C M of communication and belief are, however, exhibited which map objects to people ("believers") and persons to ideas.
 Under the interpretation appropriate to M C M , the schemata of crucial postulates of O T M instantiate to epistemic instances of the Laws of Contradiction and Excluded Middle.
 M C M features complementary ideas which, as it were, appropriate or lose adherents.
 Empirical instantiations of this apparently counterintuitive theory are shown to occur in the lexicologies and ideologies of possession by ideas (and, perhaps, by their yet more anthropomorphic spirit avatars) and in the grammar of expressions for a change of mind.
 Thematic role structure, relations to "middle' constructions and, briefly, use in verbal action are discussed.
 I conclude that the mental leap reflected in the linguistic data warrants use of moderately formal tools to investigate open class lexica of natural languages for underiying theories.
 Communication as Exchange? What is cormnunication? "An exchange or at least transfer of something, viz.
 information", says common sense.
 Languages tend to concur.
 The "conduit metaphor" [CM] (Reddy, 1979) offers getting a thought across and giving ideas.
 And when Eve tells A d a m the time.
 Eve gives, and A d a m receives information.
 Moreover, canons of gossip  exchange of confidences — bespeak an obligation to repay in kind.
 But the analogy suggested by C M meets an obstacle.
 If you give away a material object, you no longer have it.
 Whereas imparted information is not thereby lost to you (Leach, 1970:110 contra LeviStrauss, 1945).
 A m o n g people, only rights to and advantages of its exclusive use are alienable.
 This difference, reflected already in phrases such as imparting or sharing information, also prompted wellknown distinctions in the linguistic literature following Gruber (1965) between physical, abstract and indeed mental transfer.
 Ask next: what is a criterion of analogy? Standardly, the existence of a structurepreserving map (homomorphism) of relational structures.
 I therefore consider a grossly underspecified, axiomatic theory having a model O T M of object transfer, just complex enough to engage intuitions of exchange.
 I then look for an equally simple model in the domain of communication (i) related to O T M by a structure and cardinalitypreserving map, i.
e.
 an isomorphism, and (ii) engaging the intuition that communication brings about changes of epistemic state.
 Then I exhibit empirical instances of the same analogy in natural languages.
 One objective is to show how the search for isomorphisms ~ taken literally and pursued formally  can elicit metaphoric structure which has remained unexplored to date.
 Another objective is to investigate the metaphoric correspondence for its bearing on current debate concerning the semantic content of "thematic relations" (Dowty, 1991; Gruber, 1965; Jackendoff, 1990) that intertwine spatial, causal and social constraints.
 Point of departure for the analysis is an attempt by Luc Racine (1986) to characterize elementary notions of reciprocity in terms of a simple paradigmatic situation and some of its structural constraints.
 Racine's Model of Material Object Transfer: OTM Racine (1986) offers for consideration a system of two persons (more abstractly: 'poles')  call them A d a m and Eve ~ and two material objects, X and Y, such that each object can be held by at most one pole at any one time, and must be held by at least one at any given time.
 This yields a set of 4 possible states.
 In close to Racine's graphic notation: ^00 lAxY' E.
J Sqi [A^.
; E.
yJ Sio lAy; ExJ S|| [A.
.
; ExyJ He then considers possible changes of state, i.
e.
 transitions in which objects move from pole to pole.
 Abstracting from distinctions of perspective ('giving' vs.
 'receiving'), which evidently are not represented in such a simple structure, he first considers transitions that preserve information about source and target.
 Example: X moves from Elo A.
 Not finding interesting structure there, he abstracts further, considering transitions of the form "X moves" and aims to identify the product of such transitions, which are their own inverses, with themselves as the underlying structure of the notion "loan (and return)".
 The product of two distinct transformations is to be identified with the notion "exchange".
 124 mailto:arthur@ims.
uniStuttgart.
deThis enterpnse could not be wholly successful.
 At the level of extreme abstraction chosen by Racine crucial distinctions of sequence collapse: "loan" cannot be distinguished from no transaction at all.
 Similarly for distinctions of initial and target state; exchange" requires initial and final states where not both objects are held by one party alone.
 Despite its failure to serve the intended sociological purpose, Racine's simple paradigm is a useful point of departure for analyses of semantic structure in which, as so often (Lakoff & Johnson, 1980:17), spatial representations provide the basic organizational pattern.
 However, we shall see that a very abstract structure (specified, if anything, in "propositional" terms, to use the terminology of Lakoff 1987:118) provides our basic naive theory.
 Its most natural concrete mode! is indeed spatial.
 But there is also a fairly compelling sociological model, albeit one of which intuitively important features are left underdetermined by the abstract theory.
 To investigate precisely what constraints implicit in intuitive theories are captured by which structural relations of our explication I propose to invest in machinery more often met in closedclass semantics.
 (Hoping to convince the empiricallyminded reader in due course that there is some payoff to such tedium after all.
) Recast in formal terms Racine's paradigm is a structure OTM = <Indp, Indo; Rel; Sto; Pop; Op> where Indp = (E,A ] a set, intuitively of two persons ("poles"); Indo = {^Y] 3 set, intuitively of two material objects; Rel a set of binary relations /?y c Ind^xlndp, intuitively "is held by" or "is in the possession of (or "is located at"); Sto = {Joo.
̂ oi.
̂ io.
̂ ii} a set of (types of) 'social states'; Pop c PF(Sto), the set of partial functions Sto  Sto; O p = {x,y,z,I} c PF(Sto) is a set of total unary operations; and [ 1 ] Each of X, Y is /?related to ("held by") exactly one of A,E.
 Put differently: [1'] Rel is, extensionally, the set of (total) functions Indo  Indp.
 aye XAYA „  V : ^ XAYE A eya * ' exa I axe XEYA exa axe aye t ^^111^*1 XEYE eya Figure 1 (Gr 1) Mnemonic labels aye etc.
 denote these statetransitions (Fig.
l).
 Example: XAYA := " X is held by A , Y is held by A"; axe := X moves from A to E.
 If w e add function composition, e.
g.
 exaaye, graph Grl becomes a small category (specifically: a groupoid).
 However, intuitions that distinguish sequentiality from simultaneity, and "forthandback" from "no change" cannot be so represented.
 They are if we treat the graph as an abstract machine and let pairs <initialstate,stringofedgelabels> represent transactions, indexing states by times r,.
 Then one can project (as Racine more or less did on the way to less attainable goals) upon a sequence of transitions X A Y A „ ayeXAYE,2eyaXAYA,j the sociological description "loan of Y by A to E, and return of Y ".
 (Though no constraint precludes e.
g.
 "theft and recovery".
) And upon a sequence X E Y A „ — a y eXEYE,2exaXAYE,^'t.
\c\vax^gt in which A gives Y to E and E gives X to A" or "in which E robs A of Y and A robs E of X .
 The latter should instantiate typical forms of reciprocity or retribution.
 O n paf)er this projection sounds less than compelling.
 But the thesis (and one I expect to be substantiated soon) would be that experimental setups a la Michotte (1963) mildly cued will reveal their conceptual salience.
 Yet for now what matters is not ecological salience, but the conditional: "If salience here, then salience there".
 "Here" is O T M .
 What, then, is "there"? Communication and Exchange In [1] "exactly one" thus factors into "at most one" and "at least one'.
 Correspondingly [1'] requires that any R £ Rel be a partial function and lefttotal.
 W e identify each s.
, c Sto with an R,j c Rel.
 (By [1 ]/[!'] card(Rel) = 4.
) Extensionally, any R c Rel is a set of (two) ordered pairs <a,P> (a e Indo,P c Indp).
 I.
e.
 <a,P> e R iff a/?p := "a is held by p".
 Mnemonicaly labeled: Sni XAYA] XAYE] s,o I XEYA ] s„ [XEYE] := {< X.
A >,< Y,A >} •.
= [<X.
A>,<Y,E>] :=(<X£>,<y,>4>} •.
= {<X.
E>,<YE>] Thus, Pop consists of partial functional [Indo  Indp]  [Indo  Indp].
 Racine (1979) had also considered information exchange, presupposing the message / object analogy.
 Information "units" are "held" by persons and distributed as the case may be.
 This setup (not to be confused with rather more sophisticated theories of information economics) yields no useful formal structure.
 Pleasant and ubiquitous as the analogy proposed by the conduit metaphor is, in which information objects ("propositions" or, if you will, "infons") take the place of material objects, it does not extend well.
 If "held by" spells "believed by" (conflate with "known to" for the nonce) there is no useful intuitive interpretation for a structure with persons A, E and propositions X,Y such that [#] "Each of X,Y is believed by exactly one of A,E (at any time/state)".
 Relations admitted by [#] would characterize states in which just one person believes both propositions (and the other might be 125 fully agnostic) along with states where each person believes a different proposition.
 N o intuitable model of communication seems to tit this pattern.
 The prototype relation of being in possession of, like that of being spatially located at, is a function.
 The relation of being known to or believed by is not.
 If proposition <I> is believed by Eve (E) it might as well be believed by A d a m (A) too.
 N o w consider a situation where E comes to believe <I>, whereas A doesn't (yet).
 But then A comes to believe <!> too.
 In many contexts we should infer that E had communicated O to A (or persuaded A of <I>).
 Having just three individual entities A, E, O there can be no strict analogy, i.
e.
 isomorphism, to a comparably sparse model of object transfer which engages, however crudely, the notion of exchange.
 But now consider a structure MCM = <Jndp, JndoiQel; Stc; Pep; Cp> where Jndp = {E,A} a set, intuitively of two persons ("poles"); Jndo = {X,Y} a set, intuitively of two material objects; Qel a set of binary relations Q^ c Jnd„xJndp, intuitively "believes" or "is committed to"; Stc = {Coo,Ci,„C|„,c„} a set of (types of) "conrunittment states"; Pep c PF(Stc), the set of partial functions Stc  Stc; C p = |x,y,z,I} c PF(Stc) is a set of total unary operations; and Qel contains all and only those Qij in Jndp x Jndo satisfying [2] Each of A, E is Qrelated to ("believes") exactly one of X,Y.
 Thus: [2'] Qel is the set of (total) functions Jndp  Jndo.
 Given [2], what pairs of propositions would be natural instances for X, Y ? Well, pairs such that Y = >X, i.
e.
 pairs of contradictories .
 For then the requirement that Q be a partial function would be the epistemic correlate of the "Law of Contradiction" [<X & >X)]; and the requirement that Q be total the epistemic correlate of "Excluded Middle" [X V >X].
 (A partition {X, >X} is familiar as a binary issue or, as statisticians say, a dichotomy.
) As in the case of "exchange", we need three (suitable!) states and intervening transitions to impute communication.
 E.
g.
: AXEX,,xeyAXEY,2xayAYEY,3.
 Intuition: to start with both E and A believe X; now E changes her mind (endo or exogeneously) then A changes his (Fig.
 2 ).
 xey AXEX , A yei :*lAXEY yax My yax xey xay AYEX ^ yex Figure 2 (Gr 2) ^ A Y E Y Without cueing this description is hardly compelled by the structure.
 (We want experiments in the vein of Michotte 1963 and Premack 1990.
) But it is consistent with it and can thus motivate epistemic interpretation of states.
 Analogy and its Linguistic Reflexes Look at our twosorted domains Ind := {A,E,X,Y} and Jnd := {A,E,X,Y} and the two corresponding sets of possible states given by Rel and Qel.
 There are 4! = 24 distinct bijections from Ind (a 4element set) to Jnd (a 4element set).
 Only 4 of these extend to /?isomorphisms: exactly those which map the persons of Ind to the propositions of Jnd, and the objects of Ind to the persons of Jnd.
 W h y ? A mapping (fr̂: C  D where D and C are sets endowed respectively with relations R and Q is an Rhomomorphism iff R and Q are similar relations and, for any c,, ĉ  in C, if c,Rc2 then ijfCiQ tfrĉ.
 The homomorphism is an Risomorphism iff it is also a bijection, i.
e.
 maps each element of C to exactly one element ofD.
 What makes relations R and Q of same arity "similar"? An abstract characterization of this is needed to if questions are not to be begged.
 And it is supplied by [1'] and [2'].
 If one or both persons were mapped to persons by a bijection ij/, one or both objects would be mapped to propositions.
 But whereas any admissible relation on Ind^ x Indp is a function, not all admissible relations on Jnd^xJndp or on A x B (where A = Jndp, B = Jndo, and card(A) = card(B) = 2 and A u B = Jnd) are functions.
 Only those on Jndp x Jndo are all functions.
 Hence ij/ would not in general preserve /?structure.
 N o w the mere existence of isomorphisms does not guarantee good analogy (witness the late Klein4Group Cargo Cult).
 Goodness also depends on how much structure ignored by simplification to isomorphic models would be preserved under mapextensions defined on models of theoryextensions.
 Here this means: do families Rel and Qel and their (co)domains have more in common than comprising functions from twoelement sets to twoelement sets? Consider the relations denoted by is held by.
 Isomorphic transfer from Sto to Stc yields partial Stcdescriptions of the form "Person a is held by Proposition p".
 This accords poorly with the English expression of persons "holding beliefs".
 However, substituting adheres to or is committed to yields a smoother fit; and even sociological sense.
 Witness Menger's (1934) sociologistic notion of the extension of an idea (proposition): the set of persons believing it.
 More importantly, the kind of apparent role reversal undergone by persons in the mapping is routinely lexicalized in natural languages.
 People can be possessed, besessen, possedes, etc.
 by an idea or by a belief.
 It can take hold of you; have you in its grip; and so on.
 And in its properly anthropomorphic form the notion has been keeping exorcists busy for all of time memorial.
 Possession by spirits is a good candidate for an anthropological universal.
 If so, a naive, tacit theory of communication in which ideas are, if anything, agents — and believers, if anything, patients (cp.
 Dowty, 1991 on clusters of properties for "protoagents" and "protopatients") takes on a significance wider than is usually conceded to dead metaphor.
 The moment of exclusive control that defines possession of objects in the law (cf.
 the Oxford English Dictionary) has a counterpart in the constraint on conduct which commitment to an 126 idea involves.
 And in turn, material goods committed to a purpose are, in effect, under the exclusive control of (whatever serves) that purpose.
 Such relations are asymmetric, and so are their linguistic reflections.
 Example: John is (ruled/governed /dominated by /in the grip of) the (idea /belief/ that the earth is flat, but *The (idea/beliefJ that the earth is flat is (ruled/ governed/dominated by /in the grip of} John.
 Even the closedclass lexicon (possessive preposition of) and inflectional morphology (German Genitive) arguably concur.
 You can be of the opinion that, de I'opinion que, der Meinung, dass, or jointly of one mind, du m i m e avis, einer Meinung or eines Sinnes, or, by German contrast, geteilter Meinung when opinions are divided.
 Suppose we pursue the analogy.
 From the picture of conflicting ideas, which come in complementary pairs and appropriate or alienate adherents, to Durkheimian "collective representations" and supraindividual "social forces" it is but a small step.
 Its value to Anthropology writ large is not my business to judge.
 In simple anthropology, however, we note the use of such representations in verbal action: to downplay personal responsibility.
 The best known grammatical correlate of such efforts at disingenuousness is, of course, the passive voice.
 But here we get something less familiar.
 In M C M persons move between ideas, just as in O T M objects move between persons.
 A change of mind, opinion or ideas corresponds to a change of hands, viz.
 a change of owner or possessor.
 Objects change hands, persons change their mind.
 The change is not gradual; i.
e.
 minds and hands are not worked as "incremental themes' in the sense of Dowty (1991).
 Widely taught European languages differ slighdy in imputed degree of agentivity.
 French partitive Jean changea (d'avis / d'idee/d'opinion), like pronoun and articlefree English John changed (hands / owner / possessor / colour} represents the subject as undergoing the change rather than initiating it.
 Changer de leaves open who, if anyone is agent or patient.
 Says Tresor de la language Frangaise, salomonically: "the change affects both subject and object".
 Change possessor / owner, change hands and change sides cannot be transitiveV>fP (verbobject) constructions (pace Oxford English Dictionary) but are fairly idiomatic intransitive complex verbs.
 Test: change won't passivize as in transitive occurrence.
 Thus we have * (Hands / Possessor / Colour) (were / was) changed (by the ball).
 English gives thinkers a more active role: mind does not pattern with colour and needs a possessive pronoun agreeing with the activevoice grammatical subject: John^ changed hisj mind.
 Note the oddity of any reading with >(i = j), whose sarcastic ring will indicate flouting of a constraint.
 Unlike crane his neck, however, change his mind admits nonidentity subjects if they denote facts or environmental eventualities, e.
g.
 (The weather /Meeting Kim / ?Kim} changed Sandy's mind and Sandy's mind was changed by (the weather/ ?Kim}.
 Closer here than Fr.
 changer d'avis is se changer les idees as in Je m e change les idees.
 And it is similar in that Cela m e changea les idees is attested (T.
L.
F), but the likes of Jean m e changea les idees are odd.
 German is neutral: Jo wechselte die Ansicht ("Jo changed his point of view"); (Jo /Das Geld) wechselte den Besitzer ("Jo / The money changed possessor") have the same syntax as Jo wechselte (die Farbe /das H e m d ) ("Jo changed {colour / his shirt"}; cp.
 Fr.
 Jo changea de veste).
 In sentences of this form.
 e.
g.
 Der Ball wechseltden Besitzer (word for word: "TheNOM ball changes thence possessor") the subject, prototypically in Agent role (cf.
 Jackendoff, 1990), is here, in the reality of legal imputability, the patient.
 Whereas the legal agent is in object position with accusative case marking.
 But for many German speakers too Jo^ dnderte seinê  Meinung is subject to a constraint Consider also the minimal pair John moved (i.
 house / ii.
 (the /his) house).
 In (i) John moves; in (ii) the house.
 As in John changed (i.
 sides / ii.
 (the / his}} sides.
 It is the notion of "undergoing a change"  changing position with respect to a given coordinate system  that informs the simple absolute forms m o v e ( N / N P ) and change ( N / N P ) and distinguishes them from transitive move N P and change NP, which do not require nonanimacy of the N P denotatum.
 John changes (hands/his mind) is, in this semantic respect, like a "middle" construction", such as This fabric washes easily.
 Fagan (1992:2) notes for IndoEuropean middles: "surface subjects that are notional objects", and inability to specify notional agents with^>'PPs.
 Benveniste (1972: Ch.
 14) sees the subject as "doing something which happ)ens to it".
 K e m m e r (1993) ranges beyond IndoEurope and offers, somewhat like Benveniste, (i) "initiator as affected entity" along with (ii) "low degree of elaboration" of event structure.
 Persons who change their mind are, in M C M , being represented as affected entities, i.
e.
 Themes in the spatially rooted sense of Gruber (1965) and Jackendoff (1990).
 And yet surface form of our example constructions with change leaves agency very often ambiguous.
 This brings us to Kemmer's second criterion, which is said to subsume the first.
 Here we have a more specific formal correlate, which also reveals another twist in the metaphoric correspondence.
 More Abstract State Transformations In OTM any basic nonidentity transition connects two states.
 Racine aimed to explicate notions "loan" and "exchange" by elements of the "Klein 4" (Dj) group (x,y,z,r) of maps in O p on Sto (see Figure 3 ).
 (The canonical model of this group are the symmetries of the rectangle: flips around the vertical and horizontal axis, and rotation through 180°  around the center of gravity.
) Each of x,y,z composed with one of the other two yields the third.
 And any transformation is its own inverse: composed with itself it yields the identity transformation / ("no change").
 XAVA * XAYE XEYA Figures Racine's descriptive appeal to algebra was misguided.
 Even 127 ignoring temporality and the structure of obligation, z (i.
e.
 xy) would cover unilateral appropriation / alienation of all "assets" no less than reciprocal exchange.
 However, for present purposes some linguistic and diagnostic interest attaches to such abstraction from directionality and perspective.
 First, one can plausibly identify jc with the intuitive notion "X changes hands", similarly y for Y\ and their product xy = z with the notion "Both objects change hands".
 (As long as one considers initial and resulting states alone.
) Secondly, the nonidentities (any one of which is the product of the two others) generate subgroups (x,I), (y,!) and {z,l) of O p that each partition Sto into orbits: sets of those states which are transformable by elements of the subgroup into one another.
 Adding natural descriptions w e get Sto/x := {{XAYA.
 XEYA], {XAYE.
 XEYE]} •Y is held by A", "Y is held by E" Sto/v := {{XAYA, X A Y E ) , {XEYA.
 X E Y E } ] 'X is held by A", "X is held by E" Sto/z  { { X A Y A , X E Y E ] , {XAYE, XEYA]] both are held by one","one is held by each" The descriptions for the orbits of (z,l) are the most general nontrivial descriptions among those available in that they do not make reference to specific individual entities .
 Those for Sto/j: and Sto/y must always refer to specific individuals.
 W e can characterize the two disjoint sets of states in Sto/z more laconically yet by intuitive, naturalsounding predicates of states: {XAYE, XEYA) := balanced states; {XAYA, X E Y E ] := unbalanced states If suitably intuitive values attach to objects, then balanced states are those where the difference between the two persons' intersubjectively assigned assetvalues are at a minimum (or, for present purposes, zero).
 A n "exchange" always transforms balanced states into balanced states (and, if not simultaneously, then by way of an unbalanced intermediate state).
 In M C M let C p = (a,d,e,J} be the elements of the Dj transformation group acting on Stc (Fig.
 4), interpreted respectively, as A changes his mind (from X to Y, or Y to X ) , E does, both do, neither does.
 A X E Y A Y E X A V E Y Figure 4 W e obtain Stc/a := { { A X E X , A Y E X } , { A X E Y , A Y E Y } } ; "E believes X", "E believes Y" Stc/e := { { A X E X , A X E Y ) , { A Y E X , A Y E Y ) } "A believes X", "A believes Y" Stc/d := | { A X E X , A Y E Y } , | A X E Y , A Y E X }} "both believe the same","each believes something different.
" Again, one of them, Stc/d, stands out by generality of description.
 Two more intuitive ways of describing the equivalence classes in Stc/d, with respective psychological and sociological slants, are: {AXEX, AYEY} := the two persons agree; {AXEY, A Y E X ) := the two persons disagree .
 Call these two classes respectively the sets of harmonious and of disharmonious states.
 N o w {AXEX, A Y E Y } , the set of harmonious states in Stc, is the set of initial and final states for what comes closest to a transaction of communication in M C M .
 And the set {XAYE, XEYA ] of balanced states in Sto is the set of initial and final states for what comes closest to a transaction of exchange.
 Thus, an isomorphism from the ObjectTransferGraph Grl to the MindChangeGraph Gr2 that maps "exchange" to "communication" must map balanced to harmonious states.
 So there is no set of maps firom the ObjectTransfer structure to the MindChange structure which both maps 'exchanges' to communications' and preserves the internal structure of states (stateisomorphism)! This is easy to see.
 Structural labels XEYA and X A Y E (balanced states) each contain four alphabetically distinct letters; A X E X and A Y E Y (harmonious states) each contain only three.
 This second twist perhaps occasions in part the unobviousness of the analogy.
 Communication in M C M , unlike what one would expect from the notion of exchange, corresponds to unilateral appropriation of believers by one idea.
 Descriptive nongenerality also happens to correlate with intuitions of instability.
 There is a common presumption that unbalanced (inequality) states should tend to change to balanced (equality) states; and that disagreement should be resolved to agreement.
 This takes us from kinematics (specification of how systems can change in time), well into naive dynamics (how they should tend to change, given initial conditions).
 Conclusions and Implications Each semantic field, writes Jackendoff (1990:27), has particular "inference patterns".
 His example is, not wholly surprisingly, the spatial domain seen through its "fundamental principle" that an object cannot be in two disjoint places at once.
 And he points out, in line with tradition, that information which goes from one person to another will "be" at, or with, the target of the transfer (as in the spatiotemporal domain of objects) but will not thereby (unlike in the spatiotemporal domain of objects) cease to be at the source.
 So this part of the inference  that an entity going from one location to another will no longer be at the first  now fails to go through.
 Jackendoff concludes that this presents an argument for decomposition into "features" of meaning.
 The present example shows that attention to features that 128 combine additively, wedded as it is to strong intuitions of content, would dispose one to overlook a significant structural aspect of lexical and, if you will, metaphoric relations.
 Viewed more abstractly, and treating wouldbe inference patterns as axioms of theories with models in more or less concrete relational structures, lexical relations can be investigated in properly modeltheoretic terms.
 One advantage of proceeding thus, expensive as it might seem, is that we get characterizations of structure which are independent of particular contents of specific concrete models.
 It becomes much easier then to decide which features of a given concrete model can be specified in structural terms (and hence are indeed accounted for by one's intended account of metaphor) and which ones are unexplicated contraband.
 The abstract theory, of which two socioeconomic and socioepistemic models are presented above, is most compelling in the purely spatial domain.
 It is no accident that the spatiotemporal notion of an entity moving or being located with respect to ostensibly given points reference is prominent enough in lexical semantics to play the ubiquitous role or cluster of roles labelled Theme by Gruber (1965).
 Somewhat less obvious, though not by much, is the correspondence of the spatial constraints  having to be at some place and not being able to be at more than one  to the logical constraints of Excluded Middle and NonContradiction.
 Having the two sets of constraints as constituents of models of one and the same abstract theory might then raise questions about which induced which.
 But then the socioeconomic notion of possession enters the picture and forces one to consider in semantic representation, next to the "thematic" tier of location and motion, an "action" tier of agentpatient relations (Jackendoff, 1990; in line with Culicover & Wilkins, 1984; Talmy, 1985).
 Clearly, uniqueness of possession is as open to qualification as the idea that anything which can be possessed must have some possessor.
 But such a qualification, in the first case and at least in contemporary European cultures, is a deviation from the legal ideal of unmitigated control.
 And even the second aspect may be close to usual expectations; much as Excluded Middle, which common idiom, viz.
 being in two minds, appears to conflate with NonContradiction.
 One question raised by the interaction of three domains intuitively: the spatial, the economic, and the mental  is which of two potentially competing semantic dichotomies, Talmy's and Jackendoff s pair of Thematic and Action tiers or Dowty's two clusters of ProtoAgent and ProtoPatient roles, provides the more productive approach to which class or aspects of lexical phenomena.
 The set of models introduced above, fortuitously or not, appears initially to favour the distinction along Thematic and Action tiers.
 For clearly, the most compelling model of the naive miniaturetheory satisfied by O T M and M C M is that of spatial location and motion.
 Intuitions of properly social relations, apparently economic or apparently doctrinal, are not directly captured by the theory, though consistent with it.
 However, the ease with which constraints proper to these domains latch on to those of the spatial domain in metaphoric transfer bespeaks the power of the second dichotomy of clusters.
 And perhaps the proliferation of notions of "affectedness" in Jackendoff (1990) indicates something else: that w e can start to speak of a cognitive semantics of content only to the extent that w e command theories of the wouldbe domain of denotata which come close in elegance and sophistication to those at our disposal for the physical realms.
 Finally, I should return to a question briefly touched upon: the rhetorical function of deagentivization in M C M .
 This is a characteristic of passives and middles and the less than disinterested use of the former is well established in exculpatory discourse.
 M C M is a reminder that abstract structure of naive theories of communication and cognition has eminently practical, sophisticated uses.
 References Benveniste, E.
 (1972).
 Problemes de linguistique generate.
 Paris: Gallimard.
 Culicover, P.
 & Wilkins, W .
 (1984).
 Locality and linguistic theory.
 N e w York: Academic Press.
 Dowty, D.
 (1991).
 Thematic protoroles and argument selection.
 Language, 67, 547—619.
 Fagan, S.
 (1992).
 The syntax and semantics of middle constructions.
 Cambridge: Cambridge University Press.
 Gruber, J.
S.
 (1965).
 Studies in lexical relations.
 Ph.
D.
 Thesis MIT.
 Repr.
 with revisions in J.
S.
 Gruber, Lexical structures in syntax and semantics.
 Amsterdam: NorthHolland, 1976.
 Jackendoff, R.
 (1990).
 Semantic structures.
 Cambridge, M A : M I T Press.
 Kemmer, S.
 (1993).
 The middle voice.
 Amsterdam: Benjamins.
 Lakoff, G.
 (1987).
 Women, fire and dangerous things.
 Chicago: University of Chicago Press.
 Lakoff, G.
 & Johnson, M .
 (1980).
 Metaphors we live by.
 Chicago: University of Chicago Press.
 Leach, E.
R.
 (1970).
 UviStrauss.
 London: Fontana (Rev.
 ed.
 1974).
 LeviStrauss, C.
 (1945).
 L'analyse structurale en linguistique et en anthropologie.
 Word, 1, 3353.
 Menger, K.
 (1934).
 Moral, Wille undWeltgestaltung.
 Vienna: Springer.
 Michotte, A.
E.
 (1963).
 The perception of causality.
 N e w York: Basic Books.
 Premack, D.
 (1990).
 The infant's theory of selfpropelled objects.
 Cognition, 36, 116.
 Racine, L.
 (1979).
 Theories de I'echange et circulation des produits sociaux.
 Montreal: Presses de I'Universite de Montreal.
 Racine, L.
 (1986).
 Les formes elementaires de la reciprocite.
 L'Homme,26/3,91\\S.
 Reddy, M.
J.
 (1979).
 The conduit metaphor a case of fiame conflict in our language about language.
 In A.
 Ortony (Ed.
) Metaphor and thought (pp.
 284324).
 Cambridge: Cambridge University Press.
 Talmy, L.
 (1985).
 Force dynamics in language and thought.
 In Papers from the list Regional Meeting of the Chicago Linguistic Society.
 Reprinted in Cognitive Science, 12 (1988), 49100.
 129 Predicating Nominal C o m p o u n d s Bernard Jones Centre for Cognitive Science University of Edinburgh 2 Buccleuch Place Edinburgh, EH8 9LW United Kingdom bernie@cogsci.
ed.
ac.
uk Abstract It is generally accepted that in the semantic interpretation of compound nominals there is a set of possible relationships that could apply between the nominal constituents.
 This, however, has not been reflected adequately in the literaUire, which favours very deterministic processing or analyses performed on a pragmatic level.
 This study extends the existing set of relationships described by Levi (1978), postulating a set of rules to predict a subset of these relationships for a particular compound using a unificationbased formalism with typed featurestructures.
 The system shows that by operating on a purely semantic level a small set of valid predicates for the meaning of the whole compound can be obtained.
 Introduction Linguistic approaches to the problem of nominal compounding have tried to classify the compound on purely grammatical criteria, but fail to provide constraints that can consistently explain the semantic interpretation of nominal compound.
 More recently, however, there have been attempts to view nominal compound interpretation as governed by tight semantic constraints.
 Levi (1978) developed a theory of nominal compounding whereby either the head noun is a nominalisation and its modifier is interpreted as an argument of the related verb (a ship builder builds ships), or the two elements of the compound are related by a possible nine specific deletable predicates (e.
g.
 from relates olive oil, have relates government land, and m a k e relates honey bee) The nine predicates are described in more detail later.
 Despite the fact that this approach was criticised for being too pragmatically dependent (Downing, 1977), many computational approaches to nominal compounds are based around Levi's work.
 Finin (1980) was one of the first to use parts of Levi's theory to attempt interpretation of compounds.
 His system, working on a large but restricted set of compounds, generates a single 'strongest likelihood' semantic interpretation using a very specific set of productive and structural rules.
 The system has problems generalising, however, since it would require a virtually unbounded set of rules.
 Isabelle (1984) addresses some of the shortcomings of Finin's work in a reasonably flexible nominal compound resolution system.
 H e addresses compounding in two ways — either the head noun is treated as predicative (so the head subcategorises for the other compound element) or as a nominalisation.
 Isabelle differs from Levi by using six types of nominalisation where the nominalising verb does not necessarily have to be related to the root of the nominal.
 A drawback of this 'nonrelation' is that the system has to be very rigidly specified.
 The system is also rather inflexible generally since each head noun only has one possible predicating verb associated with it.
 The conclusions of linguistic research, that there is a constrained set of possible relations for any given nominal compound, seem to have been ignored in the main.
 One exception is the approach of Hobbs and Martin (1987), which postulates an unspecified predicate that acts between the compound elements, and tries to prove the identity of this predicate using a pragmatic knowledge base.
 This results in all applicable semantic representations that the knowledge base contains being assigned to the compound nominal, but will also mean that all semantic disambiguation is pragmatic, which is not really computationally or linguistically tractable with realworld data.
 A totally different approach to the problem is taken by Bouillon et al.
 (1992), where a large but well defined and closed set of compounds are lexicalised to include a representation of their meaning.
 In any realistic nonclosed system, however, a lexicalisation approach is unlikely to be suitable since a huge lexicon would be necessary.
 Therefore some mechanism is needed that yields the possible interpretations of a compound without resorting to totally lexical or pragmatic methods.
 A small amount of pragmatic postprocessing (which would always be necessary to handle the exocentric and metaphorical compounds anyway) could then produce the most appropriate interpretation.
 Of course, this does not preclude the possibility of lexicalising frequent or difficult compounds (pantyhose, hatchback).
 This paper represents a novel attempt to use these linguistic insights in the development of a widecoverage nominal compound interpreter that will yield a small set of possible relations for every compound processed, dependent on the semantic type of the compound elements.
 Approach The linguistic hypothesis, that for a particular compound there are only a restricted set of possible applicable relationships, can also be stated in a different way if w e assume that the 130 mailto:bernie@cogsci.
ed.
ac.
ukassignment of these relationships is nonarbitrary.
 Namely: for each semantic head of a compound there is a restricted set of relationships that can apply between the head and the other element of the compound (the modifier).
 Similarly, for each modifier there is also a set of possible relationships that can apply between it and the head.
 This simplifies matters considerably since rather than trying to recover the set of relationships given a novel compound, it should be possible to infer the relevant relationships from the components of that compound.
 In addition, given that multiple predicates will be associated with each nominal, it is easy to produce a set of predicates as the output of the analysis stage.
 The assignment of predicates will be based on the application of worldknowledge to the compound elements, and there are essentially two locations where this knowledge can be encoded.
 If the information is lexicalised then the entry for each possible compound head would contain a characteristic set, Shead, containing all the predicates that could possibly be applied to a compound with that head (1).
 Such a system could easily result in overgeneration of interpretations, unless the choice of predicates is made with respect to the modifier, in which case some of the world information needs to be stored in the grammar anyway.
 (1) Shook = {physicalcomposition, subject, use.
.
.
} paperback book, physics book, spelling book.
.
.
 The alternative to lexicalisation is to place the information in the grammar and make use of the semantic features of the compound elements to decide which rules to apply.
 This solution is necessarily less specific than the previous one, since the identities of head and modifying elements must be generalised by some form of type system, but it is far more efficient to write a rule, Tlreiation, or set of rules for every possible relation that could hold between elements than including a set of such relations in every single lexical entry.
 Thus basic grammatical rules are necessary, each encoding one predicate, that require a head and/or modifier of a particular semantic type in order to be applicable to the compound in question.
 (2) illustrates the putative rule for relation physicalcomposition.
 (2) Uphyacomp iff [ head=concrete & modifier=physical] concrete dog, but not concrete idea or sun dog The problems and relative merits of these approaches lie in the tradeoff between lexicon size (and plausibility) and restricting the possible relations.
 Both approaches have advantages in particular situations, but the problems with the lexical approach are of a more serious and fundamental nature if we are to aim for a general coverage of compounds.
 Therefore a rulebased approach, with its associated possibility of slight overgeneration, has been chosen here.
 Predicate Hierarchy The predicates necessary to semantically interpret nominal compounds will range from the most specific, designed to capture a precise relationship between specific nominal elements.
 to the most general, designed to act as a catchall, encoding a very generalised meaning for nominal compounds which none of the more specific predicates have captured.
 The most appropriate format for such a set of predicates therefore is a hierarchy.
 To act as the root node of the hierarchy a general compound predicate is necessary that has minimally specified arguments, but yields a standard interpretation for a nominal compound.
 A rule encoding such a predicate will have to generate a grammatical entity that incorporates the syntactic features of the head element of the compound and that semantically links the head to the modifier through a nonspecific (or null) predicate.
 At deeper levels of the hierarchy, there are many possible predicates that represent the set of possible relationships between two nominal elements.
 A compromise must be found between overspecificity and overgenerality.
 The former will lead either to impossible degrees of overgeneration in the result and overspecification of the predicate arguments, while the latter will lead to a set of results that are too general for productive semantic processing.
 A suitable starting point for a sensible set of predicates is the set of nine that Levi argues are recoverably deletable in the process of complex nominal formation (Levi, 1978, p76).
 These are loosely defined as: CAUSE HAVE MAKE USE BE IN FOR FROM ABOUT In addition Levi's nominalisations (ibid, pi68) introduce a potentially infinite set of predicates corresponding to verbs that have been nominalised through derivational morphology e.
g.
 builder Irom build, invention from invent and error from err.
 There are four types of nominalisation under Levi's system; act, product, agent and patient.
 The further nominalisation types proposed by Isabelle (1984) are not strictly necessary since they are subsumed by other predicates.
 Levi's predicates are rather general, but are suitable for the second level of the predicate hierarchy to act as "attachment points' for more specific predicates.
 Whilst some researchers, notably Finin (1980), have come up with remarkably specific predicate rules, such as dissolvedin, this represents an intractable degree of specificity; therefore the deeper levels of the hierarchy should only contain a small number of predicates.
 The CAUSATIVE predicate, for example can be subdivided into cases where the head causes the modifier (disease cell) or is caused by the modifier (nicotine fit).
 The hierarchy can similarly be extended under the nominalisation rules.
 Wheras agent and patient nominalisations (meat cleaver, student invention) require predicates of arity two (cleave, invent), the act and product nominalisations (birth control, ocean study) require predicates of arity one (control, study).
 Therefore both these nominalisations can be subdivided into cases where the modifier acts as subject or object of the predicating verb.
 The full predicatehierarchy generated by extension of Levi's predicates is seen in Figure 1.
 131 GENCOMP CAUSATION DUETO POSSESSION OWNERSHIP COMPOSITION GENERATE HAVE PARTOF MADEOF MAKE GENUS METAPHOR INHABIT PHYSLOC TEMPLOC EVENTLOO PLACE LOCATIVE INTENDED ACTIVE NATSOURCE TRANSSOURCE SUBJECT CONCERN ABOUT NOMINAL PRODUCT PATIENT  BODYPART  INGREDIENT ACTSUBJECT ACTOBJECT PRODSUBJECT PRODOBJECT Figure 1: Predicate Hierarchy for Nominal Compounds Implementation The nominal compound rule system was implemented in the Acquilex L K B system (Copestake, 1992 & 1993), a typed graphbased unification formalism allowing default inheritance.
 The default inheritance machanism is a very useful way to implement the hierarchical rules — the more specific ones inheriting by default from their less specific mothers.
 The grammatical rules are represented as 3element featurestructures (Figure 2) — the elements corresponding to the result of the rule application and the two arguments of the rule.
 These ruleelements are labelled 0, 1 (modifier) and 2 (head) respectively The specification of the modifier and head noun is necessary to ensure the correct rules are being applied.
 This is straightforward using the type system in the L K B , in particular the cljiss of nominal qualia types, and associated features such as physical form and properties.
 The L K B qualia type hierarchy is shown in Figure 3.
 The most complex rule to define will be the baselevel, general compounding rule (Figure 2), since this will incorporate all the mechanisms for the syntactic and normal semantic specification of arguments and resultant structure.
 Further rules however, for deeper predicates in the hierarchy, will simply inherit this information through the LKB's default inheritance mechanism, and further specify the qualia attributes of the arguments (and the identity of the predicate linking the compound elements).
 Examples (3) and (4) show how the HAVE rule inherits from gencomp, and how the composition grammarrule sign 0 = 1 = 2 = orth = cat = E' complexorth orthl = n orth2 = E) binaryformula ind = 0 pred = and argi = (D arg2 = binaryformula ind = [U pred = logicalpred argI = a arg2 = H _ qualia = (l) sign orth sem = = , m [̂  sign orth = cat = sem = qualia 0 ID = 0 unaryformula ind = [3 Figure 2: Feature structure for the generalcompound rule 132 nomjualia natural abstract ' inanitnate naturalj)tiyscal < C ^ ^ ^ v e g e t a b l e artifactjihysical artifact abstract animate < ' y tiuman creature < C ^ animal Figure 3: The L K B nominal qualia type system rule inherits from have, replacing the predicate and restricting the qualiatypes of its arguments.
 (3) have grammarrule < > < g e n e r a l  c o m p o u n d o" < 0 :sem:arg2 :pred > = "has" "Default inheritance.
 (4) composition grammarrule <> < h a v e o < 0:sem:arg2:pred > = "composedof" < 1:qualia > = physical < 2:qualia > = physical.
 If a particular predicate can be applied in several qualiacircumstances, then several similar number rules are produced for each circumstance e.
g.
 transsource! if the modifier is inanimate, transsource2 if it is a physical artifact.
 The nominalisation rules should depend crucially on derivational morphological processes to function properly.
 Since the L K B version used for this implementation did not support morphology\ lexical entries are given for nominalisations, as though they had been through the derivational process.
 A system that supported derivational morphology, however, would not need the nominalisations lexicalised — the requisite predicating verb could be derived in processing.
 Since the system will apply all the compounding rules possible, overgeneration results where specific rules from deep levels of the hierarchy apply, since all the rules higher up the hierarchical tree are also be applied.
 Therefore the implemented rules are also hierarchically organised within the grammar, via the defaultinheritance principle.
 In the ruleapplication stage the lessspecific rules are blocked if one of their childrules has been applied.
 The final grammar contains 44 rules to implement the predicate hierarchy for nominal compounding.
 Results Since the rules for compounding take the form of grammar rules, nominal compounds must be fed into the parser to receive interpretations, producing a different parse tree for every predicate that can be applied.
 The set of examples in Figure 4 shows the rules that have been applied in the parsing 'This is due to the difficulties of implementing any morphological component in an inheritancebased system.
 More recent versions of the LKB, however, do have a morphological component.
 birth pain disease cell student power government land dog leg honey bee sweat gland music box pine Uee mountam stream human vertebrate field mouse spring shower m o m m g prayer marital sex olive oil sea breeze physics book (actives DUETO causes) (active3 make C A U S E S ) (intended POSSESSION) (intended place2placel O W N E R S H I P ! natsource2) (intended place! BODYPART) (inhabit madeof! G E N E R A T E ) (physloc madeof 1 G E N E R A T E ) (actives G E N E R A T E ) (intended inhabit have SUBTYPE2) (active! PLACE! madeof! partof! transsource!) (intended inhabit ownership! SUBTYPES) (active! INHABIT madeof I transsource!) (TEMPLOC generate) (about T E M P  L O C dueto) (TEMPLOC actives dueto) (intended place! have NATSOURCE2) (place! madeof! active! partof! TRANSSOURCE!) (ABOUT activeS) room temperature (POSSESSION active2 transsource2 dueto) abortion vote cow phone Cardiff woman (ABOUT actives dueto causes) (intended PLACE2 have) (INHABIT madeof2 active2 transsource2) Figure 4: Sample results (normal predicates) city employee ocean study birth control music critic (PATIENT inhabit madeof2 transsource2) (PRODUCT about possession transsource! dueto) (ACT causes) (AGENT generate) Figure 5: Sample results (nominalised predicates) of several different compounds (the correct/most suitable rule has been (manually) highlighted in each case).
 The sample compound 'cow phone' was motivated by the Far Side cartoon depicting a farmer talking into a telephone mounted behind a flap in the side of a cow, entitled "The rural professional and his cowphone" (Larson, 1989).
 This is obviously a pun on earphone, but the (correct) interpretation assigned to what is essentially a nonsensical compound illustrates that the system can generate correct predicates corresponding to pragmatic senseextension in some circumstances.
 Overgeneration in the results generally is purely due to underspecificity in the lexicon and the qualia type system (and hence in the definition of the compounding rules).
 The qualia type system used for this study was an experimental one, and is terribly small and underspecified.
 There are only fifteen nodes in the whole system, as shown in Figure 3, specifying little other than animacy, physical composition and the natural/artifact distinction.
 With a properly specified system, the sets of results would be much smaller, possibly even atomic, which is what is ultimately desired.
 Testing the nominalisation rules (examples in Figure 5), it 133 nounsign comple\or(h orth = cal = complexorlh orthl = orthl = concrete orth2 = dog orth 2 = house nouncat sem = binarYformula ind = (o) entity pred = and argl = arg2 = unaryformulaentityargl ind = [o] pred = liouse1 argl = [»] binaryformula ind = ini pred = intendedfor argl = [()) binaryformula ind = Q] entity pred = and arg2 = argl = arg2 = unaryformulaentityargl ind = [B pred = dogl argl = E binaryformula ind = Q] pred = madeof argl = Q arg2 = unaryformulaentityargl ind = [3 entity pred = concrete.
! argl = (U qualia = artifact̂ jhysical nounsign orlh = complexorth orlhl = concrete orlh2 = cul = nouncat complexorth orthl = dog ordi2 = house binaryl ormula Ind = 0 entity pred = and argl = arg2 = binaryformula ind = M pred = argl = arg2 = and unaryformulaentityargl ind = M pred = house.
1 argl = El binaryformula ind = [13 pred = intendedJor argl = m arg2 = unaryformulaentityargl ind = [7} entity pred = dogJ argl = Q] binaryformula ind = M pred = madejof argl = E arg2 = unaryformulaentityargl ind = [U entity pred = concrete1 argl = 0 qualia = artifact 4ihysical Figure 6: Feature structures for t w o interpretations of concrete d o g house b e c o m e s clear that the nominal predicates will most often be the m o s t appropriate of the result set.
 In the set of results for ocean study, for example, it could be argued that a b o u t is as valid a rule as p r o d u c t , and indeed there does not s e e m to be m u c h to distinguish between a study about the ocean, and a study of the ocean.
 T h e latter, however, seems neater both linguistically and computationally since it involves just the predicate and a single argument, and so the nominalised predicate has been m a r k e d as the most appropriate in this instance.
 T h e other possibilities in the set are generated since s o m e normal rules could also apply to the nominal elements.
 In the case of city employee, for example, the other rule applications are quite plausible interpretations for the c o m p o u n d , except for MADEOF2.
 Multiple compounds can also be interpreted, although the overgeneration problem becomes more pronounced.
 Since the ambiguities are multiplied, the compound concrete dog house was assigned 15 different interpretations.
 Figure 6 shows feature structures for 2 of the possibilities for the interpretation of this compound.
 The feature structures also demonstrate how the predicate is associated with its arguments in the semantics of the compound entity.
 All together, some 60 different binary compounds were analysed, and none was assigned a set of predicates of more than six members.
 The average size of the predicate set was three for conventional compounds, and four for those compounds that involved nominalisation rules.
 There is the possibility that this latter figure could be reduced to unity by assigning more weight to nominalisation predicates in the set when they occur.
 Since the compounding rules are implemented in the normal grammar of the L K B parsing system, it is very straightforward to include nominal compounds in normal parsing examples, e.
g.
 the sentence John admired the young Cardijfflower shop manageress was successfully parsed to incorporate a correct interpretation of the compound, albeit with a high degree of ambiguity.
 This is of course due to the highly complex nature of the compound.
 Discussion The original requirements of the study have been satisfied: a system of general rules has been implemented that will generate a set of predicates to relate the elements of a nominal compound.
 For normal compounds, this set invariably seems to contain the most appropriate predicate for the compound, thus justifying the approach.
 The set of rules has been based upon those predicates given in Levi's work, but these have been greatly extended, improved and organised into a hierarchy.
 W h e n combined with more conventional parsing, an unde134 sirable degree of ambiguity occurs, since every possible predicate will give rise to a seperate parse, or set of parses.
 Therefore there is an argument for carrying out the analysis of nominal compounds with suitable pragmatic disambiguation separately from the parsing process, either before or after the main parsing occurs.
 Complete separation of compound analysis from parsing could however be undesirable since there may be circumstances where there it is ambiguous whether two words are a compound or are separate.
 No claims are made for the precise formulation of the compounding rules used in this study, or even their extent.
 The quaiia structure in the L K B is extremely small, and so many rules have been made unnecessarily general.
 With a more precise semantic quaiia system and lexicon, more precise rules would be possible, and hence the result sets would contain fewer general or inappropriate predicates.
 It might also prove possible and advantageous to enlarge the predicate hierarchy suggested here with more specific rules if a more precise quaiia system were used.
 Note that rule hierarchies need not necessarily be based on Levi's (1978) predicates — these were used as a basis in the current study, since they were appropriate.
 If it proves advantageous to add to them, or to replace the functionality of one with other rules elsewhere in the hierarchy, then this should be done.
 The main purpose of the current study is to develop a novel methodology, not a canonical rule hierarchy.
 There would obviously be fewer ambiguous or inappropriate analyses if the compounding information were lexicalised.
 The argument for not mounting the lexicalisation bandwagon, however, is that it introduces a huge overhead on lexicon size and complexity, greatly complicates the interaction of grammar and lexicon (since it is here that we have to relate information from the compound elements) and requires modifications to the system that the analysis in implemented in (since e.
g.
 some complex disjunctive unification operations would be necessary).
 In addition it will prove impossible, in practice, to include all the possible compound relations in a lexical entry.
 However, lexicalisation should not be abandoned altogether.
 There will always be exocentric, metaphorical and unanticipated uses of compounding, and whilst it is possible to process some of these in a rulebased system (as the 'CowPhone' example showed) these instances are, in the main, better handled through lexicalisation.
 Thus a rulebased system such as the one described here is only more suitable for processing the endocentric nominal compounds, which constitute the majority of those encountered.
 For optimal performance, however, such a rulebased approach should be complemented by a modest number of lexicalisations for the more unusual compounds.
 Whilst not a perfect implementation, the system described in this study has shown the advantages and possibilities of interpreting nominal compounds via a set of possible predicates relating the nominal elements, and has shown how such a set of predicates can be derived from the nature of the compound elements.
 This represents a very novel approach to the problem of extracting the meaning of a nominal compound from its constituents, and although the system's performance as described is less than perfect, the possibilities are almost infinite, given a larger and more specific quaiia system and lexicon.
 Through judicious formulation of compounding rules, and use of a good qualia/semantic description, we should be able to interpret a very much more wide and general range of nominal compounds than has hitherto been possible, and derive more detailed and useful interpretations.
 Acknowledgements This paper is based upon a thesis submitted for the degree of Master of Philosophy at the University of Cambridge (Jones, 1992).
 The research was carried out under a grant from the (UK) Science and Engineering Research Council.
 Thanks for instructive and helpful comments to Ann Copestake, John Carroll, Andrew Fordham and anonymous reviewers.
 The author is currently supported by a grant from the (UK) Economic and Social Research Council.
 References Bouillon, R; Bosefeldt, K.
; and Russell, G.
 (1992).
 Compound Nouns in a Unificationbased M T System.
 In Proceedings of the Third Conference on Applied Natural Language Processing (pp.
 209215).
 Trento, Italy.
 Copestake, A.
 (1992).
 The Acquilex LKB: representational issues in semiautomatic acquisition of large lexicons.
 In Proceedings of the Third Conference on Applied Natural Language Processing (pp.
 8892).
 Trento, Italy.
 Copestake, A.
 (1993).
 The Compleat LKB: AcquilexII Deliverable 3.
1.
 Technical report no.
 316.
 Cambridge, U K : Cambridge University Computer Laboratory.
 Downing, P.
 (1977).
 On the Creation and Use of English Compound Nouns.
 Language, 53, 810842.
 Finin, TW.
 (1980).
 The Semantic Interpretation of Nominal Compounds.
 In Proceedings of the First National Conference on Artificial Intelligence (pp.
 310312).
 Hobbs, J.
R.
 and Martin, P.
 (1987).
 Local Pragmatics.
 In Proceedings of the 10th IntemationalJoint Conference on Artificial Intelligence (pp.
 520523).
 Isabelle, P.
 (1984).
 Another Look at Nominal Compounds.
 In Proceedings of the 10th International Conference on Computational Linguistics and the 22nd Annual Meeting of the A C L (pp.
 509516).
 Jones, B.
 (1992).
 Predicting Nominal Compounds.
 MPhil thesis.
 Cambridge, UK: Department of Engineering, University of Cambridge.
 Larson, G.
 (1989).
 Night of the CrashTest Dummies.
 London, UK: Futura.
 Levi, J.
N.
 (1978).
 The Syntax and Semantics of Complex Nominals.
 New York: Academic Press.
 135 A M o d e l of Practice R e l a t e d Shifts in the L o c u s of B r a i n Activity D u r i n g V e r b a l R e s p o n s e Selection T a s k s Vijaykumar Gullapalli Mechanical & Aerospace Engg.
 Princeton University Princeton, NJ 08544 vij ayffiphoenix.
princeton.
edu Jack J Gelfand Psychology Department Princeton University Princeton, NJ 08544 j jgffiphoenix.
princeton.
edu Douglas L T Rohde Computer Science Department Princeton University Princeton, NJ 08544 dlrohdefflphoenix.
princeton.
edu Abstract Recent Positron Emission Tomography (PET) and other studies have produced detailed information about the areas of the brain involved in word association tasks, their functional roles in learning word associations, and the changes in activity in these areas during learning.
 We present a dynamic neurond model that replicates observed human cognitive behavior in learning word associations while satisfying salient neuroanatomical and neuropsychological constraints.
 The model captures the observed dynamics of corticothalamobasal ganglionic loops.
 Introduction Although "practice makes perfect" has been a longstanding dictum of skill learning, it is only recently that some light has been shed on the brain mechanisms involved in the learning of skills with practice.
 By combining information about the functional anatomy of the brain obtained through Positron Emission Tomography (PET) with other anatomical and physiological data, researchers have been able to piece together a more complete picture of the brain mechanisms involved in learning specific cognitive and motor tasks (e.
g.
, (Raichle et al.
, 1994; Wise k Houk, 1994)).
 This, in turn, has facilitated the construction of realistic models of these brain mechanisms.
 Our focus in this paper is on modeling the brain mechanisms involved in iterative verbal response selection tasks while satisfying known anatomical and functional constraints.
 W e present a heterogenous dynamic neuronal model that integrates diverse areas of the brain at a systems level.
 Our model replicates both the highlevel cognitive behavior and the microlevel neuroanatomical characteristics of the diverse brain circuits involved.
 Human cognitive behavior in iterated verbal response selection tasks is a simple, yet interesting, example of learning with practice.
 When subjects are asked to respond, for example, with appropriate verbs for a visually presented list of nouns, repeated presentation of the list initially elicits varying responses to each noun, but with practice, stereotypic responses develop.
 Practiced responses also are produced faster than those in the naive condition.
 In addition to these basic characteristics, verbal response selection also shows dependence on several cognitive variables, which, when manipulated, can give rise to priming, masking, interference, and other cognitive phenomena.
 Related Research In a recent set of studies, Raichle et al.
 (1994) and others used PET scans to examine the differences in the functional anatomy of the brain during naive and practiced performance of verbal response selection.
 PET scans over repeated presentations showed a shift in brain activity from the anterior cingulate, the left prefrontal and left posterior temporal cortices, and the right cerebellar hemisphere in the naive condition to the sylvianinsular cortex bilaterally and the left medial extrastriate cortex after practice.
 Introduction of a novel stimulus after practice reactivated the regions active in the naive condition.
 Raichle et al.
 (1994) concluded that two distinct brain circuits were employed in verbal response generation, one for controlled selection of responses and the other for the production of learned or automatic responses.
 Complementary to the broad overview provided by the abovementioned P ET studies of the functionality of the brain areas involved in response selection, more focused studies have yielded fairly detailed information about the neuroanatomy and neurophysiology of the areas involved.
 For example, while cortical areas in general represent information regarding the internal state of the organism or the external state of the environment (e.
g.
, (Mountcastle, 1978)), there is evidence to suggest that the cingulate cortex specifically represents information pertaining to the task that is currently being performed (Pardo et al.
, 1990; Vogt et al.
, 1992).
 Similarly, it is suggested that the sylvianinsular cortex serves as an associative store for learned responses to stimuli (Mitz et al.
, 1991; Raichle et al.
, 1994).
 Finally, the volume edited by Houk et al.
 (Houk et al.
, 1995) (see also, Houk and Wise (Houk & Wise, 1993)) presents considerable evidence to indicate that the basal ganglia are involved in the selection and latching of relevant aspects of the current cortical state in a taskdependent fashion.
 This volume also describes the projections between areas of the cortex, the basal ganglia, and the thalamus in detail.
 In devising our model, which is based on the modular architecture described by Houk and Wise (Houk & Wise, 1993), we have adhered to the abovementioned and other known anatomical and functional constraints.
 136 Neural Modeling of Verbal Response Selection Although verbal response selection is a highlevel cognitive behavior, our model is implemented at a neuron level in order to enable us to incorporate our knowledge of the neurophysiology of the brain areas participating in the task.
 W e have used lumped models of the neurons in our implementation, primarily because little is known about the impact of subneuronal dynamics on the highlevel cognitive behavior.
 However, one of our goals is to determine the appropriate level of detail needed to model all the relevant aspects of verbal response selection in humans.
 The most important feature of our model is that it incorporates the dynamical characteristics of the brain circuits involved.
 This allows us to replicate the temporal characteristics of the observed cognitive behavior, which is essential for any meaningful study of the phenomenon of learning.
 It will also enable us to compare the dynamic behavior of the model in simulations with the temporal characteristics of neuronal activations revealed by E R P data.
 Description of the Model The architecture used for our preliminary model is depicted in Figure 1.
 A primary feature of this architecture is the presence of two processing streams.
 The controlled stream consists of the cingulate cortex, the cortical modules representing the input words, the frontal cortex, the basal ganglia, and the thalamus.
 There is also an automatic stream, which consists of the sylvianinsular cortex.
 In the P E T studies, these were the areas whose excitation differed significantly in the naive and practiced performance of the response selection task (e.
g.
, (Raichle et al.
, 1994)).
 Both these streams receive common inputs from the sensory areas and send outputs to the motor areas.
 The cortical modules representing the anterior cingulate and the sensory and language areas are organized as columns of neurons that correspond to cortical columns, each functioning as a relatively coherent information processing unit as discussed by Mountcastle (1978).
 Each cortical module forms a distributed representation of some internal state of the organism or external state of the environment.
 Corticocortical interconnections formed through Hebbian learning (Hebb, 1949) make it possible for the cortical modules to develop robust representations.
 The representations used clearly have a significant impact on the functioning of a model.
 In the current model, we used a distributed representation over the sensory and language cortical modules to encode stimulus words, with each module denoting a "feature" or "category" of words (e.
g.
, "colors" or "verbs").
 The rationale for this representation is presented in the next section.
 These cortical representations are input to the basal ganglia, the sylvianinsular cortex, and the frontal cortex.
 Additionally, the cingulate module stores a representation of the task (e.
g.
, "generate a color response"), and provides it to the basal ganglia and the sylvianinsular cortex.
 W e postulate that there would be a projection from the cingulate to the cerebellum as well and this will be implemented in future work as described in the discussion section.
 Phasic activity in the sensory/language cortical modules is passed on to the frontal cortex through direct projections as shown in Figure 1.
 In addition, the frontal cortex also has highly specific reciprocal projections with the thalamus, resulting in local corticothalamic loops that, when active, m a y sustain activity in frontal cortex neurons (Houk & Wise, 1993).
 These loops could be activated through selective disinhibition by the basal ganglia (for review, see (Chevalier & Deniau, 1990)), which acts as a patternrecognizer as suggested by Houk and Wise (Houk & Wise, 1993).
 W e have modeled these interactions of the frontal cortex, the thalamus and the basal ganglia, which together form the controlled response pathway.
 Based on inputs from the cortical modules and the cingulate, the basal ganglia selectively disinhibit the frontal cortexthalamus loops corresponding to the word features appropriate for the task, resulting in sustained activation of these features in the frontal cortex.
 Thus the output of the controlled circuit is an appropriate word represented by the tonically selected features in the frontal cortex.
 In parallel with the controlled circuit, the sylvianinsular cortex module, which forms the automatic circuit, produces a response associated with the cortical inputs.
 Because of a lack of concrete anatomical evidence at this point, we simply modeled the insular learning as a linear associative network.
 Although this is not biologically faithful, it does have the property of incrementally learning the correct output response based on examples given by the performance of the controlled pathway and thus allows us to observe the overall dynamics of the model.
 Depending upon previous experience, the response given by the associative network simulating the sylvianinsular cortex m a y not be appropriate for the specified task.
 Therefore there is a need for deciding which response generation circuit to rely on.
 As mentioned in the discussion, we hypothesize that this role is played by the cerebellum, which would inhibit the inappropriate response.
 In the current implementation, learning of synaptic weights takes place in the intra and intercortical module connections, and in the sylvianinsular cortex.
 Although the other connections are currently hardwired, we plan to incorporate learning in both the cerebellum and the basal ganglia in order to replicate the development of their pattern matching abilities.
 Considerable evidence regarding the presence of training signals and their operation in these areas is already available to guide this work.
 Representation of words Our use of a distributed representation over the sensory and language cortical modular array (Wise & Houk, 1994) to encode stimuli is inspired by the functional anatomy of the cortex (e.
g.
, (Mountcastle, 1978; Asanuma, 1975)).
 The general organization of cortical circuits appears to be in the form of a distributed set 137 Anterior Cingulate Cortex ' Cortical Modules FrontoThalamoBasal Ganglionic Loop Striatal Thalamus Left Spiny Reciprocal Prefrontal Cells monosynaptic Cortex • :llor .
Dlslnhiblllon̂ ^ projeciions Controlled pathway Tasks Associative memory words Sylvian Insular Cortex Articulatory output Automatic pathway Figure 1: T h e architecture of the verbal response selection m o d e l .
 of functionally specific regions or c o l u m n s interactively involved in the execution of a given task.
 E a c h functionally specific region extracts f r o m its inputs higher level information regarding a particular aspect of the task.
 Sharing of processed information through reciprocal corticocortical projections between regions enables information extracted in one region to influence the processing of information in other regions concerned with the execution of the task.
 Cortical organization in columns with reciprocal projections between columns has been observed, for example, in the primary and secondary visual areas (Mountcastle, 1978), as well as in the motor cortex (Asanuma, 1975).
 The cortical modular array (Wise & Houk, 1994) in our implementation corresponds to the local information processing regions of the cortex, with each module concerned with the representation of a "feature" or "category" of words.
 For example, a module might represent a color or colors associated with the stimulus word, or the fact that it is a verb.
 As a result, each word is represented as a distributed activation of the features associated with that word.
 Currently, the nominal level of this distributed activation is predetermined for each stimulus word in our model.
 The levels of activation are given in Table 1.
 Thus, presentation of a stimulus word is effected by adding the activations indicated in the table to the corresponding neurons in the cortical modules.
 If no value is specified in the table for a neuron, its activity is not changed.
 For example, when the stimulus " A P P L E " is presented, (among others) the activations of the neurons representing " E A T " are increased by 0.
5 and those of the neurons representing " S W E E T " by 0.
7, while the activations of the neurons representing "PET", for instance, are not changed at all.
 These changes in activation values were selected to reflect the degree of association between the stimulus and the corresponding word.
 Thus, for instance, while " A P P L E " is highly associated with both " R E D " (1.
0) and "FRUIT" (1.
0), it is associated to a lesser extent with "EAT" (0.
5), and not at all with " B L A C K " (0.
0).
 T w o factors influence the temporal dynamics of these distributed activations.
 First, shuntingtype lateral inhibition (e.
g.
, (Pinter, 1983)) among the neurons in a cortical module results in a winnertakeall type selection of the feature represented by that module.
 Modeling neurons as leaky integrators with shuntingtype inhibition leads to dynamic interactions between the new activity due to presentation of a stimulus and the previously existing activity of neurons in a module.
 These interactions play a significant role in determining what is represented in each module: previous strong activity of other features might inhibit weak new activity of a feature, resulting in suppression of a feature in the predetermined representation of the stimulus word.
 Alternatively, previous activation of the same feature might lead to priming of the new feature, increasing its prominence in the representation.
 In contrast to this, the cortical modules attempt to maintain a coherent set of features in a representation by filling in missing features that were often active in the past in conjunction with those that are currently active.
 This is accomplished by mutually excitatory projections between modules in the cortical modular array whose strengths are determined via Hebbian learning (Hebb, 1949).
 Due to the dynamic nature of the representation of stimulus words, presenting the same word in different historical contexts can elicit different responses due to priming effects, much as in the case of human subjects.
 Simulation Results In this section, we present simulation results that demonstrate the features of our model.
 For these simulations, we selected a list of 20 words to represent in our model.
 Of these, six were used as stimuli, while the responses could be selected from all 20.
 The responses were classified into four groups, namely, stimuli, color names, verbs, and miscellaneous.
 A separate cortical module was used to represent words in each group.
 In Table 1, we present 138 Table 1: Representation of the stimulus words in the preliminary model as activations of cortical modular array neurons representing the features that comprise potential responses.
 Stimulus Potential Responses A P P L E BANANA GRAPE CAT DOG MOUSE BLACK BROWN RED YELLOW BUY EAT FALL RUN HOUSE FRUIT PET SWEET SOUR TREE APPLE 1.
0 1.
0 0.
9 0.
5 0.
8 1.
0 0.
7 0.
5 0.
4 BANANA 1.
0 1.
0 0.
9 0.
2 0.
8 0.
8 0.
4 0.
1 0.
1 GRAPE 1.
0 0.
5 0.
3 0.
9 0.
7 0.
9 0.
5 0.
9 CAT 1.
0 0.
5 0.
6 0.
8 0.
5 0.
2 0.
8 0.
3 1.
0 DOG 1.
0 0.
7 0.
9 0.
3 0.
9 0.
3 1.
0 MOUSE 0.
2 1.
0 0.
9 0.
7 0.
1 0.
9 0.
2 1.
0 the (predetermined) activations of the words in each sensory/language cortical module when each of the stimulus words is presented.
 The model captures the dynamics of corticothalamobasal ganglionic loops suggested by Houk and Wise (1993) based on neurophysiological evidence gathered by several researchers (e.
g.
, (Chevalier & Deniau, 1990; Faster & Alexander, 1973; GoldmanRakic & Friedman, 1991)).
 A n example of this is presented in Figure 2.
 The first plot shows the activity of frontal cortex neurons when no task is specified.
 As can be seen, the initial activity of the neurons due to stimulus word presentation decays with time.
 W h e n a " C O L O R " task is specified, the activity of neurons representing a color associated with the stimulus word is sustained through selective activation of the corresponding loops, while the activity of the other neurons decays away.
 Similarly, when a " V E R B " task is specified, activity of neurons representing actions associated with the stimulus word gets selectively sustained.
 As reported by Raichle et al.
 (1994), the median response times of human subjects decreases significantly over successive blocks of presentation of the same set of stimuli.
 If a novel stimulus set is presented immediately following these repeated blocks, the response time returns to about the same level as in the naive condition for the original stimulus set.
 W e ran a similar experiment with our system.
 W e presented three stimuli, A P P L E , D O G , and M O U S E , for 10 successive blocks, followed by 10 more blocks with the stimuli B A N A N A , G R A P E , and CAT.
 As illustrated in Figure 3, the response time of the system also decreased with repeated presentations of the same stimulus set for 10 blocks.
 Moreover, as with human subjects, presentation of a novel stimulus set caused a significant increase in the response time, which further repetitions caused to decrease.
 Discussion The results given in the last section indicate that a model which is based upon the anatomical and functional features of the areas of the brain observed to participate in learning word association tasks does indeed exhibit the cognitive behaviour observed in humans.
 The model raises many important questions which suggest several directions for future research.
 T w o major issues are discussed below.
 A primary issue for investigation is the existence of dual (controlled and automatic) pathways for verbal response selection.
 Although the P E T data from Raichle et al.
's study (1994) supports such a model, additional functional evidence obtained using alternative methods such as event related potentials (ERP) is needed to confirm or refute the conclusions of the P E T study.
 A n important aspect requiring study is the functional role of the cerebellum.
 As mentioned above, increased right cerebellar activity has been observed in the naive condition of the word association task.
 W e hypothesize that the cerebellum facilitates verbal response selection in two important ways: it arbitrates between the controlled and the automatic circuits, and it facilitates learning in the automatic pathway.
 This hypothesis is based on data from Feiz et al.
 (Feiz et al.
, 1992), who found that damage to the right cerebellar hemisphere of a human subject due to a stroke resulted the patient's inability to select appropriate word association responses to words as well as his ability to learn at this task.
 W e are in the process of incorporating this function of the cerebellum in our model.
 139 f'teltontHi and Cingulale Cortex Actlvalions Over Tinio: No Task Condition; Sllmiilus = APPLE , _ BLACK •— RED <BUY Q RUN « TREE ̂ COLOR TASK » VERB TASK « > 1 i • Time Prelrontal and Cingulate Cortex Activations Over Time Tasl( = COLOR.
 Stimulus = APPLE ^ ^ I : |,w' r[.
 f*'' ' o.
.
.
 " Â    » .
.
*— t — ~ •> B.
   1 '̂.
̂  Q '>f.
̂  • o .
.
̂  D _ J ^   * • • • • « BLACK •— RED »BUY QRUN « TREE »• COLOR TASK »• • A VERB TASK • J • ' : ^ "  i  " " ^ Time Prelrontal and Cingulate Cortex Activations Over Time: Task = VERB; Stimulus = APPLE 0.
2 BLACK »— RED ̂BUY e RUN H TREE •̂ COLOR TASK »• • VERB TASK •• • t t * t "̂̂ îSr.
.
.
,.
.
.
,, 4 6 Time Figure 2: Example of selection of an appropriate response for different tasks by the controlled circuit.
 The color and verb task plots are activations of neurons in the cingulate cortex representing those tasks.
 The response activations (e.
g.
, "RED", "BUY", "TREE") are of neurons in the prefrontal cortex.
 140 Performance While Learning COLOR Responses Through Practice Novel Stimuli in Block 11 6 • 3 • 0 ' >I I I I I I 1 I APPLE, DOG, MOUSE BANANA.
 GRAPE, CAT V — ^  — • — H H _l 1 1 1 1 1 1_ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Training Block (3 Stimulus Words Per Block) Figure 3: Learning verbal responses.
 Stimuli switched from (APPLE, DOG, MOUSE) to (BANANA, GRAPE, CAT) in block 11.
 Acknowledgements We would like to thank Prof.
 James C.
 Houk of Northwestern University for his guidance and many valuable suggestions.
 This work was partially supported by grants from the James S.
 McDonnell Foundation and the Office of Naval Research.
 References Asanuma, H.
 (1975).
 Recent developments in the study of the columnar arrangements of neurons in the motor cortex.
 Physiological Review, 55, 143156.
 Chevalier, G.
 & Deniau, J.
 M.
 (1990).
 Disinhibition as a basic process in the expression of striatal functions.
 Trends in Neuroscience, 13, 277280.
 Feiz, J.
 A.
, Petersen, S.
 E.
, Cheney, M.
 K.
, & Raichle, M.
 E.
 (1992).
 Impaired nonmotor learning and error detection associated with cerebellar damage.
 Brain, 115, 155178.
 Faster, J.
 M.
 & Alexander, G.
 E.
 (1973).
 Firing changes in cells of the neucleus medialis dorsalis associated with the delayed response behavior.
 Brain Research, 61, 7981.
 GoldmanRakic, P.
 S.
 & Friedman, H.
 R.
 (1991).
 The circuitry of working memory revealed by anatomy and metabolic imaging.
 In Levin, H.
 S.
, Eisenberg, H.
 M.
, k.
 Benton, A.
 L.
 (Eds.
), Frontal Lobe Function and Dysfunction, pages 7291.
 New York: Oxford University Press.
 Hebb, D.
 O.
 (1949).
 The Organization of Behavior: A Neuropsychological Theory.
 New York: Wiley.
 Houk, J.
 C, Davis, J.
 L.
, & Beiser, D.
 G.
 (1995).
 Models of Information Processing in the Basal Ganglia.
 Cambridge, Mass: MIT Press.
 Houk, J.
 C.
 & Wise, S.
 P.
 (1993).
 Outline for a theory of motor behavior: Involving cooperative actions of the cerebellum, basal ganglia, and cerebral cortex.
 In Rudomin, P.
, Arbib, M.
 A.
, CervantesPerez, F.
, & Romo, R.
 (Eds.
), Neuroscience: From Neural Networks to Artificial Intelligence.
 Research Notes in Neural Computation, volume 4, pages 471493.
 Berlin Heidelberg: SpringerVerlag.
 Mitz, A.
 R.
, Godschalk, M.
, & Wise, S.
 P (1991).
 Learningdependent neuronal activity in the premotor cortex: activity during the acquisition of conditional motor associations.
 Journal of Neuroscience, 11, 18551872.
 Mountcastle, V.
 B.
 (1978).
 An organizing principle for cerebral function: the unit module and the distributed function.
 In Edelman, G.
 M.
 & Mountcastle, V.
 B.
 (Eds.
), The Mindful Brain, pages 750.
 Cambridge, Mass: MIT Press.
 Pardo, J.
 v.
, Pardo, P.
 J.
, Janer, K.
 W.
, & Raichle, M.
 E.
 (1990).
 The anterior cingulate cortex mediates processing selection in the Stroop attentional conflict paradigm.
 Proceedings of the National Academy of Sciences, USA, 87, 256259.
 Pinter, R.
 B.
 (1983).
 The eloctrophysiological bases for linear and for nonlinear product term lateral inhibition and the consequences for wide field textured stimuli.
 Journal of Theoretical Biology, 105, 233243.
 Raichle, M.
 E.
, Feiz, J.
 A.
, Videen, T.
 O.
, MacLeod, A.
 M.
 K.
, Pardo, J.
 V.
, Fox, P.
 T.
, & Petersen, S.
 E.
 (1994).
 Practicerelated changes in human brain functional anatomy during nonmotor learning.
 Cerebral Cortex, 4, 826.
 Vogt, B.
 A.
, Finch, D.
 M.
 .
, & Olson, C.
 R.
 (1992).
 Functional heterogeneity in cingulate cortex: the anterior executive and posterior evaluative regions.
 Cerebral Cortex, 2, 435443.
 Wise, S.
 & Houk, J.
 C.
 (1994).
 Modular neuronal architecture for planning and controlling motor behavior.
 Biological Communications of the Danish Royal Academy of Sciences, 43, 2133.
 141 A Connectionist M o d e l of Hemispheric Interaction in Unilateral Visuospatial Neglect Richard Shillcock Centre for Cognitive Science University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, U.
K.
 rcsOcogsci.
ed.
ac.
uk Paul Cairns Centre for Cognitive Science University of Edinburgh 2 Buccleuch Place, Edinburgh EH8 9LW, U.
K.
 pcairns@cogsci.
ed.
ac.
uk Abstract The dominant models of unilateral visuospatial neglect are noncomputational models.
 Two such models (Kinsbourne, 1970, 1993; Halligan & Marshall, 1994) rely on conlralaterally oriented attentional systems in the two hemispheres of the brain to capture the rich data from neglect.
 The linebisection task is a standard diagnostic test that produces rich, detailed, elegant, quantitative data.
 W e describe an implemented connectionist model of the performance of neglect subjects in the linebisection task.
 Our model demonstrates that both the central characteristics of unilateral neglect and its taskspecific complexities may be derived directly from the bicameral nature of the brain and the necessity for perceptual processing to integrate a precisely divided visual world.
 Our model is strictly divided at the input and hidden units, but allows complex interaction at the output units.
 It demonstrates the lefttoright graded nature of visuospatial neglect across the whole visual field, together with the detailed effects of midpoint displacement in the linebisection task.
 Very idealised connectionist models of hemispheric interaction can accurately capture detailed patient data.
 P e r c e p t i o n a n d D i v i d e d P r o c e s s i n g The most fundamental, immediately visible aspect of the brain's architecture is its division into two hemispheres; the hemispheres are connected by the 2 0 0 M fibres of the corpus callosum, with sensory input and motor output being predominantly contralaterally organised.
 These basic facts pervade numerous models of unilateral neglect behaviour, but such models fail to provide detailed accounts whose explanatory power is grounded in these facts.
 W e demonstrate below that an idealised connectionist model of hemispheric interaction, based on these facts, can provide a principled account both of the core characteristics of neglect and of the finegrain data from a particular task.
 First w e demonstrate the divided nature of perceptual processing.
 The division of the visual field into two halves contralaterally projecting to the two hemispheres has long been recognised.
 However, a recent study (Fendrich & Gazzaniga, 1989) has shown the precision of this division about a vertical meridian.
 A splitbrain subject was unable to match two stimuli when they straddled the vertical containing the fixation point.
 A distance as small as 15' of arc past the meridian was sufficient to prevent comparison.
 In humans, the visual world  both nonfoveal and foveal is exactly split about the vertical, with very little bilateral projection.
 Once sensory information has reached one of the hemispheres it may be transferred to the other hemisphere, typically by means of the corpus callosum.
 Thus, a fundamental task of visual perception is the integration of the visual information in the two hemifields.
 Unilateral Neglect: Data and Models Unilateral neglect typically results from a stroke.
 The standard example is of left neglect caused by a lesion to the right hemisphere (RH), and to the parietal region in particular.
 Halligan, Marshall and W a d e (1989) reported some degree of neglect, using a star cancellation task, in 30 out of a sample of 80 unselected stroke patients.
 Neglect manifests itself in a failure fully to respect one side of a stimulus or stimulus field.
 In left visuospatial neglect, the left of a drawing might be inadequately copied, food on the left of the plate might be disregarded, or the first letter(s) of a word might be misreported.
 In the linebisection task (Schenkenberg, Bradford & Ajax, 1980) the subject marks the midpoint of a horizontal straight line.
 The left neglect subject typically displaces the midpoint to the right of the objective middle, apparently failing to process some of the left extent of the line.
 This task is commonly used in the diagnosis of neglect; it behaves very elegantly, reliably producing finegrain, quantitative data that is sensitive to a range of different factors in the presentation of the task.
 In terms of computational modelling, linebisection is more tractable than copying or drawing tasks: the extent of the line and the position of the midpoint and the fixation point(s) can all be precisely specified.
 A s examples of the detailed neglect data that the linebisection task produces, w e consider three observations taken from the extensive literature on this task (for a fuller review, see Shillcock & Cairns {submitted).
 First, the size of the rightward displacement of the midpoint is proportional to line length (tested with lengths up to approximately 28 cm) (Nichelli, Rinaldi & Cubelli, 1989; Riddoch & Humphreys, 1983).
 Further, withinsubject variability (standard deviation of the mean) is positively related to line length (Halligan & 142 http://ed.
ac.
ukmailto:pcairns@cogsci.
ed.
ac.
ukMarshall, 1988; Marshall & Halligan, 1989a; Nichelli, Rinaldi & Cubelli, 1989; Riddoch & Humphreys, 1983; Halligan & Marshall, 1989a).
 Second, in left neglect, right displacement may turn into left displacement for lines less than 25 m m (Halligan & Marshall, 1988; Halligan & Marshall, 1989a; Halligan & Marshall, 1989b; Marshall & Halligan, 1989a); the patient may mark the midpoint to the left of the objective midpoint for such small lines.
 Third, cueing the subject's attention to the left end of the line may ameliorate left neglect (Halligan & Marshall, 1989b; ReuterLorenz & Posner, 1990; Heilman & Valenstein, 1979) and even turn it into right neglect, meaning that the midpoint is displaced leftwards (Halligan, Manning & Marshall, 1991; Halligan & Marshall, 1989c).
 As an example of a more general characteristic of neglect, we consider the graded nature of the neglect phenomenon, extending across the whole visual field.
 Kinsboume (1993) criticises thirteen recent accounts of neglect phenomena for "assum(ing) either that there is a stepfunction in attention, such that it is intact in one hemispace and impaired in the other, or that the impairment is with respect to space, rather than things in it.
" (p.
 67).
 Kinsboume argues that "neglect is not dichotomously organised: when one of two opponent processors is relatively ineffective, the resulting bias is expressed right across the whole visual field" (p.
 67).
 Moreover, "action towards the side of the lesion is not merely preserved, but exaggerated" (p.
 67); for instance, neglect patients overreact to visual stimuli introduced ipsilesionally (Barany, 1913).
 Such observations apparently militate against "representational" accounts in which a lesion simply causes a representational loss in a region of visual space.
 In Kinsbourne's account, contralaterally oriented attentional processors specific to each hemisphere operate in opposition, and the impairment of one tilts the attentional gradient by simultaneously decreasing the activity of that processor and releasing the activity of the other processor.
 W e demonstrate, below, that a connectionist model of unilateral neglect is able simultaneously to embody the general graded nature of neglect  a characteristic that is present across modalities and tasks  and to provide a detailed, predictive account of behaviour in a specific task, namely the linebisection task.
 A connectionist model of linebisection The principle of our approach is to proceed from the most basic architectural constraints on the cognitive processing under study.
 In this case, the most inescapable constraint is the precise division of the visual field about the fixation point and the contralateral projection of the two halves to the two hemispheres of the brain.
 W e can investigate the consequences of this fundamental architectural constraint by embodying it in a simple model of the behaviour.
 If the desired behaviour emerges, then w e have a powerful argument that the model in question is the most parsimonious one possible.
 To the extent that the desired behaviour does not emerge, w e have a starting point from which to increment the complexity of the model as conservatively as possible and then to investigate the resulting behaviour.
 This approach is particularly valuable in the study of neglect, as the concept of attention, involved in many models, has historically tended to generate compelling metaphors with few a priori constraints.
 The model is shown in Figure 1.
 There is a precise, complete division at the input and hidden units, paralleling the splitting of the visual field.
 The single arrows denote complete connectivity between the relevant groups of units.
 The pattern of connectivity between the output units and the hidden units allows complex and varied interaction to occur after initial processing of the input.
 Figure 1 shows the input and output patterns for a particular line of length 10: consecutive activated nodes represent the line at input, and the model is required only to output the locations of the ends of the line at output.
 This is a conservative interpretation of the task; identifying the midpoint of the line presupposes locating the ends of the line.
 W e have not incorporated any additional mechanism to divide in two the distance between the two ends; as w e will demonstrate, the human data may be adequately modelled using a midpoint inferred from the endpoints at the output by the experimenter.
 W e have based the training set on observed human fixation behaviour in line inspection and bisection: subjects scan the line, fixating anywhere along its length, but do not fixate beyond its length (Ishiai, Furukawa & Tsukagoshi, 1987).
 The training set consisted of all the line lengths from length 2 to length 16, displayed in all the positions across the 16 input units in which the line either straddled the "fixation point" (the gap between the two halves of the input units) or immediately abutted it; thus, there were three tokens of line length 2, four of line length 3, and so on.
 The model was trained using the backpropagationthroughtime learning algorithm (Rumelhart, Hinton & Williams, 1986); every inputoutput mapping was learned, with the exception of a small subset withheld for crossvalidation purposes.
 Our aim was to allow substantial scope for interaction between the two halves of the model, following the initial division of the input; hence, the activation at the output was allowed to change over time as activation passed between the output units and the two sets of hidden units.
 f»IWBl B|1|B|B|B|B|B|B|8|1|Ba:: A n oatpnt bidden B|B|B|B|B|1iirn |1|1|1|1|1|1|11b] input Figure 1.
 The model of unilateral neglect.
 143 lOU c u u 3 u o C u u 755025/ / /I / / Jd P^ Left displacements • Correct I Right displacements / / 10 11 12 13 T 14 I 15 16 Line length Figure 2.
 Midpoint displacement data for the different line lengths, from the 50 differently lesioned versions of the model.
 Following successful training, the model was lesioned: 2 5 % of the connections from the left hidden units to the output units were randomly destroyed.
 This was intended to correspond to R H damage.
 Fifty different lesionings of this type were generated and tested to ensure the generality of the effects.
 The model was tested with the original training inputs, including those used for crossvalidation, and the outputs recorded, producing 78 individual results for each lesioning and a grand total of 3900 observations.
 The general model, when trained and lesioned as described above, in fact produces a range of neglect models from left to right neglect, determined by the original weights.
 In the simulations described below, we report only the behaviour of a trained model that produced left neglect when lesioned: i.
e.
 midpoint displacements were predominantly to the right of the objective midpoint.
 W e will demonstrate that this model accurately captures linebisection behaviour in left neglect.
 The fact that the general model produces a range of behaviour is critical.
 It means that the same model may account for both left and right neglect and for ipsilesional and contralesional effects: whereas contralesionally induced left neglect predominates in the patient population (at least after the acute stage), right neglect is qualitatively similar to left neglect in all respects except direction, and neglect may atypicaliy be produced by ipsilesional damage.
 These less usual instances of neglect present a challenge to existing models of neglect that base their explanations of left neglect on the contralateral projection of autonomous attentional processors (Kinsbourne, 1970, 1993), or on the differences between the attentional processors in the L H and R H (Halligan & Marshall, 1994).
 For the present model, the observed distribution of left and right neglect and ipsilesionally and contralesionally induced neglect in the patient population requires other factors, external to the basic architectural constraints we investigate here.
 W e require a computational principle with the potential for constraining the behaviour of the model to resemble the range of patient data.
 Coarsecoding in the RH, reflecting an observed hemispheric difference, offers one potential solution, as does a change in the balance of the connectivity between the hidden units and the output, reflecting contralateral projection more closely.
 W e do not investigate these additional constraints here; rather, we examine the desired detailed behaviour that naturally emerges from a single model as a result of basic architectural constraints.
 Simulation results Figure 2 shows the behaviour of the left neglect model when presented with the different numbers of lines of different length.
 For each of the 50 differently lesioned versions of the model, a mean result for each length of line was calculated from the individual results: thus, for line length 2, there were 27 correct judgements, 9 right displacements and 14 left displacements, totalling 50.
 Human data is chiefly only available for lines small enough to fall within one visual hemifield, so lengths 2 to 7 in Figure 2 are the relevant results from this simulation.
 Across this range, there is a positive linear relationship between line length and 144 percentage of right displacements (r = .
993, df= 5, p < .
01) and a similar correlation between line length and standard deviation {r = .
91\.
 df= 5,p < .
01).
 (In one study, Bisiach ei al.
 (1983) report linearity between length and displacement for longer lines, but the result is scarcely conclusive, as they present data for three points only  at 200, 400 and 600 m m .
 W e will show below that the performance from the nonlinear part of the graph in Figure 2 is in accordance with more general neglect behaviour.
) Figure 2 shows the characteristic reversal from right to left displacement of the midpoint, occurring between lengths 2 and 3.
 Such smooth crossovers in behaviour seem to be typical of models resembling that shown in Figure I.
 Figure 3 shows the effects of "fixating" on the left or right extreme of the line, meaning that the data only concern those lines that had an endpoint immediately adjacent to the gap between the two halves of the input units.
 These lines fell completely within one or other of the model's hemifields.
 As Figure 3 shows, more correct identifications of the midpoint arise from fixating the left end of the line.
 Moreover, fixating the left end results in more left displacements of the midpoint than right displacements: focusing on the left end of the line may cause left neglect to turn into right neglect.
 This exactly mirrors the human behaviour.
 .
102010Q Left displacements • Correct Q Right displacements 29 7.
6 v/, y// 13.
4 m • 40.
4 ».
o ^// V A 1.
57 Right end of line Left end of line Fixation point Figure 3.
 Midpoint displacement data when the line is "fixated" at its ends.
 The model therefore captures finegrain behaviour from the linebisection task.
 Figures 4 and 5 illustrate the behaviour of this same set of lesioned models, in relation to the graded nature of left neglect.
 Figures 4 and 5 respectively show plots of the displacement of the left and right endpoint against the position of that end of the input line.
 Each point on the graphs corresponds to a mean error from the 50 differently lesioned networks, and the number of points against any one increment on the A:axis is determined by the number of lines available to provide measurements at that point.
 In Figure 4 w e see that the closer the left end of the line is to the left extreme of the L V F , the larger is the rightward displacement of the left endpoint.
 A s the line moves over towards the right, this displacement decreases and, indeed, reverses in direction as the fixation point is approached.
 The reversal principally occurs between points 7 and 8, the two L V F locations closest to the fixation point.
 Within the context of our representation of the linebisection task, there is a gradation of neglect behaviour across the whole L V F , which continues across the fixation point and into the R V F , with no drastic stepfunction as the transition is made between LVF and RVF.
 y = 0.
345x2.
413 5 § Position of left end of line 9 10 fixation point Figure 4.
 Left endpoint displacement plotted against position of the left end of the line.
 y = 0.
139x 1.
563 i I I I I I I I I 9 10 11 12 13 14 15 16 17 fixation point Position of tight end of line Figure 5.
 Right endpoint displacement plotted against position of the right end of the line.
 145 Figure 5 reveals overall behaviour similar to that shown in Figure 4: graded behaviour across the whole visual field, crossing smoothly over into the other visual field.
 In accordance with the human data, neglect also occurs in the visual field corresponding to the "unimpaired" hemisphere, although it is worse in the visual field corresponding to the lesioned hemisphere (compare the slopes in Figures 4 and 5).
 Moreover, the right extreme of the RVF shows the exaggerated, reversed action associated with the end of the ipsilesional visual field.
 In the terms of the linebisection task, this means a performance which does not just preserve the normal function (which would give a correct response) but exaggerates it in the direction away from the overall left neglect performance: Figure 5 shows that performance on the righthand side of the RVF is characterised by left displacement, the crossover occurring smoothly between points 11 and 12.
 In general.
 Figures 4 and 5 show that unilateral damage to the model did not simply result in errorful output in the LVF and correct output in the RVF.
 Conclusions We have shown that the fundamental characteristics of unilateral neglect and its detailed, taskspecific behaviour both emerge very naturally from a connectionist model which mirrors the gross architecture of human visual perceptual processing  an initial clean division of the perceptual input into two visual fields and a later, freer interaction between the two halves of the model.
 The general behaviour we have described seems to be robust across minor changes in architecture; we have also explored this general model in connection with neglect dyslexia (Shillcock & Cairns, 1994).
 The split nature of the model is central to its behaviour; the precise details of the recurrent connections at the hidden and output levels are probably less important.
 W e have shown that the existence of attentional and behavioural gradients across and within visual hemifields is not incompatible with a sharp division of responsibility between the two hemispheres.
 Rather, the former emerges naturally and directly from the latter, even with the very simple abstract network model we have described.
 Our model might be seen as broadly isomorphic with Kinsbourne's orientational bias model of unilateral neglect (Kinsboume, 1970, 1993): the two halves of our model's input might be seen as contralaterally directed attentional processors, and the complex hidden/output processing might be seen as the site of the reciprocal opponent interactions of Kinsbourne's model.
 Kinsbourne's model was developed from the perspective of an "attentional" explanation of neglect, whereas our own model, which uses explicit representations, was based on a consideration of the fundamental perceptual problem of integrating a split visual field.
 The genesis of the two models is relatively unimportant, however, given the collapse of the previous opposition between "attentional" and "representational" approaches: notions of attention must eventually be grounded in patterns of activation.
 The fact that our model incorporates visual field splitting means that we can explicitly model the role of eye fixation data in neglect.
 It should be noted that in Figures 2 and 3, where we have recorded percentages of displaced and correct outputs, the final response would typically be an aggregate of several of these data points, corresponding to several different fixations.
 The simulations demonstrate that, at least for the linebisection task, the desired behaviour can be obtained from a consideration of overt fixation behaviour, rather than an underspecified, covert attentional processor underlying that fixation behaviour.
 This is in contrast to an existing connectionist model of neglect (specifically neglect dyslexia) (Mozer & Behrmann, 1990) which elegantly accounts for much of the existing data, but is based at a level more abstract than that at which hemispheric splitting occurs and imposes a smooth, left to right gradient on an attentional processor.
 The broad isomorphism between Kinsbourne's model and our own points to the value of explicit computational modelling.
 Traditional cognitive neuropsychological models, consisting of linguistic descriptions of modular processing, have been unable to provide an explicit, detailed, explanatory account of the rich data from unilateral neglect which captures the diverse, quantitative data of tasks like the linebisection task, with its reliable correlations between subject performance and task parameters, and its crossover effects.
 Only an explicit computational model can demonstrate the detailed processing consequences of autonomous processors interacting with each other to determine the final perception.
 The success of the current model in bridging the gulf between gross cognitive architecture and detailed performance underlines the power of connectionist approaches in cognitive neuropsychological theory.
 Acknowledgements This research was carried out with support from MRC grant G9421014 N (UK).
 W e would also like to thank an anonymous reviewer for comments.
 References Barany, R.
 (1913).
 Latente Deviation der Augen ud Vorbeizeigen des Kopfes bei Hemplegie und Epilepsie.
 Wiener klinische Wochenschrift, 26, 597599.
 Bisiach, E.
, Bulgarelli, C, Sterzi, R.
 & Vallar, G.
 (1983).
 Line bisection and cognitive plasticity of unilateral neglect of space.
 Brain and Cognition, 2, 3238.
 Fendrich, R.
 & Gazzaniga, M.
S.
 (1989).
 Evidence of foveal splitting in a commissurotomy patient.
 Neuropsychologia, Vol.
 27, No.
 3, pp.
 273281.
 Halligan, P.
W.
, Manning, L.
 & Marshall, J.
C.
 (1991).
 Hemispheric activation vs spatiomotor cueing in visual neglect: A case study.
 Neuropsychologia, 29, 2, 165176.
 Halligan, P.
W.
 & Marshall, J.
C.
 (1988).
 How long is a piece of string? A study of line bisection in a case of visual neglect.
 Cortex,lA, 321328.
 146 Halligan, P.
W.
, Marshall, J.
C.
 & Wade, D.
T.
 (1989).
 Visuospalial neglect: Underlying factors and test sensitivity.
 Lancet, 2, 908911.
 Halligan, P.
W.
 & Marshall, J.
C.
 (1989a).
 Line bisection in visuospatial neglect: Disproof of a conjecture.
 Cortex, 25, 517521.
 Halligan, P.
W.
 & Marshall, J.
C.
 (1989b).
 T w o techniques for the assessment of line bisection in visuospatial neglect: a case study.
 Journal of Neurology, Neurosurgery and Psychiatry, 52, 13001302.
 Halligan, P.
W.
 & Marshall, J.
C.
 (1989c).
 Perceptual cueing and perceptuomotor compatibility in visuospatial neglect: a single case study.
 Cognitive Neuropsychology, 6, 423^35.
 Halligan, P.
W.
 & Marshall, J.
C.
 (1994).
 Towards a principled explanation of unilateral neglect.
 Cognitive Neuropsychology, 11 (2), 167206.
 Heilman, K.
M.
 & Valenstein, E.
 (1979) Mechanisms underlying hemispatial neglect.
 Annals of Neurology, 5, 166170.
 Ishiai, S.
, Furukawa, T.
 & Tsukagoshi, H.
 (1987).
 Eyefixation patterns in homonymous hemianopia and unilateral spatial neglect.
 Neuropsychologia, 25, No.
 4, 675679.
 Kinsbourne, M.
 (1970).
 A model for the mechanism of unilateral neglect of space.
 Transactions of the American Neurological Association, 95, 143146.
 Kinsbourne, M .
 (1993).
 Orientational bias model of unilateral neglect: Evidence from attentional gradients within hemispace.
 In I.
H.
 Robertson & J.
C.
 Marshall (Eds), Unilateral neglect: Clinical and experimental studies.
 LEA, Hove, UK.
 Marshall, J.
C.
 & Halligan, P.
W.
 (1989).
 When right goes left: An investigation of line bisection in a case of visual neglect.
 Cortex, IS (3), 503  515.
 Mozer, M.
C.
 & Behrmann, M .
 (1990).
 On the interaction of selective attention and lexical knowledge: a connectionist account of neglect dyslexia.
 Journal of Cognitive Neuroscience, 2, 96123.
 Nichelli, P.
, Rinaldi, M .
 & Cubelli, R.
 (1989).
 Selective spatial attention and length representation in normal subjects and in patients with unilateral spatial neglect.
 Brain and Cognition.
 9, 5770.
 ReuterLorenz, P.
A.
 & Posner, M.
L Components of neglect from right hemisphere damage: An analysis of line bisection.
 Neuropsychologia, 28, 327333 (1990).
 Riddoch, M.
J.
 & Humphreys, G.
W.
 (1983).
 The effect of cueing on unilateral neglect.
 Neuropsychologia, 21, 589599.
 Rumelhart, D.
E.
, Hinton, G.
E.
, Williams, R.
J.
 (1986).
 Learning internal representations by error propagation.
 In Parallel Distributed Processing: Explorations in the Microstructure of Cognition , (Eds.
 David E.
 Rumelhart, James L.
 McClelland), MIT.
 Schenkenberg, T.
, Bradford, D.
C.
 & Ajax, E.
T.
 (1980).
 Line bisection and unilateral visual neglect in patients with neurological impairment.
 Neurology, 30, 509517.
 Shillcock, R.
C.
, Cairns, P.
 (1994).
 Neglect dyslexia and the neuropsychology of reading: a connectionist model of neglect dyslexia with no attentional component.
 Research paper HCRC/RP52, Human Communication Research Centre , University of Edinburgh.
 Shillcock, R.
C.
, Cairns, P.
 {submitted).
 A principled model of unilateral neglect behaviour in the linebisection task.
 147 T h e Interaction of Spatial Reference Frames and Hierarchical Object Representations: A Computational Investigation of Drawing in Hemispatial Neglect Jeffrey BengHee H o Depanment of Psychology Carnegie Mellon University Pittsburgh, PA 152133890 ho+Ocmu.
edu Marlene Behrmann Department of Psychology Carnegie Mellon University Pittsburgh, PA 152133890 mb9h@crab.
psy.
emu.
edu David C.
 Plaut Department of Psychology Carnegie Mellon University, and Center for the Neural Basis of Cognition Pittsburgh, PA 152133890 plaut@cmu.
edu Abstract In drawing a figure, hemispatial neglect patients typically produce an adequate representation of parts on the right of the figure while omitting significant features on the left.
 This contralateral neglect is influenced by multiple spatial reference frames and by the hierarchical structure of the object(s) in the figure.
 The current work presents a computational characterization of the interaction among these influences to account for the way in which neglect manifests in drawing.
 Neglect is simulated by a "lesion" (monotonic dropoff from right to left) that can affect performance in both objectcentered and viewercentered reference frames.
 The joint effects of neglect in both these frames provide a coherent account of the drawing performance of a patient, JM, and may be extended to account for the copying performance of other patients across a range of objects and scenes.
 Introduction Hemispatial or unilateral neglect is a visuospatial deficit, typically caused by brain damage to the right parietal lobe, in which patients fail to perceive or act on information that appears on the side of space opposite the lesion While patients with (leftsided) neglect have normal intellectual abilities and intact primary motor and sensory function, they do not notice objects on the left, may leave food untouched on the left side of the plate, and m a y not shave or bathe the left side of the body.
 Neglect is generally interpreted as a failure to distribute attention evenly along the horizontal meridian such that less attention is deployed to the left than to the right (Cohen, Romero, ServanSchreiber, & Farah, 1994; Kinsboume, 1993; Mozer & Behrmann, 1990; Posner, 1988).
 A central question in understanding neglect is what constitutes "left"—that is.
 With respect to what frame of reference is the left side defined? Possibilities include viewercentered frames (e.
g.
, aligned with the retina, head, or trunk), environmentcentered frames (e.
g.
, aligned with the room, table, or page), and objectcentered frames (i.
e.
, aligned with depicted objects).
 Under most viewing conditions, these frames are all aligned, so there is no way to evaluate which frame determines the nature of neglect behavior.
 In fact, recent evidence suggests that neglect behavior is sensitive to spatial information defined simultaneously with respect to multiple reference frames.
 W h e n viewercentered and objectcentered frames are deconfounded by rotating the stimulus or the viewer, patients continue to exhibit viewercentered neglect but also fail to report information on the left of the object even though this information is located to the right of midline of the viewer and/or the environment (Behnnann & Moscovitch, 1994; Driver & Halligan, 1991; Young, Hellawell, & Welch, 1991).
 A compelling example of this objectcentered neglect is the case of N G , a patient with rightsided neglect, w h o failed to read the rightmost letters of a word even when the word was presented vertically or in mirrorreverse format (Caramazza & Hillis, 1990).
 Objectcentered neglect can also be demonstrated under fixed viewing conditions.
 W h e n viewing an equilateral triangle with a gap on one side, patients with leftsided neglect fail to detect the gap more often when they are biased to see the uiangle as pointing in a direction that places the gap on the left of the perceived major axis (Driver, Bay lis, Goodrich, & Rafal, 1994).
 These data support the view that the spatial positions of parts of an object are coded with respect to a reference frame aligned with the principle axis of the object itself (Marr, 1982; Marr & Nishihara, 1978), and that visual attention is allocated, at least in part, relative to this frame.
 Objectcentered effects in neglect may manifest in more complicated ways in a copying task, in which a target stimulus, often a daisy or a clock, is presented upright in the center of a blank piece of paper.
 Patients with neglect often produce an adequate representation of the right side of the figure while leaving out significant features on the left.
 For example, the left drawing in Figure 1 shows the performance of a neglect patient, JM, in copying an upright daisy, in which the leftmost petals were omitted.
 Again, though, the standard copying task confounds the influences of reference frames centered on the viewer, the environment, and the object.
 If parts are located with respect to an objectcentered frame, then, when copying a daisy rotated from the upright, patients should continue to neglect to draw parts on the left defined intrinsically with respect to the object itself.
 As is evident in Figure 1, patient J M still omits features on the objectcentered left of the daisy when copying misoriented versions of the target daisy.
 Interestingly, objectcentered neglect in copying may occur not only for a single object but also when the figure to be copied contains multiple items.
 In this case, patients may omit features on the left of an object while still including features on the right of another object that is further to the left on the page (Gainotti, Messerii, & Tissot, 1972; Marshall & Halligan, 1993).
 Moreover, the objectcentered deficit may appear even within subparts of asingle, complex object.
 W he n patient PP (Driver & Halligan, 1991) was required to copy a single wheel, presented on the left or right of a page, she omitted spokes on the left of the wheel.
 W h e n two wheels were presented, one on the left and one on the right, she omitted spokes only on the left of the left wheel.
 W h e n the 148 mailto:mb9h@crab.
psy.
emu.
edumailto:plaut@cmu.
eduu Figure 1: Neglect patient JM's copying of a daisy presented in different orientations two wheels appeared as parts of a larger object (a bicycle), PP omitted the left wheel entirely, retaining only the right one.
 These findings make sense if the representation of an object has a hierarchical structure in which its parts are in themselves objects at a smaller spatial scale, and which decompose further into their own parts at an even smaller scale (Marr & Nishihara, 1978; Palmer, 1977).
 During the copying of a complex figure, a reference frame aligned with a part of the object serves as the context frame for locating and drawing its subparts.
 Thus, the objectcentered frame is not fixed throughout the task; rather, objects are recursively decomposed and dynamically assigned to roles as objects and parts depending on the current relevant level of the hierarchy (see Hinton, 1990).
 Accounting for the copying performance of neglect patients (and of normal subjects) is complicated because, at one point in time, the context frame may represent the spatial coordinates for copying a particular part, whereas at a second point in time, this same part may itself define the context frame for the copying of its own subparts.
 The goal of this paper is to examine how hierarchical object representations might interact with spatial reference frames to explain the performance of patients who show neglect both with respect to multiple frames of reference and at multiple levels of the object hierarchy.
 First, we examine whether, as suggested above, the performance of normal subjects in copying misoriented versions of a daisy is mediated by a hierarchical representation of the daisy.
 W e then implement this process as a conventional treetraversal algorithm over a hierarchical data structure representing the daisy.
 During the traversal, the position of each component is maintained relative to both the local objectcentered frame and the global viewercentered frame.
 By imposing a spatially defined lesion, analogous to the deficit hypothesized to underlie the attentional impairment in patients with rightparietal damage, we demonstrate how neglect can arise with respect to both the viewer and objectcentered reference frames even when objects are misaligned from their canonical orientation.
 Hierarchical Representations in Drawing It is commonly assumed that hierarchical object representations are used to structure drawing (Taylor & Tversky, 1992) and that this representation is the same one that mediates perception (Kosslyn, 1987; Van Sommers, 1989).
 In the case of the daisy, we assume that the hierarchical representation is composed of three major parts (parents), each of which can be broken down into their subparts (children) (see Figure 2).
 These children are decomposed further—for example.
 n Flowerhead Center Petal Petal L Branch R Branch I I , L Leaf R Leaf Pot I Lip I Base Figure 2: A daisy and its hierarchical representation.
 the central stem decomposes into the oblique stems which break down further to encompass the leaves.
 The representation used in this study has four levels, as illustrated in Figure 2.
 To verify that this hierarchical object representation adequately captures drawing performance, we had 20 normal subjects generate 3 copies of a daisy presented in each of 4 orientations (upright, 90" rotation to the left or right, and inverted).
 W e tracked the order of strokes used by the subjects.
 Drawing performance was considered to obey the hierarchical representation if the order in which the components were drawn followed a depthfirst traversal order through the hierarchy (ignoring the order among subparts).
 In other words, once a stroke within a particular subtree is drawn, all of its components and subcomponents must be drawn before a stroke within another subtree at the same level is drawn.
 Any stroke that did not adhere to this rule was counted as a violation of the hierarchy.
 Across all subjects and drawing conditions, the mean number of hierarchy violations was 1.
3 (SD 0.
84), and was not significantly affected by the orientation of the daisy (F<1).
 This number of violations is significantly different from the mean obtained from 120 randomlygenerated stroke sequences (17.
2; S D 2.
6; Fi,238=3953, p<.
001).
 This finding supports the proposal that the performance of normal subjects in copying the daisy is baseid on traversing a hierarchical representation like the one in Figure 2.
 Implementation of Neglect Drawing M e t h o d Given the evidence that normal subjects use a hierarchical object representation when drawing, a computational investigation was carried out to explore the implications of a spatial impairment in object and viewercentered reference frames when drawing using a hierarchical representation.
 The hierarchy depicted in Figure 2 was represented as a conventional tree data structure, in which each node in the tree cortesponded to a particular part of the daisy.
 The node for a part contained 149 l.
U ^ 0.
8 00 •S 07 ? 2 0.
6 a ^ 0.
5 o 2^0.
4 S 0.
3 ^0.
 2 i; 0.
1 ^ ^̂ '"̂ ^ y^ y^ y/ / / h / /  / 1 _ _ • ' • 97 .
96 .
88 .
95 ' I.
O 0.
8 0.
6 0.
4 0.
2 0.
0 0.
2 0.
4 0.
6 0.
8 1.
0 Horizontal Position Figure 3: The probability that a part is drawn (i.
e.
, not neglected) as a f\inction of its horizontal position within a reference frame.
 information on its location in the objectcentered frame defined by its parent.
 Specifically, the objectcentered frame for a part was oriented and centered on its parent, with a scale defined by the horizontal extent of the parent (with xcoordinates ranging between ± 1 ) .
 The viewercentered frame was always upright, centered on the entire daisy, and used a scale defined by the horizontal extent of the daisy.
 Thus, for instance, the rightmost petal in the upright daisy has a viewercentered xcoordinate of about 0.
5 (i.
e.
, the horizontal position of its center is about half way between the midline of the daisy and the tip of the right leaf) and an objectcentered xcoordinate of about 2.
0 (i.
e.
, its horizontal distance from the center of its parent, the circle, about twice the radius of the circle).
 For a misoriented daisy, the viewercentered positions of parts changed accordingly but their objectcentered positions remained the same.
 For a particular orientation of daisy, the probability that the part would be drawn (i.
e.
, not neglected) in a particular frame was assumed to be a monotonicallyincreasing function of its horizontal position in that frame (Figure 3).
 The specific (exponential) form of this function is not critical as it influences only quantitative aspects of the results.
 Notice that the probability of drawing a part is near 1.
0 on the right side of the frame, about 0.
9 at the midline, and drops off sharply towards the left of the frame.
 The overall likelihood that a part is drawn was assumed to be a weighted average of its separate probabilities in the viewercentered frame and in the objectcentered frame—the effects of different relative weightings are explored below.
 All else being equal, the effect of neglect is generally stronger in the objectcentered frame than in the viewercentered frame because the former is defined more locally (i.
e.
, parts typically fall outside the ± 1 frame defined by the horizontal extent of their parent).
 A simple depthfirst tree traversal algorithm was used to determine the neglect pattern.
 At every node, the probability that the corresponding part was drawn was calculated based on its viewercentered and objectcentered coordinates.
 W e assumed that if a part was not drawn, then none of its subparts would be drawn.
 Thus, the probability of a part being drawn is the product of and the probability of its parent being drawn and its o w n local probability based on its relative positions in the viewer and objectcentered frames.
 The order of traversal among children of the same parent was irrelevant.
 (a) (b) Figure 4: The probabihties that the parts of a leftfacing daisy are drawn when neglect operates (a) solely in the viewercentered frame, and (b) solely in the objectcentered frame(s).
 The outcome of the tree traversal was that every part was assigned a probability of being drawn based on the orientation of the daisy and the particular weightings of the viewer and objectcentered frames.
 Results and Discussion To investigate the relative contribution of the viewer and objectcentered neglect on drawing performance, w e calculated the probability of each part being drawn for daisies in all four orientations—up, left, down, and right—first when the viewer and objectcentered effects had independent influences on drawing performance and then when performance was influenced by a combination of viewer and objectcentered effects.
 To explore the independent effects of the two frames, the weighting of either the viewer or objectcentered effect was set at 1 and the other effect was set at 0.
 Thereafter, combinations of the two frames were examined when the weighting of one frame was 0.
75, 0.
5, or 0.
25 and that of the other was set to produce a sum of 1.
 Because the misoriented daisy allows for the decoupling of the viewer and objectcentered effects, unlike the upright daisy.
 Figure 4 illustrates the independent contribution of viewercentered neglect and of objectcentered neglect in a leftfacing daisy.
 The numbers superimposed on the daisy indicate the probability of each feature being drawn, calculated according to the algorithm described above.
 It is important to recognize that the probability of a part being drawn is contingent on the probability of its parent being drawn—if the parent or containing objects is omitted, so is the child.
 The probabilities for the subparts such as the petals and leaves, therefore, reflect the conditional probability of parent and child both being drawn and are subsequently lower than the probability of the parent alone.
 A s is evident from this figure, when the viewercentered influence is 1.
0 with no objectcentered influence (Figure 4a), information on the viewercentered left has a fairly low probability of being drawn, with the probability of the daisy head being 0.
75 and the surrounding left and right petals ranging from 0.
45 to 0.
63 respectively.
 The petal that occupies the leftmost position has a probability of 0.
38.
 In contrast, when the viewercentered effect is set to have no influence and neglect arises solely within the objectcentered frame (Figure 4b), information to the right of the canonical midline of the daisy has a high probability of being drawn (approximately 0.
94) whereas the petals and leaf on the left of the intrinsic axis have a very low probability of being drawn (approximately 0.
24).
 The leaf on the canonical left stem has a probability of 0.
06 because it is conditional on its parent stem being drawn 150 Up LcK Down Right Viewer 0.
75 Object 0.
25 .
54 Viewer 0.
50 Object 0.
50 93 .
91 .
64 Viewer 0.
25 W \ T r } Object 0.
75 9a .
88 .
75 Figure 5: The effects of various mixtures of neglect in the viewercentered frame and in the objectcentered frame(s).
 Figure 6: Drawings produced by a mixture of 0.
6 viewercentered neglect and 0.
4 objectcentered neglect, assummg a threshold probabUity of drawing a part of 0.
57.
 151 and because it occupies the most extreme left position in the objectcentered frame.
 Figure 5 illustrates how a mixture of neglect in the viewerand objectcentered fnunes affect the probability of a feature being drawn.
 As is evident from the upright daisy, the objectcentered effect has a somewhat stronger influence on performance—when it is set at 0.
75.
 the probability of the petals and stem on the left being drawn is lower than when the viewercentered effect is set at 0.
75.
 In all cases, the midline structures (flowerhead, stem, and pot) have a high probability of being drawn.
 The slightly stronger influence of the object is also seen in the upsidedown figure where, even when the two effects are equivalent at 0.
5, the probability of drawing parts on the left, defined in the objectcentered frame, is lower than the probability of drawing parts on the left of the viewercentered frame (canonical right of daisy).
 The interaction of the two effects is best seen in the 90°  misoriented daisies.
 In the leftfacing daisy, the probability of drawing the petals on the canonical left (where the petals are also on the viewercentered left) is much lower than in the rightfacing daisy (where these same petals appear on the right of the viewercentered frame).
 As either the severity of the vieweror the objectcentered neglect is increased, so the probability of drawing such a leftsided petal decreases.
 For example, on the leftfacing daisy, when the viewer and objectcentered effects are equivalent, at 0.
5, the probability of drawing the petal to the immediate left of the canonical midline is 0.
36.
 As the objectcentered effect is decreased to 0.
25, the probability of that petal being drawn increases to 0.
41, and as the objectcentered effect is increased to 0.
75, so the probability decreases to 0.
30.
 The important point is that when a petal appears on the left of both the object and the viewercentered frame, it has a high probability of being neglected, relative to when it appears on the left in only one frame.
 This is in marked contrast to the data from the same petal (canonical left) on the rightfacing daisy in which, irrespective of the relative contribution of object and viewercentered neglect, remains approximately constant with a probability of about 0.
97.
 The crucial result from this analysis is that there are joint effects on neglect on the distribution of attention in both frames and that these are exacerbated as the severity of neglect—particularly in the objectframe—increases.
 The probabilities in the figures can be interpreted as indicating the frequency with which individual parts would be drawn over a large sample of drawings.
 In order to account for the drawing performance of a single neglect patient, JM, and to generate daisies that would adequately characterize his performance, w e adopted a discrete approach in which w e converted the probabilities into absolute values.
 W e then selected a threshold of 0.
57 such that features with values below this threshold were not drawn (i.
e.
, were neglected).
 Figure 6 contains the renderings of the daisies in four orientations when this threshold value is used.
 The relative weightings of viewerand objectcentered neglect were 0.
6 and 0.
4, respectively, as these best accounted for JM's drawings.
 As can be seen from these drawings, the data are reasonably well captured by this mixture of object and viewercentered neglect with the threshold as the cutoff value for performance.
 O n e apparent discrepancy is that JM's drawing of the leftfacing daisy does not contain the upperright petal (Figure lb).
 As it turns out, he initially drew this petal and then erased it, removing a small part of the circle along with it.
 Another aspect of his data not yet explained is the rightfacing daisy (Figure Id), in which petsils on the canonical object left are omitted but petals are also omitted from the left of the daisy head defined in viewercentered coordinates.
 This pattern again reflects the joint effect of viewer and objectcentered effects.
 One interesting possibility is that after J M drew the daisy head (which he did first), because the circle in the center has no intrinsic axis, it has no obvious leftright asymmetry.
 This ambiguity lends itself to neglect in both frames: In an objectcentered frame, a petal to the left is ignored and in a vieweredcentered frame, petals to the left are also ignored.
 Although we cannot account for these data in our current implementation and the joint effect of the two frames in Figure Id is beyond the interactions w e have modeled here, the model may be extended to account for these data utilizing the same principles as those incorporated in the simulations thus far.
 Conclusions We have presented a computational investigation of how hierarchical object representations might interact with multiple spatial reference frames.
 This combination of the representation and reference frames is able to reproduce the pattern of drawing performance observed in patients with hemispatial neglect.
 The deficit in patients with neglect is considered to be a failure to distribute attention evenly across space with the result that information on the contralateral side is ignored or omitted.
 O f much recent interest is that, in addition to neglect of information on the left defined by viewercentered coordinates (Farah, Brunn, Wong, Wallace, & Carpenter, 1990; Kamath, 1994), patients may simultaneously ignore information on the left defined by coordinates intrinsic to an object (Behrmann & Moscovitch, 1994; Caramazza & Hillis, 1990; Driver & Halligan, I99I; Marshall & Halligan, 1993).
 W e simulate the coexistence of neglect in more than one set of coordinates by assuming that the same deficit (instantiated as a monotonic dropoff of attention firom right to left) underlies the distribution of attention in these different reference frames (but see Humphreys & Riddoch, 1994).
 By computing the probability of drawing a feature as a function of its leftright position in the object and viewercentered frames, w e can explain why neglect patients fail to localize objects or to attend to information situated in a larger context frame.
 Through the dynamic reassignment of elements to object or parts roles, this same model can account for neglect of objects on the left of a multiobject scene, neglect on the left of a single object, and neglect for features on the left of a part of a single object.
 W e also show how, by varying the relative weighting of neglect in each frame, w e can account for the drawing performance of neglect patient, JM.
 O n e aspect of neglect copying performance which is not easily explained by the current model and which is robust across patients is that some features are retained.
 Under the account w e have proposed, these same features should probably be omitted.
 For example, patients almost never draw only the right half of the circle for the head of the flower, nor do they omit the lip of the pot (if the base is drawn), even if it occupies a position on the left of the spatial reference frame.
 Similarly, in clock drawing or copying, even if patients neglect 152 to fill in the numbers on the left of the clock, they invariably draw the entire perimeter of the clock.
 A possible explanation for this retention of leftsided information derives from the nature of the object representation underlying the subject's performance.
 Several recent studies have shown that patients with neglect remain sensitive to Gestalt properties of the stimulus.
 Thus, if a feature on the left of the object's midline can be grouped together with a feature on the right to form a "good" figure, based on principles such as good continuation, symmetry or closure, the leftsided feature is less likely to be neglected (Ward, Goodrich, & Driver, 1994).
 The grouping of features according to Gestalt heuristics ma y be incorporated into the hierarchical representation adopted here and a rather direct extension of the current implementation can account for these seemingly contradictory results.
 The ^proach adopted here has been to characterize systematically the behavior of a mechanism in which hierarchical object representations and multiple reference frames interact to codetermine performance of a system.
 The simulations are not intended to be a veridical instantiation of the neural mechanism underlying neglect nor to parallel directly the function of parietal lobe.
 The principles embodied in this work, however, are consistent with many views that argue that the parietal lobe integrates and transforms data from one set of coordinates to another (Colby, 1991; Kamath, 1994; Stein, 1992).
 H o w the brain might actually implement a hierarchical representation and how it might achieve the dynamic reassignment of the components to parts and wholes are difficult research issues (see Hinton, 1990, for a connectionist £^proach to these problems).
 The example of the daisy was used in this research because it is standardly used in the clinical assessment of neglect and because much is known about the way neglect patients perform on this task.
 The principles governing the joint effects of neglect in more than one reference frame, as proposed here, however, are believed to apply more generally.
 Predictions from this model m ay be generated to account for the copying behavior of neglect patients when they are confronted with more complex hierarchical objects and visual scenes.
 Acknowledgments Financial support for this research was provided by the National Institute of Mental Health (Grant MH47566), the McDonnellPew Program in Cognitive Neuroscience (Grant T8901245016), the Neural Processes in Cognition Summer Internship Program, and a Student Undergraduate Research Grant from Carnegie Mellon University.
 References Behrmann, M.
, & Moscovitch, M.
 (1994).
 Objectcentered neglect in patients with unilateral neglect: Effects of leftright coordinates of objects.
 Journal of Cognitive Neuroscience,6{l), 116.
 Caramazza, A.
, & Hillis, A.
 E.
 (1990).
 Spatial representation of words in the brain implied by studies of a unilateral neglect patient.
 Nature, 346,261269.
 Cohen, J.
 D.
, Romero, R.
 D.
, ServanSchreiber, D.
, & Farah, M.
 J.
 (1994).
 Mechanisms of spatial attention: The relation of macrostructure to microstructure in parietal neglect.
 Journal of Cognitive Neuroscience, 6(4), 377387.
 Colby, C.
 L.
 (1991).
 The neuroanatomy and neurophysiology of attention.
 Journal of Child Neurology, 6, S90S118.
 Driver, J.
, BayUs, G.
 C , Goodnch, S.
, & Rafal.
 R.
 D.
 (1994).
 Axisbased neglect of visual shape.
 Neuropsychologia, 32{\\), 13531365.
 Dnver, J.
, & Halligan, P.
 W.
 (1991).
 Can visual neglect operate in objectcentered coordinates: An affirmative study.
 Cognitive Neuropsychology, 8, 475496.
 Farah, M.
 J.
, Brunn, J.
 L.
, Wong, A.
 B.
, Wallace, M.
, & Carpenter, P.
 (1990).
 Frames of reference for the allocation of spatial attention: Evidence from the neglect syndrome.
 Neuropsychologia, 28, 335347.
 Gainotti, G.
, Messerli, P.
, & Tissot, R.
 (1972).
 Qualitative analysis of unilateral spatial neglect in relation to laterality of cerebral lesions.
 Journal ofNeurology, Neurosurgery, and Psychiatry, 35, 545550.
 Hinton, G.
 E.
 (1990).
 Mapping partwhole hierarchies into connectionist networks.
 Artificial Intelligence, 46{l), 4776.
 Humphreys, G.
 W.
, & Riddoch, M .
 J.
 (1994).
 Attention to withinobject and betweenobject spatial representations: Multiple sites for visual selection.
 Cognitive Neuropsychology, 11{2), 207241.
 Kamath, H.
 O.
 (1994).
 Distumed coordinate transformation m the neural representation of space as the crucial mechanism leading to neglect.
 In P.
 W.
 Halligan, & J.
 C.
 Marshall (Eds.
), Spatial neglect: Position papers on theory and practice (pp.
 147150).
 Hove, UK: Lawrence Erlbaum Associates.
 Kinsboume, M.
 (1993).
 Orientational bias model of unilateral neglect: Evidence from attentional gradients within hemispace.
 In I.
 H.
 Robertson, & J.
 C.
 Marshall (Eds.
), Unilateral neglect: Clinical and experimental studies (pp.
 6386).
 Hove, UK: Lawrence Erlbaum.
 Kosslyn, S.
 M.
 (1987).
 Seeing and imagining in the cerebral hemispheres: A computational approach.
 Psychological Review, 94(2), 148175.
 Marr, D.
 (1982).
 Vision.
 San Francisco, CA: W .
 H.
 Freeman.
 Marr, D.
, & Nishihara, H.
 K.
 (1978).
 Representation and recognition of the spatial organization of threedimensional shapes.
 Proceedings of the Royal Society of London, Series B, 200, 269294.
 Marshall, J.
 C , & Halligan, P.
 W.
 (1993).
 Visuospatial neglect: A new copying test to assess perceptual parsing.
 Journal of Neurology, 240, 37^0.
 Mozer, M.
 C , & Behrmann, M.
 (1990).
 O n the interaction of selective attention and lexical knowledge: A connectionist account of neglect dyslexia.
 Journal of Cognitive Neuroscience, 2(2), 96123.
 Palmer, S.
 E.
 (1977).
 Hierarchical structure in perceptual representation.
 Cognitive Psychology, 9, 441474.
 Posner, M.
 I.
 (1988).
 Structures and functions of selective attention.
 In T.
 Boll, & B.
 Bryant (Eds.
), Clinical neuropsychology and brain function: Research, measurement and practice {pp.
 173202).
 Washington, DC: American Psychological Association.
 Stein, B.
 F.
 (1992).
 The representation of egocentric space in the posterior parietal cortex.
 Behavioral and Brain Sciences, 16, 691700.
 Taylor, H.
 A.
, & Tversky, B.
 (1992).
 Descriptions and depictions of environments.
 Memory and Cognition, 20,483^96.
 Van Sommers, P.
 (1989).
 A system for drawing and drawingrelated neuropsychology.
 Cognitive Neuropsychology, 6{2), 117164.
 Ward, R.
, Goodrich, S.
, & Driver, J.
 (1994).
 Grouping reduces visual extinction: Neuropsychological evidence for weightlinkage in visual selection.
 Visual Cognition, 1{\), 101129.
 Young, A.
 W.
, HellaweU, D.
 J.
, & Welch, J.
 (1991).
 Neglect and visual recognition.
 Brain, 115, 5171.
 153 A M o d e l of Visually Guided Plasticity of the Auditory Spatial M a p in the B a r n O w l Andrea Haessly Department of Computer Sciences The University of Texas at Austin Austin, TX 78712 andrea@cs.
utexas.
edu Joseph Sirosh Department of Computer Sciences The University of Texas at Austin Ausan,TX 78712 s iroshOcs.
utexas.
edu Risto Miikkulainen Department of Computer Sciences The University of Texas at Austin Austin, TX 78712 ristoQcs.
utexas.
edu Abstract In the bam owl, the selforganization of the auditory map of space in the external nucleus of the inferior colliculus (ICx) is strongly influenced by vision, but the nature of this interaction is unknown.
 In this paper a biologically plausible and minimalistic model of ICx selforganization is proposed where the ICx receives a leant signal based on the owl's visual attention.
 When the visual attention is focused in the same spatial location as the auditory input, the learn signal is turned on, and the map is allowed to adapt, A twodimensional Kohonen map is used to model the ICx, and sitnulations were perfonned to evaluate how the learn signal would affect the auditory map.
 When primary area of visual attention was shifted at different spatial locations, the auditory map shifted to the corresponding location.
 The shift was complete when done early in the development and partial when done later.
 Similar results have been observed in the bam owl with its visual field modified with prisms.
 Therefore, the simulations suggest that a learn signal, based on visual attention, is a possible explanation for the auditory plasticity.
 Introduction In the brain, several computational maps process sensory information.
 The maps transform the sensory input into a localized activity on the map, which can be easily accessed by other neural processes.
 These m ^ s selforganize so that the input space is represented topologically on the m a p (Knudsen et al.
, 1987), Typically each m a p is concerned with only one sensory modality.
 However, the b a m owl is unusual in that its auditory m a p is strongly influenced by a different modality, vision.
 S o m e kind of visual influence on the auditory m a p is known to exist because the auditory m a p adapts even when only vision is distorted.
 The auditory m a p in the external nucleus of the inferior colliculus (ICX) projects the auditory input to tlie optic tectum.
 In the optic tectum, the auditory information is combined with visual input to form a bimodal topogr^hic m ^ of space.
 This spatial m a p allows the b a m owl to locate its prey using either visual or auditory cues.
 In order to support the bimodal organization in the optic tectum, the auditory m a p in the inferior colliculus must be stmctured appropriately; a visionbased calibration signal must be involved in its selforganizing process.
 In this paper, the hypothesis that a leam signal, based on coincidence of visual attention and auditory input, mediates the auditory plasticity of the ICx, is proposed and evaluated computationally.
 A u d i t o r y a n d Visual Localization in the Barn Owl To motivate discussion of the leam signal, let us first review the roles the inferior colliculus and the optic tectum have on localization.
 The b a m owl primarily uses sounds to localize its prey in the dark, and it can do this with an accuracy surpassing that of most birds and mammals (Payne, 1971), The auditory maps that give the b a m owl its extraordinary abilities are located in the inferior colliculus.
 There are three subdivisions of the inferior colliculus known as the central nucleus (ICc), extemal nucleus (ICx), and superficial nucleus (ICs), The ICs is a relatively small portion of the inferior colliculus, and little is known about its function other than there may be a few projections to the ICx (Knudsen, 1983), The neurons in the ICc, however, are sharply tuned to frequency and tonotopically organized, and the neurons in the ICx are broadly tuned to frequency and spatiotopically organized.
 The ICx receives its input from the ICc.
 The frequencycoded auditory input to the ICc is transformed to spatial location in the ICx by the projection from the ICc to the ICx.
 This transformation process, involving interaural level differences (ILD) and interaural time differences (ITD), can unambiguously determine the location, in azimuth and elevation, of the source of the auditory input (Brainard et al.
, 1992; Knudsen, 1987).
 The spatiotopic organization that exists in the ICx is projected to the optic tectum.
 In the optic tectum (OT), there is a general bimodal m a p of space that responds to both visual and auditory input (Knudsen, 1982).
 This m a p enables the owl to determine the location of its prey either using visual cues or auditory cues.
 Experiments with visual stimuli have shown that neurons in the optic tectum are organized according to azimuth and elevation, and a visual stimulus in a certain area of space causes the neurons representing that area of space to fire much more rapidly (Knudsen & Konishi, 1978; Knudsen, 1982), The m a p responds to auditory stimuli in the same way.
 Most of the neurons that respond to visual stimuli also respond to auditory stimuli.
 In addition, the location of an auditory response is usually very close to the location of the corresponding visual response.
 This way, both modalities lead to similar responses, and other neural structures can process location information in the same way, irrespective of the originating modality.
 Since the m a p in the O T is formed by merging two different 154 mailto:andrea@cs.
utexas.
eduICX Output to OT Learn Signal t Input Vector (from ICC to ICX) Figure 1: The ICx model.
 The twodimensional feature map stands for the auditory spatial map in the ICx of the bam owl.
 The input from the ICc is a vector that is propagated to each node in the network.
 The learn signal is either on or off, and determines whether the map will be adapted.
 The neurons of the ICx project to the optic tectum.
 modalities, auditory and visual input must have a compatible structure in order to assure that the bimodal m j ^ will encode the same location for both inputs.
 Furthermore, since the region of the bimodal map that corresponds to the area directly in front of the owl is magnified (occupying a disproportionately large portion of the m ^ ) , the auditory spatial map in the ICx must have the same amount of magnification in this area in order for the visual and auditory locations to correspond.
 The structure of the retina causes magnification of the visual input.
 Since there is no corresponding mechanism that magnifies auditory input, the auditory map in the ICx must be conforming to the visual map in the optic tectum.
 Therefore, it seems that a visually based calibration signal must exists which guides the development of the auditory map in the ICx.
 Several experiments have been performed to determine what influence vision and hearing have on the formation of the bimodal map in the optic tectum (Knudsen, 1985; 1988; Knudsen & Brainard, 1991; Knudsen & Knudsen, 1985a; 1985b; 1990).
 Since the O T receives its auditory input from the ICx, any changes in the representation of auditory space in the O T reflect the plasticity that is occurring in the ICx due to vision.
 For example, prisms or occluders were mounted over the owl's eyes to manipulate the visual information the owl received (Knudsen & Knudsen, 1985a).
 The ad^tation usually took weeks and the prisms were left on for a period of months.
 While the owls still had the prisms on, their auditory localization abilities were tested by having the owl orient its head directly at the location of an auditory stimulus.
 However an owl, wearing right shifting prisms, localized to the right of the auditory stimulus.
 Even though the owl received correct auditory information, it could not accurately locate the stimulus; instead the owl chose a location that conformed to the visual distortion created by the prisms.
 This is an instance where a shifted visual signal causes the formation of an abnormal auditory spatial m ^ in the ICx, and therefore in the OT, even though there were no distortions in the auditory input.
 Vision is used as a recalibration mechanism for the auditory spatial map in the ICx, even if the visual cues are incorrect.
 These experiments show an innate dominance of vision over audition.
 Where does the visual recalibration signal come from? The ICx does not respond to any visual inputs, so there are no direct visual signals available for comparison at the ICx.
 Anterograde labeling revealed that there was no direct feedback from the optic tectum to the ICx either (Knudsen & Knudsen, 1983).
 Previous computational models of visual calibration in the ICx map have relied on such connections, modeled by backpropagation of an error signal and/or a reinforcement signal (Rosen et al.
, 1994; Pouget et al.
, 1995).
 In addition, these models did not address how the twodimensional maps in the ICx could selforganize from the visual input.
 It has been confirmed that the syn^tic changes that alter the auditory maps occur in the ICx itself, and not in the lower centers or in the optic tectum (Brainard & Knudsen, 1993).
 To date, the nature of the recalibrating signal to the ICx is not well understood.
 In the remainder of this p^er, a simple biologically plausible mechanism for the selforganization and plasticity of the ICx is proposed.
 Simulations are performed to demonstrate the plasticity of the ICx and the effects of the proposed learn signal.
 The results are then discussed along with some possible future areas of research.
 The Learn Signal Model The model is based on the selforganizing feature map (Kohonen, 1981,1989,1990), which is an abstraction of the biological mechanisms that give rise to topographic maps.
 Here, a twodimensional Kohonen m a p models the auditory spatial map in the ICx.
 The spatial location is assmned to be computed by the projection from the ICc to the ICx, and the map network receives the resulting spatial representation vector as its input (figure 1).
 These auditory input vectors are uniformly distributed since a sound can originate at any location in space (figure 2a).
 H o w could visual input calibrate the auditory m a p formed by the Kohonen algorithm? Because the ICx does not respond to any visual inputs directly, the calibration signal, while visually based, must be of a different form.
 A simple learn signal that turns the synaptic learning on or off is proposed in this paper.
 W h e n the visual attention and the location of the sound source coincide, the learn signal is turned on and allows the m ^ to adapt.
 Thus, the signal forces the m a p to learn the portion of the input space currently attended to.
 Since the owl at155 l̂ ::̂ :̂ :;,.
.
:;:.
,::';̂ ';.
 ̂ •>v,̂ •;•: V/,y/i=>̂ :̂ ,;.
V.
''.
; ::::'W0M^:y.
 (a) Auditory input space {b) Visual attention centers (c) Auditory spatial map Figure 2: Selforganization of the normal topographic ICx map.
 The square region in (a) is a twodimensional representation of the auditory space, and the inputs are uniformly distributed in this space.
 Figure (b) shows the distribution of visual attention centers that were used to determine the on/off value of the visual instructive signal.
 The attention is distributed about the center of the input space in a gaussian fashion, so that the center is attended to more frequently than the periphery.
 When trained with these signals, a topographic map of the input space develops, as shown in figure (c).
 The width of the map corresponds to the spread of the attention signal.
 tends more often to the center of its visual field than to the periphery, a gaussian distribution around the center of the input space is used to generate the visual attention (figure 2b).
 In the Kohonen m a p the neuron that is most similar to the input vector is known as the excitation center.
 The excitation center of the auditory map, for input v is defined as the neuron r' for which Vr : \ \ v  w r ' ||<||t^iyr (1) where r are the nodes in the network and î r is the vector of weights.
 The excitation center is the image of the auditory input on the map.
 During training the learn signal must be computed.
 If the Euclidean distance between the auditory input and the visual attention is within a certain threshold 9, the learn signal will be on; otherwise the signal is off.
 W h e n the signal is on, the synaptic strengths of the neighborhood around the excitation center are modified according to the standard feature map learning algorithm ^new ^ ^old ̂  ^ ( ^ _ ^ o M ) (2) where a is the learning rate.
 Adaptation occurs only when the owl is attending to the area of space where the sound originates, that is, when the auditory input and visual attention coincide.
 Simulations Simulations were performed using a 20 x 20 neuron network with random initial values for all weights.
 Each training trial consisted of four steps: (1) A n input vector was generated and the excitation center was determined using equation 1.
 (2) A n attention center was generated and (3) compared with the excitation center.
 If the signals were relatively close (within the threshold 6), the learn signal was turned on; otherwise the learn signal was off.
 (4) If the learn signal was on, synapses were modified according to equation 2.
 A total of 20,000 training trials were required for the m a p to organize.
 A series of experiments were performed to simulate the different experimental conditions on owls with and without prisms.
 The first experiment simulated the contfol case where the owl is allowed normal vision.
 The visual attention is generated from a gaussian that is centered over the input space (figure 2b).
 The resulting topographic m a p is shown in figure 2c.
 The m ^ is centered in the input space, and the extent to which the map covers the space is determined by the spread of the gaussian attention signal.
 Thus, the learn signal focuses the map to the most attended portion of the input space.
 To simulate the development of the ICx map with prisms, the center of the gaussian distribution of attention was shifted relative to the input space (figure 3a).
 The second experiment simulated the owl wearing the prisms before its eyes had opened.
 In this case, the gaussian was shifted before any training steps.
 The resulting network had a similar shape as in the control case, but the entire network had shifted in the direction of the learn signal (figure 3b).
 Here, the map was forced to learn the inputs in the shifted region.
 In the third experiment, the center of the gaussian was shifted after 10,000 Qaining trials, simulating a period of normal development, after which the prisms were placed over the owl's eyes.
 Initially the map was forming in the center of the input space.
 After the shift occurred, the m a p slowly moved towards the new attention center.
 The area of the map furthest away from the signal was slower to adapt and looked similar to the map where the learn signal is centered.
 In conclusion, if the shift was inttoduced right from the start, the network learned only the attended region (figure 3&); however, if the shift was introduced in the middle of training, the map shifted only partially (figure 3c).
 These results are in agreement with those observed experimentally in the b a m owl (Knudsen & Knudsen, 1990).
 156 file:////vwr''I'v^^i^M:^; :':>̂  • ••*0;̂'>ffcll.
'iî•?!:•;' , (a) Shifted visual attention centers {b) Attention shifted from start (c) Attention shifted after some training Figure 3: Selforganization of the ICx map with shifted inputs.
 Figure (a) shows the shifted distribution of visual attention centers.
 Figure (fc) displays the map trained from the start with the shifted attention signal.
 The entire map has shifted to coincide with the position of the attention signal.
 However, if the attention signal is shifted midway during training, only the portion of the map close to the new attention center shifts, as shown in figure (c).
 Discussion The proposed model of the visually guided plasticity in the ICx is minimalistic in its assumptions and biologically wellmotivated.
 The single Kohonen map represents the auditory spatial maiQ that exists in the ICx of the b a m owl.
 It is not necessary to model the O T because the plasticity of the auditory map occurs at the level of the ICx.
 The model shows that a simple on/off learn signal, based on the coincidence of visual attention and auditory input, is a sufficient explanation for auditory map plasticity.
 The learn signal does not need connections from the optic tectum to the ICx, which several other models rely on, because the learn signal is not based on a comparison of the visual and auditory inputs in the OT.
 The learn signal is also much simpler than an error signal, which would include information such as the magnitude and location and even direction of error.
 The learn signal could originate from the higher cortical areas of the brain where visual input has already been processed, and the location for visual attention formed.
 In humans and other animals, sensory modalities are combined to give a single cohesive view of the world.
 In certain cases the perception of the world can be distorted, as in an illusion, because of conflicting information from different sensory inputs.
 The visual dominance in the formation of the multimodal map in the ba m owl gives insight into the mechanisms used for the integration of different sensory modalities and how one modality can distort the perceptions of other modalities.
 In future work, w e plan to extend the model with more realistic neurons with lateral connections where the weight modification process is completely unsupervised (e.
g.
 Sirosh & Miikkulainen, 1994).
 Furthermore, w e plan to include the ICc to ICx connections, which are responsible for computing the spatial input representation from the frequencyspecific interaural level differences (ILD) and interaural time differences (ITD).
 This way the ICx would be organized according to direct inputs from the ICc instead of intermediate spatial representations as in the current model.
 The bimodal m ^ that exists in the O T could also be included.
 This m a p would not only represent the visual input, but it would also incorporate the auditory input from the Kohonen m a p in the existing model.
 Such a comprehensive model would be a major step toward verifying that the leam signal is still sufficient for the plasticity of the ICx on this large scale, and that it causes a similarity in stmcture of both the auditory and visual spatial maps so that the merging done in the O T is possible.
 Conclusion The simulations reported in this paper demonstrate that a simple visuallybased leam signal is a sufficient explanation of the auditory plasticity observed in the ICx of the b a m owl.
 Unlike in previous models, an error signal is not necessary to calibrate the auditory map.
 Rather, the simple coincidence of visual attention and spatial location of auditory input may alone drive the plasticity of the ICx.
 The coincidence signal may be generated in the cortical area that is responsible for attention.
 Direct feedback projections from the optic tectum or close coupling of the O T and ICx are not necessary.
 In the future, biological experiments should be performed to verify whether such a leam signal exists, and also to determine the signal pathway to the ICx from the higher cortical areas, possibly via the ICs.
 References Brainard, M.
S.
 & Knudsen E.
I.
 (1993).
 Experiencedependent plasticity in the inferior colliculus: A site for visual calibration of the neural representation of auditory space in the bam owl.
 The Journal of Neuroscience 13,45894608.
 Brainard, M.
S.
, Knudsen, E.
I.
 & Esterly S.
D.
 (1992).
 Neural derivation of sound source location: Resolution of spatial ambiguities in binaural cues.
 The Journal of the Acoustical Society of America 91,10151027.
 157 Knudsen, E.
I.
 (1982).
 Auditory and visual maps of space in the optic tectum of the owl.
 The Journal of Neuro science 2,11771194.
 Knudsen, E.
I.
 (1983).
 Subdivisions of the inferior colliculus in the bam owl (Jyto Alba).
 The Journal of Comparative Neurology 2\%,\l^\%(i.
 Knudsen, E.
I.
 (1985).
 Experience alters the spatial tuning of auditory units in the optic tectum during a sensitive period in the bam owl.
 The Journal of Neuroscience 5, 30943109.
 Knudsen, E.
I.
 (1987).
 Neural derivation of sound source location in the bam owl.
 An example of a computational map.
 The Annals of the N e w York Academy of Science 5, 30943109.
 Knudsen, E.
I.
 (1988).
 Early blindness results in a degraded auditory m ^ of space in the optic tectum of the bam owl.
 The Proceedings of the National Academy of Science 85, 62116214.
 Knudsen, E.
I.
 & Brainard, M.
S.
 (1991).
 Visual instmction of the neural map of auditory space in the developing optic tectum.
 Science 253, 8587.
 Knudsen, E.
I.
, du Lac, S.
 & Esteriy, S.
D.
 (1987).
 Computational m ^ s in the brain.
 Annual Review of Neuroscience 10,4165.
 Knudsen E.
I.
 & Knudsen RE.
 (1983).
 Spacem^ped auditory projections from the inferior colliculus to the optic tectum in the bam owl (Tyto Alba).
 The Journal of Comparative Neurology 21%, lSl\96.
 Knudsen, E.
I.
 & Knudsen P.
F.
 (1985a).
 Vision calibrates sound localization in developing bam owls.
 The Journal of Neuroscience 9(9), 33063313.
 Knudsen, E.
I.
 & Knudsen P.
F.
 (1985b).
 Vision guides the adjustment of auditory localization in young bam owls.
 Science 230, 545548.
 Knudsen, E.
I.
 & Knudsen PP.
 (1990).
 Sensitive and critical periods for visual calibration of sound localization by bam owls.
 The Journal of Neuroscience 10, 222232.
 Knudsen, E.
l.
 & Konishi, M.
 (1978).
 A neural map of auditory space in the owl.
 Science 200, 795797.
 Kohonen, T.
 (1981).
 Automatic formation of topological maps of pattems in a selforganizing system.
 In Proceedings of the 2nd Scandinavian Conference on Image Analysis (pp.
 214222).
 Espoo, Finland: Pattern Recognition Society of Finland.
 Kohonen, T.
 (1989).
 SelfOrganization and Associative Memory, chapter 5.
 Berlin; Heidelberg; N e w York: Springer.
 Kohonen, T.
 (1990).
 The selforganizing map.
 Proceedings of the IEEE 78,14641480.
 Payne, R.
S.
 (1971) Acoustic location of prey by bam owls (Tyto Alba).
 The Journal of Experimental Biology 54,535573.
 Pouget, A.
, Deffayet, C.
 & Sejnowski, T.
J.
 (1995).
 Reinforcement learning predicts the site of plasticity for auditory remapping in the bam owl.
 In Advances in Neural Information Processing Systems 7 San Mateo, CA: Morgan Kaufman Publishers.
 Rosen, D.
J.
, Rumelhart, D.
E.
 & Knudsen, E.
I.
 (1994).
 Aconnectionist model of the owl's sound localization system.
 Advances in Neural Information Processing Systems, 6.
 Sirosh, J.
 & Miikkulainen, R.
 (1994).
 Cooperative selforganization of afferent and lateral connections in cortical maps.
 Biological Cybernetics 71(1), 6678.
 158 M a n d a t o r y scale perception promotes flexible scene categorizations Aude Oliva Laboratoire de Traitement d'Images et Reconnaissance de Formes Institut National Polytechnique de Grenoble 46, Avenue Felix Viallet 38031 Grenoble, France oliva@tirf.
grenet.
fr Abstract Efficient categorizations of complex stimuli require effective encodings of their distinctive properties.
 In the object recognition literature, scene categorization is often pictured as the ultimate result of a progressive reconstruction of the input scene from precise local measurements such as boundary edges.
 However, even complex recognition tasks do not systematically require a complete reconstruction of the input from detailed measurements.
 It is well established that perception filters the input at multiple spatial scales, each of which could serve as a basis of stimulus encoding.
 When categorization operates in a space defined with multiple scales, the requirement of finding diagnostic information could change the scale of stimulus encoding.
 In Schyns and Oliva (1994), we showed that very fast categorizations encoded coarse information before fine information.
 This paper investigates the influence of categorization on stimulus encodings at different spatial scales.
 The first experiment tested whether the expectation of finding diagnostic information at a particular scale influenced the selection of this scale for preferred encoding of the input.
 The second experiment investigated whether the multiple scales of a scene were processed independently, or whether they cooperated (perceptually or categorically) in the recognition of the scene.
 Results suggest that even though scale perception is mandatory, the scale of stimulus encoding is flexibly adjusted to categorization requirements.
 Introduction Efficient categorizations of complex visual stimuli require effective encodings of their distinctive properties.
 In the object recognition literature, scene categorization is often pictured as the ultimate result of a progressive reconstruction of the input scene from simple measurements (e.
g.
, Marr, 1982).
 Boundary edges, surface markers and other lowlevel visual cues are progressively integrated into successive layers of representations of inaeasing complexity, the last of which derives the identity of a scene from the identity of a few objects.
 For example, in the central picture of Figure 1, combinations of finegrained edge descriptors and other local cues suggest the presence of cars, road panels, highway lamps and other objects which typically compose a highway scene.
 Precise categorization of a scene often requires that the local identification of component objects precedes the identification of the scene.
 Philippe G .
 S c h y n s Dept.
 of Psychology Montreal University C.
P.
 6128, Succursale A Montreal (Quebec) H3C3J7 schynsp@psy.
umontreal.
ca However, complex visual displays composed of many partially hidden objects are often recognized quickly, in a single glance~in fact, as fast as a single component object (Biederman, Mezzanotte, & Rabinowitz, 1982; Potter, 1976; Schyns & Oliva, 1994).
 This data suggests that there could be more direct routes to scene categorization than "objectbeforescene.
" Categorization processes could sometimes directly extract global representations of the input scene; representations allowing "express," but comparatively less precise classifications of the input.
 To illustrate the different routes of scene categorization, squint or blink while looking at the central picture of Figure 1, another scene should appear (if this demonstration does not work, step back from the picture until you perceive a city).
 Figure 1 simultaneously presents visual cognition with two scenes associated with a different spatial scale.
 Although it is possible to identify the background city scene from the spatial layout of its major "blobby" components, it is virtually impossible to identify each isolated blob as a building (a blob can potentially correspond to many objects).
 This example demonstrates that objectbeforescene is not a mandatory route to successful scene categorizations.
 Scenebeforeobject can also characterize the recognition of complex pictures.
 In any case, scalespecific information can be used independently to achieve distinct categorizations of the same hybrid stimulus.
 Recent studies on the relationships between categorization and perception have revealed that the highlevel task being accomplished influences the lowlevel encodings of the stimuli (e.
g.
, Goldstone, 1994; Schyns & Murphy, 1994).
 The availability of multiple levels of representation of the same scene coiJd promote selective encodings of the scene at the scale best suited for the task considered.
 For example, while precise categorizafions could reconstruct the input from local finegrained measurements (e.
g.
, boundary edges), express categorization processes could encode the same stimulus at a cruder resoluUon highlighting the global scene structure.
 In Schyns and Oliva (1994), w e reported such a coarsetofine encoding of hybrid stimuli.
 However, in agreement with the demonstration of Figure 1, control sfimuli also revealed that the two spatial scales were available at the onset of processing.
 Thus, the reported coarsetofine could result from task constraints rather than from a mandatory order of spatial scale perception.
 In this paper, w e report two experiments studying how categorization processes operate in the space of spatial scales made available by perception.
 The first experiment tested 159 mailto:oliva@tirf.
grenet.
frmailto:schynsp@psy.
umontreal.
ca( n  1 ) ( n ) ^ ^ ^ ^ ^ ^ ^ ^ ^  ^ ^ ^ ^ H ' ''M':^^Hi^| ^̂ Îr ">̂ ^̂ Î̂ ̂̂ e ^^^^^H^^^^I^^H ^̂ ^̂ ^̂ ^̂ ^̂ ê̂ ^̂ ^̂ î ^̂ l̂ ^ • H H m BW^^^el^^^^^^^^^^M • • IB^BI^K^^^K ^ ^ H ^̂ ^̂ ^̂ ^̂ ĥ' !̂ «̂: ̂^̂ Ĥ ^ H ^ ^ ^ ^ ^ K ^ "^Jmimhy^^^^B ^ ^ ^ ^ ^ ^ ^ H p ^^B;^^' r/'''̂/'' ^^^K'S ^ ^ 1 ^^H • V.
 • '̂i ( n  1 ) Figure 1: This (isyn Ulvstrsites tlie liybrid stimuli vsed mowexpetimenits.
 n1 and IL+1 art LF/Nois« hybids.
 nis uiamLi^uovs hybrid.
 Tht svjsctssicuL of these three hyhrids iUustrate the jist of the crossfrequeiwy primlny In ExpemnenJC 2.
 The H F component of n^vn^ys \ns of tne s&me aXi^ryts the lF componenjt of n+1.
 The triple shown illvitnaltes the peroeptiuJcondition.
 In the c«egotic«l condition (nol shown on this fi^we), the H F component of n was a different scene of the highway category.
 160 whether the expectation of finding diagnostic information at a particular scale influenced the selection of this scale for preferred encoding of the stimuli.
 The second experiment investigated whether the coarse and fine spatial components were processed independently, or whether they cooperated (perceptually or categorically) in the recognition of the input.
 Experiment 1 To demonstrate that categorization influences the scale of stimulus encoding, we ran a simple experiment in which subjects were asked to categorize 18 hybrid stimuli (see the n picture of Figure 1).
 Hybrids are inherently ambiguous and so w e should expect equivalent proportions of categorizations based on coarse and fine information.
 But if categorization processes expect diagnostic information to reside at only one scale, then input encoding could preferentially operate at this scale and influence the categorization of the hybrid.
 To induce such expectation through categorization, w e initially exposed two groups of subjects to hybrids that were meaningful at only one scale, before presenting the groups with the same set of ambiguous hybrids.
 The LowFrequency (LF) (vs.
 HighFrequency, HF) group was initially sensitized to 6 hybrids whose H F (vs.
 LF) component was structured noise.
 W e expected that these stimuli would sensitize categorization to the scale components containing diagnostic information.
 Without subjects being aware, the two scale components of the last 12 hybrids were both diagnostic.
 W e expected mutually exclusive categorizations of these stimuli, without subjects being aware of the other meaningful scene.
 This result would provide evidence that the highlevel constraint of finding diagnostic information for categorization induces scalespecific encodings, without an obligatory processing of one scale before the other.
 Methods Subjects.
 Twentyfour adult subjects with normal or corrected vision volunteered their time to participate to the experiment.
 They were randomly assigned to the L F (vs.
 HF) group with the constraint that the number of subjects be equal in each group.
 Stimuli.
 Three types of hybrid stimuli were constructed (LF/Noise, HF/Noise and ambiguous) from different pictures of four categories (city, highway, livingroom and bedroom).
 W e synthesized a total of 6 LF/Noise (vs.
 6 HF/Noise) sensitizafion sfimuli by combining the L F (vs.
 HF) components of two disfinct pictures of the categories with H F (vs.
 LF) structured noise (see the n  1 and the n t1 pictures of Figure 1).
 Test sfimuli were ambiguous hybrids, computed as explained earher by combining the L F and H F components of two different scenes.
 W e synthesized a total of 24 hybrids by systemafically combining 2 pictures of 4 distinct categories with the constraint that the two scenes of a hybrid were of a different category.
 Hybrids subtended 6.
4 x 3.
4 deg of visual angle on the monitor of an Apple Macintosh.
 (See Schyns & oliva, 1994, for a detailed description of the computation of hybrids).
 Subjects did not directly experience these hybrids.
 Instead, they saw one animafion per hybrid stimulus.
 Each hybrid (sensitization and test) was presented in a brief animation composed of three successive framesat a rate of 45 m s per frame, to ensure that they fuse on the refina.
 The first, second and third frames presented the hybrid with low and highfrequency Butterworth cutoff points set at 2 and 6, 3 and 5, 4 and 4 cycles/deg of visual angle, respectively.
 Although subjects saw brief animations, for ease of presentation, w e will refer to the animafions as hybrids in the remaining of the text.
 Procedure.
 Sensitization Phase.
 L F subjects were exposed to 6 LF/Noise, and the H F group saw 6 HF/Noise.
 In a trial, subjects would see one hybrid for 135 m s on a C R T monitor.
 Order of trials were randomized with a 1.
5 sec interval between trials.
 Subjects' task was to categorize the hybrid.
 As there was only one meaningful scene in LF/Noise and HF/Noise stimuli, subjects could only succeed by attending to the diagnostic scale (LF or HF).
 Testing Phase.
 Testing stimuli were presented immediately after the sensitization stimuli, without disconfinuity in their presentafion.
 There are two ways to synthesize a hybrid from two scenes, depending on which picture is assigned to the L F (or H F ) component.
 Half of the subjects of each group saw one version of each hybrid, and the other half saw the other version.
 For example the first half saw L F cityl/HF highwayl (block A ) and the other half saw L F highwayl/HF cityl (block B).
 There were 12 hybrids in each block.
 This strategy ensures a balanced design, without repefifion of trials.
 Note that the pictures used for sensifizafion were not used for tesfing.
 The 12 hybrids of the testing phase were each presented as explained above, and the entire experiment lasted for about 2 minutes.
 W e recorded the number of L F (vs.
) H F categorizafions of the 12 ambiguous hybrids in each condition.
 Debriefing.
 After the experiment, we asked subjects several questions about the experiment.
 One of these questions was particularly important for the interpretation of the results.
 Subjects were shown a hybrid stimulus composed of two meaningful scenes and were asked the following question: "Here is a stimulus composed of two scenes.
 Did you explicitly notice, or did you have the impression that there were such stimuli during the experiment?" Results and Discussion To ensure that \he blocks of test hybrids did not influence performance, w e first ran an A N O V A taking the LF vs.
 HFgroup, block A vs.
 B and L F vs.
 H F categorizations as factors.
 As neither the block factor nor the interactions with L F vs.
 H F categorizations were significant, we collapsed the two blocks in each group.
 Subjects sensitized to the L F scale categorized 7 3 % of ambiguous hybrids according to their L F component, while H F subjects categorized 7 2 % of the same stimuli on die basis of their H F information.
 A two way A N O V A revealed a significant interaction between sensitization (LF vs.
 H F ) and categorizations (LF vs.
 H F ) , F(l, 22) = 43.
69, p<.
0001.
 The data reveal mutually exclusive categorizations of identical stimuli.
 There are at least two possible accounts of 161 the opposite categorizations.
 Subjects could notice that there were two meaningful scenes in the 12 hybrids, but strategically decide to report only the scale information congruent with their sensitization phase.
 Another, perhaps more interesting interpretation would propose that the sensitization phase influenced the way stimuli were encoded for categorization.
 That is, although lowlevel perception would register both spatial scales, stimulus encoding and categorization processes would only operate at the scale imposed by the initial categorization constraints.
 In the debriefing phase, one of the questions specifically asked subjects whether they noticed that two meaningful scenes composed a large number of the stimuli.
 All subjects (but one) reported seeing only one scene that was perceived as a noisy picture—as if the scene was observed through a dirty window.
 Subjects were surprised to learn that twothird of the hybrids were composed of two scenes.
 Together, these results suggest that the selection of a spatial scale for categorization can be determined by the information content of that scale.
 It is doubtful that categorizations could be maintained at a single scale (when both scales were meaningful) if the selection of spatial scales for higherlevel processing was mandatorily fixed by lowlevel processes.
 If the groups reliably categorized the same stimuli as different scenes, it seems likely that their stimulus encoding and categorization processes were driven by the constraint of finding diagnostic information.
 Experiment 2 Experiment 1 provided evidence that highlevel processes can actively "select" the spatial scale of stimulus encoding, and that subjects were not aware of the information at the other scale.
 Awareness, however, should not be equated with processing.
 Subjects could very well be unaware of the other scale, but implicit processing at this scale could influence explicit processing at the relevant scale.
 This influence could simply be perceptual, revealing a cooperation of the spatial scales in the lowlevel analysis of the input, or the influence could be categorical, suggesting that the two spatial scales of a hybrid could simultaneously activate highlevel representations.
 Experiment 2 was designed to address the issue of perceptual or categorical influences across spatial resolutions.
 Three groups of subjects were asked to categorize a series of hybrids.
 Most hybrids of the series were LF/Noise, so we expected categorization to operate mostly at this scale, as shown in Experiment 1.
 Once every 4 LF/Noise, on trial n, we introduced an ambiguous hybrid whose HF component was the same scene as the LF component of the next hybrid (see Figure 1).
 W e hypothesized that although explicit categorizations were accomplished only at the LF scale, an implicit processing of HF information could influence explicit categorizations.
 In the perceptual group, the prime and the target were different scale representations of exactly the same scene.
 In the categorical group, the prime and the target were different scale representations of distinct pictures of the same scene category (e.
g.
, two different highways).
 In the control group, all n stimuli were replaced by LF/Noise sfimuli.
 If all spatial resolutions are mandatorily perceived, we should only observe a posifive priming in the perceptual condition.
 If all spatial resolutions are perceived and encoded for categorization, priming should occur in two experimental conditions.
 Methods Subjects.
 Subjects were 44 Grenoble University students who were paid to participate to the experiment.
 Only 36 subjects (12 per group) we used for the analysis (see below).
 Stimuli.
 Hybrids were the 24 ambiguous stimuli of Experiment 1 and sensitization stimuli were the 8 LF/Noise of 8 scenes (2 pictures of 4 categories).
 As in Experiment 1, threeframe animations of the hybrids were presented (at a rate of 45 ms per frame).
 Procedure.
 In an initial sensitization phase, subjects categorized two times the 8 LF/Noise, to ensure that they would categorize the scenes consistently fast.
 In contrast to Experiment 1, LF/Noise were interleaved with ambiguous hybrids throughout this experiment, as explained below.
 The priming situafion used triples of hybrid stimuli (see Figure 1).
 Hybrid n 1 and n had identical LF components.
 This procedure was meant to prime a LF categorization of n (to reduce chances of HF categorizations).
 Hybrid n was ambiguous for the perceptual and the categorical groups.
 In the perceptual group (illustrated on Figure 1), the HF component of n and the LF component of n + 1 were different scale representations of the same scene.
 In the categorical group, these two components were different scenes of the same category.
 This situation allowed the tesfing of a crossresolution priming (perceptual and categorical) of the HF of n on the LF of n t 1.
 In the control group, there was no correspondence across resolutions between n and n i 1 (i.
e.
, n was a LF/Noise).
 Each of the 24 hybrids served as n stimulus in composing 24 triples, using the appropriate n 1 and n + 1 hybrids.
 Triples describe the organizafion of Related (R) trials.
 Triples were separated from one another with one LF/Noise stimulus.
 These 24 separators were used as fillers to keep categorizafion at the LF scale.
 The n 1 stimulus of a triple served to compute UnRelated (UR) trials.
 UR trials were always preceded by a LF/Noise stimulusi.
e.
, there was no scene correspondence across resolutions.
 The entire experiment was composed of a total of 96 trials (24 triples plus 24 LF/Noise).
 Note that the only difference across group is the nature of the HF component of a n hybrid.
 Subjects' task was to categorize stimuli (by naming them) as fast and as accurately as they possibly could.
 W e recorded subjects' reaction dmes with a Lafayette vocalkey and also measured their categorization performances.
 Debriefing.
 After the experiment, we asked subjects the same questions about the overall appearance of the stimuli as in Experiment 1.
 Results and Discussion As there were repetitions of trials in this experiment, the proporfion of subjects who noficed two scenes in some hybrids grew accordingly (4 in 16 in the perceptual group and the same proportion in the categorical group).
 Their data were discarded from the analysis.
 In the remaining data, we also removed the triples in which the n stimulus was 162 categorized as HF, to ensure that priming was only measured after an explicit LF categorization of the ambiguous hybrid.
 On average, 2 triples (out of 24) were removed per subject.
 9 1 % of LF categorizations of the ambiguous hybrids indicate that categorization was reliably kept at only one spatial scale.
 Crossresolution priming rates were high (28 ms) between R and U R trials in the perceptual group, but nonexistent in the categorical and control groups (0 and 1 ms, respectively).
 An A N O V A with groups (perceptual, categorical and control) and types of trials (R vs.
 U R ) revealed a significant interaction F(2, 33) = 3.
77, p < .
05.
 A posthoc test between R and U R trials of the perceptual group showed a significant effect of priming, F(l, 33) = 11.
52, p < .
01, but no such effect was observed for the control and the categorical groups.
 The results provide further evidence that diagnostic information can bias explicit categorizations to the informative scale.
 But they also demonstrate that the uncategorized information is not lost.
 Instead, this information is implicitly registered and influences explicit categorizations, across resolutions.
 This influence only occurs when the prime and target are identical scenes represented at different scales.
 When the two spatial scales represented different exemplars of the same category, no priming was observed.
 Together, these results suggest a mandatory processing of the complete scale space, even when diagnostic information is consistently associated with only one spatial scale.
 The constraint of finding relevant categorizafion information influences which spatial component is preferenfially encoded and categorized.
 Implicit processing does not seem to go beyond the perceptual registration of the different scale components.
 General Discussion The aim of this paper was to investigate how the highlevel constraint of categorizing complex scenes interacts with the materials made available by lowlevel scale perception.
 Results of Experiment 1 demonstrated that the scale for preferred processing was determined by the diagnostic information present at this scale.
 The second experiment showed that even when explicit categorizations were accomplished at the diagnostic scale, they were perceptually (but not categorically) influenced by implicit processing at the other scale.
 Together, these results indicate that scale processing mandatorily occurs at all spatial scales.
 The constraint of finding diagnostic information determines which aspect of the stimulus is encoded for categorization.
 It is interesting to note that categorizations can be kept at a single level of resolution, even when diagnostic information is present at the other spatial scale.
 If object and scene recognition systematically resulted from a reconstruction of detailed and highly processed measurements of the input, one should expect a bias in favor of the H F categorization of a hybrid.
 The same bias should be observed if categorization was initiated after a lowlevel coarsetofine analysis of the scenebecause categorization would preferenfially operate on the detailed informafion.
 The fact that no a priori bias is observed for one particular scale when both scales are registered suggests a flexible usage of a mandatorily processed scale space.
 In summary, our experiments suggest that scale perception constrains categorization to operate in a scale space, but a space sufficiently diversified to promote flexible (in the case of our experiments mutually exclusive) categorizations of the same input stimulus.
 Our experiments indicate that informafion, rather than lowerlevel processes, determines which aspect of the stimulus is encoded for categorization.
 W e believe there is much to learn about the ways task constraints and percepnon parficipate to the encoding of complex visual sfimuli for categorization.
 References Biederman, I.
, Mezzanotte, R.
 J.
, & Rabinowitz, J.
 C.
 (1982).
 Scene perception: Detecfing and judging objects undergoing relafional violafions.
 Cognitive Psychology, 14, 143177.
 Goldstone, R.
 L.
 (1994).
 Influences of categorizafion on perceptual discrimination.
 Journal of Experimental Psychology: General, 123, 178200.
 Marr, D.
 (1982).
 Vision.
 San Francisco: Freeman.
 Potter, M .
 (1976).
 Shortterm conceptual memory for pictures.
 Journal of Experimental Psychology: Human Learning and Memory, 2, 509522.
 Schyns, P.
G.
, & Oliva, A.
 (1994).
 From blobs to boundary edges: Evidence for time and spafial scale dependent scene recognition.
 Psychological Science, 5, 195200.
 Schyns, P.
 G.
, & Murphy, G.
 L.
 (1994).
 The ontogeny of part representation in object concepts.
 In Medin (Ed.
).
 The Psychology of Learning and Motivation, 31, 305354.
 Academic Press: San Diego, CA.
 163 Ecological Robotics: Controlling Behavior with Optical Flow Andrew P.
 Duchon Department of Cognitive and Linguistic Sciences Brown University Providence, RI 02912 duchon@cog.
brown.
edu William H.
 W a r r e n Department of Cognitive and Linguistic Sciences Brown University Providence, RI 02912 Bill WarrenSBrown.
edu Leslie Pack Kaelbling Department of Computer Science Brown University Providence, RI 02912 lpk@cs.
brown.
edu Abstract There are striking parallels between ecological psychology and new trends in robotics and computer vision, particularly regarding how agents interact with the environment.
 W e present some ideas from ecological psychology, including control laws using optical flow, affordances and action modes, and describe our implementation of these concepts in a small mobile robot which can avoid obstacles and play tag solely using optical flow.
 This work ties in with those of others arguing for a methodological approach in robotics which foregoes a central model/planner.
 Ecological psychology may not only contribute to robotics, but robotic implementations in turn provide a test bed for ecological principles and sources of ideas which could be tested in animals and humans.
 I n t r o d u c t i o n Classical symbolic systems have proven to be powerful in modeling some aspects of human cognition.
 However, the things humans do easily (e.
g.
, recognizing patterns, moving around in the world, speaking) are difficult to explain and mimic with a symbolic approach.
 (We take the symbolic approach to mean symbolic/syntactic processing only, despite arguments for its allinclusiveness (Vera & Simon, 1993).
) Within both the cognitive science and AI communities an increasing dissatisfaction with this approach has led to the emergence of alternative approaches.
 In cognitive science, ecological psychology and especially connectionism are influential, and in the fields of robotics and computer vision, nonsymbolic and situated architectures are having a strong impact.
 In this paper w e explore the similarities between ecological psychology and these new trends in robotics and computer vision.
 For its own reasons, ecological psychology has avoided explanations of perception and action which require a central model/planner and has promoted tighter binding between perception and action through the concepts of control laws, affordances, and action modes.
 W e present these ideas and relate some of our work implementing them in a small mobile robot.
 BehaviorBased Robotics and Active V i s i o n In the past few years, a new approach has developed in robotics called behaviorbased robotics (Brooks, 1991a).
 Although earlier work on mobile robots had some successes, e.
g.
, SRI's Shakey (Nilsson, 1984) and Moravec's (1981) C A R T , they were generally of the "sensemodelplanact" variety, requiring intense computation for inferring the location and identity of objects, updating a central world model, and planning a course of action to achieve some defined goal state.
 In contrast, the new approach (Brooks, 1991b) attempts to build up robots through networks of simple, fully functional behaviors mapping sensors to actuators, with no central model.
 Complex behavior emerges from the dynamic interaction between the agent with its simple mappings and the environment, producing what appears to be goaldirected action.
 Most of the work in robotics uses sensors other than vision.
 Sonar, infrared detectors, laserlight stripers, and deadreckoning provide metric distance information and traditionally, the robot uses this information to place itself at a particular point in its world model and to plan a metric path through the environment.
 The typical role of vision in these robots is to create or augment the model.
 Using visual information as simply another way to obtain metric values allows one to treat computer vision as a separate task, one of scene analysis: creating a description of the threedimensional world from twodimensional images.
 The numerous means of constructing such models (e.
g.
, shape from shading, structure from motion), as they are presently formulated, are often illposed problems requiring assumptions and noise models which do not generalize to realworld vision (Aloimonos & Rosenfeld, 1991).
 However, with active control of the visual system {active vision) these problems become wellposed, usually with unique solutions and a few reasonable assumptions (Aloimonos & Rosenfeld, 1991; Ballard, 1991).
 Purposive or animate vision (Aloimonos, 1993; Ballard & Brown, 1992) goes one step further than finding better solutions to the old problems; rather it poses the question, "What is vision for?" (Ballard, 1991).
 If vision is used to achieve the goals of the organism, where a goal need not be a discrete state of the world, the system may not need to model the world at all before acting upon it.
 Ecological Psychology and Robotics Many of the papers in animate vision and robotics have made passing reference to the works of J.
J.
 Gibson, but we would like to probe further into the relevance of his ideas (see Pickering (1992) for other points).
 Ecological psychology, as developed by Gibson (e.
g.
, 1955, 1966, 1979), 164 mailto:duchon@cog.
brown.
edumailto:lpk@cs.
brown.
eduviews animals and their environments as "inseparable pairs" that should be described at a scale relevant to the animal's behavior.
 So, for example, animals perceive the layout of surfaces, not the coordinates of points in space.
 A main tenet of the ecological approach is that the optic array, Ihe pattern of light reflected from these surfaces, provides adequate information for controlling behavior without further inferential processing or mode! construction.
 This view is called direct perception: the animal has direct knowledge of, and a relationship to, its environment as a result of natural laws.
 H o w far into cognition perception plays a role is an open question, but minimally, the information involved in both perception and action could ground other, nonperceptual tasks.
 The strategy is to push natural law as far as possible into cognition, thus placing more constraints on the cognitive system.
 The Gibsonian approach can be summarized in the idea that it is more desirable to put the animal in its environment than to put the environment in the animal.
 Rather than internally representing detailed knowledge of the world, animals detect and use information about it as it is required.
 This is the "fundamental hypothesis" of the ecological approach to vision: Optical structure specifies its environmental source and .
.
.
 therefore, mobile organisms with active visual systems that can pick up this information will see their environments and suitably adjust their activity, if and when they detect that information, and only then (Turvey et al.
, 1981, p.
 243, emphases ours).
 Now, if we replace "mobile organisms" with "mobile robots," or more generally, "agents," this hypothesis is just as applicable to behaviorbased robots as it is to animals.
 That is, sufficient information is available in the robotenvironment interaction to control the robot's behavior without further inference or reconstruction.
 In addition, appropriate perceptionaction dynamics in the robot provide a noninferential source of information upon which other aspects of computation (planning, mapping, reasoning, etc.
) can be based and by which they can be limited.
 Similar hypotheses might be made in regards to the other senses or sensors, but it is primarily vision that seems the most promising for unifying the fields of robotics and ecological psychology.
 Both would gain from such a union.
 The latter can provide insights into what kinds of information can control the actions of agents, that is, what ecological laws are at work for a given task; and the former can provide an experimental and demonstrative setting in which to test the viability of proposed control strategies and facilitate the discovery of new ones.
 The new robotics and the ecological approach complement each other well and both ultimately have the same concerns; thus, mobile robotics provides a promising test bed for ecological principles.
 Optical Flow and Control Laws A relevant case is the study of optical flow.
 As an observation point moves through the environment, the pattern of light reflected to that point changes continuously, creating optical flow (Lee, 1980; Gibson, 1958).
 Optical flow contains information about both the layout of surfaces and the motion of the point of observation.
 For example, if an observer is translating, the/oca^ of expansion (FOE), or center of the radial flow pattern, specifies the observer's heading.
 If the observer is moving at a constant velocity, then the timetocontact with a surface is given by the relative rate of expansion t = r/v, where x is the "optic variable" toMglobal (Tresilian, 1991; Lee, 1976), r is the visual angle between a point on the surface and the F O E , and v is the rate of change in this angle.
 The observer's heading and timetocontact are just two examples of information available in optical flow.
 One way an agent can use this information is by acting to achieve a certain type of flow.
 For example, to maintain ambient orientation, the type of optical flow required is no flow at all.
 If some flow is detected, then the agent should change the forces produced by its effectors (e.
g.
, wings or legs) so as to minimize this flow, according to a L a w of Control: AFinternal = f(Aflow) (1).
 That is, the change in the agent's internal forces (as opposed to external forces like wind) are a function of the changes in the optical flow (here, from no flow to some flow).
 Gibson (1958) described various control laws an animal might use for locomotion: .
.
.
to begin locomotion, therefore, is to contract the muscles so as to make the forward optic array flow outward.
 To stop locomotion is to make the flow cease.
.
.
.
 To aim locomotion at an object is to keep the center of flow of the optic array as close as possible to the form which the object projects (1958, p.
 187).
 These types of rules have been noted by scientists studying the control of balance, steering, and braking in humans (Lee, 1976; Lee & Lishman, 1977; Yilmaz & Warren, in press; Warren, et al.
, in press) and the control of flight in flies (e.
g.
, Collet & Land, 1975; Reichardt & Foggio, 1976; Wagner, 1986ab).
 Ambient orientation, or hovering, is controlled by minimizing the global optical flow: purely vertical flow (say, upward) will induce increased lift by the fly to minimize that flow (Srinivasan, 1977; Gotz, et al.
, 1979).
 Similarly, a fly in a rotating drum will produce a differential thrust with the two wings, tracking the drum by rotating about its own vertical axis (Collett, 1980ab).
 Warren (1988) proposed a set of control laws a fly might use for each of its major activities.
 For example, the laws of control for hovering in the face of vertical and horizontal flow, respectively, could be A U = {k/c)Ay A(FlFr) = (A:/c)Aw (2) (3).
 where U is the amount of upthrust given by the two wings, (k/c) is the ratio of the drag constant to an optical scaling coefficient, y is the vertical component of the optical flow, F is the forward thrust given by a wing, and w is the horizontal component of the optical flow.
 Which control laws govern the fly's behavior at any one time depend upon the goal, or "global action mode" of the fly (Warren, 1988): cruising, landing, foraging, pursuing 165 conspecifics, etc.
 For each of these global action modes, objects in the environment will "afford" certain actions.
 Strictly speaking, the "affordances" of surfaces in the environment are constant for a particular animal (Gibson, 1979), but the global action mode determines which ones the fly uses.
 For example, while foraging, a fly will use a flower's affordance of nourishment and support, while avoiding all other surfaces.
 However, when tired, the fly might avoid flowers, but use the affordance of a resting place which large stationary objects will have.
 Once an action mode is adopted, the laws of control direct the actual output of the flyEcological Robotics We discuss below some work demonstrating that the control laws outlined in the previous section can be used successfully to control a mobile robot.
 W e call this practice ecological robotics.
 It should be noted though that any mobile agent (be it biological or artificial) with a device to register the optical flow can use control laws like these to achieve its goals, with only the adjustment of some constants.
 Thus the study of optical flow for the control of action provides a domain in which experiments in two separate fields, ecological psychology and mobile robotics, can have direct relevance to each other.
 Obstacle Avoidance Our first work (Duchon & Warren, 1994) looked into control laws for the most crucial ability of a mobile agent: avoiding obstacles.
 The robot had a 12inch base and a single camera with a 60°  field of view placed about 75 cm off the ground.
 A fast patchmatching optical flow algorithm (Camus, 1994) provided a dense, robust flow field at 4 frames per second, allowing us to control the robot moving at a speed of 4 cm/s.
 Because we tested the robot in a tightly constrained office environment with poor lighting, we equipped the robot with a couple of "emergency" reflexes which would stop and turn the robot 90°  when it got too dark (i.
e.
, when no flow could be seen) and when a crash was immanent (x<l sec).
 W e investigated the performance of two control laws in this environment.
 In the Balance Strategy, the agent moves so as to equate the average magnitude of optical flow seen on each side of the F O E (as some bees do [Srinivasan, 1992]).
 In the AvoidClosest Strategy the agent turns away from the point in the visual field with lowest x.
 W e generally found the Balance Strategy to be more stable since it takes the entire field of view into account when determining the amount of rotation, whereas the AvoidClosest Strategy is based only on a local region.
 For example, to go through an aperture, the Balance Strategy allowed the robot to head straight down the middle (where the flow would be equal on the two sides), whereas the AvoidClosest Strategy required the robot to sequentially avoid one side or the other of the aperture until the sides were no longer in the field of view.
 However, both of the control strategies allowed the robot to wander and avoid obstacles successfully as illustrated in Figure 1.
 Dark regions under the tables and textureless chair backs caused problems for the robot, but its ability to avoid hands placed suddenly in its path demonstrates the utility of these control laws.
 K E Y V starting position and orientation of the robot n small chair large chair with arms table = 10 feet trash can hand, temporary emergency tau stop emergency dark stop end point of run n n B 1 1 1 i|i 1 u • 1 1 i "i I u Figure 1.
 Obstacle Avoidance.
 A: Balance Strategy.
 The robot successfully avoids the hands placed in its path.
 The trial is stopped due to floor debris after 500 frames.
 B: AvoidClosest Strategy.
 The robot is positioned just in front of a chair and the tau reflex makes it stop and turn 90°  to the right.
 It avoids the hands and just misses a chair arm before running into a dark area.
 It has a problem again with the darkness under the tables, but the reflexes eventually point the robot in a favorable direction and it heads down the middle of the room towards the farthest comer.
 The trial is stopped due to cable lengths after 1000 frames.
 166 At least two other groups have independently implemented similar ideas.
 Sandini et al.
 (1993) built a robot which would balance the flow seen from two cameras facing laterally.
 Coombs et al.
 (in press) have recently designed a robot with two cameras facing forward, one with a wide angle lens (115° ) and one more foveal (40° ), both of which are controlled with active gaze stabilization.
 Whereas they balance the maximal normals of the optical flow in the left and right peripheral fields, w e take an average of the entire left and right fields relative to the F O E .
 Thus, the Balance Strategy used here can avoid a headon collision with a welltextured wall from only 40 c m away (no such surfaces were present in the trials of Figure 1), because noise in the system breaks the symmetry and once a small difference in the flows is acted upon the difference becomes greater until the robot has completely avoided the wall.
 Also, no gaze stabilization is required since during a fast rotation, the amount of flow should be equal on the two sides, specifying no rotation, so optical flow due to the agent's o w n rotation is cancelled.
 Other robotic implementations based on the insect literature (e.
g.
.
 Cliff (1992), Franceschini et al, (1992), and Sobey (1994)) have all used metric distance calculations and a mapping function for planning a (local) path or for tracking (cf.
 below).
 This information is totally absent here.
 Aloimonos (1992) and Nelson & Aloimonos (1989) took a similar approach to ours but required an additional intermediate representation of a "hazard m a p " based on normal flow to find the heading of the safest path.
 The Game of Tag Wandering around and not hitting things may help an agent avoid getting hurt, but survival requires more goaldirected behavior such as that exhibited in predatorprey interactions.
 A lion attacking a herd of zebras will chase the closest or slowest animal in the herd, and then use its claws to bring down the prey.
 The prey, for its part, must recognize that it is being attacked and make sure that the predator comes no closer.
 In humans, the children's game of tag is a (usually) gentler form of this interplay.
 Our implementation of tag is slightly different from the typical game.
 W e consider tag to be a global action mode, like foraging, and the aspects of tag like chasing and escaping to be subordinate action modes.
 Instead of the concept of It, there is only an agent and a target.
 While in the watching mode, the agent does not move until a moving target appears in its field of view.
 It then fixates the target by centering it in the field of view and tracks it throughout the trial.
 In our simplest implementation, no segmentation of the target is done.
 Instead, the conUol law for fixating is simply to turn to the right (increase force on the left) if more flow is seen on the right: ( F l  F r ) = A:(|wr||wl|) (4).
 While watching, this means that the robot will turn towards the side where the target appears and will continue to do so until the amount of flow is equal on the two sides of the field of view, i.
e.
, it has fixated the target.
 This control law will be functional as long the target is the sole or fastest moving object (e.
g.
, a rabbit in a field), the target is the closest object, all the moving objects are potential targets (e.
g.
, a school of fish), or the motion signals are subsequently filtered (see Prokopowicz et al.
 (1994) for further discussion of h o w and when to use various kinds of information for tracking—though w e would argue that motion signals can still be used when the agent is moving).
 y \ <  m watching hadowing ri > m escaping caught! Fl+Fr0 or no change in for some time docking ^ 2 docked! escaped! Figure 2.
 The action modes for tag and the transitions between them.
 Fixating takes place continuously throughout the game.
 A miss! was recorded if the target fell outside the robot's field of view.
 The transition conditions and control laws for each mode are described in the text.
 If the target withdraws from the agent (i.
e.
, the optical flow has an focus of contraction, detectable by \lx = r\ < me, where m e is a "margin value") then the agent chases it.
 If the target approaches the agent (i.
e.
, r| > m e ) then the agent enters the escape mode, backing up until it is caught or successfully escapes.
 Chasing is defined as having two parts: a) the shadowing mode in which the agent matches the speed of the target; and b) the docking m o d e in which the agent makes a controlled approach (rather than a hard attack) with the target.
 Shadowing is achieved by A(Fl + Fr) = M (5) i.
e.
, increasing force if the target is escaping and decreasing force if the agent is gaining on it.
 Escaping is essentially the same except that the agent needs to continue to increase the distance from the target at all times, which can be done by adding the term k\x to the righthand side of equation (5), where \i.
 is the minimum amount of acceleration from the target.
 The agent exits the escaping or shadowing modes if it has stopped accelerating.
 The second aspect of chasing, docking, is achieved by A ( F l + F r ) = A:(x + 0.
5) (6) where x is the derivative of T, and can be used to control deceleration prior to contact.
 If x is kept equal to 0.
5, the observer will just touch the target (Lee, 1976).
 Docking is complete when x is below a certain margin value, mc.
 167 which can also be used to register that it has been caught if it is escaping.
 Once the escape or dock is complete, the agent stops and the process begins again—the agent waits for a target to come into its field of view.
 Figure 2 gives a summary of these control laws.
 (Further discussion can be found in Warren (1988)).
 In the office environment of Figure 1, we videotaped a series of escapes and chases.
 The experimenter brought a 4x12 inch textured target into the robot's field of view and moved it away from (or towards) the robot at an appropriate rate and with a few changes in direction.
 Even without explicit segmentation of the target, the robot successfully chased down the target 7 0 % of the time, with some chases lasting 34 meters.
 Escaping was more difficult since the robot had to move backwards while facing the target and only 4 0 % of the escapes stopped soon after the target stopped approaching.
 W e also implemented these controls laws with segmentation based on a simple differenceofboxes operator acting on the horizontal dimension of the optical flow, but found that the percent of successful chases did not increase.
 This may have been due to the crude nature of the segmentation algorithm.
 Animals undoubtedly have more sophisticated means of segmentation which would include other properties of the target (e.
g.
, color, shape, size, and type of internal motion).
 Nevertheless, segmentation is hard and as was seen with the obstacle avoidance algorithm, reliance on precise segmentation can lead to less robust performance.
 Psychophysical experiments in our lab (Warren & Saunders, in press) indicate that humans do not segment the scene before determining their heading either.
 Further work is underway to investigate the extent to which 3D models of the environment are used by humans when navigating under circumstances similar to the robots here.
 Conclusion We have discussed behaviors like obstacle avoidance and the game of tag which can be produced in a robot with no reconstruction of the visual scene (Aloimonos, 1993).
 At a minimum, this work points to an approach eschewing a central model in favor of a tighter binding between action and perception.
 This methodology has been explored by a number of robotics researchers (e.
g.
, Aloimonos, 1992; Brooks, 1991b; Coombs, et al.
, 1995; Horswill, 1993; Pfeifer and Verschure, 1993; Sandini etai, 1993) and has even produced higherorder behaviors like planning (e.
g.
, Mataric, 1992; Meeden, 1994).
 The similarities between these approaches and ours based independently on Gibsonian ideas suggests that the application of the theories and results from fortyfive years of ecological psychology will surely enhance this endeavor.
 Our work also ties in with recent physiological studies and lesion cases (Milner & Goodale, 1993) that suggest separate "what" and "how" pathways in the brain.
 The lesion cases have indicated a difference between knowing what an object is, and knowing how to maneuver it.
 This change of emphasis is also reflected in some philosophical approaches to knowledge whereby to "know that" first requires one to "know how" (Bechtel, 1990; Ryle 1949).
 Our robot does not need to know what an object is in order to avoid it, nor identify a target before knowing how to control its escape.
 In essence, we have implemented a simple "how" pathway.
 But, since an approaching conspecific may afford mating as well as escape, it is important that all the affordances of an object be recognized and one of them acted upon.
 Neural networks would be an ideal means of satisfying the many soft constraints (affordances) of an object and choosing a single output (action mode) (see also Brooks' subsumption architecture [1991b] and Pfeifer & Verschure's distributed adaptive control [1993]).
 In any case, knowledge of the affordances of an environment provides a basis for a choice of action, and that action, once chosen, can be controlled without a central model of the world.
 Such procedural, functional knowledge seems necessarily prior to more abstract, declarative knowledge.
 Finally, the fact that these control laws are essentially universal for mobile agents with perceptual systems capable of detecting optical flow means that they can be investigated in insects, animals, humans and robots.
 W e are beginning an interactive approach with the last two kinds of agents.
 Robotic modeling helps us determine the plausibility of control laws that have been hypothesized for biological agents, and from psychophysical studies we hope to find new control laws useful in a robot.
 The study of control laws based on optical flow thus provides a unique opportunity for cognitive scientists, computer scientists and engineers to work together, solving the same problems.
 Acknowledgments Tom Dean kindly provided the robots and cameras.
 Ted Camus' work on realtime optical flow made this entire project possible.
 Jak Kirman, Moises Lejter, and Jon Monsarrat were very helpful in getting the robots and computers working.
 This work was supported by a National Science Foundation Graduate Research Fellowship to the first author.
 References Aloimonos, Y.
 (1992).
 Is visual reconstruction necessary? Obstacle avoidance without passive ranging.
 J.
 of Robotic Systems, 9(6),843858.
 Aloimonos, Y.
 (1993).
 Introduction: Active Vision Revisited, In Y.
 Aloimonos (ed.
).
 Active Perception, (pp.
 118).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Aloimonos, Y.
 & Rosenfeld, A.
 (1991).
 Computer Vision, Science, 253, 12491254.
 Ballard, D.
 (1991).
 Animate vision.
 Artificial Intelligence, 48, 5786.
 Ballard, D.
H.
 & Brown.
 C M .
 (1992).
 Principles of animate vision.
 CVGIP: Image Understanding, 56(1), 321.
 Bechtel, W .
 (1990).
 Multiple level of inquiry in cognitive science.
 Psychological Research, 52, 271281.
 Brooks, R.
A.
 (1991a) N e w approaches to robotics.
 Science, 253, 12271232.
 Brooks, R.
A.
 (1991b).
 Intelligence without representation.
 Artificial Intelligence, 47, 139160.
 Camus, T.
 (1994b).
 Realtime optical flow.
 Doctoral dissertation and technical report CS9436.
 Providence: 168 Brown University.
 Cliff, D.
 (1992).
 Neural networks for visual tracking in an artificial fly.
 In Proc.
 of the 1st European Conf.
 on Artificial Life (pp.
 7887).
 Cambridge, M A : MIT Press.
 Collett, T.
S.
 (1980a).
 Some operating rules for the optomotor system of a hoverfly during voluntary flight.
 / of Comparative Physiology, 138, 271282.
 Collett, T.
S.
 (1980b).
 Angular tracking and the optomotor response: An analysis of visual reflex interaction in a hoverfly.
 J.
 of Comparative Physiology, 140, 145158.
 Collet, T.
S.
 & Land, M.
F.
 (1975).
 Visual control of flight behavior in the hoverfly, Syritta pipiens L.
 J.
 of Comparative Physiology, 99, 1 66.
 Coombs, D.
, Herman, M.
, Hong, T.
, & Nashman, M.
 (in press).
 Realtime obstacle avoidance using central flow divergence and peripheral flow.
 In Proc.
 of the 5th Int.
 Conf.
 on Computer Vision.
 Duchon, A.
P & Warren, W.
H.
 (1994).
 Robot navigation from a Gibsonian Viewpoint.
 In IEEE Int'l Conf.
 on Systems, Man, and Cybernetics (pp.
 22722277).
 Piscataway, NJ: IEEE.
 Franceschini, N.
, Pichon, J.
M.
, and Blanes, C.
 (1992).
 From insect vision to robot vision.
 Phil.
 Trans.
 R.
 Soc.
ofLond.
 B, 337, 283294.
 Gibson, J.
J.
 (1950) The Perception of the Visual World.
 Boston: Houghton Mifflin.
 Gibson, J.
J.
 (1958).
 Visually controlled locomotion and visual orientation in animals.
 British J.
 of Psychology, 49(3), 182194.
 Gibson, J.
J.
 (1966).
 The senses considered as perceptual systems.
 Boston: Houghton Mifflin.
 Gibson, J.
J.
 (1979).
 The Ecological Approach to Visual Perception.
 Boston: Houghton Mifflin.
 Gotz, K.
G.
, Hengstenberg, B.
, & Biesinger, R.
 (1979).
 Optomotor control of wing beat and body posture in Drosophilia.
 Biological Cybernetics, 35, 101112.
 Horswill, I.
D.
 (1993).
 Specialization of perceptual processes.
 Doctoral Dissertation.
 Cambridge: MIT.
 Lee, D.
N.
 (1976).
 A theory of visual control of braking based on information about timetocollision.
 Perception, 5, 437459.
 Lee, D.
N.
 (1980).
 The optic flow field: The foundation of vision.
 Phil.
 Trans.
 R.
 Soc.
 of Land.
 B, 290, 169179.
 Lee, D.
N.
 & Lishman, R.
 (1977).
 Visual control of locomotion.
 Scandinavian J.
 of Psychology, 18, 224230.
 Mataric, M.
 (1992).
 Integration of representation into goaldriven behaviorbased robots.
 IEEE Trans, on Robotics and Automation, 8(3), 304312.
 Meeden, L.
A.
 (1994).
 Towards planning: Incremental investigations into adaptive robot control.
 Doctoral Dissertation.
 Bloomington: Indiana University.
 Milner, D.
A.
 & Goodale, M.
A.
 (1993).
 Visual pathways to perception and action.
 In Hicks, T.
P.
, Molotchnikoff, S.
 & Ono, T.
 (eds.
) Progress in Brain Research.
 Volume 95.
 (pp.
 317337).
 NorthHolland:Elsevier Science Publishers.
 Moravec, H.
P.
 (1981).
 Rover Visual Obstacle Avoidance.
 In Proc.
 of the 7th International Joint Conference on Artificial Intelligence (pp.
 785790).
 Nilsson, N.
J.
 (1984).
 Shakey the robot.
 SRI International Technical Note, No.
 325.
 Pfeifer, R.
 & Verschure, P.
 (1993).
 Designing efficiently navigating nongoaidirected robots.
 In Proc.
 of the 2nd Int'l Conf.
 on the Simulation of Adaptive Behavior (pp.
 3139).
 Cambridge, M A : M I T Press.
 Pickering, J.
 (1992).
 The new artificial intelligence and biological plausibility.
 In: Studies in Perception and Action II: Posters Presented at the Vlllth Int'l Conf on Event Perception and Action (pp.
 126129).
 Hillsdale, NJ: Lawrence Erlbaum.
 Prokopowicz, P.
N, Swain, M.
J.
, & Kahn, R.
E.
 (1994).
 Task and environmentsensitive tracking.
 In Proceedings of the lARP/IEEE Workshop on Visual Behaviors (pp.
 7378).
 Piscataway, NJ: IEEE.
 Reichardt, W .
 & Poggio, R.
 (1976).
 Visual control of orientation behavior in the fly.
 Quarterly Reviews of Biophysics, 9 (3), 311315.
 Ryle, G.
 (1949).
 The Concept of Mind.
 N e w York: Barnes and Noble.
 Sandini, G.
, SantosVictor, J.
 Curotto, F.
 & Garibaldi, S.
 (1993).
 Robotic Bees.
 In Proc.
 ofIROS93, Yokohama, Japan.
 Sobey, S.
 (1994).
 Active navigation with a monocular robot.
 Biological Cybernetics, 71, 433440.
 Srinivasan, M.
V.
 (1977).
 A visuallyevoked rollresponse in the housefly.
 J.
 of Comparative Physiology, 119,114.
 Srinivasan, M.
V.
 (1992).
 H o w bees exploit optic flow: Behavioural experiments and neural models.
 Phil.
 Trans.
 R.
 Soc.
 Lond B, 337, 253259.
 Tresilian, J.
R.
 (1991).
 Empirical and theoretical issues in the perception of time to contact.
 J.
 of Experimental Psychology: HPP, 17, 865876.
 Turvey, M.
 T.
, Shaw, R.
E.
, Reed, E.
S.
, & Mace, W .
 M .
 (1981).
 Ecological laws of perceiving and acting: In reply to Fodor and Pylyshyn (1981).
 Cognition, 9, 237304.
 Vera, A.
H.
 & Simon, H.
A.
 (1993).
 Situated Action: A symbolic interpretation.
 Cognitive Science, 17, 748.
 Wagner, H.
 (1986a).
 Flight performance and visual control of flight of the freeflying housefly (Musca Domestica L.
) II.
 Pursuit of targets.
 Phil.
 Trans.
 R.
 Soc.
 of Lon.
 B, 312,553579.
 Wagner, H.
 (1986b).
 Flight performance and visual control of flight of the freeflying housefly (.
Musca Domestica L.
) III.
 Interactions between angular movement induced by wide and smallfield stimuli.
 Phil.
 Trans.
 R.
 Soc.
 of Lon.
 5, 312, 581595.
 Warren, W.
H.
 (1988).
 Action modes and laws of control for the visual guidance of action.
 In Meijer, O.
G.
 & Roth, H, (eds.
) Complex Movement Behaviour: The motoraction controversy (pp.
 339380).
 NorthHolland: Elsevier Science Publishers.
 Warren, W.
H.
, Kay, B.
 & Yilmaz, E.
 (in press) Visual control of posture during walking: Functional specificity.
 J.
 of Experimental Psychology: HPP.
 Warren, W.
H.
 & Saunders, J.
 (in press) Perception of heading in the presence of moving objects.
 Perception.
 Yilmaz, E.
 & Warren, W.
H.
 (in press) Visual control of braking: A test of the taudot hypothesis.
 J.
 of Experimental Psychology: HPP.
 169 Developing Object Permanence: A Connectionist Model Denis Mareschal Experimental Psychology Oxford University South Parks Road Oxford OX 13UD deriis@psy.
 ox.
 ac .
 uk Abstract Kim Plunkett Experimental Psychology Oxford University South Parks Road Oxford OX 13UD plunkett@psy.
ox.
ac.
uk Paul Harris Experimental Psychology Oxford University South Parks Road Oxford OX 13UD harris@vax.
ox.
ac.
uk When tested on siuprise or preferential looking tasks, young infants show an understanding that objects continue to exist even though they are no longer directly perceivable.
 Only later do infants show a similar level of competence when tested on retrieval tasks.
 Hence, a developmental lag is apparent between infants' knowledge as measured by passive response tasks, and their ability to demonstrate that knowledge in an active retrieval task.
 W e jwesent a connectionist model which learns to track and initiate a motor response towards objects.
 The model exhibits a capacity to maintain a representation of the object even when it is no longer directly perceptible, and acquires implicit tracking competence before the ability to initiate a manual response to a hidden object.
 A study with infants confirms the model's prediction concerning improved tracking performance at higher object velocities.
 It is suggested that the developmental lag is a direct consequence of the need to coordinate representations which themselves emerge through learning.
 Introduction This paper presents a connectionist model of the development of object permanence on a task involving visual pursuit Object permanence is the understanding that objects continue to exist independently of direct perception.
 It is a central theme in the study of infant cognitive development.
 Piaget's (e.
g.
, 1952) n o w classic studies relied on the active search f w and manual retrieval of hidden objects to gauge the infant's understanding of object permanence.
 If a baby reached for a visible object but failed to reach for the object when an occluding screen was lowered in front of the object, Piaget concluded that the infant did not understand that the object continued to exist behind the occluding screen.
 It was not until 7.
5 to 9 months of age that infants succeed at this task.
 While Piaget's findings are highly replicable, a different experimental prxadigm suggests far more precocious abilities in infants.
 Studies using preferential looking or surprise as the dependent measures, instead of active manual search, suggest that infants as young as 3.
5 months understand that object' continue to exist when hidden (e.
g.
, Baillargeon, 1993; Spclke, 1994).
 These infants will respond differentially when some property (such as solidity) of a hidden object is violated as compared to when no violation occurs.
 Hence, a developmental lag is evident between infants' understanding of object permanence as measured by passive response tasks and their ability to demonstrate that knowledge in active retrieval tasks.
 The lag cannot simply be due to a motor control problem since infants can retrieve a visible object by 4 months (von Hofsten, 1989).
 Furthermore, preferential looking studies suggest that 5.
5 month olds are able to differentiate possible from impossible actions for retrieving a hidden object under some circumstances (Baillargeon, 1993).
 The origins of the developmental lag, and what it reflects about the underlying mental representations required for completing both tasks is a key question for current infant research.
 A number of hypotheses have been advanced to address this question.
 O n e suggestion is that the nature of the representations which underlie perception and action in these tasks are radically different (Spelke, Katz, Purcell, Ehrlich & Breinlinger, 1994) and that these develop at different rates.
 A related suggestion is that the underlying representations for the two tasks are the same, but that the perception and action knowledge domains are encapsulated: there is no transfer of learning from one domain to another (Spelke, 1994).
 According to this view, the developmental lag simply reflects that fact that infants begin practice with manual retrieval at a later age.
 Finally, a third suggestion is that the underlying representation of an object develops along a continuum such that the representation required to elicit a perceptual response is simply an early state of the representation required to elicit a retrieval response (Fischer & Bidell, 1991; Munakata, McClelland, Johnson, Siegler, 1994).
 W e propose that there are 2 distinct factors which conOibute to the pattern of results ouUined above.
 First, that hidden objects fail to elicit the same level of response in infants as visible objects is due to the need for stronger, more consolidated representations of objects in the former case than the latter.
 Hence, w e subscribe to the view that the underlying representation of an object develops along a continuum.
 Second, w e assume that the manual retrieval of an object typically involves an integrated response requiring the coordination of information about an object's identity and position.
 In contrast, the predictive visual pursuit of an object need not involve information about an object's identity, only its position (Day & B u m ham, 1981).
 Hence, w e subscribe to the view that the task 170 mailto:plunkett@psy.
ox.
ac.
ukmailto:harris@vax.
ox.
ac.
ukd e m a n d s imposed b y manual retrieval involve exploiting and coordinating distinct rep^sentational components while predictive visual pursuit need only refer to the representation of an object's position.
 W e explain the developmental lag between predictive pursuit of hidden objects and manual retrieval of hidden objects as a consequence of the differential task d e m a n d s for the t w o behaviours.
 M a n u a l retrieval requires the coordination of representations while predictive visual pursuit does not.
 W e suppose that the coordination of representations itself needs to be learnt.
 H e n c e tasks requiring the coordination of representations will be developmentally delayed in relation to tasks that d o not require this extra level of representational integration.
 Note that the manual retrieval of displaced hidden objects constitutes the most difficult case for the child from this perspective.
 N o t only must the child coordinate representations of the object's identity and position, but they do so in the absence of direct perceptual cues.
 In contrast, predictive visual pursuit of a visible object constitutes the easiest case for the c h i l d — n o coordination of distinct representations is required and direct perceptual input is available to support predictions about the object's trajectory.
 T h e predictive visual pursuit of hidden objects and the manual retrieval of visible objects constitute tasks of intermediate difficulty o n this perspective.
 In particular, the manual retrieval of visible objects should be easier than that of hidden objects because the latter require the representations that coordinate object position and identity to b e c o m e m o r e strongly established.
 This paper describes a working m o d e l of the development of object permanence in the d o m a i n of visible and occluded visual pursuit tasks (cf.
 Bremner, 1985 for a review).
 W e implement a computational m o d e l that learns to establish the identity of an object in terms of its distinguishable features, that learns to predict the future position of an object on the basis of its recent trajectory and that learns to initiate a m a n ual retrieval response based o n a composite representation of an object's position and identity.
 T h e m e c h a n i s m s brought to bear on the computation of the object's position and identity are quite separate.
 H o w e v e r , they are exposed to the s a m e input stimulus throughout training and thus have the s a m e opportunity to learn about the relevant characteristics of the environment.
 T h e architecture of the m o d e l is constrained in such a w a y that predicting the position of an object takes no account of the object's identity.
 In contrast, the inititation of a manual retrieval response requires a sensitivity to both position and identity.
 These architectural constraints are motivated by the findings cited above suggesting the independent representation of spatial and featural information by infants.
 O u r purpose in building the mode l is to explore the viability of the view that the relatively late emergence of the ability to retrieve displaced hidden objects is due to the c o m bined requirements to develop strong internal object representations and to coordinate those representations.
 T h e model is continuously tested o n its ability to predict the next position of visible and hidden objects (predictive visual pursuit) and on its potential to retrieve visible and hidden objects (manual retrieval).
 W e can, therefore, establish a developmental profile of the mastery of these skills in the model and c o m p a r e this profile to that observed in infants.
 Furthermore, w e can manipulate systematically various features of the m o d e l in order to determine their effect o n performance.
 T h e facility to manipulate characteristics of the model permits us to determine the essential properties that govern its performance and to generate novel behaviours that can be evaluated against the experimental literature or inspire n e w experiments with infants.
 The Model Figure 1 shows a schematic outline of the model.
 It con100 Outputs j ' j J? 100 Outputs p m I *'' vf0dkA\oti I Ei;:Ŝ ĝ!̂ Ex;:?xg: iResponse 75 Hiddens 00 Visual Memory Cells CompI Input Retina (4)(2S grid witi 4 lealue deledor units per grid cell) Figure 1: Schematic of modular network architecture.
 sists of a modular architecture.
 Each functional module is enclosed by a dashed line.
 N o t e that s o m e units are shared by t w o modules and serve as a gateway for information between the modules.
 In accordance with recent neurological evidence (Ungerlieder & Mishkin, 1982) spatiotemporal information about objects in the world is processed independently of featural information.
 Information enters the network through a 2dimensional retina h o m o g e n e ously covered by feature detectors.
 It is then funnelled d o w n one pathway which processes the temporal history of the object and another which develops a spatially invariant feature representation of the object (Foldiak, 1991).
 T h e retina consists of a 4 x 2 5 cell grid.
 E a c h cell contains four feature detectors responding to different properties (e.
g.
 Ught/dark, high/low contrast, hot/cold, soft/hard).
 If a projected object image overlaps with a grid cell, the cell's feature detectors take o n the value i1.
0 if the feature is present and 1.
0 if the feature is absent (Treisman & Sato, 1990).
 Cells o n which the object image is not projected are quiescent and take o n the value 0.
0.
 A n occluding screen is also projected o n the retina.
 T h e cells corresponding to those positions have a constant value of I.
O and d o not encode object features.
 171 The network experiences 4 different objects with correlated features (i.
e.
, {1 11 1),{1 1 11).
 111 11}.
 111 1 1)).
 All object images are 2x2 grid cells large.
 For each object presentation, an object moves once back and forth across the retina, either horizontally or vertically.
 Vertical movements can result in either nonoccluding or occluding events while all horizontal movements involve an occluding event.
 Note the ambiguity when predicting the next position of the object based on a snapshot of its current position.
 There are four possible next positions for the object: up, down, left, or right.
 This can only be resolved by learning to attend to the temporal history of the object.
 The object recognition module generates a spatially invariant representation of the object by using an unsupervised learning algorithm.
 That is, it learns to partition the world into consistent feature clusters (to respond similarly to similar objects) without expUcit teaching.
 The feature representation is encoded on a bank of 5 complex cells.
 These cells are initially randomly connected to all feature detectors.
 The module develops its representations by using a modified version of the algorithm developed by Foldiak (1991)^ This algorithm exploits the fact that an object tends to be temporally contiguous with itself.
 Thus two successive images will probably be derived from the same object.
 Learning results in an object (defined by a unique set of features) activating the same complex cell irrespective of its position on the retina.
 The trajectory prediction module uses a partially recurrent feedforward network trained with the backpropagation learning algorithm^.
 At each time step information about the visible position of the object image is extracted from the retina.
 The retinal grid cells with which the object image overlaps become active (+1.
0) while the other cells remain inactive (0.
0) (Recall that the ti"ajectory prediction module does not encode feature information about object identity.
) These 1(X) values are mapped onetoone onto 100 units in the visual memory layer.
 The network is trained to predict the next instantaneous position of the object.
 The result is output on a bank of 100 units coding position in the same way as the inputs into the module.
 The network has a target of+ 1.
0 for those units corresponding to the next object position and 0.
0 for all other units.
 All units in the visual memory layer have a selfrecurrent connection.
 This gives them the power to process temporal information and generate a representation of the object's spatiotemporal history^.
 The result is a spatial distribution of activation in the form of a comet with a tail that tapers off in 1.
 Setting the activations of the loosing units in the competitive phase to a small negative value (P ) greatly increases the stability of the representations under continued training.
 W e used the following parameter values: 5 = 0.
1 , P = 0.
02 , learning rate e = 0.
001 , and weight_range = 0.
2.
 2.
 All backpropagation networks used the following parameter values: learning rate E = 0.
1 and momentum Tj = 0.
3 .
 3.
 The recurrent connections were fixed at n = 0.
3 .
 the direction from which the object has come.
 The length and distinctiveness of this tail depend on the velocity of the object.
 The information in this layer is then forced through a bottleneck of 75 hidden units.
 It is here that the network has to generate a more compact, internal rerepresentation of the object's spatiotemporal history.
 As there are no direct connections from the input to the output, the network's ability to predict the next position is a direct measure of the reliability of its internal object representation.
 W e suggest that the responses of the trajectory prediction network correspond to the responses observed in infants through the use of (passive) preferential or surprise measures (e.
g.
, Baillargeon, 1993; Spelke, 1994).
 They are a test of the infant's sensitivity to violations of object position.
 The output of the response integration network corresponds to the infant's ability to coordinate and use the knowledge it has about object position and object identity.
 This network is designed to integrate the internal representations generated by other modules (i.
e.
 the feature representation at the complex cell level and spatiotemporal representation in the hidden unit layer) as and when required by a response task.
 It consists of a singlelayered backpropagation network whose task is to output the same next position as the prediction network for two of the objects, and to inhibit any response (all units set to 0.
0) for the other two objects.
 This reflects the fact that infants do not respond (e.
g.
 reach) for all objects.
 S o m e objects are desired (e.
g.
 sweet) whereas other are not desired (e.
g.
 sour).
 Active intentional response necessarily require the processing of featural as well as ti^ajectory information.
 Occluded Tracking The network learns very quickly to predict an object's next position when it is in sight.
 Moreover, the hidden unit representations that it develops j)ersist even when the object has disappeared and allows the network to keep Qack of the object even when it is no longer direcUy perceptible.
 Figure 2 shows a graphic representation of the network's ability to predict the next position of an occluded object.
 The lefthand column shows what is projected onto the retina once featural information has been removed.
 The righthand column shows the corresponding object position predicted by the trained trajectory network.
 The rows (from top to bottom) correspond to successive time steps.
 This network has seen 30,(XX) presentations of randomly selected objects moving back and forth in random positions and directions at a fixed speed.
 At / = 0, the object is about to disappear behind the occluding screen.
 At all subsequent time steps, the network correctly predicts that the object will have moved over one position.
 Note especially step 3 for which the direct perceptual information available to the network is exacUy the same as at / = 2 .
 The network is able to pre172 Retinal Input Prediction Figure 2: Network tracking of occluded object at 5 consecutive time intervals.
 Both the screen and the object are projected onto the retina.
 The network correctly predicts the next position of the object even when the object is not directly perceptible.
 diet the subsequent reappearance of the object taking account of how long it has been behind the screen.
 Moreover, as found with infants (MuUer & Aslin, 1978), the network's ability to track an occluded object depends on the length of the occluding screen: the longer the screen, the worse the performance.
 Developmental lag The model was designed to examine the developmental lag between an infant's implicit knowledge of object permanence (predictive visual pursuit) and its ability to demonstrate that knowledge with an appropriate response (manual retrieval).
 Figure 3a shows the network performance (averaged across 10 randomized replications) on both the manual retrieval and visual pursuit tasks when presented with an unoccluded desired object.
 The reliability of a module is computed as (1  sumofsquarederrors across outputs) averaged over the output units and patterns involved in the event.
 In this case, the network learns very quickly to track and to Unoccluded [>Mirad Objects Occluded Desired Objects 0 95 0 950 85 Prediction 0 85 0 85Pradiction Prediction ••»•••• Retrieval —ij Retrieval *•••• Retrieval identify the desired object and to produce an appropriate retrieval response.
 W h e n the object is occluded the network's behavior is very different (Figure 3b).
 Tracking and retrieval responses are initially equally poor.
 T h e internal representations are not adequately mature to support a ny reliable response.
 A t about 5 0 0 0 epochs they begin to diverge.
 T h e reliability of the predictive visual pursuit develops faster than that of the integrated m a n u a l retrieval response.
 A r o u n d 20,000 epochs there is a consistent difference between the network performance in the t w o different m o d e s .
 T h e accuracy differential o n the t w o tasks then disappears with further training.
 Note that the ma n u a l retrieval response w h i c h is required for a desired object has exacdy the s a m e m o d e of representation as that for predictive visual pursuit.
 M o r e o ver, both sets of output units receive exactly the s a m e information from the hidden units about the spatiotemporal history of the object.
 T h e only w a y the functioning of these t w o modules differs is that the m o d u l e that drives manual retrieval mus t integrate information c o m i n g from the object recognition module.
 This indicates that the developmental lag in the network arises from the added task d e m a n d s of integrating information.
 A n advantage of modeling is that w e can test this hypothesis directly thanks to a manipulation w h i c h w o u l d not be possible with infants.
 If the developmental lag is indeed d u e to the need for an integration of information, then it should disappear w h e n presented with a task that does not require information integration.
 O n e possibility is to observe the network's behavior w h e n presented with an undesired object.
 Undesired objects d o not require information integration because it suffices to attend only to the feature representation in order to elicit a proper response, i.
e, not to retrieve the object.
 O n c e the object has been identified as undesirable, then an inhibitory output can b e emitted which does not require any spatiotemporal information.
 Figure 3c show the network's performance when presented with an undesired object.
 It learns more quickly to inhibit attempts at retrieval than to track objects.
 The feature recognition module learns to categorize the different object types very quickly.
 Hence, it is the need to attend to and integrate information from different sources that produces the lag between reliable predictive visual pursuit and manual retrieval of occluded objects.
 Occluded Undesired Objects 1—•—1—>—r 10 15 20 Epoohs(IOOOs) (a) 10 15 20 25 Epochs (1000s) (b) 30 10 15 20 25 Epochs (1000b) (C) Figure 3: Network performance on predictive visual pursuit and manual retrieval to (a) an unoccluded desired object, (b) an occluded desired object, and (c) an occluded undesired object.
 A Test of the Model's Fit Figure 4a shows the reliability in tracking produced by the network as a function of the velocity of the object image (fast 173 Natworfc Reliability 0 950 9085 (a) 10000 15000 20000 25000 Epochs o( Training 30000 low velocity high velocity Total Intant looking tima Initial Infant looking lima Velocity Distance (C) Figtire 4: The effect of velocity on tracking in (a) the network and on the infants' (b) total tracking time and (c) initial tracking time.
 objects m o v e two grid cells per unit time whereas slow move one grid cell every two time steps).
 There is consistently better performance at the higher velocity.
 The greater accuracy arises from the more distinct representations generated in the visual memory layer at higher velocities.
 W e have found that infants also show superior tracking at higher velocities^.
 In the study, thirtysix 2 to 6monthold infants sat 0.
6m from a viewing theatre and watched an 8' black and white bull'seye move back and forth across the 1.
5 m theatre at either 8 or 12 '/see.
 Figure 4b shows the proportion of total tracking time to total visible time that infants spent tracking an object moving across a viewing theatre.
 Infants showed significantly more tracking in the high velocity condition than the low velocity condition (F(l, 33) = 7.
506, p = 0.
0098) supporting the predictions of the model.
 The total looking time can underestimate the power of a moving object to elicit tracking since subsequent captures and looking times can be artificially reduced due to infant habituation.
 Since habituation is not implemented in this model, initial infant tracking time may be a better test of the model.
 Figure 4c shows the proportion of looking time for the initial tracking interval with infants at 0.
6m and 1.
2m from the target.
 The velocities at the far distance were 6 Vsec and 8 Vsec.
 The velocities at the near distance are 8 and 12 7 sec.
 These correspond to a constant linear velocity difference of 4.
2 cm/s at both distances.
 The object was scaled to sub4.
 The results reported here are part of those obtained during a study designed to test some predictions of the model and to investigate the role of egocentric and aJlocentric cues in infants' visual pursuit.
 A full report is in preparation.
 lend 8' at either distance.
 At both distances there is a significantly longer initial track at higher velocities (F(l, 33)=6.
577.
 p<0.
0151) with no significant effect of distance (F(l, 33)=0.
291.
 p<0.
5933) or distance by velocity interaction (F(l, 33)=2.
548.
 p<0.
12).
 Again, the main effect of velocity supports the model's predictions.
 Discussion This model suggests that connectionist style learning algorithms are powerful enough to develop perceptually independent representations of objects.
 These representations allow the network to keep track of an object's properties such as position, velocity, and feature descriptions even when the object is fully occluded.
 Moreover, there is a gradual emergence of these representations as opposed to an allornone acquisition.
 The representations are not present from the onset and are developed through the interactions of computationalarchitectural constraints and interactions with the environment.
 A critical characteristic of the approach taken in this work is the postulation of a small number of different mechanisms attuned to particular aspects of the environment (cf.
 Baillargeon, In press).
 The model assumes the existence of a mechanism designed to compute object identity and a mechanism designed to track object position.
 Each module leams independently from the same, c o m m o n experience.
 The asymmetry in performance on the manual retrieval task and the predictive visual pursuit task is a direct consequence of the requirement that computations delivered by both mechanisms need to be integrated for the former task but not for the latter.
 It should be noted, however, that the implications of this approach extend beyond the domains of visual pursuit and manual retrieval.
 In general, any task that demands the integration of the computations from distinct modules is likely to be developmentally delayed compared to a task that requires the computations to be delivered from either one of the modules.
 Of course, the degree of delay observed will depend on the difficulty of the integrative process itself.
 Thus, in the current model the integration of the computations is particularly difficult for the manual retrieval of hidden objects.
 The model also enables to make predictions about infant reactions when objects suffer feature violations.
 Recall (see Figure 1) that the object recognition network receives direct input from the retina.
 The complex cells develop spatially invariant object representations from the very start of learning.
 A s these representations become consolidated with training they will tend to persist^ over time, even w h e n the object is occluded.
 In other words, the complex cells retain a representation of the object's properties even when 5.
 The degree of persistence is primarily determined by the parameter 5 (see Footnote 1).
 174 the object is out of sight.
 This information is available to drive a surprise response.
 Moreover, note that the model predicts precocious behaviour in this domain since the surprise response does not require the integration of computations from distinct representational modules.
 Knowledge of object properties, such as size, can be driven by computations from a single source.
 W e are currently implementing this extension of the model.
 In the future, the model offers further opportunities to investigate the interactions between recognition, visual tracking, and object permanence.
 Empirical studies have suggested that when a different object reappears from behind the screen, it is the novelty of the object that determines whether infants interrupt their tracking (Goldberg, 1976) and not the change itself.
 Similarly, this model would suggest that a novel object would disrupt tracking, but only when the change was to an undesired object or one with radically different features.
 W e continue to investigate these interactions both in the model and with infants.
 In summary, we suppose that objects are represented and develop in a fragmentary fashion in the child's cognitive system.
 Different properties of the object (e.
g.
 featural versus spatialtemporal information) are processed in functionally independent modules.
 The manner in which these properties are brought together depend upon the task demands.
 The level of object knowledge that the child demonstrates may vary according to the requirements of the task itself.
 Acknowledgements This work was funded in part by the MRC (UK) and FCAR (Quebec).
 in 5monthold infants.
 Journal of Experimental Child Psychology, 22 AlS491.
 Muller, A.
 A.
.
 & Aslin, R.
 N.
 (1978).
 Visual tracking as an index of the object concept.
 Infants Behavior and Development, 1,209319.
 Munakata, Y.
, McClelland, J.
 L.
, Johnson, M .
 N.
, & Seigler, R.
 S.
 (1994).
 N o w you see it now you don't: Agradualistic framework for understanding infant success and failures in object permanence tasks.
 Technical Report, PDP.
CNS.
94.
2, Carnegie Mellon University, Pittsburg, USA.
 Piaget, J.
 (1952).
 The Origins of Intelligence in the Child.
 New York: International Universities Press.
 Spelke, E.
 S.
 (1994).
 Early knowledge: Six suggestions.
 Cognition, 50,431445.
 Spelke, E.
 S.
, Katz, G.
, Purcell, S.
 E.
.
 Ehrlich, S.
 M.
 & Breinlinger, K.
 (1994) Early knowledge of object motion: continuity and inertia.
 Cognition, 51, 131176.
 Treisman, A.
 & Sato, S.
 (1990).
 Conjunction search revisited.
 Journal of Experimental Psychology: Human Perception and Performance, 16,459478.
 Ungerheder, L.
 G.
 Mishkin, M.
 (1982).
 Two cortical visual systems.
 In: D.
 J.
 Ingle, M.
 A.
 Goodale, & Mansfield (Eds.
), Analysis of visual behavior.
 Cambridge, M A : MIT Press.
 von Hofsten, C (1989).
 Transition mechanisms in sensorimotor development.
 In: A.
 de Ribaupierre (Ed.
), Transition mechanisms in child development: The longitudinal perspective, 223259.
 Cambridge, U K : Cambridge University Press.
 References Baillargeon, R.
 (1993).
 The object concept revisited: New directions in the investigation of infant's physical knowledge.
 In: C.
 E.
 Granrud (Ed.
), Visual perception and cognition in infancy, 265315.
 London, UK: LEA.
 Baillargeon, R.
 (In press) A model of physical reasoning.
 In C.
 RoveeCollier & L.
 Lipsitt (Eds.
), Advances in infancy research, 9, Norwood, N.
J.
: Ablex Bremner, J.
 G.
 (1985).
 Object tracking and search in infancy: A review of data and a theoretical tvd\u?ii\on.
 Developmental Review, 5,311396.
 Day, R.
 H.
 & Bumham, D.
 K.
 (1981) Infants' perception of shape and color in laterally moving patterns.
 Infant Behavior and Development.
 4, 341357.
 Fischer, K.
 W.
 & Bidell, T (1991).
 Constraining nativist inferences about cognitive capacities.
 In: S.
 Carey & R.
 Gelman(Eds.
), Epigenesis of mind: Essays on biology and cognition, 99126, Hillsdale, NJ: Erlbaum.
 Foldiak, P.
 (1991).
 Learning invariance in transformational sequences.
 Neural Computation, 3,194200 Goldberg, S.
 (1976).
 Visual tracking and existence constancy 175 Belief Revision in Models of Category Learning Evan Heit Department of Psychology Northwestern University h e i t @ n w u .
 e d u Abstract In an experiment, subjects learned about new categories for wbich tbey had prior beliefs, and made probability judgments at various points during the course of learning.
 The responses were analyzed in terms of bias due to prior beliefs and in terms of sensitivity to the content of the new categories.
 These results were compared to the predictions of four models of belief revision or categorization: (1) a Bayesian estimation procedure (Raiffa & Schlaifer, 1961); (2) the integration model (Heit, 1993, 1994), a categorization model that is a generalization of the Bayesian model; (3) a linear operator model that performs serial averaging (Bush & Mosteller, 1955); and (4) a simple adaptive network model of categorization (Gluck & Bower, 1988) that is a generalization of the hnear operator model.
 Subjects were conservative in terms of sensitivity to new information, compared to the predictions of the Bayesian model and the linear operator model.
 The network model was able to account for this conservatism, however this model predicted an extreme degree of forgetting of prior beliefs compared to that shown by human subjects.
 Of the four models, the integration model provided the closest account of bias due to prior beliefs and sensitivity to new information over the course of category learning.
 Imagine that you are an American traveling in Europe for the first time.
 Until now, your concepts of people, locations, and things in European cities have been largely shaped through media images rather than direct experience.
 For example, suppose that your concept of people in City P includes the strong prior belief that these people tend to be unfriendly to Americans.
 T o be specific, you might expect that on 9 0 % of your encounters with people in City P, the person you meet will be rude or unfriendly.
 N o w say that during the first day of your visit, you meet ten citizens of P.
 To your delight and surprise, only three of them act unfriendly to you.
 Your expectations about people in City P m a y have been derived from an inaccurate stereotype.
 Clearly, your concept of these people must be revised in light of these new observations.
 But how much revision should take place? W h e n you travel the next day, will you expect the majority of people to be unfriendly or friendly? Say that on the next day, you meet ten more people, and again, three people are unfriendly.
 H o w do you put together your prior knowledge, the first day's observations, and the second day's observations? Belief revision is an important task that people face often, even when they are not traveling the world.
 Whenever people learn new concepts, they may bring to bear their previous expectations and theories (Murphy & Medin, 1985; Murphy, 1993).
 Typically there will be some discrepancy between prior knowledge and what is observed about a new category, otherwise there would be nothing to learn.
 Therefore, category learning may be considered as a kind of belief revision.
 Furthermore, categories in the world can change over time, so beliefs about these categories must be updated periodically.
 For example, improvements in technology have led to changes in people's concepts of telephones (Elliott & Anderson, in press).
 The experiment in this paper addresses the dynamics of category learning, in which performance depends on prior knowledge and new observations.
 Subjects had initial beliefs about persons in a fictional place referred to as City W , then gradually revised their concepts as they observed descriptions of persons in City W .
 The results are considered in terms of four computational models of belief revision.
 Method Ov e r v i e w .
 First, the subjects' initial beliefs about various categories of people in a new city, e.
g.
, shy people, joggers, were assessed.
 Then the subjects observed descriptions of people in City W .
 Some desaiptions were congruent with prior knowledge, such as a shy person who avoids parties, and some descriptions were incongruent, such as a jogger without expensive running shoes.
 This observation phase was interrupted periodically as subjects were asked to make probability judgments about transfer stimuli.
 Overall, the procedure was similar to that of Heit (1994), except that the subjects' changing beliefs were assessed a total of five times over the course of learning.
 Stimuli.
 Each subject saw training examples derived from five couplets of descriptive terms (see Table 1; the complete pool is in Heit, 1994).
 Each couplet of four features was comprised of two pairs of opposites or complements.
 For example, not shy is the complement of shy, and does not attend parties often is the complement of attends parties often.
 The first and third item in each couplet were congruent with each other (e.
g.
, shy and does not attend parties often), likewise the second and fourth item were congruent.
 The first and fourth items, as well as the second and third items, were incongruent (e.
g.
, shy and attends parties often).
 The stimuli were pretested on other subjects to validate this manipulation of prior knowledge (see Heit, 1994).
 176 mailto:heit@nwu.
eduTable 1: Feature Couplets (Examples) Shy / not shy Does not attend parties often / attends parties often Jogs regularly / does not jog regularly Owns expensive running shoes / does not own expensive running shoes Travels two or more times per year / travels less than two times per year Has frequent flyer number / does not have frequent flyer number Watches more TV than average / watches less TV than average Reads books less than average / Reads books more than aveaage Generous / not generous Donates to charity / does not donate to charity Each training example was a desaiption of a person, in terms of two features from a couplet.
 A pairing of two features was either congruent or incongruent.
 The five couplets were assigned randomly for each subject to the following structure: one couplet had 0 % congruent pairings, one couplet had 2 5 % congruent pairs, one couplet was 5 0 % congruent, one was 7 5 % congruent, and one was 1 0 0 % congruent.
 For example, when the shynessparties couplet was assigned to the 1 0 0 % congruent condition, all the shy people did not attend parties often and all the nonshy people did attend parties often.
 Procedure.
 At the beginning of the experiment, subjects were told that they would see descriptions of persons living in City W , a city located in Illinois.
 The procedure followed a teststudyteststudyteststudyteststudytest sequence.
 In the first test block, subjects' prior beliefs about people in City W were assessed, presumably reflecting their general knowledge about people in Illinois.
 Within a study block, the training examples were presented individually, in a random order, about every 3.
5 seconds.
 In each study block, subjects were presented with forty training examples, eight per couplet.
 In effect, subjects were given four members of each category during a study block.
 For example, subjects would see four descriptions of shy persons in each study block.
 Each of the four study blocks was followed by a test block.
 Thus, subjects were tested after they had observed 0, 4, 8, 12, and 16 members per category.
 In each test phase, subjects made 20 conditional probability estimates.
 These questions were worded as follows: Consider a person from City W with the following characteristic: x H o w likely is it that this person would also have this characteristic? A, where x and A were two features.
 Subjects responded on a scale from 0 % to 100%.
 The test stimuU for each block had a two factor design: (1) whether the two features were congruent or incongruent with each other; and (2) the conditional probability of presentation during the study phase, which was 0 % , 2 5 % , 5 0 % , 7 5 % , or 100%.
 Eight test questions were derived from each couplet, thus there were 40 possible test questions.
 In each test phase, 20 of these questions were chosen randomly and asked of the subject.
 Subjects.
 Fortytwo Northwestern University undergraduates participated.
 Results The average responses at different points during the experiment are shown in the first column of Figure 1.
 The top panel shows the initial responses, before any training had begun.
 Here, subjects clearly were influenced by their prior knowledge, as indicated by the higher judgments for congruent test questions (e.
g.
, how likely a jogger is to own expensive running shoes) compared to incongruent test questions (e.
g.
, how likely a shy person is to attend parties often).
 There was no influence of observed proportion of stimuli cooccurring, because at this point the subjects had not observed any training stimuli.
 (For the top panel, the observed proportions were defined for the experiment but not known to the subjects.
) The lower panels in this column, corresponding to category sizes 4, 8, 12, and 16, show that subjects did revise their beliefs as they observed people in City W .
 T w o concepts are critical for understanding these trends.
 First, it is useful to consider subjects' bias, that is, the direct influence of prior knowledge about these categories.
 Bias may be measured in terms of the difference between congruent and incongruent judgments, at a given level of observed proportion.
 For example, a subject with no bias would show zero difference between congruent and incongruent lines.
 The second consideration is the subjects' sensitivity to what they observed.
 That is, how well do the estimated proportions reflect the observed proportions of category membership in City W ? Sensitivity can be measured in terms of the slope of the Unes in Figure 1.
 A zero slope indicates no sensitivity to observed proportion, and higher slopes approaching one indicate greater sensitivity.
 N o w , looking at the panels in the first column of Figure 1 from top to bottom, two trends are apparent.
 First, with more experience, subjects became less biased by prior knowledge; the lines tend to converge.
 Second, subjects became more sensitive to the observed data with more experience; the slopes increase.
 (Also see Table 2.
) Statistical analyses supported these observations.
 There was a main effect of congruent versus incongruent test question, indicating that subjects gave higher judgments for congruent questions, F(l,41)=83.
0, p<.
001.
 The congruent versus incongruent factor exhibited an interaction with test block, such that the difference between congruent and 177 Category Size Results Bayesian Model Integration Model Network Model 16 n5 "8 1007550w 25 J Congruent Incongruent 1 — I — r — 8 S 12 S ^ w 25 w 25 w 25 LU 1 — I — r 1 — I — r T — I — r T — I — r r w 25 UJ C ^ ] 1 — I — r 0 25 50 75 100 Observed %  i — I — r 0 25 50 75 100 Observed % : c f C ^ T — I — r 0 25 50 75 100 Observed % " I — I — r 0 25 50 75 100 Observed % Figure 1: Results and model predictions.
 incongruent questions diminished with more items studied, F{4, 164)=37.
0, p<.
001.
 There was also a main effect of objective probability, F(4, 164)=70.
2, p<.
00l, indicating that subjects' judgments were sensitive overall to what they observed.
 This effect of objective probabiUty interacted with testing block, F(16, 656)=23.
0, p<.
001, such that subjects were more sensitive to objective probability as more items were studied.
 Model Evaluations Four models were considered as accounts for these results.
 The first two, the Bayesian revision model and the linear operator model, were included because they are classic models of learning and judgment.
 The integration model is an exemplar model of categorization that generalizes the Bayesian model.
 Also, a simple connectionist network model, a generalization of the linear operator model, was considered Bayesian and Linear Operator Models The Bayesian revision model provides a means for combining a prior belief at>out a statistical parameter with new observations (Raiffa & Schlaifer, 1961).
 This model is especially important because within the framework of Bayesian statistical theory it is taken to l)e a normative procedure.
 Therefore, comparing the results of this experiment to the predictions of the Bayesian model gives some perspective on whether subjects were behaving optimally.
 The Bayesian formula for revising an estimate of a proportion is shown in Equation 1.
 178 Pn = Np + Gq N + G (1) In this equation, Pj^ is the estimated proportion of items with description x that belong to category A, after N observations have been made.
 The variable q represents the prior estimate of this proportion (before any observation), and G indicates the strength of this prior belief.
 The variable p is the proportion of the new observations that belong to category A.
 As A' inaeases, the estimate depends more on the observed proportion, p, and less on the prior belief, q.
 The linear operator model is derived from classic mathematical learning theory (Bush & Mosteller, 1955), and this model has been applied to numerous results in learning and probability judgment (see Bower & Heit, 1992).
 Furthermore, this formula is useful for calculating a running estimate of a proportion using an anchorandadjust procedure (Busemeyer, 1991).
 This model is shown in Equation 2.
 PN=PN^+P{dNPN^) (2) Note that P q is set to q, the prior belief about this proportion.
 The indicator variable di\f refers to what is observed on trial N; it is assigned a value of 1 when the observed item is in category A and a value of 0 when the observed item is not in category A.
 Note that the expected value of d!\i in Equation 2 is equivalent to the proportion p in Equation 1.
 Finally, p refers to the learning rate, between 0 and 1.
 The estimated proportion after observation N is the previous estimate, from trial N  1, plus a correction, determined by difference between what is observed, d^, and the previous estimate, PmI In the asymptote, P n will approach p, the proportion of observed items in category A.
 Note that each of these models has two free parameters.
^ The value of q, the prior estimate of the proportion, was estimated for each model from the responses on the first block of test trials, before any observations had taken place.
 The bestfitting value of, q, derived algebraically, was .
72.
 To estimate the other parameters, the two models were fitted to the average responses on the 50 test questions.
 The values of G and P in the two models were estimated by simulating each model with various parameter values, and searching through the parameter space with the criterion of minimizing the root mean square error of prediction over the 50 judgments.
 For the Bayesian model, when G had the value of 10.
08, the root mean square error (RMSe) of the model was .
0504.
 For the linear operator model, when P had the value of .
064, the R M S e of the model was .
0563.
 (Because trial order has a slight effect on the predictions of 'The average of all the responses in this experiment was 53%; however, each of the four models to be considered predicts an average response of 50%.
 The discrepancy seems to be due to a slight lack of calibration by the subjects (see Heit, 1994; Wallsten & GonzalezVallejo, 1994).
 To compensate for this difference, a correction of .
03 was added to every prediction of each model.
 the linear operator model, this model was simulated with 100 different random orders of trials, and the predictions were averaged.
) In terms of the R M S e performance measure, the two models are close, but the Bayesian model is slightly better.
 The bestfitting predictions of the Bayesian models are shown as the lines in the second column of Figure 1, overiaid on the data points.
 (The predictions of the linear operator model are not shown, but they are similar to the Bayesian model.
) The models capture the qualitative pattern of belief revision: With more observations of category members, the models predict that bias decreases and sensitivity increases.
 However, the subjects' responses were much less sensitive than what is predicted by the models.
 This finding is evident in the second column from comparing the slopes of the lines to the slopes of the data pointsthe lines have steeper slopes, indicating greater sensitivity for the models.
 Another way of stating this result is that, compared to the normative Bayesian model as well as the linear operator model, subjects were conservative in terms of sensitivity.
 The subjects' conservatism might derive from additional details of processing, such as memory confusions or a lack of sensitivity in the response scale, not captured by these models.
 The next two models to be described are similar to the Bayesian and linear operator models, except for additional processing assumptions.
 Integration and Network Models The integration model (Heit, 1993, 1994) is an exemplar model of categorization that has already been applied to several categorization experiments where subjects were influenced by preexperimental knowledge.
 ITie critical claim of the integration model is that when people learn about a new category, they are influenced by prior examples from other, related categories.
 Information from prior examples and from new observations is simply summed together.
 For example, in learning about shy people in City W , subjects would be influenced by memories of shy people from other places as well by actual observations of people in City W .
 Such transfer of memories from one source or context to another has been described and documented by Johnson, Hashtroudi, and Lindsay (1993).
 For the present experiment, in which subjects predicted a category given a single feature, the integration model is a generalization of the Bayesian revision model.
 The integration model is described by Equation 3 (see Heit, 1994).
 Pn = Np + Gq + sN{1p) + sG{'\q) N + G + sN + sG (3) The new variable in this equation is s, which measures the degree of confusions in memory (see Medin & Schaffer, 1978).
 The value of s may range from 0 to 1, with greater values indicating poorer feature memory.
 Note that when s = 0, Equation 3 is equivalent to Equation 1 for the Bayesian model.
 In the integration model, G is interpreted as a number of prior examples retrieved for a given category A, and q is the proportion of prior examples with description x.
 179 The final model to be considered is a simple connectionist network mtxlel proposed by Gluck and Bower (1988).
 This model learns direct associations between input units and output units using the leastmeansquare (LMS) learning rule.
 This model is particularly appropriate because subjects predicted single variables from a single cue.
 The network model is quite similar to the linear operator model in Equation 2, with a few exceptions.
 First, the training signals (dn) as well as the prior belief {q) range from 1 to 1 instead of 0 to 1.
 Second, the output of the linear operator model is passed through a logistic activation function, Pf^ = 1 / (1 + exp (9 Ofj )).
 Here, Of^ refers to the value obtained from Equation 2, and 6 is a scaling parameter.
 Increasing values of 9 indicate greater overall sensitivity in judgments.
 Each model has three free parameters.
 To make the fits of the integration and network models comparable to other models, these models were constrained to fit the initial set of judgments as closely as possible.
 After some algebraic manipulation, the models were constrained as follows.
 For the integration model, q must be equal to .
5 + ((.
22) (1 h .
y)) / {I  s) to fit the initial judgments.
 For the network model, ^=.
94/9.
 With those constraints set, the free parameters were estimated.
 For the integration model, when the q parameter was .
85, G was 4.
73, and s was .
23, the EiMSe of the model was .
0261, about half the error of the Bayesian model.
 For die network model, when the value of q was .
73, P was .
12, and 9 was 1.
29, the R M S e of the model was .
0364, intermediate between the integration model and the other two models.
 The predictions of these two models are shown as die lines in third and fourth columns of Figure 1.
 With the additional free parameters allowing some degree of memory confusions or lack of responsiveness, die models now give good accounts of subjects' sensitivity over the course of learning.
 Note that in the third and fourth columns, unlike the second column, the slopes of the lines (Uie model predicuons) are quite close to the slopes of Uie data points.
 The integration model also gives an excellent account of how subjects' biases due to prior knowledge, in terms of the difference between congruent and incongruent lines, change over the course of learning.
 In contrast, die network gives a poor account of bias due to prior knowledge.
 The network model predicts that the initial biases will be nearly forgotten near the end of learning, i.
e.
, the lines nearly converge in the bottom two panels of Uie fourth column.
 In contrast to this prediction, subjects still showed substantial bias towards the end of learning.
 This model's rapid forgetting of earlier beliefs is similar to die phenomenon of catastrophic interference in more complex networks (Ratcliff, 1990).
 W h y does the integration model gives a better account of die prior knowledge bias than die network model? The integration model assumes that prior examples and previous observations have a persistent influence, even as new examples are observed.
 As a learner accumulates more information, the marginal influence of each additional observation decreases.
 This can be seen by rewridng Equation 1 as a difference equation analogous to Equation 2.
 (Equation 3 can also be rewritten as a difference equation to make a similar point, but the resulting equation is more unwieldy.
) P n = P .
 1 A/1 G + N {dNPN^) (4) What is critical in EquaUon 4 is diat die learning rate, 1 / (G + N ) , decreases as more items are observed, i.
e.
, as Â  increases.
 In contrast, in the learning rule for the network model in Equadon 2, the estimate is revised at a fixed rate, P, regardless of the number of previous observations.
 Towards the end of the experiment, the network model was revising too quickly compared to the subjects.
 It should be possible to improve die performance of die network model by additionally assuming that the learning rate decreases over the course of the experiment.
 Conclusion These results are consistent widi previous results on probability revision, such as the classic umsandballs problems reviewed by Edwards (1968).
 In those studies, subjects were also conservative compared to a Bayesian model, in terms of sensitivity to observed proportions.
 The present experiment differs from those older studies in diat subjects' prior beliefs were derived from realworld social knowledge (e.
g.
, about shy people).
 In related research, Elliott and Anderson (in press) examined the learning of categories that change over the course of an experiment.
 Elliott and Anderson also found that an exemplar model gives a better account of belief revision than a network model.
 In addition, they found evidence for forgetting of earlier observations, so that an exemplar model wiUi assumptions of memory decay performed even better.
 (In Table 2: Summary of sensitivity and bias for experimental results and model predictions.
 Category Size 0 4 8 12 16 Results .
01 .
32 .
43 .
45 .
51 Sensitivity (Slope) Bayesian Model .
00 .
29 .
44 .
54 .
61 Lin.
 Op.
 Integ.
 Model Model .
00 .
00 .
23 .
29 .
41 .
40 .
55 .
45 .
65 .
49 Network Model .
00 .
23 .
38 .
46 .
50 Results .
43 .
22 .
17 .
14 .
10 Bayesian Model .
43 .
32 .
25 .
20 .
17 Bias Lin.
 Op.
 Model .
43 .
34 .
26 .
20 .
15 Integ.
 Model .
43 .
23 .
16 .
12 .
09 Network Model .
43 .
27 .
16 .
10 .
06 180 contrast, the integration model does not implement memory decay.
) Elliott and Anderson's work is well suited to investigate forgetting because their categories changed over the course of learning, unlike the present experiment in which the categories did not change.
 Yet their procedure may have encouraged subjects to strategically ignore early observations, because using the older observations would lead to incorrect predictions.
 So what appears to be forgetting may also reflect some discounting of old information.
 In summary, the present results show how people's concepts initially are influenced by prior beliefs and are revised gradually as new category members are observed.
 This process of belief revision can be described in terms of the integration model (Heit, 1993, 1994).
 According to this model, when people learn about a new category, they retrieve prior examples from related categories as well as accumulate examples that they actually observe for the category.
 At a general level, the predictions of the integration model are similar to those of other models, but at a more detailed level the integration model gives a more successful account of the course of learning and the relation between sensitivity and bias due to prior knowledge.
 (See Table 2 for a summary of the results and the models' predictions in terms of sensitivity and bias.
) The detailed model comparisons suggest two additional principles that are central to the integration model's ability to fit these results: (1) allowing some degree of memory confusions and (2) persistent influence of previous beliefs such that the learning rate decreases as more knowledge accrues.
 The simple nature of this experiment, in which subjects predicted category labels from information about single features, was useful in distinguishing among these models.
 In future research, it would be interesting to compare the integration model to more complex connectionist networks (e.
g.
, Choi, McDaniel, & Busemeyer, 1993) for categorization experiments in which subjects are influenced by prior knowledge but learn about more complex multidimensional stimuli.
 Acknowledgments This research was supported by NIMH Grant 1 F32 MH1(X)69 and NSF Grant 9110245.
 I am grateful to Douglas Medin and Gordon Bower for discussions of this research.
 After August 1, 1995, address correspondence to Evan Heit, Department of Psychology, University of Warwick, Coventry CV4 7AL, United Kingdom.
 Bush.
 R.
 R.
, & Mosteller.
 F.
 (1955).
 Stochastic models for learning.
 New York: Wiley.
 Choi, S.
, McDaniel, M.
 A.
, & Busemeyer, J.
 R.
 (1993).
 Incorporating prior biases in network models of conceptual rule learning.
 Memory & Cognition, 21, 413423.
 Edwards, W.
 (1968).
 Conservatism in human information processing.
 In B.
 Kleinmuntz (Ed.
), Formal representation of human judgment (pp.
 1752).
 New York: Wiley.
 Elliott, S.
 W.
, & Anderson, J.
 R.
 (in press).
 The effect of memory decay on predictions from changing categories.
 Journal of Experimental Psychology: Learning, Memory, and Cognition.
 Gluck, M.
 A.
, & Bower, G.
 H.
 (1988).
 From condiUoning to category learning: An adaptive network model.
 Journal of Experimental Psychology: General, 117, 227247.
 Heit, E.
 (1993).
 Modeling the effects of expectations on recognition memory.
 Psychological Science, 4, 244252.
 Heit, E.
 (1994).
 Models of the effects of prior knowledge on category learning.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 12641282.
 Johnson, M.
 K.
, Hashtroudi, S.
.
 & Lindsay, D.
 S.
 (1993).
 Source monitoring.
 Psychological Bulletin, 114, 328.
 Medin, D.
 L.
, & Schaffer, M.
 M.
 (1978).
 Context theory of classification learning.
 Psychological Review, 85, 207238.
 Murphy, G.
 L.
 (1993).
 Theories and concept formation.
 In I.
 V.
 Mechelen, J.
 Hampton, R.
 Michalski, & P.
 Theuns (Eds.
), Categories and concepts: Theoretical views and inductive data analysis (pp.
 173200).
 London: Academic Press.
 Murphy, G.
 L.
, & Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Raiffa, H.
, & Schlaifer, R.
 (1961).
 Applied statistical decision theory.
 Boston: Harvard University, Graduate School of Business Administration.
 Ratcliff, R.
 (1990).
 Connectionist models of recognition memory: Constraints imposed by learning and forgetting funcUons.
 Psychological Review, 97, 285308.
 Wallsten, T.
 S.
, & GonzalezVallejo, C.
 (1994).
 Statement verification: A stochastic model of judgment and response.
 Psychological Review, 101, 490504.
 References Bower, G.
, & Heit, E.
 (1992).
 Choosing between uncertain options: A reprise to the Estes scanning model.
 In A.
 F.
 Healy, S.
 M.
 Kosslyn, & R.
 M.
 Shiffrin (Eds.
), From learning theory to connectionist theory: Essays in honor of William K.
 Estes (pp.
 2143).
 Hillsdale, NJ: Erlbaum.
 Busemeyer, J.
 R.
 (1991).
 Intuitive statistical estimation.
 In N.
 H.
 Anderson (Ed.
), Contributions to information integration theory.
 Volume I: Cognition, (pp.
 187215).
 Hillsdale, NJ: Erlbaum.
 181 T h e "Rational" N u m b e r e: A Functional Analysis of Categorization Angel Cabrera School of Psychology Georgia Institute of Technology AUanta.
 G A 303320170 phone: (404) 853 0192 a n g e l 9 p s y .
 g a t e c h .
 e d u Abstract Category formation is constrained by three factors: the perceptual structure of the domain being categorized, the limitations and biases of the learner, and the goals that trigger the learning process in the first place.
 Many studies of categorization have paid attention to the effects of the structure of the world and some to the biases due to the learner's prior knowledge.
 This paper explores the third factor: how the goals of the agent at the time of the learning episode affect what categories are formed.
 In particular it presents an information theoretical account that views categories as a means to increase the agent's chances of achieving its goals.
 One of the predictions of the theory is that information gain, the average reduction of uncertainty induced by a category, is maximized when the domain is partitioned into about 3 categories, the closest integer to the irrational number e.
 This prediction is confirmed by evidence derived from anthropological studies of folk classifications of animal and plants by different societies from around the world, and also by an informal observation of the behavior of cognitive scientists.
 Interestingly, e also emerges from optimization analyses of memory search as well as from experimental work on memory retrieval.
 Introduction "My problem," George Miller admitted in his magical 1956 paper, "is that I have been persecuted by an integer.
" M y problem is even worse.
 I have been persecuted by an irrational number.
 The number e, base of the natural logarithms, made its ftrst apparition as I was developing a functional analysis of categorization.
 Soon after, I found that, far from being an isolated event, the number e had also appeared, in no disguise, in other theoretical and empirical areas of psychology.
 Not wanting to draw premature conclusions from this precise coincidence, I looked at data obtained in anthropological studies of biological folk classification and, imagine that, there was e again.
 At this point it has become too hard for m e not to think of some underlying pattern behind these occurrences.
 Either I a m suffering from Miller's syndrome or this coincidence is actually telling us something.
 I have decided that submitting m y symptoms for public scrutiny m ay be the only way to solve this dilemma.
 So be it.
 Three factors constraining category acquisition Category fwmation is affected by the structtire of the stimuli being categorized, the agent's limitations and biases, and the goals leading the agent to form the categories.
 The effect of the structure of the world on human categories has received extensive theoretical and empirical attention.
 Feature matching (Rosch & Mervis.
 1975; Tversky, 1977), similarity to exemplars (Medin & Schaffer, 1978; Nosofsky, 1984), correlations among features (Bilhnan, 1989), and interfeature predictability (Anderson, 1990; Corter & Gluck, 1992) are some of the characteristics of the input that have been shown to constrain the process of category formation and, consequently, determine which categories are most likely to be acquired.
 The biases of the learner (Keil, 1990) can be the result of innate, wiredin preferences (e.
g.
 Spelke, 1990) or they can be imposed by different kinds of prior knowledge such as imphcit domain theories (Pazzani, 1991) or even the language spoken by the learner (Cabrera & Bilhnan, in press).
 Finally, categories are also affected by the goals of the agent.
 People can build categories in the service of specific goals even when the category members have httle in c o m m o n perceptually (Barsalou, 1983).
 These three factors are jointly responsible for what categories end up being formed and how easily they are formed.
 They can be seen as three forces that push the process of category formation in different directions until some equiUbrium is reached.
 Although there may well be cases where one particular factor becomes predominant, in general, constraints of the three kinds will have an effect on the resulting categories.
 The functional view The functional view of categories is an attempt to isolate the constraints imposed by the goals of the learner on category formation (Cabrera, 1994).
 It is based on the idea that categories are formed by an agent in order to increase its chances of achieving some goal.
 Imagine a person in a certain context who is trying to decide which action aj to perform out of a range of n possible actions.
 A possible strategy that the person could use to optimize his choices would consist of using his prior experience in this situation to estimate the probabilities of success of each action, 182 ?(«,).
 The person could then distribute his choices proportionally to the probabilities of success of each action or simply perform the action with the highest probability'.
 There is no question that the knowledge of these probabilities will be beneficial to the agent.
 However, there is no guarantee that the selected action will in fact be the right choice.
 In information theory, this situation is described in terms of uncertainty, a measure of the amount of additional information the person would need in order to be certain of choosing the right action.
 Uncertainty can be computed mathematically according to the expression Y,P(ai\Cj)log2P(ai\Cj) (2) £P(a,)log2P(ai) (1) j=l whose result is given in bits, the standard unit of information.
 Uncertainty is m a x i m u m when the probabilities P(a,') are uniformly distributed, and zero when one of the probabilities is 1 and the rest are 0.
 This is consistent with the intuition that if the person knew that there was only one successful choice, he would need no additional information to behave optimally, whereas if all the alternatives appeared equally good the person would need some additional information before being able to make a decent choice.
 Suppose now that there is a relationship between some variable aspect of the environment and the probability of each of the actions being helpful for the person's goals.
 Let us refer to the different forms that that aspect of the environment could take as stimuli, and to the set of all stimuli, as the domain.
 If the person knew the exact relationship between every possible stimulus and the IMobability of success of each action, his chances of success could increase considerably.
 In practice however, the large (generally infinite) size of the domain is likely to preclude the person from being able to experience every stimulus at least once during his lifetime.
 Even if this were possible, the person's memory might not be large enough to store all that information.
 A less ideal but more feasible strategy would consist of partitioning the domain into a set of m categories of stimuli, Cj , and estimating the probabilities of success of each action given stimuli from each of the categories, /'(a,IC,).
 This strategy may not completely eliminate the person's uncertainty, but it has the double advantage of reducing the storage requirements to a few sets of probabilities (one set per category), as well as to allow the person to produce informed guesses fc» stimuli never experienced before if category membership can be determined on the basis of some perceptual characteristic.
 The remaining uncertainty not captured by these conditional probabilities can be quantified as ^For the purposes of the analyses presented here it does not matter what exact strategy (probability maximizing, probability matching, etc) the agent uses.
 /=! If for each category, only one of the conditional probabilities were non zero —in other words, if category membership reduced the choices to one uncertainty would be eliminated.
 In general, even when things are not that ideal, uncertainty will nevertheless be reduced whenevo the conditional probabilities P(a,ICy) are less uniformly distributed than the prior probabilities P(a,).
 In other words, the categories will be helpful to the agent if the probabilities of success of the different actions within each category are more unequal than they are across the entire doaiaxa.
 By combining the expressions for uncertainty prior to the formation of the categories (Equation 1) and conditional upon the categories (Equation 2), w e can estimate the information gain (IG) associated with a category Cj as the average reduction in uncertainty induced by that category.
 Given PiCj), the relative frequency of occurrence of the category, infcxmation gain is simply^: IG(Cj) = n } (3) P(Cj)'^[P{ai\Cj)log2 P(ai\Cj)P{ai)log2 /»(«,) 1=1 Maximizing information gain The central hypothesis underlying the functional view of categories (Cabrera, 1994) is that learners will always try to maximize the information gain of the categories they fcMm, within the constraints, of course, of the world's structure and the learner's limitations.
 In order to isolate the consequences of this functional constraint, w e first need to make some simplifying assumptions that keep the other constraints constant.
 W e will assume, for instance, that the structure of the world is such that any possible category is equally salient perceptually, that stimuli are uniformly distributed, and that the probabilities of success of the different actions are uniformly distributed.
 These assumptions are not intended to be representative of any real situation in particular: they simply try to isolate the effects of the information maximizing bias.
 Let us assume a worst case initial scenario of maximum uncertainty.
 In other words, let us assume that, in the absence of any knowledge about the environment, all actions are equally likely to be useful to the agent.
 If n is the number of possible actions ai, this assumption amounts to saying that P(ai) = — for all ai.
 According to Equation 1 n ^Tbis expression is identical in form to a measure of category utility proposed by Corter and Gluck (1992).
 However, whereas Corter and Gluck's measure was meant to capture interfeature predictability, information gain is defined with respect to the agent's goals and actions, and is independent of the perceptual structure of the categories.
 183 the total uncertainty in a situation like this will be log2 n.
 As we could expect, uncertainty increases monotonically with the number of alternatives.
 Let us further assume that the agent partitions the domain into m contrasting categories that reduce uncertainty uniformly and maximally.
 This assumption has three implications.
 First, it implies that each category will reduce the choices from n initial actions to it ̂  n.
 Second, once a category Cj has been determined, the remaining ;t actions will have equal conditional probabilities of success Piai\Cj) = — whereas the rest nk actions will have a conditional probability P(a,ICy) = 0.
 In information terms, this means that uncertainty will be reduced from log2n to log2*.
 Third, all categories must be equally likely to occur: P(C;) = —.
 •' m Let us consider the case where m < n (fewer categories than actions).
 For the uniform uncertainty reduction assumption to hold, k must equal n/m.
 For example, if the agent has to decide among 8 possible actions but only forms 4 categories, uncertainty reduction will be maximized if each of the categories reduces the choices to 2 actions.
 From Equation 3, w e can show that the average reduction of uncertainty in this case will be: /G(C,) = l(log2nlog2t) = i2g2i^ (4) IG = log2(m)/m Figure 1.
 Information gain as a function of number of contrasting categories (m < n).
 which happens to occur &i m = e (2.
71828.
.
.
).
 Since the number of categories must be a positive integer, the actual maximum is m = 3 (with an average information gain of .
S3 bits) followed very closely by m = 2 (.
5 bits) and m = 4 (.
5 bits).
 In the case where m ^ n, the assumption of uniform reduction of uncertainty requires that each category reduce the alternative actions to one (k = 1).
 This translates into a reduction of uncertainty from log 2 n to zero, and therefore: /G(C;) = l ( l o g 2 n  0 ) = i2£l£ (5) For any given number of alternative actions n, information gain decreases byperbolically with the number of categories m.
 Since m k n, information gain will be maximum when m = n.
 Having more categories than alternative actions provides no additional reduction of uncertainty beyond that obtained with only one category per action.
 Instead, every additional category induces a cost diat is reflected on an overall lower probability of occurrence of each individual category.
 n=2 n=3 n=4 M n=5 Figure 4.
 Information gain for two to four actions and one to ten categories.
 Surprisingly, this expression does not depend on the total number of actions: it only depends on the number of categories.
 The shape of this function is shown in Figure 1.
 It is 0 for m = 1, obviously, having only one category that includes the whole domain does not reduce uncertainty at all, it peaks at m = 3 and then decreases monotonically with m.
 The exact location of the maximum of this function can be obtained as the zero of its derivative.
 Figure 4 shows the average information gain for n = 2 to 5 actions and m = 1 to 10 categories.
 For each n, information gain was computed according to Equation 4 for values of m < n and according to Equation 5 for m > n.
 Notice how IG does not vary with n when m ^ n, but it does so (decreasingly) for larger m's.
 Also, with the exception of n = 2, information gain is maximum for m = 3 independently of n.
 ta2 m 184 Empirical support The previous analyses show that, if the prior probabilities of success are unifcMnily distributed across actions, and if categories are formed which reduce uncertainty unifonnly, average functional utility is optimized when the domain is split into e, that is, about 3, contrasting categories.
 But we know that clearcut categories like these tend to be the exception rather than the norm (Smith & Medin, 1981) and we also have no reason to expect that success probabilities will actually be distributed uniformly in real situations.
 Does this invalidate the conclusion? Not necessarily.
 The assumptions are made to isolate functional constraints by setting up ideal situations from the point of view of functional utility.
 In every particular situation, worid structure as well as individual biases will moderate the effects of functional constraints and will therefore determine whether the categories that would be optimal from the point of view of the agent's goals are actually formed.
 According to Anderson's General Principle of Rationality (1990, p.
28), if having three categories is optimal for the individual's adaptation to the environment, w e should expect the human cognitive system to have developed (philo or ontogeneticaily) a tendency to organize knowledge in sets of about three contrasting categories.
 To test this prediction I turned to anthropological research.
 Etbnobiology is the branch of anthropology devoted to the study of how human societies view and use nature (Berlin, 1992).
 A great deal of ethnobiological research has compared how different societies classify the plants and animals in their natural environments and how those classifications relate to the taxonomies built by western scientists.
 There is evidence suggesting that basic level categories of animals and plants m a y be determined by perceptual structure, whereas subordinate and superordinate categories tend to be formed to fulfill specific cultural needs (Malt, 1994; Berlin, 1978).
 If this is right, the functional analysis presented here would predict subordinate categories to partition basic categories into sets of around 3 contrasting categories and superordinate categories to group sets of around 3 contrasting basic categories.
 W e should therefore expect folk taxonomies to be organized at different levels of abstraction in contrasting sets of about 3 categories on average.
 It turns out that "a general principle of ethnobiological classification is that folk species most conunonly occur in contrast sets of few (two or three) m e m b w s " (Berlin, 1992, p.
 122).
 Table 1 summarizes data reported by Beriin (1992, p.
 126128) on the frequency distribution of contrast sets with two or more categories in different biological taxonomies used by several linguistically unrelated traditional societies according to detailed ethnobiological inventoies developed by himself and others.
 I have added in the last two columns the mean and median of the distributions of category set sizes corresponding to each classification system.
 Overall, the average number of contrasting categories was 2.
982.
 Table 1.
 Frequency distribution of biological category sets of different sizes.
 Classification System Tzeltal plants (Mexico) Aguanina plants (Peru) Wayampf plants (French Guyana) Hanun6o plants (Philippines) Tobelo plants (Indonesia) Seri plants (Mexico) Tobelo animals (Indonesia) Tzeltal animals (Mexico) Wayampf animals (F.
 Guyana) Huambisa birds (Peru) Huambisa fish (Peru) Aguanina mammals (Peru) Cantonese fish (China) *Cofi.
 Sci.
 concepts (Int'l.
) 2 41 68 47 224 142 32 46 25 55 36 8 9 6 21 3 16 12 13 53 13 7 20 18 22 9 4 3 7 22 4 2 9 4 15 22 8 9 5 14 2 1 4 5 8 5 5 2 2 9 7 3 2 3 5 0 2 1 3 10 6 5 3 3 5 3 3 1 2 1 0 2 0 1 4 >7 5 9 7 16 12 1 4 1 3 0 1 0 9 4 Mean 3.
123 2.
903 2.
974 2.
612 2.
754 2.
907 2.
830 2.
926 2.
840 2.
278 3.
389 2.
824 4.
410 3.
770 Median 2 2 2 2 2 2 2 3 3 2 3 2 4 3 NOTE: Following Berlin's o v ^ concerns about the origin of the data from Ndumba plants (mean = 4.
800) and animals (3.
733), I have excluded them from m y analyses (1992, p.
 283).
 *The "Cognitive Science concepts" data come from an informal inventory of numbered and alphabetized lists in the 1994 volume of the "Cognitive Science" journal (vol.
 18).
 185 For comparison's sake, I estimated the frequency distribution of category set sizes typically used by cognitive scientists in describing their theories and defending their claims.
 These data come from an informal inventory of all the articles published during 1994 by the "Cognitive Science" journal (Vol.
 18).
 Specifically, it is based on the length of numbered and alphabetized lists that appear in each article.
 These data are particularly interesting because the theoretical concepts developed by cognitive scientists rarely rely on specific perceptual forms and may therefore be more subject to functional biases than biological categories.
 About 62.
32% of the lists in the papers examined contained two or three items (the frequency of three item lists being slightly higher than two item lists), and 88.
41% contained 5 or less (there were however two papers presenting classifications consisting of 15 and even 16 items!).
 The mean category set size was 3.
770, slightly greater than the mean of the biological taxonomies reported by Berlin (1992) but within a similar range.
 Converging Evidence and Conclusions Category acquisition is constrained by (a) stimulus structure things that look similar tend to be categorized together, (b) the learner's innate or acquired preferences things that we are programmed to categorize together or that w e have categorized together in the past tend to be categorized together again, and (c) the goals of the learner things that require similar kinds of actions tend to be categorized together.
 W h e n these constraints agree, acquisition will take place readily.
 Sometimes, one of the constraints m a y overshadow the rest, as stimulus structure may do in the case of biological basic categories (Berlin, 1978), prior beliefs in the case of illusory correlations (Chapman & Chapman, 1969), and the agent's goals in the case of adhoc categories (Barsalou, 1983).
 In general, however, categc»ies will result from some sort of compromise among the three factors.
 This paper has tried to isolate the consequences of the third kind of constraint: the connection between the categories and their function with respect to the agent's goals.
 Functional utility of a category was defined as the amount of information the category provides about the best actions to perform given some goal.
 Then, it was demonstrated that, under a few simplifying assumptions, having 3 contrasting categories (actually e) maximizes the average infcxmation gain obtained from each category.
 This prediction is supported by anthropological studies of classification of animal and plants in traditional societies around the world and also by the behavior of cognitive scientists while rep)orting their research (this paper is no exception).
 Categorization is not the only aspect of cognition where e apijears to be an optimizing factor.
 Dirlam (1972) demonstrated mathematically that a branching factor of 3 maximizes search efficiency in a hierarchical memory structure if efficiency is defined as the maximum number of items that need to be scanned in order to find a target piece of information.
 In fact, 3 appeared, as it did here, as the closest integer to the irrational e.
 Dirlam's prediction was later confirmed by a number of experimental studies of human memory (Broadbent, 1975).
 These studies, in combination, convinced Anderson (1993, p.
 26) that the best chunk size for the declarative memory system of bis ACTR model might be three.
 The optimizing power of « has also been noted in the area of psychological testing.
 Tversky (1964) showed that "given a fixed total number of alternatives for a multiplechoice type test, the use of three alternatives at each choice point will maximize discriminability, power and informati(m of a test" (p.
 386).
 Although Tversky* s finding did not have a big influence in the testing community for a number of reasons^, some of the points he raised in his paper tie very nicely into the discussion at band.
 In particular, he suggested that his result might "shed some Ught on the study of information coding and processing" (p.
 390).
 H e cited data pointing to three as the optimal number of alternatives per variable in discrimination tasks and conjectured that, under some assumptions, "the use of threelevel factors will minimize confusion and decrease memory load" (p.
 391).
 Are all these findings mere coincidence? I do not think so.
 If a branching factor of three optimizes search efficiency in a hierarchically organized data set one would expea that same factor to maximize the information gained from every decision made at a decision point in the hierarchy.
 The two are, in a sense, different ways of saying the same thing.
 D o these findings contradict Miller's number seven? I do not think so either.
 Miller's concern was about information processing capacity limts (the second type of constraint if you wish), not about optimal organization of knowledge.
 The fact that most people might be limited to discriminate a maximum of seven levels of loudness does not mean that people will tend to organize sounds into sevens.
 In turn, the idea that e optimizes information gain and search efficiency should not be interpreted as an absolute bound, but as an indication that there is an optimal number of contrasting categories, "that performance will deteriorate if one goes beyond it, and therefore, that the system will tend to organize itself in chunks [contrast sets] of that size" (Anderson, 1993; p.
 27).
 If anything, these results are compatible with Miller's: people's discrimination capacity allows them to organize things in triads.
 The number e has a long history of extraordinary appearances in mathematics and the natural sciences (Maor, 1994).
 In fact, e plays such an important role in differential calculus that the logarithm base e is known as the natural logarithm.
 Mathematicians, however, do not call e itself natural because it can not be expressed without decimal digits.
 They do not even consider it rational because it can not be expressed as the ratio between two integers.
 It is ironic that, as irrational as it is, « seems to be an optimizing factor in some rational analyses of cognition.
 If I a m not suffering from delusions of persecution, this peculiar irrational number may deserve to be upgraded to the rank of "Rational" Number.
 '̂It seems that the assumption of a fixed total number of alternatives is a rare constraint in the design of real tests (Nambury S.
 Raju, personal communication).
 186 Acknowledgments I am indebted to the Spanish Ministry of Education and Science and the U.
 S.
.
 Information Agency (Institute of International Education) for their financial and logistic support through the Fulbright Scholarship program.
 I am also grateful to Dorrit Billman, Beth Cabrera, Alex Kirlik.
 Jack Marr, Ash win Ram.
 Nambury Raju, and Tony Simon for their challenging comments and suggestions.
 References Anderson, J.
 R.
 (1990).
 The Adaptive Character of Thought.
 Hillsdale, NJ: Lawrence Erlbaum.
 Anderson, J.
 R.
 (1993).
 Rules of the Mind.
 HUlsdale, NJ: Lawrence Erlbaum.
 Barsalou, L.
 W.
 (1983).
 Adhoc categories.
 Memory and CognilioQ, IL 211227.
 Bilbnan, D.
 (1989).
 Systems of correlations in rule and category learning: Use of structured input in learning syntactic categories.
 Language and CpsniUvc Processes, 4,127155.
 Berlin, B.
 (1978).
 Ethnobiological classification.
 In E.
 Rosch and B.
 Lloyd (Eds.
), Cogpition and CategQriMtion.
 Hillsdale, NJ: Lawrence Erlbaum.
 Berlin, B.
 (1992).
 Ethnobiological Classification: Principles of Catcgpn^ation of Plants and Animais in Traditional Societies.
 Princeton, NJ: Princeton University Press.
 Broadbent, D.
 E.
 (1975).
 The magic number seven after fifteen years.
 In A.
 Kennedy and A.
 Wilkes, (Eds.
), Studies in Long Term Memory.
 London, UK.
: John Wiley & Sons.
 Cabrera, A.
 (1994a).
 Functional and conditional equivalence: Conceptual contributions from behavior analysis.
 Proceedings of the Sixteenth Annual Conference of the Cognitive Science Societv.
 Hillsdale, NJ: LawrenceErlbaum.
 Cabrera, A.
 & Billman, D.
 (in press).
 Languagedriven concept learning: deciphering "Jabberwocky".
 Journal of Experimental Psycbology: Learning.
 Memory &.
 Cognition.
 Chapman, L.
 J.
, & Chapman, J.
 P.
 (1969).
 Illusory correlation as an obstacle to the use of valid psychodiagnostic signs.
 Journal of Abnormal Psvcholopv.
 74.
 271280.
 Corter, J.
 E.
 & Gluck, M.
 A.
 (1992).
 Explaining basic categories: feature predictability and information.
 Psvchological BulleUn.
 111.
 291303.
 Dirlam, D.
 K.
 (1972).
 Most efficient chunk sizes.
 Cognitive PsycboloeY.
 2.
 355359.
 Keil, F.
 C.
 (1990).
 Constraints on constraints: surveying the epigenetic landscape.
 Cognitive Science.
 14.
 135168.
 Malt, B.
 C.
 (1994).
 Category coherence in crosscultural perspective.
 Cognitive Science Technical Repeat UTUCBICS9403.
 The Beckman Institute, University of Illinois.
 Maor, E.
 (1994).
 e : The Story of a Number.
 Princeton, N.
J.
: Princeton University Press.
 Medin.
 D.
 L.
 & Schaffer, M.
 M.
 (1978).
 Context theory of classification learning.
 Psvchologv Review.
 Si, 207238.
 Miller, G.
 A.
 (1956).
 The magical number seven, plus or minus two: some limits on our capacity for processing information.
 Psvcholoyical Review, fil, 8197.
 Nosofsky, R.
 M.
 (1984).
 Choice, similarity, and the context theory of classification.
 Journal of Experimental P.
svcholoyv: Teaming.
 Memorv and Cognition.
 10.
 104114.
 Pazzani, M.
 J.
 (1991).
 Influence of prior knowledge on concept acquisition: Experimental and computational results.
 Journal of Experimental Psvchologv: Learning.
 Memorv and Cognition.
 17.
 416432.
 Rosch, E.
 & Mervis, C.
 B.
 (1975).
 Family resemblance: Studies in the internal structure of categories.
 Cognitive Psvchologv.
 7.
 573605.
 Smith, E.
 E.
, & Medin, D.
 L.
 (1981).
 Categories and Concepts.
 Cambridge, MA.
: Harvard University Press.
 Spelke, E.
 S.
 (1990).
 Principles of object perception.
 Cognitive Science.
 14,2956.
 Tverdcy, A.
 (1964).
 On the optimal number of alternatives at a choice point.
 Journal of Mathematical Psychology.
 1 386391.
 Tversky, A.
 (1977).
 Features of similarity.
 Psychological 187 Consistency is the Hobgoblin of H u m a n M i n d s : People Care but Concept Learning Models do Not Dorrit Billman School of Psychology Georgia Institute of Technology Atlanta.
 G A 30332 (404)8942349 d o r r i t .
 b i l l m a n Q p s y c h .
 g a t e c h .
 e d u D a v i d D^vila School of Psychology Georgia Institute of Technology Atlanta.
 G A 30332 (404)8942349 psg94dd0pri3m.
gatech.
edu Abstract People may be biased to leam categories which not only capture structure in the environment but organize this knowledge in a manner easy to use in reasoning.
 Concepts organized to contrast consistently on the same attributes as sister categories within a hierarchy may be particularly useful in guiding induction.
 W e assess whether systems of novel categories organized in this maimer were also easier to leam.
 Supervised concept learning was dramatically easier in the consistent over inconsistent contrast condition.
 W e tested whether several models of concept learning would show sensitivity to consistent contrast, as people did, including assessment of a model designed to use information about consistent contrast, TWILIX.
 None of the models tested (ALCOVE, rational analysis, and T W I L I X ) showed much sensitivity to the Consistent/Inconsistent contrast.
 People may flexibly adjust their learning strategy to capitalize on simple regularities when available, in a manner not incorporated in these concept learning models.
 Multiple influences conspire to produce our systems of categories and to produce new learning at the edges of existing knowledge.
 The structure of the environment is a key influence, as we use categories to refer to types of actual entities and to guide us through the world.
 Second, a person's activities and goals prioritize those aspects of the environment that support important activities over other information whose value is less clear.
 In addition, the business of mental life and economies of mental activity are important influences.
 Concepts are used in reasoning, remembering, and imagining.
 These mental activities and human mental limitations influence category construction as well.
 The present work investigates learning biases, or constraints, that make reasoning tasks more straightforward: hierarchy and consistent contrast.
 A bias to organize information into set inclusion hierarchies, at least local ones, aids many forms of default and deductive reasoiing.
 A bias for consistent contrast aids inductive reasoning.
 The experiment reported here investigates consistent contrast.
 Consistent contrast is a relation within a set of categories which are daughters of the same siq)erordinate category.
 For categories with consistent contrast, the attributes relevant to one category are also relevant to the others in the set.
 Consistent contrast is the principle motivating variability bias in the machine learning model T W I L I X (Martin, 1992;Martin&Billman, 1991) and is closely related to Goodman's (1983) notion of projectability (also Shipley, 1993; Russell.
 1986; Billman.
 1992).
 If individual, known types of animals are homogeneous with respect to diet, one should be able to generalize that the diet observed for one individual of an unfamiliar kind will be generally true for the kind as a whole (Shipley, 1993).
 The idea of consistent contrast is linked to hierarchy because it is the hierarchy that provides the set of contrasting categories.
 Type of diet will not be consistent within, or even applicable to.
 categories such groups of people or kinds of machines.
 Evidence for a consistent contrast has come from induction studies that assessed the generalizations which subjects were willing to make from a single instance of a new category.
 Macario, Shipley, and Billman (1990) found that children's generalizations from a single instance respected consistent contrast.
 Learning studies could also assess whether a whole set of novel categories are better learned when they contrast consistently.
 The present study investigates learning.
 W e compared learning sets of three categories in a Consistent Contrast Condition with learning sets of categories in an Inconsistent Contrast Condition.
 In the Consistent Contrast Condition the same attributes were important across the set.
 In the Inconsistent Contrast Condition the same individual categories were regrouped such that different attributes mattered for each of the categories in the contrast set.
 W e predicted that the identical categories would be learned more easily when part of a Consistent than Inconsistent Contrast set.
 Experimental Method Subjects.
 Fifty students from the Georgia Institute of Technology, 26 in the Consistent and 24 in the Inconsistent Condition participated for extra credit.
 All had normal color vision Materials.
 Stimuli were animated events showing alien animals, moving and vocalizing against a background scene.
 During the learning phase each trial presented one event and the learner was asked to click the appropriate name for the creature from a set of three labels (yodlarjalfaz, and muntog).
 Subjects were given feedback and the correct label was displayed.
 There were 45 learning trials, 15 from each category.
 Events were composed from six, threevalued attributes: Sound, Movement, Habitat, Color, Head, Body/Legs.
 188 Table 1: Set 1 Stimuli Schema Used for Human Participants Category 1 Category 2 Category 3 Category 1 Category 2 Category 3 Consistent Contrast CQnfiguraiJQn 1 Configurauon 2 11 XX XX 22 XX XX 33 XX XX XX 11 XX XX 22 XX XX 33 XX Inconsistent Contrast Configuration 1 Configuration 2 11 XX XX XX 11 XX XX 22 XX XX XX 22 XX XX 33 33 XX xx Configuration 3 XX XX 11 XX XX 22 XX XX 33 Configuration 3 XX XX 11 22 XX XX XX 33 XX Stimuli for the three categories for each of six subject groups are shown schematically.
 Numbers indicate the value of an attribute that was consistently assigned to members of a given category.
 X's indicate random attribute values for members of the category.
 Each column indicates an attribute, ordered as sound, movement, habitat, color, headtype, and body/leg.
 Each categcxy was deflned by a combination of two of the six attributes as shown in Table 1.
 In the Consistent Contrast Condition, the same two attributes determined category membership for all three categories.
 For example, in Configuration 1 all yodlars croaked and flew, ralfazes bleated and walked, while muntogs roared and jumped.
 Three different pairs of attributes were used in three different configurations to counterbalance the effects of attribute salience.
 In the Inconsistent Contrast Condition, however, each category used a different pair of attributes to mark category membership, for example.
 Category 1 used sound and movement.
 Category 2 used habitat and color, while Category 3 used head and body.
 The influence of individual attributes and individual attribute values was counterbalanced to equate the impact of these factors in Consistent and Inconsistent Conditions.
 As shown in Table 1 nine categories were used across the three configurations.
 These nine individual categories were identical between the Consistent and Inconsistent Conditions, but they were grouped into different category sets.
 Finally, the identical set of instances are used in a given category (i.
e.
 the xx xx 22 category, 33 xx xx category, etc.
) when it occurs in the Consistent ot in the Inconsistent Condition; e.
g.
, the identical set of xx 33 xx items are used in Consistent Condition Configiuation 2 and in the Inconsistent Condition Configuration 3.
 A single order of instances was used for all subjects in a given condition and configuration.
 The test phase consisted of 30 trials.
 Half of the test items were normal examples of the three categories seen during learning and half were incorrect events.
 A n incorrect test item scrambled up the assignments of the defining attribute pair (e.
g.
, 12 xx xx rather than the correct 11 xx xx).
 N o labels wCTe provided.
 Procedure.
 Participants worked in soundisolated cubicles.
 Subjects were instructed that they would be touring the Saturn zoo and observing different animals.
 Fot each, three names would appear and they should click on the name they thought was the correct label for the display.
 After the subject's judgment, the name the zookeepCTs use would be displayed.
 Subjects were told they would be tested later.
 During the learning phase, subjects saw an animated scene, clicked on one of three category labels, and got feedback indicating the correct category choice.
 At the beginning of the test phase, subjects were told they would see more events, some of which would be like what they had seen and some of which would be new.
 They were told to click a 'yes' button if the event was "like something you had seen before" and no' otherwise.
 Cwrect.
 familiar displays were consistent with the schema for the three categories used during learning.
 Incorrect or discrepant displays disrupted the pairings between diagnostic attribute values which had held during learning.
 N o feedback was provided.
 Finally, participants filled out a questionnaire about what they noticed.
 Design.
 The independent variables were Condition and Configuration, nested within Condition.
 The dependent measures were the number of correct classificaticxis over the learning trials and the number correct on the test Experimental Results Average number correct over learning was 86.
9% in the Consistent and 49.
5% in the Inconsistent Condition.
 Subjects in the Consistent Condition jumped to high, asymptotic classification in the fu^t 10 trials.
 The effect of Condition, F(l,44)=269, p<.
001, but not Configuration, F(4,44) =2.
27, was highly significant.
 Subjects in the Consistent Contrast Condition also performed dramatically better, mean of 75.
1% correct, than Uiose in the Inconsistent Contrast Condition, mean of 55.
3%, on test events (Condition F(l,44)=14.
03, p=.
001; Configuration F(4,44)=.
87).
 189 Subject's Average Performance on Learning Stimuli 1.
0 S c Id E I 0.
80.
60.
40.
20.
0 O OC • IC 1 1 1 1 1 1 1 1— 5 10 15 20 25 30 35 40 45 Learning Trial Figure 1: Learning curve for Consistent and Inconsistent Conditions Methods for Comparative Simulations We believe these results pose difficulties for many computational accounts of concept learning, including recent modeling that motivated these experiments.
 W e ran simulations on R A (Anderson, 1991), ALCOVE (Kruschke.
 1990, 1992), and TWILIX (Martin,1992; Martin&Billman,1991), to compare performance in the consistent to inconsistent condition.
 Dq?endent Variables.
 All models estimate the probability of each alternative category label and then pick the value with the highest probability to generate their classification response.
 W e use the probability estimates rather than the coarser measure of p»x:ent carect responses.
 Set 1 Stimuli.
 W e used stimuli from the same schematic specification as shown in Table 1.
 For the simulations, we also controlled the between category similarity and hence confusibility between categories, as well as within category similarity.
 In particular, we constructed stimuli (Table 2) such that any advantage of the Consistent Condition could not be due either to greater withincateg(H7 or lower betweencategory similarity.
 Values of the four uiqnedictive attributes were assigned to make the betweencategory similarity in the Consistent Condition HIGHER, and hence the categories more confusible, than in the Inconsistent Condition.
 A model dominated by similarity would leam faster in the Inconsistent than the Consistent Condition.
 Our purpose was simply to ensure that any advantage for the consistent condition could not be due to simple differences in similarity relations.
 Fot all models we averaged ten runs with different stimuli orderings.
 Set 2 Stimuli.
 W e used the identical stimuli seen by subjects in the experiment (represented as numbers, not bodyparts, of course).
 The six ordered sets of instances, for the two conditions by three configurations, produced six runs.
 Table 2: Set 1 Exact Items Used in Simulations Consistent Condition Learning Categay 1 Category 2 Categay 3 11 11 II 22 22 11 33 13 12 1113 12 22 3121 33 33 22 113121 22 22 23 33 22 23 1133 22 22 32 33 33 32 33 Inconsistgnt Condition Uaming Category 1 Category 2 Categ»y3 111111 22 22 11 22 1133 1113 12 23 22 12 23 13 33 113121 32 22 21 32 3133 1133 22 33 22 22 33 33 33 190 R A Avg Performance on Learning Stimuli 1.
0 I a.
 I 0.
80.
60.
40.
20.
0 B oc IC 1 1 1 1 1 1 1 1— 5 10 15 20 25 30 35 40 45 Learning Trial Figure 2: RA's Performance on Set 2 Stimuli Results f r o m C o m p a r a t i v e Simulations RA.
 The rational analysis model is a nonhierarchical unsupervised clustering algorithm that approximately optimizes the predictive utility of the clusters it creates.
 It can be ̂ plied to supervised learning by exclusively looking at the model's predictions of the attribute specifying the category label 1.
 W e anticipated that R A would be insensitive to the difference between the consistent and inconsistent conditions, as R A is indifferent to the basis for predictive success and hence to whether instances in contrasting categories are similar in the same or in differing respects.
 R A was implementation from Anderson (1991) and run with c set to .
3.
 For the similaritycontrolled stimuli of Set 1, R A showed a slight (.
04) consistent advantage for the Inconsistent Condition over the Consistent throughout the learning curve.
 After three presentations of the 12 learning items {vobability estimates of the correct category label were .
82 for the C(Hisistent and .
86 for the Inconsistent condition.
 Figure 2 shows RA's probability estimates for Stimulus Set 2, the exact stimuli seen by our subjects.
 Each of the two curves comes from three runs of RA.
 Here R A does show a modest but fairly consistent ^ R A can also be adjusted for supervised learning by changing the system's prior belief that there will be a unique vahie of the label attribute for each cluster that R A creates.
 Auxiliary runs of RA with this label sensitivity were similar.
 Runs with the coupling parameter set to .
2 produced similar results to those reported here, as well.
 advantage for the Consistent Condition run, though nothing like the strong, early contrast shown by people.
 OualitativeAttrihuteALCOVE.
 ALCOVE is an instancebased supervised concept learning algcmthm with attentional learning.
 A s well as storing instances and generalizing based on the similarity of a novel instance to known instances, it also "stretches" ot "shrinks" dimensions of the rei^esentation space to learn to weight more heavily those attributes which discriminate between categories.
 A L C O V E is designed for continuously valued attributes, but can easily be applied to binary categorical attributes by using only 1 and 0.
 However, application to multivalued categorical attributes (red/blue/yellow), required code modification.
 Instead, w e linked together sets of attribute values to a single attentional weight representing the attribute as a whole.
 Each such weight was increased or decreased in accord with the success ot failure of each classification.
 W e used code provided by Kruschke modified only as described here.
 Since the similarity relations worked to make the Inconsistent Condition categories more discriminable from each other, this should push Q A  A L C O V E toward better learning in the Set 1 Inconsistent Condition.
 However, attentional learning could benefit the Consistent but not the Inconsistent Condition.
 A L C O V E has a large parameter space.
 As a result it is strong at fitting a variety of data, but deriving predictions from A L C O V E is difficult Specifically.
 it is very difficult to provide any proof of A L C O V E ' S insufficiency without demonstrating an exhaustive search of its parameter space.
 This w e did not undertake.
 W e did 191 TWILIX Avg Performance on Learning Stimuli Q.
 I 5 10 15 20 25 30 35 40 45 Learning Trial Figure 3: TWILIX's Performance on Set 2 Stimuli think it informative to see if A L C O V E naturally produced the strong human advantage for the Consistent Condition.
 W e used parameter values from Kruschke (1990, Figs 2.
32.
10) selected to demonstrate the power of A L C O V E ' s attentional learning, for task and stimuli of broadly similar complexity.
 All these runs can show is whether for one sensible parameter choice A L C O V E shows any hint of the strong human bias f w the consistent categories.
 W e ran A L C O V E on four blocks of Set 1 Stimuli.
 For performance on the third block, mean probability estimate for the correct label was .
360 in the Inconsistent and .
361 in the Consistent Condition; number correct on this block averaged 7.
8 of 12 for Inconsistent and 7.
4 for Consistent.
 While the conditions were indistinguishable in means, the Inconsistent Condition had slightly greater variability.
 W e did not run A L C O V E on Stimuli Set 2.
 T W I L I X is a recursive hierarchical clustering algorithm, that includes variability bias.
 Variability bias alters probability estimates of the consistency of one attribute value within one category using information about the consistency of (other values oO that attribute in contrasting categories.
 If color is highly consistent within each of several familiar types of jewels, the system is biased to expect that a new type of jewel will also have a characteristic color.
 T W I L I X with its variability bias has been run on an induction task for which human data is available (NisbeU, Kranz, Jepson.
&Kunda, 1983), and its pattern of performance (Martin & Billman, 1992) was quite similar to that of people.
 W e anticipated T W I L I X would learn faster in the consistent than in the inconsistent condition.
 Like attentional learning, variability bias is a method of biasing the learner to treat some attributes as more important than others.
 Unlike attentional learning, variability bias is not a global filter, peripherally screening out information about a given attribute for any purpose in any input.
 Rather, variability bias is local to a particular context of contrasting categories: while color may be important for types of jewels but not types of cars, it will still be noticed for both types of stimuli.
 Either way of learning attribute importance could aid learning in the consistent condition, where the same attributes are important across all three categories.
 In tests on Set 1 Stimuli, T W I L I X learns quickly and identically in Consistent and Inconsistent Conditions.
 At the end of the first block of 12 instances, performance averaged .
94 in the Consistent and .
97 in the Inconsistent Conditions.
 From trial to trial the condition advantage switchs, but the average across runs and across trials 112 is .
77 for the Consistent and .
80 for the Inconsistent.
 For Stimulus Set 2 in Figure 3.
 T W I L I X also looks decidedly inhuman.
 Difference between conditions is very small, late, and again favors the Inconsistent Condition.
 T W I L I X too is basically indifferent to the contrast between Consistent and Inconsistent Conditions.
 Understanding this absence of benefit prompts a closer look at how T W I L I X uses variability bias.
 The largest influence of variability bias will be on the first use of a category.
 In particular, it will guide the system in when to set up a new category.
 Criteria for category formation will be more important in unsupervised than supervised learning tasks.
 In addition, effect of the prior probabilities provided by contrast categories will be quickly tempered as evidence about the category is collected.
 Thus most of the influence of variability bias will be seen in fu^t setting up a categcMy 192 (e.
g.
 induction from a single instance) and in estimates of the prop<»tion of category members which have the most frequent attribute value, rather than on ongoing accuracy in predicting the correct value.
 Both TWILIX and ALCOVE provide a way of prioritizing some attributes over others, but this sensitivity is too modest to produce the dramatic difference in conditions which people exhibit In a supervised learning task, when attributes that are reliably informative about all categcxies are available, people's use of this information apparently swamps sensitivity to other aspects of the problem.
 This extreme focus or selectivity apparcnily true for people does not characterize the nKwe "optimal" models presented here.
 The internal feedback model (Billman & Heit, 1988) is a fourth concept learning model applicable to this task which we did not test on these stimuli.
 It might learn differently between conditions because it has both strong attention̂  learning and strong attention limits.
 Conclusions We have found a dramatic difference in the difficulty people have in learning a set of three novel categories which consistently contrast on the same attributes versus a contrast set in which different attributes matter for different categories.
 Empirically we need to determine to what extent this advantage is due a general shift in periferal attentional versus more strategic knowledge about relevance of certain attributes to certain types of categories.
 Experiments are in progress that assess consistent contrast in hierarchically organized categories.
 Theoretically, our finding poses a challenge to most computational models of concept learning.
 Most models do not capitalize on noticing and using simple regularities where they exist, and do not {M'edict dramatically easier learning when extensive detail about multiple attributes need not be preserved.
 To accommodate instance and attribute driven learning may require models that adjust their strategies (Kruschke & Erickson, 1994) cm̂  representation in response to the task.
 lif there is an 'easy' classification rule, people will discover and use it.
 But what makes a rule easy or hard? One source of ease or difficulty stems from how simple components can be organized into a system of categories useful for deductive and inductive reasoning, as well as capturing accurate, relevant information about the world.
 Processing of Information B.
 Bums (Ed.
) Elsevier Science Publishers.
 Billman.
 D.
, & Heit, E.
 (1988) Observational learning from internal feedback: A simulation of an adaptive learning method.
 Cognitive Science.
 1?.
 587625.
 Goodman.
 N.
 (1983).
 Fact.
 FicUon.
 and Forecast 4th edition.
 Harvard University Press: Cambridge, MA.
 KruschkeJ.
K.
 (1990) ALCOVE:An connectionist model of category learning.
 Cognitive Science Tech Rep(Mt.
#19, Indiana University.
 Kruschke, J.
K.
 (1992).
 ALCOVE: An exemplarbased connectionist model of category learning.
 Psychological Esmsi.
 99, 2 2 ^ .
 Kruschke, J.
K.
 & Erickson>I.
A.
 (1994).
 Learning of rules that have highfrequency exceptions: New empirical data and a hybrid connectionist model.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society.
 A.
Ram and K.
Eiselt (Eds.
) Erlbaum Press: HiUsdale, NJ.
 Macario, J.
F.
, Shipley, E.
F.
, & Billman, D.
O.
 (1990).
 Induction from a single instance: Formation of a Novel Category.
 Journal of Experimental Child Psychology.
 5Q,179199.
 Martin, J.
D.
 (1992) Direct and indirect transfer: Investigations in concept formation.
 Technical ReptMt, Atlanta, GA: Department of Computer Science, Gemgia Institute of Technology.
 Martin.
 J.
 & Billman.
 D.
 (1991) Variability Bias and Category Learning.
 In Proceedings of the Eight IntgmaLional Workshop on Machine Learning L.
A Bimbaum & G.
C.
 Collins (Eds.
) Pp 9094.
 Morgan Kaufman: San Mateo, CA.
 Nisbett, R.
 E.
 & Krantz, D.
 H.
Jepson, C.
 & Kunda, Z.
 (1983).
 The use of statistical heuristics in everyday inductive reasoning.
 Psychological Review.
 90.
 339363.
 Russell, S.
J.
 (1986).
 Preliminary steps toward the automation of induction.
 In AAAI86 Fifth National Conference on Artificial Intelligence.
 Philadelphia Pa: American Association for Artificial Intelligence.
 Shipley, E.
F.
 (1993).
 Categories, hierarchies, and induction.
 In The Psychotogy of Learning and Motivation, D.
Medin (Ed.
).
 Academic Press: New York, NY.
 Acknowledgements Thanks to Angel Cabrera, John Kruschke, Joel Martin, and Terry Shikano for providing code and aid in running the simulations.
 References Anderson, J.
R.
 (1991) The adaptive character of thought.
 Erlbaum Press: Hillsdale.
 NJ.
 Billman, D.
 (1992).
 Modeling category learning and category use: Representation and Processing.
 In PerceptsConcepts, and Categories: The Representation and 193 T h e Abstraction of Relevant Features by Children and Adults: the Case of Visual Stimuli JeanPierre Thibaut University of Li6ge Department of Psychology 5, boulevard du rectorat.
 4000Lifege.
 B E L G I U M j t h i b a u t @ v m l .
 u l g .
 a c .
 b e Abstract In two experiments, children aged four years and adults were presented with unfamiliar stimuli.
 They had to segment them into relevant parts.
 Stimuli presented in a category shared global shape and features, but each occurrence of a potential feature was different.
 Results of the first experiment show that adults and children found the relevant features despite the differences between occurrences of potential features.
 Children's selections differed from adults' selections in terms of coherence of the segmentations.
 In the second experiment, the hypothesis that children used the global shape of the stimuli to find the relevant features was tested.
 The global shape of stimuli was manipulated in order to assess its role on feature selection.
 Results demonstrated that the number of incoherences produced by children increased when they could not rely on a global shape for their segmentation.
 The results are discussed in terms of the relative influence of configural and featural aspects of the stimuli.
 It is argued that adults rely more on feature identity than children when they segment stimuli into relevant features.
 I n t r o d u c t i o n Conceptual learning, categorization and the development of expertise are generally described in terms of features.
 In conceptual development, for example, one might explain the overgeneralization of the word "dog" to all fourlegged animals by postulating the feature "fourlegged" which is a cue for the category "dog" (Clark, 1983); then, new features like "barks", etc.
 are added to the concept and distinguish "dogs" from other fourlegged animals.
 However, such an explanation requires that we explain how children know that these features are relevant cues that distinguish dogs from other categories.
 If one looks at the unfamiliar objects displayed in Figure 1 and has to describe them, by pointing to important parts, there are many aspects that could be pointed to, considering either global or more local parts.
 More generally, if a stimulus can be described by an infinite number of potential features (Murphy & Medin, 1985), how do children and adults come to select specific aspects of stimuli as relevant descriptors? T w o determinants of feature selection have been suggested for visual stimuli: perception (bottomup perspective), and general knowledge and theories (topdown).
 In the bottomup approach, the perceptual system provides the conceptual system with a set of perceptual features that are interpreted as conceptual units in a second step.
 In theorybased approaches, expectations of the subjects based on their world knowledge influence the features they list about members of a category.
 For example, Wisniewski and Medin (1994) provide evidence that a set of stimuli were interpreted as having different features depending on subjects' information about their source.
 Is there a cognitive function (e.
g.
, perceptual) that provides subjects with a unique set of features usable as relevant descriptors of a category? As many authors have pointed out, the structure of stimuli can be processed at multiple levels (from the overall shape to specific components) and relevant features for categorization could be situated at anyone of these levels.
 From a developmental point of view, it is unlikely that children know a priori all the relevant features for categorization.
 In this paper, w e focus on the role of the structure of categories to which unknown stimuli belong and suggest that construction of relevant features is an active process based on comparisons between the stimuli of a category (Schyns, Goldstone, & Thibaut, 1995; Thibaut, 1991).
 In the following experiments, w e compare how children and adults segment unfamiliar stimuli presented alone, or as one member of a category.
 Some developmental psychologists have suggested that, relative to adults, children process stimuli in a more holistic manner.
 Young children seem to use preferentially holistic properties that are analyzed into components by adults (Kemler, 1989; Smith, 1989).
 Smith (1989) suggests that young children and adults can isolate stimulus dimensions, but that they differ on their capabilities in selectively focusing on the constituting dimensions when performing object comparisons.
 Older children and adults emphasize dimensional identity because of their greater skill in focusing on individual stimulus dimensions.
 Children under six years of age categorize stimuli on the basis of overall similarity (see, however, Ward & Scott, 1987).
 In most categorization experiments, subjects are presented with stimuli composed of well defined and clearcut dimensions, Uke squares, stars, etc.
 However, most often, the members of a category are not identical (e.
g.
, different kinds of dogs, or the shape of usual and modem chairs).
 W h e n a subject encounters a set of unfamiliar stimuli, variations can contribute to the difficulty of 194 mailto:thibaut@vml.
ulg.
ac.
beabstracting features that potentially defines a category, since the subject has to decide whether parts of different stimuli are exemplars (or not) of the same feature.
 However, despite these variations, entities that belong to the same category generally share a global shape and ihe topological relations between features are identical in the stimuli belonging to the category (e.
g.
, different kinds of chairs).
 W h e n stimuli share an overall shape, variations might contribute to the discovery of relevant features in the stimuli.
 Imagine which segmentations an extraterrestrial would perfwm from the picture of a seated person to those he would produce from a moving figure.
 Arm gestures, for example, indicate that arms are entities independent of the rest of the body.
 In the first experiment, subjects were presented with a category of unfamiliar stimuli designed in such a way that the potential features that constituted them were never identical in the different stimuli.
 W e compare how children and adults segment a member of the category presented separately or within a category (see Figure 1).
 If children are more holistic processors how might they segment stimuli into features? One could argue that their segmentation of a single stimulus will be more holistic, i.
e.
 children will isolate fewer dimensions than adults.
 If they are presented with a category of stimuli unfamiliar to them in which overall shape is constant, but that display variations at the feature level, how will they segment the stimuli compared to adults? One might suggest the hypothesis that adults will abstract the relevant features despite variations and that children will rely more on the global shape of the stimuli.
 This could mean that they will isolate fewer features than adults, or that they won't be able to find a coherent segmentation of the category.
 This would be the case if each stimulus (or subsets of stimuli) is (are) segmented without reference to the other (subsets of) stimuli.
 To summarize, w e compare the features selected as descriptors of a given target stimulus presented separately to the ones selected when the same stimulus is included in a category of unknown stimuli.
 One hypothesis is that these two contexts should lead to different segmentations and that the way children and adults segment the stimuli will differ.
 Experiment 1 A category was designed in which all the stimuli shared the same global shape.
 W e compared the parsing obtained for a target stimulus in two conditions.
 In the single condition, the target stimulus was presented alone.
 In the category condition, it was presented together with all the other stimuli.
 Children were compared to adults in the 2 conditions.
 Methods Subjects and stimuli.
 Subjects were 38 children aged 4;0 to 4;11 and 40 undergraduates students from the University of Lifege who participated as volunteers.
 A set of six stimuli was constructed according to the following design.
 The stimuli were outlines of unknown shapes.
 A first stimulus was designed in which global (GF) and local (F) target parts were selected a priori (see Figure 1, global features G F l to G F 3 , local features F4 to F7).
 The other stimuli consisted of distortions of this first form.
 Each occurrence of a target part of the target stimulus was distorted in the other stimuli.
 A s a consequence, a target part never appeared with an identical shape in two stimuli.
 The parts were lengthened, or shortened, or broadened, or any combination of these three actions.
 Each target part was present in each stimulus.
 All the stimuh had the same global configuration defined by the features GFl, G F 2 , G F 3 ("global shape" in what follows).
 Local features (F4>F7) were appended to the global feature GF3.
 All the potential parts (the expected parts) (i.
e.
 features mentioned above) were located in the same place on any stimulus (see Figure 1).
 Procedure.
 Adult subjects were randomly assigned to one of the two conditions.
 They were presented with the category of stimuli {category condition) or the target stimulus (single condition).
 In the category condition, subjects were told that they would see unfamiliar stimuli from an unknown planet and that the stimuli formed a category.
 They were asked to circle carefully the main attributes of each stimulus, i.
e.
 the important parts of the stimuli that people could use to recognize or categorize those stimuli.
 Subjects had to delineate the occurrences of a given part in the stimuli with the same color.
 The six stimuli were displayed on the same sheet of paper.
 In the single condition, the instructions were adapted for the stimulus presented separately.
 Subjects were asked to circle the parts of the stimulus that could be important to recognize and categorize it.
 The instructions were adapted for children.
 First, they completed the delineation task with two wellknown entities or two wellknown categories (chairs and dogs).
 W h e n the child showed that he/she had understood the instructions, the experimenter presented the child with the unfamiliar category (or stimulus in the single condition) and asked him/her to perform the same task that was required for the familiar categories.
 There was no time limit.
 The adults completed the task in 5 to 15 minutes and the children in 25 to 40 minutes.
 All the subjects were tested individually.
 Results and discussion.
 Adults' and children's segmentations obtained for the target stimulus were compared in the two conditions.
 First, a grid composed of the features subjects delineated was built (see Table 1).
 Subjects selected expected features (GF1>GF3, F4>F7), but also other features: combinations of the expected features, subparts of them, or combinations of those subparts (e.
g.
, a subpart of G 2 and a subpart of G 3 could be delineated as one feature).
 195 Target stimulus 6 Fs.
Bf^^€ft Figure 1: Two stimuli from the category condition including the target stimulus t f Figure 2: Three stimuli from the second experiment 196 More than 35 different features were selected, many of them by one subject only.
 T w o independent judges counted the number of times each feature of the grid was selected in each condition by adults and children (Table 1 is restricted to the most frequent attributes).
 Cases of disagreement between the judges were rare.
 They concerned infrequent delineations and did not influence results significantly.
 In order to compare adults and children, the total number of features delineated was computed for each subject.
 Children and adults were compared in the single condition and in the category condition.
 A ttest revealed that children and adults did not differ significantly on the number of selected attributes : for the single condition, t(37) = 1.
918 (p < .
062); for the category condition, t(35) = 1.
642 (p < .
109).
 W e also compared the number of expected features (GF1>GB, F4>F7) selected by children and adults in the two conditions.
 Children and adults significantly differed on the number of attributes in the category condition [t(35) = 3.
45 (p < .
0015, Adults' mean = 3.
2, children's mean = 1.
06], but did not differ in the single TABLE 1: Number of selections of each feature for the target stimulus in the two experimental conditions for adults and children.
 condition, [t(37) = .
842, p < .
4].
 A further analysis was performed on each feature taken separately.
 For each feature taken separately, we compared the proportion of subjects w h o selected it.
 For feature a given featurej: (e.
g.
, GF3), H q was that the proportion of children who selected it would not differ from the proportion of adults w h o selected the same feature.
 In the single condition, Fisher Exact Tests revealed that adults selected more often than children the features G F 3 and G F 8 while children selected more often the feature F U and F4 (see Figure 1) than adults (p < .
05).
 In the category condition, Fisher Exact Tests revealed that adults selected more often than children the features G F 3 and G F 8 while children selected more often the features Fll and F4 (see Figure 1) than adults (p < .
05), (see Table 1).
 Feature/=> Condi tionJi Single Children Single Adults Category Children Category Adults GFl 8 8 4 8 GF2 1 3 3 7 GF3 0 8 6 9 F4 4 0 1 9 F5 5 1 1 11 F6 0 0 1 10 F7 3 1 1 10 GF8 1 10 5 12 F9 0 3 2 4 FIO 9 11 6 4 Fll 12 4 1 1 F12 4 9 5 7 F13 2 4 2 1 F14 6 3 6 0 F15 7 4 6 0 Note : "Single" refers to the single condition where the target "Category" refers to the category condition.
.
 Fl,.
.
.
, The first analysis showed, in the category condition, that adults produced more expected features (GF1>GF3, F4>F7 features).
 This means that they used variations more efficiently than children in order to capture a coherent segmentation of the category.
 The second analysis of the category condition seems to provide evidence that adults are more analytic than children who selected less local features (F4>F7).
 However, to interpret these differences, first note that F4 and F5, F6 and F7 are local neighboring parts.
 If children delineated more global parts than adults, these neighboring parts would be unified as larger parts by children than by adults (F4 and F5, F6 and H brought together in FIO and F12, respectively).
 This is not the case as children segmented the feature F12 into F14 and F15 instead of F6 and F7, i.
e.
 they selected other local features.
 Moreover, adults selected the global feature G F 8 (GF1+GF2) more often than children.
 Part of the interpretation of the difference between children and adults deals with the fact that the stimulus was presented separately.
 Fi,.
.
.
, Fn refer to the selected features.
 coherence in children's selections of features differed from adults' coherence.
 Given the structure of the stimuli, a given part of a stimulus always has a corresponding part in each of the other stimuli that takes the same place in the structure of the stimuli (e.
g.
, there is a GFl, a F4 in each stimulus, see materials above).
 A n incoherence was defined as a delineation of a part of a given stimulus having a different structure (e.
g.
, number of subcomponents) and/or location than the corresponding part in the other stimuli (e.
g.
, a subject delineated F5 with a red pen for each stimulus except the target stimulus where he used a green pen).
 The total number of incoherences in the 20 adults' delineations was 2! However, a number of children did not always follow such a coherence in their segmentation.
 For example, several children split F12 into F6 and F7 on every stimulus, except one where F12 was split into F14 and F15.
 Another example of incoherence is related to F7 that was correctly delineated on each stimulus except the target stimulus where Fll took the place of F7.
 The total number of incoherences in children's delineations 197 was 30.
 Children seemed to be misguided by perceptual factors.
 For example, some children seemed to follow a rule like "what is usually outside should remain outside" when they segmented the target stimulus.
 As a consequence, some subjects delineated F4 and F5 as different features in each stimulus because F4 is inside the stimuli and FS outside the stimuli except in the target stimulus where F5 is inside.
 For that target stimulus.
 F5 was grouped with F4.
 Some subjects replaced F5 in the target stimulus by the upper part of F6.
 i.
e.
, an external part pointing to the outside.
 Some children used the perceptual cue "verticality versus horizontality": for example, in the target stimulus.
 F7 and the vertical part of F6 were grouped to form a single feature (F15).
 and the remaining part of F6 (the two horizontal segments) was selected as another feature (F14).
 Some children modified the location of a feature in one stimulus: for example, F7 was selected correctly in each stimulus except the target stimulus where F7 was replaced by Fll.
 A possible consequence of these local incoherences was that, sometimes, a feature selected for 5 stimuli had no counterpart in the sixth one (e.
g.
, F7 was selected in each stimulus except the target stimulus).
 The analysis of these incoherences supports the idea that children rely on the global shape (configural aspects) of the stimuli to select relevant features.
 First, incoherences are obtained, for a given stimulus, when the relationship between a local feature and the global shape of that stimulus is different from the equivalent relationship in the other stimuli.
 This is the case for the target stimulus which was responsible for the majority of incoherences (e.
g.
, a number of children selected the upper part of F6 as an occurrence of F5 in the target stimulus because the "real" F5 is located inside this stimulus).
 Second, children do not take the position of the local features on the global structure into account in the same as adults.
 For the target stimulus, some children selected the local Fl 1 which is connected to G F 2 (or is a subpart of GF2), for F7 which is connected to GF3.
 Third, children also select features irrespective of their local structure.
 For example, in the target stimulus, some children split F6 into its upper part on the one hand, and the other two parts on the other hand, despite the fact that in the other stimuli F6 is composed of 3 subunits.
 In short, the location of the features and their local structure (shape, number of components) determine feature selection by adults.
 The relations between the features selected in one stimulus must be confirmed by the corresponding features in the other stimuli.
 Children produced more incoherences.
 Children did not always pay attention to the location and the structure of the features they selected and seemed to rely more on the global, configural aspects of stimuli.
 Experiment 2 This experiment tested more precisely the role of the configural aspects of the stimuli (global shape) on segmentation.
 It was hypothesized that if stimuli do not display a global shape, children will produce more incoherences (see above) in their segmentations than in the preceding experiment.
 N e w stimuli were constructed the size and shape of which were more variable than in the preceding experiment.
 Method Subjects and stimuli.
 Subjects were 14 children aged 4;04;ll and 20 undergraduates students from the University of Li6ge participating as volunteers.
 A set of six stimuli was constructed (see Figure 2).
 The features F4.
 F5, F6, F7 from the preceding experiment were used.
 Their shape and size were identical to the one they had in the preceding exjjeriment.
 Their location on the parts to which they were attached remained the same, i.
e.
, F4 was always on the top of F5, and F6 always on the left of F7.
 T w o other features were used, GFl and GF2.
 GFl and GF2 in the present experiment are the equivalent of GF8 and G F 3 respectively, in the first experiment.
 The features F4 to F7 were connected to G F 2 in the same way that they were connected to G F 3 in the first experiment (see Figures 1 and 2).
 The shape and size of GFl and G F 2 were more variable than the equivalent features, GF8 and GF3, in the preceding experiment.
 Compare, for example, the shap)e and size of Fl for the stimuli Stl and St2 (see Figure 2).
 Procedure.
 The instrucfions are the same as in the preceding experiment.
 There was no cut off.
 The adults took approximately 10 to 15 minutes to complete the segmentation test, whereas the children completed the task in 30 to 40 min.
 Subjects were tested individually.
 Results Two independent judges counted the number of incoherences in adults' and children's segmentations.
 W e compared the number of incoherences produced by adults and children.
 The 20 adults produced 12 incoherences (mean of .
6 incoherence), the children produced 96 (mean of 6.
86 incoherences).
 As expected, the children produced significantly more incoherences in the present experiment than in the first one (MannWhitney, twotailed, z = 3.
 215, p < .
0013), (the average number of incoherences is 1.
812 in the first experiment, 6.
714 in the second experiment).
 This result can be related to the fact, for adults, that the relevant segmentations were clearer in the present experiment than in the first one.
 This difference is suggested by the number of different segmentations produced by adults in the two experiments.
 In the first experiment, there were 19 different segmentations (out of 20).
 In the second experiment, 7 different segmentations were obtained (out of 20).
 A Fisher Exact Test indicates 198 that these proportions differ significantly (p < .
001).
 General discussion The first experiment showed that adults and children found relevant features for the description of a category despite variations displayed by the features across stimuli.
 However, the results indicated that adults selected more expected features than children in the category condition but not in the single condition.
 This could mean that for adults, variations at the feature level contributed to reveal the constant parts of the stimuli and their limits.
 Children selected fewer "areas of variations".
 This result is consistent with the fact that they rely more on configural aspects of stimuli.
 It is likely that the abstraction of commonalities despite the presence of variations requires a finetuned analysis of the parts of the stimuli.
 Adults' segmentations also appeared to be more coherent than those of children, in the sense defined above.
 The fact that children produced more incoherent segmentations in the second experiment than in the first one supports the hypothesis that they rely on the global shape of stimuh.
 In i\\Qcategory condition, the extraction of features requires that subjects used two kinds of similarities: similarity in terms of the internal perceptual structure of features, and similarity in terms of position on the stimulus.
 In our experiments, the fact that two features have a similar perceptual structure does not mean that they are identical since the shape of features was varied across stimuli: children and adults do not use the internal structure in the same way.
 Adults delineate parts that the display the same internal structure (e.
g.
, a potential feature with 3 subparts must display these 3 subparts across stimuli).
 O n the contrary, children seem to emphasize local perceptual cues like (inside vs outside the shape) or (vertical vs horizontal position of a part).
 As a consequence, the features that they selected did not always display the same internal structure across stimuli.
 To summarize, children and adults do not value the same kind of similarities: adults value identity at a structural level, while children value identity at a siuface perceptual level.
 At the relational level (i.
e.
, the spatial position of features on the stimuli), children also differ from adults w h o delineated features which displayed the same position across stimuli.
 Children attribute more weight to superficial perceptual aspects of a feature than to their position on the stimuli even if perceptual aspects contradict the positional aspects.
 This means that children do not integrate the relational aspects between features and the perceptual properties of those features into one coherent picture of the stimuli.
 Other experiments have shown that relational aspects is a source of troubles for children (e.
g.
 relational analogies, see Centner & Rattermann.
 1991).
 In the introduction, w e mentioned three determinants of feature extraction: perception, theories, and structure of the stimuli belonging to a category.
 The preceding experiments investigated the relationships between perceptual and category information.
 W e did not manipulate theoretical aspects (in the sense of Murphy & Medin, 1985) in the present experiments.
 However, preliminary evidence seems to indicate that providing theoretical information (e.
g.
, by suggesting a name for the category) do not change the general picture given by the present results.
 Acknowledgements The author would like to thank Rob Goldstone, Jean Rondal, Phil Schyns and Ezio Tirelli for many stimulating discussions and comments.
 Thank you also to Myriam Dupont, Juliette Quadri, and Dominique Vilain for their help in running the experiments and/or analyzing the data.
 References Clark, E.
 V.
 (1983).
 Meanings and concepts.
 In P.
 H.
 Mussen (Ed.
), Handbook of child psychology (Vol.
 Ill: Cognitive development).
 New York: Wiley.
 Centner, D.
, & Rattermann, M.
J.
 (1991).
 The career of similarity.
 In S.
A.
 Gelman & P.
J.
 Byrnes (Eds.
) Perspectives on thought and language: Interrelations in development (pp.
 225277).
 Cambridge, England: Cambridge University Press.
 Kemler, D.
 G.
 (1989).
 The nature and occurrence of holistic processing.
 In B.
 E Shepp & S.
 Ballesteros (Eds.
), Object perception (pp.
357386).
 Hillsdale, NJ: Lawrence Erlbaum.
 Medin, D.
 L.
 Goldstone, R.
 L.
, & Centner, D.
 (1993).
 Respects for similarity.
 Psychological Review, 100, 254278.
 Murphy, G.
 L.
, & Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Schyns, P.
 G.
, Goldstone, R.
 L.
, & Thibaut, J.
 P.
 (1995).
 The development of features in object concepts.
 Indiana University Cognitive Science Research Report 133, Indiana University, Bloomington, IN.
Smith, L.
 B.
 (1989).
 A model of perceptual classification in children and adults.
 Psychological Review, 96, 125144.
 Thibaut, J.
 P.
 (1991).
 Recurrence et variations des attribuls dans la formation de concepts.
 Unpublished doctoral dissertation.
 University of Liege, Liege.
 Tversky, B.
 (1989).
 Parts, partonomies and taxonomies.
 Developmental Psychology, 25, 983995.
 Ward, T.
, & Scott, J.
 (1987).
 Analytic and holistic modes of learning familyresemblance concepts.
 Memory & Cognition, 15, 4254.
 199 Preferred Mental Models in Qualitative Spatial Reasoning: A Cognitive Assessment of Allen's Calculus Markus Knauff, Reinhold Rauh & Christoph Schlieder University of Freiburg Center for Cognitive Science 79098 Freiburg i.
 Br, FRG Tel.
: ++497612034944 / 4943 / 4945 knauffIreinholdIcsOcognition.
iig.
unifreiburg.
de Abstract An experiment based on Allen's calculus and its transfer to qualitative spatial reasoning, was conducted.
 Subjects had to find a conclusion X rj Z that was consistent with the given premises X rj Y and Yr2 Z.
 Implications of the obtained results are discussed with respect to the mental model theory of spatial inference.
 The results support the assumption that there are preferred models when people solve spatial threeterm series problems.
 Although the subjects performed the task surprisingly well overall, there were significant differences in error rates between some of the tasks.
 They are discussed with respect to the subprocesses of model construction, model inspection, validation of the answer, and the interaction of these subprocesses.
 In the second part of his paper Allen introduced a reasoning algorithm based on these relations.
 For instance, if the system receives the information that X meets Y and Y is during Z it is computed that the following relations between X and Z are possible: X overlaps Z or X is during Z or X starts with Z.
 The set of all possible conclusions that has X rj Y and Y r 2 Z a s its premises can be denoted as c (rj rj).
 Since Allen's theory contains thirteen relations, w e get 144 compositions c (rj r2), omitting the trivial "'equar relation.
 It is easy to see that what the system does is very similar to what cognitive scientists call a spatial three term series problem.
 Introduction In a spatial three term series problem, two spatial relational terms, X rj Y and y r2 Z are given as premises.
 The goal is to find a conclusion X r^Z that is consistent with the premises.
 Such compositions of binary spatial relations have been studied in cognitive psychology (e.
g.
 JohnsonLaird, 1980; JohnsonLaird & Byrne, 1991) as well as in spatial reasoning  a subiield of AI which studies formalisms of encoding spatial relations.
 One of the most important approaches in this research area is given by Allen's calculus.
 Allen (1983) presented a temporal logic based on intervals representing events, qualitative relations between these intervals and an algebra for reasoning about relations between these intervals.
 Although Allen's theory was originally developed in the area of temporal reasoning it has triggered numerous research enterprises in spatial reasoning as well.
 Gusgen (1989), Mukerjee & Joe (1990), H e m ^ d e z (1994) and in particular Freksa (1991) transferred Allen's theory to the spatial domain.
 Allen denotes thirteen qualitative relations between two intervals: before (<) and its converse after (>), meets (m) and met by (mi), overlaps (o) and overlapped by (oi), finishes (f) and finished by (fi), during (d) and contains (di), starts (s) and started by (si), and equal (=) that has no converse.
 Figure 1 gives pictorial examples for these relations.
 It is easy to see that these 13 relations can be used to express any qualitative relationship that can be held between two intervals.
 X before 'x leets > x overlap sjyduring 'x starts 'x finisht ; jt equal Figure 1: The possible qualitative relations that hold between two intervals (Allen, 1983).
 C onceptual a n d inferential a d e q u a c y Allen's theory has often been claimed to be cognitively adequate (e.
g.
 Freksa, 1992).
 However, there is no agreement on what cognitive adequacy is.
 In a strong sense, it at least means that something is a model of human cognition (Strube, 1992).
 The following is an attempt to give a specialization of what the cognitive adequacy of Allen's theory may be.
 The question is, whether cognitive adequacy is claimed for the thirteen qualitative relations or for the reasoning mechanism? W e distinguish between two kinds of cognitive adequacy, namely conceptual and inferential cognitive adequacy.
 Conceptual cognitive adequacy can be claimed, if and only if empirical evidence supports the assumption that Allen's system of relations is a model of people's conceptual knowledge of spatial relationships.
 However, as far as w e know there is no attempt to test empirically whether or not Allen's calculus is cognitively adequate from this point of view.
 200 Inferential cognitive adequacy can be claimed, if and only if the reasoning niechanism of the calculus is structurally similar to the way of people reason about space.
 According to this definition, w e have to answer two main questions.
 If the same spatial relational terms, X rj Y and K rj Z are given as premises to human subjects and to a system using Allen's calculus, do both come up with the same conclusion? This is the first question, which is relatively easy to test empirically.
 The second question is concerned with the mental processes underlying spatial inference.
 For a long time, the great majority of researchers believed in mental representations of formal rules of inference.
 They proposed that inferences are made by formal derivations and proof of conclusions (Hagert, 1985).
 Recently, the most successful approaches, however, argued against these rulebased approaches of spatial reasoning.
 The most important theories are those that go back on the different variants of mental models (Huttenlocher, 1968; JohnsonLaird, 1983; JohnsonLaird & Byrne, 1991).
 Generally, the key idea of mental model theories is that people translate an external situation of the real world as well as abstract concepts into a mental "simulation" or mental model.
 For spatial inference tasks JohnsonLaird argued that people solve them by imagining the spatial layout.
 Spatial reasoning from this point of view relies not primarily on syntactic operations, but on the semantic processes of construction and manipulation of mental models (JohnsonLaird & Byrne, 1991).
 First an internal model of the "state of affairs" that the premises describe is built {comprehension phase), then a parsimonious description of the mental model including a putative conclusion is constructed (description phase).
 In a third stage, people try to find alternative models of the premises in which this conclusion is false (validation phase).
 If they cannot find such a model, the conclusion must be true.
 If they find a contradiction, they return to the second stage  and so on until all possible models are tested (JohnsonLaird & Byrne, 1991).
 JohnsonLaird's theory of spatial inferences does not answer a number of questions, however.
 In particular, it does not seem plausible that the sequence of tested mental models is a stochastic one.
 Contrary to that, w e believe that there are preferred models, which will be generated first.
 If such preferred models for most of the inference tasks described by the Allen calculus can be found, w e would assume that  at least in those cases  the model construction process is deterministic.
 In other words, the given premises uniquely determine the model which is constructed.
 The agreement of experimental data with mental model theory in this essential point would be a strong argument for the applicability of the theory to spatial inferences with the Allen relations.
 This is the question of whether Allen's calculus can be called inferentially adequate, which w e will now investigate.
 E x p e r i m e n t To distinguish between conceptual and inferential aspects of Allen's calculus, the computeraided experiment was separated into three blocks: a definition , a learning , and the inference phase.
 Subjects: 33 students of the University of Freiburg, with an age range from 20 to 42 years.
 Method and Procedure: In the definition phase, subjects read descriptions of the locations of a red and a blue interval using the 13 qualitative relations (in German).
 Each verbal description was presented with a short commentary about the location of the beginnings and endings of the two intervals and a picture with a red and blue interval that matched the description.
 The learning phase consisted of blocks of trials, where subjects were presented with the onesentence description of the red and blue interval.
 They then had to determine the beginning and ending of the blue interval: out of 8 possible points that were displayed below a red interval, subjects had to choose 2 of them by pressing associated numbers on the keyboard.
 After confirmation of her/his final choices, the subject was told whether her/his choices were correct or false.
 If they were false, additional information about all correct answers was given.
 Trials were presented in blocks of all 13 relations in randomized order.
 The learning criterion for one relation was accomplished if the subject gave correct answers in 3 consecutive blocks of the corresponding relation.
 The learning phase stopped as soon as the last remaining relation reached the learning criterion.
 Subjects needed 15 to 30 minutes to accomplish the learning phase.
 For each trial, the subject's choices of beginnings and endings, type of answer (correct vs.
 incorrect) and response times were recorded.
 In the inference phase, the main part of the experiment, subjects had to solve 144 spatial threeterm series problems according to Allen's twelve relations (without "equal").
 They were presented in randomized order in the following way: The red interval starts with the green interval (premise 1); The green interval overlaps the blue interval (premise 2).
 Which relationship can be held between the red and blue interval (question for conclusion)? Subjects had to determine the beginning and ending of the blue interval by pressing numbers on the keyboard as learned before.
 The dependent measure were reaction times and error rates.
 Results For the statistical analyses, a level of significance of 5% will be adopted.
 Types of answer (correct vs.
 incorrect) were analyzed, and are reported in the following section.
 Learning phase.
 As mentioned above, the learning phase should guarantee that subjects acquire the relational 201 Table 1: Mean number of learning trials and percentage of correct answers for each relation.
 X % correct < 3.
27 94.
4 m 3.
27 92.
6 0 3.
36 91.
9 fi 3.
24 95.
3 di 3.
33 93.
6 si 3.
42 92.
0 = 3.
00 100 s 3.
45 91.
2 d 3.
55 89.
7 f 3.
36 93.
7 oi 3.
67 90.
1 mi 3.
67 89.
3 > 3.
27 93.
5 Total 3.
38 92.
9 concepts and associate them correctly with natural language expressions.
 In Table 1, the mean numbers of learning trials across subjects are listed, that means how many trials our subjects needed to accomplish the required 3 consecutive correct answers for each relation.
 As can easily be seen, subjects understood the relation "=" at once (X = 3.
00) whereas, on the average, they needed the most learning trials for the relations "ol" and "mi" ( X = 3.
67 , each).
 The maximum number of learning trials that one subject needed for the relation "si" was 10.
 As expected, the pattern was nearly the same for the related measure of the percentage of correct responses (see Table 1).
 From these results, w e can conclude (i) that our learning phase was successful, (ii) that Allen's relations can be acquired and associated with natural language expressions in reasonable time, (iii) and that the following results of the inferential phase are affected only or mostly by the cognitive inferential process.
 The substantial differences between relations indicate that fiirther research regarding the conceptual adequacy is necessary.
 Preferred mental models.
 To test the global hypothesis that there are generally preferred mental models, a chisquare test was conducted, based on the Hq that the number of answers per category would be equally distributed for all three term series problems with multiple models (i.
e.
, 72 out of 144 problems; see shaded cells in Table 2).
 Based on this hypothesis, w e obtained a chisquare value of z^(240) = 1848.
04, p < .
001.
 Thus, we can reject the Uq and adopt the hypothesis that there are preferred mental models in spatial reasoning based on Allen's calculus.
 Testing the 72 multiple model problems separately, w e obtained statistically significant chisquare values in 53 (+ 6 = 59) out of 72 tests (see Table 2 for details)^ The most impressive example is the problem dl  oi, where 84.
8% of our subjects chose the relation "oi", whereas the other two correct relations "di" and "si" (see Table 1) were not used.
 Considerable differences can be found with regard to percentages correct, which range from 60.
6% (fi  m ) up to 97.
0% (<  <, m  m, o  <, si  si, d  <) in the one model problems, and from 69.
7% (oi  m ) up to 100.
0% (o  o, o di, 0  d„ fi  >, di  <, di  d, si  <, s  si, >  o, >  d) in the multiple model problems.
 1.
 For the 6 threeterm series problems with 9 and 13 models, respectively, expected cell values are so small that the approximation of the test statistic to the chisquare distribution may be rather unsatisfactory.
 So, these results may be interpreted only with caution.
 Discussion As was outlined in the first section, the question of whether Allen's calculus is a cognitively adequate model for human spatial reasoning has to be broken down into several subordinated questions.
 To these subordinated questions, we can now give some tentative answers.
 W e could show that (i) Allen's relations together with natural language expressions can be acquired quickly, and (ii) that subjects are rather good in solving inference problems of the given kind (more than 6 0 % correct answers in the worst case).
 There is also substantial evidence, however, that there are differences with respect to the conceptual and the inferential adequacy, which a cognitive plausible model must account for.
 With respect to inferential adequacy, an extension and specification of the mental model approach seems most promising to us.
 W e were primarily interested in the existence of preferred models, but there is also a connection between the error rates found and the mental model approach that is worthy of discussion.
 Any detailed modeling of the inference process will have to account for the fact that, although the subjects performed surprisingly well overall, there are significant differences in the error rate between some of the tasks.
 In the following, we will address two questions related to a mental model interpretation of error rates: (1) H o w do mental model theories explain differences in error rates? (2) Which of these alternative explanations are ruled out by the present data? To answer the first question it is necessary to come back to the general structure of the inference process described above.
 First, what JohnsonLaird & Byrne (1991, p.
36) call comprehension phase, that is, the construction of a model of the premises, second, the description phase in which the model is inspected to find which conclusion holds, finally the validation phase which consists of examining alternative models.
 Note that the validation phase amounts to an iteration of the two earlier phases: new models are constructed and inspected until all or a suitable number of models are exhausted.
 In general, we may expect the three phases to appear in any kind of such inference tasks.
 However, there are slight differences depending on the inference paradigm that is used.
 T w o inference paradigms are commonly found in literature on reasoning.
 W e will refer to them as inference verification task and active inference task.
 To make the difference explicit we introduce the notation {cPi'92' ^ ^ 3 > ̂ o denote the 202 a B s c u O E c a c « V s o a (A o (A c # # * *r» •n O ^X8 w * e< (S •0 T *i : l w <0 'O => H f i g o 3 W ^ <58 ^ ^ V | W # 00 3 oc r̂  'O n w m o •^ ^ ^ 00 v$ r>J oj tn <» pt; fi 0« » s w •n V O' t ^ ̂  (jt w^ p^ 00 »n S 00 W # # # >n « 8\ g 2 g •5 o W T »> * 92 » # # # 00 — & tie ̂  g VI *o O .
1" # tf: <^ tĵ  •« V 00 .
5 o o W a* * * <r> ̂  o\ ao (s d •» *r 5.
 vlw ^ 5 § I H S R 8 XI w g 2 § vi r4 K r~ — 00 «« # # O — 00 w * ?3 So # ^ ̂  VJ f*l 00 I OS OS (̂  (̂  fn vS w OS o oc 3° 3 w •5 S W ^ * g S'^?: ^ •8 I w 00 ^ ^ « r< 3 W oo ^ 2 g cS g «> 05 O 00 *^ o ^ 00 00 «w t o O «S8 tw OS 4» I w oc t~ t4 00 «23 <̂  w <n "0 p •« « r~ v^ v tf .
.
1 wn r̂  r' r^ »p 00 .
J <5 w ^ # * 00 — ̂  ii v% >r» o :?S8 N # # * u ^ »̂  « <P >o <o ĉ  •* p* *r> <o & Au # # # •«t <n 6> w <r> •» CT.
 •5 3 W * # # v^ •« Oj " j: •3 o W ff> fF 95 « <^ 0\ w « ; w •<r w) o pi « r•S 3 W •5 I W ^ 5 ! ^ <>4 00 •*•.
.
 Hi ff^ y 5P' n *ri o «: 3 W # * ^ 00 — 00 uK so r 00 o 3W g «i # # >o (̂  o> .
.
 i A 3 w g ^ Ĵ  58 ^ fS f»> \n v oi •S3 w v> »Q o 00 00 K •» T 0> H fi o W e 3« ĉ  3̂  # vv ir OS v> tr> So n « * o I rCO «n 00 .
 1 8 3 W K 2 S o 3 W ^ § f 'vl« g S g I*' »rl r4 VI — r! ri •• I •531^ "o <n «5 00 *<» w* •T m 00 .
•Ih 3 Os o> ^ m 2F.
 .
.
1 3 3 w ^ <? # 5 V) « •a 3 w # # # •<»; 10 5) S S oi I w I* oc OS <*\ P* o SS8 A 3 W '̂  'O P <s ̂  r^ » <0 OS •sl W Os oOs S S 8 5 3 3 w ^ f l •s 3 w w ^ 0 D.
 D 'H E (U D.
 E «j u •u OJ T3 ^ 00 E ^ 2 Q.
 a) T3 0 h «J c 0 OJ «j ^ ^ lb rs •2: in C Er r; ^ U • —' "S ^ t2 trt Ji ij 0(j c 0 0 CI.
 >s c OJ rr 1̂  c V •h •a ~ V, r 0 ?!̂  Oj — u_ 0 c CG 1 203 fact that the conclusion cp^ is compatible with the premises ^1 and ^ 2 .
 Then, the two paradigms may be written as follows: (1) inference verification: does {^>^,<\>2} > cp^ hold? (2a) active general inference: find all (p^ such that {(Pj,Cp2} > Cpj.
 (2b) active particular inference: find some cp^ such that {cpj^Cpj} > 93The experiment clearly follows (2b), the active particular inference paradigm.
 For active inferences the following structuring of the inference process is implied by mental model theory (cf.
 the similar description of JohnsonLaird & Byrne, 1991, p.
36 for the inference verification paradigm).
 repeat model <— answers Construct a model from (Pj and (P2 Inspect the model for (p and add it to answers.
 until there are no more models In the case of an active particular inference the loop is executed just once.
 There are three places where one can look for algorithmic complexity in the procedure, a complexity which should translate into cognitive complexity, and eventually into higher error rates.
 Obviously, these places correspond to the three phases.
 The most relevant among them is the validation phase, i.
e.
 the repeat loop in the above procedure, since it has to cope with the complexity that arises from there being different models to examine.
 Several alternatives (cf.
 JohnsonLaird, 1983, p.
 163) can be envisaged for the validation phase.
 Two of these which are important are: (I) generation of models within the validation loop (2) generation of all models before entering the validation loop.
 (1) means that the models are generated within the iterative validation loop described above, that is, model construction and model inspection alternate.
 Opposed to this, in (2) all models are generated before entering the loop, that is, model construction and model inspection processes are separated.
 In agreement with the overall assumption of sequential flow of control generation before entering the loop is to be thought of as an iterative process in itself.
 Both alternatives imply that an inference task involving several models is computationally more complex and thus harder than an inference task involving just a single model.
 Byrne & JohnsonLaird (1989) were able to show for a certain type of spatial inferences in the verification paradigm that the number of models is in fact an adequate complexity measure in the sense that it allows differences in the error rate between tasks to be explained.
 In our experimental setting which follows the active particular inference paradigm, an effect of the number of models on the error rate would only be predicted by alternative (2).
 Since in our paradigm the repeat loop is entered exactly once, there will be computational costs depending on the number of models only in the case that all models are generated at once before entering the loop.
 W e are now in a position to answer the second of the two initial questions: which of the alternative explanations (e.
g.
 1 or 2) can be ruled out on the basis of the present data? The data of the experiment do not show a positive correlation between the number of models and the error rate; in fact, the correlation is negative: r = .
4146, p < .
001 counting inferences with 13 models (no error possible), r = .
3737, p < .
001 not counting those inferences.
 So we may discard alternative (2).
 Conclusions and future work We introduced a specialization of the term "cognitive adequacy of Allen's calculus", that distinguishes inferential and conceptual aspects.
 The experiment followed this distinction.
 The results indicated the existence of preferred models for spatial inferences with the Allen relations.
 The findings support an account of the inference process following mental model theory.
 Further evidence will be needed before a detailed modeling of the inference process is possible.
 A series of ensuing experiments will be concerned with the question of whether the number of models is an adequate complexity measure for reasoning in the Allen calculus  a question which implies a shift firom the active particular inference paradigm to the active general inference or the inference verification paradigm.
 Besides this, we will carry out experiments to test the assumption of the conceptual adequacy of Allen's calculus.
 Acknowledgements This work has been partially supported by the German Ministry for Research and Technology (BMFT) within the joint project F A B E L under contract no.
 41340010irW104.
 W e are grateful to Gerhard Strube for helpful comments and to Karin Banholzer and Thomas KuB for carrying out the experiment.
 References Allen, J.
 F.
 (1983).
 Maintaining knowledge about temporal intervals.
 Communications of the A C M , 26, 832843.
 Byrne, R.
 M.
 J.
 & JohnsonLaird, P.
 N.
 (1989).
 Spatial reasoning.
 Journal of Memory and Language, 28, 564575.
 Freksa, C.
 (1991).
 Qualitative spatial reasoning.
 In D.
 M.
 Mark & A.
 U.
 Frank (Eds.
), Cognitive and linguistic 204 aspects of geographic space.
 Dordrecht: Kluwer.
 Freksa, C.
 (1992).
 Temporal reasoning based on semiintervals.
 Artificial Intelligence, 54, 199227.
 Giisgen, H.
 W.
 (1989).
 Spatial reasoning based on Allen's temporal logic (Technical Report ICSITR89049).
 Berkeley, CA: International Computer Science Institute.
 Hagert, G.
 (1985).
 Modeling mental models: Experiments in cognitive modeling of spatial reasoning.
 In T.
 O'Shea (Ed.
), Advances in artificial intelligence (pp.
 179188).
 Amsterdam: NorthHolland.
 Hernandez, D.
 (1994).
 Qualitative representation of spatial knowledge.
 New York, NY: Springer.
 Huttenlocher, J.
 (1968).
 Constructing spatial images: A strategy in reasoning.
 Psychological Review, 75, 268298.
 JohnsonLaird, P.
 N.
 (1980).
 Mental models in cognitive science.
 Cognitive Science, •̂ ,71115.
 JohnsonLaird, P.
 N.
 (1983).
 Mental Models.
 Towards a cognitive science of language, inference, and consciousness.
 Cambridge, M A : Harvard University Press.
 JohnsonLaird, P N.
 & Byrne, R.
 M .
 J.
 (1991).
 Deduction.
 Hove(UK): Erlbaum.
 Mukerjee, A.
, & Joe, G.
 (1990).
 A qualitative model for space.
 Proceedings AAAI90, 721727.
 Strube, G.
 (1992).
 The role of cognitive science in knowledge engineering.
 In F.
 Schmalhofer, G.
 Strube, & T.
 Wetter (Eds.
), Contemporary knowledge engineering and cognition (pp.
 161174).
 Berlin: Springer.
 205 Diagrambased Problem Solving: T h e Case of an Impossible Problem N.
 Hari Narayanan College of Computing & EduTech Institute Georgia Institute of Technology Atlanta, G A 303320280 narayan@cc.
gatech.
edu Masaki S u w a Hiroshi Motoda Advanced Research Laboratory Hitachi Ltd.
 Hatoyama, Saitama 35003, Japan suwa,motoda@harl.
hitachi.
co.
jp Abstract Diagrambased problem solving is an activity in which subjects solve problems that are specified in the form of diagrams.
 Since the diagram contains critical information necessary for problem solving, this is an activity that clearly requires reasoning with the diagram.
 Recent research on diagrammatic reasoning has uncovered many interesting aspects of this process.
 One such aspect that the authors have been exploring, by means of a set of verbal and gestural protocol analysis experiments, is the role of the diagram in guiding the reasoning process.
 The trajectory of reasoning is revealed both by the intermediate hypotheses generated, and by the shifts of focus induced from problem solving protocols.
 In this paper we focus on the protocols collected for a particularly interesting problem, one whose solution is arrived at through a pair of contradictory inferences.
 W e derived the reasoning trajectories of subjects by extracting the temporal order and spatial distribution of their intermediate hypotheses leading toward the final solution.
 These trajectories indicate that the spatiotemporal order of hypotheses depend on more than the device structure depicted in the diagram and inferred causation of events from the diagram.
 W e propose that subjects employ impUcit search strategies which together with their internal goals to verify hypotheses and the need to replenish short term memory influence their reasoning trajectories.
 Introduction More often than not, external representations form integral parts of the representational repertoire utilized by human cognitive processing.
 However, it is only recently that research has begun to address issues of h o w cognitive processes operate on distributed representational systems that consist of external and internal representations, and what the representational effects different kinds of representations have on cognitive processes (Zhang & Norman, 1994).
 Diagrams form an interesting class of external representations, one which is quite often used in activities such as instruction, design and problem solving.
 Zhang and Norman (1994) argue that external representations can anchor and structure cognitive behaviors.
 In this vein, h o w external diagrams facilitate reasoning, visualizations, and problem solving is a topic that has recently received considerable research attention from both computational and cognitive perspectives (for example, see Cheng, 1994; Clement, 1994; Glasgow, Narayanan & Chandrasekaran, 1995; Lindsay, 1994).
 Diagrammatic reasoning m a y be defined as the kind of reasoning in which diagrams are used as external representations.
 Diagrambased problem solving then is a particular kind of diagrammatic reasoning activity in which problems, specified in the form of diagrams that are annotated with labels and some explanatory text, are solved.
 Research on diagrambased problem solving with diagrams of mechanical devices has uncovered many interesting aspects of this process.
 For instance, it has been found that readers w h o study mixed media descriptions comprising both diagrams and text construct better mental models of the kinematics of a device (Hegarty & Just, 1993) and are better able to solve problems concerning the functioning of the device (Mayer, 1989).
 Eyefixation and protocol studies (Hegarty, 1992; Hegarty & Sims, 1994; Narayanan, S u w a & Motoda, 1994) show that subjects decompose the device representation into units corresponding to components or groups of components related by contact and connectivity as perceived from the diagram.
 These studies also reveal that during problem solving the diagram serves as an external memory, facilitates mental visualization of spatial behaviors of device components, and guides the reasoning process along the direction of causality.
 O n e aspect of diagrambased problem solving that w e have been exploring is the role of the diagram in guiding the reasoning process.
 W e have collected and analyzed concurrent thinkaloud protocols and gestures of subjects solving a set of device behavior hypothesis problems presented as labeled diagrams.
 In addition to analyzing verbi protocols, the gestures and marks made by subjects were examined and used to annotate the verbal data.
 In earlier work w e proposed a model of diagrammatic reasoning for this problem solving task, and explained focus shifts induced from the protocol data in terms of perceptual and cognitive processes (Narayanan, Suwa & Motoda, 1994).
 In this paper w e continue that exploration, this time by focusing exclusively on the protocols collected for a particularly interesting problem  an "impossible"' problem whose solution is arrived at through a pair of contradictory inferences.
 The trajectory of reasoning in diagrambased problem solving is revealed at the macro level by the intermediate hypotheses that subjects generate, hypotheses which lead toward a final solution, and at the microlevel by the shifts of focus that could be induced from protocol data or by tracking eyemovements.
 Here w e derive the reasoning trajectories that subjects traversed in solving this "impossible" problem by extracting, directly from the verbal protocols annotated with 'This is called an impossible problem because unlike the other problems used in this set of experiments, the most intuitive solution to this problem requires one to predict that no motion is possible.
 Furthermore, this impossibility of motion is revealed only at the very end when two opposite motions get predicted for the same component.
 206 mailto:narayan@cc.
gatech.
edumailto:motoda@harl.
hitachi.
co.
jpgestural information, the temporal order and spatial distribution of their intermediate hypotheses leading toward the final solution.
 These trajectories indicate that the spatiotemporal order of subjects' hypotheses depends on the device stnicturc as depicted in the diagram, inferred (from both the diagram and prior knowledge) causation of events, the implicit search strategy employed in traversing branching and merging event chains, internal verification goals, and the need to replenish short term memory.
 Experimental Method The problem solving task used in this study was the following: given the schematic diagram of a mechanical device depicting the spatial configuration of its (labeled) components^ and an initial behavior, hypothesize the potential behaviors of the device in terms of the behaviors of its components.
 Subjects: Five adult high school graduates (three of w h o m  named subject 1,2 and 3  had some vocational training and were employed as technicians whereas the other two  named subject 4 and 5  were administration employees) volunteered as subjects.
 Materials: The subjects were seated at a table and presented with one sheet (per problem) containing a labeled diagram with an initial condition and instructions written below the diagram.
 A pen was kept on the table.
 The subjects were told that they could use it to point or draw on the problem sheet.
 Procedure: All subjects attended an initial session in which concurrent thinkaloud verbal reporting (Ericsson & Simon, 1983) was explained and illustrated by the experimenter.
 Each subject attended two problem solving sessions lasting approximately 45 minutes each, separated by a week.
 Subjects were asked not to discuss the experiments among themselves during this period.
 In each session a subject was first given a general instruction sheet that explained what was expected of them in terms of thinkaloud reporting.
 These instructions followed the guidelines presented in (Ericsson & Simon, 1983).
 They were then given three training problems followed by the actual problems.
 Concurrent verbal and gestural data were collected.
 Verbal reports (in Japanese) were taperecorded and gestures with hands and pen were videotaped.
 The verbal reports were transcribed and translated into English.
 Gestures and drawings that the subjects made were examined using both the video recording and the problem sheets on which subjects drew.
 These gestures typically appeared concurrently with verbalizations or during pauses.
 The entire study involved five subjects and six problems.
 Of the thirty protocols collected, twelve (three subjects and four problems) were annotated with gestural data, segmented, encoded and analyzed to arrive at the model and conclusions presented in (Narayanan, Suwa & Motoda, 1994).
 W e consider the protocols of all five subjects on the fifth problem in this paper.
 SpatioTemporal Order of Hypotheses The "impossible" problem that was given to the five subjects is shown in Figure 1.
 For the analysis presented here w e used their raw verbal protocols directly, annotated with descriptions of accompanying gestures.
 Figure 2 shows an excerpt from ^We use the term components to mean components, individual parts of components, and substances.
 Gear 2 Gear 1 Gear 3 Piston B Piston ( Pipe 2 You are required to predict everything that will happen if someone pushes handleA in the direction shown by the arrow.
 There may be many possibilities.
 ^f^^cmmammmmm Piston A Space A1 ^ Handle A Figure 1: The Problem one such annotated protocol.
 It is fairly obvious that the most intuitive solution of this problem is to predict that Gear 2 will not rotate (and therefore.
 Handle A will resist being pushed).
 Since the problem is underspecified (e.
g.
, relevant parameters such as die force with which Handle A is being pushed are not provided), other solutions are certainly possible.
 In fact, since the problem statement explicitly noted the possibility of multiple solutions, every subject came up with oUier somewhat more farfetched scenarios as well (e.
g.
, Gear 2 rotating in one direction, breaking off the teeth of the opposing gear).
 Interestingly enough, all subjects initially reached the conclusion that Gear 2 will not rotate before considering other possibilities.
 Upon further reflection on this solution, it may be seen that there is a a sequence of intermediate hypotheses that culminate in this solution and that these hypotheses correspond to a causal chain of events triggered by pushing Handle A.
 This causal chain splits into two paths at the branching point of the pipe, and later joins together at Gear 2.
 Therefore, this sequence of hypotheses has both a temporal order (hypotheses regarding earlier events precede those regarding later events in the device) and a spatial distribution over the structure of the device 207 ^ Uie piston A.
 if ihe pis(on A pivs up.
 .
.
 .
.
 (lie sixitv A2.
 Un' volimv ot ilk .
sp.
itx* Kl will bcnuilosnull, and so ot cour* tnl will (low Umnifth Uk* pjv bruuh LuulUuHaiuh 2 inlo ilkpiston.
 Ov spaa BI ol cylimlcr B ,uul Uic s[\ux* CI ot Uv cylinder C tos|Kvliwly.
 It it flows iiil< (he piston B and the piston C resfvtUvely.
 by Uie pressure, by Uk jm'ssure ol tlk spatv BI motionprojection(piston B.
up) and the space CI.
 wdl be pushed upward.
 II Ihey are pustvd upward, lirst, the liik'ar pear Bl Ihe linear gear B.
 I ani pvinp to think aU'Ul tliis.
 tins will be pushed up and so Uic ne.
\r I.
 lei rne motionpro|ection(linear gear B.
up) * \ areapointing(between linear gear B and gear 1) see routes to which way' it nuy rotate to ihe reverse directionof watches going.
 I guess.
 componentpointing(gear 1) motionprojechon(gear 1, counterclockwise) And then, let me see.
 whenihe piston C goes up.
 the linear gjear C will be pushed upas well componentpontingipiston C) J componentpointing(lineaf gear C)( mottonproiection{piston C.
 up) motionpro|ection(linear gear C, up) lies to the saine \vay as wakltes go! motionpro)ection(gear 3.
 clockwise) andin that ca*^.
 Lhe gear 3.
 let m e see rotates to the same \vay as walcltes go! componentpointingtgear 3) Figure 2: A n excerpt from verbal protocols annotated with gestures structure such as a network or tree; depthfirst and breadthfirst.
 Figures 3 and 4 illustrate the temporal order and spatial A B C D E F G H I J K L M N O P Q Hypotheses (a) Temporal order •B Space A2 PulonA (b) Spatial distribution (dotted lines indicate the causa] cbain) Figure 3: Depthfirst generation of intermediate hypotheses (in terms of the spatial location of components that hypotheses refer to).
 The following (paraphrased) hypotheses were selected from the set of all intermediate hypotheses generated by the five subjects in the course of coming to the conclusion that Gear 2 will not rotate.
 A Handle A pushed upwards.
 B Piston A moves upwards.
 C Space A 2 contracts.
 D Oil in Space A 2 pushed upwards.
 E Oil pressure in Pipe 1 increases.
 F Oil pressure in Pipe 2 increases.
 G Oil in Space Bl moves upwards.
 H Oil in Space CI moves upwards.
 I Piston B moves upwards.
 J Piston C moves upwards.
 K Linear Gear B moves upwards.
 L Linear Gear C moves upwards.
 M Gear 1 rotates counterclockwise.
 N Gear 3 rotates clockwise.
 O Gear 2 rotates clockwise.
 P Gear 2 rotates counterclockwise.
 Q Gear 2 will not rotate at all.
 The spatial distribution of these is obvious since each hypothesis refers to one particular component of the device.
 But what is their temporal order? Clearly, hypotheses A, B, C and D follow in that order.
 At this juncture the causal chain splits, and the temporal order is no longer unique.
 The model of diagrammatic reasoning that w e proposed in (Narayanan, Suwa & Motoda, 1994) suggests that at the beginning of each cycle of reasoning a hypothesis to focus on is retrieved from short term memory, into which all new hypotheses generated in that cycle is stored at its end.
 But in what order, if any, are hypotheses retrieved from short term memory? Computationally, there are two standard ways of traversing a branching Ge.
r2 G«/2 Space CI Piston A B A B C D E F G H I J K L M N O P Q Hypotheses (a) Temporal order (b) Spatial distribution (dotted lines indicate the causal chain) Figure 4: Breadthftrst generation of intermediate hypotheses distribution of aforementioned hypotheses if the causal chains were to be followed depthfirst or breadthfirst respectively (assuming that the rightside branch is attempted first).
 These figures are provided for purposes of comparison with Figures 5, 6, 7, 8 and 9, which show the temporal order and spatial distribution of the same hypotheses as generated by the five subjects.
 Discussion W e have illustrated the temporal order and spatial distribution of intermediate hypotheses that subjects generated in the 208 Qu2 Iq] >i ^fTTl i •S [h] SpicCl ABCDEFCHI J KLMNOPQ Hypotheses fa) Temporal order HmdfcA lAj fb) Spatial distribution 0 Spic« BI 1 ! 1 ! ! j i : : j i ^ ;;;:;:; T*| B f (1̂=: i.
̂4lU ̂ \ : j i • <j ) ; ) : : ; : H i i : : i i i : ^ • ; : ; • • A B C D E F G H I J K L M N O P Q Hypottieses (a) Temporal order (b) Spatial distributioD Figure 5: Hypothesis sequence generated by subject 1 Figure 6: Hypothesis sequence generated by subject 2 course of arriving at an intuitive solution to a given problem of predicting the operation of a diagrammatically specified mechanical device.
 This problem is interesting because the causal chain of events in the device undergoes a split and a merge, with a contradiction at the merge point alerting the subjects to the solution.
 The trajectories of subjects' reasoning are derived from the spatiotemporal order in which hypotheses are generated during diagrambased problem solving.
 What can be said about factors that influence these trajectories? W e postulate that reasoning trajectories of diagrambased problem solving are influenced by the following factors.
 Device Structure: The device structure as depicted in the diagram clearly influences the trajectory of reasoning.
 This is particularly evident in the problem here because the structure of the device as depicted in the diagram provides the primary clues to the branching and merging of component behaviors.
 Inferred Causation: The causal order of events in the operation of the device is inferred from the diagram by applying prior knowledge about mechanical components.
 Causation is most often inferred by using connectivity, contact or proximity information from the diagram, or by mental visualization of component behaviors using the diagram.
 A s may be verified from Figures 5, 6, 7, 8 and 9, the spatiotemporal order in which hypotheses are generated follows the causal order, except for switches between different branches or to previously generated hypotheses.
 Search Strategy: That the device structure as depicted in the diagram can influence one's reasoning trajectory seems intuitive and plausible.
 So does the conclusion that the flow of causality that subjects infer in the operation of the device will determine their reasoning trajectory to some extent, by influencing the spatiotemporal order in which events are hypothesized.
 Both of these conclusions are also supported by prior reactiontime, eyefixation and protocol analysis studies (Hegarty, 1992; Hegarty & Just, 1993; Hegarty & Sims, 1994; Narayanan, Suwa & Motoda, 1994).
 But w e postulate that subjects must have employed some implicit .
search strategies in traversing the branching and merging causal chains, which also influenced the reasoning trajectories they produced.
 This is because device structure and inferred causation are not sufficient to explain the many loops and backandforth switches between branches that are evident in Figures 5, 6, 7, 8 and 9.
 However, while our analysis shows that device structure and inferred causation by themselves are insufficient to explain the reasoning trajectories that subjects produced (which led us to postulate the existence of implicit search strategies), the question remains as to what these strategies might be.
 A s the contrast between the reasoning trajectories produced by depthfirst and breadthfirst searches (Figures 3 and 4) and the actual trajectories of subjects indicates, no subjects consistently employed either one of these strategies.
 It is also not clear whether the diagram affects the search strategy employed, or whether the influence flows the other way  the search strategy influencing focus shifts among components in the diagram.
 It is evident that none of the five subjects followed a search strategy (such as depth or breadthfirst) consistently.
 Instead, the spatiotemporal order of their hypotheses indicate a more or less random combination of the two.
 This is true in general for all the thirty protocols w e have collected.
 Uncovering the logic behind this apparent randomness by discovering factors that determine the search strategy is an important and unresolved issue requiring further research.
 A related open question is whether and h o w the search strategy is affected by the diagram, or whether the influence flows only in the other direction.
 Verification goals: M a n y backandforth switches within subsequences of hypotheses m a y be noticed in the hypothesis sequences that the five subjects generated.
 These can be explained in terms of an internal goal to reconfirm an already generated hypothesis by returning to a previous hypothesis (in the causal chain) and rederiving the intermediate hypotheses that lead to the hypothesis to be reconfirmed.
 This behavior is particularly evident among hypotheses closer to the final solution (sec the temporal orders of hypothesis generation by 209 Oail SptotCl [7] /HE Oil D SluocBI A 8 C D E F G H I J K L M N O P Q (3) Temporal order Huidk A [aJ (b) Spatial distribution Figure 7: Hypothesis sequence generated by subject 3 the five subjects).
 Replenishing short term memory: It is also possible that some of the shifts across branches that can be observed in these figures are merely for replenishing the set of active hypotheses being maintained in short term memory.
 In an earlier paper w e did a finegrained analysis of focus shifts  h o w the problem solving focus is shifted from component to component  during diagrammatic reasoning (Narayanan, S u w a & Motoda, 1994).
 This revealed that three perceptual and cognitive processes (noticing connectivity/contacts between components, mental visualization of component behaviors, and search for information) can explain 6 2 % of the total number of focus shifts observed over the twelve protocols considered.
 T h e present analysis indicates that some of the remaining 3 8 % focus shifts m a y be explainable by the search strategy employed, which causes switching a m o n g spatially separated components (belonging to different branches of behaviors).
 Internal goals of verifying (or rederiving) already generated hypotheses and the need to replenish short term m e m o r y from time to time also m a y generate focus shifts that are not explained by the three factors w e considered previously.
 Thus, the search strategy, internal goals, and replenishing short term m e m o r y could be three additional factors which influence focus shifts at the microlevel and spatiotemporal order of hypothesis generation at the macrolevel.
 Though this study used diagrams of mechanical devices, w e believe that oiu findings have relevance in general to the design of static and dynamic (e.
g.
, animations and other kinds of visualizations) graphical representations to guide reasoning, or to teach phenomena involving the propagation of causality.
 It is important that such graphical representations (1) clearly show the physical structure of the domain in terms of delineated components, (2) explicate (particularly in case of animations) the causal chains of events that occur, (3) exGc«l a o Gmf 3 Spice Bl SpiwCI SpiuA3 Pinun A B A B C D E F G H l J K L M N O P Q Hypotheses (a) Temporal order Handle A [Aj (b) Spatial distiibutioD Figvue 8: Hypothesis sequence generated by subject 4 plicitly provide clues about which branches to follow in what order if the behaviors of interest branch and merge instead of being linear, and (4) facilitate the reasoner (or the learner) to go back and forth between earlier and later stages in the reasoning process (e.
g.
, by providing control to the user to "rewind" and "restart" animations).
 While previous research by Hegarty and colleagues (Hegarty, 1992; Hegarty & Just, 1993; Hegarty & Sims, 1994) has shown that device structure as depicted in the diagram and inferred causation of events in the operation of a device are significant factors in diagrammatic reasoning, the influence of implicit search strategies and internal goals of reasoning (such as goals to reconfirm hypotheses) on the trajectory of diagrammatic reasoning in the case of devices with branching and merging behaviors has not hitherto been considered.
 The main contributions of work reported here are in illustrafing h o w the spatiotemporal order of hypothesis generation can be derived from protocol studies of diagrambased problem solving, and h o w the graphical depiction of this order may provide clues to other factors influencing the uajectory of diagrammatic reasoning.
 A note of caution, however, is that these conclusions are preliminary, and more research is required to gather additional evidence.
 W h a t determines the search strategy employed in diagrambased problem solving tasks in which branching and merging behaviors occur? H o w can diagrammatic representations be tailored to lead reasoners along the right branches, in the right order, and toward the correct conclusions? If returning to previous hypotheses within causal chains is a c o m m o n phenomenon in diagrammatic reasoning, what implications does it have for the design of animations for teaching students h o w devices work? These are but a few of the m a n y open questions in need of further research.
 Acknowledgments Financial support for this research was provided by Hitachi Ltd.
, and the experiments reported here were conducted while 210 A B C D E F G H I J K L M N O P Q Hypotheses (a) Ten^oral order HtDdfcA |_A| (b) Spatial distribution Space Bl SdmxCI Narayanan, N.
 H.
, Suwa, M.
, & Motoda, H.
 (1994).
 A study of diagrammatic reasoning from verbal and gestural data.
 In Proceedings of the W ' Annual Conference of the Cognitive Science Society (pp.
 652657).
 Hillsdale, NJ; Lawrence Erlbaum Associates.
 Zhang, J.
 & Norman, D.
 A.
 (1994).
 Representations in distributed cognitive tasks.
 Cognitive Science, 18,87122.
 Figure 9: Hypothesis sequence generated by subject 5 all three authors were at Hitachi's Advanced Research Laboratory.
 References Cheng, P.
 CH.
 (1994).
 An empirical investigation of law encoding diagrams for instruction.
 In Proceedings of the 16"" Annual Conference of the Cognitive Science Society (pp.
 171176).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Clement, J.
 (1994).
 Imagistic simulation and physical intuition in expert problem solving.
 In Proceedings of the 16"" Annual Conference of the Cognitive Science Society (pp.
 201206).
 Hillsdale, NJ; Lawrence Erlbaum Associates.
 Ericsson, K.
 A.
 & Simon, H.
 A.
 (1983).
 Protocol Analysis: Verbal Reports as Data.
 M I T Press, Cambridge, M A .
 Glasgow, J.
 I.
, Narayanan, N.
 H.
 & Chandrasekaran, B.
 (Eds.
).
 (1995).
 Diagrammatic Reasoning: Cognitive and Computational Perspectives.
 Menlo Park, CA: A A A I Press and Boston, M A : MIT Press.
 Hegarty, M.
(1992).
 Mental animation: inferring motion from static displays of mechanical systems.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 18(5), 10841102.
 Hegarty, M.
 & Just, M.
 A.
 (1993).
 Constructing mental models of machines from text and diagrams.
 Journal of Memory and Language, 32, 717742.
 Hegarty, M.
 & Sims, V.
 K.
 (1994).
 Individual differences in mental animation during mechanical reasoning.
 Memory and Cognition, 22(4), 411430.
 Lindsay, R.
 K.
 (1994).
 Understanding diagrammatic demonstrations.
 In Proceedings of the 16"* Annual Conference of the Cognitive Science Society (pp.
 572576).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Mayer, R.
 E.
 (1989).
 Models for understanding.
 Review of Educational Research, 59,4364.
 211 Complementary strategies: w h y w e use our hands w h e n w e think David Kirsh I>epartment of Cognitive Science University of California, San Diego kirshQcogsci.
ucsd.
edu ABSTRACT A complementary strategy can be defined as any organizing activity which recruits external elements to reduce cognitive loads.
 Typical organizing activities include pointing, arranging the position and orientation of nearby objects, writing things down, manipulating counters, rulers or other artifacts that can encode the state of a process or simplify perception.
 To illustrate the idea of a complementary strategy, a simple experiment was performed in which subjects were asked to determine the dollar value of collections of coins.
 In the nobands condition, subjects were not allowed to touch the coin images or to move their hands in any way.
 In the hands condition, they were allowed to use their hands and fingers however they liked.
 Significant improvements in time and number of errors were observed when S's used their hands over when they did not.
 To explain these facts, a brief account of some commonly observed complementary strategies is presented, and an account of their potential benefits to perception, memory and attention.
 Introduction A complementary strategy can be defined as any organizing activity which recruits external elements to reduce cognitive loads.
 The external elements may be our fingers or hands, pencil and paper, movable icons, counters, measuring devices, or other entities in our immediate environment.
 Typical organizing activities include pointing, arranging the position and orientation of nearby objects, (Kirsh, 95), writing things down, manipulating counters, rulers or other artifacts that can encode the state of a process or simplify perception.
 A n obvious example of a complementary strategy is using pencil and paper to help add a list of several two and three digit numbers.
 Most of us find it easier, faster and more reliable to write down incremental sums, and carry overs, than to do the summing entirely in our heads.
 For long lists, w e tend, as well, to recruit the pencil itself as a pointer to help keep our place.
 Each of these actions has its cognitive benefit.
 By writing down numbers w e offload that portion of working memory required to store intermediate results, by pointing to particular numerals we help direct attention and offload that portion of working memory required to store knowledge of location, and by recording carry overs w e set up the enviroiunent to simplify verification of our sum, should we desire to redo part of it.
 In m y terminology, such actions complement the internal processes occurring when we add.
 They are external components in an interactive computation.
 (Hutchins, 95).
 It is certainly no new claim to argue that, as intelligent creatures, w e have techniques for altering our environment to enhance our cognitive performance.
 Cognitive anthropologists, and situated activity theorists have long discussed some of the ways we have of changing our environment to augment cognition.
 (Lave 88).
 Typically, however, the changes discussed are cultural, they arise when new technologies are introduced, or when we leam new facts, methods and concepts.
 They take days or weeks or years to evolve, and they involve sharing resources and frequently cooperating with others.
 Moreover, they are rarely studied experimentally.
 (Kirsh & Maglio, 94) The environmental adaptations I shall focus on, however, occur moment by moment as we manage our workspaces.
 They are usually quick to set up, and their effect is brief measured in seconds or fractions of seconds,.
 Moreover, these strategies are often acquired quickly, as when, for instance, in the course of an activity, we discover the value of pointing, or laying down a ruler, etc.
 W e often leam these by ourselves, and our improved performance can be studied both analytically and experimentally.
 In this paper I explore one pervasive example of such complementary strategies: using our hands to help think, remember and perceive.
 After briefly elaborating the central idea, I introduce a pilot experiment to explore a few of the functions served by pointing and related hand movements.
 I conclude with a short account of some of the principles underpinning complementary strategies.
 Complementary strategies Imagine being shown an upside down photograph and asked to identify the person depicted.
 Your natural action is to reach out and turn the picture right side up.
 Faces are more readily recognized when upright.
 Apparently, to facilitate perception, we perform an action that adapts the world to our perceptual capacities.
 This idea  that sometimes the best way to solve a cognitive problem is by adapting the world rather than adapting oneself — lies at the heart of complementary strategies.
 212 http://ucsd.
eduI believe we leam these adaptational strategies by the thousands.
 For example, if an agent were given the task of memorizing the letters of a string, such as Q I U Y O K J H U Y T O G U , first without touching the letters, then with touch and rearrangonent allowed, it is likely that he or she would discover a method of moving the letters to reliably increase performance.
 One such lettermoving technique would be to shift the letters into groupings, such as Q I U Y O K J H U Y T O G U .
 Another, more radical technique, would be to reorder the letters in alphabetical order, such as G H I J K O O Q T U U U Y Y .
 In any such activity there is a tradeoff: the cost in time and effort to perform the complementary activity in the world vs.
 the time and effort to use existing mental procedures and strategies to accomplish the task without external aid.
 (Kirsh, 95).
 More factors are involved in the choice of a complementary strategy than just speed, however.
 In addition to (potentially) faster performance the virtue of such strategies is that by changing the local environment ~ at the right time and in the right way ~ agents are able to reduce the probable error rate, to cope with larger, more complex problems, and to deal with interference more successfully  all typical measures of performance, and indicators of the cognitive demands a task imposes.
 Complementary strategies, therefore, allow agents to compensate for resource limitations in working memory and processing power, and cognitive limitations in categorizing skill, and so on.
 (Backman et al, 92).
 The objective of research on complementary strategies is to expose the ubiquity of these strategies  particularly those that are spontaneously displayed by subjects ~ to describe the key tradeoffs, such as speedaccuracy, speedproblem size, speedrobustness, and to explain these in terms of an underlying processing account describing the way mental resources are used.
 If complementary strategies are pervasive, there ought to be general principles governing the shape of tradeoff curves for successful complementation strategies.
 A Simple Coin Counting Experiment: To observe how complementary strategies enhance performance, a simple pilot experiment was performed.
 Three male and two female subjects (age 2338, mean 26) were shown two sets of 30 images, each depicting a different arrangement of quarters, dimes and nickels.
 Their task was to determine the dollar and cents amount present.
 See figure 1.
 In condition one, the no hands condition, subjects were told not to point at the coin images, or to move their hands.
 In condition two, the hands condition, they were allowed to use their hands and fingers to point or count They were instructed to sum the coins as quickly as possible, but to make every effort to give the correct answer.
 The results showing the mean time taken to announce a sum, hereafter time, and the mean number of mistaken sums, hereafter errors, are given in figure 2.
 O n average subjects took 22.
5 sec in no hands and 18.
7 sec in hands to announce their answer, and they were mistaken in no hands 6 8 % or 20.
3 out of 30 stimuli, (p<.
4), and in hands 4 2 % or 12.
6 out of 30 stimuli, (p<.
4).
 ® ® ® ( 2 5 ) ® @ @ @ ® ® 25; ® @ ® @ ® Figure 1.
 To get a sense of the problem, count the coins depicted in figure 1: first without using your hands and then count them using your fingers and bands.
 The difficulty in keeping track of which coins one has counted makes pointing a useful complementary strategy.
 Subjects who have to count real coins can use more powerful complementary strategies such as clustering the coins into denominations, or pushing them off to one side as they are counted.
 These are familiar complementary strategies which occur naturally.
 But the experiment reported here did not use real coins or permit physical rearrangement.
 The results of the experiment are shown in figure 2.
 H a n d s Improve Performance Errors Figure 2.
 Three features of this simple experiment deserve special mention.
 First, each subject was tested on a random selection of 30 stimuli in each condition.
 The number of coins displayed was a random selection of nickels, dimes and quarters totaling anywhere from 21 to 31 coins, (mean of 26), and the number of coins was matched across 213 conditions, so that each subject summed three sets of 21,22 .
.
31 coins in no hands (totaling 30 stimuli) and three sets of 21,22 .
.
 31 coins in hands (totaling 30 stimuli).
 All S's saw the same 60 stimuli, which were sufficient to yield significant differences in mean error (p < .
04) and mean speed (p <.
04) for each individual subject.
 Second, there was clear evidence that subjects evolved strategies microgenetically.
 During the fu^t 2 0 % of trials, or so, every subject appeared to be experimenting with different techniques, (this view was confirmed in verbal reports in the debriefing).
 Later a dominant strategy was selected, and was then used for the rest of the trials in that condition.
 Once a comfortable strategy was found, subjects usually continued using it even when the condition changed.
 Thus, when subjects were tested fu^t on no hands, then on hands, the complementary strategy used in hands was geared to help the basic strategy settled on in no bands.
 Hence the term complementary strategy: performing external actions that complement internal actions.
 There was verbal support evidence of this pattern of setting a strategy to be used in both conditions even for subjects who were given the hands condition first.
 These subjects reported trying to count without hands in a manner that resembled the way they had counted with hands.
 Third, given the complexity of the phenomena being studied, any claims about what is occurring during the microgenetic phase, and bow a complementary strategy comes into being, must be speculative at best Clearly, subjects are aware of trying out new strategies, both mental and complementary strategies.
 But w e cannot say how they think up new strategies, or why they settle on one strategy rather than continue looking for better ones.
 Despite this limitation, it is clear that a minimal theory of complementary strategy should provide a set of theoretical principles powerful enough to explain why any particular complementary strategy succeeds or fails in terms of the mental resources and mental strategies used.
 Complementing Visual Strategies In order to evaluate how helpful a complementary strategy is, w e must have some idea of the mental strategy it is complementing.
 The theory of visual routines (Ullman 1985) provides the starting place for a framework for discussing certain mental strategies.
 It offers an account of the basic computational operations available to a subject for selecting and manipulating elements of a scene, and is therefore a natural place to begin a theory about visually counting.
 The basic idea is that visual routines are procedures or programs that use primitive visual operations to idenUfy a target property.
 The flexibility this gives the visual system is that properties invented on the fly, such as a group of four quarters not yet counted, can become targets for systematic visual search.
 In Ulbnan's study there is no explanation of the processes which shape the evolution of visual routines.
 Nor is there any account of how limitations on nonvisual memory constrain the type of visual routines that may exist The theory of visual routines, accordingly, does not explain how the need to remember intermediate values, such as the dollar value of quarters, or dimes, helps to shape visual strategies for counting.
 Ultimately, the plan an agent settles on must be responsive to 'nonvisual' constraints as well.
 Thus, if the plan is to first count quarters in fours, then add dimes incrementally to the dollar value of quarters, then add nickels, we should see this not as a purely visual strategy, but as a mixed strategy, one that is sensitive both to the visual skills and visual memory limitations of the agent, and the nonvisual memory skills and limitations of the agent.
 In figure 3 the mixed strategy of subject SR is depicted.
 Of all subjects, S R displayed the most significant improvement in performance in the two conditions.
 What is revealing about SR's approach is that his mental strategy regularly called for memory of more visual markers than he could recall.
 By substituting certain external actions be was able to reduce demands on visual memory enough to reduce errors by 6 0 % and increase speed by 2 0 % .
 In the debriefmg, S R described his strategy like this: First, I count the quarters by grouping them into fours in a sort of clockwise manner, if that is natural If the quarters total an odd number, such as $2.
75, I look around for a nickel to use to put the total to an even number, $2.
80, so that I can runv add the dimes easily, by just adding ten to what is really an easier number to work with i.
e.
 280 instead of 275.
 I then add nickels in groups of two.
 I found that if I had 'stolen' a nickel I would often forget where it was.
 So when I use my hands, I put my thumb on the stolen nickel This helped a lot.
 Then, when it came time to count nickels, I could use two fingers from my other hand to point to the two I was on, and so add my two nickels easily.
 In what follows I will discuss some of the benefits SR reaped with this curious strategy, and tie the discussion to more general notions of memory, perception and attention.
 214 current focus marked, center ojc 4 quarter set Stolen nickel Figure 3a N o Hand Strategy currentfocus ® @ Figure 3b Hand Strategy Figure 3a is an attempt to represent SR's no hand or mental strategy.
 Figure 3b portrays his hand or complementary strategy.
 The symbols n s 1 X and + are used to indicate the visual markers proposed by Ullman, and the closed curves mark subitized regions.
 In 3a, S R has counted all the quarters and is about to start on the dimes.
 H e began his mental counting by subitizing the four quarters in the upper left quadrant and marking the center of that set of 4 quarters with his first visual marker, represented by s .
 His next step was to subitize a second group of 4 quarters, this time in the upper right quadrant, and mark the set by +.
 Three quarters remain, all in the lower left, and these he counted and marked with n.
 Having now found $2.
75 worth of quarters he proceeded to steal' a nickel to make a sum of $2.
80, and marked the stolen nickel with his fourth marker 1.
 He then turned his attention to dimes, again beginning in the upper left quadrant.
 To keep his attention on that location he marked that target with his final marker, X In 3b, S R makes use of his left forefinger to mark the location of the stolen nickel and so to liberate one of the markers for additional use.
 In his oral account, S R also described using his right hand to help count nickels in twos.
 But that action is not shown here Memory The most obvious cognitive burden subjects encounter in the counting experiment is to remember intermediate sums.
 It is easy to drop a digit in counting  'am I at 285 or 385?' Some subjects' response to this problem was to partially count with their fingers.
 Subject JD, for instance, would encode the current dollar value on her fingers so that all mental counting could be done using one or two digits.
 Thus, rather than mentally counting with three digits as in 275, 285, 295, 305, she would extend two fingers and count 75, 85, 95, extend a third finger and count 5.
 This reduced JD's working memory loads.
 SR's strategy was equally effective but more baroque.
 By stealing a nickel to convert odd valued amounts (275) to even ones (280), SR achieved the same economizing in working memory as subject JD did but without reducing digit length.
 His trick was to limit the phonological complexity of the numeral he had to continually update.
 The number of syllables kept in the articulatory loop (Baddelly) is greater for twoseventyfive than for twoeighty despite both 275 and 280 being three digits long.
 Thus, although SR seemed to be using three digit numbers whereas JD seemed to be using two digit numbers, both used equisyllabic numbers, e.
g.
 twentyseven vs.
 twoseventy.
 Memory savings in syllable length also translate fairly directly into savings in processing time.
 Presumably, one of the potential limitations on counting speed is the time needed — to mentally utter twentyseven ~ that is, to encode updated sums in articulatory memory.
 Accordingly, how fast one can count partly depends on the length of time it takes to mentally utter the numbers.
 Any reduction in syllable size translates to a reduction in counting time.
 (Baddeley et al, 84).
 Hence, SR's technique saved both time and memory.
 Another savings in working memory produced by SR's technique, stems from shifting items out of working memory to long term memory.
 S R suggested that his greatest memory savings came from placing his thumb over the stolen nickel, for now he no longer had to remember both whether he had stolen a nickel, and which particular nickel to avoid counting.
 Prima facie the function of this external marker is to liberate an internal marker.
 But arguably the real savings lies elsewhere.
 For presumably, regardless of whether an agent keeps an internal visual marker on a mental representation of a nickel, or an external finger marker on a physical nickel, he still must keep in some portion of memory the meaning of the marker  here lies the stolen nickel.
 In the case of internal visual markers, these labels must be in some pan of working memory, for the markers are created on the fly with potentially ad hoc meanings.
 In the case of external marking, however, the meaning of one's thumb on a coin 215 may become conventional, hence drawn from long term memory.
 Managing Attention One easily forgettable feature of attention is that its management is either highly practiced and automatic, or is driven by a program resident in W M .
 It takes memory to remember the strategy one is currently following.
 A further consequence of SR's technique of marking the stolen nickel is that it reduces the memory costs associated with running the attentional strategy.
 T o see this, return to the function achieved by pointing to the stolen nickel.
 From a purely logical point of view there is no reason to point to one nickel rather than another.
 The informational function of hiding a nickel is to mark the fact that a nickel, any nickel, has been counted already.
 This function could equally well be achieved by holding one's nose.
 But, from SR's oral accounts it was clear that he did not point to a random nickel, and clear, moreover, that when it came time to count nickels, he would intentionally avoid counting the marked nickel.
 This is not simply idiosyncratic.
 The action is adaptive.
 For had S R not bidden a particular nickel, he would be forced to choose a particular nickel to overlook.
 That is, he would have had to survey all nickels, and recall that bis finger being extended meant that one nickel should be ignored.
 The judgment of which nickel to ignore, however, can be eliminated if a specific nickel is occluded.
 Accordingly, if SR's finger serves an occluding rather than a marking function, S R will have fewer regions to attend to since he will know which region to ignore.
 This saves him from following a visual instruction such as, go to that region but ignore the mentally marked nickel.
 That is, by occluding a nickel, S R is able to reduce the number of distracters he must deal with, and reduce the mental oveibead of following an attentional strategy.
 Helping Perception Although pointing and marking can obviously help to direct attention and help to save the use of visual markers, there are several purely perceptual functions they may serve as well.
 Chief among these is changing the context of observation.
 In placing one's finger on a surface, the set of items in view is altered.
 For example, imagine a subject asked to count the following string of dots To help fixate on one dot at a time, and reduce the interference from neighboring dots, a subject will naturally want to use a finger or pencil to help keep place.
 Belying this simple complementary strategy, however, is a sly trick: for by pointing a pencil tip at a dot, and moving it up one dot at a time, one is effectively counting the number of pencil moves, rather A / \ \ / than the number of dots.
 The dots are still too small to count directly, but not too small to touch one by one with an instrument.
 Even more compelling is the way adding a feature can alter the static gestalt properties of a \ / figure.
 For instance, in the Mueller V Lyer illusion it is easy to defeat the appearance of unequal lines by placing one's finger over the V portion of one of the lines and visually lining up the tops.
 W h y do these actions work? H o w is our visual field affected? A n adequate theory of complementary strategy would recruit enough psychophysical theory to explain the mechanism at woric, and the likely decrease in error rate.
 Conclusion Intelligent creatures amplify their cognitive abilities by adapting their environments of action to environments where they can get the best results from their limited cognitive resources.
 A neglected aspect of this ad£q)tive faculty concerns the way hands, fmgers and surrounding material objects are recruited for cognitive use.
 In this paper a simple experiment was presented to show that the performance benefits of such spontaneously created strategies  complementary strategies  can be readily measured empirically.
 To properly understand the basis of these performance improvements, it is necessary to understand the way various external actions fit into an overall strategy of computation.
 This requires identifying mental functions served by external actions and changes, and enumerating the resources saved in specific cognitive components such as visual memory, articulatory loop, attention and perceptual control.
 I have done no more than gesture at the range and complexity of these savings here, but the need to explore complementary strategies should be evident.
 A c k n o w l e d g e m e n t s I am grateful for comments by Marta Kutas, and Paul Maglio on earlier drafts.
 This research is partially funded by NIA grant A G 11851.
.
 216 Bibliography Hutchins, E.
 1995.
 Cognition in the wild,.
 MTT Press Cambridge, MA.
 Kirsh.
 D.
 and Maglio, P.
, 1994.
 On distinguishing Baddeley, A.
 D.
 and Lewis, V.
 J.
 and Vallar, G.
 1984.
 epistemic from pragmatic action.
 Cognitive Science, 18: Exploring the articulatory loop, Quarterly Journal of 513549.
 Experimental Psychology, 36: 233252.
 Kirsh, D.
, 1995.
 The intelligent use of space.
 Artificial Backman, Lars, Dixon, Roger A.
 1992.
 Psychological Intelligence, 73: 3168.
 compensation: A theoretical framework.
 Psychological Lave, J.
 1988.
 Cognition in practice, Cambridge, England, Bulletin, vl 12(n2):259283.
 Cambridge University Press.
 Ulhnan, S.
, 1984.
 Visual routines Cogmtion, 18: 97159.
 217 A Computational M o d e l of D i a g r a m Reading and Reasoning Anthony M.
 Leonardo^ Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 leonardo+@cinu.
 edu Hermina J.
M.
 Tabachneck HCl Institute School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213 tabachneck+ecmu.
edu Herbert A.
 Simon Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 hashes.
emu.
edu Abstract We describe an extension of CaMeRa, a Computational model of M.
ultiple Kepresentations in problem solving (Tabachneck, Leonardo.
 & Simon, 1994, 1995).
 CaMeRa provides a genera] architecture for LTM, S T M and their interactions, and illustrates how experts integrate pictorial and verbcd reasoning processes while solving problems.
 A linked production system and parallel network are used to further resolve the communication between pictorial and verbal knowledge by simulating how a diagram is understood by an expert.
 Lowlevel scanning processes and an attention window, based on both psychological and biological evidence, are incorporated into CaMeRa, and productions are developed that allow these processes to interface with the highlevel visual rules and representations already in the model.
 These processes can explain interruptibility during problem solving, and show how understanding is reached when reading a novel diagram.
 Introduction While an expert is solving a problem in economics, there is a knock at the door.
 She answers it, and is drawn by a colleague into a conversation about new astrophysical data suggesting the existence of a black hole of forty million solar masses.
 Eventually her friend leaves, and the expert returns to her desk, somewhat muddled.
 But after glancing only briefly at the economics diagram she had been drawing, she immediately resumes where she left off, as if the interruption had never occurred.
 The contents of her shortterm memory were written and rewritten many times during the course of the distracting discussion.
 All she has left from her previous efforts are a sketchy diagram, a few carelessly scrawled equations, and the contents of her longterm memory.
 Yet she does not have to begin the problem anew, or even take much time to reconstruct her position prior to the interruption.
 She is able to resume working quickly, at the correct place in the problem solving sequence.
 H o w is such a feat accomplished? ^Address after September 1, 1995: Computation and Neural Systems Program; California Institute of Technology; Pasadena, C A 91125 USA Clearly, a number of factors are at play ~ the features of the diagram, the processes of recognition, longterm memory ( L T M ) , and shortterm memory (STM).
 This interruption task is a good example of the fact that recognition is faster than recall.
 W h e n beginning the problem, the expert must recall everything from longterm memory.
 W h e n reconstructing her position after the interruption, she needs only to recognize the meanings of the various cues on the diagram and the associations between them.
 A properly built diagram summarizes all the critical information processed thus far, and reasoning can be continued as long as this external summary is available.
 Recognizing a diagram's components is necessary both for reconstructing the meaning of a diagram and for understanding a novel diagram.
 In each case, perceptually significant features must be identified.
 These features must be scanned into S T M using lowlevel visual processes.
 Finally, the information in S T M must be matched to information in L T M (if it exists) and analyzed for its implications.
 In this paper, w e will present a computational model which simulates each step of this process, basing the implementation of each process on both psychological and biological evidence.
 The remainder of the paper will make each of these steps specific, and fmally, present a framework in which they come together to produce the behaviors described above.
 CaMeRa C a M e R a is a computational model of the use of multiple representations in expert problem solving (Tabachneck, Leonardo, & Simon, 1994, 1995).
 It demonstrates how an economics expert, by carefully combining pictorial and verbal knowledge, is able to produce a coherent and effective explanation to problems that novices are unable to understand.
 The work described in this paper represents an extension of CaMe R a .
 One of the motivations for this research, in addition to giving an account of the behaviors described above, was to expand CaMeRa's abilities by providing it with processes for reading diagrams and pictures.
 This wiU ultimately allow the model to understand problems from many different domains.
 C a M e R a consists of a linked production system and parallel network.
 It contains representations of (1) a pictorial external display, (2) pictorial shortterm memory, (3) pictorial longterm memory, (4) verbal shortterm 218 Input through lowlevel vUiial ^ perceptual processes External Display (The Blackboard) Spatial NodeLink Relation Node Relations Visual Buffer Object NodeLinic Pictorial Short Term M e m o r y (The Mind's Eye) Pictorial Long Term Memory Not Implemented—I l::':;'X;:::::x2i:;Input through lowlevel auditory perceptual processes 4 I I t I I I I t (t ) Proposidonal List Structures Verbal Short Term M e m o r y (The Mind's Ear) (PropoiUionat A Liit Struelttrei J Verbal Long Term Memory — — — — access information ' access and modify information Figure 1: The Architecture of C a M e R a memory, and (5) verbal longterm memory (see Figure 1).
 The model uses the external display (the "blackboard") just as the expert does, for drawing, reasoning, recognition, and input to S T M .
 Recognition consists of matching information placed in S T M from the blackboard to information stored in L T M .
 Because the recognition of cues on the blackboard drives the problem solving forward, CaMeRa has little need for an explicit goal stack.
 This type of control architecture places a minimal load on shortterm memory capacity.
 Pictorial longterm memory (pLTM) has a nodelink representation.
 Verbal longterm m e m o r y ( v L T M ) knowledge is represented by instances of a generic propositionaJ relation.
 This single relation was sufficient to model all of the knowledge needed by C a M e R a in the limited economics domain we examined.
 L T M knowledge is represented in the brain as associations among symbols, with structure and hierarchy being a function of these associations.
 The images which are generated from p L T M are computationally equivalent to those generated from perception, as are the processes which operate on them (Kosslyn, 1994).
 The same applies for v L T M .
 All problem solving, reasoning, and modification of memory systems are done through S T M .
 CaMeRa's current S T M does not yet have any limitations on the quantity of information it can store (for more on S T M capacity, see Simon, 1976).
 Implementing the diagramreading processes will allow us to model the capacity limits of S T M in C a M e R a at a later time, as the blackboard can now be used to refresh S T M through constant lowlevel scanning of the diagram.
 S T M structures can be defined as specific exemplars of L T M structures.
 They may also be associated with S T M strucnires in their own and other modalities.
 The highly regulated and limited interaction that takes place between p S T M and v S T M , allowing for these associations to emerge, is a critical feature of the model (see Tabachneck, Leonardo, & Simon, 1994, 1995).
 The Mind's Eye (MI) represents a synthesis of a number of pictorial shortterm memory data structures and the productions that operate on them.
 Three types of representations appear in the M I : the visual buffer, object structures, and spatial structures.
 The visual buffer, which is the physical location of mental images, is the area in which feanire extraction and other lowlevel, highly parallel, visual processes operate.
 The projection of an image onto the visual buffer facilitates complex visual reasoning which could not be done using only the object and spatial structures of S T M (e.
g.
, the perception of geometrical relations, etc.
).
 As the visual buffer is the focus of much of our improvements to Ca M e R a , its properties will be further specified in the following section.
 The remaining two structures are used to simulate the interaction between two of the visual subsystems of the brain, namely the spatial 219 properties of the object (location, distiuice, etc.
, represented in the posterior parietal lobes), and the form properties of the object (shape, color, size; represented in the inferior temporal lobes) (Farah, 1990).
 The Mind's Ear (ME) is a combination of the verbal shorttenn memory data representations and the productions that operate on thein.
 It contiiins knowledge represented as propositional list structures, like its v L T M counterpart.
 Diagram Reading The visual buffer is the geometrically organized, multilayered bitmap representation of pictorial S T M .
 It contains images generated from light striking the retina, and from internal p S T M and p L T M structures.
 Feature extraction and simple recognition take place in the visual buffer, analogous to computations being performed in the early visual cortex (Kosslyn & Koneig, 1992; Kosslyn.
 1994).
 Because it is represented as a bitmap, CaMeRa's visual buffer exhibits a topographic organization similar to that of the visual cortex.
 Perception results from using a feedforward parallel network to perform the feature extraction, and Gestalt principles to use these features to scan the buffer for structure and form.
 1 aver 1 fl(Oi) = 1 if Oi on 0 if Ui off Layer 2 f2(Ui)= ^SUM[8 units around Ui in layer 1] Q = units which project to Ui in the next layer — •̂ : r: i ^ \ Layer 3 V ^ N v m f3 (Ui) = 1 [Ui / A(n, Ui) ]  1 I A(n, Ui) = the average activation of n layers of units around unit Ui Figure 2: Topology Parallel Network The network functions by perceiving nonmodal areas in the local topology of the object.
 As all connections between pixels on the bitmap are presumed to be of equal, positive weight, no training is necessary.
 By detecting points that depart from the local modal value, the network identifies all perceptually significant areas on the visual buffer'.
 This is accomplished through the three layered process depicted in Figure 2.
 ' W e have recently learned that the topology network is similar to a class of pyramidbased segmentation techniques developed for computer vision by Rosenfeld (1986, 1988).
 It also has parallels to the methods devised by Marr (1982).
 The first layer of the visual buffer represents information projected directly into the brain from the external world.
 Pixels are either on (activation = 1) or off (activation = 0).
 The first filtering process sums the activations of all units iiround a given unit U i ; this summation is the activation of Ui in layer 2.
 For example, if the input was a 3x3 square, the activation of the center of the square in the second layer of the visual buffer would be eight (one for each of the eight units surrounding the center point).
 The processing in the first layer builds a representation of the topology of the object.
 Points in clusters mutually increase each other's activations, while isolated points retain only their initial activation.
 Processes in the second layer determine which areas of the entire topology are the most significant, by calculating how similar the activation of unit Ui is to the average activation of its local area.
 The function A(n, Ui) gives the average activation of the local area around Ui (a square array of length n) in layer 2.
 Ui is turned on in the third layer if its the ratio of its activation to A(n, Ui) exceeds the threshold /: U.
 Ain,U,)  1 > t Consequently, if the activation of Ui in layer 2 equals the average activation of its local area, Ui's activation in layer 3 will be zero  it is not perceptually significant as it can not be distinguished from the points surrounding it.
 The result of this process is a saliency map in layer 3 of all the perceptually significant features found in the image on the visual buffer, such as intersection points, line endpoints, labels, object outlines.
 The coordinates of these points are sent to the highlevel object and spatial representations of the pictorial S T M for further processing.
 Productions may then request the visual buffer to identify a specific feature by matching the foveasized area around the point to patterns stored in pictorial L T M , or to scan a line or other object by applying gestalt principles.
 W e have chosen to implement the network in this fashion for two reasons  i) it is more cognitively plausible than other AI feature extraction mechanisms, and ii) we were unable to perform the feature extraction successfully with these other mechanisms.
 For example, matching small areas of the diagram to a finite set of feature patterns will not identify the salient points because it runs into the problem of computational overload  countless variations of the same pattern are needed to recognize tiny perturbations in the original image.
 The topology network circumvents this dilemma.
 In short, our path solves the problem effectively, and has some features in common with what is known of the relevant neurology.
 However, we refer to CaMeRa's lowlevel perceptual system as a "parallel network" to emphasize that its components are units, not neurons, and while its architecture has certain similarities to the visual cortex, it is not a model of this brain area.
 It should be kept in mind that there is no mathematical basis for assuming that the functional properties of a real neuron are preserved in the abstraction to a formless connectionist unit.
 W e assume that the results of the topology network 220 are computed somewhere in the visual cortex, but most likely through different mechanisms than we have used here.
 After the perceptually significant areas on the visual buffer are determined, the entire image is recognized as a set of associated objects, using gestaltist lowlevel rules of organization.
 C a M e R a employs Good Continuation, Good Form, Proximity, and Familiarity (Goldstein, 1984).
 Rules related to motion, convexity, etc.
.
 were not required in our tasks.
 W e have implemented these serially, rather than in parallel, because the serial design captured the relevant cognitive principles in a lucid and explainable manner.
 To coordinate the four gestalt rules, the model first saccades to the closest perceptually significant point on the visual buffer.
 This is the point in layer 3 which is the shortest disuince from CaMeRa's current focus of attention.
 It then determines whether the small area of CaMeRa's fovea surrounding this point contains a familiar pattern.
 If the fovea's contents match a pictorial L T M pattern, action is taken.
 For example, a label (an icon) causes a structure to be created in p S T M to represent it.
 A line segment evokes Good Continuation and Good Form.
 This causes the model to focus its attention on the nearest endpoint of the line, and then scan the entire line through a series of short saccades.
 Individual lines are processed by looking at the points near the initijil line segment feature, applying the rules of Good Continuation and Good Form, and thereby following the simplest connected path.
 If a salient point falls into the attention window as C a M e R a scans the line, it immediately focuses on that point and processes the area around it for familiar patterns, which are then associated with the line through Proximity.
 Finally, if a point in the fovea is not recognized, or processing on it has been completed, the model focuses on the nearest perceptually significant feature.
 Using feedback from the results of these computations, the model keeps track of the salient points it has already seen, juid thus avoids reprocessing them.
 As it scans, CaMeRa removes each feature it processes from layer 3 of the visual buffer, continually shifting its attention to unprocessed points, and elaborating further its representation of the diagram.
 Mozer et al.
 (1992; see also Behrmann, Zemel, & Mozer, 1995) have designed a connectionist model of object segmentation based on the phaselocking of related features, which develops the properties of some of the gestalt rules we employ.
 Comparison of the behavior of the two systems suggests that many of the differences between our serial design and a parallel one m a y be only implementational and not functional.
 In further support of this point, although C a M e R a was not intended to segment images, it has the capability to do so by virtue of the iirchitecture of its visual buffer and the processes that operate on it.
 C a M e R a is able to discriminate the component lines of geometrical objects (squares, diamonds, triangles, etc.
) that are overlaid on each other (so far we have tested up to four overiaid objects).
 These lines could be bound into appropriately segmented objects by implementing the gestalt rule of Closure.
 W e have based the implementation of CaMeRa's fovea and attention window on biological and psychological data as much as possible.
 CaMeRa's fovea is the area within which it can see high levels of detail and recognize patterns.
 This is intended to correspond to the central area of the eye where almost all of the cones are located (Humphreys & Bruce, 1991), subtending about one degree of visual angle.
 This corresponds to a circle of approximately six letters in diiuneter at a reading distance of 15 inches.
 It is less clear how to set the size of the attention window: if too small, it is useless for detecting features close to a point in focus; if too large, the model is frequently distracted and unable to scan consistently.
 W e have chosen a size of three fovea diameters, a magnitude that allows fairly smooth and efficient processing of the image.
 The attention productions that control the movement of the fovea and attention window always cause the two to move in unison  the center of the attention window is always at the center of the fovea.
 However, C a M e R a will eventually be modified to allow the focus of attention to be outside the fovea.
 Diagram Understanding Figure 3 illustrates how C a M e R a would read a diagram.
 The time series contains a sequence of four images exactly as they would appear on the computer screen as C a M e R a processes the diagram.
 In 3a, the model has identified all the perceptually significant points on the graph (small clusters and isolated points), and has projected them onto layer 3 of the visual buffer.
 CaMeRa's fovea and attention window are focused on the upper lefthand comer of the diagram, its default starting position.
 The model will now shift its attention to the closest meaningful feature, in this case, the endpoint of the Price axis (arrow, 3a).
 Next, C a M e R a will try to match the fovea sized area around this point to patterns it has stored in p L T M .
 The match is successful, and the point is identified as part of a vertical line segment, evoking Good Continuation and Good Form.
 C a M e R a now scans in the entire vertical line through a series of saccades.
 Figure 3b illustrates part of this event ~ it has written to the text screen that a vertical line (VLINE) has been found.
 The fovea and attention window are now midway down the line, approaching the lower endpoint.
 While C a M e R a is scanning the image, the fovea and attention window in figure 3 move dynamically, giving the observer a clear understanding of what the model is doing at each moment.
 Upon processing the vertical line, C a M e R a creates a spatial structure in p S T M for the endpoints of the line, and an object structure in p S T M for the form of the line (represented as an equation).
 This is shown in 3c as "VLINE (15 15 15 135)".
 Then, C a M e R a focuses its attention on the closest point of interest, in this case the endpoint of the supply Une.
 Again, C a M e R a will recognize this as part of a diagonal line, and will scan the entire supply line (arrow, 3c).
 Finally, 3d shows the model as it finishes scanning the supply line, and notices near the line endpoint a cluster of significant points.
 It focuses on these points, recognizing the label for the supply Une.
 This label is associated with the diagonal line which was just processed, using Proximity.
 To return to the example cited in the introduction, how would C a M e R a resume problem solving after being 221 Visual Ituffir I.
 C a M e R a i>h> MmihI lliitTir I < aMiKa Visual Buffer L3 Visual Buffer L3 After identifying all perceptually significant points on the visual buffer, C a M e R a focuses its attention on the closest of these points, indicated bj the arrow.
 • .
• •'>.
 sSifiSiiSv3 C t aMcRa OL.
NE .
 13 15 15 133: After identifying both endpoints of the \ertjcal line, C a M e R a shifts its attention to the next closest point salient point, and attempts to match this area to patterns stored in L T M .
 It recognizes a diagonal line segment, and acts to scan the entire line in a series of saccades.
 Visual Buffer L Visual Buffer L3 C a M e R a identifies this point as part of a vertical line segment, and begins to scan in the entire line using the gestalt rule of good continuation.
 IB li W o Ca M e R a ( rmatifirapU > ULINE <15 15 15 135) nLINE_2 (30 120 IJO 30) SUPPLV.
l As it reaches the second endpoint of the diagonal line, CaMeRa notices additional signiricant points falling within Its attention window.
 It saccades to this area and recognizes the Supply Line label, || which it associates with the diagonal line.
 Visual Buffer LI Visual Buffer L3 Figure 3: Diagram Reading T i m e Series interrupted? This process can be simulated by allowing C a M e R a to reach a certain depth in the problem solving sequence, and then erasing the contents of S T M .
 T o continue processing, C a M e R a must n o w rescan the diagram it has drawn, using the processes described above.
 A s the lowlevel functions read in data and interact with the highlevel S T M productions, the lost contents of S T M could be quickly reconstructed.
 With a novel diagram, the system would try to match the scanned objects to objects in L T M as best it could.
 A partial explanation, emerging from successful L T M matches, in conjunction with inference processes, would produce an interpretation of the diagram.
 A s an image is scanned into p S T M through the lowlevel visual processes described above, the higherlevel productions activate and elaborate the reasoning chain.
 W h e n the system has c o m e to rest, the lowlevel processing would continue where they had left off and more input would be sent to S T M until further highlevel processing could take place.
 Hybrid Models By combining a feedforward parallel network and a production system in its architecture, C a M e Ra demonstrates that hybrid models can be extremely advantageous in modeling complex cognitive tasks.
 Previous hybrid models have tended to focus on artificial intelligence problems, with limited concern for cognitive plausibility.
 For example, A L V I N N , developed by Pomerleau, G o w d y & Thorpe (1991), enables a robot to perform autonomous navigation.
 Other types of hybrid models include expert systems with dual production and neural network knowledge bases (Rose, 1990), and spreadingactivation semantic networks (Just & 222 file:///ertjcalCarpenter, 1992; Lange et al.
, 1990), used to simulate a cognitive theory of language processing^ W e believe that certain tasks are best accomplished and understood within a serial design, while others ;uc more suited to a parallel one.
 W e found that a serial feature detection algorithm was slow and ineffective, whereas a parallel one was highly efficient.
 Likewise, we could have designed small parallel networks for each of the gestalt principles, but these would have produced results identical to those of their production rule counterparts, while yielding a significant increase in design complexity and only a minimal increase in structural plausibility.
 Our goal has been to develop a clear account of the cognitive processes involved in expert reasoning.
 Combining serial and parallel methodologies, as we have in CaMeRa, allows one to build more sophisticated simulations by both broadening the potential task domain and facilitating implementation and analysis of the system.
 ConclusloD CaMeRa is a cognitive model of the interaction of visual and verbal elements in reasoning.
 In this paper, we have described a parallel network that extends CaMeRa's capabilities into a cognitively plausible model of the basic structure of visual perception.
 The model is able to construct, read, and reason about diagrams, using both verbal and visual information.
 Frequent interaction between highlevel and lowlevel visual processes allows CaMeRa to build an elaborate representation of the diagrams it is reading.
 Employing both a production system and a parallel network has allowed us to develop a computational model which would be extremely difficult to design in either of these frameworks alone.
 Acknowledgments The second author was supported by a James S.
 McDonnell Foundation Cognition in Education Postdoctoral Fellowship, grant # 925.
 References Behrmann, M.
, Zemel, R.
, & Mozer, M.
 (1995).
 Objectbased segmentation and occlusion: Evidence from normal subjects and a computational model.
 In press.
 Farah, M.
J.
 (1990).
 Visual Agnosia: Disorders of Object Recognition and what they tell us about Normal Vision.
 Cambridge, M A : MIT Press.
 Goldstein, B.
E.
 (1989).
 Sensation and Perception.
 Belmont, CA: Wadsworth Publishing Company.
 Humphreys, G.
W.
 & Bruce, V.
 (1991).
 Visual Cognition.
 London, UK: Lawrence Erlbaum Associates.
 Just, M.
A.
 & Carpenter, P.
A.
 (1992).
 A Capacity Theory of Comprehension: Individual Differences in Working Memory.
 Psychological Review, 99(1), 122149.
 Kosslyn, S.
M.
 (1994).
 Image and Brain: The Resolution of the Imagery Debate.
 Cambridge, M A : MIT Press.
 Kosslyn, S.
M.
 & Koenig, O.
 (1992).
 Wet Mind: the new cognitive neuroscience.
 N e w York, N.
Y.
: The Free Press.
 Lange, T.
.
 Melz, E.
, Wharton, C.
 & Holyoak, K.
 (1990).
 Analogical Retrieval Within a Hybrid SpreadingActivation Network.
 In Proceedings of the 1990 Summer School for Connectionist Models (pp.
 65276).
 San Mateo, CA: Morgan Kauffman Publishers.
 Marr, D.
 (1982).
 Vision.
 San Francisco, CA: W.
H.
 Freeman.
 Mozer, M.
I.
, Zemel, R.
S.
, Behrmann, M.
 & Williams, C.
K.
 (1992).
 Learning to Segment Images Using Dynamic Feature Binding.
 Neural Computation, 4, 650665.
 Pomerleau, D.
A.
, Gowdy, J.
 «& Thorpe, C.
E.
 (1991).
 Combining Artificial Neural Networks and Symbolic Processes for Autonomous Robot Guidance.
 Engineering Applications of Artificial Intelligence, 4:4 pp 279285.
 Rose, D.
 (1990).
 Appropriate Uses of Hybrid Systems.
 In Proceedings of the 1990 Summer School for Connectionist Models (pp.
 277286).
 San Mateo, CA: Morgan Kauffman Publishers.
 Rosenfeld, A.
 (1986).
 Some Pyramid Techniques for Image Segmentation (CSTR1664).
 Maryland: University of Maryland, College Park, Center for Automation Research.
 Rosenfeld, A.
 (1988).
 Computer Vision: A Source of Models for Biological Visual Processes? (CSTR1971).
 Maryland: University of Maryland, College Park, Center for Automation Research.
 Simon, H.
A.
 (1976).
 The Informarion Storage System Called Human Memory.
 In Models of Thought, Volume I.
 New Haven: Yale University Press.
 Sun, R.
 & Bookman, L.
A.
 (1995).
 Computational Architectures Integrating Neural and Symbolic Processes: A Perspective on the State of the Art.
 Boston, M A : Kluwer Academic Publishers.
 Tabachneck, H.
J.
M.
, Leonardo, A.
 & Simon, H.
 A.
 (1994).
 H o w does an expert use a graph? A model of visual and verbal inferencing in Economics.
 In Proceedings of the 16th Annual Meeting of the Cognitive Science Society.
 Hillsdale, NJ: Lawerance Erlbaum Associates.
 Tabachneck, H.
J.
M.
, Leonardo, A.
 & Simon, H.
A.
 (1995).
 H o w does an expert use a graph? A Computational Model of Multiple Representations.
 Submitted for Publication.
 Âdditional descriptions of hybrid models may be found in Sun & Bookman (1995).
 223 Multiple d e t e r m i n a n t s of the productive use of the regular past tense suffix Virginia A.
 Marchman Department of Psychology 1202 W.
 Johnson Street University of Wisconsin, Madison Madison, W l 53706 marchinan@merlin.
 p s y c h .
 w i s e .
 e d u Abstract We offer evidence that the productive use of English regular past tense morphology (e.
g.
, drived) results from competitions among lexicallevel features within a single mechanism associative system.
 W e present error data from: (1) online elicited productions by adult native speakers (N = 51), and (2) cormectionist backpropagation networks trained to map stems and past tenses of 552 English verbs.
 The frequency of regularizations is analyzed in terms of item frequency, stem final alveolar consonant, and similarity in past tense mapping across "friends" and "enemies" in phonologically defined neighborhoods.
 All items were compiled from a lexicon of 1,191 verbs which represents a nearexhaustive listing of monosyllabic stempast tense pairs in current American English.
 Results revealed striking similarities between the hiunan and simulation data.
 Regularizations were significantly correlated with item frequency, as well as phonological attributes of the stem.
 Crucially, regularization was a function of phonological similarity to frequent suffixed items, especially for irregulars that normally undergo a vowelchange.
 These results are incompatible with the view that regularization applies by default, independently of interitem similarities which support the acquisition and processing of lexical items in associative systems.
 Introduction The productive use of patterns abstracted from English regular (e.
g.
, quit = > quitted) and irregular (e.
g.
, flow = > flew) verbs has become a fertile testing ground for models of language acquisition and processing (e.
g.
, Daugherty & Seidenberg, 1992; Marchman & Bates, 1994; Marcus, Ullman, Pinker, Hollander, Rosen, & Xu, 1992).
 O n e central issue revolves around the claim that regular morphology involves rulegoverned mechanisms that are distinct from those used in the processing and acquisition of individual lexical items (e.
g.
, Marcus, et al.
, 1992; Pinker & Prince, 1988).
 In dualmechanism models, regularly inflected forms are produced via concatenation which joins stem and suffix in a default fashion regardless of itemlevel features.
 Irregular stems and past tenses, in contrast, including zeromarking (e.
g.
, hit => hit), vowel change (e.
g.
, ring => rang) and miscellaneous (e.
g.
, go => went) mapping subtypes do not adhere to the suffixation pattern and are stored as pairs often in "clusters" of similarly sounding neighbors (i.
e.
, "friends").
 These features Daniel E.
 Callan Department of Psychology 1202 W.
 Johnson Street University of Wisconsin, Madison Madison, WI 53706 callan@merlin.
psych.
wisc.
edu determine the ease with which an irregular is accessed and the susceptibility of other forms lo "irregularization.
" This model is supported by apparent dissociations between regular and irregular forms, for example, the processing of regulars is less sensitive to item frequency than irregulars and judgments of "goodness" are a function of similarity between neighbors of irregulars (but not regulars) (e.
g.
, Prasada & Pinker, 1993).
 Single mechanism models, in contrast, propose that the production of regularizations as well as irregularizations are governed by similar sets of itemlevel factors processed within a single associative system (Daugherty & Seidenberg, 1992; MacWhinney & Leinbach, 1991; Rumelhart & McClelland, 1987; Plunkett & Marchman, 1991, 1993).
 These models are typically grounded in connectionist architectures which exploit distributed encodings to select among competitors within and across all types of conflicting mappings.
 Both dual and singlemechanism models are consistent with findings that children's past tense regularizations are more frequent with stems that are low frequency (Marcus, et al.
, 1992) and that possess certain phonological features, such as a stem final alveolar consonant (Bybee & Slobin, 1982) or a non"dominant" vowel (Stemberger, 1993).
 However, Marchman (1994) showed that interitem similarity was also important in predicting the frequency of regularization errors produced by children in an elicited production task.
 In that study, item frequency, phonological •features, m i similarity to a high frequency regular neighbor each contributed about the same amount of independent variance toward the prediction of which items would be regularized.
 N o one factor was the primary determinant of error frequency.
 Analyses of zero marking and vowel change errors indicated that similar factors predicted an item's vulnerability to irregularization as well.
 Thus, in contrast to a dualmechanism view, these results cast doubt on the need to posit a special mechanism for productivity of the regular suffix.
 More generally, the results suggest an outline for a c o m m o n set of principles guiding productivity with both regular and irregular patterns.
 Analogous results have been found in studies of reading where both regular and irregular phonologicaltoorthographic mappings are influenced by frequency, phonological features, as well as neighborhood structure and consistency (Jared, McRae & Seidenberg, 1990; Seidenberg & McClelland, 1989).
 In this paper, w e further evaluate the legitimacy of characterizing the productive use of regular past tense verbal 224 mailto:callan@merlin.
psych.
wisc.
edumorphology in terms of competitions among itembased factors within a single mechanism system.
 W e present regularization data from two sources: (1) an online elicited production task with adult native speakers of English, and (2) connectionist backpropagation networks trained to map stems and past tenses of English monosyllabic verbs.
 The frequency of regularizations is analyzed in terms of item characteristics, including token frequency, presence of phonological features, and similarity across "friends" and "enemies" in phonologically defined neighborhoods.
 In conjunction with previous analyses (Marchman, 1994), the results suggest that productive use of both regular and irregular patterns by human speakers can be viewed as a competitive associative process similar to that implemented in connectionist singlemechanism models.
 Method Online Elicitation Task Subjects.
 Fiftyfive adult native monolingual English speakers participated in the online elicitation task.
 All were students at the University of Wisconsin, Madison and received extracredit in their Psychology courses in exchange for their participation.
 Four participants were omitted due to equipment malfunctions (e.
g.
, microphone failure), yielding a final sample of 51.
 Task and Procedure.
 The elicitation task involved producing past tense forms of familiar English verbs as they appeared in stem form on the screen of a Macintosh llci running PsyScope (Cohen, MacWhinney, Flatt, & Provost, 1993).
 Each stem remained on the screen until the onset of the verbal response or 2500 msec, with 2500 msec between Uials.
 An instruction screen reminded participants that some English verbs form their past tenses through suffixation, while others "do something different, for example, changing a vowel or nothing at all.
" An 8 item practice session was given.
 Responses were audiotaped and later transcribed.
 Reaction times to initiate responses were also recorded, but will not be discussed here.
 Speakers also participated in a naming task (not discussed) administered in a counterbalanced order across subjects.
 Items.
 A total of 78 items were used in the online tasks, selected from a nearexhaustive lexicon of all monosyllabic stems and their simple past tense forms in current usage in Standard American English.
 This lexicon was compiled from Kucera & Francis (1967) (KF) and other text and freespeech corpora and served as the basis for estimating phonological neighborhood values (see below) for the English past tense inflectional system.
 Fortyfour of the 1191 items in the lexicon were coded as either having more than one acceptable past tense form (e.
g.
, sneaked vs.
 snuck) or as homophones (e.
g.
, to break a car (braked) vs.
 to break a vase (broke)).
 Verbs with two acceptable forms were weighted as 0.
5 in all calculations.
 Each item was coded for the following with reference to the complete corpus lexicon: (1) Verb class: Items were grouped into subclasses depending on the type of relationship that obtains between stem and past tense form: Regular (i.
e.
, suffixed), VC/BL, Zeromarking, and Miscellaneous.
 The distribution of items across classes in the corpusbased lexicon is outlined in Table 1.
 Table 1 also shows the class distribution of the 78 items selected from this lexicon for use in the online task (regular: N = 40; irregular N = 38).
 (2) Token Frequency: Items were grouped based on their K F frequency values for simple past tense forms: High (N=40.
 M=117.
6; regular: M=105.
6; irregular: M=129.
7) and Low (N=38 M=6.
2; regular: M=6.
1; irregular: M=6.
3).
 Items were matched across the two major classes, and hence, class differences in frequency were not statistically reliable in either the low or high fiequency sets.
 (3) Phonology: Stems were classified as alveolar (N = 29) or nonalveolar (N = 49), defined by a /t/ or /d/ in stemfinal position.
 Irregulars consisted of 20 alveolar and 18 nonalveolar stems.
 All zeromarking items are alveolar; whereas, 18 (of 29) VC/BL items are nonalveolar.
 T A B L E 1.
 Distribution of type frequency of items across class.
 CLASS REGULAR VOWELCHANGE (VC) BLEND (BL) ZEROMARKING MISCELLANEOUS TOTAL CORPUSBASED LEXICON 1049 (88.
8%) 82 (6.
8) 25 (2.
1) 25 (2.
1) 10 (0.
8) 1,191 SIMULATION 474 (85.
9%) 42 (7.
6) 18 (3.
3) 14 (2.
5) 4(0.
7) 552 (16,214 tokens) ONLINE 40 22 7 8 1 78 225 (4) Past Tense Neighborhood Structure: Friend Factors: • Friends (F): Number of items in the phonological neighborhood defined by stem final vowelconsonant or vowel which undergo a similar mapping, e.
g.
, ring => rang; sing => sang.
 • Past Tense Friend Freauencv (PFF): The sum of K F past tense frequencies of friends.
 Enemy Factors: • Enemies (E): Number of neighbors that undergo a different transformation in total (EALL) or by transformation type (ESUFF) • Past tense E n e m v Frequency (PEF): S u m m e d frequency of all enemies (PEFALL) or those that involve suffixation (PEFSUFF).
 Neighborhood Factors: • Number Ratio: Ratio of number of friends to total number of neighbors.
 • Frequency Ratio: Ratio of total friend frequency to neighboriiood frequency.
 Scoring and data reduction.
 All responses were coded as correct, error or nonvalid.
 Only final responses were coded in the case of selfcorrections.
 Errors were classified as repularization (stem + suffix), zeromarking (identical stem and past tense form), vowelchange (modification to vowel), blend (vowel change + suffix), or miscellaneous.
 Present, progressive, and participle (with or without auxiliary) forms were nonvalid and omitted from analyses.
 Simulation Procedure.
 Ten fully interconnected networks (51 input, 45 hidden, 68 output units) were trained on mappings between stems and past tenses of English verbs using a standard backpropagation algorithm (TLEARN).
 All inputs and outputs were encoded with a 17unit binary phonological feature system similar to that reported in Marchman (1993).
 Values for initial weights, momentum and learning rate were randomly assigned within a small range.
 Training used random presentation for 100 passes with itembased updating.
 Training corpus and network architecture.
 A total of 552 English verbs were chosen for use in the simulations, representing all di or triphonemic verb stems listed in the corpusbased lexicon.
 Due to architecture constraints, stems involving more than three phonemes were excluded.
 Stems took the form ConsonantVowelConsonant (CVC), C V V , V C C , V C or C V , encoded in a maximum of 51 units (17 units per phoneme).
 Past tense forms could include a fourth suffix phoneme (17 units), yielding an output layer length of 68 units.
 A set of neutral values (all O's) was used as a placeholder for nonsuffixed past tense forms or diphonemic forms.
 All suffixes appeared in the far right phoneme slot.
 All homophones were excluded (i.
e.
, each phonologically encoded stem had only one past tense form).
 Each stem was presented to the network according to K F token frequency values.
 Thus, the total training set included 16,214 tokens (552 verb types).
 Each stem in the simulation corpus was coded for: past tense subclass, K F token frequency, presence/absence of stemfinal alveolar consonant, and past tense neighborhood structure.
 Neighborhood variables were calculated using the same procedures as the elicitation study, restricted to the 552 items in the training corpus.
 Table 1 presents the number of verb types in each class.
 Note that this distribution closely approximates that of the full lexicon, even though items were selected solely in terms of length in phonemes.
 Scoring and data reduction.
 Performance was sampled at 5 intervals (6, 12, 24, 48 and 92 epochs) chosen to maximize the assessment of network periformance early in training.
 Each output was evaluated using a "closest vector" technique on a phonemebyphoneme basis.
 In other words, an output was considered correct if it "best fit" the target for each and every phoneme in the past tense form.
 For errors, the actual closest fit output was evaluated against the target stem and coded as regularization, zeromarking, vowelchange, blend, or miscellaneous.
 All data are averaged across the 10 networks.
 Results and Discussion Frequency of Errors in Humans and Networks As expected, adult native speakers produce the majority of past tense forms correctly in this elicitation context.
 Nevertheless, a total of 338 (of 3978, 8.
5%) erroneous responses were recorded.
 The majority of these (310 of 398, 91.
2%) occurred on irregular items and primarily (although not exclusively) involved the overuse of the /ed/ suffix (212 or 68.
4%).
 Thus, although regularizations were the most common type of error, adults also produced irregularizations on botii regular and irregular stems, e.
g.
, zeromarking (31), vowelchange/blend (29), and miscellaneous (43) error types.
 Table 2 outlines performance in the networks as a function of epoch of training.
 Note that proportion correct steadily increases over training, eventually reaching more than 9 3 % correct (M = 6.
5% errors).
 It is assumed that performance could continue to improve with training, yet note that levels of accuracy are strikingly similar in the human speakers and networks.
 The right hand portion of Table 2 presents the proportion of erroneous responses in the four error categories.
 Although there is considerable variation across networks, these networks were generally likely to produce VC/BL, regularization and miscellaneous errors, while zeromarking errors were infrequent across the period.
 This is in contrast to the adult human speakers who overwhelmingly preferred regularizations, even though all error types occurred.
 Nevertheless, note also that regularizations tended to decrease, while vowel change/blend errors tended to increase over training.
 A similar developmental tradeoff between regularizations and irregularizations has been reported for human children (Marchman, 1994).
 226 TABLE 2.
 Average percent correct and proportion of error types across simulation EPOCHS % CORRECT DISTRIBUTION OF ERROR TYPES REGS VC/BL MISC.
 ZERO 6 12 24 48 96 81.
5% (15.
6) 86.
5 (12.
3) 90.
0 (8.
5) 92.
4 (6.
6) 93.
5 (6.
2) 16.
9% (26.
3) 13.
5 (23.
3) 11.
7(22.
5) 6.
4 (15.
0) 4.
1 (11.
9) MEAN M , 88.
: 8(113) 10.
5 (20.
9 Item Analyses: Predictors of regularization errors W e now focus on the contribution of frequency, phonological features, and neighborhood factors in predicting which irregular verbs will be vulnerable to regularization.
 W e should first note that the vast majority of items (32 of 38, 84.
2%) were subject to regularization by at least one human speaker.
 However, items in the zeromarking subclasses (M = 13.
3) were significantly more likely to be regularized than V C / B L items ( M = 2.
8; (t(35)=4.
9, p<.
0001).
 That is, all 8 zeromarking items were regularized at least once; whereas, 6 of the VC/BL items (of 23, 20.
7%) were not regularized by any of the human participants.
 This trend was also observed in the networks.
 VC/BL items ( M = 0.
006) were significantly less likely to be regularized than zeromarking items ( M = 0.
13 t(368)=8.
9, p < .
001).
 As w e shall see, these two general classes of irregular items differ in several attributes that may contribute to this pattern.
 Table 3 overviews firstorder correlations between these factors and the frequency of regularizations in human speakers and the simulations for all items, as well as VC/BL vs.
 Zeromarking items taken separately.
! Note first that, as predicted by both a single and a dualmechanism view, frequency is negatively correlated with regularization rate, accounting for approximately 1 8 % of the variance in the human data.
 To illustrate, high frequency irregulars ( M = 1.
9) were significantly less likely to be regularized by human speakers than low frequency irregulars ( M = 9.
7, t(36)=3.
8, p<.
001).
 Further, the 6 items that were produced correctly by all 51 human participants (drive, find, meet, tell, wear, write) were all members of the high frequency set This relationship obtains when both V C / B L and Zeromarking items are analyzed separately as well.
 Token frequency is also a significant predictor in the simulations.
 Items that were regularized at least once by the network had a token frequency of M = 2.
4, compared to those that were never regularized ( M = 160.
6) (t(388)=3.
3, p ! Firstorder correlations are provided for the zeromarking items to facilitate comparison to the patterns observed in the VC/BL items.
 However, these values should be interpreted with caution given the small number of items in this class.
 37.
4% (34.
0) 42.
7 (37.
8) 44.
6 (39.
7) 49.
9 (41.
2) 50.
5 (43.
2) 10.
0% (16.
2) 8.
8 (15.
1) 8.
9 (17.
5) 9.
5 (17.
5) 11.
3(23.
3) 2.
4% (4.
4) 1.
7(3.
7) 1.
4 (3.
7) 0.
9 (3.
4) 0.
8 (3.
6) 45.
1 (39.
3) 9.
7 (18.
0) 1.
5 (3.
8) < .
0001).
 This relationship is less reliable for VC/BL only items (p < .
07), but is quite robust among the zeromarking items.
 All in all, these data are generally consistent with the wellknown pattern that token frequency strengthens associations and can serve to protect items from error.
 As has been noted in studies with children (Bybee & Slobin, 1982; Stemberger, 1993), phonological features can also be seen to play a role in predicting regularization frequency.
 For example, in the human data set, frequently regularized items were more likely to be alveolar ( M = 7.
4) than nonalveolar ( M = 3.
6).
 However, this relationship is only marginally reliable (p < .
08) and clear counterexamples exist Indeed, 3 (of 6, 50%) items that were never regularized in the online task were alveolar stems, going against the general prediction.
 As noted above, these neverregularized items were all quite high in frequency and thus, it is perhaps not surprising that they were protected from error despite being linked with this phonological feature.
 Nevertheless, the role of stemfinal alveolar consonants cannot be taken at face value given that the correlation between regularization rate and alveolar reverses if we restrict our analyses to V C / B L items.
 For these items, human speakers were less likely to regularize alveolars ( M = 1.
5) than nonalveolars ( M = 3.
6).
 A similar pattern is found in the networks.
 Here, for all items, alveolar stems are more likely to undergo regularization ( M = 0.
06) than nonalveolars ( M = .
008) (F(l,389)=24.
6, p<.
001), regardless of frequency (F(l,388)=19.
4, p<.
001).
 Yet, a switch in the direction of relationship is suggested when the V C / B L items are taken separately (r = .
09, p < .
08).
 W e can speculate that this reversal is related to an interaction between two major classes of phonological features, i.
e.
, presence of vowelconsonant clusters and stemfinal alveolar consonants.
 These factors, in interaction with item frequency, appear to be operating as opposing cues to mapping type.
 The importance of steminternal phonological cues to past tense formation is consistent with recent findings by Stemberger (1993) who has shown that some vowel change/blend verbs are resistant to regularization because their past tense forms involve a "dominant" (i.
e.
, easier to produce) vowel.
 W h e n the dominant vowel is contained in ihc sum, in contrast, 227 regularizations are more likely because speakers are pushed toward producing the stem and hence, stem+suffix forms.
 Marchman (1994) has also demonstrated that vowel dominance was one of several features contributing to regularization in children's elicited productions.
 A complete analysis of the interactions between steminternal and stemfinal phonological attributes are beyond the scope of the current paper.
 Nevertheless, these findings suggest that these factors do play an important role and future studies should match items for these features.
 W e finally turn to a brief discussion of the role of neighborhood factors.
 Both single and dualmechanism models predict that similarity to items that undergo the same type of past tense transformation (i.
e.
, "friends") should help to support the irregular pattern and hence, should bear a negative relationship to regularization frequency.
 There is some suggestion that friends offer such support here, either in terms of sum of friend frequency (PFF) or the relative frequency of friends to enemies (Frequency Ratio).
 However, further analyses indicate that these variables are significantly intercorrelated with item frequency, and do not make significant unique contributions in either the simulation or human data sets.
 Relatively weak contributions of friendbased factors are consistent with data reported in Marchman (1994).
 Nevertheless, these findings are puzzling in that both singleand dualmechanism models place considerable importance on withinneighborhood similarities in the processing of irregular forms.
 In light of the findings reported above, one possible explanation is that the role of friends might best be redefined in terms of particular phonological characteristics (e.
g.
, presence or absence of a particular vowel, stemfinal alveolar, etc.
), rather than similarity across items per se.
 Again, further investigation of this issue is left to future studies.
 Our last set of results focuses on the role of enemy factors, representing a key point where the predictions of the single and dualmechanism models diverge.
 In the dualmechanism model, regularization is proposed to apply by default and hence, an irregular verb's similarity to a regular verb should not make it any more vulneral regularization than any other item in need of a pasi form.
 In contrast, singlemechanism models pos errors of all types derive from analogies that are drawn items.
 Thus, the presence of regular enemies i increase the chance that a verb is regularized.
 Returning to Table 3, note that there appears to b minor impact of enemies (either in total or suffixed) i the human and simulation data for all items taken io{ Neighborhood factors make little contribution b frequency, and possibly phonological factors, le support for a dualmechanism view.
 Yet, it is puzzlir these relationships are also absent in the simulation c which the associative lexical learning mechani presumed to rely on these crossitem relationships.
 However, when we restrict our analyses to VC/BL only, robust correlations emerge in both the huma simulation data.
 To illustrate, VC/BL items that are regularized have approximately M = 6.
3 suffixed neij which have a KF frequency of 36.
0.
 In contrast, iten are regularized have an average of 6.
0 suffixed neif with a frequency of 61.
3.
 Multiple regression an further indicate that enemy factors account for variance and beyond both item frequency (r̂  change = 15.
39 .
02) and presence of an alveolar consonant (r̂  cha 15.
8%, p < .
02) in the human data.
 Conversely, whil fiequency makes its own unique contribution beyond ( factors (r2 change = 10.
8%, p < .
05), the presence alveolar consonant does not (r̂  change = 6.
8%, ns).
 consistent with Marchman (1994), both item frequen< similarity to regular neighbors make significant indep< contributions to regularization frequency for \\ speakers.
 As might be expected, the simuL demonstrated the impact of enemies quite strongly ii subclasses of items.
 These factors overrode any efi frequency or presence of an alveolar consonant in the \ items.
 For the relatively small set of zeromarking both similarity to suffixed enemies (r̂  change = 5.
1' .
05) and item frequency (r̂  change = 7.
5%, p < contributed unique variance.
 T A B L E 3.
 Predictors of overgeneralizations of the /ed/ suffix.
 Predictor KFfreq.
 Alveolar # Friends (F) I Friend Freq.
 (PFF) # Enemies (EALL) X EALL Frequency # Suffix E (ESUFF) Z ESUFF Freq.
 Number Ratio Freq̂ uency Ratio ALL H U M A N 0.
39** +0.
25 +0.
18 0.
19 0.
21 +0.
11 0.
10 +0.
05 +0.
25 0.
34** ITEMS S I M 0.
13** +0.
24** +0.
12* 0.
14** 0.
16* +0.
02 0.
15* +0.
07 +0.
25** 0.
18** VC/BL H U M A N 0.
44** 0.
38* +0.
34** +0.
13 +0.
12 +0.
54*** +0.
20 +0.
48** +0.
16 0.
24 SIM 0.
08 0.
09 0.
01 0.
05 +0.
05 +0.
23** +0.
10* +0.
44*** 0.
05 0.
11* ZEROMARKING H U M A N 0.
69 0.
13 0.
41 0.
32 0.
33 0.
52 +0.
31 0.
01 0.
27 SIM ^036*" 0.
04 0.
27* 0.
22 0.
12 0.
18 +0.
32* +0.
09 0.
19* * = p < .
05 ** = p<.
01 *** = p < .
001 228 Conclusion In conclusion, these studies sought to evaluate influences on the productive use of the English past tense suffix in both human speakers and connectionist simulations.
 In general, human speakers of English and networks trained on a lexicon of English vocabulary items produce past tense errors to about the same degree.
 While there are some clear differences in the types of errors that are produced, striking similarities were observed across the two sources of data regarding which items were vulnerable to error.
 Several previous findings were replicated, including the importance of token frequency in protecting an item from error and the complex role of phonological factors.
 Most importantly, it was demonstrated that factors which capture competitions between similarsounding items within a phonological neighborhood do indeed play a strong role in the productive usage of the English regular suffix in both networks and human speakers.
 These results are consistent with previous analyses using data from children, as well as recent studies in other language domains, such as visual word recognition.
 In general, these data support the conclusion that both regularization and irregularization are best thought to involve competitive associative processes similar to those implemented in singlemechanism connectionist networks.
 Acknowledgments This research was supported by grants from the Wisconsin Alumni Research Foundation (WARF), NIHNIDCD (R29 02292), and NIHNICHD (Waisman Mental Retardation Center Core Grant).
 W e thank Whit Schonbein and Dai Kimura for programming and modeling assistance, as well as members of the U W Cognitive Science Reading group for insightful comments and feedback.
 Marchman, V.
 (1994).
 Children's productivity in the English past tense: The role of frequency, phonology and neighborhood factors.
 Manuscript under review.
 Marchman, V.
 & Bates, E.
 (1994).
 Continuity in lexical and morphological development: A test of the critical mass hypothesis.
 Journal of Child Language, 21(2), 331366.
 Marcus, G.
F.
, Ullman, M.
, Pinker, S.
, Hollander, M.
, Rosen, T.
J.
, & Xu, F.
 (1992).
 Overregularization in language acquisition.
 Monographs of the Society for Research in Child Development.
 57(4), Serial No.
 228.
 Plunkett, K.
 & Marchman, V.
 (1991).
 Ushaped learning and frequency effects in a multilayered perceptron: Implications for child language acquisition.
 Cognition, 38, 43102.
 Plunkett, K.
 & Marchman, V.
 (1993).
 From rote learning to system building: Acquiring verb morphology in children and connectionist nets.
 Cognition, 48 (1), 2169.
 Pinker, S.
 & Prince, A.
 (1988).
 On language and connectionism: Analyses of a parallel distributed model of language acquisition.
 Cognition, 28, 59108.
 Prasada, S.
 & Pinker, S.
 (1993).
 Generalization of regular and irregular morphological patterns.
 Language and Cognitive Processes, 8(1), 156.
 Rumelhart, D.
 & McClelland, J.
 (1987).
 Learning the past tenses of English verbs: Rules or PDP? In B.
 MacWhinney (Ed).
 Mechanisms of language acquisition.
 Cambridge: Cambridge University Press.
 Seidenberg, M.
S.
 & McClelland, J.
 (1989).
 A distributed, developmental model of word recognition and naming.
 Psychological Review, 96, 523568.
 Stemberger, J.
P.
 (1993).
 Vowel dominance in overregularizations.
 Journal of Child Language, 20 (3), 503521.
 References Bybee, J.
 & Slobin, D.
l.
 (1982).
 Rules and schemas in the development and use of the English past tense.
 Language, 58, 265289.
 Cohen, J.
D.
, MacWhinney, B.
, Flatt, M.
, & Provost, J.
 (1993).
 PsyScope: A new graphic interactive environment for designing psychology experiments.
 Behavioral Research Methods, Instruments & Computers, 25(2), 257271.
 Daugherty, K.
 & Seidenberg, M.
S.
 (1992).
 Rules or connections? The past tense revisited.
 Proceedings of the 14th Annual Meeting of the Cognitive Science Society.
 Hillsdale, N.
J.
: Erlbaum.
 Jared, D.
, McRae, K.
 & Seidenberg, M.
S.
 (1990).
 The basis of consistency effects in word naming.
 Journal of Memory and Language, 29, 687715.
 Kucera, H.
 & Francis, W.
N.
 (1967).
 Computational analyses of presentday American English.
 Providence, R.
I.
: Brown University Press.
 MacWhinney, B.
 & Leinbach, J.
 (1991).
 Implementations are not conceptualizations: Revising the verb learning model.
 Cognition, 40(12), 121157.
 229 Inducing a G r a m m a r Without an Explicit Teacher: Incremental Distributed Prediction Feedback Michael SpiveyKnowlton Department of Brain and Cognitive Sciences University of Rochester Rochester, N Y 14627 s p i v e y O p s y c h .
 r o c h e s t e r .
 e d u J e n n y R.
 Saffran Department of Brain and Cognitive Sciences University of Rochester Rochester, NfY 14627 saf f r a n O p s y c h .
 r o c h e s t e r .
 e d u Abstract A primary problem for a child learning her first language is that her ungrammatical utterances are rarely explicitly corrected.
 It has been argued that this dearth of negative evidence regarding the child's grammatical hypotheses makes it impossible for the child to induce the grammar of the language without substantial innate knowledge of some universal principles common to all natural grammars.
 However, recent connectionist models of language acquisition have employed a learning technique that circumvents the negative evidence problem.
 Moreover, this learning strategy is not limited to strictly connectionist architectures.
 What we call Incremental Distributed Prediction Feedback refers to when the learner simply listens to utterances in its environment and makes internal predictions online as to what elements of the grammar are more or less likely to immediately follow the current input.
 Once that subsequent input is received, those prediction contingencies (essentially, transitional probabilities) are slightly adjusted accordingly.
 Simulations with artificial grammars demonstrate that this learning strategy is faster and more realistic than depending on infrequent negative feedback to ungrammatical output Incremental Distributed Prediction Feedback allows the learner to produce its own negative evidence from positive examples of the language by comparing incrementally predicted input with actual input.
 Introduction Recently, connectionist models have begiin to use time as a critical factor.
 Radier than receiving an explicit training signal for associating arbitrary inputs with arbitrary outputs, irrespective of any temporal relationship, the model is exposed to sequences of inputs and incrementally attempts to predict what the subsequent input will be.
 Without an explicit teacher, the model compares its predicted subsequent input with the actual subsequent input, and uses the difference as an error signal.
 Some models of this type use recurrent connections to compute a prediction based on a "Gestalt" of several timesteps (e.
g.
, Elman, 1990; Juhano & Tanenhaus, 1995; St.
 John & McClelland, 1990), but this is not a necessary condition in order to use this learning strategy.
 Standard feedforward networks can also learn by predicting the subsequent input based on the current input (Schutze, 1994).
 In fact, this learning strategy need not be restricted to connectionist architectures at all.
 The work w e present in this paper is a test case in which we compare this learning strategy with one that requires explicit corrective feedback in terms of their ability to induce a simple grammar matrix (for an example, see Figure 1).
 The learning model consists of a reproduction of the matrix with initially equal values in all cells (i.
e.
, identical connection weights for all possible sequential pairings).
 Starting off with this tabula rasa assumes no initial predisposition toward particular kinds of connectivity (i.
e.
, no innate constraints devoted to likely patterns).
 The first learning strategy w e simulate is derived from a standard assumption that explicitly correcting the child's ungrammatical utterances would be an optimal method of grammar induction.
 Such corrections are known as 'negative evidence'.
 The corresponding idealized model, implemented in simulations lA and 2A, is called Explicit Negative Evidence Feedback (ENEF), in which the learner randomly produces sequential pairings that it thinks are grammatical (initially, any pairing) and occasionally receives corrective feedback from a teacher when the pairing is in fact ungrammatical.
 a b t±i c d e f a b c d e f 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 Figure 1.
 Elements of the language are crossindexed with one another, and some sequential pairings (from t to t+1) are deemed grammatical (1) while others are considered ungrammatical (0).
 For example, along the top row, a can be followed by b or by d, but not by a, c, e or/.
 (This kind of local transition system is equivalent to a finite automaton language or a Markov chain with equal probabilities from a given state to the possible next states.
 It follows that results of modeling the learning of such a grammar may not generalize to that of natural grammars which are considerably more complex.
) 230 W e compare this learning strategy, within the same model architecture, to one based on the learning method employed by the connectionist models that were discussed above.
 Simulations IB and 2B implement Incremental Distributed Prediction Feedback (IDPF), in which the learner listens to grammatical pairings in its environment and makes online predictions (i.
e.
, multiple bels of varying magnitude) about what elements at time t+1 are more or less likely to follow the current element.
 The bet that wins is rewarded, thus increasing the strength of that prediction in future instances.
 All other pairings from that initial element are punished, with a corresponding decrease in their prediction strength.
 Both learning strategies will eventually get the learner to some arbitrary criterion of accuracy (say, 95%) in its internalization of the grammar.
 The case for the child learning her first language, however, is special because the scarcity and variability of corrective feedback regarding the child's utterances suggests that relying on negative evidence alone would simply take far longer than children generally require to learn their first language (Marcus, 1993).
 The purpose of our simulations is to compare how many utterances must typically be produced by EhfEF to reach 9 5 % accuracy in its encoding of the grammar with how many utterances must typically be heard by IDPF to reach 9 5 % accuracy in its encoding of the grammar.
 Negative Evidence In principle, negative evidence serves to correct children's misconstrued linguistic rules and to drive change in the developing grammar.
 The critical role of negative evidence was demonstrated in a classic paper by Gold (1967), who proved that natural languages cannot be learned in a finite period of time from a finite set of positive examples alone (grammatical sentences from the language).
 Given that children do, however, learn language with all due speed, there are two possible means to circumvent this leamability problem; 1) to receive corrections (negative evidence), or 2) to restrict the hypothesis search space through innate constraints.
 Within the leamability framework, then, a language acquisition device unencumbered by innate consU^aints requires negative evidence in response to its ungrammatical output.
 Without negadve evidence, such a device could not converge upon the target grammar  this fact is a primary feature of the "poverty of Uie stimulus" argument for innate linguistic structure (Chomsky, 1972; Pinker, 1984).
 For these reasons, the question of the existence of negative evidence has received much debate.
 While early studies indicated that parents tend to correct the truthvalue of children's utterances rather than grammatical errors (Brown & Hanlon, 1970), more recent research has found Uiat some parents respond differentially to children's errors, for example by repeating ungrammatical sentences more often than grammatical sentences (e.
g.
, Bohannon, MacWhinney & Snow, 1990; Bohannon & Stanowicz, 1988; HirshPasek, Treiman, & Schneiderman, 1984).
 However, such effects are generally small, and are not seen consistenUy either across subjects or across studies (Gordon, 1990; Marcus, 1993; Morgan & Travis, 1989).
 Moreover, even when negative evidence is available, it is not necessarily used by children (e.
g.
, McNeill, 1970, Chapter 7).
 T o date, both the availability and effectiveness of explicit negative evidence remains controversial.
 There exists a different learning method, however, that employs a type of feedback which has not been widely considered in discussions of the logical problem of language acquisition.
 In principle, a child could recover from an overly general hypothesis  such superset cases are exactly where Gold's proof required negative evidence  by observing that the predictions generated by the hypothesis are not borne out in the speech she hears.
 For example, a child might learn Uiat all dative verbs do not alternate ('I donated the book to him/*I donated him the book', as opposed to 'I gave the book to him/I gave him the book') by observing that 'donate' never occurs in a doubleobject frame.
 Of course, this powerful mechanism must be constrained, as there are an infinite number of sentences which the child will never hear.
 This might be accomplished by embedding such a mechanism in a prediction framework: as the child listens to others speak, she predicts that certain elements will follow one another.
 W h e n the predictions are incorrect, such as a prediction that 'donate' will be followed by the indirect object (based on an overly general rule resulting from the observation that givetype verbs can be followed by the indirect object), the hypothesized sequential pairing which gave rise to the incorrect prediction is decremented.
 Thus, the child learns by listening to utterances rather than by producing them, and generates her own negative evidence (or error signal) by comparing her predicted inputs with the actual input.
 Simulation lA: Explicit Negative Evidence F e e d b a c k We begin with ENEF because it is based on a commonly held view of language acquisition, in which the learner entertains discrete hypotheses about which grammar relations are allowed and which are disallowed.
 Within this perspective, a method by which the learner rules out hypotheses (that is, those hypotheses not already ruled out by innate constraints) is by producing a hypothetically grammatical utterance and receiving corrective feedback indicating that it is ungrammatical.
 W e wanted to make the implementation of E N E F unrealistically strong in order to determine the near Umit in how fast it can induce a grammar with 9 5 % accuracy.
 Therefore, it is given a generous amount (compared to what children typically receive) of noisefree explicit negative evidence, and the model requires only one instance of corrective feedback in order to rule out any particular hypothesized sequential pairing.
 These first simulations are based on 6 X 6 grammars, similar to the one in Figure 1.
 The model starts out assuming that every sequential pairing between every element of the grammar is allowed (I's in all 36 cells).
 The model randomly produces a sequential pairing that it hypothesizes is grammatical.
 If this output is, in fact, ungranmiatical according to the target grammar, there is a 2 0 % chance that the model will receive corrective feedback, turning the strength of that sequential pairing from one to 231 a 0 0 0 1 1 0 b 0 1 0 I 1 1 c 1 0 0 0 1 1 d 1 0 1 0 0 1 e 1 0 1 1 0 0 / 0 1 0 0 1 0 A .
 a h c d e f Figure 2.
 The richest and the sparsest grammars on which the model was trained, respectively.
 The gnunmar in panel A has 19 ungrammatical pairings and the one in panel B has 30.
 B .
 a b c d e f a 0 0 0 0 0 1 b 1 0 0 0 0 0 c 0 1 0 0 0 0 d 0 0 1 0 0 0 e 0 0 0 1 0 0 / 0 0 0 0 1 0 zero, thus discretely ruling out that specific hypothesis.
 If the output happens to be grammatical, no learning lakes place.
 This process is repeated until the model's internalization of the grammar is at least 9 5 % accurate.
 In a 6X6 grammar, this means the model must learn all but one of the zeroes in the target grammar.
 The number of utterances required to achieve this criterion of accuracy is referred to as the "learning time".
 (It is important to note that the last few zeroes take the longest to learn because, by that time, there is a slim chance that the model's random output of hypothesized sequential pairings will come upon an ungrammatical one.
 And this slim chance is multiplied by the .
2 probability of negative evidence!) The model was trained on twelve different grammars (see Figure 2).
 100 simulations were conducted per grammar in order to compute a reliable average learning time.
 With the richest grammar, one containing many grammatical sequential pairings (Figure 2A), learning was slowest.
 The average learning time for this grammar was 315 timesteps (or produced utterances).
 In contrast, the absolute sparsest grammar (Figure 2B) took an average of only 242 timesteps.
 The remaining grammars of intermediate densities had average learning times between those extremes, gradually decreasing as density decreased.
 As mentioned above, the probability of ruling out an hypothesized sequential pairing on any one timestep is equal to the probability of receiving negative evidence when an ungrammatical pairing is produced multiplied by the probability of proiducing an ungrammatical pairing.
 Thus, at the onset of learning the grammar in Figure 23, there is a relatively high probability of ruling out an hypothesis that is ungrammatical: P(c) = .
2(30/36), where P(c) is the probability of a correction, and 30/36 is the ratio of ungrammatical pairings over the total number of pairings.
 If a correction does not take place (either because the utterance happened to be grammatical, or the teacher failed to provide negative evidence), then the probability of a correction increases on the next timestep, according to probability summation over time (Wat.
son, 1979).
 Using probability summation over time', the E N E F s mean learning time for the twelve granmiars is approximated; r^=.
90.
 See also the open and filled triangles of Figure 4.
 Simulation I B : Incremental Distributed Prediction F e e d b a c k IDPF learns in a much more realistic fashion than ENEF.
 It requires no explicit negative evidence regarding produced utterances.
 Instead, it listens to random utterances comprised of a randomly generated element followed by a randomly selected grammatical subsequent element.
 Incrementally, it makes distributed predictions about what elements should follow the initial input element.
 It typically requires about 1020 exposures to an utterance in order to reduce the prediction strength of alternative ungrammatical pairings from that first element to less than .
05.
 In the next set of simulations, we trained the IDPF model on the same twelve grammars.
 IDPF is probabilistic, in that it starts out with prediction strengths that sum to 1 across any given row of the matrix (like a typical Markov chain).
 Beginning with a blank slate, the leamerhas .
167 1 (1) c u m P ( C ) = 10(111^) where t\ is the probability of receiving negative evidence (should the learner produce an ungrammatical utterance), Q is the number of ungrammatical pairings still hypothesized by the learner to be grammatical, y is the total number of sequential pairings still hypothesized by the learner to be grammatical, and T is the timestep or utterance number.
 The cumulative probability of a correction increases as x increases.
 When the cumulative probability of a correction exceeds .
632 (that is, 11/e), the signal has, on average, occurred (cf.
 Watson, 1979).
 Thus, we iterated this equation, decrementing Q and y by 1 each time cumP(C) exceeded .
632 (as that meant there was one less ungrammatical pairing left to learn, and one less pairing hypothesized by the learner), and starting again at T=l.
 This was repeated until Q=l,which meant that all but one incorrect hypothesis had been ruled out; >95% accuracy.
 The sum of the Q1 values of x corresponds to how many timesteps probability summation over time predicts the ENEF model will require to learn the grammar.
 232 a b c d e f a .
020 .
519 .
010 .
024 .
308 .
010 b .
324 .
004 .
010 .
024 .
255 .
481 C .
020 .
004 .
010 .
500 .
005 .
479 d .
596 .
004 .
010 .
404 .
005 .
010 e .
020 .
004 .
950 .
024 .
005 .
010 f .
020 .
465 .
010 .
024 .
422 .
010 Figure 3.
 IDPFs 9 5 % accurate probabilistic representation of the grammar in Figure 1.
 (achieved in 107 timesteps.
) prediction strength in every cell of the 6X6 matrix.
 And reaching 9 5 % accuracy in internalizing the grammar means that the summed error in each row averages .
05.
 Figure 3 shows the learner's prediction strengths after reaching 9 5 % accuracy on the grammar shown in Figure 1.
 The model modifies its prediction strengths by comparing its weighted predictions of the input at time t+1 with the actual (discrete) input at time t+1.
 The one weighted prediction that was correct is increased by 1 5 % of the difference between 1 and its current value, and the five predictions that were incorrect are decreased by 1 5 % of their current values.
 This learning procedure is a version of the generalized delta rule (Rumelhart, Hinton & Williams, 1986), or "backpropagation", with a .
15 learning rate.
^ As before, 1(X) training simulations were run on each grammar.
 The IDPF learner reached criterion accuracy well before E N E F on all twelve grammars.
 [In fact, in order to achieve performance equivalent to IDPFs, E N E F requires an extremely unrealistic 4565% explicit negative evidence.
] An important observation here is that E N E F learns cellbycell, that is, it has a chance at each utterance of learning completely about one particular sequential pairing.
 In contrast, IDPF (because its predictions are distributed across the entire matrix row) learns gradually rowbyrow, thus every utterance is a learning experience with respect to all of the elements that could follow the element at time t.
 Learning time results for IDPF are shown in Figure 4, combined with the results of E N E F A lower Hmit on the learning time for IDPF is easily computed by determining the minimum number of exposures to an initial element required to bring the sum of that row's ungrammatical cells to less than or equal to .
05.
^ By adding to this lower limit the number of rows in the matfix minus 1, w e can closely approximate IDPF's mean learning time (learning time = (I If) + N1); r2=.
98.
 See the open and filled circles in Figure 4.
 Sim 2A: E N E F with 10X10 Grammars To test how well these models scale up to larger grammars, this next set of simulations trained E N E F on a larger size of the same type of grammar (see Figure 5).
 A s before, 100 simulations were run on each grammar to compute mean learning times.
 E N E F learned in the same fashion described in Simulation lA, but this time all but/ive ungrammatical sequential pairings needed to be learned; in a 10X10 grammar, this was sufficient to produce 9 5 % accuracy.
 For the richest grammar tested (Figure 5A), E N E F was slowest, producing an average of 777 pairings in order to achieve 9 5 % accuracy.
 As the grammar became sparser, E N E F learned faster, with the sparsest granmaar (Figure 5B) being learned in 679 timesteps.
 As in Simulation lA, probability summation over time approximated the mean learning times for the twelve grammars; t^=.
945 (Figure 6).
 Sim 2B: IDPF with 10X10 Grammars IDPF was trained on the same twelve grammars, in the same fashion as in Simulation IB.
 The 9 5 % accurate internalization of the 10X10 grammar, at the end of learning, was analogous to the 6X6 version shown in Figure 3.
 IDPF scaled up to this larger grammar much more gracefully than did E N E F .
 IDPF learned the richest grammar in an average of 159 timesteps, and the sparsest grammar in 181 timesteps.
 As before, Equation (2) (in foomote 3) closely approximated the mean learning times for the twelve grammars; t^=.
99 (see Figure 6).
 General Discussion A common assumption in the field of language acquisition is that if innate constraints did not encode certain grammatical relationships, then the standard negative evidence model, with its extremely slow learning, is all the learner could resort to.
 The results of these simulations suggest that an alternative, and cognitively plausible, method of learning (IDPF) is a great deal faster than the standard model.
 IDPFs distributed prediction of temporal associations is analogous in mechanism to the priming of semantic or syntactic associations.
 However, it remains an empirical question whether children learning their first language actually use this kind of passive incremental prediction of temporal associations between inputs.
 •̂  In fact, the IDPF model is equivalent to a perceptron (with no hidden unit.
s) using the delta rule, but with the "desired output" signal being provided by the subsequent input, rather than by an explicit teacher.
 (2) "I'ndTi) <.
05 where Q^ is the number of ungrammatical cells in row r, N is the number of elements in the language, T is the timestep, and T[ is the learning rate [playing a similar role here as did the negative evidence term in Equation 1 for probability summation over time in ENEF (see footnote 1)].
 By solving for x for each row of the matrix, and suimning those N values of x, we get a lower limit of learning time for IDPF (lower limit = ZXj).
 233 u c u 350 3003 250o E H 'c 2 100 200 15050  A — HSfEF • A   • probability summation over time IDPF O lower limit+ N1 18 20 22 24 26 28 30 32 G r a m m a r Sparseness (# of ungrammatical utterances) Figure 4.
 Results of Simulations lA and IB.
 E N E F learns sparse grammars faster than dense ones, and is apiwoximated by probability summation over time.
 IDPF learns much faster than ENEF, with a modest increase in learning time as a function of the ratio of ungrammatical cells to total cells in the grammar.
 A .
 a b c d e f 8 h i J a 1 0 1 0 0 0 0 1 0 1 b 1 0 0 0 0 1 1 0 1 0 c 1 0 0 1 1 0 0 1 0 1 d 1 0 1 0 1 0 0 1 0 0 e 0 1 0 0 1 1 0 1 1 0 / 1 0 0 1 1 0 1 0 1 0 g 1 1 0 0 1 1 0 0 0 1 h 0 1 1 1 1 0 0 1 0 0 / 0 0 0 1 1 0 1 0 0 1 ; 1 1 0 1 0 0 1 0 1 0 B .
 a b c d e f 8 h i J a 0 1 0 0 1 0 0 0 1 0 b 1 0 1 0 0 0 1 0 0 0 c 0 0 0 0 0 0 0 0 1 0 d 1 0 0 1 0 1 0 0 0 1 e 0 0 1 0 0 0 0 1 1 0 / 0 0 0 0 0 0 0 0 0 1 8 0 0 0 0 0 1 0 1 0 1 h 1 0 0 0 0 0 1 0 0 0 / 0 1 0 0 0 0 0 1 0 1 j 0 0 0 0 1 0 0 0 0 0 Figure 5.
 Simulations 2A and 2B: The richest and sparsest grammars on which the model was trained, respectively.
 The grammar in panel A has 54 ungrammatical pairings and the one in panel B has 76.
 With Incremental Distributed Prediction Feedback, the learner can take advantage of the conspicuous absence of certain grammatical relationships in the input.
 Moreover, if the input contains graded statistical biases for some sequential elements over others, IDPF's probabilistic encoding will cause it to reflect those graded preferences, just as adult comprehenders do (e.
g.
, Juliano & Tanenhaus, 1993; Saffran, Newport & Aslin, submitted).
 The standard negative evidence model cannot produce such graded preferences, as its coding is discrete.
 It is certainly possible that evolution has caused our D N A to encode certain constraints devoted to language learning (Batali, 1994; Pinker & Bloom, 1990).
 However, our results cast some doubt on whether the apparent lack of negative evidence can be used as a vaUd motivation for such a claim.
 In fact, what IDPF provides is a mechanism by which the child can produce her own negative evidence by comparing predicted (or primed) input with actual input.
 Certainly, these simulations are a simplified test case, and do not apply to natural grammars, which contain multiplecontingency relationships of far greater complexity than pairwise sequences.
 Future work on this issue will require comparing the two learning styles ("overt testing" vs.
 "passive predicting") in their ability to learn more complex, natural grammars.
 234 4) u B u 4> O i e 750700200150 ? ENEF probability sununation over time  O ••• IDPF lower limit + N1 z Figure 1 1 50 60 70 80 Grammar Sparseness (# of ungrammatical utterances) j^.
 Results of Simulations 2A and 2B.
 The gap between E N E F and IDPF is even greater.
 Acknowledgments: This research was supported by N S F Graduate Research Fellowships to both authors.
 W e are grateful to Gail Mauner, Toby Mintz, EUssa Newport, Whitney Tabor and Mike Tanenhaus for helpful discussions of the work.
 References Batali, J.
 (1994).
 Artificial evolution of syntactic aptitude.
 Proceedings of the 16th Annual Conference of the Cognitive Science Society.
 Bohannon, J.
 & Stanowicz, L.
 (1988).
 The issue of negative evidence: Adult responses to children's language errors.
 Developmental Psychology, 24, 684689.
 Bohannon, J.
, MacWhinney, B.
 & Snow, C.
 (1990).
 N o negative evidence revisited: Beyond leamability or who has to prove what to whom.
 Developmental Psychology, 26, 221226.
 Brown, R.
 & Hanlon, C.
 (1970).
 Derivational complexity and order of acquisition in child speech.
 In J.
 Hayes (Ed.
), Cognition and the development of language.
 N e w York: Wiley.
 Chomsky, N.
 (1972).
 Language and mind.
 N e w York: Harcourt Brace Jovanovich.
 Ehnan, J.
 (1990).
 Finding structure in time.
 Cognitive Science, 14,179211.
 Gold, E.
 (1967).
 Language identification in the limit.
 Information and Control, 10, 447474.
 Gordon, P.
 (1990).
 Leamability and feedback.
 Developmental Psychology, 26, 217220.
 HirshPasek, K.
, Treiman, R.
 & Schneiderman, M .
 (1984).
 Brown and Hanlon revisited: Mother's sensitivity to ungrammatical forms.
 Journal of Child Language, 11, 8188.
 Juliano, C.
 & Tanenhaus, M .
 (1993).
 Contingent frequency effects in syntactic ambiguity resolution.
 Proceedings of the 15th Conference of the Cognitive Science Society.
 Juliano, C.
 & Tanenhaus, M .
 (1995).
 A constraintbased lexicalist account of the subject/object attachment preference.
 Journal of Psycholinguistic Research, 23, 459471.
 Marcus, G.
 (1993).
 Negative evidence in language acquisition.
 Cognition, 46, 5385.
 McNeill, D.
 (1970).
 The acquisition of language.
 N e w York: Harper and R o w .
 Morgan, J.
 & Travis, L.
 (1989).
 Limits on negative information in language input Journal of Child Language, 16, 531552.
 Pinker, S.
 (1984).
 Language leamability and language development.
 Cambridge, M A : Harvard University Press.
 Pinker, S.
 & Bloom, P.
 (1990).
 Natural language and natural selection.
 Brain and Behavioral Sciences, 13, 707784.
 Rumelhart, D.
, Hinton, G.
 & WiUiams, R.
 (1986).
 Learning internal representations by error propagation.
 In D.
 Rumelhart, J.
 McClelland, and the P D P Research Group (Eds.
), Parallel Distributed Processing.
 Volume 1: Foundations.
 Cambridge, M A : M I T Press.
 Saffran, J.
, Newport, E.
 & Aslin, R.
 (submitted).
 W o r d segmentation: The role of distributional cues.
 Schiitze, H.
 (1994).
 A connectionist model of verb subcategorization.
 Proceedings of the 16th Annual Conference of the Cognitive Science Society .
 St.
 John, M .
 & McCleUand, J.
 (1990).
 Learning and applying contextual constraints in sentence comprehension.
 Artificial Intelligence, 46, 217257.
 Watson, A.
 B.
 (1979).
 ftobability summation over time.
 Vision Research, 19, 515522.
 235 Connectionist Rules of L a n g u a g e Gert Westermann Department of Computer Science Technical University of Braunschweig 38106 Braunschweig, Germany westermafiibr.
cs.
tubs.
de Rainer Goebel Max Planck Institute for Brain Research Deutschordenstr.
 46 60528 Frankfurt, Germany goebel(Ompihf rankf urt.
 mpg.
 d400.
 de Abstract A modular connectionist network is described that learns the German verb paradigm.
 The architecture of the network is in accordance with the ruleassociative memory hypothesis proposed by Pinker (1991): it is composed of a connectionist shortterm memory enabling it to process symbolic rules and an associative memory acting as a lexicon.
 The network successfully learns the German verb paradigm and generalizes to novel verbs in ways that correspond to empirical data.
 Lesioning the model gives further evidence for the ruleassociative memory hypothesis: When the lexicon is cut off, the network strongly overgeneralizes the regular participle, indicating that regular forms are produced with the shortterm memory but irregular forms rely on the lexicon.
 However, in contrast to the ruleassociation theory, the two paths are not strongly dissociated, but both the shortterm memory and the lexicon work together in producing many participles.
 The success of the network model is seen as evidence that emergent linguistic rules need not be implemented as rules in the brain.
 Introduction It has recently been argued that certain parts of the language system are represented in the brain by a dualistic framework combining rule manipulation with associative memory (Pinker, 1991).
 For example, in the English past tense regular forms are claimed to be produced by a symbolic rule ("add ed to the verb stem") while irregular verbs are stored in an associative memory together with hnks to their past tense forms.
 W h e n a past tense form is to be produced, first the associative memory is searched for a matching entry, and only if none is found the default rule is applied (Marcus et al.
, 1993).
 The cases in which the default rule applies are called regular.
 Regularity is independent from frequency, because the default rule might apply only to a minority of aU cases.
 Marcus et al.
 (1993) argued that this is true for both the German noun plural and the German participle: The default noun plural ending s has a type frequency of less than 8 % and a token frequency of less than 2 % of all nouns.
 The regular verb participle accounts for 4 5 % of all verb types and only 1 7 % of eill verb tokens.
 This discrepancy between regularity and frequency is in contrast with the English past tense, where 8 6 % of all verb types (40% of aW tokens) are regular.
 The instances in which the regular cases do not form the majority of all cases can be seen as a touchstone for connectionist models.
 This is because homogenous connectionist models (e.
g.
 MacWhinney and Leinbach, 1991, Rumelhart and McClelland, 1987) learn by exploiting the statistical regularities of the input data and therefore necessarily assign the regular status to the most frequently occuring input.
 In this paper, a modular connectionist network is described that implements the ruleassociative memory framework for the German verb paradigm.
 The network consists of a connectionist shortterm memory enabling it for symbol manipulation (see Goebel, 1991) and a lexicon in the form of an associative memory.
 It is shown that the network learns the verb inflection paradigm and generalizes to novel verbs in a way comparable to empirical data.
 The interned representations developed by the network follow the ruleassociative memory theory (Pinker, 1991) in that most regular forms are produced solely with the shortterm store while the irregular forms are handled by the lexicon.
 It is demonstrated, however, that in contrast to this theory the rule path and the associative memory are not strongly dissociated from one another, but they interact in producing the correct output for certain verbs.
 The fact that the network model displays rukehke behavior without hardwired rules suggests that emergent linguistic regularities need not be implemented as explicit rules in the brain.
 Below, the German verb paradigm is first briefly reviewed.
 Our experiments, including the data and the network architecture, are then described, followed by a detailed analysis of the network's performance and of its internal representations.
 Finally, we discuss the imphcations to the ruleassociative memory theory (Pinker, 1991).
 The German Verb Paradigm The German verb paradigm is illustrated in table 1 (for a more detailed account, see Marcus et al.
, 1993).
 Each verb has three paradigmatic forms: an infinitive, a preterite, and a participle.
 Infinitives are formed by adding the suffix en to the verb stem: For example, the verb spielen has the stem spiel and the infinitive is formed by adding en .
 Preterites are formed in different ways, 236 Table 1: The structure of the German verb paradigm Infinitive Preterite Participle W e a k verbs spielen (to play) woUen (to want) spielte (played) wollte (wanted) gespielt (have played) gewoUt (have wanted) Strong verbs kommen (to come) gehen (to go) kam (came) ging (went) gekommen (have come) gegangen (have gone) M i x e d verbs konnen (can) denken (to think) konnte (could) dachte (thought) gekonnt (have been able to) gedacht (have thought) but they are not common in spoken language and hence play no role in our simulation experiments.
 Participles are formed by adding a sufHx (either t or en ) to the stem which might be different from the infinitive stem.
 Participles whose stems have primary stress on the first syllable (most of them do) receive the prefix ge.
 There are three verb classes, weak verbs, strong verbs, and mixed verbs, which differ in the ways that preterites and participles are formed: The participle of weak verbs is always formed by adding the t sufiix and the ge prefix (where applicable) to the unchanged stem: ge spiel t .
 The participle of strong verbs is formed by adding the suffix en (and the prefix ge) to the participle stem which may or may not be different from the infinitive stem: For example, kommen does not change its stem: ge komm en , while gehen does: ge gang en .
 Mixed verbs change their stems like strong verbs, but they receive the suffix t like weak verbs: koimen ge konn t .
 Only one verb has completely idiosyncratic preterite and participle forms: sein (to be)  war  gewesen.
 Marcus et al.
 (1993) give evidence that the weak verbs constitute the regular (default) case for the German verb paradigm.
 Experiments The gojJs of the experiments were threefold: First, to examine whether the connectionist model could learn the task of acquiring the German verb paradigm which is claimed to employ symbolic rules.
 Second, to test the network's ability to generalize to novel verbs and compare the results with data from psycholinguistic experiments.
 Third, to analyze the internal representations developed by the network in learning the German verb paradigm and relate them to the dualistic framework proposed by Pinker (1991).
 Data The data for the experiments was taken from a corpus of spoken utterances by German children in the first grade of elemantary school (Pregel and Rickheit, 1987).
 This corpus consisted of 824 types with 7,468 tokens.
 Since it contained a great number of composite verbs, all separable prefixes were removed because they do not influence formation of the participle.
 From the resulting corpus 100 types were randomly extracted, yielding 944 tokens.
 Since it was not given in this corpus, the ratio of the infinitive to participle forms of each verb was taken from the C E L E X database.
 The tokens of each verb in the data were then divided according to this ratio.
 W h e n a token did not appear in C E L E X it was given the frequency 1 for both the infinitive and the participle form, thus guaranteeing the appearence of each verb at least once in each form.
 For the experiments half the nimiber of tokens for each verb form were used.
 The final data set thus contained 100 types with 538 tokens, of which 388 were in the infinitive form and 150 in the participle form.
 A n aneJysis of this data set yielded the following structure: Verb class weak (regular): strong (irregular): mixed: 52% types, 45.
33% participle tokens 41% types, 50.
00% participle tokens 7 % types, 4.
67% participle tokens Although weak verbs had a slight majority counting the types, they only accounted for 45.
33% of the participle tokens.
 Even together with the mixed verbs (which also have the t ending) they did not present a majority of the participle tokens.
 However, a comparison of this corpus with one for adult language (Ruoff, 1981) showed significant differences: In the adult corpus, only 4 5 % of the types and 1 7 % of the tokens belonged to the weak class in contrast to 5 2 % and 45.
33% for the child data, respectively.
 The vocabulary of children seems to comprise a higher ratio of weak verbs than that of adults, and these weak verbs seem to be used more often.
 In fact Pregel and Rickheit (1987) remarked that e.
g.
 the frequency of the weak verb haben is 10.
18% of all verb usages for children but only 4.
65% for adults.
 The vocabulary of children is much less diverse than that of adults and it is obviously more slanted towards weak verbs.
 Whether this difference has implications for language acquisition 237 Input Task Output /g/ 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 00 » * • .
 » • .
 * » .
 » » • » .
 * /el/ 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 00 • » • » • .
 .
 * .
 .
 » .
 .
 * * • /a/ 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 oo » * » » • » » » .
 .
 * * * * * * /n/ 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 00 .
 * .
 • * • • * » .
 .
 , .
 .
 * * 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 /g/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 /9/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 /g/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 /a/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 /t]/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 /a/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 /n/ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 01 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Figure 1: A typical inputoutput sequence for the network.
 The input is the verb gehen, the output the participle gegangen.
 The stars ("•") mark "don't care" states in which the activation of the units is irrelevant.
 needs to be further investigated.
 For the input to the network model the verbs were transcribed to phonetic writing and then encoded with phonetic featurevectors.
 Each of 56 phonemes was represented by a string of 14 features following Wurzel (1981).
 A n additional feature was added to indicate whether a vowel was stressed.
 This was necessary to determine whether the participle would receive the ge prefix (see above).
 In the feature vectors, '1' indicated the presence of a particular feature and '0' its absence.
 Task The task to be learned by the network model was as follows: A verb was presented to the input layer as a sequence of phonetic feature vectors.
 After presenting the input, one of the two task units was activated to determine the required output which was either a phonetic sequence for the infinitive form (that is, a duplication of the previous input) or the participle form of the verb.
 Figure 1 shows a typical sequence in which the input is the word gehen and the output is the participle of gehen, that is, gegangen.
 Network Architecture The network (see figure 2) was composed of two subsystems following the duahstic framework (see also Indefrey and Goebel, 1993): a shortterm memory and a phonological lexicon.
 The shortterm memory had fast weights enabhng it to store a sequence of feature vectors after one presentation and retain the stored information (for a detailed description of the architecture see Goebel 1990, 1991).
 As it has been argued in Goebel (1991), shortterm memory and selective attention are prerequisites for the ability to manipulate symbols.
 The shortterm store thus represented the rule path of the dualistic framework.
 The task of the phonological lexicon was to act as an associative memory for the input verbs transforming the input sequence of phonemes to a locaJist representation which could then act as a "plan vector" for determining the output.
 The lexicon consisted of two layered selforganizing feature maps.
 The lower map, which received the phonetic feature vectors from the input layer, was organized in a 12x12units plane.
 It had been pretrained so that tJl 56 diflferent phonemes were laid out over the map.
 Each unit was connected to itself with a weight of 0.
9.
 This adlowed for a slow decay of unit activation after a phoneme had been presented.
 Thus, when the phoneme sequence of a verb was presented it left a unique trace on the map.
 The phoneme m a p was used as input for the upper selforganizing feature map.
 This feature map had 400 units.
 It was trained so that each trace left by a verb on the phoneme m a p would be clustered to a single maximally responding imit, roughly corresponding to an entry in the phonological mental lexicon.
 Out of the 100 different verbs, 88 clustered to distinct units.
 The remaining twelve verbs were clustered in pairs of two.
 Generally, rhyming verbs were grouped together on the map, for example, heisen, reisen, beisen, and schmeisen clustered to four neighboring units.
 The lexicon had connections to the shortterm store via a control unit.
 The idea behind these connections was that when the participle form was to be produced, the lexicon could inhibit activation of the shortterm store until the prefix ge had been produced.
 After ge had been put out, the shortterm store would be activated by the lexicon and replay the sequence for the input verb.
 Together with the plan vector from the lexicon, the correct participle stem and ending could then be formed.
 The network model operated in two stages, a recognition stage and a production stage.
 In the recognition stage, the input sequence was presented and routed to the two subsystems, shortterm memory and lexicon.
 After training of this recognition stage, the lexicon locally represented the input verb while the shortterm memory held the sequence of phonemes.
 In the production stage, the activated lexical entry together with the sequentially accessible shortterm store produced the required output sequence.
 Performance The production stage of the network was trained on the corpus of 538 tokens for 400 epochs with the backpropagation through time algorithm (Rumelhart et al.
, 1986).
 Throughout the training process, the performance of the network was tested at intermediate stages.
 238 Sequential Output /t/ I 0 0 0 0 0 (I I I I 10 0 0 0 [ Lexicon /n/ 1 000 0 00 0>1 10 110 Task units Phoneuc map Short Term Memory Control Short Term Memory 000000000000000 Sequential Input Figure 2: The network architecture.
 In order to eveduate the role that the lexicon played in learning the task it was cut off and performance with and without the lexicon was compared.
 Learning After training the network for 400 epochs it was able to produce edl 100 infinitives and 93 of the participles correctly.
 All of the seven participles that were not learned were strong verbs having the phoneme /ae/ in the infinitive which was not changed correctly in the participle.
 This error might well be due to a local m i n i m u m on the error surface.
 Interestingly, the most frequent verb, sein with the participle gewesen, was a m o n g the unlearned.
 The infinitive forms were learned well before the participle forms (after 40 epochs), and they were learned equally well with and without the lexicon.
 This was not surprising because the task of producing the infinitive simply consisted in duplicating the input sequence that was stored in the shortterm m e m o r y .
 The learning curve for the participle forms is shown in figure 3.
 W e a k forms and strong participles that did not change their stems were learned equally well.
 Both mixed verbs and strong verbs that changed their stems were learned slower.
 Obviously it was easier for the network to prefix the participles with ge where necessary and learn the correct participle ending than to change the stem.
 In order to evaluate the role of the lexicon in learning the different participle forms, performance was also tested with the lexicon cut off.
 These results are shown in figure 4.
 Most significantly, at early training stages over 6 0 % of the weak participles were produced correctly even without the lexicon (except that the prefix ge was omitweak verbs not changing suong verbs changing strong verbs mixed verbs 100 150 200 Epoch 250 300 350 400 Figure 3: T h e learning curve for the participles of the different verb classes.
 T h e w e a k participles (52 types) were learned after about 60 epochs, the m i x e d participles (7 types) after 300 epochs, the strong participles that kept their stems (17 types) after 320 epochs, a n d the strong participles that required a stem change (24 types) were not fully learned.
 ted because it relied o n the lexicon to inhibit the shortterm store, see above), but n o n e of the strong forms were produced correctly, n o matter whether they changed or kept their stems.
 This result strongly supports the dualistic framework which claims that regular (weak) participles are formed in the rule path but irregulars (strong) are produced with the lexicon.
 H o w e v e r , in contrast to the dualistic framework, the n u m b e r of correct regulars decreased with further tredning.
 This indicated that the lexicon played a role even in the production of s o m e w e a k forms at later stages of training.
 A closer analysis of this p h e n o m e n o n showed that without the lexicon s o m e parti239 weuk verbs not ch.
inyiny struny verbs chanyinj: strnny verbs mixed verbs e; 40 Figure 4: Percentages of the participle f o r m s that w e r e p r o d u c e d correctly w h e n the lexicon w a s cut off.
 InitiaJly over 6 0 % of the weak forms were still produced correctly, but none of the strong verbs were.
 Later, however, the percentage of correct regular forms decreased.
 ciple stems were changed, including those of weak verbs.
 For example, without the lexicon, the participle of the weak hiipfen (to jump) was not produced as gehiipft but as (ge)hupft, and the participle of bewegen not as bewegt, but as bewagt.
 In these cases, the rule path had formed a "default stem change" and cases where this change did not apply (including weak verbs with no change at cill) were the exception and were therefore handled by the lexicon.
 Still, without the lexicon many of the strong and mixed verbs were overgenereJized to the weak form: For about 8 0 % of the strong verbs that did not change their stems, 2 5 % of the strong verbs that did change their stems, and 3 0 % of the mixed verbs now a weak participle was produced, that is, the infinitive stem was kept and a t was sufRxed.
 For example, the participle of nehmen (to take) which should be genommen was now (ge)nehmt and the participle of sein (to be) was (ge)seint instead of gewesen.
 Obviously the network had detected the correlation between not changing the stem and using the t suffix.
 This correlation existed for the 52 weak verbs (67tokens), while only 17 strong verbs (38 tokens) did not change their stems and used the en suffix and only 7 mixed verbs (7 tokens) did change their stems and used the t suffix.
 The fact that the weak participle was overgeneraUzed to all other forms verified computationally that this form is the regular case in the German verb paradigm.
 Generalization GeneraUzation of the network model was tested with 16 nonexisting novel verbs.
 Five of these rhymed with weak verbs, that is, they activated the same unit as a weak verb on the lexicon (e.
g.
 tolen rhymed with holen and pachen with wachen).
 Three test verbs rhymed with existing mixed verbs, three with strong verbs that kept their stems, one with a strong verb that changed its stem, and four did not rhyme with any of the verbs.
 The novel verbs that rhymed with existing verbs formed their participles in the same ways as the existing verbs did: novel verbs rhyming with existing weak verbs were inflected as weak, the ones rhyming with existing strong verbs as strong, and the ones rhyming with mixed verbs were inflected as mixed.
 This result corresponds to psycholinguistic data: Olawsky (1993) showed that the inflection of novel verbs is influenced by rhyming existing verbs.
 Of the four novel verbs that did not rhyme with any of the existing verbs, three were inflected as weak and one had no participle ending.
 This result, too, quahtatively backs the ruleassociative memory hypothesis in producing the regular participle as default when there are no similarities to existing verbs.
 Discussion The results of our experiments show that the modular connectionist network model was able to successfully learn the German verb paradigm, that it generalized to novel verbs in ways comparable to psychoUnguistic data, and that its interned representations qualitatively corresponded to the ruleassociative memory hypothesis (Pinker, 1991).
 Furthermore, the results gave computational evidence that the weak verb class is the regular class in German verb inflection.
 Our model deviates from the ruleassociative memory hypothesis in two important aspects, however: First, the rule path and the associative memory are not strongly dissociated from one another, but both are needed to produce irregular and mixed verbs and even some of the regular verbs.
 The associative memory is needed to allow for stem changes and the en ending of the irregular participles.
 Regularities for novel verbs that do not rhyme with existing verbs emerge because for these verbs the lexicon contributes nothing to the production of the participle, resulting in the shortterm store keeping the infinitive stem and adding the suffix t .
 The experiments further show that certciin "microrules" are incorporated into the shortterm path based on the statistical regularities of the inputoutput phoneme mappings, resulting in certain "default" vowel changes even for regular verbs when the lexicon is cut ofl.
 The second diff"erence to the ruleassociative memory theory is that in our model no rules are hard wired but both the shortterm store and the lexicon are entirely connectionist subsystems.
 The model's architecture is not specifically adapted to represent the characteristics of the German verb system, and its ruleUke behavior emerges solely through the interaction of the shortterm memory and the lexicon.
 This suggests that in humans, also, rulelike behavior can emerge without expUcit rules being present.
 240 C o n c l u s i o n Modeling the German verb paradigm with a modular neural network gave evidence for the theory that two subsystems, a rulepath aind an associative memory, might be involved in handling of this paradigm by humans.
 In contrast to this theory, however, both paths worked together in producing many verb participles, and regular behavior emerged without rules being hard wired.
 Our model can easily be extended to handle homophones: the lexicon only need to contain nonphonological, e.
g.
, semantic information.
 This can be achieved by adding a semantic feature map to the phonological map (see Miikkulainen, 1990).
 Also, the fact that production of the ge prefix in our model relies on the lexicon and not on the phonological properties of the verb can be avoided by controlling the shortterm store from the recurrent hidden layer of our model instead of from the lexicon.
 In principle, network models with similar architectures should be capable of handling all tasks that display default cases and exceptions, for example, script processing and algorithmic problem solving.
 The model, being able to manipulate symbols, might eventujtlly lead to a unified theory of symbolic and subsymbolic computing.
 This will be our meiin direction of future research.
 References Goebel, R.
 (1990).
 A connectionist approach to highlevel cognitive modeling.
 In Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, 852859.
 HiUsdale, NJ: Erlbaum.
 Goebel, R.
 (1991).
 Binding, episodic shortterm memory, and selective attention, or why are P D P models poor at symbol manipulation? In Touretzky, D.
, Elman, J.
, and Hinton, G.
, editors, Connectionist Models.
 Proceedings of the 1990 Summer School.
 San Mateo: Morgan Kaufman.
 Indefrey, P.
, and Goebel, R.
 (1993).
 The learning of weak noun declension in German: Children vs.
 artificial neural networks.
 In Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society, 575580.
 ffiUsdale, NJ: Erlbaum.
 MacWhinney, B.
, and Leinbach, J.
 (1991).
 Implementations are not conceptualizations: Revising the verb learning model.
 Cognition, 40:121157.
 Marcus, G.
, Brinkmann, U.
, Clahsen, H.
, Wiese, R.
, Woest, A.
, and Pinker, S.
 (1993).
 German Inflection: The Exception that Proves the Rule.
 Occasional Paper #47.
 M I T Center for Cognitive Science.
 Miikkulainen, R.
 (1990).
 A distributed feature map model of the lexicon.
 In Proceedings of the 12th Annual Conference of the Cognitive Science Society, 447454.
 Hillsdale, NJ: Erlbaum.
 Olawsky, K.
 (1993).
 Psycholinguistische Experimente zur Partizipienbildung im Deutschen.
 Master's thesis, HeinrichHeineUniversitat Diisseldorf.
 Pinker, S.
 (1991).
 Rules of language.
 5cjence, 253:530535.
 Pregel, D.
, and Rickheit, G.
 (1987).
 Der Wortschatz im Grundschulalter.
 Hildesheim: Georg 01ms Verlag.
 Rumelhart, D.
 E.
, Hinton, G.
 E.
, and WiUiams, R.
 J.
 (1986).
 Learning internal representations by error propagation.
 In Rumelhart, D.
 E.
, and McClelland, J.
 L.
, editors, Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations, 318362.
 Cambridge, M A : M I T Press.
 Rumelhart, D.
 E.
, and McCleUand, J.
 L.
 (1987).
 Learning the past tenses of Enghsh verbs: Implicit rules or parallel distributed processing.
 In MacWhinney, B.
, editor.
 Mechanisms of Language Acquisition.
 Hillsdale, NJ: Erlbaimti.
 Ruoff, A.
 (1981).
 Haufigkeitsworterbuch gesprochener Sprache: Gesondert nach Wortarten alphabetisch, riickldufig alphabetisch und nach Haufigkeit geordnet.
 Tubingen: Niemeyer.
 Wurzel, W.
 (1981).
 Phonologie: Segmentale Struktur.
 In Heidolph, K.
 E.
, Flamig, W.
, and Motsch, W.
, editors, Grundziige einer deutschen Grammatik, 898990.
 Berlin: AkademieVerlag.
 241 Lexical C h a n g e as Nonlinear Interpolation Whitney Tabor Center for the Sciences of Language and Department of Brain and Cognitive Sciences University of Rochester Rochester, N Y 14627 whitney@psych.
rochester.
edu Abstract Current, rulebased theories of grammar do not provide much insight into how languages can develop new behaviors over time.
 Yet, textual data indicate that languages usually evolve new grammatical patterns by gradually extending existing ones.
 I show how a grammar model that is sensitive to prototype structure can model innovation as a process of extrapolation along salient dimensions of the category clusters.
 A Connectionist network provides a usefully interpretable implementation.
 Confirming evidence comes from a study of the development of English be going to as a marker of future tense.
 1.
 Introduction H o w can a highly structured system evolve new behaviors without undergoing dissolution in the process? Natural language is an especially good domain in which to investigate this question: linguistic theory reveals the highly categorical, rulegoverned character of its behavior at any point in time; but historical texts and studies of usage in communities show that change takes place by gradual metamorphosis of the existing system.
 Here I concentrate on grammatical class membership change, taking as a case study the development of the future auxiliary usage of English be going to.
 A key step in developing a model of this process is to take into account information about the relative frequencies of words in grammaticallydefined contexts.
 I model language change by positing a grammar corresponding to every point in time.
 Following c o m m o n linguistic practice, I refer to a single grammar at one point in time as a "synchronic" model, and to a sequence of grammarstates as a "diachronic" model.
 It is useful to examine a diachronic model by drawing a diagram of (part of) its behaviorspace.
 Consider be going to.
 Originally, go was strictly a verb of motion and hence could only be used in the kinds of environments that accomodated verbs like walk, run, ride.
 However, during the past five or six centuries, the particular use of go in the expression be going to has expanded its capabilities and become a marker of future tense as well as a motion verb.
 Thus one can now say (1) It is going to rain tomorrow.
 [Nonagentive V P Compl] where the complement of be going to is a NonAgentive verb phrase (VP) and a motion interpretation is not plausible.
 In this usage it is reasonable to say that be going to is a type of auxiliary verb.
 Clearly, English is currently in the middle phase of this transition for w e can still say: (2) She is going to Sarajevo.
 [Placedenoting N P Compl] where the complement is a Placedenoting Noun Phrase (NP) and only a motion interpretation is possible.
 A type that played an important role in the transition from old to new, and which I will say more about below, is the nowambiguous case, (3) I a m going to deliver this letter.
 [Agentive V P Compl] with an Agentive V P complement.
 If w e consider the relative likelihood with which a given grammar predicts each of these types, then the behavior at any given time can be characterized as a 3dimensional vector.
 Moreover, since the three values form a probability distribution, they are restricted to appearing in the triangle with vertices (1,0,0), (0,1,0), and (0,0,1) in 3space.
' Figure 1, showing just the triangle, shows points corresponding to motion verbs and canonical auxiliary verbs like will based on instance counts in a corpus.
^ These verbs' behaviors have not changed much in the relevant regards during the course of the 16th through the 20th centuries (see Warner (1990) for information on will), so Figure 1 is a reasonable approximation of the behavior diagram for these verbs at every point during this period.
 I model the change in be going to's status as a process of lexical reclassification, treating be going to as a single word.
 This is a nontrivial simplification but it permits the formulation of a model that is both reasonably accurate and easily interpretable.
 Standard linguistic grammars do not normally make predictions about relative frequencies, but there is a natural extension of any generative model which turns it into a statistical model: probabilities can be assigned to the generative rules or parameters.
^ Under such models, with their categorical treatment of lexical representation, it is expected that all behaviors which arise during the process of lexical reclassification can be modelled by assigning words, with varying probabilities to one or more of the existing grammatical classes.
 As a consequence, lexical reclassification is expected to involve purely linear interpolation between behavior states in all but a few cases.
'* 'This representation is called a ternary diagram.
 ^For the auxiliary verbs, I sampled will.
 may.
 and seem to.
 For the motion verbs, I sampled walk.
 run.
 and move.
 'Examples include the probabilistic context free phrase structure grammars used by computational linguists (see Charniak, 1993), the Competing Grammars model of Kroch (1989), the probabilistic Principles and Parameters model of Clark and Roberts (1991).
 ""The exceptions are situations where the changing word appears more than once in a grammatical structure defining a behavior Such cases are rare and are not usually pertinent to assessing the main 242 mailto:whitney@psych.
rochester.
eduTable 1: Quantitative data from the history of be going to—3 dimensions.
 Year Source 1.
 I'lacc 2.
 Agt 3.
 Nonagt Tokens 1590 1695 1796 1841 1884 1907 1911 1970 MOTION AUXILIARY Shakespcaie Defoe Austen Dickens Hardy Lawrence Joyce London Lund (Start state) (End state) 64% 47% 48% 22% 18% 24% 19% 12% 88% 0% 35% 45% 43% 64% 60% 47% 58% 48% 12% 34% 0% 8% 10% 15% 22% 31% 23% 38% 0% 66% 31 62 150 151 149 142 124 139 164 374 Place AUXIIMARY MOTION NonAgt Figure I: Relative positions of Motion Verbs and Canonical Auxiliary Verbs.
 Place „a/io AUXIWARY MO^ON NonAgt Figure 2: The succession of states of be going to—3 dimensions.
 The dotted line is the Linear Model.
 The solid curve is the Nonlinear Model.
 243 If this Linear Interpolation Model is correct, then the study of lexical reclassification Is not of much interest from the standpoint of learning about innovation, because lineaî  interpolation involves only mixture of existing types.
 Here, however, I propose an alternative nonlinear interpolation model with a smoothness constraint, which suggests a more interesting scenario.
 The notion of prototype structure plays a central role: if words that would be assigned to a single monolithic class in a standard linguistic grammar show statistical variation that is asymmetrically distributed around a prototype, then the model forms a representation that is locally alligned with the prototype structure.
 Because of the smoothness constraint, this allignment affects interpolated states as well, so the trajectories of words that change classes are expected to move along channels dictated by the prototype structure.
 In some cases, this intluence produces a trajectory farremoved from the prediction of the linear model—one that can more reasonably be said to involve the occurrence of novel behavior.
 The current work complements its closest relative.
 Hare and Elman (1992 and 1993), which shows how prototypestructured categories can appropriately model the tendency of certain linguistic classes to attract new elements in historical change.
 I show how such categories properly constrain the trajectories of changing elements even when they don't capture them as permanent members.
 Independent support for the notion that languages have prototypestructured categories has been provided by researchers in Cognitive Grammar (Langacker.
 1987; Lakoff, 1987).
 Evidence that prototypebased categories play an important constraining role in historical change has been provided by Warner (1990) and K e m m e r & Israel (to appear).
 A Connectionist network provides a useful implementation of the Nonlinear Interpolation model.
 Consider a 3layer network with a hidden layer that is smaller than its output layer.
 Suppose w e train this network as follows: lexical items are given distinct indexical bit representations^ on the input layer and behaviors (e.
g.
 the behavior of occurring in a paiticular position in particular sentence frame) are given distinct indexical bit representations on the output layer; each training example consists of a single input paired with a single output; the relative probability of each inputoutput pair is the observed relative frequency of the ilemwithbehavior in ' a sample corpus.
 For each input unit, w e want the activation of each output unit to converge on the likelihood that the item corresponding to the input unit will exhibit the behavior corresponding to the output unit.
 Thus, the output activations form a probability distribution.
 Given these specifications, a network with multinomial error function, fixedsigmoid hidden units, and softmax output units, trained with backpropagation is appropriate (Rumelhart et al.
, 1995).
 I model lexical reclassification in this framework by training a network on a set of elements belonging to different classes and considering a straightline trajectory in the hidden unit space from a location associated with one class (Motion verb) to a location associated with a different class (Auxiliary verb).
 Although the trajectory is linear in the hidden unit properties of a word's behavior so I will not consider them further here.
 ''By an indexical hit representation I mean a vector with a value of I on one dimension and 0 elsewhere.
 space, it may not be linear in the output space, so the model's predictions differ from those of the standard grammar models.
 2.
 Case Study: English he ^oiu^ to Quantitative data on the change of be f>oinf> to in the part of behavior space outlined in the previous section are shown in Table I.
 Figure 2 shows the corresponding ternary diagram along with the predictions of the Linear and Nonlinear Interpolation Models.
 The Nonlinear model is a Connectionist network with 10 input units, I hidden unit, and 3 output units.
 The inputs fall into two classes of 5 members each whose behaviors are clustered around the points labelled " M O T I O N " and "AUXILIARY".
 Crucially, the M O T I O N inputs vary only along dimensions I and 2 (Place and V P Agentive).
 while the A U X I L I A R Y inputs vary only along dimensions 2 and 3 (VP Agentive and V P NonAgentive).
 This kind of restricted prototype scatter reflects a situation c o m m o n in language u.
se: there is high variation along dimensions that are simultaneously allowed by a categorical grammar but essentially no variation along dimensions that are disallowed.
 Clearly the historical trajectory is skewed in the direction predicted by the Nonlinear Model.
 This is an interesting finding not only because it shows how quantitatively unusual behavior can arise in the course of a simple reclassification episode, but also because it indicates that by monitoring subtle quantitative changes, it may be possible to make predictions about subsequent categorical changes: in Shakespeare (1590).
 be going to shows no instances of novel behaviors (Danchev and Kyto, 1991), but it's distribution is highly skewed in the direction that indicates imminent appearance of such behaviors.
 It turns out that the history of be going to is more complex than this simple portrayal indicates.
 Linguistic theories generally distinguish two types of auxiliary verbs, called Ecjui and Raising.
 Criteria often considered diagnostic of Raising status include ability to take "dummy" subjects (/f seemed/appeared/tended to rain.
.
 There .
seemed to he a thundercloud on the horizon.
) and ability to intervene in idioms (The cat seems to be out of the bag.
).
 Equi verbs contrast in both regards, (e.
g.
, McCawley, 1988).
 W e can add the fact that Raising verbs permit inanimate subjects while Equi verbs do not, except in an anthropormorphic sense (e.
g.
.
 The table seems to be unpainted.
 # The table wants to he unpointed.
).
 A good summary of the constraint imposed by Equi verbs is that they require "sentient" subjects.
 Raising verbs, by contrast, simply put no constraints on the type of their subject (Nunberg, Sag, and W a s o w 1994).
 By these diagnostics, the auxiliary verb m// is a raising verb in its use as a future marker, for one can say things like // will rain and The table will fit in the corner.
 Perez (1990) notes that be going to went through a stage in the 17lh19th centuries in which it seemed to have a meaning like intend before it developed the very general distribution it has today.
 Thus we might hypothesize that be going fo's transition was actually a three stage process: Motion — Equi — Raising.
 This provides an interesting challenge for the diachronic model: can it nonstipulatively generate the intermediate stage? To clearly distinguish Equi and Raising verbs, it will be 244 Year Table 2; Quantitative data from the history of be going to—4 dimensions.
 Source 1.
 Place 2.
 Agl 3a.
 Sent/Nonagt Nonsent/Nonagt Tokens 1590 1695 1796 1841 1884 1907 1911 1970 MOTION EQUI RAISING Shakespeare Defoe Austen Dickens Hardy Lawrence Joyce London Lund (Start state) (End state) 64% 47% 48% 22% 18% 24% 19% 12% 88% 0% 0% 35% 45% 43% 64% 60% 47% 58% 48% 12% 91% 34% 0% 8% 9% 15% 15% 19% 13% 20% 0% 8% 37% 0% 0% 1% 0% 7% 12% 10% 18% 0% 1% 29% 31 62 150 151 149 142 124 139 164 415 374 Place onsent Sent Figure 3: Motion, Equi, and Raising Verb locations.
 245 useful to make the behavior space 4dimensional by breaking Behavior 3 down into two parts: nonagentives with sentient subjects and nonagentives with nonsentient subjects.
 (3a) The man was going to I'aint.
 [Sentient Subject, NonAgentive V P ] (3b) There is likely to be an eclipse.
 [NonSentient Subject, NonAgentive V P ] This makes Raising verbs categorically different from Equi verbs since Equi verbs do not normally occur with nonsentient subjects (* There expected to be an eclipse), although they sometimes occur with nonagentive complements {Gregor expected to faint).
 Table 2 gives quantitative data under this portrayal.
 Under the constraint that they form a probability distribution in 4space, the outputs are now restricted to a threedimensional subset in the form of a tetrahedron.
 Figure 3 shows the mean locations of Motion, Equi, and Raising verbs on the tetrahedron.
 Figure 3 is unambiguous given the knowledge that all the depicted points lie on exposed surfaces (and edges) of the tetrahedron.
 However, since be going to's trajectory need not lie entirely on the surface, I now switch to a different display scheme.
 Figure 4a shows a threedimensional "parallel coordinate" image of the trajectory predicted by the Linear Interpolation Model.
 The Xaxis marks timepoints, the Yaxis marks behavioral category, and the Zaxis measures relative probability.
 Figure 4b shows the trajectory predicted by a nonlinear, connectionist model (time has been scaled for a good fit).
 This model has 15 input units, 2 hidden units, and 4 output units.
 A s in the last example, it was trained on data with prototype scatter along dimensions that are categorically positive for each wordtype.
 Note the significant skewing of the trajectory in the direction of Equi status in the middle of the transition (indicated by the peak in behavior 2 around 1800).
 Figure 4c shows the historical data.
^ Indeed, this diagram reveals a significant skewing in the direction of Equi behavior, confirming Perez's impressionistic observations and confirming the predictions of the Nonlinear Model.
 It is interesting to note, however, that be going to does not actually ever inhabit a canonical Equi state but only passes near such a state.
 This seems in keeping with the observation that while there are many historical examples during the 17th19th centuries which can reasonably be assigned an intend interpretation, there seem to be none that definitively require it.
 Example (4) is a typical case.
 (4) c.
 1695 H e was going to reply.
.
.
 but he heard his sister coming, Defoe, Moll Flanders.
 3.
 Conclusion I started by touting natural language as a worthy domain for studying change in highly structured systems.
 Focusing on lexical reclassification episodes, I noted that standard models predict nothing that could reasonably called "innovation", for they only perform linear interpolation, which is equivalent to mixture of existing types.
 By contrast, a simple Connectionist model performs nonlinear interpolation and hence predicts ''The pure motion verb starting state and the (hypothetical) pure future auxiliary ending state have been included at the dates 1400 and and 2100, respectively, to facihtate comparison with the two interpolation models.
 Legend X: Year Y: 1 = Place N P 2 = Agentive V P Compl.
 3 = Sentient Subject + NonAgentive Compl.
 4 = NonSentient Subject + Nonagentive Compl.
 Z: Relative Frequency a.
 Linear interpolation.
 b.
 Nonlinear interpolation.
 c.
 Historical Data.
 Figure 4: Comparison ol Models—1 dimensions.
 246 interestingly novel states.
 I noted that data distributed around reduceddimension prototypes, as is typical in natural language, interacts with this Nonlinear Interpolation model in a strong way: transitions are expected to be locally consiranKil by the prototype structure.
 This prediction is born out by data from the history of English be going to.
 One conclusion of interest is that subtle quantitative shifts may anticipate significant categorical developments and hence have predictive value.
 Also, quantitative variation is intimately connected with optionality: linguistic items show significant quantitative variation only when grammar is indeterminate as to how something should be said.
 While it is tempting to think of optional decisions as inherently unbinding (if one chooses A one day, and A is optional, then one may legitimately choose ij4 the next), the present study indicates that a sequence of correlated optional decisions can, in the domain of grammar, bring about revision of the rules, so that what was once optional becomes mandatory or vice versa.
 The conditions under which such creeping systemic revision can occur must be of interest not only to historical linguists, but also to biologists and sociologists—even politicians! Acknowledgements Thanks to Robert Jacobs, Michael SpiveyKnowlton, and anonymous reviewers for helpful comments.
 The text corpora where made available by the Oxford Text Archive, BookStacks, Project Gutenberg, and the Trent University Archive.
 The research has been supported in part by postdoctoral fellowship funding to the Center for the Sciences of Language (NIHNIDCD 5T32DC003504).
 References Chamiak, E.
 (1993).
 Statistical Language Learning.
 MIT Press, Cambridge, Massachusetts.
 Clark, R.
 and Roberts, I.
 (1991).
 A computational model of language leamability and language change.
 Linguistic Inquiry, 24(2):299345.
 Danchev, A.
 and Kyto, M.
 (1991).
 The construction be going to + infinitive in Early Modern English.
 In Kastovsky, D.
, editor.
 Papers from the Early Modern English Conference (EMEC), Tulln, I99L Mouton de Gruyter Hare, M.
 and Elman, J.
 L.
 (1992).
 A connectionist account of English inflectional morphology: evidence from language change.
 In 14th Cognitive Science Proceedings, pages 265270.
 Lawrence Edbaum.
 Hare, M.
 and Elman, J.
 L.
 (1993).
 From wearedlo wore: a connectionist account of language change.
 In 14th Cognitive Science Proceedings, pages 265270.
 Lawrence Edbaum.
 Kemmer, S.
 and Israel, M.
 ((to appear)).
 Variation and the usagebased model.
 In CLS 30 Parasessionon Variation and Linguistic Theory.
 University of Chicago Press.
 Kroch, A.
 S.
 (1989).
 Reflexes of grammar in patterns of language change.
 Journal of Language Variation and Change, 1 (3): 199244, Lakoff, G.
 (1987).
 Women, Fire, and Dangerous Things.
 University of Chicago Press, Chicago.
 Langacker, R.
 W.
 (1987).
 Foundations of Cognitive Grammar, v.
 1.
 Stanford University Press, Stanford, California.
 McCawley, J.
 D.
 (1988).
 The Syntactic Phenomena of English, v.
 12.
 The University of Chicago Press, Chicago.
 Nunberg, G.
, Sag, I.
 A.
, and Wasow, T.
 (1994).
 Idioms.
 Language, 70(3):491538.
 Pdrez, A.
 (1990).
 Time in motion: Grammaticalisation of the be going to construction in English.
 La Trobe University Working Papers in Linguistics, 3:4964.
 Rumelhart, D.
, Durbin, R.
.
 Golden, R.
.
 and Chauvm.
 Y.
 (1995).
 Backpropagation: The basic theory.
 XnBackpropagation: Theory.
 Architectures, andApplicatins.
 Lawrence Erlbaum.
 Wamer, A.
 (1990).
 Reworking the history of English auxiliaries.
 In Adamson, S.
, Law, V.
, Vincent, N.
, and Wright, S.
.
 editors.
 Papers from the Fifth International Conferenceon English Historical Linguistics.
 John Benjamins.
 247 H o w Misconceptions Affect Formal Physics Problem Solving: ModelBased Predictions and Empirical Observations Rolf Ploetzner Department of Psychology University of Freiburg D79085 Freiburg, Germany p l o e t z @ p s y c h o l o g i e .
 u n i  f r e i b u r g .
 d e Abstract One important finding in physics education is that very often students enter physics courses with misconceptions about the domain.
 An often raised, but hardly ever thoroughly investigated question is whether and how students' misconceptions in physics come into play in solving formal textbook problems which ask for a precise quantitative solution.
 W e developed a cognitive computer model of the role qualitative physics knowledge plays in formal physics problem solving.
 On the basis of the model it cannot only be hypothesized where misconceptions might come into play during formal physics problem solving, but also which correct qualitative physics knowledge should be applied instead in order to guide the use of quantitative physics knowledge efficiently and successfully.
 In particular, the model predicts that the application of misconceptions prevents the results of qualitative problem analyses from being exploited to construct additionally required formal, quantitative physics knowledge.
 An empirical investigation confirmed that misconceptions frequently affect formal physics problem solving in the way predicted by the model.
 Commonly, subjects who applied misconceptions during problem solving reached an impasse when they tried to express the results of their qualitative problem analyses in quantitative terms.
 Most of the subjects were not able to resolve such an impasse successfully.
 Introduction One of the major findings in research on science education in formal sciences such as physics is that students before instruction develop preconceptions about the phenomena that physicists explain (for a bibliography see Pfundt & Duit, 1991).
 Because very often these preconceptions differ from the concepts taught, they are firequently named misconceptions.
 Though misconceptions have received much attention in research on science education, the major work consists in documenting as many of them as possible.
 Commonly, to pinpoint misconceptions, problems are posed to students which can be solved by exclusively making use of conceptual, qualitative physics knowledge.
 Figure la shows a problem that is exemplary for the problems which have frequently been taken advantage of by investigators of misconceptions in physics (e.
g.
, Clement, 1982; McCloskey, 1983).
 To solve such a problem it is not required to apply formal, quantitative physics knowledge which relies on A coin is thrown straight up in the air and comes straight back down again.
 Using the dots on its path, draw the forces acting on the coin at that point in its path.
 a) C e B •D b) I B • D •{ Figure 1: A physics problem to pinpoint misconceptions (a) and a frequently observed incorrect solution (b).
 mathematical formalisms such as algebraic equations.
 Figure lb displays a frequently observed incorrect solution to the problem shown in Figure la.
 In addition to the gravitational force, it erroneously involves an upwardpointing, decreasing, and nonexisting force to account for the object's motion.
 Since this misconception resembles in many ways the concept of impetus as it was discussed during the middle ages by Philoponus and others (for a discussion see Franklin, 1976; Szabo, 1976), it is usually named impetus concept, one of the most prominent misconceptions in classical mechanics.
 Typically, the impetus concept is applied to moving objects characterized by the absence of a proper force in the direction of motion.
 In research on physics education, much less attention has been given to describing whether and h o w misconceptions such as the impetus concept also come into play during formal, quantitative physics problem solving and to modeling the problem solving of successful students.
 This 248 mailto:ploetz@psychologie.
unifreiburg.
deneglect might be rooted in an assumption that seems to be considerably widespread in the physics education community.
 It is often assumed that conceptual, qualitative physics knowledge is a subset of formal, quantitative physics knowledge.
 Thus, mastering quantitative physics should cause mastery of qualitative physics and hence remedy qualitative physics errors including those based on misconceptions.
 As a consequence, instruction frequently focuses on quantitative physics knowledge in order to set up conditions on which misconceptions are not applicable any more.
 Though we have not found explicit statements expressing this assumption, we have inferred it from how the relationship between qualitative and quantitative physics knowledge is frequently addressed in the literature as well as in physics textbooks.
 In recent studies, however, we were able to show that qualitative physics knowledge is on no account a mere subset of quantitative physics knowledge (Ploetzner, 1993; Ploetzner & VanLehn, in preparation).
 Instead, both kinds of knowledge encode complementary information.
 In particular, successful problem solving approaches frequently demand the coordinated use of both kinds of knowledge.
 Due to these findings it is not safe to assume that misconceptions do not affect formal physics problem solving.
 W e developed a cognitive computer model of the role qualitative physics knowledge plays in formal, quantitative problem solving.
 O n the basis of this model it cannot only be hypothesized where misconceptions might come into play, but also which correct qualitative physics knowledge should be applied instead.
 After a brief overview of the cognitive computer model has been presented, the model is taken advantage of to predict how misconceptions might affect formal physics problem solving.
 Thereafter an empirical study is described bringing to the fore how students* formal problem solving is influenced by misconceptions.
 The text concludes with a short discussion of the findings.
 The Coordinated Use of Qualitative and Quantitative Physics K n o w l e d g e To better understand how qualitative and quantitative physics knowledge complements each other in formal, quantitative problem solving, we developed a cognitive computer model which simulates how the use of correct qualitative and quantitative knowledge can be coordinated to solve textbook problems in physics successfully and efficiently (Ploetzner & Spada, 1993).
 The problems are taken from the domain of onedimensional motion with constant acceleration.
 The knowledge investigated is made up of qualitative and quantitative physics knowledge about various concepts in dynamics (e.
g.
, gravitational, normal, and friction force) and kinematics (e.
g.
, position, velocity, and acceleration).
 The model has been implemented in Prolog by taking advantage of an equationbased representation language similar to the representation language employed by VanLehn, Jones and Chi (1992).
 Qualitative physics knowledge encodes information such as the abstractions to be considered in a certain problem situation, the conditions on which physics concepts can legitimately be applied, the attributes possessed by physics concepts and the values concept attributes might have.
 Quantitative physics knowledge encodes precise functional relationships between the physics concepts by means of algebraic and vectoralgebraic equations.
 The main focus of the model is on how the results of qualitative reasoning can be taken advantage of during subsequent quantitative problem solving.
 The model simulates characteristic differences in the problem solving performance of those subjects w h o coordinate their qualitative and quantitative physics knowledge and those subjects who do not.
 Especially, on the basis of the model it can be shown that efficient and successful problem solving in the application domain requires the coordinated use of qualitative and quantitative physics knowledge.
 Coordination can take place within the model in two different ways.
 Firsdy, by drawing on vectoralgebraic knowledge, the results of qualitative problem analyses are expressed in algebraic terms to construct additional quantitative physics knowledge not available to the model beforehand.
 It may algebraically specify the resultant force on an object whose motion has to be analyzed, for example.
 In many cases, such additionally constructed quantitative knowledge is a necessary prerequisite for being able to solve the posed problems.
 Secondly, the outcome of qualitative reasoning is exploited to constrain the use of already available quantitative knowledge.
 This kind of coordination makes quantitative problem solving more efficient because h o w quantitative physics knowledge is used depends more on the way how the problem is represented qualitatively and less on what is the unknown quantity.
 For further details about the cognitive computer model the interested reader is referred to Ploetzner and Spada (1993).
 The role qualitative domain knowledge plays in problem solving has been previously investigated with respect to other domains as well.
 For example, Ohlsson and Rees (1991) developed a cognitive computer model which simulates how knowledge about qualitative domain principles in mathematics can be taken advantage of to constrain problem solving.
 Predictions To predict how misconceptions such as the impetus concept affect formal physics problem solving the qualitative knowledge available to the model has been extended with incorrect qualitative knowledge which encodes the misconceptions under scrutiny.
 Subsequently, the model has been applied to a number of formal physics problems and 249 its change in problem solving performance has been analyzed.
 In the model, the application of misconceptions during formal physics problem solving affects both kinds of coordination as described above.
 With respect to the first kind of coordination, the application of misconceptions such as an impetus concept results in qualitative problem representations which cannot be utilized to construct additionally required quantitative knowledge.
 This is mainly due to the fact that misconceptions have no formal, quantitative counter parts.
 If qualitative problem representations which involve misconceptions have to be expressed algebraically, an impasse is reached.
 In the model, such an impasse can only be overcome by dropping the misconceptions and by applying correct qualitative knowledge instead.
 Otherwise, additionally required quantitative physics knowledge cannot be constructed and problem solving fails.
 With respect to the second kind of coordination, the application of misconceptions results in qualitative problem representations which can only partially be exploited to constrain the subsequent use of quantitative physics knowledge.
 In solving simple problems which do not require the first kind of coordination this (merely) leads to less efficient problem solving behavior.
 Thus, on the basis of the model it is predicted that the application of misconceptions by humans during formal physics problem solving affects their ability to coordinate their qualitative and quantitative physics knowledge in the ways just described.
 Since the problems considered in this text do require the first kind of coordination, the question of efficiency is not considered any further.
 Empirical Investigations In order to examine how students coordinate their qualitative and quantitative physics knowledge in formal problem solving, w e conducted an empirical study which comprised 28 subjects (6 females and 22 males) who were students of a technically oriented high school.
 In this type of school, adults m a y receive a degree which qualifies for university entrance after they have already completed a first professional training.
 The grade corresponded to grade 13.
 The subjects' age ranged between 20 and 28 years.
 At the time the investigation took place, the physics of particle motion in one dimension had been taught to the students about 9 months before.
 In the course of the study, the subjects had to work on five textbook problems.
 All problems asked for a precise quantitative solution.
 During problem solving, the subjects had available two tables.
 The first table showed all the quantitative physics relevant to the posed problems.
 The second table presented a short summary of how to resolve vectors for their components.
 The subjects were urged to use only the provided materials, to apply no energy principles, to make notes of all their attempts to solve a problem as detailed as possible and to work on the problems as in a classroom examination.
 In the following, only those problems posed to the subjects will be considered which are characterized by the absence of a force in the direction of motion (cf.
 Table 1).
 Since the impetus concept could be applied to each of these problems, they are of special interest with respect to the question of how students' misconceptions affect their performance in formal problem solving.
 Table 1: Three problems characterized by the absence of a force in the direction of motion.
 Problem 1: What is the minimum stopping distance for a car travelling along a flat horizontal road with the velocity v = 30 m/s, if the coefficient of friction between tires and road is/= 0.
67 Problem 2: A coin is tossed straight up into the air with the velocity v = 7 m/s.
 H o w far up does the coin go until its velocity is reduced to v = i m/sl Problem 3: A block of mass m = 10 kg is projected up an inclined plane widi the velocity v = 5 m/s.
 The plane is inclined at an angle a = 3(fi.
 H o w far up the plane does the block go, if the coefficient of friction between block and plane is/= 0.
31 Table 2 shows the observed number of correct and incorrect solutions to each problem.
 In many cases subjects were not able to come up with a final solution but stopped working on the problem.
 The application of an impetus concept has been diagnosed in 7 cases with respect to Problem 1, in 5 cases with respect to Problem 2 and in 16 cases with respect to Problem 3.
 Generally, the application of an impetus concept has been diagnosed, whenever a subject drew or verbally referred to a force in the direction of motion.
 One subject applied an impetus concept to all three problems, five subjects applied an impetus concept to Problem 1 and 3, four subjects to Problem 2 and 3, one subject only to Problem 1 and six subjects only to Problem 3.
 Table 2: Observed number of correct and incorrect solutions.
 Correct solutions Incorrect solutions N o solution 1 14 4 10 Problem 2 7 13 8 3 9 14 5 Z 30 31 23 Further misconceptions which have been diagnosed (cf.
 also Halloun & Hestenes, 1985) are the beliefs that an 250 object subjected to a constant force moves with constant velocity (3 applications) and that acceleration and velocity are the same concepts (4 applications).
 Unlike what is commonly believed, these results clearly demonstrate that students frequently make use of their misconceptions such as an impetus concept even in a formal problem solving setting.
 However, had the application of an impetus concept any consequences with respect to the correctness of the problem solutions? Table 3 reveals that the number of correct problem solutions decreased significantly, if an impetus concept had been applied (x^ = 13.
26; df = 2; p < .
01).
' The use of misconceptions obviously affected formal problem solving in that it frequently led to incorrect or no problem solutions at all.
 Table 3: How the use of an impetus concept affects the correctness of problem solutions.
 impetus applied no impetus applied I correct solution 3 27 30 incorrect solution 12 19 31 no solution 13 10 23 Z 28 56 84 i:f = ? In which direction does the friction force act? Does it always act opposite to the direction of motion? Ifso:IF = Fp,,h(Fgy + Ff) N o w I have the same problem as in the previous case; how to derive F from v? I'm searching for t! Ar = 1/2 * a * At^ V = a * At, At = V / a » * a = m * apush  (» * ag^ i m * af) apush and agx are unknown, I can't figure them out.
 (Translations by the author.
) Figure 2: H o w a subject failed by applying an impetus concept.
 As predicted by the model, in most of the cases, subjects who applied an impetus concept encountered severe difficulties in their problem solving attempts exactly when the results of their (incorrect) qualitative problem analyses had to be coordinated with the use of their quantitative physics knowledge.
 In 25 cases (89%) in which an impetus concept has been applied, subjects were not able to express the results of their (incorrect) qualitative reasoning algebraically and reached an impasse.
 12 subjects resolved this impasse by means of illegal algebraic transformations, for example, leading to incorrect problem solutions.
 13 subjects, however, stopped making any further effort to solve the respective problem.
 Figure 2 exemplifies such an observed problem solving behavior with respect to Problem 3.
 Apparently, the subject holds an impetus concept.
 It constructs a freebody diagram which, among other inadequacies, visualizes a nonexisting force in the direction of motion.
 The subject refers to this force by the symbol Fp̂ ^̂ ^̂ .
 In accord with the freebody diagram, an incorrect resultant force is subsequently derived.
 Thereafter, the subject writes down various kinematics laws, but finally fails to derive the problem's solution because she is not able to determine the blocks acceleration.
 1.
 This is not to say that the problems would have been solved correctly otherwise.
 Many subjects made multiple errors during problem solving such as applying an impetus concept and neglecting some relevant proper physics concept.
 Only in 3 cases subjects w h o applied an impetus concept came up with correct problem solutions.
 After one subject failed to algebraically express an arrow drawn in the direction of motion, he simply dropped the impetus concept represented by that arrow and successfully resumed its problem solving attempts.
 T w o subjects determined the correct problem solutions by treating the assumed impetus concepts algebraically as if they were resultant forces.
 Conclusions On the basis of a cognitive computer model it has been predicted that misconceptions also might come into play when solving physics problems which ask for precise quantitative solutions.
 In particular, it has been predicted that the use of misconceptions makes it difficult to exploit qualitative problem representations in constructing additionally required quantitative physics knowledge.
 A n empirical investigation confirmed the modelbased prediction.
 Students who applied misconceptions reached an impasse in their problem solving attempts when they tried to express the results of their qualitative reasoning in quantitative terms.
 In most of the cases the students were not able to resolve such an impasse successfully.
 By means of the model, however, it cannot only be hypothesized how misconceptions affect formal physics 251 problem solving, but it can also be demonstrated which correct qualitative physics knowledge should be applied instead and how it can be taken advantage of to construct and guide the use of quantitative physics knowledge.
 In an instructional setting, the model can thus serve as a basis for supporting individual problem solving (and learning) especially when an impasse due to the use of misconceptions has been reached.
 VanLehn, K.
, Jones, R.
 M.
, & Chi, M.
 T.
 H, (1992).
 A model of the selfexplanation effect.
 The Journal of the Learning Sciences, 2, 159.
 A c k n o w l e d g e m e n t s This research was supported by the German National Research Foundation (Deutsche Forschungsgemeinschaft) under contract Sp 251/61.
 I thank Hans Spada who supported the research reported herein and who gave valuable comments on an earlier version of this paper.
 Two anonymous reviewers provided many detailed comments and suggestions which helped to further improve the paper.
 The help of Johannes Bellert, Michael Bosnjak, and Kai Linder in conducting the empirical investigations and analyses is appreciated.
 References Clement, J.
 (1982).
 Students' preconceptions in introductory mechanics.
 American Journal of Physics, 50, 6671.
 McCloskey, M .
 (1983).
 Naive theories of motion.
 In D.
 Centner, & A.
 L.
 Stevens (Eds.
), Mental models (pp.
 299324).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Franklin, A.
 (1976).
 The principle of intertia in the middle ages.
 Boulder, C O : Colorado Associated University Press.
 Halloun, I.
 A.
, & Hestenes, D.
 (1985).
 C o m m o n sense concepts about motion.
 American Journal of Physics, 53, 10431055.
 Ohisson, S.
, & Rees, E.
 (1991).
 The function of conceptual understanding in the learning of arithmetic procedures.
 Cognition and Instruction, 8, 103179.
 Pfundt, H.
, & Duit, R.
 (1991).
 Bibliography: Students' alternative frameworks and science education (3rd ed.
).
 Kiel: Institute for Science Education.
 Ploetzner, R.
 (1993).
 H o w quantitative problem solving in mechanics improves by qualitative reasoning.
 In R Brna, S.
 Ohisson, & H.
 Pain (Eds.
), Proceedings of the World Conference on Artificial Intelligence in Education (pp.
 282289).
 Charlottesville, VA: Association for the Advancement of Computing in Education.
 Ploetzner, R.
, & Spada, H.
 (1993).
 Multiple mental representations of information in physics problem solving.
 In G.
 Strube, & K.
 F.
 Wender (Eds.
), The cognitive psychology of knowledge (pp.
 285312).
 Amsterdam: Elsevier Science Publishers.
 Ploetzner, R.
, & VanLehn, K.
 (in preparation).
 The acquisition of informal physics knowledge during formal physics training.
 Szabo, I.
 (1976).
 Geschichte der mechanischen Prinzipien und ihrer wichtigsten Anwendungen.
 Basel: Birkhaeuser.
 252 T h e Effects of SelfExplanation on Studying Examples and Solving Problems William A.
 Sandoval Institute for the Learning Sciences and School of Education & Social Policy Northwestern University Evanston, Illinois 60208 s a n d o v a l i i l s .
 n w u .
 e d u J.
 G r e g o r y T r a f t o n Naval Research Laboratory Code 5513 4555 Overlook Ave.
 S.
W.
 Washington, D C 203755337 t r a f t o n @ i t d .
 n r l .
 n a v y .
 m i l B r i a n J.
 Reiser Institute for the Learning Sciences and School of Education & Social Policy Northwestern University Evanston, Illinois 60208 r e i s e r @ i l s .
 n w u .
 e d u Abstract Examples play a critical role in guiding the acquisition of cognitive skills.
 W e have argued that students need to apply the knowledge gathered from studying examples to solve analogous problems for that knowledge to be effective.
 There is a tradeoff between the active nature of constructing solutions and the facilitating effect of guiding problem solving with a worked example.
 The present study examined the impact of selfexplanations on the effectiveness of examples in guiding later problem solving.
 W e found that within a learning environment which provided direct support for the selfexplanation of worked examples, such study could be as effective as direct problem solving practice.
 Introduction There has been much attention focused on the role of examples in acquiring new skills.
 Examples clearly play a critical role in guiding learning (Sweller, 1988).
 Students strongly focus on examples in instructional material, and the ways in which students process examples has a strong effect on their later problem solving (Chi, Bassok, Lewis, Reimann, & Glaser, 1989; VanLehn, Jones, & Chi, 1992).
 In a recent series of experiments, w e examined the ways in which processing examples can be useful in acquiring problem solving knowledge (Trafton, 1994; Trafton & Reiser, 1993).
 W e argued that students need to apply the knowledge gathered from studying examples to solve later problems in order to form useful problem solving skills (cf.
 Anderson, 1987).
 The effectiveness of studying annotated examples was reduced when a related problem to solve did not immediately follow the studied example, suggesting that drawing upon information studied from an example to construct one's own solution to a new problem is an important component of acquiring problem solving knowledge.
 These results emphasize the importance of the manner in which students process instructional examples.
 A n important approach in this work has been to manipulate students' study activities on a set of source problems, and then examine the effects of working with those sources on their ability to solve later analogous target problems.
 Source and target problems overlap in the knowledge and subskills needed to solve them.
 What influences the effectiveness of a source problem in guiding later problem solving? Sweller and Cooper (1985) argued that studying worked examples as sources is more effective than solving the same problems.
 They found that studying examples interleaved with problem solving drawing upon those sources produced more effective performance on later posttests than solving those same sources.
 In contrast, Trafton (1994) found that solving sources led to superior posttest performance, and produced faster problem solving on the targets than studying the same example sources.
 Clearly, there are many factors that might influence the relative effectiveness of encoding source problems through study or solving them oneself.
 Trafton and Reiser (1993) argued that there is a tradeoff between the active nature of constructing solutions, in which students must perform subgoal decomposition, operator selection, and execution, and the facilitating effect of guiding problem solving with a worked example.
 If the search space is extensive, then the guidance of an example may greatly facilitate problem solving, and it may be difficult to map from a solution constructed with much patching and debugging.
 Yet, if the problem solving can be made more productive by reducing the overhead of constructing solutions, making them more easily interpretable, then the additional practice of generating solutions may be more profitable.
 Trafton (1994) found that when the learning environment provided sufficient support for instrumental parts of the task (e.
g.
, minimizing the cognitive load of syntax and debugging in programming), the extra practice involved in constructing solutions to source problems outweighed the benefits of the guidance provided by worked examples.
 The strategies used to process examples may also mediate their effectiveness relative to solving problems.
 Subjects who take a more active role in studying solutions, attempting to explain each component, considering why it was selected and how it operates, learn more from studying those examples (Chi, et al.
, 1989; VanLehn, et al.
, 1992).
 Thus, the degree to which subjects treat examples as problems to be 253 mailto:trafton@itd.
nrl.
navy.
milmailto:reiser@ils.
nwu.
edumentally solved affects how well those examples can function in guiding later problem solving.
 The initial evidence for the effectiveness of selfexplanation has been correlational, relying on classifying more and less successful problem solvers and looking for associated differences in their selfexplanation behavior on examples in the lesson (Chi, et al.
, 1989; PiroUi & Recker, 1994).
 Recently, there has also been an attempt to train selfexplanation and see whether subjects thus trained perform better in later lessons (Bielaczyc, Pirolli, & Brown.
 1994).
 H o w does selfexplanation affect the relative efficacy of studying examples versus solving problems? Again, w e focus on the use of knowledge acquired from processing a source problem to facilitate constructing solutions to target problems.
 Can selfexplained examples as sources function as effectively as solving those problems themselves? The present experiment examines this question, using a supportive learning environment for LISP programming, in which we had previously observed superior performance with solved sources (Trafton, 1994).
 Second, we consider whether selfexplanation also affects the efficacy of a solved problem.
 W e are exploring the extent to which selfexplanation can be supported in the structure of the learning environment activities.
 In our work on learning environments, we have argued that environments can be constructed to be congruent with effective reasoning strategies (Merrill & Reiser, 1994).
 In the present experiment, w e examine the support a learning environment can provide for selfexplanation strategies.
 Method Design W e examined novices learning to program in LISP.
 W e presented subjects with pairs of source and related, but not isomorphic, target problems which overlapped in the subskills necessary for their solution.
 W e manipulated the type of source problem (worked example or problem to solve) and whether subjects were given instructions to selfexplain while studying or solving the source problems.
 Source and target problems were interleaved to enable examination of the effects of the source study method on solving problems requiring overlapping subskills.
 A sample source/target pair is shown below: • Source Problem: A sales company has planned all the routes of its sales personnel.
 Then management decided that all sales personnel must begin each trip at the nearest branch office instead of whatever they had originally planned as a first destination.
 Write a function that takes two inputs — the new destination, e.
g.
 Chicago, and a list of old destinations, e.
g.
 (detroit cinci stl), and replaces the first destination of the list with the new destination.
 The output should be the new route ~ e.
g.
, (chicago cinci stl).
 • Target Problem: While a university admissions worker was entering personal information about students, it was discovered that many last names were entered incorrectly.
 To simplify future data input, write a function that takes a correct last name, e.
g.
, smith, and a list of personal information, e.
g.
, (John smit 24 psychology), and returns a new, corrected list with the last name replacing both the first and last name of the old list, e.
g.
 (smith 24 psychology).
 Your function should take two inputs: the first should be the correct last name (an atom), and the second should be the old information (a list).
 Subjects in the Example conditions studied a problem statement, presented with a motivating cover story, and a solution presented with no annotation other than a sample input and its output.
 These subjects also constructed the example solutions in the editor, to equate for interface practice in building, editing, and running programs across all conditions.
 Subjects in the Solve conditions saw the same source problems but solved them entirely on their own.
 All conditions solved the same target problems, which were indistinguishable in presentation from the source problems of the Solve conditions.
 All problems were taken from Trafton (1994), and were modified to exclude the annotations used in this earlier study; piloting showed that subjects were at a loss as to what to selfexplain when given fully annotated examples.
 All problems were presented in the same order to all subjects.
 The design is summarized in Table 1.
 Table L Design of the learning sessions E x a m p l e Solve N o SelfExplain Studied example sources; solved targets Solved sources and targets SelfExplain Explained aloud example sources; solved targets Solved and explained aloud sources; solved targets Apparatus and Materials Subjects worked with VSE , an interactive learning environment for LISP which provides significant support for the operational aspects of programming: ensuring legal syntax and providing strong support for testing and debugging programs.
 (VSE is described more completely in Merrill & Reiser, 1994).
 Programs are built in V S E by dragging functions from a menu and placing them into an initially skeletal function body (containing a defun form with a given name and empty parameter list), significantly simplifying the code construction process.
 V S E also enables students to run their programs on test inputs, either all at once or stepbystep.
 Solutions are then submitted to V S E, which 254 informs students if their solutions are correct or not.
 Further, a debugging probe allows students to inspect intermediate function output values during a run.
 Finally, V S E provides simple hints on legal use of functions when errors arise while running programs.
 V S E allows students to focus less on the operational aspects of programming LISP functions, and more on the semantics of combining functions.
 For the SelfExplain conditions, V S E was slightly modified to prompt subjects to predict the output of their functions, based on the input values they entered, immediately prior to any code being evaluated.
 In this way, the justifications of their code elicited through selfexplanation were immediately tied to their expectations about program behavior.
 This should enhance any effects of selfexplanation by instantiating any newly generated domain knowledge in explicitly visible program behavior.
 Procedure Subjects participated in a single session which they began by reading the first chapter from an introductory lASP textbook (Anderson, Corbett, & Reiser, 1987).
 The text described some basic LISP functions, the role of functions in programming, and the use of variables.
 Subjects retained this text for reference throughout the acquisition phase of the experiment.
 Following the reading, subjects in the SelfExplain conditions were given a brief explanation of the purpose of selfexplanation and some initial practice in selfexplanation techniques.
 To ground this explanation, these subjects solved a constraints satisfaction problem (from Nathan, Mertz, & Ryan, 1994), unrelated to LISP or programming.
 Subjects in the Example SelfExplain condition were given this practice problem and a stepbystep solution which they were asked to explain.
 Subjects in the Solve SelfExplain condition were given the same problem without a solution, and asked to solve it and justify each step in their solution.
 Subjects in the two SelfExplain conditions were then provided instruction on the purpose of selfexplanation and the kinds of things to explain when solving a LISP problem.
 Specifically, subjects were instructed to explain the purpose of each function used in a solution with respect to the requirements stated in the problem, and how that function achieved its purpose.
 Subjects were also instructed to explain the role of any variables used in the problem, including what information that variable held upon entry to the function and how it was operated on.
 At this time, subjects were given a list of strategic questions from Bielaczyc et.
 al (1994) and instructed that asking themselves these questions would help them to construct selfexplanations.
 This explicit instruction in selfexplanation was intended to control the kind and quality of elaborations subjects produced.
 In particular, w e aimed to maximize the quality of selfexplanations in order to maximize its benefits.
 Subjects in all four conditions then received a demonstration of the computer system, working through two problems (one source, one target) with the experimenter.
 Subjects then worked through five sourcetarget problem pairs, uninformed of the source vs.
 target distinction.
 All subjects worked on each problem until correct.
 In the SelfExplain conditions, subjects read each source problem aloud and then proceeded to explain either the solution given (Example) or their o w n solution (Solve).
 These source problems were solved in front of the experimenter, who prompted subjects only when necessary to clarify vague statements, when subjects paused talking for more than a few seconds, or when subjects needed to speak more loudly.
 Subjects were not required to explain solutions in any particular order.
 For the Example SelfExplain condition, this meant that subjects could explain the role of any function in any order, not necessarily from left to right.
 For the Solve SelfExplain condition, subjects were encouraged to explain each step as they went.
 Subjects were required, however, to explain all portions of their code they had not yet explained prior to their first run of a new or modified solution.
 Following the successful solution of the source, subjects were left alone to solve the next target problem.
 During the acquisition phase, subjects received help from the experimenter only for questions related to the operation of VSE.
 Subjects were referred to the text for LISPrelated questions.
 Direct help on any problem was provided only if subjects took an inordinate amount of time to reach solution (more than 20 minutes on a single problem).
 Help was always given as hints, never as direct suggestions as to what to do next, or which function to use, etc.
 Help was offered by the experimenter only after a request from a subject, but was actually rarely sought.
 Posttest: Following the acquisition phase, all subjects completed the same posttest.
 Subjects were not instructed to selfexplain during the posttest, but they were also not discouraged from doing so.
 During the posttest, the reference text read prior to the acquisition phase was unavailable, as was the V S E feature allowing functions to be run and debugged.
 Subjects constructed what they thought was the correct solution to a problem, and submitted it without feedback on its correctness from the system or experimenter.
 Subjects Subjects were 40 Northwestern University undergraduates with one quarter course or less of computer programming experience.
 N o subject had prior experience with LISP.
 Data from one potential subject were not included in these analyses because the subject exhibited substantially more difficulty with the material than other subjects (as indicated by solution time and errors), and appeared to be engaging in a guessing strategy (submitting untested answers) different from other subjects.
 Of the 40 subjects, 26 were female and 255 14 were male.
 The age of the subjects ranged from 18 to 22 years, mean 20 years.
 Subjects were randomly assigned to condition so as to approximately balance mathematics S A T scores.
 The mean math S A T scores of each condition were: Example NoSelfExplain 673, Example SelfExplain 675, Solve NoSelfExplain 676, and Solve SelfExplain 677.
 The median math S A T score for all conditions was 670.
 Results and Discussion W e were interested in two aspects of subject performance: difficulty in solving target problems and posttest performance.
 First, we considered the time subjects took to solve the target problems as a measure of the relative utility of their work on the preceding source problem.
 W e performed a 2x2 analysis of covariance of source problem type (example or solve) and source instruction (selfexplain or not), using math S A T score as the covariant.
 There were no main effects of either source problem type or source instructions on target problem solution time.
 The pattern of results, shown in Figure 1, suggests differential effects of selfexplanation depending on source instruction, but the interaction was only marginally reliable, F(l, 35) = 2.
42, p = .
13.
 Because we expected there may be differential effects of self explanation depending upon whether subjects studied or solved the source problems, we computed two planned comparisons to separately examine the effects of selfexplanation for each of the Example and Solve conditions.
 Also, to examine more closely exactly where subjects' time was being spent, we broke target solution time down into four components: initial planning time (time spent looking at a problem prior to any activity), build time (the time spent inserting new functions or variables into code), edit time (deleting and replacing code), and testing time (time spent running programs).
 ^ 30n 127.
5.
 "̂  25.
| i= 22.
5 I I 20^ 117.
5 ̂  o W 15 ,.
« Solve Example No SelfExplSelfExpl Source Instructions Figure 1: Time to Solve Targets Of the four components of target solution time, the interaction of source instruction and problem type was reliable for editing time, F(l,35) = 4.
9, p < .
05 (Figure 2), and not for the other three components.
 The planned comparison revealed that subjects who selfexplained examples spent significantly less time editing their solutions, F(l,35) = 3.
8, p = .
05.
 In contrast, there were no effects of selfexplanation for subjects solving source problems, F<1 on any target solution time components.
 Subjects who selfexplained examples also displayed fewer errors during program runs, 1.
3 vs.
 3 errors, although this trend was not reliable, F(l,35)= 1.
96, p = .
17.
 Consistent with this.
 Example subjects deleted somewhat fewer program components on targets if they selfexplained the sources, 6.
3 vs.
 13.
1 deletes, although this trend also was not reliable, F(l,35)= 1.
56, p>.
20.
 These results suggest that subjects who did not selfexplain examples may have performed more edits or spent more time deciding how to repair their programs than subjects that did selfexplain.
 Taken together, the time and error trends suggest that subjects who selfexplained examples were able to more effectively encode the relevant knowledge and subskills from source problems and apply them successfully to subsequent target problems with fewer errors.
 Indeed, as Figure 1 suggests, this improved encoding improved the performance of the Example SelfExplain condition to the level of the Solve conditions.
 Interestingly, there was no evidence that selfexplanation benefited the subjects who solved the source problems.
 12.
5, £ 7.
5Solve Example No SelfExpl SelfExpl Source Instructions Figure 2: Time Editing Targets We also examined the posttests to determine the effects of source study method on later performance.
 There were no main effects of source problem type or source instruction or an interaction on posttest score, all F<1 (see Table 2).
 It seems likely that our subjects reached a ceiling effect on posttest score, since all subjects eventually correctly solved all the problems in the acquisition phase, using the debugging tools available in the environment.
 There was, however, a significant interaction of source type and instruction on the time to construct solutions on the posttest, F(l,35) = 5.
38, p < .
05.
 Again, this interaction was due to the improved performance of the Example subjects who selfexplained sources over those who did not, F(l,35) = 8.
39, p<.
01, while there was no effect of selfexplanation on the Solve conditions, F<1.
 Thus, the benefit of selfexplaining examples carried over to problem solving efficiency on the posttest.
 Selfexplanation while studying examples improved performance, as evidenced by faster solutions, and improved it to the level of subjects who solved the original sources.
 256 Table 2: Score Time (min) Deletes Score Time (min) Deletes Performance on the Posttest E x a m p l e N o SelfExpl 78.
0 19.
0 9.
0 Solve N o SelfExpl 83.
0 15.
7 5.
1 E x a m p l e SelfExpl 80.
4 13.
6 5.
7 Solve SelfExpl 81.
4 16.
2 6.
6 H o w did the selfexplanations while studying examples led to greater problem solving efficacy? VanLehn et al.
 (1992) proposed that the elaborations generated during selfexplanation provide new knowledge which can be used to guide later problem solving.
 Our findings suggest this is indeed the case within this environment.
 Recall that subjects were explicitly instructed to provide domainbased justifications for the use of functions: why one would want to use a particular function in a certain place, and how that function would achieve a subgoal of the problem.
 These subjects' selfexplanation activity was thus focused on encoding both the operational behaviors of LISP functions and the kinds of subgoals that pieces of code could accomplish.
 This encoding then enabled them to better m a p the knowledge acquired studying examples to analogous situations in target problems.
 Thus, selfexplanation of examples allowed subjects to more accurately guide their search of the solution space during target problems, as reflected by the lesser amount of time spent editing erroneous solutions.
 Furthermore, subjects not only elaborated their understanding of why a particular example solution would work, but also tested their predictions of the outcome of each solution component.
 Thus, subjects could test and debug these encodings prior to subsequent problem solving.
 W e believe that this explicit support within the learning environment for testing predictions contributed to the efficacy of selfexplanation for these subjects.
 The results in Figure 1 are consistent with the findings of Trafton (1994), in which students solving source problems outperformed students studying examples.
 Here, selfexplanation of examples seems to have improved performance to the level exhibited by the Solve conditions in these studies.
 Subjects' selfexplanation of examples allowed them to construct the kind of problem solving knowledge that the Solve condition subjects were generating by constructing their own solutions.
 Consistent with our earlier arguments (Trafton, 1994; Trafton & Reiser, 1993), subjects who selfexplained examples were actively constructing solutions similar to Solve subjects, while benefiting from the guidance of a completed solution they were attempting to explain that they knew to be correct.
 Being high on both levels of this tradeoff appears to be an advantage for subsequent problem solving.
 W e must ask, of course, why selfexplanation had no positive effect for subjects solving source problems.
 The explanation may be simply that, within this environment at least, the act of generating solutions to problems led to the acquisition of subsequently relevant problem solving knowledge, and there was little room for selfexplanation to have any benefit.
 V S E provides significant support for problem solving, effectively reducing the search space subjects must traverse to build solutions.
 In such a constrained problem space, the need for strategic monitoring of problem solving is reduced, thus reducing a major benefit of selfexplanation.
 Furthermore, the domain problem solving knowledge that subjects selfexplaining examples were constructing was already being directly generated by subjects in the Solve conditions.
 Thus, the elaborations elicited by selfexplanation may have been no more productive than the elaborations subjects were already constructing to select and execute plans and operators.
 The results here are consistent with the results from other recent studies demonstrating an advantage for selfexplanation (Bielaczyc, et al.
, 1994; Nathan, et al.
, 1994; Pirolli & Recker, 1994).
 Both Bielaczyc et al.
 and Pirolli and Recker measured performance gains as we did on target problems: the number of errors on subsequent problem solving trials, rather than on posttests.
 W e do not see the improvement in posttest scores found by Nathan, although it seems most likely that our subjects reached a ceiling effect on the posttest due to the substantial feedback provided by V S E and the requirement that subjects correctly solve all problems in the learning session.
 In summary, our results show a marked trend toward improved performance for those subjects w h o selfexplain examples over subjects employing their default study strategies.
 O ne may wonder why subjects' decreased editing time is not significantly reflected in our other measures of the problem solving process, such as the time to plan, build, or test solutions.
 One possible explanation is that the intervention described here is quite short.
 Subjects had minimal instruction on selfexplanation and were able to practice it on only five problems.
 In Bielaczyc et.
 al's (1994) study, for example, subjects spent over 12 hours problem solving, with more than an hour devoted solely to learning selfexplanation strategies.
 Still, even with the minimal training provided here, subjects who selfexplained worked examples were able to more efficiently solve target problems and posttest problems.
 Our results suggest that the benefit these subjects gained was a clearer understanding of what each function they had learned did and how they could be combined.
 That is, subjects w h o selfexplained examples built correct target solutions with less effort spent repairing erroneous solutions than their counterparts w h o merely studied examples.
 The 257 elaborations that these subjects produced enabled them to construct relevant problem solving knowledge as if they had solved the problems themselves.
 The benefit of selfexplanation appeared only when subjects had worked examples to explain.
 Subjects in the Solve conditions had to do considerably more work to generate source solutions than their example counterparts.
 This work apparently paid off during target problem solution, regardless of whether it was selfexplained.
 Selfexplanation did not appear to affect subjects' ability to generate solutions on their own.
 Conclusion The present study complements our earlier studies (Faries & Reiser, 1995; Trafton, 1994; Trafton & Reiser, 1993) showing that the effectiveness of the study of examples as a method of skill acquisition is critically related to students' ability to apply the knowledge gained through such study to problem solving practice.
 W e have previously argued that studying examples is not in itself enough to ensure useful learning in such domains as programming; examples must be actively and productively applied to new problems to be effective.
 This study shows that selfexplanation enhances the utility of examples and students' ability to more efficiently apply new knowledge gained through such study of worked examples to new problems.
 It is unclear from our current findings whether selfexplanation can, under some conditions, have a beneficial effect for students trying to solve problems on their own.
 Perhaps the strategies for selfexplaining selfgenerated solutions are different than for selfexplaining worked examples.
 If such is the case, it has important implications for inquiry learning, where students are often generating not only their own solutions, but their own problems.
 Here, the ability to successfully monitor one's own problem solving activity becomes paramount.
 W e are investigating these issues in a considerably less procedural domain: scientific reasoning (Tabak, Sandoval, Smith, Agganis, Baumgartner, & Reiser, 1995).
 W e expect that supporting students in articulating and explaining their own inquiry will be crucial to their success.
 Acknowledgments The learning environment reported in this paper was constructed by Adnan Hamid and Douglas Merrill.
 This research was supported in part by grants NOOO1491J1125 to Princeton University and NOOO 149310136 to Northwestern University from the Office of Naval Research.
 The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of these institutions.
 W e thank Susan Williams for helpful comments on earlier drafts.
 See U R L http://www.
ls.
sesp.
nwu.
edu/Learning_Sciences/faculty/ reiser.
html for related work.
 References Anderson, J.
 R.
 (1987).
 Skill acquisition: Compilation of weakmethod problem solutions.
 Psychological Review, 94(2\ 192210.
 Anderson, J.
 R.
, Corbett, A.
 T.
.
 & Reiser, B.
 J.
 (1987).
 Essential LISP Reading, M A : AddisonWesley.
 Bielaczyc, K.
, Pirolli, P.
, & Brown, A.
 L.
 (1994).
 Training in selfexplanation and selfregulation strategies: Investigating the effects of knowledge acquisition activities on problemsolving (Report No.
 CSM7).
 University of California at Berkeley.
 Chi, M.
 T.
 H.
, Bassok, M.
, Lewis, M.
 W.
, Reimann, P.
, & Glaser, R.
 (1989).
 Selfexplanations: How students study and use examples in learning to solve problems.
 Cognitive Science, 13, 145182.
 Faries, J.
 M.
, & Reiser, B.
 J.
 (1995).
 The encoding and retrieval of problem solving episodes.
 In preparation, The Institute for the Learning Sciences, Northwestern University: Merrill, D.
 C, & Reiser, B.
 J.
 (1994).
 Scaffolding effective problem solving strategies in interactive learning environments.
 In A.
 Ram & K.
 Eiselt (Eds.
), Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, (pp.
 629634).
 Atlanta, GA: Erlbaum.
 Nathan, M.
 J.
, Mertz, K.
, & Ryan, R.
 (1994).
 Learning through selfexplanation of mathematics examples: Effects of cognitive load.
 Paper presented at AERA, New Orleans, LA.
 Pirolli, P.
, & Recker, M.
 (1994).
 Learning strategies and transfer in the domain of programming.
 Cognition and Instruction, 12, 235275.
 Sweller, J.
 (1988).
 Cognitive load during problem solving: Effects on learning.
 Cognitive Science, 12, 257285.
 Sweller, J.
, & Cooper, G.
 A.
 (1985).
 The use of worked examples as a substitute for problem solving in learning algebra.
 Cognition and Instruction, 2, 5889.
 Tabak, I.
, Sandoval, W.
 A.
, Smith, B.
 K.
, Agganis, A.
, Baumgartner, E.
, & Reiser, B.
 J.
 (1995).
 Supporting collaborative guided inquiry in a learning environment for biology.
 In review: Trafton, J.
 G.
 (1994).
 The contributions of studying examples and solving problems to skill acquisition.
 Ph.
D.
 Thesis, Princeton University.
 Trafton, J.
 G.
, & Reiser, B.
 J.
 (1993).
 The contributions of studying examples and solving problems to skill acquisition.
 In Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society, (pp.
 10171022).
 Boulder, CO: VanLehn, K.
, Jones, R.
, & Chi, M.
 T.
 H.
 (1992).
 A model of the selfexplanation effect.
 The Journal of the Learning Sciences, 2, 159.
 258 http://www.
ls.
sesp.
nwu.
edu/Learning_Sciences/faculty/Effects of Background on Subgoal Learning Richard Catrambone Georgia Institute of Technology School of Psychology Atlanta, G A 303320170 USA rc7@prism.
gatech.
edu Abstract It is hypothesized that when a set of steps in an example solution are labeled, the label can serve as a cue to the learner to group those steps and to attempt to determine their purpose.
 The resulting subgoal that represents the steps' purpose can aid transfer to novel problems that involve the same subgoal but require new or modified steps to achieve it.
 The present experiment tested the labelasgroupingcue hypothesis by examining transfer performance by learners with different math backgrounds who studied examples that used either no labels or labels that varied in meaningfulness.
 Learners with a stronger math background transferred equally well regardless of the meaningfulness of the label, and better than learners not receiving labels in their examples, while learners with weaker math backgrounds transferred successfully only when they studied examples using meaningful labels.
 This result is consistent with the claim that the presence of a label, rather that only its semantic content, can be sufficient to induce subgoal learning if the learner has sufficient background knowledge.
 Organizing P r o b l e m Solving K n o w l e d g e b y S u b g o a l s A good deal of research has examined the transfer success people have after studying training materials such as those containing stepbystep instructions (Kieras & Bovair, 1984; Smith & Goodman, 1984), examples (e.
g.
, Ross, 1987, 1989), or both (Fong, Krantz, & Nisbett, 1986).
 Although there have been some exceptions (e.
g.
, Fong et al.
, 1986; Zhu & Simon, 1987), the usual finding from such research is that people can carry out new procedures or solve new problems that are quite similar to those on which they were trained, but have difficulty when the novel cases involve more than minor changes from what they had previously studied.
 This transfer difficulty seems to stem from a tendency by many learners to form representations of a solution procedure that consist of a linear series of steps rather than a more structured hierarchy.
 An advantage of a hierarchical organization is that it can provide guidance for adapting the procedure for novel cases.
 One potentially useful hierarchical organization for a solution procedure would be a set of goals and subgoals with methods for achieving them (e.
g.
.
 Card, Moran, & Newell, 1983; Catrambone & Holyoak, 1990; Newell & Simon, 1972; Singley & Anderson, 1989).
 Problems within a domain typically share the same set of subgoals, although the steps for achieving the subgoals might vary from problem to problem.
 For instance, physics mechanics problems typically share the subgoals of identifying all "systems" in the problem and identifying all forces acting on the object of interest regardless of whether the problems involve objects on inclined planes or blocks suspended over pulleys (Heller & Reif, 1984).
 Consider a student facing a novel problem, that is, one in which the steps are not the same as those seen in a previouslystudied example.
 If the student has memorized only a rote set of steps for the overall solution procedure, he or she will have little guidance as to which steps need to be modified, as well as what new steps might need to be created, in order to solve the problem.
 Conversely, a student who learned a solution procedure organized by subgoals and methods~a set of steps for achieving a subgoalcould attempt to apply those subgoals to the novel problem.
 This approach has two advantages.
 First, the learner would know which steps from the learned procedure are relevant for achieving a particular subgoal.
 Thus, if those exact steps can not be carried out in the current problem, the learner knows that those steps need to be modified.
 Second, if the learner is attempting to achieve a particular subgoal and realizes that a modification to the old steps will not achieve it, then the subgoal can help constrain the memory search for other relevant information for achieving that subgoal (Anzai & Simon, 1979).
 Thus, the search space for useful information would be reduced.
 Factors Influencing Subgoal Learning Anzai and Simon (1979) offered an account of subgoal learning in the context of a person learning to solve the Tower of Hanoi problem.
 They argued that subgoal acquisition is greatly aided when the search space (e.
g.
, possible moves in the Tower of Hanoi problem) is simplified.
 When the search space is simplified, working memory load is reduced.
 This aids subgoal formation because a JM^goal is formed when a learner is working towards a certain goal (perhaps derived from task instructions) and notices that a set of steps places him or her in a situation to be able to carry out additional steps that ultimately achieve the goal.
 The learner will be better able to notice the result of the first set of steps, and be able to chunk that sequence of steps, if working memory load has been reduced (see also Sweller, 1988).
 259 mailto:rc7@prism.
gatech.
eduLabels.
 A key component in Anzai and Simon's model is the presence of a perceptual system that allows the learner to observe various external features of the problem situation.
 For example, in the case of the Tower of Hanoi problem, one feature would be a particular disk being located next to a smaller disk.
 However, in learning tasks that are less obviously perceptually oriented, such as learning to solve word problems in probability, physics, or algebra, simple perceptual features are less likely to play a key role in subgoal formation.
 Rather, cues in worked examples will play a larger role.
 These cues may take the form of text and diagrams in the problem that direct the learner to relevant aspects of the problem and relevant prior knowledge (cf.
 Ward & Sweller, 1990).
 A label can serve as a cue by leading the learner to group a set of steps in the example solution and thus, to increase his or her chances of recognizing that a particular outcome is the result of the execution of those steps.
 That is, the recognition of the grouping is hypothesized to lead the learner to try to uncover the purpose of the group of steps.
 This "purpose" can be conceptualized as a subgoal.
 Background Knowledge.
 Anzai and Simon (1979) suggested that one way a learner can simplify the search space, and thus, to reduce working memory load, is to use prior knowledge of certain facts that can be applied to the domain.
 In the case of the Tower of Hanoi, such a fact might be that move repetitions are inefficient.
 In domains such as probability or physics, relevant background knowledge might include the ability to recognize what a set of steps calculate.
 Ausubel (1968, p 148149) suggested that the value of "organizers" hinges upon the learner possessing relevant background information so that the pieces of information being organized already have some meaning.
 For instance, if a student learning mechanics is told that one part of a solution procedure is to determine the components of force along the x and y axes, this organizer for the subsequent steps will be of minimal use if the learner knows little or nothing about coordinate systems or trigonometry.
 Testing the LabelasGroupingCue Hypothesis In the probability examples used in the current study, the ultimate goal of each is to calculate a probability.
 The solution procedure for achieving this goal involves a number of steps, a subset of which constitutes a sequence of multiplication and addition operations that can be grouped under the subgoal "find the total frequency of the event.
" Consider the "No Label" solution to the probability example in Table 1 involving the Poisson distribution.
' A learner could study this example and memorize the steps for solving a problem that involves the same set of steps, even 'The Poisson distribution is often used to approximate the binomial for events occurring with small probabilities.
 The [(ê )(>.
̂ )]_ , where X is the average P(X=x) = ) Poisson equation is x! (the expected value) of the random variable X.
 if the new problem involved farmers and tractors instead of lawyers and briefcases.
 After studying the N o Label solution, the learner's knowledge for the part of the solution procedure that involves finding X, the average, might be represented as: Goal: Find X Method: 1.
 Multiply each category (e.
g.
, owning exactly zero briefcases, owning exactly one briefcase, etc) by its observed frequency.
 2.
 Sum the results.
 3.
 Divide the sum by the total number of lawyers to obtain the average number of briefcases per lawyer.
 This representation would serve the learner well for problems that involve calculating X in the same way as the example.
 However, this representation fails to capture the fact that the first line of the N o Label solution also involves calculating a total frequency.
 Finding the total frequency is a subgoal that might be achieved in a variety of ways depending on the givens in the problem.
 A novel problem that requires finding total frequency in a different way than in the example might cause problems for the learner with the above representation.
 For instance, consider the problem in Table 2b.
 In this problem the total frequency is calculated by adding a set of simple frequencies.
 This is a lesscomplex method than was used in the example, but the learner might not be able to construct it because the subgoal for finding the total frequency, and an instance of a method for achieving it, were never isolated.
 If the learner had formed the following representation, then his or her chance of solving the problem in Table 2b might be better since this representation identifies the steps involved in finding the total: Goal: FindX Method: 1.
 Goal: Find total number of briefcases Method: a.
 Multiply each category by its observed frequency.
 b.
 S u m the results to obtain the total number of briefcases.
 2.
 Divide the total number of briefcases by the total number of lawyers to obtain the average number of briefcases per lawyer.
 Catrambone (1995) found that learners studying the "Meaningful Label" solution in Table 1 were more likely than those studying the N o Label solution to find the total frequency as measured by their success at solving problems such as the ones in Table 2.
 This was taken as initial evidence that the former group had learned the subgoal to find a total.
 While the results of Catrambone (1995) were consistent with the claim that a label aids subgoal learning by leading a learner to group a set of steps, they did not constitute a strong test of the account.
 It is possible that part of the transfer advantage enjoyed by the Meaningful 260 Label group could have been due to the fact that the label itself provided information beyond serving as a cue to group a set of steps.
 That is, the label indicated that the total number of briefcases was being found.
 Thus, instead of the label leading learners to group a set of steps and to lorin a subgoal to represent the steps' purpose, it may simply have provided them with this fact: finding the total number of things is something that one does when solving Poisson problems.
 One way to tease apart these possible explanations is to provide learners with labels, such as the label "Q" used in the "LessMeaningful Label" solution in Table 1, that contain no explicit information about the domain and examine whether transfer performance is as good as transfer performance by learners who study examples with more meaningful labels.
 A second way to get at this issue is to examine the effects of learners' background on subgoal formation.
 A learner with a weak math background might look at a series of addition and multiplication steps for the N o Label solution in Table 1 (i.
e.
, "1(180) + 2(17) + 3(13) + 4(9)") and not group them and therefore not notice that they calculate a total.
 Even a learner with a reasonable math background (but little or no training in probability) might be predicted to be less likely to form the subgoal of finding the total frequency in this situation compared to a learner studying the Meaningful Label solution in Table 1 in which the steps were labeled with "total number of briefcases owned.
" However, if it is merely the presence of a label, rather than its content, that is sufficient to lead a learner to group a set of steps and form a subgoal to represent their purpose, then the LessMeaningful Label solution in Table 1 should also be effective in helping a learner to form the subgoal to find a total, at least if the learner has a reasonably strong math background.
 Conversely, a learner with a weaker math background might be less likely to be able to determine the purpose of the steps labeled with "Q" in the LessMeaningful label solution and thus, be less likely to form the subgoal to find a total.
 This learner would require a more meaningful label in order to form this subgoal.
 Table 1: Example with N o Label , Meaningful Label, and LessMeaningful Label Solutions.
 A judge noticed that some of the 219 lawyers at City Hall owned more than one briefcase.
 She counted the number of briefcases each lawyer owned and found that 180 of the lawyers owned exactly 1 briefcase, 17 owned 2 briefcases, 13 owned 3 briefcases, and 9 owned 4 briefcases.
 Use the Poisson distribution to determine the probability of a randomly chosen lawyer at City Hall owning exactly two briefcases.
 No Label Solution: E(X) = 1(180)+ 2(17)+ 3(13)+ 4(9) ̂  289 219 219 = 1.
32 = X = average number of briefcases owned per lawyer P(Xx) = [(""^K^")] P(X=2) = 1(2:718:13032^ = (27)(1.
74) ^ 235 x! 2! 2 Meaningful Label Solution: g,jj.
 ^ 1(180)+ 2(17)+ 3(13)+ 4(9) ^ total number of briefcases owned ^ 289 219 219 219 = 1.
32 = A, = average number of briefcases owned per lawyer (rest of solution identical to No Label solution) LessMeaningful Label Solution: g.
y.
 1(180)+ 2(17)+ 3(13)+ 4(9) _ W _ 289 219 219 219 = 1.
32 = X = average number of briefcases owned per lawyer (rest of solution identical to No Label solution) 261 Table 2: Sample Test Problems.
 a.
) A number of celebrities were asked how many commercials they made over the last year.
 The 20 celebrities made a total of 71 commercials.
 Use the Poisson distribution to determine the probability that a randomly chosen celebrity made exactly 5 commercials.
 Solution (not seen by participants): E(X) = — =3 55 = ^.
 = avg # of commercials per celebrity 20 P(X5) [(2.
718^^^)(3.
55^)] _ (.
029)(563.
82) _ ^^^ 5! 120 b.
) Over the course of the summer, a group of 5 kids used to walk along the beach each day collecting seashells.
 We know that on Day 1 Joe found 4 shells, on Day 2 Sue found 2 shells, on Day 3 Mary found 5 shells, on Day 4 Roger found 3 shells, and on Day 5 Bill found 6 shells.
 Use the Poisson distribution to determine the probability of a randomly chosen kid finding 3 shells on a particular day.
 Solution (not seen by participants): 4 + 2 + 5 + 3 + 6 20 E(X) = = — = 4.
0 = ̂  = average number of shells per kid P(X3)  [(2.
718̂ Q)(4.
03)] _ (.
018)(64) _ j^j 3! 6 Experiment Method Participants.
 Participants were 150 students recruited from several Atlantaarea colleges who received course credit or payment for their participation.
 In order to participate in the experiment, a student either had to have taken no college level calculus courses or to have had between two and four collegelevel mathematics courses beyond introductory calculus.
 However, no student could have taken a probability course prior to participating in the experiment.
 Materials and Procedure.
 All participants initially studied a cover sheet that briefly described the Poisson distribution along with a simplified notion of a random variable.
 Participants were randomly assigned to one of three groups.
 Of the 50 participants per group, 25 had a stronger (calculus) math background and 25 had a weaker (no calculus) math background.
 The Meaningful Label group studied three examples demonstrating the weighted average method for finding A, in which the steps for finding the total frequency were given a label that was assumed to have meaning to the participants and made mathematical sense given the steps that preceded it (see the Meaningful Label Solution in Table 1 for an example).
 The LessMeaningful Label group studied examples in which the steps for finding the total frequency were labeled with Q which was assumed to have little meaning for the participants in the context of the examples (see the LessMeaningful Label Solution in Table 1).
 The No Label group studied examples in which the steps for finding the total frequency were not labeled (see the No Label Solution in Table 1).
 After studying the examples, participants were asked to describe how to solve problems in the domain.
 After writing their descriptions, participants solved six problems.
 The first two required the use of the weighted average method for finding X (isomorphic to the example in Table 1).
 The next four problems required new ways of finding the total frequency: either by recognizing that the value was given directly in the problem (see Table 2a for an example) or by adding simple frequencies (see Table 2b).
 Participants were told not to look back at the examples when writing their descriptions or solving the test problems.
 Only the results from the transfer task have been analyzed so far.
 Predictions Most participants were predicted to find X correctly in the isomorphic test problems since the same sets of steps used in the examples could be applied to those problems.
 If the presence of a label, rather than its semantic content, is sufficient to promote grouping, then learners with adequate background knowledge should be able to determine the purpose of the grouped steps and thus, form a subgoal to represent that purpose regardless of the meaningfulness of the label.
 Therefore, participants with a calculus background should be equally likely to learn the subgoal to find a total in the Meaningful and LessMeaningful Label conditions.
 Thus, these two groups should find X correctly on the novel test problems about equally often and should outperform the No Label group since these problems involved new ways of finding the total frequency.
 However, for participants with 262 the weaker math background, the semantic content of the label is predicted to play a larger role in helping them to understand the purpose of the labeled steps.
 Thus, for these learners, those receiving the more meaningful label should be more likely to form the subgoal to find a total compared to those receiving the lessmeaningful label.
 Therefore, the Meaningful label condition should produce more success than the LessMeaningful Label condition at finding X, on the novel problems.
 Results Participants were given a score of 1 for a given problem if they found X correctly and a score of 0 otherwise.
 The scores for the two problems that were isomorphic to the training examples, Problems 12, were summed, thus creating a score from 02 for performance on those problems.
 Similarly, the scores for the four novel problems.
 Problems 36, were summed, thus creating a score from 04 for performance on those problems.
 A twoway analysis of variance was carried out with condition and math background as the factors.
 Table 3 presents the average scores on the test problems as a function of group.
 There was a significant effect of condition, F(2, 144) = 9.
49, p = .
0001, M S e = 3.
18, and math background F(l, 144) = 19.
31, p < .
0001.
 There was also a significant interaction between these factors, F(2, 144) = 3.
12, p = .
047.
 The most typical mistake that students made on these problems was to write in the solution area that not enough information was given to solve the problem.
 If only participants with a calculus background were considered, pairwise comparisons indicated that the two label groups did not perform differently (p > .
7) while both showed a tendency to outperform the N o Label group (j> = .
04 vs Meaningful Label; p < .
08 vs LessMeaningful Label; onetailed).
 If only participants without a calculus background were considered, the Meaningful Label group outperformed the other two groups (both p's < .
0005) while there was no significant difference between the LessMeaningful and N o Label groups (p > .
7).
 Discussion Students firequently learn a solution procedure as a series of steps with little or no higherlevel organization (Reed, Dempster, & Ettinger, 1985).
 As a result, while they can solve new problems that involve the same steps as a previouslystudied example, they have difficulty with problems that require a change in the steps, even though the conceptual structure from the example to the problem is preserved.
 A guiding assumption of the present research is that transfer performance will be enhanced if a solution procedure is structured by subgoals and a method for achieving each one rather than just a single linear set of steps for the entire procedure.
 Presumably there is a continuum of structuredness depending on the number of subgoals into which a procedure is broken.
 The results from the present experiment are consistent with the hypothesis that the presence of a label, rather than its semantic content, can be sufficient to induce a learner to form a subgoal, at least when the learner has adequate background to take advantage of the label.
 Presumably, a label serves as a cue to learners to group a set of steps and to retrieve information from longterm memory in order to explain why those steps belong together.
 The subgoal that is hypothesized to be formed as a result of this process can aid transfer to novel problems.
 While the present results do not include converging evidence of subgoal learning, such as evidence from learners' descriptions of how to solve the problems, prior studies have found such converging evidence (Catrambone, 1994; Catrambone, 1995).
 It is worth noting that while the present results provide support for the theoretical claim that subgoal learning can be aided by the presence of a label, regardless of its meaningfulness, there is also a potential educational implication.
 A subgoal that is formed in response to a label that makes mention of superficial features from the example might become tied to those features.
 For instance, the subgoal formed by Meaningful Label participants in the experiment might have been "find the total number of objects.
" Conversely, a subgoal formed in response to a more abstract label might be less likely to be tied to superficial features.
 For instance, the subgoal formed by LessMeaningful Label participants with a stronger math background might have been "find the total.
" This latter subgoal is more general and closer to being formally correct.
 One implication of forming a subgoal that is tied to superficial features is that the learner is confusing superficial and structural features of the domain.
 Future work could test this possibility by constructing test problems that systematically manipulate the relationship between superficial and structural features and observing the degree to which the features guide learners' performance (cf.
 Ross, 1987, 1989).
 Table 3: Scores on Novel Test Problems as a Function of Condition and Math Background.
 Meaningful Label LessMeaningful Label No Label Calculus N o Calculus 3.
04 2.
72 2.
88 0.
80 2.
08 0.
64 (Maximum possible score = 4) 263 Acknowledgements This research was supported by Office of Naval Research Grant NOOO1491J1137.
 References Anzai.
 Y.
, & Simon, H.
A.
 (1979).
 The theory of learning by doing.
 Psychological Review, 86 (2), 124140.
 Ausubel, D.
P.
 (1968).
 Educational psychology: A cognitive view.
 New York: Holt, Rinehart and Winston, Inc.
 Card, S.
K.
, Moran, T.
P.
, & Newell, A.
 (1983).
 The psychology of humancomputer interaction.
 Hillsdale, NJ: Erlbaum.
 Catrambone, R.
 (1995).
 Aiding subgoal learning: Effects on transfer.
 Journal of Educational Psychology, 87 (I), 517.
 Catrambone.
 R.
 (1994).
 Improving examples to improve transfer to novel problems.
 Memory & Cognition, 22 (5), 606615.
 Catrambone, R.
, & Holyoak, K.
J.
 (1990).
 Learning subgoals and methods for solving probability problems.
 Memory & Cognition, 18 (6), 593603.
 Fong, G.
T.
, Krantz, D.
H.
, & Nisbett, R.
E.
 (1986).
 The effects of statistical training on thinking about everyday problems.
 Cognitive Psychology, 18, 253292.
 Heller, J.
I.
, & Reif, F.
 (1984).
 Prescribing effective human problemsolving processes: Problem description in physics.
 Cognition and Instruction, 1 (2), 177216.
 Kieras, D.
E.
, & Bovair, S.
 (1984).
 The role of a mental model in learning to operate a device.
 Cognitive Science, 8, 255273.
 Newell, A.
, & Simon, H.
A.
 (1972).
 Human problem solving.
 Englewood Cliffs, NJ: PrenticeHall.
 Reed, S.
K.
, Dempster, A.
, & Ettinger, M.
 (1985).
 Usefulness of analogous solutions for solving algebra word problems.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 11 (1), 106125.
 Ross, B.
 (1987).
 This is like that: The use of earlier problems and the separation of similarity effects.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 13 (4), 629639.
 Ross, B.
 (1989).
 Distinguishing types of superficial similarities: Different effects on the access and use of earlier problems.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 15 (3), 456468.
 Singley, M.
K.
, & Anderson, J.
R.
 (1989).
 The transfer of cognitive skill.
 Cambridge, MA: Harvard University Press.
 Smith, E.
E.
, & Goodman, L.
 (1984).
 Understanding written instructions: The role of an explanatory schema.
 Cognition and Instruction, 1 (4), 359396.
 Sweller, J.
 (1988).
 Cognitive load during problem solving: Effects on learning.
 Cognitive Science.
 12, 257285.
 Ward, M.
, & Sweller, J.
 (1990).
 Structuring effective worked examples.
 Cognition and Instruction, 7 (1), 139.
 Zhu, X.
, & Simon, H.
A.
 (1987).
 Learning mathematics from examples and by doing.
 Cognition and Instruction, 4 (3), 137166.
 264 M a k i n g H e a d s or Tails out of Selecting ProblemSolving Strategies Marsha C.
 Lovett Psychology Department Carnegie Mellon University Pittsburgh, PA 15232 lovett+@cmu.
edu John R.
 Anderson Psychology Department Carnegie Mellon University Pittsburgh, PA 15232 ja+@cmu.
edu Abstract When solvers have more than one strategy available for a given problem, they must make a selection.
 As they select and use different strategies, solvers can learn the strengths and weaknesses of each.
 W e study how solvers learn about the relative success rates of two strategies in the Building Sticks Task and what influence this learning has on later strategy selections.
 A theory of how people learn from and make such selections in an adaptive way is part of the ACTR architecture (Anderson, 1993).
 W e develop a computational model within ACTR that predicts individual subjects' selections based on their histories of success and failure.
 The model fits the selection behavior of two subgroups of subjects: those who select each strategy according to its probability of success and those who select the more successful strategy exclusively.
 W e relate these results to probability matching, a robust finding in the probabilitylearning literature that occurs when people select a response (e.
g.
, guess heads vs.
 tails) a proportion of the time equal to the probability that the corresponding event occurs (e.
g.
, the coin comes up heads vs.
 tails).
 Introduction People often have multiple strategies available for approaching a given problem, but they must select just one strategy to apply.
 M u c h research on this selection process has focused on the influence of problem features— how the "looks" of a problem can influence what strategy solvers choose to apply to it (e.
g.
, Atwood et al.
, 1980; Reder & Ritter, 1992; Siegler & Shipley, 1995).
 Another influence on strategy selection, however, is the knowledge solvers have learned about the strategies themselves (e.
g.
, how successful different strategies are or how costly they are to apply).
 It is clear that, all else being equal, solvers should tend to select a strategy that is more successful, less costly, etc.
 than the others, but little is known about how solvers actually represent and use such strategy information.
 In this paper, w e describe a detailed, quantitative study of how solvers' histories of success with different strategies impact selection.
 While this focus has not received much attention in the problemsolving literature, the influence of success rates on an analogous selection task has.
 This is the twochoice selection task studied in probabilitylearning experiments (e.
g.
, Estes, 1964; Humphreys, 1939; Jones, 1971).
 The basic paradigm of these experiments is to ask subjects to predict which of two outcomes will occur (e.
g.
, a coin coming up heads or tails), where one outcome (say, heads) has probability p and the other (tails) has probability \p.
 In these experiments, the success rate p is varied within or between subjects, and selection tendencies (e.
g.
, guessing heads vs.
 tails) are studied as a function of p.
 A c o m m o n finding is that, with multiple trials, subjects exhibit probability matching—they select each response a proportion of the time equal to its probability of occurring (Estes, 1964).
 For example, if heads comes up with probability 0.
8, subjects will tend to guess heads 0.
8 of the time.
 (Notice that this does not maximize one's expected number of correct guesses.
) M a n y models have been developed that predict probability matching in such contextually sparse situations (Atkinson & Estes, 1963; Gluck & Bower, 1988; Lordahl, 1970).
 A n interesting question, however, is whether people will exhibit probability matching when the selection task is embedded in the larger context of solving a problem.
 O ne might expect that the learning mechanism underlying probability matching is fundamental and applies in a variety of contexts, but it is possible that, when making selections in service of a larger goal, solvers will be more likely to maximize their expected number of solutions by selecting the more successful strategy all of the time.
 To gain a better understanding of the role of strategysuccess information in strategy selection and to test the generality of probability matching, w e studied h o w solvers select between two problemsolving strategies in a novel task, the Building Sticks Task (BST) (Lovett, 1994).
 This provided us with two important opportunities.
 First, it allowed us to record every success and failure a solver experienced while using the two strategies.
 W e used these trialbytrial, individual histories to compare an A C T  R model of strategy selection with the class of models that predicts asymptotic probabilitymatching behavior.
 Second, it allowed us to manipulate the strategies' success rates from the start of subjects' experience.
 Thus, w e could study the effects of strategy information as it is acquired.
 Note that, for all the problems w e asked subjects to solve, the two suategies appeared equally appropriate and equally likely to lead to a solution; this focused our study on h o w subjects' history of success with the various strategies influenced their selections, and it made the analogy to probabilitylearning experiments clearer.
^ A major goal ^See Lovett & Anderson (1995) for a discussion of how history of success and apparent appropriateness of various choices jointly influence selections in problem solving.
 265 http://cmu.
eduhttp://cmu.
eduof this research was to capture, in a computational model, how people leam from and make strategy selections.
̂  A model of how people select between strategies in the B S T A theory of how people do this in an adaptive way is part of the A C T  R architecture (Anderson, 1993).
 W e developed a computational model within ACTR that predicts individual subjects' strategy selections in the BST.
 In the BST, the goal is to build a current stick that is equal in length to the desired slick by adding and subtracting multiple building sticks (see Figure 1).
 This goal can be achieved either by selecting a building stick that is smaller than the desired stick and subsequently building up to the desired stick's length (the U N D E R S H O O T strategy) or by selecting a building stick that is longer than the desired stick and subsequently cutting down to the desired slick's length (the O V E R S H O O T strategy).
 In the model, each strategy corresponds to a single production whose actions are executed only when its conditions are met in the current situation.
 Since both strategies can be executed in the initial problem stale, the model must select between them on the first step of each problem.
 Solvers make the same selection implicitly as they solve each problem, and these selections are easily identified (to the experimenter) by the first step.
 UNDERSHOOT desired: C current: • building: r~ir DCZI INITIAL STATE OVERSHOOT desired: C current: building: DCZI desired: C current: • building: DCZZI UNDERSHOOT desired: ̂ ^ ^ ^ ^ ^ current: ^ H building: • I 1 Figure 1.
 Initial and successor states in the BST.
 To select between the two strategies, the model attempts to choose the step that will lead to the highest probability of success (where success is defined as achieving the goal).
 Since the actual probability of success resulting from a particular step cannot be known in advance, the model estimates the predicted probability ^ u r modeling goals differ from those of related machinelearning work (e.
g.
, Sutton, 1988).
 of success (PPS) for each move as a function of the history of success of the production involved in the move.
 The more often a strategy (i.
e.
, production) has led to success in the past, the higher the model's PPS for moves using that strategy.
^ The PPS of strategy j is estimated as a Bayesian posterior probability of success, PPSi = „ ̂ ii].
.
'( , where sj is the number of successes and fj the number of failures experienced with that a • strategy and ^ ̂ s is the model's prior for the success of that strategy.
 Note that the more one uses a particular strategy, the less its PPS depends on the prior and the more its PPS depends on the number of successes and failures experienced with the strategy.
 W e should emphasize that, while this updating formula for PPS is meant to model a part of the process by which people make strategy selections, w e do not propose that people are actually calculating these Bayesian updates per se.
 Rather, this formula is meant to capture the changes in knowledge that people leam through experience—changes that are presumably "computed" at the neural level.
 W h e n the model is selecting among multiple moves, it tends to select the move with highest PPS.
 To include a stochastic component in this selection process, Gaussian noise is added to each PPS value before the selection is made.
 Thus, the model can be thought of as selecting each move with a particular probability that is a function of its PPS value, relative to the other moves, and the amount of noise in the system.
 Note that our ACTR model can exhibit probabilitymatching behavior, but it can also model other selection tendencies as long as the more successful strategy is selected more often than its competitors.
 Method Subjects Subjects in this experiment were 68 Carnegie Mellon University undergraduates; of these, 49 received course credit for participating, and 19 received $5.
00.
 Design There were eight experimental conditions that differed according to three factors: (1) which strategy (UNDERS H O O T or O V E R S H O O T ) was designed to be more successful, (2) the relative success rate of the more successful strategy to the less successful strategy (high or low), and (3) whether or not the two strategies were complementary (i.
e.
, whether failure of one implied success of the other).
 Analyses revealed that the assignment of U N D E R S H O O T vs.
 O V E R S H O O T to the more successful strategy did not affect the results, so we collapse this factor and label the four remaining conditions comphi, complo, noncomphi, and noncompIo.
 ^In ACTR.
 the estimate of PPS can be influenced by other factors as well, but here it is relatively well modeled as a monotonic function of success rate alone.
 266 Table 1.
 Solution probabilities as manipulated across conditions.
 Condition Comphi M S selected first LS selected first Complo M S selected first LS selected first P(MS) .
80 .
80 .
60 .
60 P(LS) .
20 .
20 .
40 .
40 P(N) .
00 .
00 .
00 .
00 Condition Noncomphi M S selected first * LS selected first ** Noncomplo M S selected first • LS selected first *• P(MS) .
80 .
64 .
60 .
36 P(LS) .
04 .
20 .
16 .
40 P(N) .
16 .
16 .
24 .
24 Note: M S = more successful strategy; LS = less successful strategy; P(MS) = probability M S solves; P(LS) = probability LS solves; P(N) = probability unsolvable.
 Text refers to * and **.
 Subjects were assigned to one of these four "environments" that determined how likely each strategy was to solve problems.
 The ratios of success were chosen as 80/20 (high) and 60/40 Oow).
 In the complementary conditions, these ratios represented the observed solution rates for the two strategies (e.
g.
, in comphi, the more successful strategy solved 8 0 % of the problems and the less successful strategy 2 0 % ) .
 In these conditions, whenever the strategy chosen first on a given problem did not lead to a solution, the other strategy would.
 In contrast, in the noncomplementary conditions, some problems were not solvable.
 Each strategy had its designated probability of solving the problem (e.
g.
, 8 0 % and 2 0 % for the more and less successful strategies in noncomphi).
 But, if the strategy selected first did not solve the problem (according to that probability), the other strategy only had a chance of solving (according to its designated probability).
 So, the probability that a problem would be solved by a particular strategy depended on which strategy was selected first.
 Table 1 presents the probabilities of success for each strategy in terms of which strategy was selected first.
 Note that these values are different for the complementary and noncomplementary conditions.
 In particular, for the latter, the ratios of the two strategies' solution rates are not fixed at 80/20 and 60/40: W h e n solvers select the more successful strategy first, the ratios become more extreme (80/4 and 60/16; see * in Table 1), and when solvers select the less successful strategy first, the ratios become less extreme (64/20 and 36/40; see ** in Table 1).
 Apparatus Subjects worked individually on Macintosh Ilci computers.
 A cT program (Physics Academic Software, 1992) ran the B S T interface, provided initial instructions to subjects, and collected data.
 Each rectangle in Figure 1 is a sketch of the interface subjects saw.
 Procedure At the beginning of the experiment, a computer tutorial provided subjects with instructions and practice on how to use the mouse to build sticks.
 Then, it automatically solved two sample B S T problems (one by U N D E R S H O O T and the other by O V E R S H O O T ) .
 The experimental trials included 90 B S T problems.
 In the complementary conditions, subjects were required to work on each problem until they solved it or had taken at least 20 steps.
 In the noncomplementary conditions (because some problems were unsolvable), subjects had the additional option of clicking on a "next problem" button that activated after they took six steps.
 After the experimental trials, subjects were asked if the experiment had reminded them of any experiments they had learned about in class.
 One subject was reminded of Luchins's (1942) water jars experiment and the Einstellung effect and so was removed from the analysis.
 Stimuli All problems were designed so that the two strategies would appear equally appropriate and equally likely to lead to a solution.
 This neutrality was measured according to a hillclimbing metric tested by Lovett & Anderson (1995).
 In addition, all problems had three, nearly identical versions: one solvable by U N D E R S H O O T , one solvable by O V E R S H O O T , and one unsolvable.
 The three versions of a given problem had the same desired stick but slightly different building sticks (they varied by one or two pixels on the screen).
 Thus, the three versions allowed a single problem to be switched from being solved by one strategy to the other or neither, merely by adjusting the building sticks sizes ever so slightly.
 Performing these adjustments with specified probabilities enabled us to manipulate the success rates of the strategies according to the values in Table 1.
 Adjustments only occurred in how the building sticks added to or subtracted from the solver's current stick.
 N o subject noticed these adjustments or was suspicious about how the interface worked.
 Results and Discussion In general, we present our results in terms of the percentage of problems on which subjects selected the more successful strategy first, with "more successful" defined by their condition.
 Figure 2 presents these averages for each block of 15 problems for each condition.
 W e can use these data to test whether subjects' asymptotic behavior approximates probability matching.
 The two thin, horizontal lines in the figure represent probabilitymatching behavior for the comphi and complo conditions at 8 0 % and 6 0 % .
 Although the comphi selections are somewhat above 8 0 % , observed percentages for both of these conditions in the last three blocks are within 9 5 % confidence intervals of the matching values.
 267 •B D NoncompHi • CompHi O NoncompLo • CompLo 1 1 1 1 115 1630 3145 4660 6175 Problem N u m b e r 7690 Figure 2.
 Mean percentage of problems (per 15) on which the more successful strategy was selected.
 For the noncomplementary conditions, 80% and 60% are not necessarily "matching" percentages because here the proportion of problems solved by each strategy varies with the strategies subjects select.
 Suppose a represents the proportion of problems on which a noncomphi subject selects the more successful strategy first.
 Referring to Table 1, this subject should experience success of the more successful strategy on .
80a + .
64(la) of the problems, on average, and success of the less successful strategy on .
04a + .
20(1a) of the problems, on average.
 A further complication in defining probability matching here is that these two expressions do not add up to 1 since some problems are unsolvable.
 In other studies of choice, where not all trials lead to success, matching has been defined by the matching law (Hermstein, 1961), which claims that subjects match their ratio of responses to the ratio of experienced reinforcements (reinforcements = solutions in our case):'^ »A_Responses _ »Absolutions ,̂ , #S_Response ~ *B_Solutions • '•'•' Setting the lefthand side equal to al{\a) and the righthand side equal to (.
80a + .
64(1a ))/(.
04a + .
20(1a)), we can obtain an equilibrium matching value by solving for a.
 For noncomphi, a ~ .
94, and, for noncomplo, a ~ .
69.
 Thus, the almost exclusive selection of the more successful strategy among noncomphi subjects and the "above 6 0 % " selection among the noncompIo subjects both fit closely to these predicted values.
 While these global results are consistent with matching, analysis of individuals' selection tendencies reveal some important differences.
 For example, three of the comphi subjects (18%), two of the noncomplo subjects (13%), and one of the complo subjects (6%) selected the more successful strategy on 43 or more of the last 45 problems.
 Under a probabilitymatching model, the probabilities of such extreme preferences for the more successful strategy ^Note that the RHS of this equation does not include unsolvable problems but the LHS does.
 Thus, the equation reduces to probability matching when all problems are solvable (i.
e.
, #A_Soluiions + #B_Solutions = all trials).
 are very low.
 If we assume that subjects are selecting with probability p equal to the matching value of their condition, the expected probabilities for the three situations above are .
003.
 .
00001, and .
00000005 (computed from the binomial distribution).
 Thus, it is very unlikely that these subjects are probability matching; instead, they are likely using an "exclusive" approachselecting the more successful strategy almost exclusively.
 Figure 3 presents individual subjects' selection data (proportion of last 45 problems on which the more successful suategy was selected) against the average of their solution experiences (proportion of solved problems solved by the more successful strategy) preceding each of those problems.
 The line y=x, r2=.
60, represents the matching law (and, hence, the prediction of any model that leads to asymptotic probability matching), but the data suggest that the majority of subjects are, in fact, overmatching relative to their experience.
 So.
9 50.
8 iiO.
7 ooO.
e ^0.
5 Q a •̂ 90.
1 1 — \ — \ — \ — \ — \ — \ — r 0.
2 0.
3 0.
4 0.
5 0.
6 0.
7 0.
8 0.
9 1 Observed M S Solurions (Matching Predictions) Figure 3.
 F*roportion of the last 45 problems on which the more successful suategy (MS) was selected against the prediction of the matching law, computed for each subject.
 Our ACTR model can be fit to subjects' selection data across all problems.
 As described above, our model estimates the PPS of each move and then selects the move with the highest PPS value, given some noise is added to each.
 W e set the variance of this Gaussian noise to be 0.
05^ and obtain the model's predicted probability p of selecting U N D E R S H O O T for each problem for each subject.
 This probability also depends on the individual subject's history of success with U N D E R S H O O T and O V E R S H O O T preceding that problem.
 W e only varied one model parameter to fit these data, the sum a+p.
 The sum atP is used in the model's formula for updating its estimate of each strategy's probability of success.
 It functions as a "learning rate" for PPS: the larger the sum, the smaller the infiuence of one success or failure, and the smaller the sum, the larger the influence of one success or failure.
 The same atP was used for both U N D E R S H O O T and O V E R S H O O T , with a set to half a+p.
 The value 255 for a+p minimized the sum of the 268 1 — I — I — I — I — I — r Predicted Proportion Figure 4.
 Observed and ACTR predicted proportions more successful strategy selected across all trials, all subjects.
 squared differences between the model's p and the subject's response ( U N D E R S H O O T or O V E R S H O O T ) across all subjectproblem pairs.
 Since subjects' responses are a binary variable ( U N D E R S H O O T or O V E R S H O O T ) and the model generates a probability, w e present the model's fit by "binning" together problems for which the p s are similar.
 Figure 4 plots the average of the p s in each bin against the observed proportion of U N D E R S H O O T selections on the corresponding trials.
 The line y=x, r2=.
99, shows that, over all subjectproblems, the ACTR model provides an excellent fit.
 go.
9 8o U0.
7 c/50.
6 8 I 1 I I I I I I r 0.
2 0.
3 0.
4 0.
5 0.
6 0.
7 0.
8 0.
9 1 Predicted M S Selections Figure 5.
 Observed and predicted proportions of more successful strategy selections on last 45 problems, by subject.
 Our model can also be compared with the predictions of probability matching (cf.
 Figure 3) by fitting individual subjects' selections on the last 45 problems.
 In Figure 5, we plot our model's predicted proportion of selections of the more successful strategy against the observed proportion of selections of the more successful strategy, averaged over the last 45 problems for each subject The line y=x, r2=.
66, shows that the model accounts for the major trend in ibe data without systematically over or underpredicting, but there is still much variability.
 Note that the major difference between Figures 5 and 4 is that Figure 5 displays the model's predictions subject by subject whereas Figure 4 combines the predictions that had similar values, allowing multiple subjects' data to contribute to each bin.
 A similar difference applies to Figures 3 and 2: Figure 3 presents averages within subjects, and Figure 2 presents averages across subjects.
 The greater variability and model misfit in Figures 5 and 3 suggest that there are more factors influencing individual strategy selections than most models take into account.
 By aggregating over subjects, these factors lend to average out.
 Conclusions The main result of this experiment is that, while group data suggest that solvers are selecting between strategies by probability matching, individual data suggest that there are a variety of selection tendencies.
 Individualized predictions based on the matching law showed that many subjects tend to "overmatch" (use the more successful strategy more often than its proportion of solutions) and left 4 0 % of the variance in subjects' asymptotic selection behavior unaccounted for.
 Our A C T  R model does not necessarily predict matching behavior, but it does predict that solvers will tend to prefer the more successful strategy.
 This prediction stems from the claim that solvers are choosing moves with the highest PPS, and PPS is estimated by their past successes and failures with each strategy.
 However, the model also assumes there is some noise in this process.
 So, when one strategy's success rate is much higher than another strategy's, the "better" strategy will likely be selected, but when two strategies' success rates are very similar, one will be selected essentially at random.
 Thus, according to our model, the degree of preference for one strategy over another depends on the relative number of successes and failures experienced with each strategy and the amount of noise in the system.
 This stochastic selection based on the relative "strengths" of alternatives is similar to several interactive competition models (Gluck & Bower, 1988; Siegler & Shipley, 1995; McClelland & Rumelhart, 1981).
 W h e n the A C T  R model was fit to all subjects' selections across the entire experiment, it provided an excellent fit.
 This shows that the model is fitting subjects' overall selection tendencies as they develop through the course of the experiment.
 Similar to the "matching" predictions, however, our model left a large portion of the variance unaccounted for when predicting selections at an individual level.
 This suggests that there are individual differences influencing selection beyond the variability in individual subjects' experiences.
 The free parameters in our model may allow us to capture such intersubject differences.
 269 W e are currently investigating individual differences that may be significant influences on subjects* selection behavior.
 One such difference is subjects' learning rate— how much of an impact one success or failure has on later selections.
 Another is subjects' assessments of the value of exploration versus exploitation—how much utility is attributed to solving the problem versus experimenting with the various strategies.
 By incorporating these differences into our model, we hope to gain an even better understanding of the processes involved in strategy selection.
 References Anderson, J.
R.
 (1993).
 Rules of the mind.
 Hillsdale, NJ: Erlbaum.
 Atkinson, R.
C.
, & Estes, W .
 K .
 (1963).
 Stimulus sampling theory.
 In R.
D.
 Luce, R.
R.
 Bush, & E.
 Galanter (Eds.
), Handbook of mathematical psychology.
 Vol.
 2.
 N e w York: Wiley.
 Atwood, M.
E.
, Masson, M.
E.
J.
, & Poison, P.
G.
 (1980).
 Further explorations with a process model for water jug problems.
 Memory and Cognition.
 8, 182192.
 Estes, W.
K.
 (1964).
 Probability learning.
 In A.
W.
 Melton (Ed.
), Categories of human learning.
 N e w York: Academic Press.
 Gluck, M.
A.
, & Bower, G.
H.
 (1988).
 From conditioning to category learning: An adaptive network model.
 Journal of Experimental Psychology: General, 117, 225244.
 Hermstein, RJ.
 (1961).
 Relative and absolute strength of response as a function of frequency of reinforcement.
 Journal of the Experimental Analysis of Behavior, 4, 267272.
 Humphreys, L.
G.
 (1939).
 Acquisition and extinction of verbal expectations in a situation analogous to conditioning.
 Journal of Experimental Psychology, 25, 294301.
 Jones, M.
R.
 (1971).
 From probability learning to sequential processing: A critical review.
 Psychological Bulletin, 76, 153185.
 Lordahl, D.
S.
 (1970).
 An hypothesis approach to sequential predictions of binary events.
 Journal of Mathematical Psychology, 7, 339361.
 Lovett, M.
C.
 (1994).
 The effects of history of experience and current context on problem solving.
 Unpublished doctoral dissertation.
 Carnegie Mellon University, Pittsburgh.
 Lovett, M .
 C , & Anderson, J.
R.
 (1995).
 History of success and current context in problem solving: Combined irfluences on operator selection.
 Manuscript submitted for publication.
 Luchins, A.
S.
 (1942).
 Mechanization in problem solving.
 Psychological Monographs, 54 , 248.
 McClelland, J.
, & Rumelhart, D.
 (1981).
 An interactive activation model of context effects in letter perception: Part 1.
 A n account of the basic findings.
 Psychological Review, 88, 375402.
 Reder, L.
M.
 (1987).
 Strategy selection in question answering.
 Cognitive Psychology, 19, 90138.
 Reder, L.
M.
 (1988).
 Strategic control of retrieval strategies.
 In The Psychology of Learning and Motivation (pp.
 227259).
 Academic Press.
 Reder, L.
M.
.
 & Ritter, F.
E.
 (1992).
 What determines initial feeling of knowing? Familiarity with question terms, not with the answer.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 18, 435451.
 Siegler, R.
S.
, & Shipley, C.
 (1995).
 Variation, selection and cognitive change.
 In G.
 Halford & T.
 Simon (Eds.
), Developing cognitive competence: New approaches to process modeling.
 Hillsdale, NJ: Erlbaum.
 Sutton, R.
S.
 (1988).
 Learning to predict by the methods of temporal differences.
 Machine Learning, 3,944.
 270 Explanation and Evidence in Informal Reasoning Sarah Brem Department of Psychology Northwestern University 2029 Sheridan Road Evanston, IL 60208 sbrem@nwu.
edu L a n c e J.
 Rips Department of Psychology Northwestern University 2029 Sheridan Road Evanston, IL 60208 rips@nwu.
edu Abstract Explanation and evidence play important and noninterchangeable roles in argument.
 However, previous research has shown that subjects often confuse explanation and evidence (Kuhn, 1991).
 This study investigates the circumstances under which this confusion occurs.
 In Experiment 1, subjects generated arguments about issues of popular interest such as problems in schools and drug abuse.
 In Experiments 2 and 3, subjects rated the strength of evidence presented to them.
 The results of the protocol analyses and ratings tasks suggest that subjects tend to overestimate the strength of explanations when they lack sufficient knowledge of the domain or when they are unable to generate alternatives to the hypotheses presented to them.
 W e consider reasons why relying on explanations in these circumstances might be a valuable heuristic.
 Explanation and physical evidence both play important roles in arguments, but these roles are disrinct and noninterchangeable.
 In many cases, explanations are a sort of causal story, while evidence informs us as to whether or not these stories are likely to be true.
 In creating and evaluating arguments, we need to keep these roles clear or risk ertoneous conclusions.
 In her book The Skills of Argument.
 Kuhn (1991) examined everyday reasoning on social issues.
 She found that subjects have difficulty producing multiple hypotheses and provide weak evidence to support their opinions.
 One of the more striking findings was subjects' inability to produce what Kuhn terms "genuine evidence," instead producing "pseudoevidence," even when arguing about familiar issues (Kuhn, 1991, Chapter 3).
 The present study investigates factors that contribute to subjects' difficulties in producing genuine evidence.
 The distinction between genuine evidence and pseudoevidence is based on whether subjects produce a merely plausible tale of causeandeffect, or whether they also provide evidence that the proposed cause actually does occur.
 One way to think of this is as a failure to distinguish between explanation and evidence.
 Both explanation and evidence must be taken into account in evaluating an argument; explanations provide causal mechanisms and motivate experiments and observations.
 But when creating an argument, it is important to be clear about which aspects of that mechanism have been substantiated, and which aspects are still based on unsubstantiated claims and assumptions.
 To the extent that any explanation relies on assumption, it should be viewed with a certain amount of caution.
 However, the subjects in Kuhn's study did not exhibit this caution.
 In Kuhn's study, subjects were asked to give a reason why children fail in school and to say how they would prove they were right.
 If a subject explains how a parent's lack of interest could lead to their child failing in school, this explanation alone counts as pseudoevidence.
 If the subject supports this opinion by comparing children whose parents are highly involved with children whose parents are less involved, this would be genuine evidence.
 Kuhn further divided genuine evidence and pseudoevidence into subcategories, which we list in Table 1.
 Although it is possible to question some of these distinctions, we accept them temporarily in order to compare our own results to Kuhn's.
 When Kuhn asked subjects to give reasons for everyday social problems, such as failure in school, subjects produced relatively few examples of genuine evidence.
 Although subjects claimed to be very familiar with the school failure topic, only 6 6 % of collegeeducated subjects and 2 9 % of subjects without a college education provided genuine evidence.
 Results for less familiar topics showed a similar pattern, although the amount of genuine evidence decreased across all groups.
 In a subsequent phase, the same topics were presented a second time, but factual information was provided.
 There were two tasks.
 One involved underdetermined evidence.
 Several potential causes were presented, but the evidence was insufficient to draw any conclusion.
 The other involved overdetermined evidence: Experts gave evidence strongly supporting multiple causes.
 In both tasks, subjects tended to claim that the passage still supported their original opinion and, furthermore, that it did not support any alternative hypotheses.
 Taken together, the results of Kuhn's study suggest that even people with academic training have difficulty providing and recognizing sound evidence.
 There appear to be at least two possible reasons for this: (a) Subjects possessed insufficient information to make their case, or (b) The facts were available, but subjects failed to distinguish genuine evidence from pseudoevidence.
 Lack of relevant information.
 If subjects have no firsthand knowledge of an issue, they may have to settle for providing a plausible story.
 In Kuhn's protocol task, the wording may have led them to believe that they were limited 271 mailto:sbrem@nwu.
edumailto:rips@nwu.
eduTable 1.
 Criteria for classifying responses, and examples of subjects' responses.
 P S K U D O E V I D E N C K GENERALIZED SCRIPT: Subject explains how the proposed cause could bring about the effect without showing that the cause described actually occurs.
 W h y do AfricanAmericans facg ggatgr gconomic hardship than Caucasians? Because AfricanAmericans generally come from a poor economic background, they are not given the same opportunities to develop as Caucasians.
 Thus, they have to struggle harder.
.
.
.
 SPECIALIZED SCRIPT: Like a generalized script, but formulated as a specific example.
 What causes anathv in teachers? M y mother was a schoolteacher who quit because she worked around the clock with students who didn't care and parents who didn't care for barely enough money to survive on.
 GKNUINE EVIDENCE DISCOUNTING: Supports the proposed cause by undercutting rival causes.
 What causes homelessness? People are usually not b o m into this state of homelessness.
 1 would show that many homeless people just fell on bad economic times and were fcxced out ANALOGY: Produces information about a second domain and shows that it is similar to the argument domain.
 W h y are the children of alcoholics likelv to become alcohoUcs? Children leam to speak.
.
.
from watching their parents.
 If a parent has an accent it is probable that the child will develop this accent also.
.
.
.
So if a child has an alcoholic parent.
.
.
then they too might become alcoholics.
 CORRELATION: The proposed cause cooccurs with the effect.
 W h v do criminals return to crime? Check the number of criminals who return to crime who are brought up in a hostile environment or are from broken families.
 COVARIATION: The effect is present when the cause is present, absent when the cause is absent.
 >Vhat causes drug abuse among tggps? \Lock at] reports showing the difference between teens who have jobs or extracirricular activities vs.
 those who don't and the degree to which they abuse drugs.
 OTHER NO RESPONSE.
 Question is left unanswered.
 AUTHORITY.
 Subject stated that he/she would read newspapers or journals, or interview experts.
 The subject did not state what they would look for, or what they expected to find.
 NONEVIDENCE.
 A response is categorized as nonevidence when the subject: 1.
 Claims evidence is unnecessary, that the correctness of their opinion is selfevident.
 2.
 Gives evidence establishing the effect.
 (E.
g.
, when asked why failure in school occurs, subjects give evidence that failure does occur without stating why.
) 3.
 Claims the effect does not exist (E.
g.
, subject claims school failure doesn't occur.
) to evidence they actually possessed.
 In the example of have to produce evidence they had previously encountereda failure from school, subjects would have provided genuine difficult task for nonexperts.
 evidence if they described a hypothetical study comparing Admittedly, the comprehension tasks do suggest that even involved to uninvolved parents.
 Unless they recognized that when subjects have the relevant facts they cannot use them hypothetical evidence was legitimate, however, they would property.
 However, the initial protocol task could have 272 file:///Lockinfluenced their later responses.
 Having already taken a stand on the issues could have: (1) pressured subjects to maintain consistency with their previous responses, or (2) hampered their ability to generate additional hypotheses (Koriat, Lichtenstein, & Fischhoff.
 1980; Holt & Watts.
 1969).
 Failure to distinguish different kinds of evidence.
 A second explanation for Kuhn's results is that subjects were simply unable to distinguish genuine evidence from pseudoevidence.
 A related possibility is that subjects may have provided pseudoevidence because their criteria for a good argument were different from those of the experimenter.
 Science requires that w e rule out alternative hypotheses, but less stringent criteria may be ̂ propriate in everyday situations.
 W e often have neither the time nor the resources to test all possible hypotheses, and some factors are beyond our control, such as replacing the teacher when your child does poorly in school.
 What passes as a good argument in practical terms may not be a good scientific argument Having identified some possible causes of the results described above, we now turn to the experiments that may help us to differentiate them.
 Experiment 1: Can lack of knowledge account for failure to produce evidence? The first experiment tested the possibility that the subjects in Kuhn's experiments may have suffered from a lack of relevant facts, coupled with a failure to understand the hypothetical demands of the task.
 The procedure was similar to that used in Kuhn's protocol task, except that subjects were assigned to one of two conditions: Ideal or Actual.
 In the Actual condition, w e solicited evidence using the same wording as in Kuhn's study.
 In the Ideal condition, w e asked subjects to give the strongest supporting evidence they could imagine.
 If subjects in Kuhn's study provided explanations to make up for their lack of sufficient information, they should produce more genuine evidence in the Ideal condition than in the Actual condition.
 Method We asked subjects about their opinions on 16 different issues (e.
g.
, why do children fail in school?).
 Subjects were asked to write down their opinion on an issue and then rate their familiarity with that issue.
 Familiarity ratings were made on a 0 to 7 scale.
 Next subjects were asked to provide one or two pieces of evidence to support their opinion.
 Subjects in the Actual condition were asked "If you were trying to convince someone your view is right, what evidence would you give to try to show this?" Subjects in the Ideal condition were asked, "If you were trying to convince some else that your view is right, what would be the ideal evidence to show this? Imagine that you have access to any information or techniques you require.
" Finally, all subjects were asked to rate the strength of their own evidence on a 0 to 7 scale.
 All questions pertaining to an issue were presented on the same page of a booklet Twenty paid subjects participated, 10 in the Actual condition and 10 in the IdeJal condition.
 All had completed at least two years of college and were native speakers of English.
 Results The results were scored by two raters, one who was blind to the hypothesis.
 Disagreements were resolved through discussion.
 The raters categorized the subjects' responses as genuine evidence, pseudoevidence, or other.
 These categories were further broken down into the subcategories used by Kuhn (1991).
 The criteria for classification and examples of subjects' responses are given in Table 1.
 For the purposes of analysis, responses categorized as other were excluded, as they cannot be clearly incorporated as genuine evidence or pseudoevidence.
 In the Actual condition, 34.
8% of responses were classified as genuine evidence; 57.
6% of responses in the Ideal condition were genuine evidence.
 The difference between conditions is significant (by subject, t (18) = 2.
25, p < .
05; by item t (30) = 3.
51, n.
 <.
001).
 A s shown in Table 2, Actual and Ideal differ primarily in three subcategories: correlational instances, generalized scripts, and references to authoritative sources.
 Subjects in the Actual condition produced 75 generalized scripts (i.
e.
, general descriptions of possible causeeffect relations), 24 instances of correlational evidence, and 6 references to authority.
 Subjects in the Ideal condition produced 41 generalized scripts and 43 instances of correlational evidence, and 35 references to authcHity.
 There was little difference between the familiarity and satisfaction ratings in the two conditions.
 Subjects in the Actual condition gave a mean familiarity rating of 3.
82 (SD Table 2.
 Frequency of evidence types by subcategory (Experiment 1).
 fiENllINK K Y I D K I N C K ACTUAL IPRAL Correlation Covariation Correlated Change Analogy Discounting TOTAL FSEUDOEVIPENCE Generalized Scripts Specialized Scripts TOTAL OTHER Authority Nonevidence No Response TOTAL 24 13 2 1 46 75 1 1 86 6 6 H 28 43 18 5 0 2 68 41 9 50 35 4 4 43 273 = 1.
19).
 and a satisfaction rating of 3.
46 (SD = 1.
25).
 In the Ideal condition, subjects gave a mean familiarity rating of 3.
61 (SD = 1.
00), and a satisfaction rating of 3.
90 (SD = 1.
06).
 Ttests showed that the differences between conditions were not significant (Familiarity: t (18) = 0.
44, p > .
10; SaUsfacUon: t (18) = 0.
85, p > .
10).
 Discussion The results of Experiment 1 suggest that subjects' inability to provide appropriate evidence is at least in part due to a lack of relevant facts.
 The topics addressed in both Kuhn's studies and this experiment are matters of popular interest, but they are complex issues, and providing a sound analysis involves a considerable amount of data and effort.
 Unless subjects rely on hypothetical data, they are not likely to succeed at the task.
 Subjects in the Actual condition felt constrained to rely only on their own current knowledge, which was generally too meager to support genuine evidence.
 Subjects in the Ideal condition, however, were able to invent stronger evidence or seek an appropriate source of information.
 This implies that many subjects have an understanding of what makes good evidence and are able to make a strong case under favorable circumstances.
 Although subjects performed considerably better in the Ideal condition, 3 1 % of responses were scripts, and 8 2 % of these were generalized scripts, which provide no evidence whatsoever that the proposed cause exists.
 Also, subjects' satisfaction with these generalized scripts was roughly the same in both conditions (Actual condition, 3.
81; Ideal condition, 3.
79).
 This suggests that, rather than being aware of producing inferior evidence, subjects in the Actual condition were as content with their result as subjects in the Ideal condition.
 It may be that subjects are drawn to scripts even when they are not limited by their personal resources.
 W e wished to determine whether subjects would still consider scripts good evidence when they did not produce the evidence themselves.
 Experiment 2: Can people evaluate evidence accurately? Experiment 2 was conducted to determine whether the subjects would perform the same when presented with evidence as did the subjects in Experiment 1, who produced their own evidence.
 If the earlier subjects produced scripts simply because they were unable to come up with better evidence, they should nevertheless be able to recognize genuine evidence.
 Method Stimuli consisted of 16 sets of stories.
 The issues were the same as those in Experiment 1.
 For each issue, we generated an opinion and evidence supporting that opinion.
 There were eight types of evidence: generalized script, specialized script, discounting, covariation n = 1 (single instance), covariation n > 1 (multiple instances), correlated change n = 1.
 correlated change n > 1, and field study (see Table 1).
 The types of evidence are distinguished by the same criteria used in Experiment 1, except for field studies, which were not produced in Experiment 1.
 Field studies are defined as having an authoritative source, random assignment, and statistically significant results.
 Additionally, 16 filler items were included.
 Each filler item consisted of an opinion and a piece of evidence concerning some issue, and two filler items were generated for each of the eight levels of evidence.
 Fillers were indistinguishable from the test items.
 Subjects were presented with the 16 test items and 16 filler items.
 For each issue, subjects saw only one piece of evidence, and all items were presented on a separate page.
 Subjects were asked to rate the strength of each piece of evidence on a 7point scale, 7 indicating the strongest evidence.
 After a 15 minute interval, subjects completed a recall task involving the rated items.
 The recall tadc is not relevant to this study and will not be discussed further.
 Twentyfour Northwestern undergraduates received class credit for their participation.
 All were native speakers of English.
 Results The mean strength ratings are presented in Table 3.
 There was a significant difference between subcategories in both a byitem analysis (F(7,105) = 5.
46, p < .
01) and a bysubject analysis (F(7,154) = 7.
59.
 p < .
01) The mean rating for genuine evidence (3.
86) was lower than for pseudoevidence (4.
13).
 A planned comparison contrasting scripts with genuine evidence showed a marginally significant difference (by subjects: F(l, 154) = 2.
85, p < .
10; by item: F(l,105) = 3.
38, p< .
10).
 Discussion Subjects showed a trend toward preferring scripts over genuine evidence.
 This is consistent with Kuhn's finding; subjects seem willing to accept scripts as good evidence.
 One reason subjects may not have distinguished between explanations and evidence is that they saw only one piece of evidence for each question, and were unable for this reason to pick out what is most important about the supporting evidence.
 Comparing two items can highlight differences, allowing subjects to reflect on which elements are significant (Gentner & Markman, 1994).
 In essence, subjects were being placed in an impoverished condition by seeing only one piece of evidence supporting each opinion.
 Subjects who have insufficient information may place a higher value on scripts.
 Experiment 3: Does context help subjects recognize genuine evidence? The stimuli were the same as those in Experiment 2, with the omission of the filler items.
 Subjects saw all 16 question/opinion pairs and all eight levels of evidence for each question.
 The evidence supporting an opinion was presented together on a single page, and subjects rated the strength of each piece of evidence on a 0 to 7 scale (7 = strongest evidence).
 W e encouraged subjects to compare all the evidence associated with an opinion before making their ratings.
 Twenty Northwestern undergraduates participated, receiving class credit.
 All were native speakers of English.
 274 Table 3.
 Mean ratings from 2 and 3.
 in which subjects rated the strength of presented evidence on a 0 to 7 scale (7=strongest).
 PSEIIDOEVIDENrK Generalized Scripts Specialized Scripts fiENUINE EVIDENCE Discounting Correlation, N = 1 Covariation, N = 1 Correlation, N > 1 Covariation, N > 1 Field Study KXPF.
RIMENT 2 4.
09 4.
25 2.
58 3.
65 4.
00 4.
00 4.
23 4.
35 FXPF.
RIMKNT 3 3.
24 2.
96 2.
66 3.
44 3.
90 3.
51 4.
11 4.
66 Results The mean strength ratings appear in Table 3.
 As in Experiment 2, the evidence subcategories differed in perceived strength (F(7,133) = 7.
90, p < .
01 by subjects, F(7,105) = 33.
67, p < .
01 by item).
 This time, ratings forgenuine evidence were higher, on average, than ratings for scripts (3.
72 vs.
 3.
12).
 A planned contrast of scripts vs.
 genuine evidence showed a significant difference (F(l,133)=14.
90 p<.
01 by subjects, F(l, 105)=44.
47, p<.
01, by item).
 W e should note that the strength of genuine evidence in Experiments 2 and 3 may be reduced by the inclusion of discounting evidence (see Table 1 for an example of discounting).
 In both experiments, subjects gave unusually low ratings to discounting, as shown in Table 2.
 Kuhn classifies discounting as genuine evidence.
 However, while discounting argues against rival causes, it fails to show that the poposed cause actually occurs.
 In this way, discounting is not unlike scripts.
 If w e remove discounting from our analysis, the difference between scripts and evidence in Experiment 2 decreases (Scripts: 4.
13 vs.
 Evidence: 4.
04), while in Experiment 3 the difference increases (Scripts: 3.
12 vs.
 Evidence: 3.
92).
 Therefore, providing subjects with a variety of evidence may have a greater beneficial effect than was initially suggesteid.
 Disciission In contrast to the results of Experiment 2, the results of Experiment 3 suggest that subjects can distinguish between evidence and scripts.
 This experiment differed from Experiment 2 in that subjects saw more supporting evidence for each opinion, and they were explicitly encouraged to compare different types of evidence.
 Subjects may have had difficulty generating alternative evidence in Experiment 2 and therefore failed to consider that better arguments could be made.
 W h e n that evidence was provided for them in Experiment 3, their accuracy increased.
 G e n e r a l Discussion The purpose of this study was to determine whether subjects distinguish between explanations and evidence.
 Taken together, the results suggest that subjects do understand the difference, but that this distinction blurs when resources are limited.
 If subjects have strong evidence at their disposal, they will tend to recognize that explanations make for a fairly weak argument.
 W h e n evidence is unavailable, subjects place more weight on explanations.
 Available information may affect subjects in more than one way.
 In Experiment 1, w e showed that subjects were capable of inventing evidence when encouraged to do so.
 In Experiment 2, however, subjects apparently failed to consider that there could be other arguments besides the one presented to them.
 W h e n we gave them examples of these alternatives in Experiment 3, they may have recognized the merits of each and were therefore able to give a more accurate appraisal.
 The ability to conceive of alternatives may play an important role in evaluating arguments, and encouraging subjects to generate alternatives m a y improve their argumentation skills.
 The importance of alternative hypotheses has been argued by Kuhn (1991).
 Subjects who did not generate alternative hypotheses were more confident and less realistic in evaluating their arguments than subjects who were able to imagine other possibilities.
 The pattern that emerges from our data is that when subjects are faced with limited resources, they will tend to rely more heavily on explanations as support for a particular position.
 It is important to point out that this, in itself, is not necessarily an irrational or problematic strategy.
 A number of authors have pxjinted out that presumptive reasoning, that is, reasoning based on supposition and unsubstantiated claims, plays a vital role in informal reasoning, (e.
g.
, Walton, 1992).
 There are many decisions to be made and debates to be resolved in environments in which the concrete examples and statistics are not available, and may never be available.
 In those cases, rather than shutting down altogether, people show great flexibility and 275 ingenuity by asking "What if.
.
.
" and following that line of reasoning, with all of its assumptions, to its conclusion.
 Presumptive reasoning has a number of valuable aspects: it can uncover internal inconsistencies in reasoning; it can make clearer what issues and questions are involved in a particular debate or decision (Walton, 1992); it may suggest new experiments or sources of information.
 Along similar lines, causal scripts can make a hypothesis more plausible by illustrating a logically possible route from the proposed cause to its effect.
 Although, as Kuhn (1991) points out, relying heavily on unsupported explanations can be a poor strategy, since plausibility does not ensure correctness, plausibility may be a good heuristic.
 Problems such as teacher apathy do not have a simple answer; we may never identify all the factors involved.
 And these issues are not only intellectual puzzles, but real problems, often requiring a quick, decisive response.
 The plausibility heuristic may narrow down the possibilities to a manageable number.
 Pennington and Hastie (1986, 1992) have put forth a related argument, claiming that creating plausible stories is a spontaneous and important precursor to forming an opinion.
 They show that jurors organize evidence into a story before rendering a verdict Their model posits that contructing a story helps subjects in a number of ways, including determining the significance of and flnding the holes in their interpretation of a case.
 Although our subjects may not use evidence explicitly in constructing their stories, organizing their thoughts in this way may help them to determine the significance of possible factors and to maintain consistency.
 Several other lines of research have suggested additional reasons why a reliance on explanation may be a productive strategy.
 For example, in the domain of electricity, Schauble, Glaser, Raghavan, and Reiner (1992) found that subjects' grasp of domaingeneral principles of evidence generation depended on their understanding of electricity.
 Without a solid theory of how circuits woiic, subjects could not determine what constituted a good experiment.
 Likewise, in everyday reasoning, if subjects do not have a good theory of a phenomenon, they may have difficulty identifying strong evidence.
 In such a situation, using scripts may seem like a good idea, in that they layout a causal model.
 Also, subjects' interest in explanations seems quite sensible if sensitivity to causal mechanisms is judged important in causal attribution.
 W e may be uncomfortable with unsubstantiated explanations of an event, but we also find observations without explanations unsatisfying.
 Ahn, Medin, Kalish, and Gelman (1995) found that subjects who were asked to determine the reason for a particular event focused much more heavily on data relating to possible causal mechanisms than to covariational data.
 Subjects apparently do not simply want to know that there is a statistical relationship between a cause and event, but they also want to know why.
 The danger in presumptive reasoning is failing to recognize that one is reasoning from assumptions and unsubstantiated claims.
 If the world fails to behave as we predict, these are the links in our theory that should receive the largest share of our initial suspicions and come under the closest scrutiny.
 T o the extent that unsubstantiated explanations are vulnerable in this way, it seems reasonable to view them as somewhat weaker than claims supported with evidence, and it is important is that we remember that these are merely assumptions when things go awry.
 An interesting followup to the studies described here would be to determine whether subjects do maintain an awareness of which claims are supported and which are not.
 References Ahn, W.
, et al.
 (1995).
 The role of covariation versus mechanism information in causal attribution.
 Cognition, 54.
 299352.
 Centner, D „ & Markman, A.
B.
 (1994).
 Structural alignment in comparison: N o difference without similarity.
 Psychological Science, 5, 152158.
 Holt, R.
, & Watts, D.
 (1969).
 Salience of logical relationships among beliefs as a factor in persuasion.
 Journal of Personality and Social Psychology, 11, 193203.
 Koriat, A.
, Lichtenstein, S.
, & Fischhoff, B.
 (1980).
 Reasons for confidence.
 Journal of Experimental Psychology: Human Learning and Memory, 6.
107118.
 Kuhn, D.
 (1991).
 The skills of argument.
 Cambridge: Cambridge University Press.
 Pennington, N.
, & Hastie, R.
 (1986).
 Evidence evaluation in complex decision making.
 Journal of Personality and Social Psychology, 51, 242258.
 Pennington, N.
, & Hastie, R.
 (1992).
 Explaining the evidence: Tests of the story model for juror decision making.
 Journal of Personality and Social Psychology, 62.
 189206.
 Schauble, L.
, Glaser, R.
, Raghavan, K.
, & Reiner, M.
(1992).
 The integration of knowledge and experimentation strategies in understanding a physical system.
 Applied Cognitive Psychology, 6, 321343.
 Walton, D.
N.
 (1992).
 Plausible argument in everyday conversation.
 Albany: State University of N e w York Press.
 276 Integration of Anomalous Data in Multicausal Explanations Josef Krems University of Regensburg Department of Psychology D93053 Potsdam, Germany kreins@psychologie .
 uniregensburg .
 de Abstract This paper describes and evaluates a computational model of anomalous data integration.
 This model makes use of three factors: entrenchment of the current theory (the amount of data explained), the relative probability of the contradictory explanations (based on conditional probabilities as part of the domainknowledge), and the availability of alternative explanations based on learning.
 In an experimental study we found that the enuenchment of a theory and the availability and likelihood of an alternative explanation influenced solution speed and the correctness of inferred causal explanations.
 However, in detail, the single levels of both factors were not cleariy distinguishable and did not follow the predictions.
 These findings suggest that entrenchment itself is not a major factor in determining the difficulty of a task.
 Instead, we hypothesize that task difficulty is dominated by a person's ability to construct an alternative explanation of a given situation, a factor that is only indirectly related to entrenchment.
 Introduction Integrating anomalous data with an existing theory or explanation is an essential subtask in scientific discovery, diagnostic reasoning and in everyday problem solving such as story understanding.
 In this paper w e focus on the integration of anomalous data into an existing multicausal explanation for a set of observations.
 In its simplest form, a causal inference has the following form: Given knowledge that A causes B, upon observing B, A is hypothesized as the explanation for B.
 This is a kind of abductive inference (Josephson & Josephson, 1994).
 In multicausal abductive tasks the explanation is composed of multiple causal hypotheses, which together explain the observations.
 A n anomaly occurs when new evidence contradicts the existing explanation.
 The general problem then is to decide how to modify the multicausal explanation, so that all evidence, including the new observation, is explained.
 W e have designed and implemented a mental model based theory of abduction in Soar (see Johnson, Krems & Amra, 1994, for details) for which we have proposed a mechanism of anomalous data interpretation.
 This paper describes this mechanism and also presents results of an experimental study in which the cognitive plausibility of the mechanism was evaluated.
 Todd R.
 Johnson Division of Medical Informatics and Center for Cognitive Science The Ohio State University Columbus, Ohio 43210 tjOmedinfo.
ohiostate.
edu Multicausal Explanations and Anomalies In abductive reasoning, an anomaly occurs whenever new evidence contradicts one or more hypotheses in the existing multicausal explanation for previously given evidence.
 N e w evidence can contradict the existing explanation in one of two ways: 1) The new evidence is logically inconsistent with the existing explanation, such that there is no way to explain the new evidence without modifying the explanation; or 2) The hypothesis chosen to explain the new evidence contradicts the existing explanation, but a different hypothesis for the new evidence is consistent with the explanation.
 W h e n an anomaly occurs, the reasoner must either modify the old explanation so that it is valid for both the new and preexisting evidence, or select a different hypothesis for the new data so that the new hypothesis is consistent with the explanation for the old evidence.
 Our major research question is to clarify the factors that affect this decision and the processes used to make the decision.
 Previous studies of the interpretation of anomalous data provide evidence on the role of various factors, such as entrenchment of a theory, the availability and likelihood of an alternative explanation, and a subject's background knowledge.
 Chinn and Brewer (1993) argue that the entrenchment of a theory is one of the characteristics of an individuals current beliefs that influence h o w a person responds to anomalies.
 O n e way theories are entrenched is due to the amount of evidence they explain.
 Applied to abductive reasoning this should mean that theorypreserving responses should covariate with the amount of data already explained by the current theory.
 The literature on the confirmation bias (e.
g.
, Klayman & Ha, 1987; Krems, 1994) as well as studies by Burbules and Linn (1988) also indicate that the availability and likelihood of an alternative hypothesis can influence a person's response to anomalous data.
 Although researchers have proposed several models of scientific discovery and abductive reasoning, most do not provide a detailed process model of anomalous data interpretation.
 For example, Dunbar and Klahr's (1989) model ( S D D S , Scientific Discovery as Dual Search) shows h o w explanations are formed and modified by searching in hypothesis and experiment spaces, but does not provide a 277 detailed description of what happens when new data contradicts the current explanation.
 Thagard's (1992) theory of explanatory coherence (TEC) offers an account of how anomalous data affects the strength (or coherence) of new and existing hypotheses; however, it does not offer a theory for how people use belief changes to decide how to modify the explanation so that it can account for both the new and old data.
 T E C does imply, however, that a person would attempt to retain the most coherent hypotheses.
 Thus, it seems reasonable for a model based on T E C to search for alternative hypotheses to replace the less coherent, contradictory hypotheses.
 Theories based on casebased explanation generation (Schank, Riesbeck and Kass, 1994) emphasize the role of prior experience in explaining anomalies.
 Read and Cesa (1991) showed that expectation failures are important cues for retrieving relevant memories of previous anomalies.
 However, little is known about the process of explanation modification.
 A Computational Model Basic Features of the Model In previous work, we developed a mental model based theory of abduction and implemented it in Soar (Newell, 1990).
 For details of the model see Johnson, Krems and A m r a (1994).
 W e view abduction as the sequential comprehension and integration of data into a single situation model that represents the current best explanation of the data.
 Suppose that a new datum is available.
 First, the situation model is updated to include the new datum.
 Next, the new datum is comprehended, i.
e.
, knowledge is brought to bear to determine what the new datum implies about the situation.
 Comprehension results in one or more explanations for the datum, where each explanation consists of one or more hypotheses together with the data they explain.
 If the generated explanation is inconsistent with any hypotheses or data in the existing situation model, an anomaly has occurred and the model must be updated by either finding an alternative explanation for the new datum or by altering an explanation for the old data.
 Processing Anomalous Data The model responds to anomalous data by rejecting all but one of the anomalous explanations and then constructing alternative explanations for the data left unexplained by the rejection(s).
 It does this using a limited lookahead search to determine which explanation is the best to keep.
 Suppose that explanations, el and e2, for two data, dl and d2, are inconsistent.
 In the lookahead search it first selects one of the explanations, say el, and rejects it.
 Then it searches for an alternative explanation for dl and evaluates the resulting situation model.
 Next it returns to the original anomalous situation, rejects e2, searches for an alternative to explain d2 and evaluates the results.
 The model then rejects the explanation whose rejection resulted in the best situation model (where best is defined as the model that explains the most data with the fewest number of explanatory components).
 For example, if rejecting el results in a better alternative explanation (than that found by rejecting el), then el will be rejected and the alternative explanation for el will be used.
 If an alternative explanation for one of the data items cannot be found (either because none exists or because processing limitations prevent adequate search), then the explanation for that datum will be retained and the explanation for the other datum will be modified.
 If rejecting el and el result in equally good situation models, then the difference between the probabilities (if known) that el explains dl versus that el explains dl is used to break the tie.
 The probability (or frequency) that a given set of evidence is explained by a certain set of causes is not calculated by the model but is considered to be part of the domain knowledge.
 A number of studies reveal that people can implicitly acquire such frequency of occurrence information and then use it during decision making (see Hasher &Zacks, 1984).
 Thus, to decide which explanation to reject, the model makes use of three factors: entrenchment of the current theory (the amount of data explained), the relative probability of the contradictory explanations (based on conditional probabilities as part of the domain knowledge), and the availability of alternative explanations.
 W e assume that the availability of alternative explanations depends on situationspecific knowledge and the amount of time spent searching for an alternative.
 The more often a situation is faced in which the existing explanation is replaced by an alternative, the more likely it is that the person has generated an appropriate alternative for that explanation.
 This means that availability of potential explanations should increase with problem solving experience.
 It also means that subjects' confidence in their explanations should correlate with the relative frequencies that the explanations were correct for a set of data.
 The Task To explore human abductive problem solving we use a task called Black Box (BBX).
 In this task, four atoms are hidden in a box (an 8 x 8 matrix) and the player's goal is to discover their locations by shooting rays into the box (the subjects are trained on these rules prior to introducing them to the abductive task).
 The B B X device is shown in Figure 1.
 Each atom (labeled 14) has a field of influence (shown as a larger circle around the atom).
 These fields deflect or absorb light rays (according to certain laws) as illustrated in the figure.
 If a ray directly hits an atom, it is absorbed, and the ray's input cell is marked with a circle (Rays B, C, D and E); if a ray enters and exits at the same location (Rays I, J and H ) , that location is marked with 278 / A —ed p g ^ G \ O F \ / <\ ? e 1;̂  A © t V > ^ N n i ® V o y 1 © \ J * • • * \ A 1 G / H Figure 1: The Black Box with four atoms and the paths of sev eral light rays visible.
 double arrows (this is called a reflection); otherwise, the locations at which the ray enters and exits the box are marked with a unique symbol (Rays A, F and G, marked with letters).
 The player does not actually see the path that the ray follows; hence, the path must be inferred.
 W e selected Black Box for three primary reasons.
 First, it shares many features with realworld abductive tasks such as device diagnosis and medical test interpretation.
 These similarities include: 1) Additional data must be collected based on the current working hypothesis; 2) The data can be decomposed into subsets such that the data in a subset can be explained by the same hypothesis; and 3) A single datum can require multiple individual hypotheses to explain.
 Second, Black Box is easy to understand—subjects easily learn the rules of the task within one hour of training.
 Third, one of the major problems with many studies of abductive reasoning (such as those done in medical domains or natural scientific domains) is the difficulty in controlling for background knowledge differences between subjects.
 By using a simple domain like Black Box w e can ensure that all subjects have the same knowledge of the device and that no additional external knowledge is given to the subjects.
 Anomalous Data Interpretation in BlackBox A typical example of an anomaly in Black Box and two ways to resolve it are illustrated in Figure 2.
 In Figure 2a the subject sees Ray A and places Atom 1.
 Next, Ray B is shot and the subject assumes that the ray actually traveled straight through the box as shown in Figure 2a.
 This explanation is anomalous, however, with the explanation for Ray A, because Atom 1 will cause Ray B to turn to the right.
 The typical response, at this point is to assume that Atom 1 is incorrect and to generate an alternative explanation for Ray A.
 Figure 2b shows one possible alternative in which Atom 1 is removed and Ray A is explained using three different atoms.
 Figure 2c, however, shows a completely different possibility in which Ray A is still explained by Atom 1, but Ray B is explained by an alternative configuration.
 Thus, the existence of an anomaly depends on how the data is initially explained.
 Entrenchment in this task refers to the number of rays accounted for by a certain atom.
 The model predicts that the higher this number is before anomalous data are seen the harder it is to give up the current explanation.
 Relative probability indicates which of the two contradictory explanations is more probable.
 Specifically, relative probability is the ratio of probabilities between the two contradictory explanations—^for example, between the probability tiiat Ray A is explained by the path shown in Figure 2a and the probability that Ray B is explained by the straight path in Figure 2a.
 The model predicts that the less probable explanation has a greater chance of being modified.
 Finally, the model predicts that availability of an explanation will increase with level of practice.
 Therefore, level of practice should affect a person's responses to anomalous data.
 / A \ J « 1 ^ E o \ J i r ! \ / / A \ I • ^ B W B • • N / / A \ I 4 1 \ E o 1 E ' i • • \ / (a) (b) (c) Figure 2: (a) illustrates an anomalous situation; (b) and (c) illustrate two ways to resolve the anomaly.
 279 E x p e r i m e n t a l Evaluation of the Predictions The predictions described in the last section were investigated in an experimental study.
 Ten undergraduate students at the University of Regensburg played on five consecutive days a total number of 185 games (25 training games and 12 test games every day).
 Design and Procedure A 5 (level of practice) x 3 (confirmatory evidence) x 4 (relative probability) withinsubjects design was used.
 The factor level of practice has five levels: one for each day of training.
 Confirmatory evidence was measured in terms of the number of ray markers an explanation (one or more atoms) accounts for.
 This factor varied from 2 to 4.
 Relative probability refers to the ratio of the probability of the old versus the new explanation.
 This factor had four levels: equal, new explanation is less likely than the old explanation, new explanation is more likely, and new datum absolutely contradicts the explanation for the old data, i.
e.
, the new datum cannot be explained without modifying the existing explanation.
 The relative probabilities are based on the frequencies that were computed for all possible combinations of ray patterns and atoms in B B X (e.
g.
, we know that 86.
7% of all absorptions are explained by a single atom).
 Combining these two factors results in 12 different combinations.
 Every session consisted of a training phase followed by a test phase.
 In the training phase, subjects were trained on 25 randomly generated games.
 In the test phase, subjects were presented with 12 critical cases (one for each of the above mentioned combinations) containing anomalies.
 The subjects' task in the training and the test games was to develop an explanation of rays by placing atoms.
 In a modified version of the original B B X game, subjects could place atoms, remove atoms or ask for new data.
 N e w data was requested by clicking on a button, labeled "More Data," which highlighted one of the perimeter cells of the Black Box matrix.
 This told the subject where the ray would be shot into the box.
 Clicking on this perimeter cell revealed the outcome of the ray shot.
 Thus the data was presented sequentially as it would be if the subjects had actually shot the rays themselves.
 By not allowing the subjects to select their own ray shots, we could use predefined games and therefore better control the situations presented to the subjects during the trials.
 After placing an atom, the subjects gave a confidence judgment that the location was correct.
 The confidence scale consisted of seven categories (between guessing and certain).
 All atom placements, removals and data requests were timestamped and recorded.
 Results Amount of evidence.
 On average, it took subjects less time to solve games with two or four pieces of confirming evidence than games with three data items (see Figure 3).
 In an A N O V A we found that the main factors practice, Fp^^ = 31.
44, p < 0.
01, and confirmatory evidence, F(;̂ f̂ = 23.
71, p < 0.
01, and their interaction, F^^^ ̂  Conf= ̂ •'̂ ̂ P < 0.
01, were highly significant With respect to difficulty (measured in terms of the number of correctly placed atoms), we found that games with two and three pieces of evidence were the hardest over all days.
 The mean of correct solutions remained significantly below the games with four confirming data items.
 Both main factors were significant, Fp^^ = 14.
94, p < 0.
01, Fc„nf= 8.
21, p < 0.
01.
 Howevei; there was no significant interaction between confirmatory evidence and practice (concerning the correctness of solutions), Fp,.
̂  ̂  Conf= 191, p < 0.
071.
 Relative Probability.
 Subjects took longest to solve inconsistent situations, followed by games in which the new explanation was more likely or as likely as the existing one.
 Games in which the old explanation was more likely were comparatively quick to play, Fĵ gi = 7.
7, p <.
 0.
001.
 Solution time decreased constandy with level of practice, Fp,^=19.
2, p < 0.
000, Fp,^,^,,^, ^1.
13, p < 0.
34.
 The mean of correct solutions was lowest with inconsistent situations, followed by equal and then by new and old, F = 10.
5.
 p < 0.
01.
 N e w and old switched after the first two trial sessions (see Figure 3).
 There was a general improvement between the training sessions, Fp^^= 14.
93, p < 0.
01 With respect to correctness, no interaction between the factors relative probability and level of practice could be found, Fp^^^i^^/p^ = 0.
67, p = 0.
8.
 ConfidenceRating.
 The model predicts that anomalous situations will lead subjects to search for alternative explanations, hence with practice on anomalous situations people should become more aware of alternatives.
 This means that the confidence ratings should increase for explanations that rarely proved to be wrong, but decrease for explanations that were frequenUy wrong due to anomalous data.
 The first assumption could be verified, x^= 28.
94, p < 0.
00.
 For the second hypothesis, however, statistical tests showed that the categorical variables confidence (7 categories) and level of practice (5 days) are independent, X^ = 13.
24, p > 0.
05.
 This means that subjects stabilized their judgment in cases where the current explanation remained correct but they did not become "more careful" or "more uncertain" for anomalous situations.
 Even after having seen a set of counterexamples that made it necessary to give up a current explanation, subjects continued placing these atoms with a degree of confidence that did not change based on experience.
 Discussion and Conclusions The amount of evidence and the likelihood of an alternative interpretation cleariy influenced the modification of explanations.
 This is, in general, consistent with the find280 0.
 o E CONF I 3 4 2 Day CONF Day ^ § S.
 "  8 RPROB inc eq new old in en in p ^ _ _ _ _ _ _ ^ / " ^ ^ T l ^ ^ / // / / / / RPROB n 1 ew Id eq inc Day Day Figure 3: Improvement across level of practice (day) dependent on the confirmatory evidence of the existing explanation (above) and the relative probability of the alternatives (bottom).
 The graphs on the left show improvement in terms of mean time per action (ms), where an action consisted of placing or removing an atom or asking for more data.
 The rightmost graphs show improvement in terms of the number of atoms correctly placed.
 [CONF—confirmatory evidence, RPROB—relative probability with inc—inconsistent, eq—equal.
] ings of Chinn and Brewer (1993) and also with the literature on cognitive biases (e.
g.
 Klayman & Ha, 1987).
 However, in detail, the single levels of both factors were not clearly distinguishable and did not follow the predictions.
 Based on these findings w e assume that entrenchment itself is not a major factor in determining the difficulty of a task.
 Instead, w e hypothesize that a person's ability to construct an alternative explanation of a given situation affects task difficulty.
 W e hypothesize that in a situation with anomalous data a person selects an explanation to modify based on awareness of alternatives for that explanation and on the possibility to explain all conflicting data by an alternative.
 If such an alternative explanation can be developed, then the simplest version that requires the smallest number of changes to the existing explanation, but that explains the most data, is selected.
 This is indirectly connected to the amount of confirming data.
 The greater this number is for the current theory the harder it may be to find an alternative that explains this data as well as the conflicting data.
 This is consistent with the model w e outlined earlier.
 Note, the necessity to construct an alternative explanation is a specific feature of the B B X task.
 Anomalous data in this task cannot just be ignored by rejection or exclusion, in contrast to the task used by Chinn and Brewer (1993).
 Therefore entrenchment and relative probabihty are dominated by a search for (and availability of) an alternative explanation.
 According to our model, search for an explanation ends as soon as a single satisfactory explanation is found.
 The empirical results on the confidence rating support this assumption since subjects' confidences in their initially constructed explanations remain constant even after seeing anomalous situations in which they had to construct alternative explanations for the same data.
 Thus, a subject's confidence in an explanation was independent of the relative frequencies that a certain explanation is correct for a pattern of data.
 This suggests that the confidence in a hypothesis is either dominated by the ease with which a hypothesis can be initially generated from domain knowledge or by parsimony.
 The subjects not only got faster, but also achieved better accuracy (see Figure 3).
 W e hypothesize the following explanation based on bounded search and knowledge compilation.
 According to the bounded search hypothesis, people will only expend a limited amount of effort before terminating a search with failure.
 These searches are not done in vain, however, because knowledge compilation will compile many of the steps of the terminated search.
 The next time a search is done, the person will be able to reach the previous point of the search process with less effort, due to the compiled steps.
 This allows the person to 281 search further.
 Eventually they will reach a desired state and generate a solution which will, in turn, affect the quality of their performance.
 Thus, we assume that people engage in a type of progressive deepening where the depth of succeeding searches is extended as a result of learning over prior searches (Johnson, Zhang & Wang, 1994).
 Quality of performance improves with experience because it may take many terminated search attempts before enough knowledge is compiled to permit a successful search.
 Acknowledgments This work has benefitted from comments and suggestions by Kathy Johnson.
 Hans Bogenberger programmed the Windows version of B B X .
 This work is supported by a GermanAmerican Collaborative Research Grant from the American Council of Learned Societies and the German Academic Exchange Program (DAAD).
 Additional support was provided by a Seed Grant from The Ohio State University and a grant from VielberthStiftung, University of Regensburg.
 Krems, J.
F.
 (1994).
 Wissensbasierte Urteilsbildung [Knowledgebased Diagnostic Reasoning].
 Bern: Huber.
 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M A : Harvard University Press.
 Read, S.
J.
 & Cesa, IL.
 (1991).
 This reminds me of the time when.
.
.
: expectation failures in reminding and explanation.
 Journal of Experimental Social Psychology, 27, 125.
 Schank, R.
, Riesbeck & Kass.
 (eds.
) (1994).
 Inside Casebased Explanation.
 Hillsdale: Erlbaum.
 Thagard, P.
 (1992).
 Conceptual Revolutions.
 Princeton, N e w Jersey: Princeton University Press.
 References Burbules, N.
C.
 & Linn, M.
C.
 (1988).
 Response to contradiction: Scientific reasoning during adolescence.
 Journal of Educational Psychology, 80, 6775.
 Chinn, C.
 A.
 & Brewer, W .
 F.
 (1993).
 Factors that influence how people respond to anomalous data.
 In Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society (pp.
 318323).
 Hillsdale, NJ: Lawrence Eribaum Associates.
 Dunbar, K.
 & Klahr, D.
 (1989).
 Developmental differences in scientific discovery processes.
 In D.
 Klahr & K.
 Kotovsky (eds.
).
 Complex Information Processing: The Impact of Herbert Simon (pp.
 109143).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Hasher, L.
 & Zacks, R.
 (1984).
 Automatic processing of fundamental information: The case of frequency of occurrence.
 American Psychologist, 39, 13721388.
 Johnson, T.
R.
, Krems, J.
F.
 & Amra, N.
K.
 (1994).
 A computational model of human abductive skill and its acquisition.
 In A.
 Ram & K.
 Eiselt (Ed.
), Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, (pp.
 463^68).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Johnson, T.
R.
, Zhang, J.
 & Wang, H.
 (1994).
 Bottomup recognition learning: a compilationbased model of limitedlookahead learning.
 In A.
 Ram & K.
 Eiselt (Ed.
), Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp.
 469474).
 Lawrence Erlbaum Associates.
 Josephson, J.
R.
 & Josephson, S.
G.
 (1994).
 Abductive Inference.
 Cambridge: University Press.
 Klayman, J.
 & Ha, Y.
W.
 (1987).
 Confirmation, disconfirmation, and information in hypothesis testing.
 Psychological Review, 94, 21122%.
 282 Are Experts Unbiased? Effects of Knowledge and Attitude on M e m o r y for Text Jennifer Wiley Department of Psychology and Learning Research and Development Center University of Pittsburgh Pittsburgh, P A 15260 wileyOpitt.
edu Abstract Subjects with varying amounts of domain knowledge read texts on two controvCTsial issues: whether the US should participate in the Persian Gulf War and ŵ iether abortion should be legal.
 Each text contained ten arguments for each side of the issue.
 Subjects with the most knowledge about the topics recalled rou^ly equal numbers of arguments from either side of the issue, while subjects with less knowledge recalled more arguments for the side they agreed with.
 The results were replicated with a third topic, the OJ Simpson case.
 The results of both experiments suggest that recall bias due to attitude may be eUminated by the possession of domain knowledge.
 ImpUcations for instructional programs using expert models are discussed.
 Experiment 1 Recent conceptions of expertise have stressed that it is not just the sheer quantity of domainrelevant knowledge possessed that separates experts from novices, but also the organization, integration and accessibility of that knowledge (e.
g.
 Bedard & Chi, 1992).
 Ericsson and colleagues (Chase & Ericsson, 1981; Ericsson & Staszewski, 1989) have advanced a "skilled memory" theory which suggests that as people acquire content knowledge, they also develop mechanisms, like retrieval structures, that enable them use their knowledge.
 It is argued that the presence of such a mechanism enables experts to rapidly encode, store and retrieve information related to their domain.
 One possible consequence of welldeveloped retrieval structures among experts is that expert recall may be qualitatively different than that of novices.
 In particular, the present study investigates whether expertise can eliminate (or reduce) the influence of attitude on recalL Since the early days of psychology, it has been observed that information which is consistent or congruent with our attitudes, opinions or beliefs is better remembered than attitudeopposing information.
 Bartlett (1932) noted that "When a subject is being asked to remember, very often the first thing that emCTges is something of the nature of attitude.
 The recall is then a construction made largely on the basis of attitude, and its general effect is that of a justification of the attitude.
" (pp.
 2067) However, over fifty years and fifty experiments later, empirical findings on "consistency bias" provide no clear support for these ideas, with some studies finding better recall for attitudesupporting information, and other studies finding no differences at all (See Pratkanis, 1989; Roberts, 1985 for further discussion).
 One possible reason for the failure to find a consistency bias effect overall may be that consistency bias is moderated by the possession of domain knowledge.
 The present study was designed to examine whether expertise (the possession of a large amount of domain knowledge) can reduce or eliminate consistency bias related to attitude in the recall of text.
 The position taken is that experts, because they have the advantage of a weUdeveloped and accessible store of domain knowledge, would not need to use their attitude as a cue for retrieval Thus, experts would not be susceptible to consistency bias.
 Nonexperts, however, lack a welldeveloped, accessible store of domain knowledge, and may default to attitude as a basis for encoding or retrieval Thus, nonexperts would be susceptible to consistency bias.
 Three specific hypotheses are made with respect to this general prediction that consistency bias should be moderated by the possession of domain knowledge.
 First, nonexperts should recall more information consistent with their attitudes than inconsistent while experts should recall at least as many attitudeinconsistent items as consistent.
 Second, lesseducated nonexperts may show more bias than moreeducated nonexperts.
 In order to separate the effects of possession of domain knowledge from general ability or motivation differences, experts in a specific domain read two kinds of texts.
 Some experts served as subjects with a large amount of domain knowledge on a text within their domain, while some read a text outside their domain, serving as moreeducated nonexperts.
 Undergraduates in an Introductory Psychology course served as lesseducated nonexperts for both texts.
 Even though moreeducated nonexperts may not possess more domain knowledge than the lesseducated nonexperts, they may better appreciate opposing arguments.
 Thus, the moreeducated nonexperts may recall more opposing arguments, making them less biased than their lesseducated counterparts.
 Third, recognition perfonnance should not be affected by the reader's attitude or amount of domain knowledge.
 All information should be encoded to some degree by all subjects.
 As a result, roughly equal numbers of consistent and inconsistent items should be recognized by all subjects.
 Method Subjects Twenty undergraduates at the University of Pittsburgh enrolled in an Introductory Psychology course, 20 graduate students in Political Science, and 20 Law students served as subjects.
 Subjects were paid for their participation.
 283 Materials Two texts were written of approxiiualcly equal leugtli.
 The first, on abortion, was 533 words and titled "Should abortion be legal?"; the second on llie Persian Gulf War was 548 words and titled "Should tlie United States use force against Iraq?" The topics were chosen as arguments about tlieni would be familiar arid of interest even to nonexperts.
 Also, presentation in Uie fonn of a prose passage was chosen over a list of statements in llie interest of keeping tlie task more incidental, aiid hence, naturalistic.
 Eiach text contained 20 arguments, 10 supporting each side of the issue.
 Arguments for either side of the issue were intemiingled throughout the text.
 Because coherence of tlie text was a primary consideration, the exact pro/con ordering was not identical for the two texts.
 Most importajitly, arguments for each side of tlie text were matched for strengtli and familiarity through piloting.
 For each text, recognition tests were developed consisting of the 20 arguments from the text and 10 distractor items (5 for each side).
 Recognition items were not taken verbatim from tlie texts, rather they were rephrased to prevent surface recognition.
 In addition, a 10ilem knowledge test was developed for each topic.
 Procedure The experiment took place in 1991 after the war had ended.
 Subjects were told they were piloting materials and rated the familiarity of each sentence of the text on a 10point scale while reading.
 Familiarity judgement was chosen as a task because each sentence would be read, but as opposed to an agreement judgement task, would not necessarily invoke attitudebased processing.
 Subjects first read and rated the experimental text.
 After a 30 minute filler task, subjects were asked to write down as much as they could of tlie article they read at the begiiuiing of tlie session, referred to by title, and prompted to remember as many points from the article as possible.
 W h e n finished recalhng, subjects were given a 30item recognition test and a 10item domain knowledge test on the same topic as the text they had read.
 Position on issues was assessed using a 10point scale before and after the task.
 Before the task subjects were asked to rate their opinion on many issues, and the taskrelevant issue was embedded in tliis hst.
 Design Ten undergraduates (le.
sseducated nonexperts), 10 Political Science graduate students (moreeducated nonexperts), and 10 Law students (experts) read the text on abortion; while 10 undergraduates (lesseducated nonexperts), 10 Law students (moreeducated nonexperts) and 10 Political Science graduate students (experts) read the text on the Persian Gulf War.
 Tims, tiiree levels of expertise were split across two texts to yield six independent cells.
 Each text contained 20 arguments in total, 10 arguments for each side of the Issue.
 Consistency witii position was tested as a within subjects variable.
 Tiuis, the design was a 3x2x2 (LxpertLse x Text x (Consistency) mixed design with repeated measures on tiic last variable.
 Results D o m a i n K n o w l e d g e A twofactor analysis of variance (ANOVA) using level of expertise (Lesseducated nonexpert.
 Moreeducated nonexpert.
 Expert) and text (Abortion, Persian Gulf) perfomied on the results of the 10item domain knowledge test revealed no main effect for text, 1:(1,56)=.
01, MSE=1.
90, £=.
93, but a highly significant main effect for knowledge, F(2,56)=49.
67, MSE=1.
90, e<0001.
 Tukey's H S D test of pairwdse comparisons indicated that lesseducated nonexperts answered significantly fewer items correctly (M=3.
65) than tlie moreeducated nonexperts (M=6.
50, £<.
01), who, in turn, answered significantly fewer items correctly than the experts (M=7.
85, p<.
01).
 Tlius, the expertise groups represented three distinct levels of domain knowledge.
 Recall A 3x3x2 mixed ANOVA (Knowledge Level, Text, Consistency with Attitude) on accurate recall of arguments from the texts revealed a highly significant main effect for knowledge level, F(2,56)= 10.
84, MSE=4.
65.
 e<.
0001.
 Posthoc coniparisoas indicated that experts (M=9.
6) recalled significantly more arguments than either the moreeducated nonexperts (M=7.
9), t(38)=2.
70, e<01, or the lesseducated nonexperts (M=5.
15), l(38)=7.
08, e<.
0001.
 1 s 1 6 5 4 3 2 1 [?1 IZkCOIisiftCIit MoraZd L̂ ssli Zxp«rt5 Hoii«3tp<rt3 HoiL«xp«rt5 Hi^K Low Knowledge Knowledge Figure 1: M e a n n u m b e r of consistent and inconsistent arguments recalled by knowledge group in Experiments 1 and 2 284 In addition, the moreeducated nonexperts recalled more arguments from the text than the lesseducated nonexperts, t(38)4.
38, E.
OOOl.
 Thus, as domain knowledge increased so did the number of arguments recalled.
 A significant niHin effect was also found for text, F(l,56)5.
82, MSi:4.
65.
 E=02, as subjects recalled more arguments from tiie Abortion text (M=8.
50) than from the Persian Gulf text (M6.
60).
 The most interesting result, however, as predicted by the first hypothesis, is the significant interaction between knowledge level and consistency with position, F(2,57)3.
51, MSE=1.
98.
 E=04.
 Figure 1 presents the mean number of attitudeconsistent and attitudeinconsistent arguments recalled for each knowledge level Plamied comparisons indicated that the lesseducated nonexperts exhibited a significant consistency bias, recalling more information supporting their position than opposing it, t(19)=2.
36, p=.
02.
 Moreeducated nonexperts also tended to recall more supporting than opposing information, but this bias was only marginally significant, 1(19)=180, ̂ =08.
 Experts, on the other hand, recalled slightly less supporting than opposing arguments but this difference was not significant, t(19)=1.
13, ^=.
21.
 Plamied comparisons on the difference of consistent versus inconsistent arguments recalled between groups showed that experts were significantly less biased than either lesseducated nonexperts, l(38)=2.
47, E" 02, or moreeducated nonexperts, t(38)=2.
07, e= 04.
 There was no difference in bias of lesseducated and moreeducated nonexperts, t(38)=.
40, e=69.
 Thus, in support of the first hypothesis, subjects with the least domain knowledge had a consistency bias in their recall of the text, while the most knowledgeable subjects had none.
 Further, the experts were significantly less biased than either nonexpert group.
 Support was not found for the second hypothesis, however, as no differences were found between the biases of the nonexpert groups.
 Recognition The mean number of arguments that were correctly recognized as being in the text was 16.
05 for the experts, 16.
10 for the moreeducated nonexperts, and 15.
15 for the lesseducated nonexperts.
 A 3x2x2 mixed A N O V A (Knowledge Level, Text, Consistency with Attitude) on recognition of items from the text revealed that no main effects or interactions approached significance (Fs<1.
59).
 These results support the third hypothesis and suggest that the bias observed in the recall of the lesseducated nonexperts was not due to selective attention or exposure on the basis of attitude or knowledge, as all subjects were comparable in their abihty to recognize the majority of both consistent and inconsistent items from the text.
 Conclusions The results of Experiment 1 suggest tliat recall consistency bias in favor of attitudesupporting information is moderated by the posscvssion of domain knowledge.
 Subjects witli tlie least amount of domainspecific knowledge had a significant bias in tJieir recall due to attitude, while no bias due to attitude was observed among the expert subjects.
 Meanwhile, moreeducated nonexperts fell between the experts and tesseducated nonexperts both in domain knowledge as well as in recall bias.
 It must be noted that these results may be less than convincing due to the fact tliat subjects' position on the issues was not controlled and there were differences among the knowledge groups in positions taken on tlie Persian Gull issue.
 In relation to the abortion issue, the knowledge groups were fairly similar.
 O n the Persian Gulf issue, however, tlie nonexperts were somewhat for the war while the experts were mostly against it.
 Experiment 2 In Experiment 2, position on issue was controlled such that at each knowledge level, half the subjects agreed with each side of the issue.
 Also of interest was whether the effect observed in Experiment 1 would generalize to a new topic.
 Method Subjects 20 undergraduates at the University of Pittsburgh participated in this experiment as part of the Introductory Psychology subject pool Procedure This experiment was a partial replication of Experiment 1 with a new topic, "Is OJ Simpson guilty ", done in the fall of 1994.
 A 545word text, 30item recognition test and 10item domain knowledge test were created.
 Subjects with 7 or more correct answers on the domain knowledge test were considered "high" knowledge; subjects with less than 7 were considered "low" knowledge.
 In each knowledge group, 5 subjects agreed and 5 disagreed that OJ Simpson was guilty beyond a reasonable doubt.
 Results Recall The mean number of arguments recalled was lO.
O for the high knowledge group and 9.
1 for the low knowledge group.
 N o significant difference due to level of knowledge was found, t(18)= .
88, p<.
39.
 As in Experiment I, there was a significant effect of knowledge on recall bias.
 Figure 1 presents the mean number of attitudeconsistent and inconsistent arguments recalled for each knowledge leveL Paired ttests indicated that the low knowledge group had a significant consistency bias, recalling abnost 2 more arguments in favor of their position than opposing it, t(9)4.
38, E<01.
 The high knowledge group, however, recalled sUghtly fewer supporting than opposing arguments, but this reverse bias was not significant, t(9)= .
77, p<.
46.
 Further, a two sample ttest between knowledge groups indicated that the low knowledge group was significantly more biased than the high knowledge group, t(18)=3.
40, E<.
01.
 Recognition The mean number of arguments that were correctly recognized as being in the text was 16.
2 for the high knowledge group and 16.
0 for the lowknowledge group.
 N o differences were found in recognition due to knowledge or position.
 Conclusions The results of Experiment 2 clearly replicated the effect found in Experiment 1: high knowledge subjects had no bias 285 in Iheir recall, while low knowledge subjects did.
 Further, these results were obtained on a new issue and witli an equal number of subjects on either side of Oie issue on each knowledge level.
 General Discussion The results of the two experiments clearly indicate tliat consistency bias in recall due to attitude may be moderated by domain knowledge, with the most knowledgeable subjects showing no bias, and less knowledgeable subjects showing a significant bias.
 It is suggested that recall consistency bias is the result of the less knowledgeable subjects relying primarily on their evaluation of a topic as a basis for encoding, retrieving, or reconstructing the text, while more expert subjects have the advantage of using their domain knowledge as the principal basis for text processing and retrieval.
 The observed qualtitalive difference in the recall of the experts and nonexperts has implications for research in Cognitive Science on the modeling of expert performance or processing, and the use of those models to train nonexperts.
 The present results suggest that expert models may not be appropriate tools in cases where attitudes are involved, as nonexperts may have difficulty using their knowledge in a manner similar to experts.
 O n the other hand, the demonstration of qualitative differences in the memory performance of experts and nonexperts serves to inform models of expertise, as it suggests which aspects of knowledge representation or processing may be changing as one gains expertise.
 References Bartletl, F.
 C.
 (1932).
 Remembering.
 Cambridge, England: Cambridge Univ Press.
 Bedard, J.
 & Chi, M.
 T.
 H.
 (1992).
 Expertise.
 Current Directions in Psychological Science, 1(4), 1359.
 Chase, W.
 & Ericsson, K.
 A.
 (1981) SkiUed Memory.
 In J.
 R.
 AndCTSon (Ed.
), Cognitive Skills and Their Acquisition.
 Hillsdale: Erlbaum.
 Ericsson, K.
 A.
 & Stasewski, J.
 (1989) Skilled memory and expertise.
 In D.
 Klahr & K.
 Kotovsky (Eds), Complex Information Processing.
 Hillsdale: Erlbaum.
 Pratkanis, A.
 R.
 (1989).
 The cognitive representation of attitudes.
 In A.
 R.
 Pratkanis, S.
 J.
 Breckler, & A.
 G.
 Greenwald (Eds.
) Attitude Structure and Function.
 Hillsdale: Erlbaum.
 Roberts, J.
 V.
 (1985).
 The attitudememory relationship after 40 years: A metaanalysis of the literature.
 Basic and Applied Social Psychology, 6(3), 221241.
 286 Complex Decision Making in Providing Surgical Intensive Care Andre W .
 Kushniruk Cognitive Studies in Medicine Centre for Medical Education McGill University 1110 Pine Avenue West Montreal, QC, H3A 1A3 Canada cx2v@musica.
 mcgill.
ca Vimla L.
 Patel Cognitive Studies in Medicine Centre for Medical Education McGill University 1110 Pine Avenue West Montreal, QC, H3A 1A3 Canada patel@hebb.
psych.
 mcgill.
ca David M .
 Fleiszer Montreal General Hospital McGill University 1650 Cedar Avenue Livingston Hall L9313 Montreal, QC, H3G 1A4 Canada fleiszerSmedcor.
 mcgill.
ca Abstract Decisions made by physicians in intensive care medicine are often complex, requiring the consideration of information that may be incomplete, ambiguous, or even contradictory.
 Under conditions of complexity and uncertainty, individuals may cope by using simplifying decision strategies.
 The research described in this paper examines the strategies used by physicians in coping with complexity in decision making.
 Six residents (intermediates) and three specialists in intensive care were each presented with 12 cases of intensive care respiratory problems of varying levels of complexity.
 The subjects were asked to thinkaloud as they worked through the problems and provided a management and treatment plan for each case.
 The audiotaped protocols were coded for key process variables in decision making and problem solving.
 Despite the incompleteness and ambiguity of the information available, the confidence of physicians in their decision making was consistently high.
 The strategies used by intermediates and experts in dealing with the more complex cases varied considerably.
 Expert physicians were found to focus on the assessment of the decision problems to a greater extent than intermediates.
 Implications for research in decision making and medical cognition are discussed.
 Introduction Decision making in realworld domains, such as intensive care medicine, often involves making complex decisions in situations where information is incomplete, ambiguous and uncertain.
 Problems encountered in such domains are often illdefined and subject to a number of realworld constraints.
 This paper focuses on a study of h ow intermediate and expert level physicians deal with complexity in decision making in the treatment and management of a frequently encountered respiratory condition.
 Diagnosing and treating this condition, known as pulmonary embolism, requires consideration of information from several sources and involves careful judgment in weighing clinical evidence with test results.
 This type of decision problem is typical of many diagnostic and treatment planning situations in medicine.
 Under conditions of high task complexity (e.
g.
, in choice situations involving many alternatives) or time pressure, particular simplifying strategies are likely to be adopted by decision makers (Payne, Bettman & Johnson, 1993).
 These strategies can be considered as methods for simplifying the search through the decision problem space, either by limiting the amount of information processed or by making processing of that information easier.
 Related research in the area of medical decision making has revealed the use of varied strategies by subjects in coping with complexity of reallife medical situations.
 For example, work by Patel and Leprohon (1993), involving the analysis of emergency decision making of nurses responding to 911 emergency calls, has indicated that high performance decision making was related to the decision maker's approach to the evaluation of the whole emergency situation.
 Consistent with this research, field studies of decision making in a number of naturalistic settings has indicated the importance of situation assessment in expert decision making (Klein 1993).
 Research in medical decision making has typically examined decision making from a different vantage point than research in the area of medical problem solving.
 Although conceptually similar, problem solving and decision making have traditionally been studied using different research paradigms.
 A considerable body of research findings has accumulated in the cognitive study of medical reasoning and problem solving (Patel & Groen, 1991).
 Studies have indicated that physicians use a variety of strategies in dealing with uncertain and illstructured medical problems (Patel, Arocha & Kaufman, 1994).
 In solving diagnostic problems, expert physicians have been shown to be capable of focusing on small sets of related hypotheses and are able to use efficient discrimination strategies for distinguishing relevant from irrelevant information in diagnostic reasoning (Patel & Kushniruk, 1992).
 The extent to which such research findings, emerging from the study of problem solving, can be extended to medical decision making remains to be more fully explored.
 Recently, n e w methodological perspectives have emerged from which to view research in decision making.
 287 A variety of observational field studies have appeared in the study of complex decision making (e.
g.
 Klein and Calderwood's study of firefighters, 1991).
 However, there is also the need to further develop laboratory studies that are sensitive to the complexity of realworld decision making tasks and that are at the same time experimentally rigorous.
 Such research needs to take into account the varied contexts and complexity of decision tasks, as well as the level of expertise and knowledge of the decision makers.
 The approach taken in the research described in this paper extends the "expertise approach", from the study of human problem solving and reasoning (Ericsson & Smith, 1991) to the domain of complex medical decision making.
 The research involves the use of realistic tasks and subjects with varied domain expertise, within a controlled experimental design.
 The purpose of this paper is threefold: 1) to determine how intermediate and expert physicians make decisions in dealing with complex tasks, 2) to determine what type of strategies are employed as the degree of task complexity changes, and 3) to determine the extent to which findings from this study are consistent with existing theories of decision making, problemsolving, and expertise.
 M e t h o d o l o g y In this study, written case descriptions were presented to subjects of two levels of expertise 6 intensive care residents (intermediates) in training in a surgical intensive care unit, and 3 intensive care specialists (experts).
 Preliminary observational analysis (Kushniruk, 1995) involved examining the types of information that are critical in decision making related to intensive care respiratory problems.
 This work indicated that lung scan evidence and clinical evidence are two factors that are essential in diagnosing a condition known as pulmonary embolism.
 The case descriptions used in the study were designed to systematically vary the levels of two critical types of evidence: (1) lung scan evidence for the presence of pulmonary embolism (characterized by three levels: low, intermediate and high probability of pulmonary embolism) and (2) clinical evidence for the presence of pulmonary embolism (two levels: low and high).
 Thus, in the experimental design, there were six types of cases, one for each combination of the three commonly encountered levels of lung scan evidence and two clinical evidence levels considered by physicians: Case Type Probability Lung Scan Clinical Evidence 1 L o w L o w 2 L o w High 3 Intermediate L o w 4 Intermediate High 5 High L o w 6 High High Pulmonary embolism, a condition which can result in blood clots in lungs, is most readily identified by a combination of a high probability lung scan in conjunction with high clinical evidence.
 O n the other hand, a low probability lung scan in conjunction with low clinical evidence, essentially rules out this condition.
 Complex conditions, i.
e.
 decision situations that are ambiguous, requiring the careful consideration of complex qualitative data, occur with the remaining combinations (e.
g.
 an intermediate probability lung scan in conjunction with low clinical evidence).
 T w o case descriptions were designed for each of the 6 case types, and therefore 12 cases in total were designed.
 As an example, one of the cases is given below.
 In this case (case type 6), the V/Q lung scan indicates a high probability of a pulmonary embolism (as indicated in the last statement in the case), coupled with high clinical evidence of pulmonary embolism (e.
g.
 from the patient's history, physical exam, and lab results): A 72 year old lady, previously well, sustained a fractured femur when she fell off a kitchen stool.
 She was maintained in Buck's traction for six days at which time she underwent a femoral rodding.
 In the recovery room, difficulty was encountered maintaining her oxygenation and continued mechanical support was required.
 The nurse noted there were large amounts of blood stained sputum being suctioned from the ET tube.
 On examination she was unresponsive.
 Pulse 100; BP 110/70; Temperature 39.
1 C.
 The incision was clean and there was no evidence of bleeding.
 There were no retinal or subligual hemorrhage and no petechiae.
 On auscultation breath sounds were diminished on the left and there was dependent dullness to percussion.
 E K G showed right axis deviation.
 H B 8; W B C 18,000.
 Chest Xray showed multiple infdtrates on the left and a small effusion.
 A pleural tap resulted in the aspiration of 400 cc of bloodstained serous fluid.
 FI 102 100%; P02 85; PC02 38; V/Q scan showed multiple areas of mismatch with a high probability of embolus.
 During the experimental sessions, each subject was presented with the cases, one after the other.
 The cases were initially ordered randomly.
 Each subject was asked to: (1) read the case and think aloud as they decided on a course of action to be taken in dealing with that case (i.
e.
 provide the therapeutic and management plan), (2) indicate whether they would treat with the information given (and if not, what information would be needed), (3) suggest a differential diagnosis for the case, and (4) indicate how likely they think their diagnosis is correct.
 In addition, for each case, subjects were requested to indicate how confident they were in their judgment on how to proceed with the case, on a 7 point scale, ranging from very unconfident (1) to highly confident (7).
 Data Analysis The verbal protocols of the subjects were transcribed and coded for key aspects of clinical decision making and problem solving.
 For the present study, a scheme for coding the subjects' protocols was devised.
 The scheme includes categories for coding problem solving and reasoning strategies used, including generation and testing of diagnostic hypotheses (Patel & Groen, 1986; Hassebrock & Prietula, 1992).
 In addition, the analysis 288 Coding S c h e m e Decision Processes Reasoning Assess Situation Compare Alternatives Choose Investigation Choose Treatment Choose Other Action Reconsider Choice Review Data Interpret/Evaluate Data Form Goal Consider Hypothesis Support Hypothesis Confirm Hypothesis Rule Out Hypothesis Consider Alternative Hypothesis Figure 1: Coding Scheme included coding for critical aspects of decision making.
 An important aspect of the coding scheme was the inclusion of categories for evaluating the subjects' situation assessment, defined as processes involved in the identification and clarification of the state of the decision problem (Klein & Calderwood, 1991).
 Categories related to decision making were modified from those used by Kuipers, Moskowitz, and Kassirer (1988).
 The main categories included in the coding scheme applied by the experimenters are given in Figure 1 (complete descriptions of the criteria for coding for each category are provided in Kushniruk, 1995).
 In addition to coding each protocol for aspects of decision making and problem solving, each protocol was characterized according to the strategies used by subjects.
 A decision rule was first identified for each protocol, based on the course of action suggested by the subjects for the six case types.
 More general strategies were also identified, using an approach based on that described by Elstein, Holzman, Belzer, and Ellis (1992) where strategies common to groups of subjects were identified.
 Results The results described below, deal with three areas: (1) coding of the protocols (2) determination of rules and strategies used by subjects, and (3) subjective confidence.
 Decision Making and Reasoning The results from the analysis of coded protocols are summarized in Table 1, which gives the percentage of total segments coded for each aspect of decision making Table 1: Frequency and percentage of coded segments of verbal protocols Code Assess Situation Compare Alternatives (concurrently) Choose Investigation Choose Treatment Choose other action Reconsider choice Review data Interpret/evaluate data Form goal Consider hypothesis Support hypothesis Confirm hypothesis Rule out hypothesis Consider alternative hypothesis Intermediates Frequencv 82 9 64 139 12 9 113 93 26 139 59 3 12 24 Percentage 10.
5 1.
2 8.
2 17.
8 1.
5 1.
1 14.
5 11.
9 3.
3 17.
8 7.
6 .
4 1.
5 3.
1 Experts Frequencv Percentage 171 5 20 38 5 12 56 40 20 76 15 4 6 17 35.
5 1 4.
2 7.
8 1 2.
5 11.
6 8.
3 4.
2 15.
8 3.
1 .
8 1.
2 3.
5 289 and reasoning in the coding scheme.
 The percentages arc listed for both intermediate and expert subjects.
 The most notable difference between experts and intermediates was in the category of situation assessment, with expert protocols containing a greater percentage of segments dealing with this aspect of decision making.
 A n excerpt from an intermediate subject's think aloud protocol for one of the cases is provided below (codes are in boldface).
 This case consisted of a description of a patient with a high probability lung scan in conjunction with high clinical evidence of pulmonary embolism: Uhm, my impression is that she wasn't given any therapeutic subcutaneous heparin D V T anything like that so uhm, she is a high risk case for pulmonary embolus.
 C O N S I D E R H Y P O T H E S I S : Pulmonary embolism So I would definitely start uhm, on heparin because she seems to be very sick C H O O S E T R E A T M E N T : heparin In contrast, a portion of an expert's subject's protocol for the same case is given below: Uh, I'd want further history, specifically, uhm, starting with the acute event, A S S E S S S I T U A T I O N uh, it mentioned that in the recovery room difficulty was encountered maintaining her oxygenation.
 REVIEW DATA I'd like to know whether there was any problems intraoperatively.
 Uh, specifically with oxygenation and/or hemodynamics.
 In addition, I'd want to know whether there was any difficulty intubating the patient for the operating room itself A S S E S S S I T U A T I O N In comparison to intermediate subjects, the expert subjects tended to stress the evaluation of situational aspects of the cases.
 This is reflected by the greater percentage of segments coded for situation assessment for expert physicians (see Table 1).
 Decision Strategies The decision rules used by the physicians for each of the six types of cases are presented in Table 2.
 For each type of case, the table gives the outcomes of the physician's management decision, as well as the number and percentages of cases where that treatment plan was recommended.
 As can be seen, for cases representing low probability lung scan in conjunction with low clinical evidence, and for cases consisting of high probability lung scan in conjunction with high clinical evidence, decision making was consistent across all physicians (e.
g.
 5 3 7 28 17 39 3 4 6 17 22 33 all physicians recommended the same course of action in all of the 18 cases presented that were low probability lung scan in conjunction with low clinical evidence).
 In contrast, for cases involving the other combinations of clinical and lung scan evidence, the decisions varied considerably.
 Table 2: Number and percent of subjectgenerated protocols described by decision rules (grouped by case type 1 6) Number Percent 1.
 If low probability lung scan + low clinical evidence a.
 D o not treat for PE 18 100 2.
 If low probability lung scan + high clinical evidence a.
 Do not treat for PE (rule out PE) b.
 Treat for PE immediately c.
 If pending investigations are positive then treat for PE d.
 Defer decision  assess further 3 17 3.
 If intermediate probability lung scan + low clinical evidence a.
 Do not treat for PE (rule out PE) b.
 Treat for PE immediately c.
 If pending investigations are positive then treat for PE d.
 Defer decision  assess further 5 28 4.
 If intermediate probability lung scan + high clinical evidence a.
 Do not treat for PE (rule out PE) b.
 Treat for PE immediately c.
 If pending investigations are positive then treat for PE d.
 Defer decision  assess further 2 11 5.
 If high probability lung scan + low clinical evidence a.
 D o not Ueat for PE (rule out PE) b.
 Treat for PE immediately c.
 If pending investigations are positive then treat for PE d.
 Defer decision  assess further 4 22 6.
1f high probability lung scan + high clinical evidence a.
 Treat for PE immediately 18 100 PE = pulmonary embolism Table 3 provides commonly applied global strategies used by subjects in dealing with the complex cases, where the level of lung scan evidence differed from the level of clinical evidence.
 These more global decision strategies were derived by noting that there were four approaches 3 9 4 17 50 22 7 4 3 39 22 17 290 Table 3: Higherorder strategies derived from physicians' decisions in responding to the complex case vignettes (cases type 2 5) Strategy Strategy 1: Focus on lung scan Strategy 2: Focus on clinical evidence Strategy 3: Focus on risk factors Strategy 4: Stabilize & defer decision 11 1 5 1 1 12 1 6 0 1 13 6 2 0 0 Subj^gts 14 1 6 0 1 15 6 2 1 0 16 5 3 0 0 El 1 1 0 6 E2 2 1 1 4 E3 1 2 1 4 I = Intermediate E = Expert common to groups of subjects.
 The majority of the intermediate physician's decision making could be described by three of the four strategies listed in the table; that is by focusing on lung scan evidence, clinical evidence or risk factors.
 In contrast, a strategy used by expert subjects involved the deferral of an immediate treatment decision, pending the results of a further assessment of the decision situation (i.
e.
 results of tests and investigations).
 Confidence in Decision Making The means for the physician's ratings of confidence (on a scale from 1 to 7) in their decision making, for each of the six types of case vignettes, are given in table 4.
 The confidence in the subjects' judgments of their decision making was consistently high.
 Discussion An important finding of research in human decision making is that individuals use a variety of choice strategies (Payne, Bettman, & Johnson, 1993).
 In the present study decision making by physicians was examined in order to determine how they cope when faced with complexity in decision problems.
 In the study this complexity was represented in case descriptions by varied levels of clinical and lung scan evidence.
 From a theoretical perspective, strategies can be considered as methods for simplifying the search through the decision problem space.
 Different types of strategies were found to be employed by experts and intermediates in situations involving the complex consideration of various sources of evidence.
 Intermediate subjects were found to focus on selected aspects of evidence presented.
 In contrast, expert physicians tended to defer decision making, if possible, pending further information (i.
e.
 if the patient can be stabilized).
 Although all subjects rated their confidence in decision making as consistently high, the results indicated that with complex cases, a variety of different decisions were made by physicians.
 Under emergency conditions, there may be a need for decision makers to feel confident enough to be able to act, as lack of confidence in emergency decision making could lead to potentially disastrous indecisiveness (Baumann, Deber & Thompson, 1991).
 Furthermore, the use of simplifying strategies in such domains could, in many cases be an adaptive response, ensuring that decision makers do not become overwhelmed by the amount and complexity of data to be processed.
 Research in the study of expertise in medical reasoning has shown that there are basic differences in the approaches taken in problem solving by physicians of differing levels of expertise (Patel, Arocha, & Kaufman, 1993).
 Consistent with these findings in the areas of medical problems solving, the present study indicated that intermediate and expert subjects approached the decision problems in a different manner.
 Similar to research Table 4: Confidence ratings of intermediate and expert level physicians, for each of 6 types of case vignettes (on a scale from 17) Mean confidence in judgment Condition Lung Scan Low Low Intermediate Intermediate High High Clinical Evidence Low High Low High Low High Intermediates 5.
78 5.
78 5.
35 5.
64 5.
92 6.
21 Experts 5.
63 5.
88 5.
50 6.
00 5.
35 6.
00 291 findings from studies involving the observational analysis of realworld decision making situations, including emergency nursing (Patel & Leprohon, 1993), it was found that expert subjects focused on developing a better assessment of the decision problem as a whole.
 According to Klein and Calderwood's (1993) model of expert decision making, experts process decision tasks by comparing them to previous experiences.
 In order to match to their knowledge base of previous cases, accurate assessment of the current situation is critical.
 From the analysis of the protocols it was also determined that rarely did either intermediates or experts compare choice alternatives simultaneously.
 This finding, from controlled laboratory research, is also consistent with results from naturalistic settings, indicating that in time limited and complex situations, experts tend to evaluate choice alternatives serially (Klein & Calderwood, 1991).
 From the protocols, the problem solving nature of the decision makers' approach was readily apparent.
 Interspersed between consideration of choices regarding aspects of therapy, subjects spent a great deal of time in considering diagnostic hypotheses in developing explanations of the patient's underlying problem, as evidenced by the percentage of coded segments related to consideration of hypotheses.
 In the present study, the nature of the decision problems presented to subjects were illdefined, as is the case in much decision making in realworld situations.
 Under such task conditions, it would seem reasonable that there would be a close relationship between what has traditionally been considered problem solving and decision making processes.
 In contrast to the use of experimental tasks where the options are presented to subjects, in the present study, problem solving processes had to be invoked in order to narrow the decision problem space.
 Thus operations such as goal formation, hypothesis testing and diagnostic reasoning were found to be closely related to the generation of decision options and selection of alternative actions.
 In this study, the "expertise approach", involving the use of realistic tasks and experienced subjects, in a controlled experimental setting, was employed and the findings were found to be compatible with those emerging from both research in medical problem solving and naturalistic decision research.
 Important links are being forged between research in decision making and work in related areas such as human problem solving and human expertise.
 A convergence of both methodological approaches and theoretical frameworks shows great promise for increasing our understanding of the complexities involved in decision making.
 Acknowledgments The authors are grateful to David Kaufman, Tony Marley, Jose Arocha and Michael Leccisi for their insightful comments and discussion regarding this work.
 References Baumann, A.
, Deber, R.
 & Thompson, G.
 (1991).
 Overconfidence among physicians and nurses: The 'microcertainty, macrouncertainty' phenomena.
 Social Science & Medicine.
 32(2).
 167174.
 Elstein, A.
 S.
, Holzman, G.
 B.
, Belzer, L.
 J.
 & Ellis, R.
 D.
 (1992).
 Hormonal replacement therapy: Analysis of clinical strategies used by residents.
 Medical Decision Making, 12(4).
 265273.
 Ericsson.
 K.
A.
 & Smith, J.
 (1991).
 Prospects and limits of the empirical study of expertise: An introduction.
 In K.
A.
 Ericsson and J.
 Smith (Eds.
), Toward a General Theory of Expertise.
 New York: Cambridge University Press.
 Hassebrock, F.
 & Prietula, M.
 (1992).
 A protocolbased coding scheme for the analysis of medical reasoning.
 International Journal of ManMachine Studies, 37, 613652.
 Klein, G.
A.
 (1993).
 A recognitionprimed decision (RPD) model of rapid decision making.
 In G.
 Klein, J.
 Orasanu, R.
 Calderwood, C.
 Zsambok (Eds.
), Decision Making in Action: Models and Methods.
 Norwood, NJ: Ablex Publishing Company.
 Klein, G.
A.
 & Calderwood, R.
 (1991).
 Decision models: Some lessons from the field.
 IEEE Transactions on Systems, Man, and Cybernetics, 21(5), 10181026.
 Klein, G.
, Orasanu, J.
,Calderwood, R.
, & Zsambok, C.
 (1993).
 Decision Making in Action: Models and Methods, Norwood, NJ: Ablex Publishing Company.
 Kuipers, B.
, Moskowitz, A.
 J.
 & Kassirer, J.
 P.
 (1988).
 Critical decisions under uncertainty: Representation and structure.
 Cognitive Science, 12, 177210.
 Kushniruk, A.
 W.
 (1995).
 Cognitive models of surgical intensive care decision making.
 Doctoral dissertation.
 Montreal: Department of Psychology and Centre for Medical Education, McGill University.
 Patel, v.
, Arocha, J.
 & Kaufman, D.
 (1994).
 Diagnostic reasoning and medical expertise.
 The Psychology of Learning and Motivation, 31, 187252.
 Patel, V.
L.
 & Groen, G.
J.
 (1986).
 Knowledge based solution strategies in medical reasoning.
 Cognitive Science, 10, 91116.
 Patel, V.
 L.
 & Groen, G.
 J.
 (1991).
 The general and specific nature of medical expertise: A critical look.
 In A.
 Ericsson & J.
 Smith (Eds.
), Toward a General Theory of Expertise: Prospects and Limits (pp.
 93125).
 New York, NY: Cambridge University Press.
 Patel, V.
L.
 & Kushniruk, A.
 (1992) Small Worlds: Their role in the development of medical expertise.
 33rd Annual Meeting of The Psychonomic Society,.
 St.
 Louis, MI.
 Patel, V.
L.
 & Leprohon, J.
 (1993).
 Decision making strategies in emergency telephone triage situations.
 In Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society (p.
 177).
 Hillsdale, NJ: Lawrence Eribaum Associates.
 Payne, J.
W.
, Bettman, J.
 & Johnson, E.
 (1993).
 The Adaptive Decision Maker.
 Cambridge: Cambridge University Press.
 292 A Connectionist Model for Classification Learning  T h e l A K M o d e l Martin Heydemann Institut fuer Psychologic Technische Hochschule Darmstadt Steubenplatz 12 D 64293 Darmstadt Germany heydemann@hrzl.
hrz.
thdarmstadt.
de Abstract The connectionist model lAK (Information evaluation using configurations) for classification learning is presented here.
 The model can be placed between feature based (e.
g.
 Gluck & Bower, 1988) and exemplar based models (e.
g.
 A L C O V E , Kruschke, 1992).
 Specific to this model is that during learning, sets of input features are probabilistically sampled.
 These sets are represented, in a hidden layer, by configuration nodes.
 These configuration nodes are connected to output nodes that represent category labels.
 A further characteristic of the lAK model is a mechanism which enhances retrieval of information.
 Simulations with the lAK model can explain different phenomena of classification learning which have been found in experimental studies: A Type 2 advantage without dimensional attention learning observed by Shepard et al.
 (1961); a generalisation of prototypes; a generalization based on similarity to learned exemplars; a differential forgetting of prototypes and exemplars; a moderate interference (fan effect) caused by stimulus similarity; and the missing of catastrophic interference even in AB/ABrdesigns.
 • For optimizing recall, association weights between configurations and category labels are computed taking all currently competing weights into account.
 Configurations of features are also used in the configuralcue model of Gluck and Bower (1988).
 In contrast to this model, l A K makes use of a probabilistic sampling process to select a small subset of configurations, thus avoiding a combinatory explosion of the number of configurations.
 The Model The lAKModel requires three layers: Input nodes, configuration nodes and output nodes.
 Input nodes represent the features of the stimulus.
 Their activation is either 1 (on) or 0 (off).
 During learning, input nodes are connected to configuration nodes.
 A configuration node gets an activation of 1 if all input nodes that are connected to the configuration node are on.
 Input nodes and configuration nodes exhibit an allornoneactivation characteristic.
 Output nodes represent categories for the classification tasks.
 Their activation values lie between 0 and 1.
 In classification tasks, stimuli are given that belong to different category names.
 Subjects have to classify old stimuli that have been presented during a prior learning phase and new stimuli.
 The classification depends on the involved stimuli and the degree of practice.
 There are two different ways for connectionist modeling of classification learning.
 In featurebased models associations between single features of the stimuli and features of category names are formed during learning (e.
g.
 Gluck & Bower, 1988; Estes et al.
 1989).
 O n the other side, exemplarbased models assume associations between representations of the whole stimulus and the category label, e.
g.
 A L C O V E (Kruschke, 1992) or the context model (Medin & Schaffer, 1978).
 These models explain a lot of empirical phenomena of category learning.
 The lAKModel (lAK: Information evaluation using configurations) lies between featurebased and exemplarbased models.
 The lAKModel exhibits two main properties: • Associations between small sets of stimulus features (configurations) and category labels are learned.
 .
̂  0<=4V<»1 : :   m Figure 1.
 Connections in the l A K model.
 The connection from input to configuration node is either existent or absent.
 The connection from configuration to output node has a weight between 0 and 1.
 Retrieval A n input pattern is activated and the system has to select a category represented by an output node by means of activation propagation from input nodes to output nodes.
 In classification tasks, the probability for selection of category m is: 293 mailto:heydemann@hrzl.
hrz.
thdarmstadt.
depim) = a m h (1) <a, is the activation of the ith output node corresponding to the ith category, r is the number of output nodes.
 The output activations are computed as follows: First, configuration nodes are switched on if every connected input node is on.
 A single inactive connected input node causes the configuration node to remain inactive.
 Second, the activation value a is computed for each output node: " r  t w J' i(i5r (15) \Ssum, (2) 1=1 Wji is the connection weight between the ith configuration node and the jth output node, j, is the strength of the configuration node i.
 Strength values increase during learning.
 6 and i are parameters of the lAK model.
 Ssum,i is computed by: Ssum, (3) keK,.
 K,, is the set of all configuration nodes connected to the output nodey that have connection weights to; greater than Wji lwji,>Wji for all fceK^,).
' The value of a lies between 0 and 1 because the strength values s are positive integers and the parameter values are limited to 0<6<1 and x>0.
 W 1 0.
5 0 nstlnpulforC) W y 5(18) i(l4f Figure 2.
 Illustration showing output node activation computing.
 The gray shaded area represents the activation ' If two or more active configuration nodes have the same weight to an output node then these nodes are treated as a single node with a summed strength value.
 value a.
 The maximum is 1.
 Each configuration node gets s columns; s is the strength of the configuration node.
 The configuration node with the maximum weight is placed in the first column, followed by the configuration node with the second biggest weight and so on.
 These complicated equations prevent many relatively small values of w from obscuring larger values.
 The computation of a is illustrated in Figure 2.
 Learning Learning requires two computational steps: 1.
 Sampling of input nodes and strengthening corresponding configuration nodes.
 2.
 Adjustment of weights from configuration nodes to output nodes.
 For the first step, subsets of the active input nodes are sampled with a probabilistic procedure.
 T w o parameters a and P control this process, a is the mean number of sets that are sampled in one learning trial and (3 influences the mean number of input nodes g in these sets.
 P is the linear slope for the probability gradient.
 The computation of P is illustrated in the following example.
 If there are 5 active input nodes Ii to I5 and a =1.
5 and P = 0.
2 then at least one subset is sampled and there is a probability of .
5 that a second subset is sampled.
 The probability that the subset consists of 1 element is p(g=l)=0.
533; p(g=2) = 0.
333; p(g=3) = 0.
133; p(g=4) = 0 and p(g=5) = 0.
 For instance, only one subset might be sampled with g = 2 and it might consist of I2 and L, N o w a configuration node is searched that has the connections to input nodes like the sampled subset.
 If a configurafion node exists, its strength is incremented by 1.
 If not, then an unused configuration node is chosen with strength s = 1 and connections to the input nodes of the subset.
 If an unused configuration node does not exist then the forgetting process takes place to provide a node (see section Forgetting of configuration nodes).
 In the second step, weights between all active configuration nodes and output nodes are adjusted.
 The weight Wji gives the portion in which the output nodey was a target in cases where the configuration node i was active.
 For instance, if configuration node /' was active at 20 learning trials and at 15 of these 20 trials output node7 was a target node then wy, = 0.
75.
 Forgetting of Configuration Nodes Forgetting of node connections is required in cases where the set of unused configuration nodes is exhausted and new ones are needed for learning.
 The following procedure is used repeatedly: A configuration node is randomly selected, and its strength is decremented by 1.
 Nodes with a strength of 0 are unassigned.
 Parameters and Extended Versions of the lAK Model This paper presents a reduced version of the lAK model.
 In the complete version during learning not only activating but also inhibiting connections from configuration nodes to output nodes are learned.
 These inhibitive links are rather selective and enhance the systems behavior in difficult 294 file:///Ssumdiscrimination tasks.
 Another extension deals with configuration nodes for output nodes.
 These configuration nodes are suitable for learning complex response patterns and are not used in classification tasks.
 In the reduced model reported here, only four parameters are used a.
 p, 5, and T, although others may be useful.
 For instance, a parameter is needed in Equation 1 to increase the activation values so that a medium value is not obsured by small ones.
 However, in the following simulations only qualitative results are reported and the parameters are kept at a minimum for better clarity of the model's mechanisms.
 Applications The Experiment of Shepard, Hovland, & Jenkins (1961) The task.
 The stimuli vary on three binary dimensions: size (large vs.
 small), shape (square vs.
 triangle), and color (filled vs.
 empty).
 Four of them are assigned to category A the other to category B.
 There are six structurally different types of category assignment (see Figure 3).
 <3 Type1 (D (E> Type Type ,® ® Type (B Type size Figure 3.
 One example for the six types of stimuli assignments to categories.
 Shepard et al.
 (1961; replicated by Nosofsky, Gluck, Palmeri, McKinley, & Glauthier, 1994).
 found the following ordering of difficulties in learning: Type 1 < Type 2 < (Type 3 to Type 5) < Type 6.
 The advantage of Type 2 compared to Types 3 to 5 is difficult to explain with connectionist models, unless the model has an explicit method to fade out irrelevant dimensions, e.
g.
 A L C O V E (Kruschke, 1992) or D A L R (Nosofsky, Gluck, Palmeri, McKinley, & Glauthier, 1994).
 Method of sunulation.
 The net consists of 2 output nodes representing categories A and B and 6 input nodes.
 Within one block each stimulus is presented twice in random order.
 Figure 4 shows the percentage of errors within each block from n = 400 simulations.
 The simulation replicates the ordering of type difficulties.
 Type6 — — Type4 Type3 Type2 Typel 0,15 •• 11.
12 Figure 4.
 M e a n error for 16 blocks of learning (Parameters: a = 5; [3 = 0; 5 = 0.
007; i = 5).
 Results.
 In accordance to previous empirical data (Shepard et al, 1961; Nosofsky, Gluck, Palmeri, McKinley, & Glauthier, 1994) there is no difference between linearly separable tasks (Type 4) to linearly non separable ones (Type 5).
 Also, an explicit mechanism of selective attention learning is not required by the l A K model to predict the advantage of Type 2 tasks compared to Type 3 to 5 tasks.
 The Experiment of Medin and Schaffer (1978) This experiment raises the question whether learning and generalization is based primarily on single features or alternatively on whole exemplars.
 If generalization is based on the sum of single featuretocategory associations, then the best classification should be found with the prototype stimulus for a category which consists of the features that are most typical for a category.
 A n alternative assumption is that generalization may be based on similarity to whole exemplars.
 In the experiment (exp.
 2 of Medin and Schaffer, 1978) subjects had to classify stimuli with four binary dimensions.
 Stimuli 1 to 5 are learned as category A, Stimuli 6 to 9 are learned as B, and the remaining seven stimuli are only tested.
 Method of simulation.
 For the simulation with the LAK model a net with eight input nodes and two output nodes is used.
 For each block of learning, the stimuli 1 to 9 are presented in random order.
 Table 1 compares the experimental results of the experiment of Medin and Schaffer (1978) with the results of the simulations after one (Sim: Ix) and four (Sim: 4 x) blocks of learning (Parameters: a=2; p=0; 5=0.
01; v=3).
 Results.
 Three values should be compared in detail.
 Stimulus 12 is never learned but it is the prototype of 295 Category A and is classified best in the experiment and in Table 2.
 Mean portion of errors (n=400 simulations; (X=l; the simulations.
 Stimulus 1 is more similar to the prototype P=0.
4; 6=0.
01; i=5).
 of A than Stimulus 2, but Stimulus I is classified worse than Stimulus 2 in the experiment, because Stimulus 1 is Test Old Prototype New highly similar to two stimuli (6 and 7) of the opposite Stimuli Category B.
 The simulation with the lAK model also 9 Learned Exemplars ̂^̂^̂  classifies Stimulus 1 worse than Stimulus 2.
 The Test 1 .
06 .
03 .
33 architecture of the lAK model enables both: generalization Test 2 .
23 .
12 .
41 based on features and based on the whole or parts of the 6 Uarned ExeinpTars Categor^ B ŵ 'ole Test'l '19 ^25 J3 Test 2 .
45 .
36 .
66 Table 1.
 Percentage of selection of category A 3 Learned Exemplars Catejgory C (mean values of « = 400 simulations).
 Test 1 24 78 93 Test 2 .
65 .
16 .
86 Especially in Category B, the interaction between forgetting rates of exemplars and prototypes is evident.
 As in the experimental results: The forgetting for prototypes is slower than for old exemplars.
 InterferenceEffects In the lAK model, as in other connectionist models, interference is caused by common features in stimuli from different categories.
 A simulation of the faneffect demonstrates this.
 Simulation.
 Ten stimuli are associated to ten different categories.
 Each stimulus is represented by two features, a specific one and one that is common to 1, 2, 3, or 4 other stimuli.
 This number is the degree of fan.
 Each category is represented by one specific feature.
One block consists of presentation of all stimuli in random sequence.
 T h e Interaction in Forgetting Rates for Exemplars and Prototypes One aspect of classification learning is the differential forgetting rate for exemplars and prototypes.
 In experiments (e.
g.
 H o m a et al.
 1973) subjects learned to classify dot patterns that are randomly distorted versions of a prototyf)e.
 They were tested with old exemplars from the learning phase, new unlearned exemplars and prototypes that were not shown during the learning phase.
 The main result was that forgetting is faster for exemplars than for prototypes.
 Method of simulation.
 Per block, 18 exemplars in random order, 9 of Category A, 6 of B and 3 of C are presented.
 Each exemplar consists of eight features: four are specific for the exemplar, two are randomly selected from the category prototype and the last two are randomly selected from each of the competing categories.
 After three blocks of learning, old and new exemplars and prototypes are tested (Test 1).
 Forgetting is caused by a reduction of the configuration node strength (see section on forgetting of configuration nodes, page 4).
 After a forgetting rate of 80 percent the stimuli are retested (Test 2).
 No.
 Values of Dimensions Category Exp.
 S »im: Ix Sim: 4x Learning Stimuli 1 2 3 4 5 6 7 8 9 1112 1212 1211 1121 2111 1122 2112 2221 2222 A A A A A B B B B .
78 .
88 .
81 .
88 .
81 .
16 .
16 .
12 .
03 .
78 .
86 .
91 .
79 .
79 .
38 .
37 .
22 .
12 .
85 .
91 .
96 .
83 .
84 .
34 .
34 .
15 .
06 Transfer Stimuli 10 11 12 13 14 15 16 1221 1222 1111 2212 2121 2211 2122 .
59 .
31 .
94 .
34 .
50 .
62 .
16 .
60 .
46 .
90 .
46 .
53 .
62 .
25 .
65 .
44 .
96 .
46 .
49 .
66 .
14 fan 4 fan 3 fan 1 Figure 5.
 Mean portion of errors after the 1st, 2nd, and 3rd block of learning.
 (m=400 simulations; a=0.
5; P=0.
3; 6=0.
0001; 1=3).
 Similar to empirical results, the main difference lies between degrees of fan from 1 to 2.
 Size of interference.
 The degree of interference in the lAK model is similar to interference found with people.
 There is no catastrophic interference, in contrast to other connectionist models (McCloskey and Cohen, 1989).
 The following simulation of an AB/ABr design demonstrates this.
 First, List 1 with ten stimulus response associations (a 296 k ^ ri; b k ̂  rj; c k * rs; d k * r̂  .
.
.
 f is learned, k denotes the feature for the first context.
 Second, permutated combinations with all associations altered (List 2) are learned in a new context m (e.
g.
.
 a m ^ r4; b m ^ r,, c m ^ rg.
.
.
).
 Test 1 is made after learning three blocks of List 1.
 Then follows learning of List 2 for three blocks and Test 2 is conducted.
 The simulation results in Table 3 show proactive and retroactive interference but no "catastrophic" interference.
 Table 3: Mean portion of correct responses («=400; ot=5; P=0.
2; 5=0.
01; v=3).
 Teststimuli of List 1 Teststimuli of List 2 Test 1 Test 2 .
94 .
75 .
00 .
84 Discussion This paper presents a reduced version of the lAK model.
 The model's powerful learning mechanism is nevertheless evident and applicable to more than classification tasks.
 This version of the lAK model demonstrates the following main learning mechanisms: • Input features are sampled in an allornone manner and stored as configurations.
 • Connection weights between configuration and output nodes are adjusted gradually.
 • Specific (multifeature) and unspecific (singlefeature) information is stored.
 • The probabilistic sampling process avoids unfulfillable storage requirements .
 • Weights from configuration nodes that are valid indicators for retrieval are enhanced.
 These principles are basis for the following properties: 1.
 Realistic, humanlike results of learning are achieved after a few presentations of the learning material.
 2.
 Difficult discrimination learning is possible.
 Interference is moderate but not catastrophic, even in AB/AB,transfer designs.
 Specific configuration nodes are responsible for good discrimination.
 3.
 At the same time the system exhibits favorable generalization properties.
 If specific information is applicable, then it is used and the unspecific information is fadedout to prevent specific information from blurring.
 But, if there is no specific information, then unspecific information is increased in value providing a good generalization.
 There are some structural similarities between the lAK model and R U L E X (Nosofsky, Palmeri, & McKinley, 1994).
 Both models learn in a probabilistic way.
 Rules in R U L E X may be compared to the binding of configurations to categories in lAK.
 In R U L E X , it is easier to form simple rules with one feature than rules with two or more features (complicated rules and exceptions).
 This is the same in the lAK model, especially if the parameter (3 is negative.
 But there is one main difference between the models: In the lAK model a connection weight from a configuration to a category is kept even if inconsistent examples are encountered.
 However, inconsistent examples reduce the connection weight considerable.
 Thus, in lAK a configuration is only partially discarded.
 In R U L E X , rules are discarded completely.
 Acknowledgements This research is supported by the Deutsche Forschungsgemeinschaft (Grant Schm 350/4).
 References Estes, W.
K.
, Campbell, J.
A.
, Hatsopoulos, N.
, & Hurwitz, J.
B.
 (1989).
 Baserate effects in category learning: A comparison of parallel network and memory storageretrieval models.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 15, 556576.
 Gluck, M .
 & Bower, G.
 (1988).
 Evaluation an adapfive network model of human learning.
 Journal of Memory and Language, 27, 166195.
 Homa, D.
, Cross, J.
, Cornell, D.
, Goldman, D.
, & Shwartz, S.
 (1973).
 Prototype abstraction and classification of new instances as a function of number of instances defining the prototype.
 Journal of Experimental Psychology, 101, 116122.
 Kruschke, J.
 (1992).
 A L C O V E : A n exemplarbased connectionist model of category learning.
 Psychological Review.
 97, 225252.
 McCloskey, M .
 & N.
J.
 Cohen (1989).
 Catastrophic interference in connectionist networks: The sequential learning problem.
 In G.
H.
 Bower (Ed.
; The Psychology of Learning and Motivation (Vol.
 24, pp.
 109165).
 N e w York: Academic Press.
 Medin, D.
L.
 & Schaffer, M .
 M .
 (1978).
 Context theory of classification learning.
 Psychological Review, 85, 207238.
 Nosofsky, R.
M.
, Gluck, M.
A.
, Palmeri, T.
J.
, McKinley, S.
C, & Glauthier, P.
 (1994).
 Comparing models of rulebased classification learning: A replication and extension of Shepard, Hovland, and Jenkins (1961).
 Memory & Cognition.
 22, 352369.
 Nosofsky, R.
M.
, Palmeri, T.
J.
, & McKinley, S.
C.
 (1994).
 Ruleplusexception model of classification learning.
 Psychological Review, 101, 5379.
 Shepard, R.
N.
, Hovland, C.
L.
, & Jenkins, H.
M.
 (1961).
 Learning and memorization of classificaUons.
 Psychological Monographs, 75 (13, Whole No.
 517).
 a k —> ri denotes two input nodes a and k that are associated to the category node fi.
 297 Implicit Learning in the Presence of Multiple C u e s Axel Cleeremans* Laboratoire de Psychologic Industrielle et Commerciale Universit6 Libre de Bruxelles Avenue F.
D.
 Roosevelt, 50 — CP 122 1050 Bruxelles —BELGIUM axcleer@ulb.
ac.
be Abstract Is implicit learning an independent and automatic process? In this paper, ! attempt to answer this question by exploring whether implicit learning occurs even despite the availability of more reliable explicit information about the material to be learnt.
 I report on a series of experiments during which subjects performed a sequential choice reaction task.
 On each trial subjects were exposed to a stimulus and to a cue of varymg validity which, when valid, indicated where the next stimulus would appear.
 Subjects could therefore optimize their performance either by implicitly encoding the sequential constraints contained in the material or by explicitly relying on the information conveyed by the cue.
 Some theories predict that implicit learning does not rely on the same processing resources as involved in explicit learning.
 Such theories would thus predict that sensitivity to sequential constraints should not be aftectcd by the presence of reliable explicit information about sequence structure.
 Other theories, by contrast, would predict that implicit learning would not occur in such cases.
 The results suggest that the former theories arc correct.
 I also describe preliminary simulation work meant to enable the implications of these contrasting theories to be explored.
 Introduction Implicit learning; is typically defined as the process whereby subjects appear capable of acquiring new information without concomitant awareness of what is being learnt.
 Even though this definition is currently very controversial (e.
g.
, Rcbcr.
 1994: Shanks & StJohn, 1994).
 there is now a large body of evidence suggesting that improvements in performance at a given task arc not systematically accompanied by similar improvements in subjccts"s ability to express or use the acquired knowledge in an explicit way.
 For instance.
 Artificial G r a m m a r Learning studies have shown that subjects can classify strings of letters as grammatical or not after practice at memorizing similar strings, and without being able to report on the rules that define granmiaticality (e.
g.
, sec Dicncs & Berry.
 1994, for a review).
 Sequence learning studies, on which this paper will focus, have demonstrated that subjects can become sensitive to the regularities contained in sequences of stimuli presented in a choice reaction selling despite remaining unable to report on the sequence or to perform well in other direct tests such as generation, where subjects arc asked to predict the next *Tho author is ;i Research Associate of the National Fund lor Scieniilic Research (Belgium).
 stimulus instead of reacting to the current one (e.
g.
, Cleeremans, 1993a; Nissen & Bullemer, 1987).
 Implicit learning is assumed to have a number of features that distinguish it from explicit learning.
 However, because the existence and nature of implicit learning is controversial, there is currently no agreement in the field about which features have been empirically established.
 For instance, some authors claim that implicit learning is an unconscious process that can result in abstract knowledge (e.
g.
, Reber, 1994).
 For others, however, implicit learning is essentially explicit exemplarbased learning (e.
g.
.
 Shanks & StJohn, 1994).
 These issues have been extensively explored empirically and I believe that it is fair to say that they remain largely unsolved at this point.
 In this paper I would like to focus on a assumption that often underpins the others but that has seldom been addressed directly, that is, that implicit learning is an independent and automatic process.
 Three positions about this issue have been expressed in the implicit learning literature.
 First, some authors (e.
g.
, Perruchet & Amorim, 1992) argue that performance in implicit learning tasks does not necessarily reflect the operation of an independent implicit learning system.
 Rather, performance would be mostly based on explicit processing, but the resulting knowledge is fragmented enough that verbal reports probing for general information are unlikely to reveal the extent of subjects' knowledge.
 Other authors (e.
g.
, Knowlton, R a m u s & Squire, 1992) assume that implicit and explicit learning are supported by different memory systems, and that these systems are completely independent from each other.
 Implicit and explicit learning would thus proceed in parallel, and without interacting.
 They produce different kinds of knowledge, and are most likely to operate efficiently in contrasted settings.
 Finally, there may be an intermediate position where one assumes that implicit and explicit processing indeed rely on distinct memory systems, but in which some interactions between the two systems are allowed, and in which some processing resources are shared (e.
g.
, Cleeremans.
 1993b).
 Typically, these issues have been approached by placing subjects in dual task settings.
 For instance, Keele and his collaborators (e.
g.
, Curran & Keele, 1992) used sequential reaction time (SRT) tasks coupled with a secondary tonecounting task.
 The rationale of these experiments was to determine whether learning of the sequential structure of the stimulus material can still occur despite attentional resources being recruited by the secondary task.
 In other experiments Curran & Kccle also manipulated subject's explicit knowledge by letting them study the sequence beforehand.
 298 mailto:axcleer@ulb.
ac.
beIn general, the results of these and other studies have shown that the availability of explicit knowledge results in belter performance under single task conditions, but that the presence of a secondary task results in ail subjects performing at the same level regardless of whether or no they possess explicit knowledge.
 This kind of result has often been interpreted as yielding support to the notions (I) that sequence learning involves both explicit and implicit learning, and (2) that implicit learning relies on mechanisms that are independent from shortterm memory and from the availability of attentional resources, both of which are crucially important for explicit learning to occur.
 This methodology has a number of problems, however.
 First, it is difficult to assess how much attentional capacity the secondary task requires.
 For instance, the difficulty of keeping track of how many tones of a particular kind have been presented so far may vary with the number of tones presented.
 This problem makes it hard to draw strong inferences about the relative independence of the processes responsible for learning the sequential structure.
 Second, it is hard to determine how much explicit knowledge subjects possess and actually use during the task.
 In this paper, inspired by work on overshadowing in conditioning experiments with animals (e.
g.
, Matzel, Schachtman & Miller, 1985), I report on a different way to address this issue.
 Instead of placing subjects in a dualtask setting.
 I placed them in a dualstimulus setting where on each trial, two sources of information are available to compute the response: the sequential context set by previous elements of the sequence on the one hand, and a cue indicating where the next stimulus will appear on the other hand.
 Hence, on each trial subjects can rely on either or both the temporal context and the information conveyed by the cue lo prepare for the next event.
 D o subjects learn about both dimensions or is learning of one dimension blocked by learning of the other? If implicit learning truly is an automatic process that relies on independent processing and memory systems, then one should expect to obtain such learning even in conditions where more reliable and fully explicit sources of information about the relevant material are available.
 In the following.
 I first describe experimental work that implements the design outlined above.
 Next, I report on preliminary simulation work that illustrates how one can explore these issues within the connectionist framework.
 Experimental Design Method The experiment consisted of three conditions.
 Each consisted of 10 training sessions during which subjects were exposed to a sixchoice S R T task.
 Each .
session consisted of 20 blocks of 150 trials each, for a total of 30,000 trials.
 After training all subjects were exposed to 3 blcKks of a generation task in which they were asked to predict the location at which the next stimulus would appear.
 O n each trial of the S R T task, a stimulus could appear at one of six positions arranged horizontally on a computer screen, and subjects were to press as fast and as accurately as possible on the key corresponding to the current location of the stimulus.
 Subjects were kept unaware that the material was structured sequentially.
 The sequential structure of the material was manipulated by generating the sequence based on a noisy finitestate grammar, as described below.
 In cued blocks, a cue consisting of a cross under one of the six stimulus positions appeared concurrently with the stimulus.
 This cue could either be valid or invalid.
 If valid, it indicated the location at which the next stimulus in the sequence would appear.
 During generation, the same stimulus material was presented, but subjects were instructed to try to predict the next stimulus instead of merely reacting to the current one.
 N o explicit feedback was provided during generation performance to minimize withingeneration learning.
 In the L o w Validity (LV) condition, each session consisted of 2700 cued trials followed by 300 neutral trials.
 Cue validity was set at 2 0 % .
 In the High Validity (HV) condition, the same design was used but cue validity was considerably higher (80%).
 The third condition (100% validity, or HVIOO) followed a somewhat different design: Each of the first 9 sessions consisted of 3(X)0 trials for which cue validity was 100%, and the final session consisted exclusively of 3000 neutral trials.
 Subjects Six subjects participated in each of the three experiments.
 Subjects were paid about $65 for participating in the experiment, and could earn an additional bonus of $34 to $62 based on performance in the S R T task.
 Apparatus and Display The experiment was run on Macintosh computers.
 The display consisted of six dots arranged in a horizontal line on the computer's screen and separated by intervals of 3 cm.
 Each screen position corresponded to a key on the computer's keyboard.
 The spatial configuration of the keys was fully compatible with the screen positions.
 The stimulus was a small black circle 0.
35 c m high that appeared on a white screen background, centered I cm below one of the six dots.
 The cue was a small cross (X) appearing at the same locations as the stimuli.
 The RSI was 120 msec.
 Stimulus and cue generation Stimuli were generated based on the noisy finitestate grammar illustrated in Figure I, with a small proportion of random stimuli (20%) interspersed with those derived from the grammar.
 Learning is assessed by comparing performance on stimuli that follow the rules of the grammar versus random stimuli.
 A total of 30,000 trials were presented to each subject.
 O n each trial, stimulus generation proceeded in three phases.
 First, an arc coming out of the current node was randomly selected, and its label recorded.
 The current node was set to be #0 on the first trial of any block, and was updated on each trial to be the node pointed to by the selected arc.
 Second, there was a 2 0 % chance of substituting a randomly selected label to the recorded one (identity substitutions, as well as any substitution that would result in a stimulus being repeated or legal at the current 299 Figure 1: Finitestate grammar (from Jimenez & Cleeremans, 1994) used to generate tiie stimulus material.
 Note that the first and last nodes are one and the same.
 node, were not allowed).
 Third, the label was used to determine the screen position at which the stimulus would appear by following a 6 x 6 Latin square design, so that each label corresponded to each screen position for exactly one of the six subjects in each condition.
 Note that each label appears twice in the grammar and may be followed by different successors on different occurrences.
 Maximally reducing the uncertainty associated with each label requires encoding up to three elements of temporal context.
 Cue generation proceeded independently.
 O n each trial, a cue corresponding to the next stimulus was generated.
 This vaHd cue could be presented on all trials of a given session (first 9 sessions of the H V l O O condition), suppressed entirely (neutral blocks or sessions) or be replaced by an invalid cue in either 2 0 % ( H V condition) or 8 0 % (LV condition) of the trials.
 Substitution consisted of selecting a random location for the cue to appear at, with the constraints that this location could be neither the location of the current stimulus location nor that of the next one.
 T o summarize, this generation procedure results in six types of trials defined by crossing the Grammaticality (Grammatical or NonGrammatical) and Cue Validity (Valid, Invalid, or Neutral) factors.
 A particular trial was thus categorized as "valid" if the location at which the stimulus had appeared on that trial had indeed been validly primed by the cue that had appeared on the previous trial.
 Similarly, a given trial was categorized as "grammatical" if the stimulus that had appeared on that trial was consistent with the generation rules expressed by the finitestate grammar.
 Finally, note that the sequence generation procedure makes it impossible for any stimulus to be involved in a direct repetition of itself.
 This guarantees that R T effects are not contaminated by shortterm priming effects, which have large facilitatory effects on performance that are completely independent from the factors of interest in this research.
 Results and Discussion Figure 2 represents average RTs over the 10 sessions of training and for each trial type, in the L V (left panel), H V (middle panel) and H V l O O (right panel; note the scale difference) conditions.
 Consider first the data for the H V condition (middle panel).
 It is obvious that cue validity has a large effect on performance, as RTs elicited by valid trials are considerably faster than those elicited by both neutral and invalid trials.
 This pattern of results indicates that subjects are indeed using the cue to anticipate the location at which the next event will appear and to specifically prepare their response accordingly.
 Despite the massive impact of cue validity, small effects of grammaticality are also present at all levels of cue validity, and seem to have approximately the same magnitude in each case.
 These impressions were confirmed by an A N O V A with Practice (10 levels) X Validity (Valid, Invalid or Neutral) X Grammaticality (Grammatical vs.
 NonGrammatical) as factors and R T as dependent variable.
 The analysis yielded significant main effects of Practice [F(9, 45) = 27.
389, p < .
001, M S e = 64494.
037], of Cue Validity [F(2, 10) = 162.
385, p < .
001, M S e = 1849184.
178], and of Grammaficality [F(l, 5) =39.
685, p < .
01, M S e = 29322.
225], as well as a significant interaction between Practice and Cue Validity [F(18, 90) = 8.
680, p < .
001, M S e = 7443.
181].
 There was no significant interaction between Cue Validity and Grammaticality (p > .
05).
 Overall, these results suggest that sensitivity to sequential structure was not blocked by the presence of the cue, despite the facts that subjects (1) demonstrably use the cue, and (2) that the cue conveys considerably more reliable information about the next event than the sequential structure does.
 Unsurprisingly, cue validity has a much smaller impact on performance in the L V condition (left panel): Valid, invalid and neutral trials elicit similar RTs over training (with the exception of neutral trials in the first session, see below).
 Grammadcal trials at all levels of cue validity, however, elicit faster RTs than nongrammatical trials, just as in the H V condition.
 Thus, subjects do not appear to use the unreliable cue in the L V condition, relying instead on the sequential structure to optimize their performance at the task.
 This analysis was again confirmed by an A N O V A , which produced significant main effects of Practice [F(9, 45) = 54.
328, p < .
001, M S e = 157235.
027] and of Grammaticality [F(l, 5) = 17.
987, p < .
01, M S e = 123839.
803].
 Surprisingly, Cue Validity was also significant [F(2, 10) = 26.
799, p < .
001, M S e = 14187.
900] and interacted with Practice [F(18, 90) = 5.
098, p < .
001, M S e = 3479.
17].
 Closer examination of the figure reveals that these effects are in fact artifactual.
 Indeed, the neutral trials presented during the first session elicit much faster RTs than either valid or invalid trials.
 However, this is merely a result of the fact that these trials were presented at the end of the first session.
 Hence they benefit from previous unspecific training on the other trials during the first session.
 This artifact is absent from the subsequent sessions, and analyses that exclude the first session produce non significant effects of Cue Validity.
 Finally, in contrast with the H V data, the A N O V A also revealed a significant interaction between Grammaticality and Practice [F(9, 45) = 3.
311, p < .
01, M S e = 601.
642].
 A further A N O V A on the data from both conditions revealed significant main effects of Practice [F(9, 90) = 80.
780, p < .
001, M S e = 210466.
871], of Cue Validity [F(2, 300 BOO 700 600 500 400 300 200 R«ic1ion TirTM •g 1 2 ^ * K S 3 4 ^ 5 6 Session 20°/o validity ^ ^ — » ^ = • 4 : ^ 7 8 9 10 RMCtlon Tim* 80% validity 200 •^=«=t::*=i RmcUoo Tlnt> 2 3 4 5 6 7 Session 9 10 100% validity 200 100 2 3 4 5 6 7 8 9 10 Session Figure 2: Reaction times for the L o w Validity (left panel), High Validity (middle panel) and 1 0 0 % Validity (right panel) conditions.
 R T s are represented separately for valid (squares), invalid (circles), and neutral (triangles) cues, as well as for grammatical (filled symbols) and nongrammatical (open symbols) trials.
 20) =155.
355, p < .
001, M S e = 925690.
239], and of Grammaticality [F(l, 10) = 35.
898, p < .
001, M S e = 136840.
939].
 Condition failed to reach significance.
 Cue validity interacted significantly with Condition [F(2, 20) = 157.
367, p < .
001, M S e = 937681.
239], but not Grammaticality (p  .
0654).
 To summarize these data, subjects appear to remain sensitive to the sequential structure even when a far more reliable source of information is available to anticipate the next event.
 Recall that in the H V condition, the cue will reliably predict the next event in 8 0 % of the cases.
 By contrast, a simple examination of the F S A illustrated in Figure 2 shows that even full knowledge of a deterministic version of the grammar would only allow for about 5 0 % of the trials to be correctly anticipated, as most nodes have two equiprobable outgoing arcs.
 The fact that neutral trials were interspersed throughout training makes strong inferences difficult, however.
 It remains possible that these trials provided enough training for subjects to learning about the sequential structure of the material.
 To test this hypothesis, a further condition was run in which subjects were exposed exclusively to valid cued trials throughout the first 9 sessions, and subsequently transferred R«actlon Tim« 460 450 440 430 • 420 LV HV Condition HV100 Figure 3: Reaction times for grammatical (filled symbols) and ungrammatical (open symbols) neutral trials presented during the last session of each the three conditions (LV: L o w validity; H V : High Validity; HVlOO: 1 0 0 % vahdity).
 to a final session consisting exclusively of neutral trials.
 The corresponding data are presented in the rightmost panel of Figure 2.
 One can see that even though grammatical and ungrammatical trials fail to elicit different R T s throughout training, a significant difference of 23 msec [Onetailed t(4) = 2.
79, p < 0.
1] reappears in the last session.
 To determine whether this difference could be attributed to learning within the last session, I conducted this analysis again but restricted it to the first 300 trials of this session.
 The difference between grammatical and ungrammatical trials now averaged 30.
2 msec and was significant [Onetailed t(4) = 4.
371, p < 0.
1].
 This suggests that subjects did acquire knowledge about the sequential structure of the material during training but were unable to express it because of the presence of the cue.
 Finally, Figure 3 represents reaction times to grammatical and ungrammatical neutral trials during the last sessions of all three conditions.
 The figure shows that these differences tend to be very similar in all three conditions.
 A n A N O V A conducted on these data confirmed this impression, with a significant main effect of Grammaticality [F(l, 15)  45.
844, p < .
001, M S e = 2976.
250] and no interaction between Grammaticality and Condition (p  0.
57).
 Overall then, subjects appear to learn about the sequential structure of the material regardless of the validity of the cue.
 Space limitations prevent a full treatment of the generation task data, but subjects were consistently unable to better predict grammatical elements over ungrammatical elements.
 This indicates that whatever knowledge was acquired over training with the R T task was of limited use in helping subjects produce explicit prediction responses.
 Simulation Results What kind of mechanism may account for these data? A natural starting point is the Simple Recurrent Network (SRN) model first proposed by Elman (1990), and shown in Figure 4 (inside the frame).
 The task of this backpropagation network is to predict the next element of a sequence based on the current element and on a representation of the temporal context that the network has elaborated itself Over training, the network's responses come to approximate the optimal conditional probabilities associated with each successor to 301 the current context, and can thus be interpreted as representing preparation for the next event.
 Previous work (see Cleeremans & McClelland, 1991; Cleeremans, 1993a, for detailed analysis ot both processing in such networks and SRN (next element) :( SRN CONTEXT )—•( HIDDEN UNITS ) ( HIDDEN UNITS j (current element) ( CUE ) Figure 4: The simple recurrent network (framed) augmented with an additional pathway to process cue information.
 correspondence with human data) has shown that the SRN is able to account for about 8 0 % of the variance in S R T data.
 To model performance in the experiments described above it is necessary to augment the S R N architecture with mechanisms that enable it to process the information conveyed by the cue.
 There are several different ways of doing this according to which assumptions one has about the way in which learning about the cue and learning about the sequential structure of the material interact.
 First, one may assume that processing of the cue is fully independent from processing of the sequential structure.
 Thus, learning proceeds independently in each processing pathway, just as if two separate networks were trained independently, and information conveyed by each pathway is only combined at response time.
 Second, one may assume that learning of one dimension interacts with learning of the other dimension.
 This is the case in backpropagation architectures where both pathways feed into a single output module.
 Indeed, in such arhitectures, the pathway that transmits more information will tend to develop larger connection weights and exert an increasingly larger influence on performance, at the expense of the other pathway.
 The network represented in Figure 4 is an instance of this 0.
9 07 06 05 1 .
 Luce Ratio 2 0 % validity 05 latter class of models: The S R N is simply augmented with an additional processing pathway consisting of input units to represent the cue.
 These units feed into a set of hidden units which are in turn connected with the output units.
 T o assess h o w well this kind of network w a s able to account for S R T performance in this experiment, I conducted simulations in which the model was trained on the same material as h u m a n subjects and for the same number of trials, with the parameters used by Cleeremans and McClelland (1991).
 The network used local representations on both the input and output pools (i.
e.
, each unit corresponded to one of the 6 stimuli or cues).
 T o account for shortterm priming effects, the network used dual connection weights and running average activations on the output units, as described in Cleeremans and McClelland (1991).
 T h e network w a s trained to predict each element of a continuous sequence of stimuli generated in exactly the same conditions as for h u m a n subjects.
 O n each step, both a label and a cue were generated as described before and presented to the network by setting the activation of the corresponding input units to 1.
0.
 Activation was then allowed to spread to the other units of the network, and the error between its response and the actual successor of the current stimulus was then used to modify the weights.
 During training, the running average activation of each output unit was recorded on every trial and transformed into Luce ratios (Luce, 1963) to normalize the responses.
 For the purpose of comparing the model's and the subject's responses, I assumed (1) that the normalized running average activations of the output units represent response tendencies, and (2) that there is a linear reduction in R T proportional to the relative strength of the unit corresponding to the correct response.
 T h e network's responses were subtracted from 1.
0 to m a k e increases in response strength compatible with reduction in R T .
 The resulting data are shown in Figures 5 and 6.
 O n e can see that the model's performance approximates h u m a n performance quite well, at least qualitatively.
 Indeed, just as h u m a n subjects, the model appears to be sensitive to the sequential structure of the material at all levels of cue validity in all three conditions.
 T h e relative size of the differences between performance on neutral trials during the last session of each of the three conditions is also well preserved in the simulations (Figure 6).
 80% validity \'^«— 1  Luc* Ratio 1 0 0 % validity i 04 3 4 5 6 7 Session 3 4 5 6 7 Session 9 10 4 5 6 7 Session 9 10 Figure 5: Simulated S R N responses (see text for details) for the L o w Validity (left panel).
 High Validity (middle panel) and 1 0 0 % Validity (right panel) conditions.
 Responses are represented separately for valid (squares), invalid (circles), and neutral (triangles) cues, as well as for grammatical (filled symbols) and nongrammatical (open symbols) trials.
 302 0.
90 088 086 • 084 0 82 080 1  Luc< Ratio Condition HVlOO Figure 6: Simulated S R N responses (see text for details) for grammatical (filled symbols) and ungrammatical (open symbols) neutral trials presented during the last session of each the three conditions (LV: Low validity; HV: High Validity; HVlOO: 100% validity).
 Note however that there are also discrepancies.
 In particular, the model fails to account for unspecific practice effects, that is, changes in reaction times that do not result specifically from the presence of sequential structure.
 This is a flaw shared by previous versions of the S R N model, but one that is not crucial to the arguments develoved in this paper.
 Work in progress is aimed at contrasting these results with those produced by architectures in which the two processing pathways are trained completely independently.
 Conclusion In this paper I presented three experiments aimed at exploring to what extent implicit learning of sequential structure in R T tasks proceeds independently of the availability of explicit knowledge about the stimulus material.
 By contrast to standard dualtask procedures that have been used in the past to explore this issue, I used a dualstimulus setting where on each trial, subjects were exposed to both the current stimulus and to a cue of varying validity that indicated where the next stimulus would appear.
 The results indicated that even in conditions where the cue was a much better source of information about the next event, subjects still seemed to be sensitive to the sequential structure of the material.
 Hence acquisition of sequential structure can proceed even in conditions where vastly superior and fully explicit sources of information about relevant task information are available.
 However, simulation work using a model based on the Simple Recurrent Network indicated that these results also obtain in architectures where the two processing pathways (sequential structure —• next event, and cue • next event) are not fully independent.
 This suggests that preserved learning along one dimension does not necessarily entail that the underlying structures are themselves fully independent.
 Further empirical research and modeling work is needed to increase our understanding of the relationship between performance and underlying processing modules, but the empirical data clearly suggest that implicit learning of sequential structure is a resilient process that is little sensitive to the availability of other, more reliable, and fully explicit sources of information about the stimulus material.
 Acknowledgments The author is a Research Associate of the National Fund for Scientific Research.
 I thank MarieCatherine Navarre and Arnaud Destrebecqz for help in data collection and an anonymous reviewer for valuable comments.
 References Cleeremans, A.
 (1993a).
 Mechanisms of implicit learning: connectionist models of sequence processing.
 Cambridge, M A : M IT Press.
 Cleeremans, A.
 (1993b).
 Attention and awareness in sequence learning.
 In Proceedings of the Fiftheenth Annual Conference of the Cognitive Science Society (pp.
 330335).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Cleeremans, A.
 & McClelland, J.
L.
 (1991).
 Learning the structure of event sequences.
 Journal of Experimental Psychology: General, 120, 235253.
 Curran, T.
 & Keele, S.
W.
 (1992).
 Attentional and nonattentional forms of sequence learning.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 19, 189202.
 Dienes, Z.
 & Berry, D.
 (1994).
 Implicit learning: Theoretical and empirical issues.
 Hove, England: Lawrence Erlbaum Associates.
 Elman, J.
L.
 (1990).
 Finding structure in time.
 Cognitive Science, U, 179211.
 Jimenez, L.
, & Cleeremans, A.
 Direct and indirect measures of sequence learning.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp.
 445450).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Knowlton, B.
J.
, Ramus, S.
J.
 & Squire, L.
 (1992).
 Intact artificial grammar learning in amnesia: Dissociation of classification learning and explicit memory for specific instances.
 Psychological Science, 3, 172177.
 Luce, R.
D.
 (1963).
 Detection and recognition.
 In R.
D.
 Luce, R.
R.
 Bush & E.
 Galanter (Eds.
), Handbook of mathematical psychology (vol.
 1).
 N e w York: Wiley.
 Matzel, L.
D.
, Schachtman, T.
D.
 & Miller, R.
R.
 (1985).
 Recovery of an overshadowed association by extinction of the overshadowed stimulus.
 Learning and Motivation, 16,398412.
 Nissen, M.
J.
 & Bullemer, P.
 (1987).
 Attentional requirements of learning: Evidence from performance measures.
 Cognitive Psychology, 19, 132.
 Perruchet, P.
 & Amorim, P.
A.
 (1992).
 Conscious knowledge and changes in performance in sequence learning: evidence against dissociation.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 18, 785800.
 Shanks, D.
R.
, & St.
 John, M.
F.
 (1994).
 Characteristics of dissociable human learning systems.
 Behavioral and Brain Sciences, 17, 367395.
.
 Reber, A.
S.
 (1994).
 Implicit learning and tacit knowledge: An essay on the cognitive unconscious.
 Oxford, England: Ox f o r d University Press.
 303 Training R e g i m e n s and Function Compatibility: Implications for Understanding the Effects of K n o w l e d g e on Concept Learning Sheldon J.
 Tetewsky Thomas R.
 Shultz Yoshio Takane Department of Psychology McGill University Montreal, Quebec H 3 A IBl t e t e w s k y d e g o .
 p s y c h .
 m c g i 1 1 .
 c a s h u l t z Q p s y c h .
 m c g i l l .
 c a takane(3takane2 .
 p s y c h .
 m c g i ll .
ca Abstract Previous research has indicated that breaking a task into subtasks can both facilitate and interfere with learning in neural networks.
 Although these results appear to be contradictory, they actually reflect some underlying pnnciples governing learning in neural networks.
 Using the cascadecorrelation learning algorithm, we devised a concept learning task that would let us specify the conditions under which subtasking would facilitate or interfere with learning.
 The results indicated that subtasking facilitated learning when the initial subtask involved learning a function compatible with that characterizing the rest of the task, and inhibited learning when the initial subtask involved a function incompatible with the rest of the task.
 These results were then discussed with regard to their implications for understanding the effect of knowledge on concept learning.
 Introduction One of the most effective ways to improve learning in neural networks is to structure the way the training patterns are presented.
 Rather than including all of the patterns in each training epoch, learning is often faster and more efficient when training patterns are divided into subsets representing different parts of the overall task.
 In recent years, the use of structured training regimens has assumed two complementary forms.
 Performance on a complex task can be improved by first training separate networks to do different parts of the task, and then combining the various subnetworks to produce a structure that can do the entire task (Pratt, Mostow, & K a m m , 1991; Waibel, Sawai, & Shikano,1989).
 Alternatively, complex problems can be learned more quickly if a network's training set is divided mto a series of increasingly difficult subtasks that are learned sequentially (Cottrell & Tsung, 1993; Ehnan, 1989, 1991a; Fahlman, 1991).
 Moreover, the effect of subtasking can even be accomplished with a constant training set, provided that the processing capacity of a network is increased during the course of learning (Elman, 1991b).
 In contrast to these findings, however, there is also evidence that not all problems are learned better when they are broken d o w n into smaller parts.
 Incrementally inaeasing the size of the training set in an eightbit parity problem does not improve learning, and it may even make it more difficult (Harris, 1991).
 There is also evidence that networks can learn a given task better when they learn simultaneously several related tasks (Caruana, 1992).
 Although these two sets of findings appear to be contradictory because they show that training with subtasking both facilitates and interferes with learning, Ehnan (1993) has argued that such effects actually illustrate some fundamental properties about how learning occurs in connectionist models.
 Neural networks are commonly viewed as function approximators that are trying to discover the function that underlies a given set of training patterns.
 Because learning algorithms are statistically driven, they are highly sensitive to statistics of the training set.
 Given these assumptions, Elman argued that one of the main reasons that learning is difficult is that a particular set of training patterns often has a number of different regularities, and it is not always clear which regularity a network will extract.
 By reducing the size of tlie training set, a training regimen that uses subtasking can make it easier to identify some of the regularites in the data, and so learning might be faster.
 However, a reduced training set can also cause problems because when statistics are computed on subsets of a total set of patterns, there is a danger that they may not provide a good estimate of the population statistics.
 In this case, when the size of the pattern set is inaeased, regularities that appeared in the smaller pattern sets may no longer apply, resulting in interference.
 (For related ideas, see Harris, 1991, p.
 1516; Rosenberg and Sejnowski, 1986, p.
 8485).
 Although Elman (1993) was able to explain how subtasking can both facilitate and interfere with learning, he did not provide any criteria for predicting which effect will occur on a particular task.
 For example, it is not clear why subtasking improved performance on Ehnan's (1991b) task, but failed to improve learning on Harris' (1991) task.
 In addition, it is useful to note that the simulations (Elman, 1991b) used to develop these ideas are somewhat artificial because they cannot be related to a specific psychological task.
 In spite of the fact that they were intended to model the kind of learning that occurs in language acquisition, each training set contained 10,0(X) sentences, which far exceeds the processing capacity of an adult or a child.
 Moreover, the network's task was to predict the next word in a sentence, something that would not ordinarily absorb human listeners.
 304 Given these considerations, w e decided to use a simpler and more psychologically plausible task to identify some principles that can predict how different tasks are learned under different training regimens.
 Analyzing Training Regimens in a Concept L e a r n i n g T a s k Because neural nets learn to approximate functions, w e hypothesized that the opposing effects associated with subtasking can be understood in terms of function compatibility.
 If the function learned on an early task is compatible with the function to be learned later, the new learning will be facilitated.
 In contrast, if the function learned on an early task is incompatible with the function to be learned later, the new learning wUl be inhibited.
 To test this hypothesis, w e used a concept learning task originally developed by Whitman and G a m e r (1963).
 Although the experiments they carried out were motivated by a very different set of research questions, the specific stimuli that they used provided a straightforward way of analyzing h o w function compatibility is manifested in differemt training regimens.
 The training patterns that w e used in our simulations are diagranmied in Table 1, which is adapted from a set of visual stimuli shown in Gamer (1974, p.
 83).
 Each pattern was comprised of four binary dimensions, and the total set of sixteen pattems was used to define two different classification tasks.
 In each task, patterns 18 were the positive instances of the category and pattems 916 were the negative instances of the category.
 AlUiough both classification tasks used each of the sixteen pattems once, they differed with regard to the statistical relations between the component dimensions.
 The task on the left has a simple correlational stmcture because the two categories of pattems can be distinguished from each other with regard to the correlation between dimensions one and four.
 In category S the values on these dimensions always disagree, whereas in category ~S the values on these dimensions always agree.
 In contrast, the task on the right has a complex correlational structure because there is no overall relationship between any of the four dimensions in either category C or category ~C.
 Table 1 also illustrates that each task can be divided into two distinct subtasks, as shown by the dotted line.
 In the first subtask, pattems 14 were positive instances of the category and pattems 912 were negative instances of the category.
 In the second subtask, pattems 58 were positive instances of the category and pattems 1316 were negative instances of the category.
 An examination of the statistical relations in each subtask suggests that the relative difficulty of learning each concept may change when the pattems are presented in terms of subtasks.
 For the task with a simple correlational structure, dimensions one and four are correlated in the same way in each of the subtasks, but dimensions two and three are also correlated in each subtask, albeit in different ways.
 In the first subtask, dimensions two and three agree in category S and disagree in category S, whereas in the second subtask, dimensions two and three disagree in category S and agree in category ~S.
 As noted by Elman (1993), because there is more than one regularity in each subtask, it is not clear which one will be leamed at any given time.
 S o m e networks might focus on dimensions two and three in the first subtask, thereby learning a function that is incompatible with the function they need to leam for the entire task.
 W e therefore predicted that when networks are trained on the simple correlational structure in terms of subtasks, it would be harder to leam the classification relative to an unstmctured training regimen.
 For the task with a complex correlational stmcture, in spite of the fact that there are no simple correlations between any of the dimensions, within each subtask there are two different correlations that interact with each other.
 In category C, dimensions one and four have a correlation that is opposite in sign to that between dimensions two and three.
 If the values on dimensions one and four disagree, then the values on dimenions two and three agree, as in the first subtask.
 But, if the values on dimensions one and four agree, then the values on dimension two and three disagree, as in the second subtask.
 In category ~C, these relations are reversed, so that dimensions one and four have the same correlation as dimensions two and three.
 If the values on dimensions one and four disagree, then so do the values on dimensions two and three, as in the first subtask.
 If the values on dimensions one and four agree, then so do the values on dimensions two and three, as in the second subtask.
 Given these relationships, the function necessary for leaming the first subtask in the complex concept is quite compatible with that necessary for the entire task.
 Namely, dimensions one and four have correlations opposite to dimensions two and three in one category and identical correlations in the other category.
 Because the function Table 1: Binary coding scheme for concept leaming tasks containing a simple correlational stmcture (left) and a complex pi I p2 1 p3 0 p4 0 s 0 0 1 1 0 0 1 1 0 0 1 1 1 I 0 0  s 0 1 1 0 0 1 1 0 1 1 0 0 p9 plO pll pl2 pi I p2 1 p3 0 p4 0 0 0 1 1 0 0 1 I 0 0 1 1 1 1 0 0 ~ £ 0 1 1 0 0 1 1 0 0 0 1 1 p9 plO pll pl2 p5 1 0 1 0 p6 1 1 0 0 p7 0 0 I 1 p8 0 1 0 1 1 0 0 I pl3 1 1 1 1 pl4 0 0 0 0 pl5 0 1 1 0 pl6 p5 1 0 1 1 p6 1 1 0 1 p7 0 0 1 0 p8 0 1 0 0 1 0 0 1 pl3 I 1 1 1 pl4 0 0 0 0 pl5 0 1 1 0 pl6 305 learned in the first subtask is likely to be compatible with that required for the rest of the task, we predicted that subtasking would be superior to an unstructured training regimen on the complex task.
 In summary, these considerations led us to the following prediction: W h e n subtasking exploits function compatibility it will be superior to unstructured training, but, when subtasking promotes function incompatibility it will be inferior to unstructured training.
 Simulations To test these predictions, we used Fahlman and Lebiere's (1990) cascadecorrelation learning algorithm (CC) because it has certain design features that are particularly relevant for understanding facilitation and interference effects that occur during learning.
 C C is a generative algorithm that starts out with a minimal typology, consisting of an input layer that is fully connected to an output layer.
 To solve a problem, it first tries to reduce the errw between the observed and desired activation across the output units by modifying the weights between the input and output units.
 If it fails to reduce this error within an acceptable criterion, it then recruits a hidden unit from a pool of candidates that are connected only to the input units.
 The weights from the input units to the candidate hidden units are then trained so as to maximize the correlation between each candidate hidden unit's activation and the residual error at the output units.
 W h e n these correlations reach asymptote, the input weights leading to best candidate hidden unit are frozen, this bidden unit is connected to the output units, and the network reverts back to error minimization by modifying the weights connected to the output units.
 The process of recruiting additional hidden units is then repeated as needed.
 (For more detailed discussions about the C C architecture, see Fahlman & Lebiere, 1990; Shultz, Schmidt, Buckingham, & Mareschal, 1995).
 Because the weights from the input units to each hidden unit are fixed when each hidden unit is added to the network, knowledge acquired during the course of learning is more likely to be preserved during subsequent learning, and so its effects will be more salient than with other algorithms.
 This design feature makes C C more resistant to retroactive interference than backpropogation (Tetewsky, Shultz, & Buckingham, 1995).
 The tasks were presented in the same way that they appear in Table 1, with two exceptions.
 (1) The dichotomous coding in the input patterns was represented in terms of 1 and 1, rather than 1 and 0, to speed up learning.
^ (2) W h e n subtasking was used, after a network had been trained sequentially on subtask 1 and subtask 2, it was then trained on the total set of patterns associated with the classification (i.
e.
, subtask 1 + subtask 2).
 This third phase of training provided a way to determine the extent to which the function that had been approximated from the subtasks was compatible with the function in the overall task.
 After a network learned the second subtask it would have learned all 16 ttaining patterns.
 However, if the function the network learned to approximate was different from the function contained in the overall task, then the network would require additional training in this third phase of learning.
 Furthermore, if the number of epochs needed in the third phase of training was less than the number of epochs needed to learn the task when the patterns were presented allatonce, there would be evidence for function compatibility; if the number of epochs needed in the third phase of training was greater than the number of epochs needed during allatonce presentation, there would be evidence for function incompatibility.
 The simulations were carried out as a 2 x 2 factorial design, in which there were two types of conceptual structures (simple and complex) crossed with two types of training regimens (allatonce presentation and subtasking).
 The primary dependent variable was the number of training epochs needed to learn a particular concept.
 Training was stopped when all of the output values for the patterns in a given training set fell within 4 0 % of their desired values (i.
e.
, the value of the scorethreshold parameter was 0.
4).
 Fifty networks were run in each of the four conditions of the design and the results were averaged across netwoiks.
 Results The total number of training epochs required for each of the four conditions specified in the 2 x 2 design are shown in Figure 1.
 Note that in assessing overall performance, numbers of training epochs required in each phase of subtasking were summed to get the total epochs for learning the entire task.
 Although there was no overall difference between the two training regimens (128 vs.
 133 epochs), F(l, 196) = .
955, p = .
33, there was a main effect of task structure (191 vs 70), F (1, 196) = 668, p < .
001, such that the complex structure was harder to learn than the simple structure.
 Of more importance, however, is the fact that the interaction between task structure and training regimen was highly significant, F (1,196) = 44.
9, p < .
001.
 Paired contrasts on the means confirmed that it was easier to learn the complex structure under subtasking (177 vs 204 epochs), F (1,196) = 16.
4, p < .
001, and it was harder to learn the simple structure under subtasking (88 vs.
 52 epochs), F (1,196) = 29.
5, p < .
001.
 A n examination of the frequency distributions for the total number of epochs needed in each of the four conditions provided some interesting qualifications.
 W h e n the patterns were presented allatonce during training, the distributions for the simple and complex structures tended to be normal.
 However, when the patterns were presented in subtasks, the simple and complex structures produced distinctly bimodal distributions.
 For the simple structure, 25 of the networks were in the range of 4255 epochs, and 25 were in the range of 113142.
 For the complex structure, 39 were in the range of 132167, and 11 were in the range of 216333.
 Because these subgroups fell on either side of the overall mean for the respective concept structures, for purposes of convenience they will be referred to as the easy and hard versions of subtasking for each structure.
 ^This point was suggested to us by Yasser Hashmi.
 306 220180^ 140o W 1006020 All at once Subtasking Simple C o m p l e x Structure Figure 1.
 Mean number of epochs needed to leam two concepts under two training regimens.
 Error bars represent standard errors of the mean.
 The two alternative forms of subtasking for a task with a simple structure are shown in Table 2, broken down according to the number of epochs needed in each of the three phases of learning.
 In the hard version of subtasking, subtask 1 required an average of 51 epochs to be learned, whereas subtask 2 only required 12 epochs.
 This difference was significant, F (1,48) = 1727, p < .
001, and it suggested that the knowledge the networks had acquired from subtask 1 facilitated their ability to leam subtask 2.
 But in spite of this facilitation, even though the networks had learned to classify all 16 patterns correctly after completing the first two phases of learning, they apparently did not possess the knowledge embodied in the overall task, because the number of training epochs required in phase 3 was clearly different from zero.
 In fact, phase 3 training required more epochs than were needed to leam the simple task during allatonce presention (63 vs.
 52, t (73) = 11.
3, p < .
001) providing evidence for function incompatibility.
 Thus, as a result of learning sequentially subtasks 1 and 2, networks experienced proactive interference in learning the entire set of pattems.
 In contrast to these findings, however, for the easy version of subtasking, it appears that these networks learned to approximate the correct function in subtask 1, so that there was perfect transfer across the next two phases of leaming (i.
e.
, no training epochs were required to leam either subtask 2 or the entire set of pattems.
) Table 2.
 Mean number of epochs needed in the easy and hard versions of subtasking on a simple stmcture.
 Numbers in parentheses are standard errors of the mean.
 Easy(n=25) Hard(n=25) Subtask 1 Subtask 2 Subtasks 1&2 50 (0.
7) 0 (0.
0) 0 (0.
0) 51 (0.
6) 12 (0.
6) 63 (0.
9) The two alternative forms of subtasking for a task with a complex structure are shovim in Table 3.
 In the easy version of subtasking, subtask 1 required 50 epochs to be leamed whereas subtask 2 only required 11.
 Once again, this difference was significant, F (1.
 76) = 1634, p < .
001, and it suggested that the knowledge the networks had acquired from subtask 1 facilitated their ability to leam subtask 2.
 But, in contrast to the hard version of the simple structure, the number of epochs required in phase 3 training was less than the number of epochs required to leam the complex structure when it was presented allatonce (92 vs.
 204, t (87) = 32.
5, p < .
001), providing evidence for function compatibility.
 Thus, the knowledge that developed as a result of learning sequentially subtasks 1 and 2, facilitated leaming the entire set of pattems.
 However, in the hard version of subtasking, in spite of the fact that subtasks 1 and 2 followed the same trend as in the easy version, the number of epochs needed in phase 3 training did not differ from the number of epochs required to leam the complex structure when it was presented allatonce (202 vs 204, / (59) = .
268, p > .
05.
).
 This result therefore implied that these networks had essentially leamed the same function that occurs when the training set is unstmctured.
 This particular finding is noteworthy because given the nature of the training pattems, there is no a priori reason to expect that subtasking on the complex stmcture would produce two different kinds of solutions.
 One possible way to interpret this result is by examining the number of hidden units that were recmited by the two kinds of networks.
 In the easy version of subtasking, networks recmited one hidden unit in both phase 1 and phase 3, whereas in the hard version, networks recmited one hidden unit in phase 1 and at least two hidden units in phase 3.
 Because most of the networks that leamed the complex task under an unstmctured Uaining regimen required two hidden units, there is reason to believe that in the hard version of subtasking, networks were somehow ignoring the information from the hidden unit recmited in phase 1, and leaming the task as if the training set was unstmctured.
 However, this conclusion, as well as the other inferences that w e made about the relative difficulty of learning the different correlational stmctures under the different training regimens, can only be confirmed by more detailed analyses of network knowledge representations and the corresponding functions the networks learned to approximate.
 307 Table 3.
 Number of epochs needed in the easy and hard versions of subtasking on a complex structure.
 Numbers in parentheses are standard errors of the mean.
 Easy(n=39) Hard(n=ll) Subtask 1 Subtask 2 Subtasks 1&2 50 (0.
6) 11(0.
4) 92(1.
1) 51(1.
3) 9 (0.
5) 202 (8.
9) D i s c u s s i o n These simulations were carried out to determine the conditions under which subtasking will either improve or impair learning in neural networks, relative to unstructured, allatonce training regimens.
 The results indicated that when a network extracts a function that is compatible with later learning, subtasking will facilitate learning, whereas when a network extracts a function that is incompatible with later learning, subtasking will interfere with learning.
 In evaluating these results it is important to note that in general, there is no a priori reason to expect that certain kinds of tasks will always be learned better under subtasking, whereas other kinds of tasks will always be learned better under unstructured training regimens.
 Depending on the way the subtasks are formed, it is possible that subtasking could improve performance on the simple correlational structure and impair performance on the complex structure.
 As a practical matter, it is therefore necessary to devise a training regimen that is appropriate for a given task.
 In terms of the present findings, it would therefore be useful to form other types of subtasks for each structure and examine the extent to which the general notion of function compatibility can account for the resulting outcomes.
 Finally, these simulations have some important implications with regard to understanding the effects of knowledge on learning.
 Previous psychological research in this area has primarily been concerned with showing how existing knowledge structures can reverse the difficulty of learning various formal category structures (Pazzani, 1991; Wattenmaker, Dewey, Murphy, & Medin, 1986; Waldmann & Holyoak, 1989.
) Although these findings are impressive, they are also somewhat limited because they do not show how the critical knowledge that produced the reversal was itself acquired.
 The present experiment is therefore noteworthy because it shows how knowledge, which is acquired during the course of learning, can affect the acquisition of new knowledge.
 Hence, these results can be viewed as a way of bridging the gap between formal models of categorization, which try to describe specific learning algorithms, and knowledgebased approaches, which are concerned with how concept learning is influenced by existing knowledge.
 Most connectionist models of human learning have learned from initially random weights.
 Although such results may provide important existence proofs, they are generally unrealistic as models for human learning, which ordinarily occurs from a base of initial knowledge.
 Research on subtasking illustrates the potential importance of prior knowledge in learning.
 A cknowledgements Thia research was supported by an NSERC Grant awarded to Thomas R.
 Shultz.
 The authors would like to thank Yuriko OshimaTakane, David Buckingham and Yasser Hashmi for their comments and criticisms.
 References Caruana, R.
 (1992).
 Multitask learning: A knowledgebased source of inductive bias.
 Proceedings of the Tenth International Machine Learning Conference, 4148.
 San Mateo, CA: Morgan Kaufman.
 Cottrell, G.
W.
 & Tsung, F.
 (1993).
 Learning simple arithmetic procedures.
 Connection Science, 5, 3758.
 Elman, J.
 (1989).
 Representation and structure in connectionist models.
 Center for Research in Language Technical Report 8903, U C S D , LaJoUa, CA.
 Ehnan, J.
 (1991a).
 Incremental learning, or the importance of starting small.
 Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society, (pp.
 443448).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Ehnan, J.
 (1991b).
 Distributed representations, simple recurrent networks, and grammatical structure.
 Machine Learning, 7, 195225.
 Ehnan, J.
 (1993).
 Learning and development in neural networks: tlie importance of starting small.
 Cognition, 48, 7199.
 Fahhnan, S.
 E.
 (1991).
 The recurrent cascadecorrelation architecture.
 In R.
 P Lippmann, J.
 E.
 Moody, & D.
 S.
 Touretzky (Eds.
), Advances in Neural Information Processing Systems 3, 190196.
 Los Altos, CA: Morgan Kaufmann Publishers.
 Fahlman, S.
 E.
 & Lebiere, C.
 (1990) The cascadecorrelation learning architecture.
 Technical Report, CMUCS90100, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA.
 Gamer, W.
 R.
 (1974).
 The processing of information and structure.
 Potomac, M D : Lawrence Erlbaum Associates.
 Harris, C.
 L.
 (1991).
 Parallel distributed processing models and metaphors for language and development.
 Unpublished doctoral dissertation, U C S D , La Jolla, CA.
 Pazzani, M.
J.
 (1991).
 The influence of prior knowledge on concept acquisition: Experimental and computational results.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 17, 416432.
 308 Praiu L.
 Y.
, Mostow, J.
.
 & Kamm, C.
 A.
 (1991).
 Direct transfer of learned information among neural networks.
 Proceedings of the Ninth National Conference on Artificial Intelligence, (pp.
 584589).
 Anaheim, CA.
 Rosenberg, C.
 R.
 & Sejnowski, T.
 J.
 (1986).
 The spacing effect on NETtalk, a massively parallel network.
 Proceedings of the Eighth Annual Conference of the Cognitive Science Society, (pp.
 7289).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Shultz, T.
 R.
, Schmidt, W.
C, Buckingham, D.
, & Mareschal, D.
 (1995).
 Modeling cognitive development with a generative connectionist algorithm.
 In G.
 Halford & T.
 Simon (Eds.
), Developing cognitive competence: New approaches to process modeling.
 Hillsdale, NJ: Erlbaum.
 Tetewsky, S.
, Shultz, T.
 & Buckingham, D.
 (1995).
 Interference and savings in connectionist models of a sequential recognition memory task.
 Manuscript submitted for publication.
 Waldmann, M.
 R.
 & Holyoak, K.
 J.
 (1990).
 Can causal induction be reduced to associative learning? Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, (pp.
 190197).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Waibel, A.
, Sawai, H, & Shikano, K.
 (1989).
 Modularity and scaling in large phonemic neural networks.
 IEEE Transactions on Acoustics, Speech, and Signal Processing, 37(12), 18881898.
 Wattenmaker, W.
 D.
, Dewey, G.
 I.
, Murphy, T.
 D.
, & Medin, D.
 L.
 (1986).
 Linear separability and concept learning: context, relational properties, and concept naturalness.
 Cognitive Psychology, 18, 158194.
 Whitman, J.
 R.
, & Gamer, W.
 R.
 (1963).
 Concept learning as a function of form of internal structure.
 Journal of Verbal Learning and Verbal Behavior, 2,195202.
 309 T h e Spontaneous Use of Perceptual Representations during Conceptual Processing Karen L.
 Olseth Department of Psychology 5848 S.
 University Ave.
 University of Chicago Chicago.
 IL 60637 klol@ccp.
uchicago.
edu Lawrence W .
 Barsalou Department of Psychology 5848 S.
 University Ave.
 University of Chicago Chicago.
 IL 60637 LBarsalou0uchicago.
edu Abstract Although both prepositional and perceptual representations are viewed as central to human memory, propositional representations are typically assumed to underlie conceptual knowledge.
 Propositional models of concepts, such as feature lists, frames, and networks, embody this assumption.
 Recent theories across the cognitive sciences, however, have proposed that perceptual representations are central to conceptual processing.
 These perceptual representations are postulated to be schematic, dynamic, and multimodal images that have been extracted from perception and experience.
 In the experiment reported here, we used the property verification task to determine the extent to which people use perceptual representations during conceptual processing.
 A regression analysis revealed two kinds of evidence for the spontaneous use of perceptual representations: First, neutral and imagery subjects showed a similar pattern of reaction times on the task.
 Second, perceptual variables, such as the property size, predicted verification times.
 Although human memory is often viewed as containing both propositional and perceptual representations, conceptual knowledge is typically viewed as being exclusively propositional.
 Recent theories across the cognitive sciences, however, have proposed that perceptual representations are central to conceptual knowledge.
 In the experiment reported here, we examine this possibility using a classic conceptual task: property verification.
 W h e n people verify that cars have wheels and that cats have claws, do they examine perceptual representations, or do they retrieve these properties from propositional representations? To answer this question, w e examined two potential sources of evidence: instructional equivalence and perceptual work.
 According to instructional equivalence, if neutral subjects adopt perceptual representations spontaneously, these subjects should perform similarly to imagery subjects who have been instructed explicitly to use perceptual representations.
 According to perceptual work, the performance of neutral subjects should be affected by perceptual factors, if these subjects adopt perceptual representations spontaneously.
 In the experiment to follow, w e looked for evidence of instructional equivalence and perceptual work in the property verification task.
 Background.
 Propositional models share the assumption that arbitrary and amodal symbols represent conceptual knowledge (e.
g.
, Collins & Loftus.
 1975; Collins & Michalski.
 1989; Kintsch & van Dijk.
 1978; Lenat & Guha.
 1989; Smith, Shoben, & Rips, 1974).
 Comparable to words in a language, propositions are arbitrary because they bear no analogical resemblance to their referents, being linked through convention instead.
 Propositions are amodal because they represent information in the same abstract format regardless of the manner in which it was experienced.
 Propositional models have appealed to cognitive scientists for a variety reasons, including their ability to account for gist, their productivity, and their implementability (for reviews, see Barsalou, 1993; Barsalou, Yeh, Luka, Olseth.
 Mix, & W u , 1993; Barsalou & Prinz.
 in press).
 However, propositional models also exhibit a variety of difficulties, such as failing to account for the transduction of symbols from perception, the grounding of symbols in their referents, and a principled means for identifying the symbols to include in conceptual representations.
 In response to these problems, researchers across the cognitive sciences are exploring perceptual symbol systems increasingly (e.
g.
, Barsalou, 1993; Barsalou et al.
.
 1993; Barsalou & Prinz, in press; Barwise & Etchemendy, 1991; Edelman & Reeke, 1990; Fauconnier, 1985; Glasgow, 1993; Larkin & Simon, 1987; Mandler, 1992; Glenberg.
 1995; Jackendoff.
 1987; Lakoff & Johnson.
 1980; Langacker, 1986; Talmy, 1983).
 In contrast to propositional symbols, perceptual symbols are analytic schematic images.
 Because perceptual symbols are extracted from the perceptions of objects, events, and introspection.
 they retain spatial, relational, and experiential qualities.
 Rather than being transduced into an arbitrary and amodal language of thought, these embodied symbols resemble their referents.
 Although perceptual symbols are depictive and modality specific in nature, they are not holistic, static pictures in the head' nor veridical copies of perceptions.
 Instead, they are often schematic and sparse, only containing information that has been selectively attended to during perception.
 Additionally, perceptual symbols are dynamic, capable of representing events as well as objects, and they are multimodal, drawn from introspection as well as from all of the perceptual modalities, not just vision.
 Finally, perceptual symbols are productive: From a finite set of 310 mailto:klol@ccp.
uchicago.
eduhttp://LBarsalou0uchicago.
eduperceptual symbols, an infinite set of complex perceptual representations can be constructed that are related to one another systematically (cf.
 Fodor & Pyiyshyn, 1988).
 Because people could potentially use either propositional or perceptual representations during conceptual processing, which do they use? In a classic study, Kosslyn (1976) had subjects perform the property verification task and found that, when subjects received explicit instructions to use imagery, they verified properties by constructing and scanning images.
 Because the size of a property determined the time to verify it, Kosslyn concluded that these subjects were using perceptual representations.
 Importantly, however, when neutral subjects received no imagery instructions and were allowed to adopt strategies spontaneously, they did not appear to use perceptual representations.
 Rather than size predicting verification time, associative strength between concepts and properties was critical, consistent with propositional models.
 O n the basis of these results, Kosslyn concluded that people normally use propositional representations in conceptual tasks but can adopt perceptual representations when instructed.
 Kosslyn's results for neutral subjects, however, do not necessarily imply the use of propositional representations.
 Instead, these results might simply reflect the fact that neutral subjects did not have to perform conceptual processing.
 If subjects had exploited the fact that the distractors in these experiments were unrelated to the concepts (e.
g.
, MOUSEstinger), they could have simply responded "true" when the two words were linguistically associated (e.
g.
, MOUSEwhiskers), thereby performing the task without accessing conceptual representations.
 A simple associative strategy that capitalizes on linguistic relations would have been sufficient.
 To examine this possibility, the study reported here manipulated distractor relatedness.
 Half the subjects received unrelated distractors (e.
g.
, L/ONwire), similar to Kosslyn's subjects.
 The remaining subjects received related distractors (e.
g.
, LIONjungle) to ensure that they verified parts conceptually, not using an associative linguistic strategy.
 If related distractors force subjects to use conceptual processing, and if conceptual representations are perceptual, then w e should find that perceptual factors predict performance, even though subjects are not instructed to use imagery.
 Because previous research has demonstrated the importance of distractor relatedness in conceptual processing, we suspected that this could be an important factor here (McCloskey & Glucksberg, 1979; Smith, Shoben, & Rips, 1974).
 Once w e ensure that subjects perform conceptual processing, w e need to determine whether they are using perceptual representations.
 To answer this question, w e examined two sources of evidence: instructional equivalence and perceptual work.
 Testing for insuuctional equivalence involved comparing the performance of imagery subjects, w h o were explicitly told to use imagery, with neutral subjects, who were given no instructions to use imagery.
 Instructional equivalence holds when neutral subjects perform the same as imagery subjects.
 Because much research has shown that subjects adopt imagery when instructed (e.
g.
, Kosslyn.
 1976; Kosslyn, 1980; Finke, 1989), instructional equivalence would imply that neutral subjects are using perceptual representations as well.
 Note that perceptual representations need not be conscious but could easily function unconsciously (Barsalou et al.
, 1993).
 Assessing perceptual work, the second potential source of evidence for perceptual representations, involved seeing whether perceptual variables affect verification times.
 Of interest is whether factors such as the size, position, and visibility of a property affect the time to verify it.
 The more 'perceptual work' involved in processing a property, the longer it should take to verify.
 T o examine this possibility, w e scaled all conceptpart pairs on 11 perceptual factors, and then regressed the verification times onto them.
 If neutral subjects use perceptual representations, then the perceptual factors should predict performance, just as they should for imagery subjects (i.
e.
, instructional equivalence).
 To examine the extent to which subjects used nonperceptual information, such as concepttoproperty strength, the conceptpart pairs were scaled on linguistic factors as well.
 Thus, this experiment included two orthogonal, betweensubjects manipulations: unrelated vs.
 related distractors and neutral vs.
 imagery insuuctions.
 For the unrelated neutral group, w e expected that only associative factors, not perceptual factors, would predict performance, because these subjects could use a simple associative strategy that did not require perceptual knowledge.
 In conU'ast, w e expected that perceptual factors would predict performance for the related neutral group, because the related distractors would force subjects to use conceptual representations that were perceptual.
 Finally, w e expected perceptual factors to predict performance of the two imagery groups, because imagery instructions typically induce the use of such representations.
 Method Subjects and design.
 Subjects were 44 University of Chicago students who participated for pay.
 Eleven subjects were nested in each cell of the unrelated/related distractors X neutral/imagery instructions design.
 Four addiuonal subjects' data were excluded because of error rates exceeding 2 0 % .
 The average error rate for the remaining subjects was 9%.
 (These error rates are somewhat high, because subjects did not receive feedback about the correctness of their responses during the experiment.
) Materials.
 For the true materials, 47 concepts (e.
g.
, cat, phone, blouse) from a wide variety of superordinate categories (e.
g.
, mammals, electronic equipment, clothes) were paired with 112 parts (e.
g.
, claw, receiver, sleeve).
 Each concept was paired with one to four parts, but each part was only presented once.
 For the false materials, two sets of 112 false properties were paired with the same 47 concepts used for the uue materials.
 O n e set of false properties was highly related to the target concepts, whereas the other set was unrelated.
 The highly related false properties included thematically related entities (e.
g.
, C A R garage, OWLtree), taxonomically related categories (e.
g.
, CARvehicle, OWLbird), and parts of other taxonomically related categories (e.
g.
, CARpropeller, OWLbill).
 311 Unrelated properties were entities, categories, and parts not related to the target concept (e.
g.
, CARdress.
 OWLbrick).
 Ratings by independent judges verified the different relatedness of these two property sets.
 Each concept was paired with one to four false properties in order to ensure that subjects could not anticipate the ratio between true and false properties.
 For the practice trials, 38 true conceptpart pairs were constructed similar to the materials for the critical trials.
 T w o sets of 38 false conceptproperty pairs (related and unrelated) were also constructed.
 None of the practice materials were repeated in the critical phase of the experiment Predictor variables.
 The 112 true conceptpart pairs were scaled extensively on two sets of predictors: perceptual work and linguistic processing.
 The pairs were also scaled on a variety of predictors related to expectancy and part goodness, which are not included because they played relatively minor roles.
 Table 1 presents the perceptual and linguistic predictors examined here.
 Except for the lx_llrs and bc_frq predictors, these predictors were collected from independent groups of subjects.
 In the regressions to follow, the verification times in each of the four critical conditions were regressed onto the 15 predictors in Table 1 to examine the critical hypotheses.
' Procedure.
 Subjects performed the task on Macintosh llci computers running PsyScope and using C M U button boxes that measure millisecond accuracy.
 During the task, subjects rested their forefingers on two response buttons 7 c m apart, and rested a foot on a floor pedal.
 T o initiate each trial, subjects focused their attention on an asterisk in the middle of the screen and pressed the pedal.
 The concept word appeared for 500 ms, followed by the true or false properly 1200 m s later.
 Verification time was measured from the onset of the property to the detection of a response.
 If the propeny was a physical p an of the target concept, subjects were to respond by pressing the "true" button; otherwise, they were to press the "false" button.
 Subjects used their dominant hand to make "true" responses.
 Subjects were insuucted to respond as quickly as possible but to avoid making errors.
 Subjects received no feedback regarding the correctness of their responses, so that w e would avoid imposing our biases about 'parthood' onto subjects during the experiment.
 Subjects performed 76 practice uials in all.
 T o ensure optimal performance on the critical tfials, subjects were led to believe that the last 60 practice trials were critical.
 Subjects then performed the 224 critical trials, receiving 8 ' To examine relations between the 15 predictors, correlations were calculated between them.
 Given the complexity in the pattern of conelations, a factor analysis was performed to establish clusters of predictors, with three general clusters observed: positional and size predictors for perceptual work, the remaining perceptual work predictors, the linguistic predictors.
 This scaling of the predictors ensures thai the perceptual work and linguistic predictors measure distinct types of processing in the critical regressions.
 breaks spread out evenly over the 300 trials.
 Within the practice and critical materials, trials were presented in a different random order for each subject.
 The two imagery groups received explicit instructions to form an image of the target concept and then to look for the part on the image.
 If they found the part, they were told to respond "true," otherwise to respond "false.
" Imagery subjects were exhorted to base each response on their image, even if they knew the answer without consulting it.
 The two neutral groups of subjects received no explicit insuuctions regarding suategy.
 Results Mean reaction times.
 Before reporting the primary results of interest from the regression analysis, we present a preliminary analysis of the mean verification times.
 In this, and all later analyses, the reaction times for errors are removed, as well as ouUiers (two standard deviations above or below the mean response time for each individual subject).
 As Table 2 illustrates, instructions had a main effect on mean verification time (f(l,444)=50.
56, p<.
001).
 The two imagery conditions were 130 msec slower than the two neutral conditions, replicating previous results that forming conscious images generally takes longer than other processing strategies.
 Surprisingly, distractor relatedness had no effect on uue verification time (F(l,444)=.
09), nor did it interact with insuuctions (F(l,444)=.
06).
 Lack of any difference in error rates indicates that a speedaccuracy tradeoff was not responsible.
 Although distractor relatedness had no effect on uue verification time, w e shall see that it had considerable impact on the regressions.
 As Table 2 further illustrates, disuactor relatedness did affect false verification times (F(l,444)^46.
97, p<.
00l), with the related distractors being more difficult to reject than the unrelated distractors.
 The higher error rates for the related distractor condition further support this conclusion (F(l,444)=45.
55, p<.
001), as well as indicating no speedaccuracy tradeoff.
 Regressions.
 Of primary interest were differences in how the verification times from each of the four critical conditions regressed onto the predictors in Table 1.
 W e performed these regressions in a wide variety of manners to ensure generality, with all variants pointing to the same basic conclusions.
 The regressions w e report here are four hierarchical regressions, one for each critical cell of the design.
 In each regression, the mean verification times for the 112 uuc parts in that condition were regressed onto the iwo clusters of predictors in Table I (i.
e.
, perceptual and linguistic).
 Of interest was the increase in variance accounted for (R^) as each complete set of predictors was entered.
 Because the cluster of predictors entered first always captured any shared variance, the four linguistic predictors were entered first to enable a conservative test of the perceptual hypothesis (regressions in which the eleven perceptual predictors were entered first led to the same conclusions, as did regressions in which the two sets were allowed to enter freely, either hierarchically or non312 c C/3 01 i s: ^ I 1 a .
 •Si a C/3 U O "5 Q .
 U u 00 •o c X! o •S c 8 5 5 i S Tt ro m ro «ri in r~00 0^ OO OS 00 00 t^ Q.
 U •s o •a t •S o c « I f 8 8 c c: £3 3 O.
 2 1 Q.
 Q.
 •s £>0 8 • i « x>o E p ••3 E 4) E bO E E • c 'Z •S o.
 o •S "o S bO c o U T3 1) 8 _̂  S 2  2 = S ?i c ir ^ °  o ,E a 8 ^ ^ c S ii .
S J3 .
Si .
i 1 u= « I I I I I I I I Q.
Q.
D.
Q.
Q.
Q.
D.
O.
 OC CN <N tNl (N 'S 3 r: 8 c 3 on E 3 x: c c 8 c i3 00 'E 3 O c c 8 c a V) 3 3 .
 —̂V T3 .
3 3 c i 3 aC/5 , , 'E 3 U c c 8 c F c TO E "• c o £~ (̂  E, <N <̂ > 2 en > op IE o r<> c a w o c op o 3 2 o c o — — o o o '^ i o c c o u I °  I I •s oo 2 § ^ o.
 o '•3 t a.
 ^ .
̂  0£ S 00 CN OO Ov O (N >% x: 0() ^ On O 73 CO O ̂̂  •̂  u 3 1 o c 't ^ V) B.
 3 O.
 3 CO — •2 o i> X, c i" o û  O E 3 C .
2 1 2 <i> 3 fc ^ y 5 # °i "l S ax' x' x' x' J _ Ji ^ Ji oo .
S CO ^ so .
s T3 > t m 3 (A U.
4 O 1 5 2 (A v E ^ o >> ••a V CC 313 Table 2.
 Average verification times for correct trials, and error rates.
 Conget Vgrificatipn Timg Condition TruS Faiss Error Rates True False Unrelated Neutral Unrelated Imagery Related Neutral Related Imagery 898 1028 900 1038 836 900 947 996 .
10 .
09 .
09 .
07 .
01 .
01 .
07 .
10 hierarchically).
 Thus, any variance accounted for by the perceptual predictors in these particular regressions is variance that remains after linguistic variance has been removed.
 As Table 3 illustrates, the linguistic predictors only accounted for significant variance in the two unrelated conditions.
 In these two conditions, the two associative predictors (lx_c_p and lx_p_c) accounted for most of the variance.
 These results indicate that when the distractors were easy to reject, subjects used a superficial linguistic strategy that capitalized on the associative strength between the concepts and parts: If the concept and part words were associated, subjects responded "true," otherwise they responded "false.
" Contrary to Kosslyn (1976), even imagery subjects appeared to use this strategy when the distractors were unrelated.
 Even though these subjects were told to use imagery, they still used an associative strategy, because the distractors allowed it.
 In contrast, when the distractors were related and difficult to reject, the linguistic variables did not predict performance in either the neutral or imagery condition.
 The related distractors successfully blocked subjects' use of an associative strategy, forcing them to process the materials conceptually.
 Of primary interest is how subjects verified parts when the associative linguistic strategy was blocked.
 As Table 3 illustrates, perceptual work predictors accounted for subjects' performance in the related neutral condition.
 Even though the perceptual predictors were entered after the linguistic predictors and thus do not include shared variance, they nevertheless accounted for a significant amount of variance in subjects' performance.
 Indeed, we haven't been able to find any other variables, many of which are not discussed here, that do a better job.
 Not only do we see an effect of perceptual work in the related neutral condition, we also observe a qualitative approximation of instructional equivalence: Like the performance of related neutral subjects, the performance of related imagery subjects is explained only by perceptual predictors and not by linguistic predictors.
 Effects of perceptual work were also observed in the unrelated imagery condition.
 As already noted, however, linguistic variables affected the performance of this group as well.
 Thus, unrelated imagery subjects used both strategies.
 These subjects used imagery to some extent, because they were instructed to do so, but they also used the associative strategy, because the distractors allowed it.
̂  Discussion The regression results demonstrate a strong effect of distracior relaiedness.
 Whereas the linguistic predictors accounted for variance when the distractors were unrelated, they failed to account for variance when the distractors were related.
 When distractors were unrelated, subjects used the associative strength between concept and part words as a heuristic strategy.
 When related distractors precluded using this strategy, however, subjects were forced to retrieve and process conceptual representations.
 Interestingly and significantly, these conceptual representations appeared to contain perceptual content, given the importance of perceptual predictors in both of the related distractors conditions.
 Even when subjects did not receive imagery instructions, they nevertheless used perceptual representations when the distractors forced conceptual processing.
 In summary, the presence of both instructional equivalence and perceptual work in our data indicate that neutral subjects spontaneously adopt perceptual representations in conceptual tasks.
 ^ The particular perceptual predictors that accounted for the most variance varied somewhat from regression to regression.
 In general, however, the important predictors tended to be pw_find, pw_length, pw_image, pw_salience, pw_handle, and pw_top.
 Because these factors tended to be intercorrelated, it is difficult to determine which is most important.
 Table 3.
 Change in R^ due to adding a cluster of predictors .
 Condition Unrelated Predictor set Neutral Linguistic .
16** Perceptual .
10 Unrelated Related Imagerv Neutral .
16** .
06 .
15* .
18* Related Imagerv .
06 .
29** * p<.
05, ** p<.
01 314 Although these results provide evidence for perceptual representations, they do not preclude the possibility that people use propositional representations in other task contexts.
 W u and Barsalou (1995), however, have also found strong evidence for perceptual symbols in feature production.
 In this slower and more sequential conceptual task, both instructional equivalence and perceptual work were again observed.
 Several lines of evidence in these studies indicate that subjects scan images to produce features from conceptual combinations as well as from simple concepts.
 Similarly, in another line of research, we have found that the perceptual similarity of parts affects priming during part verification (Olseth & Barsalou, 1995).
 When subjects verify that a D O G has a face, they are faster after having previously verified WOLFface than HUMANface.
 Because dog faces are more similar to wolf faces than human faces, more priming occurs from wolf faces than from human faces (a control condition rules out the possibility that category similarity is responsible).
 Thus, results from a variety of studies increasingly indicate the cenual role of perceptual representations in conceptual tasks.
 Acknowledgments Woric on the research reported in this paper was supported by National Science FoundaUon Grant SBR9421326 References Barsalou, L.
W.
 (1993).
 Flexibility, structure, and linguistic vagary in concepts: Manifestations of a compositional system of perceptual symbols.
 In A.
C.
 Collins, S.
E.
 Gathercole, & M.
A.
 Conway (Eds.
), Theories of memories (29101).
 London: Erlbaum.
 Barsalou, L.
W.
.
 Yeh, W.
, Luka.
 B.
J.
.
 Olseth, K.
L.
, Mix, K.
S.
, & W u , L.
 (1993).
 Concepts and meaning.
 In K.
 Beals, G.
 Cooke, D.
 Kathman, K.
E.
 McCullough, S.
 Kita, & D.
 Testen (Eds.
), Chicago Linguistics Society 29: Papers from the parasession on conceptual representations.
 University of Chicago: Chicago Linguistics Society.
 Barsalou, L.
W.
, & Prinz, J.
J.
 (in press).
 Mundane Creativity in Perceptual Symbol Systems.
 In T.
B.
 Ward, S.
M.
 Smith, & J.
 Vaid (Eds.
), Conceptual structures and processes: Emergence, discovery, and change.
 Washington, DC: American Psychological Associations.
 Barwise, J.
, & Etchemendy, J.
 (1991).
 Visual information and valid reasoning.
 In.
 W .
 Zimmerman & S.
 Cunningham (Eds.
), Visualization in mathematics (924).
 Washington: Mathematical Association of America.
 Collins, A.
M.
, & Loftus, E.
F.
 (1975).
 A spreading activation theory of semantic processing.
 Psychological Review.
 82.
 407428.
 Collins, A.
M.
, & Michalski, R.
 (1989).
 The logic of plausible reasoning: A core theory.
 Cognitive Science, 13, 150.
 Edelman, G.
M.
, & Reeke, G.
N, Jr.
 (1990).
 Is it possible to construct a perception machine? Proceedings of the American Philosophical Society.
 134, 3673.
 Fauconnier, G.
 (1985).
 Mental spaces.
 Cambridge, M A : MIT Press.
 Finke, R.
A.
 (1989).
 Principles of mental imagery.
 Cambridge, M A : MIT Press.
 Fodor, J.
A.
, & Pylyshyn, Z.
W.
 (1988).
 Connectionism and cognitive architecture: A critical analysis.
 Cognition.
 28.
 371 Glasgow, J.
I.
 (1993).
 The imagery debate revisited: A computational perspective.
 Computational Intelligence.
 9.
 309333.
 Glenberg, A.
M.
 (1994).
 What is memory for.
 Manuscript under review.
 Jackendoff, R.
 (1987).
 O n beyond zebra: The relation of linguistic and visual information.
 Cognition.
 26, 89114.
 Kintsch, W.
, & van Dijk, T.
A.
 (1978).
 Toward a model of text comprehension and production.
 Psychological Review, 85.
 363394.
 Kosslyn, S.
M.
 (1976).
 Can imagery be distinguished from other forms of internal representation? Evidence from studies of information retrieval times.
 Memory &.
 Cognition, 4, 291297.
 Kosslyn, S.
M.
 (1980).
 Image and mind.
 Cambridge, M A : Harvard University Press.
 Lakoff, G.
, & Johnson, M.
 (1980).
 Metaphors we live by.
 Chicago: University of Chicago Press.
 Langacker, R.
W.
 (1986).
 An introduction to cognitive grammar.
 Cognitive Science.
 10.
 140.
 Larkin, J.
H.
, & Simon, H.
A.
 (1987).
 W h y a diagram is (sometimes) worth ten thousand words.
 Cognitive Science.
 11.
65100.
 Lenat, D.
B.
, & Guha, R.
V.
 (1989).
 Building large knowledgebased systems: Representation and inference in the Cyc project.
 Reading, M A : AddisonWesley.
 Mandler, J.
M.
 (1992).
 How to build a baby: II.
 Conceptual primitives.
 Psychological Review, 99, 587604.
 McCloskey, M.
, & Glucksberg, S.
 (1979).
 Decision processes in verifying category membership statements: Implications for models of semantic memory.
 Cognitive Psychology, 11.
 137.
 Olseth, K.
L.
, & Barsalou, L.
W.
 (1995).
 Work in progress.
 Smith, E.
E.
, Shoben, E.
J.
, & Rips, L.
J.
 (1974).
 Structure and process in semantic memory: A featural model for semantic decisions.
 Psychological Review.
 81.
 214241.
 W u , L.
, & Barsalou, L.
W.
 (1995).
 Work in progress.
 315 Indirect S p e e c h A c t s a n d Politeness: A C o m p u t a t i o n a l A p p r o a c h Liliana Ardissono and Guido Boella and Leonardo Lesmo Dipartimento di Informatica  Universita di Torino Corso Svizzera n.
l85 10149 Torino  Italy Phone: +39117429111; Email: {liliana, lesmo}@di.
unit.
o.
it Abstract This p>aper describes a framework for the representation and interpretation of indirect speech acts, relating them to the politeness phenomenon, with particular attention to the Ccise of requests.
 The speech acts are represented as actions of a plcm hbreiry 2ind are activated on the b2isis of the presence of syntactic and semeintic information in the linguistic form of the input utterance.
 The speech act cuicdyzer receives in input the senicintic representation of the input sentence and uses the politeness indicators to chmb up the decomposition and generalization hierarchies of acts encoded in the librciry.
 During this process, it eliminates the indicators and collects the negated presuppositions (represented cis effects of the indirect speech act) that characterize the politeness forms.
 Some cycHc paths in the hierarchy allow the system to cope with complex sentences including nested politeness indicators.
 In the proper places of the hierarchy the semantic representation of the input sentence is converted into a domain action in order to startup, when needed, the domsiinlevel plan recognition process.
 Introduction Since Austin (1962) and Searle (1969) wrote their papers about speech cicts, it was clear that the study of language must take into account the way people use it to move in the world.
 A n utterance is an action, so it is made with some goals in mind.
 A m o n g these goals, getting cooperation fiom the audience and maintaining a good relationship with them play a major role.
 The cooperation can range from simple attention (if you just want to chat), to providing information (in case of questions), to performing some general action (as closing a window if the speaker asks the hearer to do so).
 In all these cases, speech acts must be planned by taking into account the relation between the speaker and the hearer.
 A major step in computational linguistics was made when the study of traditional fields as syntax and semantics was complemented with the computational study of pragmatics.
 However, this was accomplished by paying attention mainly to the first of the two goals mentioned above.
 In particular, it was recognized that goals and plans play a basic role in linguistic communication (Allen &: Perrault 1980), but their study was centered on domain plans.
 In the last fifteen years various models of recognition of the speaker's plans were developed, some of which gave fundamental formal accounts of the knowledge which it is based on (Cohen & Levesque, 1990; Cohen & Perrault, 1979), while others had a more computational bias (Carberry, 1988).
 More recently domain plans have been complemented with higher levels plans called discourse plans (Litman & Allen, 1987) and problem solving plans (Lambert, 1993).
 While Litman and Allen's discourse plans dealt both with communication strategies and problemsolving activities, Lambert separates the discourse level in two parts: in her framework, communicating strategies are represented in the communicative level, while problemsolving plans model the activity of building the speaker's domain plans.
 The present work addresses mainly the second goal mentioned in the first paragraph: what linguistic forms enable a speaker to manifest her/his choice to be more or less polite with the hearer? The desire of maintaining some harmony with the hearer is just one of the multiple goals of the conversation, so the problem of modeling this desire can be faced from a general perspective of modeling goals.
 However, the features that express the choices made are rather special; while the propositional content of a sentence enables the hearer, after some rather complex inferential activity, to understand the speaker's goals, it is the form in which that propositional content is expressed that makes the utterance more or less polite.
 For example, the following sentences have the same illocutionary force, but a different literal interpretation (e.
g.
 lb refers to the hearer's capabilities, Ic projects on a hypothetical perspective the hearer's action, Id refers to her/his wants, while le simply mentions an unsatisfied precondition of the desired Jict): la) D a m m t le chiavt delta bibltoteca! [Give m e the keys of the library!] lb) Potresti darmi le chiavt della bibltoteca? [Could you give m e the keys of the library?] le) M l darestt le chtavi della bibltoteca? [Would you give m e the keys of the library?] Id) Ti displace darmi le chtavi della bibltoteca? [Do you mind giving m e the keys of the library?] le) La bibltoteca e chtusa [The library is closed.
] Our goal is to get rid of these aspects of the literal interpretation, assuming that their role is just to mark the politeness strategies the speaker has adopted in communicating.
 This approach follows the guidelines drawn by the research of many linguists, that have investigated the notion of politeness and its implications in communication (Brown & Levin.
son, 1987; Kasper, 1990; Leech, 316 1983); they have shown that the origin of many indirect forms of expression lies in the necessity of smoothing the interaction for being polite.
 As far as the notion of politeness is concerned, various more or less precise explanations have been formulated.
 In our work, we will refer to Brown and Levinson (1987), who motivate the use of indirect forms of expression with the necessity to preserve some wants that every interlocutor has.
 In order to characterize these wants they introduce the notion of face as:^ The public selfimage that every member [of a society] wants to claim for himself, consisting in two related aspects: a) negative face: the baste claim of territories, personal preserves, rights to nondistraction i.
e.
 to freedom of action and freedom from imposition b) positive face: the positive consistent selfimage or 'personality' (crucially including the desire that this selfimage be appreciated and approved of) claimed by interactants Brown and Levinson interpret the behavior of speakers on the basis of a taxonomy of linguistic strategies that enable a speaker to satisfy the goal of preserving the negative face of the interlocutor.
^ For example, when a speaker wants the hearer to perform an action, s/he can express her/his request directly, using an imperative form; however, in this way, s/he does not preserve the hearer's negative face: in fact, she does not hide the presupposition that s/he believes that the hearer wants to execute the action.
 So, a safer strategy is to use an indirect request such as Id, which doesn't presuppose any hearer's attitude towards the requested action (in fact, s/he is questioned about that).
 The conditional mood in sentence Ic [mi daresti: 'would you give me') has a similar role: in this case the presupposition is canceled by projecting the utterance on an hypothetical world.
 The various methods for modulating the strength of utterances are chosen according to the degree of familiarity, respect, relative social roles of the interactants, and the impact that the contents of the acts might have on the interlocutors (Brown & Levinson, 1987).
 This paper takes into account the suggestions coming from the authors mentioned above to implement a method for processing and evaluating indirect speech acts AS politeness forms.
 This is done within a framework of plan recognition that has already been applied successfully to the recognition of domain plans in an informationseeking environment (Ardissono etal, 1993; Ardissono etal, 1994; Ardissono & Sestero, 1995).
 It must be observed that Hinkelman and Allen (1989) challenged the possibility of facing this problem on the sole basis of planning structures.
 They argue that the variability of politeness forms among different languages calls for the introduction of knowledge about idioms.
 '.
Although they presented the notion of/ace as a linguistic universal, many linguists think that it is mainly suited for describing the behavior of western societies.
 ''They also explain which forms people use to anoint the positive face of their interlocutors, but we will not deal with this aspect of communication here.
 While we agree on the need of languagespecific knowledge, we will show that the required information can be encoded within a plan formalism, so that the homogeneity of the representation is preserved.
 The rest of the paper is organized as follows: the first section describes the formalism used for representing the knowledge about speech acts; the second describes how the speech acts library is used in the process of speech act recognition; the third section shows the speechact recognition process on an example.
 Finally, some brief conclusions are presented.
 The representation of the speech acts The knowledge about speech acts and the way they relate to each other is stored in the speech acts library, represented in an action hierarchy based on a formalism similar to that by Kautz (1990).
 In particular, we set apart the decomposition hierarchy (boxed arcs in the figures) and the generalizationspecialization hierarchy (thick arrows).
^ W h e n the decomposition includes a single step, the relation between the two ax:tions is a generation relation (Pollack, 1990).
 The leaves of the hierarchy, surfimperative, surfynquestion, surfwhquestion, surfassertion correspond to the different syntcictic types of sentence, namely imperatives, declaratives and interrogatives (two small portions of the library are reported in Figure 1 and 2.
 There, the surface types are circled by thick ovals).
 The actions of the hierarchy are characterized by the following features: • parameters: the parameters of an action include the speaker, the hearer and a reference to the speech act.
 The third parameter has different meanings in the various actions of the speech act library: since the interpretation of surface speech acts starts with the analysis of the linguistic aspects in the input utterances (e.
g.
 the detection of politeness features), the actions related to that phase refer to the semantic representation of the input sentences (e.
g.
 consider askif, .
.
.
, indirectreq in Figure 1).
 O n the other hand, after considering the linguistic aspects, the analysis goes on taking into account the knowledge about domain actions (in order to relate the speaker's utterance to domain goals).
 So, the third parameter of actions referring to this phase of the analysis refers to an instance of a domain action involved by the speaker's utterance.
 The domain action is recognized from the semantic representation by a plan recognition phase [action identification (Carberry, 1990), shown in the figures as actid).
 • preconditions: they represent the presuppositions associated with actions (see Searle's felicity conditions (Searle, 1969)).
 For example, obtaininfo (the action of asking information) has the precondition that the speaker does not know the requested information.
 "The knowledge about domain actions is represented in a similar way and stored in the domain level of the plan library.
 Of course, speech acts refer to specific predicates concerning the knowledge and beliefs of tlie interactants.
 317 1 Bel(sp, ,(cando(hr.
 act)))) A Bel(sp, authorizcd(sp,hr, •do(sp, request))) A ^Bel(sp, '(wamdo(hr,act)))) prec < expr(sp, hr, int(sp, do(hr, act))) expr(sp, do(sp, actofreq)) eff eff i inrecordreq(sp, hr, act) wh acl:= Actid(self, scm) ) requesi(sp, hr, aa) ' Cint(spjw.
ini(8p, do(hr, act))) 1 (expr(sp̂ irj{̂ t(sp.
 do(hr, act)))) X directreq(sp, hr, sem) (surfi wh fe imperative(sp.
 hr, sem) fealure(sem) C(please, givedef) ^ffrecordreq(sp, hr, act) wh Agt(act) = hr /\ iact:= Actid(prcc, sem) tSs eff indireareq(sp, hr, sem) wh feaiure(sem) C (please, cond (expr(sp, do(sp, actofreq))) Vfrr explicitperform (sp, hr, sem, spacltype) wh spacttype = request /\ feature(sem) C (please) (hedgedperform (sp, hr, sem, spacttype) J Mndreql(sp, hr, sem) askif(sp, hr, semi) wh sem:=fcancel(seml) A J can 1, spacttype) QeatULre(sem) ^ P ^ : z : iskif(sp, hr,seml) wh sem:=fcancel(seml) I can2 £ feature(scm) ^ " K expr(sp, ( indreq2(sp, hr, sem) 9 ^skif(sp, hr, semi) ^ wh sem:=fcancel(seml) /\ want2 £ feature(sem) ̂  T Bel (sp, cando(hr, sem))) Q indreq3(sp, hr, sem) eff I ) statement(sp, hr, semi) wh sem:=fcancel(seml) A wantl £ fealure(sem) w ^ expr( iKnowif(sp, aulhorized(sp, hr, do(sp, spacttype)))) expr(sp, hr,i Bel(sp, wantdo(hr sem))) Figure 1: A portion of the Speechact Library restrictions: they are included in the w h property of actions and, as for parameters, their meaning varies in the different actions of the speech acts library.
 In the actions related to the analysis of the linguistic aspects of utterances, they concern the linguistic features present in their prepositional content.
 These features are called by Searle (1969) illocuttonary force indicating devices and allow the hearer to identify the kind of speech act.
 They are, for example, the form of the sentence (declarative, interrogative, imperative), the tense and m o o d of verbs, the presence of modal verbs (can, want, .
.
.
) and performative verbs (say, ask, order, .
 .
 .
 ) , or particles like please, clearly, etc.
 A n e x a m p l e of this kind of restriction is c a n 2 G feature(sein) in askif in Figure 1, which restricts the m a i n verb of the sentence to be the second person of the m o d a l potere ('can').
 In s o m e actions referring to the d o m a i n actions involved by the input utterances, the restrictions m a y link the parameters of the actions in the speech acts library with the identified d o m a i n actions, or with their parameters.
 For example, in ofFrecordreq in Figure I, a restriction forces the agent of the identified d o m a i n action to be the hearer; this restriction is important in the definition of offr e c o r d  r e q because, w h e n the restriction is not respected, a different speechact is being performed (e.
g.
 if the agent coincides with the speaker, w e have an act of stating her/his plan).
 c o i m m i n i c a t i v e effects: the actions of the library produce two types of effects: the first one consists in the communicative intentions of the speaker (e.
g.
 w h e n a request is performed successfully, then the speaker and the hearer share the belief that the speaker intends the hearer to perform an action and intends her/his intention to be a mutual knowledge)''.
 T h e second type of effects is related with the politeness consequences of the use of direct/indirect expressions in communication:^ for example, the effect of the indirect request indreql is to express that the speaker doesn't w a n t to presuppose any hearer's capability in performing the requested action, so that the negative face of the speaker is not threatened.
 T h e recursiveness of natural language implies that illocutionary force indicating devices can be nested inside each other; so, complex utterances including different speech acts can be built and interpreted in a compositional way.
 For example, the sentence; 2 ) Vorrei chiedertt se puoi dirmt dove si trova la biblioteca.
 [I would like to ask you whether you can tell m e where is the library.
] is c o m p o s e d of an external surface statement with conditional m o o d (vorrei, "I would like"), an explicit performative (chiedere, "to ask") and an indirect request expressed by an inner yes/no question (se .
.
.
, "whether .
 .
 .
 " ) .
 ^ Because of the freedom in the composition of sentences, the speech acts library contains s o m e cyclic paths (see the askif action that, in figure 2, occurs in its o w n definition).
 ""The Cint predicate is defined (Airenti etal, 1993) as: Cint(sp, hr, p)=Int(sp, MB(hr, sp, pACint(sp, hr, p))) ^Pobteness effects are associated with the predicate expr.
 In this way, we model the conventionality of politeness expressions while preserving the base formalism.
 BcisicaUy, the expr predicate states which of the various presupposition has been (conventionally) negated to preserve the face of the hccirer.
 *Also the inner indirect request is composed of nested levels: see the use of piioi, "you can".
 318 > (10iowif(sp,seni))A int(sp, Knowif(sp,seni)) i(Bel(sp, I (Knowif(hr,sem)))) Bel(sp,(authorized(spJv,do(sp,obiaininfo))) ( hedgedperform(sp, hr, sem, spacttype) j .
hr,scm)J rb (^indreql(sp.
hf.
sem)J P " ^ J obuininfo(sp, mdreq2(sp.
 hr, sem) dircciaskif(sp, hr, sem) 5xpr(sp, do (sp, aclofask)) ^^^—ry^ 1 c surfynquesuon (sp, hr, sem) /exphcitperform (sp, hr, sem, spacttype) ̂  V h spaatvpe = question /j expr(sp, hr, iBel(sp, eff aulhorized(sp,lCnowif(sp, sem)))) d aski((sp, hr, sem) indireaaskif( sp, hr, sem) Cint(sp,hr,int(sp, informif(hr,sp,sem))) (expr(sp, do(sp, aclofask))) indask4(sp, hr, sem) D indaskl(sp, hr, sem) ) (.
 .
 TT.
 , TN /statement(sp, hr, semi) •ndask3(sp, hr, sem)J ^h sem=f.
cancel(seml) A askif (sp, hr, semi) wh sem=fcancel(seml) A (canl,know)C feature(seml) {wantl,know) C feature(seml) anK ( indask2(sp, hr, sem) ^ Iskif (sp, hr, semi) wh sem=fcancel(seml) A know2£ fealure(seml) V ;tr^ " eff statement(sp, hr, semi) wh sem=fcancel(seml) A (not, k n o w l ) C feature(sem 1̂  anc expr(sp, hr, Bel(sp, Knowif(hr, sem))) Figure 2: Representation of the askif speechau:t T h e s p e e c h act recognition p r o c e s s Communicative actions should be interpreted at three levels: the phatic level, referring to the understanding of the single words uttered by the speaker, the locutionary level, referring to the comprehension of the meaning of the utterances, and the illocutionary level, referring to the interpretation of the sentences as speech acts.
 While we are not concerned with the phatic level, in our framework the locutionary and illocutionary levels correspond to different phases of analysis of the input sentences.
 In particular, a N L interpreter (Ardissono etal, 1991; DiEugenio & Lesmo, 1987; Lesmo & Terenziani, 1988) carries on the syntacticsemantic analysis and produces the semantic representation (in the formalism of semantic nets); then, the identification of the speech act is performed (this is the main topic of our paper).
 Finally, the domainrelated processing connects the sentence to the previous ones in a single picture of the overall domain plans and goals of the speaker (see Figure 3).
 These plans are represented by means of hierarchical structures based on the domain level of the plan library and are obtained by applying heuristic rules for action identification and focusing; these rules keep into account contextual information for building coherent hypotheses on the speaker's goals and plans (Ardissono etal, 1993; Carberry, 1988).
 The input to the second phase (see Figure 3) is a semantic representation of the input (with the contextual  e.
g.
 anaphorical references already solved) and its output is the recognized speech act, i.
e.
 one of the roots of the hierarchies depicted in the figures.
 As a side effect of this second step, all "politeness indicators" have been identified, so that just the "pure" propositional content of the input sentence is passed to the third step.
 Concurrently, a degree of politeness has been evaluated.
 The goal of this section is to describe how the second step extracts the politeness indicators; nothing will be said about the evaluation of the politeness degree, which is currently obtained via some simple and not yet well developed heuristic rules.
 The basic claim is that the whole process is governed by standard plan management procedures: the same procedures used in the third step for the well known domaindependent analysis of the user's plans and goals.
 First, the semantic representation undergoes an actionidentification phase.
 Since the interpreter is playing at the locutionary level, this phase does not return the main action (as expressed by the main verb) involved in the input, but the surface speech act type (e.
g.
 surfaceynquestion).
 This seems reasonable, since, at this level, the term 'ax;t' must refer to locutionary nets.
 The surface type is used as an entry point in the hierarchy, since it must match one of the leaves.
 Then, starting from the leaf found, an upwardexpansion procedure is applied.
 Again, this procedure is the same used within the focusing phase of domainlevel analysis (Ardissono etal, 1993; Carberry, 1990).
 Upwardexpansion climbs up the hierarchy along all possible paths (and this can lead to ambiguities).
 The key point is the treatment of the w h conditions appearing in the nodes of the hierarchy.
 Most of them refer to standard tests, but there are two types that deserve attention.
 The first of them is the check of feature(sem); these tests are encoded in a very compact way in the figures; what actually happens is that each of them asks for the inspection of the topmost current 319 Input Sentence Syntactic/ Semant ic/ Contextual Ana lysis ,SemantIc , RepresentatIon Speech Acts Analysis Communicative ' acts Representation Doma i n Related Ana lysis • Response Figure 3: Scliciiia of the interpretation process node of the semantic representation; if the features nuiitioned in the test are found, then the node is discarded (fcancel) and the 'main' substructure remains as sein (e.
g.
, with modal verbs, the main substructure is the one referring to the 'object' of the proposition; for example, given a sentence like "May I ask you to .
.
.
" and its semantic representation "May(User, ask(User, System, .
.
.
))"^ s e m i , after a caul test on the formula, the remaining part is "ask(User, System, .
 .
 .
 ) " , that corresponds to "User asks system to .
.
.
" s e m ) .
 So, when the hierarchy is climbed up, the politeness markers disappear and, when one of the roots is reached, what remains IS the propositional nucleus of the input sentence.
 The complete process could require that the root is reached more than once.
 In fact the process stops only when a root ha.
s been reached and no further climbing up is possible.
 But for nested levels of indirectness, the root can be used as a new entry point in the hierarchy (see the bottom askif node in the figures).
 Actually, the process can also fail in case a nonroot node has no parent for which the w h conditions are met.
 Hopefully, in this case other alternative paths remain open.
 Note however that, given a certain speech act, it is possible to identify more than one prmiary illocutionary act; so, the upward activation of the actions in the speech acts hierarchy m a y generate alternative hypotheses.
 For example, sentence lb can be interpreted as a request to have the keys (indirect interpretation) or as an attempt to obtain .
some information about the capabilities of the hearer.
 The two interpretations correspond, respectively, to the activation, while moving upward on the speech act hierarchy, of the request and obtaininfo actions.
 The second special test concerns the actid predicate (see, for instance, the oiirecordreq node in Fig 1).
 This prepares the work for the third step (domainlevel analysis).
 As stated above, the output of the speechact analysis is the recognized speechact.
 However, some speechacts refer to an actual domain action; for instance, a request expresses the intention that the hearer does something, and that something is a domain action that must be encoded within the request (note that this is not the case for obtaininfo).
 The speechact hierarchy specifies this "type coercion" among levels: a surface imperative has as argument a semantic representation, while a request has, as argument, the corres|)onding domain action.
 Procedurally, this means that the usual ar.
tionidenti/icahon procedure is executed, so that its role in tlie overall processing is made explicit in the hierarchy.
 Example Given the sentence: 3) Posso chiedertt di darmi le chiavi della biblioteca? [May I ask you to give m e the keys of the library?]* The surfynquestion action is activated on the basis of the interrogative form; the third parameter of the action is instantiated with its propositional content, that refers to the node of the semantic representation (semi), associated to potere ('may').
 The instantiated surface speech act is: surfynquestion (User, System, S e m l ) ^ After the identification of this speech act, the analysis proceeds with the activation of the speech acts of which it is a substep or a specialization (upward expansion in the speech acts library (Carberry, 1988)): the directaskif and then the askif actions are activated.
 Note that surfaceynquestion could be considered as a direct substep of obtaininfo (in a 'generation' relation).
 However, the net specifies that a surfaceynquestion generates an askif, which in turn generates obtaininfo.
 In this way, we are able to factorize an effect (the Cint effect of askif) that is shared by obtaininfo and the other actions that are generated by askif (e.
g.
 indreql or hedgedperform as shown in Figure 1 and 2); on the contrary, the peculiarity of the obtaininfo (i.
e.
 the precondition of not knowing the answer) is kept separate (in fact, in indirect acts performed by means of a question, the speaker almost always knows the answer to the question).
 Moreover, this effect is inherited both by indirectaskif and directaskif through the specialization hierarchy.
 W h e n an action is in the decomposition of more than one speech act, more than one alternative hypothesis can be built (in the example, for the sake of simplicity, we only consider obtaininfo, indreql and hedgedperform).
 However, the domainlevel processing rejects the obtaininfo since here, as usual, it does not make sense that the speaker questions the hearer about her/his own capabilities; indreql can not be instantiated because the node associated with potere ('may') should have the hearer as semantic agent, while in the example the agent is the speaker (compare with sentence lb)^° .
 So, only hedgedperform is activated, because all its restrictions are satisfied.
 Since only one higherlevel action has been instantiated, no ambiguity arises in the ' Poi' the sake of siniplicily, the seinaiitic representation of the sentence hcis l)een given in a logical form, instead of as a semantic net.
 *In Italian both verbs 'may' and 'can' correspond to the modal potere.
 ®ln the actual implementation, the constants User, System and Keys (below) are nodes in the contextual representation standing for the reference to the associated individual.
 '"The analysis of the semantic and syntactic features is performed by the analyzer which, in this example, identifies the verb potere ('may') and the performative chtedere ('ask').
 320 interpretation of the user's utterance and the upward expansion goes on, extending the unique hypothesis.
 The onrecordreq and request actions are activated, so inter|)reting the sentence as a request by the user to \h'1form the donnain action: give (System, K«!ys, User), that i,s identified by means of an action identification phase.
 Here, this phase is carried out easily, because the request is posed explicitly and the identified action coincides with the one expressed by the user.
 The situation is very different for the so called offrecord requests (Brown k Levinson, 1987), where the speaker doesn't express in an explicit way the requested action, but s/he states one of her/his goals or s/he asks whether some precondition of the action is satisfied: e.
g.
 "I would like to open the library" or "Do you have the keys of the library, please?" In this cases, the requested actions must be inferred from the utterance using the knowledge about domain actions (the task is performed by the domain plan recognition process).
 Conclusions The paper has presented an approach for coping with indirect speech acts in an interpreter of natural language.
 A planbased representation of speech acts has been adopted.
 A major advantage consists in the strict integration of the processes of recognition of speech acts and domain plans.
 In fact, the same representation underlies both processes; however, the speech act analysis is affected also by the presence of some linguistic (syntactic and semantic) features which have been discussed in tlie paper.
 These features are related to the politeness of the request.
 The next step of our work will be an assessment of the evaluation of the politene.
ss level on the basis of the features detected in the sentences and of the intended impact of this level on the receiver of the message.
 The speechacts recognition algorithm is embedded in a planrecognition system for informationseeking dialogues in a subset of the University domain.
 The system is implemented in C o m m o n Lisp and runs on workstations.
 The speechacts analysis exploits the basic actionidentification and upwardexpansion procedures written for the recognition of the domain plans of the user of the system.
 Acknowledgments This work was partially supported by MURST 60% and by National Research Council (CNR), project "Pianificazione Automatica" References Airenti, G.
 & Bara, B.
 & Colombetti, M.
 (1993).
 Conversational and behavior games in the pragmatics of discourse.
 Cognitive Science, 17, 197256.
 .
Ardi.
ssono, L.
 fc Lesmo, L.
 & Pogliano, P.
 & Terenziani, P (1991).
 Representation of determiners in natural language.
 In Proc.
 12th U C A I (pp.
 9971002).
 Sydney, Australia.
 Ardissono, L.
 fc Lesmo, L.
 l̂  Sest.
ero, D.
 (1994).
 Updating the user model on the basis of the recognition of the user's plans.
 In Proc.
 Fourth International Conference on User Modeling (pp.
 510).
 Hyannis, Ma.
 Ardissono, L.
 & Lombardo, A.
 & Sestero, D.
 (1993).
 A flexible approach to cooperative response generation in informationseeking dialogues.
 In Proc.
 31st Annual Meeting A C L (pp.
 274276).
 Columbus, Ohio.
 Ardissono, L.
 & Sestero, D.
 (1995).
 Using dynamic user models in the recognition of the plans of the user.
 User Modeling and UserAdapted Interaction, to appear.
 Austin, J.
L.
 (1962).
 H o w to Do Things with Words.
 Harvard University Pre&s.
 Brown, P.
 &; Levinson, S.
C.
 (1987).
 Politeness: some universals on language usage.
 Cambridge University Press.
 Carberry, S.
 (1988).
 Modeling the user's plans and goals.
 Computational Linguistics, 2 (pp.
 2337).
 Carberry, S.
 (1990).
 Plan Recognition m Natural Language Dialogue.
 ACLMIT Press.
 Di Eugenio, B.
 &: Lesmo, L.
 (1987).
 Representation and interpretation of determiners in natural language.
 In Proc.
 10th U C A I (pp.
 648653).
 Milano, Italy.
 Hinkelman, E.
A.
 & Allen, J.
F.
 (1989).
 T w o constraints on speech act ambiguity.
 In Proc.
 27th Annual Meeting of A C L (pp.
 212219).
 Vancouver, Canada.
 Kasper, G.
 (1990).
 Linguistic politeness: Current research issues.
 Journal of Pragmatics, 14 (pp.
 187218).
 Kautz, H.
 (1990).
 A circumscriptive theory of plan recognition.
 In P.
R.
 Cohen, J.
 Morgan, and M.
E.
 Pollack (Eds.
), Intentions in communication (pp.
 105133).
 M I T Press.
 Lambert, L.
 (1993).
 Recognizing Complex Discourse Acts: A Tripartite PlanBased Model of Dialogue.
 Doctoral dissertation.
 University of Delaware.
 Leech, G.
 (1983).
 Principles of Pragmatics.
 Longman, Cambridge.
 Lesmo, L.
 k Terenziani, P.
 (1988).
 Interpretation of nounphrases in intensional contexts.
 In Proc.
 Coling Budapest (pp.
 378383), Budapest, Ungheria.
 Litman, D.
 & Allen, J.
 (1987).
 A plan recognition model for subdialogues in conversation.
 Cognitive Science, 11 (pp.
 163200).
 Pollack, M.
E.
 (1990).
 Plans as complex mental attitudes.
 In P.
R.
 Cohen, J.
 Morgan, & M.
E.
 Pollack (Eds.
), Intentions in communication (pp.
 77103).
 M I T Press.
 Searle, J.
R.
 (1969).
 Speech Acts: an Essay m the Philosophy of Language.
 Cambridge University Press, Cambridge.
 321 C o n s i d e r i n g E x p l a n a t i o n Failure d u r i n g C o n t e n t P l a n n i n g Ingrid Zukerman Department of Computer Science Monash University Clayton, Victoria 3168, AUSTRALIA ingridObruce.
cs.
monash.
edu.
au Richard McConachy Department of Computer Science Monash University Clayton, Victoria 3168, AUSTRALIA rickyCbruce.
cs.
monash.
edu.
au Abstract Content planning systems generate explanations to achieve a communicative intent, often with respect to a particular audience.
 However, current research in content planning does not take into consideration the fact that an addressee may stop paying attention to an explanation because of boredom or cognitive overload.
 In this case, the generated explanation fails to achieve the communicative intent.
 In this paper, we present a computational representation of boredom and cognitive overload, and cast the problem of content planning as a constraintbased optimization problem.
 The objective function in this problem is a probabilistic function of a user's beliefs, and the constraints Jire restrictions pl<iced on the boredom And cognitive overload the user can experience, and on the minimal level of expertise the user should achieve.
 W e discuss two techniques for solving the optimization problem, zind consider two types of constraints for addressing the expertise requirements.
 W e also examine how variations in the populations to which constraints are applied affect the generated discourse.
 Introduction Current research in content planning focuses on planning discourse that achieves an intended communicative goal, often with respect to a particular audience, e.
g.
, (Paris, 1988; Moore & Swartout, 1989; Cawsey, 1990; Zukerman & McConachy, 1993b).
 However, this research does not take into consideration the fact that an addressee may get bored or may be unable to follow the thread of the explanation, and stop listening to the speaker.
 In this case, regardless of how carefully the discourse has been planned, it will fail to achieve the intended communicative goal.
 In this paper, we present a content planning mechanism which addresses this problem.
 Our mechanism generates a set of Rhetorical Devices (RDs) which achieves as much of the intended communicative goal as possible, while ensuring that the user does not experience boredom or cognitive overload, and that s/he achieves at least a minimum level of expertise.
 A n R D consists of a rhetorical action, such as Assert or Instantiate, applied to a proposition.
 A set of R D s typically contains (1) R D s that convey the intended propositions, (2) subordinate sets of R D s that present prerequisite or referring information, and (3) R D s that address erroneous inferences.
 These R D s are then organized by the discourse structuring procedure described in (Zukerman & McConachy, 1993a), and rendered in English by the Functional Unification Grammar described in (Elhadad, 1992).
 Table 1 illustrates two types of discourse generated by our mechanism to convey information about photosynthesis to a fairly weak student.
 The discourse on the lefthandside contains all the information that the system deems necessary to achieve the intended communicative goal.
 In contrast, the discourse on the righthandside is considerably shorter, since the system anticipates that the student will get bored with the longer text, and hence decides to present only the R D s that convey the gist of the communicative goal.
 In the following section, we discuss factors that cause explanation failure.
 Next, we specify the optimization problem, and describe two procedures that solve this problem: (1) full optimization, and (2) partial optimization combined with heuristics.
 W e then analyze the effect of variations in constraints on the discourse generated by our system, and present concluding remarks.
 Factors that cause explanation failure A n explanation fails to achieve an intended communicative goal when the addressee stops listening to it.
 Two factors that lead to this behaviour are boredom and cognitive overload.
 Our measures for anticipating whether the discourse being planned is likely to cause boredom or overload are based on the following observations.
 Boredom due to excessive discourse length.
 Most people find many instructional texts inherently uninteresting.
 Hence they get bored if instructional discourse is too long.
 The length of discourse a user can tolerate depends on his/her ability and attitude, e.
g.
, weak students are generally less able to cope with long discourse than stronger students.
 Boredom due to unnecessary RDs.
 People get bored if discourse contains information that they already know or can infer eeisily.
 W h e n a speaker addresses a heterogeneous audience, and aims the presentation at the average addressee, the addressees that are better than average are likely to experience this type of boredom.
 Cognitive overload.
 People experience cognitive overload when they cannot integrate the pieces of an explanation to form a coherent body of knowledge [Just & Carpenter, 1987].
 This can happen because they need to follow a lengthy argument or assimilate large amounts of background or clarifying information.
 Lengthy argu322 Table 1: Sample discourse with/without considering boredom Without considering boredom Plants photosynthesize.
 This process consumes water, carbondioxide and nutrients, and produces glucose and oxygen.
 Plants use light, which is a form of energy, to photosynthesize.
 However, plants cannot use other forms of energy to photosynthesize.
 Plants contain chlorophyll, which is a green pigment that absorbs light.
 However, chlorophyll does not absorb green light.
 In addition to photosynthesizing, plants respire.
 Respiration consumes oxygen and glucose, and produces carbon dioxide and water.
 Plants photosynthesize more than they respire.
 Therefore, plants produce more oxygen than they consume.
 Considering b o r e d o m Plants photosynthesize.
 This process produces oxygen.
 Plants also respire.
 This process consumes oxygen.
 Plants photosynthesize more than they respire.
 Therefore, plants produce more oxygen than they consume.
 ments are often required when the addressee has to make large changes in belief; while large amounts of background or clarifying information are indicative of relatively small shifts with respect to several beliefs.
 Cognitive overload also takes place when an addressee has difficulty understanding parts of an explanation.
 However, this situation is identified in our system, and corrected by generating supporting, background or clarifying information, thus yielding the two above mentioned cases.
 The prediction of boredom and cognitive overload requires information regarding the length of discourse, the amount of known or easily inferred information, and the maximum shift in belief an addressee can tolerate.
 In the current research, these thresholds are determined for stereotypical user models by testing the effect of different values on the discourse, while ensuring that they make sense relative to each other.
 For example, strong students can usually cope with a higher cognitive load than weak students.
 Predicting boredom due to excessive length W e compare the length of the discourse with the maxim u m length which an addressee can presumably tolerate.
 A good approximation of the length of a piece of discourse is simply the number of R D s in the discourse |{/2Z?},aid| Clearly, this approximation can sometimes be wrong, but it is not productive to realize a piece of discourse currently being planned just to measure its exact length.
 Thus, the requirement to avoid boredom due to excessive length is expressed by the following formula: \{RD}.
U < TRDmariM) (1) where T R D m a x { M ) is the maximum number of R D s a user who belongs to user model M can tolerate.
 Predicting boredom due to unnecessary RDs W e determine the amount of planned discourse that is already known or can be easily inferred by the addressee, and compare it with the amount of such superfluous discourse that the addressee can presumably tolerate.
 The superfluous part of the discourse is the difference between the planned discourse and what really needs to be said to achieve a communicative goal.
 Thus, the requirement to avoid boredom due to unnecessary R D s is expressed by the following formula: \{RD).
aid  {RDUduc.
d{M)\ < URDmariM) (2) where {RD},aid is the set of RDs generated, {RD}reducediM) is the most reduced version of {RD},aid that can still convey the intended propositions to an addressee who belongs to a particular model M , and U R D m a x { M ) is the m a x i m u m number of unnecessary R D s a user who belongs to user model M can tolerate.
 {RD}redviced{M) is obtained by removing R D s from {RD},aid so long as the communicative goal is still achieved with respect to model M .
 W h e n removing an R D , we also remove the R D s that depend only on this R D , i.
e.
, the sets of R D s that convey prerequisite and referring information for this R D only, and the R D s that contradict erroneous inferences from this R D .
 Predicting cognitive overload W e compare the total shift in belief required by the communicative goal with an addressee's conjectured ability to tolerate shifts in belief.
 The total shift in belief required to achieve a communicative goal depends on an addressee's current beliefs and on the inferences s/he is likely to make.
 For instance, a user who has strong erroneous beliefs will need to make more adjustments than a user whose beliefs are close to the intended ones.
 W e distinguish between three types of propositions for the purpose of predicting cognitive overload: P  propositions that were previously unknown or correctly believed by the user; P'  propositions that were wrongly believed by the user and must now be contradicted; and P  propositions that were wrongly inferred by the user as a result of discourse planned to convey P or >P' and must now be contradicted.
 The difficulty associated with the different types of shifts in belief is represented by F factors as follows.
 F p { M ) reflects the amount of effort required to acquire new information, Fpi{M) reflects the amount of effort required to reverse a previous belief, and F p { M ) reflects the amount of effort required to reverse a new inference {Fp{M) < F p { M ) < Fp>(M)).
 These factors depend on the type of the user, e.
g.
, a strong student usually has stronger convictions than a weak 323 Table 2: Propositional input that yields the sample texts Propositions to be Conveyed Intended Degree" of Belief Significance ^[plants doaction photosynthesis] photosynthesis consume water] photosynthesis consume carbondioxide] photosynthesis consume nutrients] photosynthesis produce glucose] ^[photosynthesis produce oxygen] plants doaction photosynthesis (use light)] plants contain chlorophyll] '̂ [plants doaction respiration] •[respiration consume oxygen] respiration consume glucose] respiration produce carbondioxide] respiration produce water] plants doaction photosynthesis(Ar)] plants doaction respiration(y)] plants produce oxygen(Z)] plants consume oxygen(VV')] * [ Z > W ] BELIEVED RATHER BELIEVED RATHER BELIEVED BELIEVED RATHER BELIEVED BELIEVED BELIEVED RATHER BELIEVED BELIEVED BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED CRITICAL MEDIUM MEDIUM HIGH MEDIUM CRITICAL HIGH HIGH CRITICAL CRITICAL MEDIUM MEDIUM MEDIUM HIGH HIGH student, and hence will have more difficulty reversing a belief.
 The following formula expresses the total weighted shift in belief experienced by a user who belongs to model M when attempting to achieve an intended degree of belief with respect to a set of propositions.
 Tshift{M) = ^fsHIFTM{p)FpiM) + pep ^ fSHIFTm{p)Fp'{M) + peP' Y.
fsHIFTM{p)Fp{M) p&p where fshiftf^ (p) represents the contribution of proposition p to Tshift{M).
 This contribution is the absolute value of the difference between the actual and the previous belief in p for a user who belongs to model M .
̂ fshiftM^P)  |te/ae(M(P) " ^e/<,/d;^ (p)| Thus, the requirement to avoid a total shift in belief which results in cognitive overload is expressed by the following formula: Tshift{M) < belshiftma^iM) (3) where belshift^axi^) is the m a x i m u m shift in belief a user who belongs to model M can tolerate.
 The Content Planner Our mechanism uses a constraintbased optimization procedure whose objective is to maximize a user's belief with respect to a set of intended propositions, and ^The 'actual' degree of belief is conjectured by means of a function which simulates a user's change in belief as a result of a piece of discourse.
 This function depends on the user's ability and on the complexity and abstractness of the information (Zukerman & McConachy, 1993b).
 whose constraints are restrictions placed on the boredom and cognitive overload the user m a y experience, and on the minimum level of expertise the user should achieve.
 Our system receives two types of input: propositional and usermodel related.
 The propositional input contains (1) a set of propositions to be conveyed; (2) the degree of belief the user is expected to achieve with respect to each proposition; and (3) the significance of each proposition, i.
e.
, how important it is that the user believes it.
 These last two inputs are often correlated.
 However, using separate measures for these inputs allows us to model cases that differ from the norm.
 For example, when conveying background information for an intended proposition it is crucial that a user acquire at least a passing acquaintance with the information in question.
 Table 2 shows the propositional input from which the texts in Table 1 are generated.
 The text on the lefthandside of Table 1 conveys all the input propositions, while the text on the righthandside conveys only the propositions marked with an asterisk (•).
 The usermodel related input is a space of user models accompanied by a probability distribution.
 The probability distribution may be interpreted either as the system's uncertainty regarding which model(s) a particular user belongs to, or as the percentage of a group of addressees that belongs to each of these models.
 The models are used to determine the information that needs to be presented to achieve a given communicative goal with respect to a particular audience.
 Each model represents the beliefs, inference patterns and attitude of a particular type of user.
 The attitude models a user's ability to understand abstract information, his/her confidence in his/her inferences, and the length of discourse, cognitive overload and amount of unnecessary R D s s/he is likely to tolerate.
 In the current implementation we maintain five stereotypical user models: excellent, good, average.
 324 Table 3: Set of R D that yields the unconstrained sample text Assert[plants doaction photosynthesis] Assert photosynthesis consume water] Assert photosynthesis consume carbondioxide] Assert photosynthesis consume nutrients] Assert photosynthesis produce glucose] Assert photosynthesis produce oxygen] Assert plants doaction photosynthesis (use light)] oAssert[light isa formofenergy] oNegate[plants doaction photosynthesis (use otherformofenergy)] Assert[plants contain chlorophyll] oAssert[chlorophyll isa greenpigment] oAssert[chlorophyll absorbs light] oNegate[chlorophyll absorbs greenlight] Assert[plants doaction respiration] oMention[plants doaction photosynthesis] Assert[respiration consume oxygen] Assert respiration consume glucose] Assert respiration produce carbondioxide] Assert respiration produce water] doaction respiration}] oxygen}] Compare Compare {plants doaction photosynthesis} > {plants {plants produce oxygen} > {plants consume mediocre and weak (a detailed description of these models appears in (Zukerman & McConachy, 1993b)).
 The output of the content planner is a set of RDs which are related to each other by means of discourse relations such as prerequisite and causality (Mann k Thompson, 1987).
 Table 3 contains the set of RDs which yields the text on the lefthandside in Table 1 (without the discourse relations).
 The RDs marked with a diamond (o) convey background information and contradict erroneous inferences.
 Specification of the Optimization Process The objective of the optimization process is to plan discourse that minimizes the distance between the actual and the intended degree of belief with respect to a list of intended propositions without violating the boredom, overload and minimumexpertise constraints.
 The belief objective must be achieved probabilistically with respect to all user models.
 Further, we emulate behaviour whereby speakers make sure that important propositions are conveyed, while placing less emphasis on less important propositions.
 To this effect, we take into consideration both the significance of the intended propositions and the degree to which these propositions are to be believed upon completion of the discourse.
 This yields the following objective function for the optimization process: ^MJ2il2fBEL{p)Si9ip)}Prob{M)} (4) where fBELuiP) M fO if |6e/actM(P)̂ *«''n'(P)l ̂^^ s%gn{helactM {p))=sign{bel,nt (p)) \belact,̂ ip)6e/,„t(p)| otherwise.
 Sig{p) is the significance or importance of a proposition, and fBEiip) represents the contribution of proposition p to the objective function.
 This contribution is 0 if belactMip) exceeds or equals the intended belief in P, beli„i{p), for a user who belongs to model M.
 Otherwise, it is the absolute value of the difference between the intended and the actual belief in p.
 The boredom and overload constraints are expressed by Equations (13).
 However, in order to take into consideration the system's uncertainty regarding which model a user belongs to, we moderate the thresholds by a function which relaxes the constraints as the probability that the user belongs to a particular model decreases.
 The following formulation specifies one constraint for each type of explanation failure and each user model: For i € {excellent, good, average, mediocre, weak } Boredom (length) \{RD},aid\ < TRDma.
iMi) • fproi{Mi) (5) Boredom (unnecessary RDs) \{RD},aid{RD]reduced{Mi)\<URDmaAMi}fprobiMi) (6) Overload TsHiFTiMi) < belshtft^,,{Mi) • fprot{Mi) (7) In addition, we propose two alternative formulations for expertiserelated constraints: ^^T.
^^fB^^'(P)S'9{p)}Prob{M) < Thr (8) M p For i e {excellent, good, average, mediocre, weak } 5]te/act^,(p)5i</(p) > Prc<M.
 ^fee/,„,(p)5i>(p) (9) p P Equation 8 stipulates that the average shortfall from the intended level of expertise weighted across all user models should not exceed a certain threshold (the shortfall is averaged over the number of propositions to be conveyed).
 This constraint, which is placed on the objective function, ensures that an adequate level of expertise is achieved on average for each proposition over all the user models.
 In contrast.
 Equation 9 demands that a user who belongs to a particular model attain a certain percentage of the intended level of expertise.
 For example, a weak student may be expected to attain at least 50% of the intended expertise, while an excellent student may be expected to attain at least 90%.
 The above constraints are not necessarily applied to all user models with nonzero probability.
 Given a (possibly 0) top margin and bottom margin, the system drops \{P)\325 from consideration the models at the tail of the distribution whose probabilities fall within these margins.
 For instance, an input such as (10%, 20%) means that the constraints are not applied with respect to the model(s) whose probabilities fall within the top 1 0 % or the bottom 2 0 % of the usermodel distribution.
 In addition, we have used Equation 9 in two different ways: (1) applied to all user models that are being considered, and (2) applied to the weakest user model under consideration.
 The above formulation yields a nonlinear integer optimization problem even without the constraints.
 Hence, a we2ik search method is applied.
 W e have implemented two methods to solve this problem: (1) a full optimization (Zukerman & McConachy, 1995), and (2) a partial optimization combined with heuristics.
 If these methods cannot find a solution that satisfies all the constraints, they relax the communicative goal, i.
e.
, they convey some propositions to a lesser extent than originally specified and/or give up conveying some propositions altogether.
 This approach is suitable for a situation where time is running short, and the information provider is willing to forego the conveyance of nonessential information so long as crucial information is conveyed.
 A n alternative approach which consists of relaxing the singlediscourse requirement, i.
e.
, conveying the same amount of information in separate chunks of discourse, is described in (Zukerman & McConachy, 1995).
 Full optimization This procedure first determines minimally sufficient sets of R D s which convey all the propositions for each user model, where a set of R D s is minimally sufficient if the removal of any R D causes the set to stop conveying the intended information.
 It then iteratively selects the set of R D s with the best objective function among the sets of R D s which satisfy all the constraints, and generates R D s that convey prerequisite and referring information for the selected set of RDs.
 The resulting set of RDs, i.
e.
, the selected set plus the R D s which convey its referring and prerequisite information, is added to the pool of candidate sets, and its constraints are recalculated.
 The optimization process terminates when it finds a set of R D s which satisfies all the constraints and requires no additional prerequisite or referring information.
 If all the candidate sets of R D s violate one or more constraints, the communicative goal is relaxed as follows.
 The system successively removes one R D from each set of R D s that satisfies the expertise constraint(s), and inspects the effect of each removal on the constraint(s) and the objective function.
 During this process, when removing an R D we also remove the R D s that depend only on this R D (as when generating {RD}reduced while predicting boredom due to unnecessary RDs).
 Each reduced set of R D s which results from this process satisfies all the constraints while yielding an objective function whose value is worse than before.
 Partial optimization This procedure first applies the mechanism described in (Zukerman & McConachy, 1994) to generate the optimal set of R D s for each of the user models being considered.
 The sets of R D s are then sorted with the value of the objective function as the primary sorting key, and the number of constraints violated as the secondary key.
 The highestranked set that violates no constraints is then selected.
 If all the sets of R D s violate one or more constraints, the communicative goal is relaxed as follows.
 The system selects the topranked set of RDs, and applies rules which take into consideration the significance and the intended shift in belief of the propositions to be conveyed in order to select a proposition which may be conveyed to a lesser extent (or not at all).
 These rules select first propositions of low significance, next propositions of medium significance which require a low or medium shift in belief, and so on.
 One of the R D s that conveys the selected proposition is then removed, and the constraints and objective function are recalculated.
 If the resulting set of R D s violates no constraints, it is selected for presentation.
 Otherwise, the set of R D s is reranked according to the value of its objective function and the number of constraints it violates, and the process is repeated.
 Results The system was run with several combinations of the following parameters: (1) the two optimization procedures; (2) the two constraints for minimum expertise, where Equation 9 was applied in two modes: to all user models and only to the weakest user model; and (3) the two types of target populations, viz all the user models and only user models that fall inside specified margins.
 The application domains included technical areas such as nuclear fission, chemistry and biology.
 W h e n boredom constraints are turned off there is no penalty for excessive length or unnecessary RDs, hence the generated text includes examples, background information and elaborations to ensure that the material is conveyed (lefthandside of Table 1).
 W h e n constraints pertaining to boredom due to length are activated, RDs that convey propositions of lower significance tend to be omitted first (righthandside of Table 1).
 If a proposition with a higher significance requires many RDs, then these R D s become good candidates for omission.
 W h e n overload constraints are activated, propositions that require a large shift in belief are removed.
 This is illustrated in the example in Table 4, where the R D that conveys proposition 1 and its dependent, the R D that conveys proposition 2, are removed.
 In contrast, when constraints pertaining to boredom due to length are activated for this example, propositions 3 and 4 are omitted (proposition 6 remains because it is linked to proposition 5).
 W h e n both types of boredom constraints are activated, if the probabilities of the user models are evenly distributed, the only way to satisfy both sets of constraints is to convey very little information, yielding an objective function with a high value.
 In this case, following accepted teaching practices, the system relaxes the unnecessaryRDs constraints, i.
e.
, it gives a higher priority to the requirements of the weaker user models.
 The full optimization procedure takes between 3060 326 Table 4: Sample discourse considering overload versus boredom due to length Propositions to be Conveyed 1.
 Network covalent substances sublime, 2.
 which is going from a solid state directly to vapor.
 3.
 Ionic substances melt.
 4.
 Metallic substances melt.
 5.
 Metallic substances are flexible, 6.
 but ionic substances are not flexible.
 Intended Degree of Belief BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED RATHER BELIEVED Significance HIGH HIGH MEDIUM MEDIUM HIGH MEDIUM seconds of C P U time on a SPARCstation2.
 The partial optimization combined with the heuristic function cuts the processing time significantly (by 1/4  2/3 depending on the number of violated constraints and the relationship between the intended propositions).
 In general, the full optimizer conveys more propositions (at least partially) than the partial optimizer, and yields a better objective function.
 In contrast, the partial optimizer generally achieves larger belief shifts for the propositions that are not removed.
 There is a marked diff"erence between the discourse generated by the partial and the full optimizer when the content planner initially generates a small set of R D s to convey a few propositions that are strongly related to each other (where the R Ds generated to convey one proposition affect the others).
 In this case, the partial optimizer relaxes the communicative goal by removing one of the R D s from the set of RDs, while the full optimizer often replaces the entire set of R Ds with a different, smaller set.
 The two formulas representing expertiserelated constraints affect the system's output as follows.
 If Equation 9 is used with respect to models that are not strongly represented in the user population, the output will be markedly different from the output obtained when Equation 8 is used.
 This happens because Equation 9 forces the system to address the needs of these models, while Equation 8 largely ignores these models owing to their small relative probability.
 Finally, ignoring portions of the population that fall below the bottom margin yields more concise text, since less explanations need to be presented, while ignoring the portions that fall above the top margin allows the system to generate more R Ds without violating the unnecessaryRDs constraints.
 Conclusion W e have oflfered a computational definition of three causes of explanation failure: cognitive overload, boredom due to excessive discourse length and boredom due to unnecessary RDs.
 W e have ceist content planning as a constraintbased optimization process which takes into account a speaker's uncertainty regarding the user model to which an addressee belongs.
 In this process, the constraints represent requirements placed on the addressee's boredom and overload, and on the level of expertise s/he is expected to attain, and the objective function is a probabilistic function of the extent to which the communicative goal has been achieved.
 W e have discussed two procedures for solving this problem in combination with two types of expertiserelated constraints, and we have considered the effect of ignoring segments of the user population that are at the tail of the distribution.
 References Cawsey, A.
 (1990).
 Generating Explanatory Discourse.
 In R.
 Dale, C.
 Mellish t M.
 Zock (Eds.
), Current Research in Natural Language Generation (pp.
 75102), Academic Press.
 Elhadad, M.
 (1992).
 F U G : The Universal Unifier User Manual Version 5.
0 (Technical Report).
 Columbia University, New York, New York.
 Just, M.
A.
 & Carpenter, P.
A.
 (1987).
 The Psychology of Reading and Language Comprehension, Allyn and Bacon, Inc.
 Mann, W.
C.
 & Thompson, S.
A.
 (1987).
 Rhetorical Structure Theory: A Theory of Text Organization (Technical Report ISI/RS87190).
 Information Sciences Institute, Los Angeles, California.
 Moore, J.
D.
 k Swartout, W.
R.
 (1989).
 A Reactive Approach to Explanation.
 In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence (pp.
 15041510), Morgan Kaufmann Publishers.
 Paris, C.
L.
 (1988).
 Tailoring Object Descriptions to a User's Level of Expertise.
 In Computational Linguistics 14(3), 6478.
 Zukerman, I.
 & McConachy, R.
S.
 (1993a).
 A n Optimizing Method for Structuring Inferentially Linked Discourse.
 In AAAI93 Proceedings  the National Conference on Artificial Intelligence (pp.
 202207), A A A I Press.
 Zukerman, I.
 & McConachy, R.
S.
 (1993b).
 Consulting a User Model to Address a User's Inferences during Content Planning.
 In User Modeling and User Adapted Interaction 3(2), 155185.
 Zukerman, I.
 & McConachy, R.
S.
 (1994).
 Being Concise versus Being Shallow: T w o Competing Discourse Planning Paradigms.
 In ECAI94 Proceedings  The European Conference on Artificial Intelligence (pp.
 515519), John Wiley & Sons.
 Zukerman, I.
 & McConachy, R.
S.
 (1995).
 Generating Discourse across Several User Models: Maximizing Belief while Avoiding Boredom and Overload.
 To appear in IJCAI95 Proceedings  the International Joint Conference on Artificial Intelligence, Morgan Kaufmann Publishers.
 327 Structural Focusing, Thematic Role Focusing and the Comprehension of Pronouns Rosemary J.
 Stevenson Human communication Research Centre.
 Department of Ps)'cholog>.
 Universitj of Durham.
 Durham, DHl 3LE, U.
K.
 rosemary.
stevenson@durham.
ac.
uk Agnieszka J.
 Urbanowicz Department of Computer Science University of Ehxrham Durham DHl 3LE UK a.
j.
urbanowicz@durham.
ac.
uk Abstract W e descnbe an experiment to test the view that structural focusing and thematic role focusing are distinct.
 Subjects were presented >Mth 2clause sentences containing because or so The first clause introduced two individuals occupying the thematic roles Goal and Source, while the subject of the second was either a pronoun or repeated name.
 Results showed that reading times for the second clause were facilitated when the pronomis referred to the Goal rather than Source, particularly when the clauses were connected b> so.
 This facilitation occurred regardless of the surface position of the Goal and regardless of tlie type of anaphor, pronoun or repeated name.
 With pronouns, facilitation also occurred when the antecedent was in the first position in its clause, but onh when the antecedent was the Source.
 With Repeated Names, reading times were slowed when the antecedent was in the first position, regardless of its thematic role.
 These findings suggest that there are two foci in an utterance, one containing the first noun phrase in the utterance and the other containing the preferred thematic role.
 W e suggest that the focus based on initial mention corresponds to the forward lookmg center described by Grosz et al.
 (1963) and that the focus based on thematic roles is part of the global focus (Grosz and Sidner, 1986).
 W e also discuss the implications of our results for Sanford and Garrod's (1981) scenario mapping model.
 Introduction The interpretation of pronouns is a central problem in discourse comprehension.
 The major issue that needs to be explained is h o w pronouns are understood so readily despite the fact that they contain little information to assist interpretation and are frequently ambiguous.
 A number of attempts to soh e this problem make use of the notion of focusing.
 In a focusbased model, discourse entities are not equally weighted.
 Instead, they are ranked according to their salience, with the most highly ranked entity being the most accessible as a the antecedent for a pronoun.
 Focusing models differ in what they regard as the mechanism underlying focusing.
 Different researchers have argued for structural focusing (e.
g.
 Grosz.
 Joshi and Weinstein.
 1983), semantic/pragmatic focusing (e.
g.
 Stevenson, Crawley and Kleinman, 1994) and focusing based on background knowledge of the topic of the discourse (e.
g.
 Sanford and Garrod, 1981).
 In this paper, w e argue that structural focusing and semantic/pragmatic focusing achieve their eflFects through different mechanisms.
 Work on structural focusing can be found in the computational literature, with Grosz et al.
's centering theory giving the most explicit account.
 According to Grosz et al, all discourse entities in an utterance are stored in a set of forward looking centers (abbreviated here as Cfs) that are ranked according to their salience.
 The Cfs link the current utterance to the subsequent one by providing potential antecedents for a pronoun.
 In addition, each utterance, except the first in a discourse, also contains a backward looking center (Cb) that links the current utterance to the previous one by being the preferred site for a pronoun.
 According to Gordon, Grosz and Gilliom (1993) and others, the C b also refers to the highest ranked Cf and is normally the subject of the sentence.
 The factors that affect the ranking of the Cf are not completely determined, but in general, surface position, grammatical role, being the C b of the utterance, and (in Japanese) empathy are thought to interact to determine ranking (Brennan, Friedman and Pollard, 1987; Kameyama, 1986; Walker.
 lida and Cole, 1994).
 There is growing psychological evidence to support the main tenets of centering theory.
 First, pronouns in subject position that refer to the highest ranked Cf of the preceding utterance are interpreted more rapidly than repeated names in subject position (Gordon et al.
.
 1993; Hudson D'Zmura, 1988.
 Hudson, Tanenhaus and Dell, 1986).
 This is attributed to an expectancy efifect (Hudson D'Zmura, 1988) because the subject position is the preferred site of the Cb, which is normally a pronoun referring to the highest ranked Cf Second, subject pronouns referring to the highest ranked Cf are interpreted more rapidly than subject pronouns referring to a lower ranked Cf (Hudson D'Zmura, 1988, Hudson et al.
, 1986).
 This can be attributed to structural focusing because the most accessible antecedent for a pronoun is the highest ranked Cf.
 Semantic/pragmatic focusing has long been recognised in the psychological literature through work showing that the causal bias of a verb can affect the ease w ith which a pronoun can be resolved.
 For example, in a sentence continuation task using sentence fragments containing because.
 Garvey and Caramazza (1974) found consistent preferences for assigning a pronoim at the end of the 328 mailto:rosemary.
stevenson@durham.
ac.
ukmailto:a.
j.
urbanowicz@durham.
ac.
ukfragment to either the first noun phrase of a sentence (NPl) or the second noun phrase (NP2).
 The>' argued that when the verb imputed the cause of the action to the first noun phrase, an h4Pl bias was observed, but when the \crb imputed the cause of the aaion to the second noun phrase, an NP2 bias was observed.
 Further support for the idea that verbs affect the accessibilit> of an antecedent comes from studies of the time taken to make pronoun assignments (Caramazza, Grober.
 Gar\ey and Yates, 1977) and from probe recognition tasks (Stevenson, 1986).
 More recently, Stevenson, Crawley and Kleinman (1994) have shown that these verb bias effects reflect preferences for certam thematic roles rather than others.
 Stevenson et al.
 used sentence continuation tasks where the sentence fragments contained pairs of thematic roles and found that people preferred to assign a pronoun to the thematic role associated with the consequences of the event described by the fragment.
 For example, when completing sentence firagments containing Goal and Source thematic roles, as in the examples below, the continuations revealed that the pronoun was most likely to be assigned to the Goal, regardless of whether it was mentioned first or second in its clause.
 (1) John seized the comic from Bill and he (Goal in first position) (2) John passed the comic to Bill and he (Goal in second position) Similar results were found for fragments containing Agent and Patient thematic roles, where the preference was for the Patient.
 In addition though, there was also an effect of surface position: first mentioned antecedents were preferred to second.
 Thus, there was evidence of structural focusing alongside thematic role focusing, although focusing due to thematic role produced the strongest effects.
 The thematic role focusing was attributed to the fact that Goals and Patients are associated with the consequences of events and it is the consequences of the described event that are most highly focused in a model of the discourse.
 To test this idea, continuations were obtained for sentence fragments ending in either 'so' or •because'.
 It was anticipated that 'so' would reinforce the preference for consequences while "because' would modify' it.
 This is because 'so' directs attention to the consequences of an event while "because' directs attention to the initiating conditions (the cause) of an event.
 The results confirmed the predictions, thus supporting the view that the thematic role preferences arise because the individual associated with the consequences of a described e\ent is the most highly focused in a model of the discourse, However, Stevenson et al.
 also found e\idence to suggest that structural focusing is distinct from thematic role focusing.
 In their experiments, they included conditions in which the sentence fragments did not contain a pronoun In these cases too there was a preference for the first person mentioned in the continuation to refer to the thematic role associated with the consequences of the described event.
 Goal or Patient.
 However, the choice of referring expression, pronoun or repeated name, depended on the suiface position/grammatical role' of the antecedent.
 Pronouns were used to refer to the first mentioned antecedent while repeated names were more likelj to be used to refer to the second mentioned antecedent.
 These results support Gordon et al.
's notion of a C b that is the expected site of a pronoun and suggest further that the choice of referring expression is governed by structural focusing, while the choice of antecedent is governed b>' thematic role focusing.
 The purpose of this experiment was to test the proposition that structural and thematic role focusing are distinct.
 Subjects were presented with 2clause sentences containing either "because' or 'so'.
 The first clause contained Goal and Source thematic roles, while the subject of the second clause was either a pronoun or a repeated name that referred to one of the two thematic roles.
 Reading times were measured for the second clause.
 W e expect both structural focusing and thematic role focusing to influence the reading times.
 Taking the Pronoun sentences first, the times should be facilitated when the pronoun refers to the Goal.
 This facilitation should occur regardless of the surface position of the Goal, since a subject pronoun (the C b in Grosz et al.
's terms) normally refers to the most highly ranked Cf, and according to Stevenson et al.
 s data, this will be the Goal.
 W e also expect the reading times to be facilitated when the pronoun refers to the first mentioned antecedent.
 as predicted by centering theory, since Stevenson et al.
 observed an effect of surface position as well as of thematic role.
 However, it is also possible that structural effect will be modified by focusing due to thematic role, since thematic role focusing took precedence over structural focusing in Stevenson et al.
's study.
 Finally, since thematic role focusing is modified by the focusing properties of the connective, w e also expect the reading time facilitation due to thematic roles to be mostly confined to So sentences.
 In the Repeated N a m e sentences, we also expect to find facilitation due to thematic role focusing, since Stevenson et al.
 found a preference for references to the Goal e\en when the continuation contained a name.
 For structural focusing, w e are concerned in these sentences with the expectancy effect, Gordon et al, (1993), HudsonDZmura (1988) and Hudson et al, (1986) have all found that when an anaphor is in subject position and refers to the highest ranked Cf in the previous utterance, reading times are slowed when the anaphor is a repeated name as opposed to a pronoun.
 In our experiment, w e cannot directly compare the Pronoim and Repeated N a m e conditions because the conditions were presented to independent groups of subjects.
 However, if structural focusing is distinct from thematic role focusing, then in the present experiment this would mean that repeated names should lead to slower times only when the antecedent is the structural focus, that is, the first mentioned noun phrase.
 Finally, as was the case ' The surface positions and grammatical roles of the antecedents COvaried in the experiments.
 329 with Pronoun sentences, we expect thematic role focusing to be more e\ ident in So than Because sentences.
 Method Subjects.
 The subjects were 32 student volunteers from the Universit) of Durham.
 Materials and Design: Each subject read 32 sentences containing either pronouns or names.
 In all other respects the materials were identical for the two groups of subjects.
 All the sentences consisted of two clauses connected b\ either because or so.
 The first clause introduced two indi\iduals occupying Goal and Source thematic roles and the second clause contained either a pronoun or a repeated name that referred to one of these two individuals.
 In half the sentences, the Goal was mentioned first in the clause and in the other half it \\as mentioned second.
 In half the Pronoun sentences, the content of the second clause biased the assigrunent of the pronoun to the Goal.
 In the remaining half, it biased the assignment to the Source.
 The same content also appeared in the Repeated Name sentences.
 There were therefore foiu factors in the experiment, all but the first being repeated across subject groups.
 The first factor was Tjpe of Anaphor (Pronoun vs.
 Repeated Name), the second was Siuface Order (Goal first \s.
 Goal second), the third was Type of Coimective (Because \s.
 So) and the fourth was Antecedent (Goal vs Source).
 An example set of materials is shown in Table 1 Table 1: Examples of Materials Used in the Experiment GOAL FIRST Malcolm won some money from Stuart BECAUSE he/Malcolm w as very good at poker he/Stuart w as ver> bad at poker SO he/Malcolm ended up feeling rich he/Stuart ended up feeling poor GOAL SECOND Stuart lost some money to Malcolm BECAUSE he/Malcolm was very good at poker he/Stuart was yen bad at poker SO he/Malcolm ended up feeling rich he/Stuart ended up feeling poor To ensure that the content of the second clause was suitably biased to the intended antecedent, an initial large pool of sentences containing pronouns was constructed each with a second clause designed to bring about the intended assignment.
 These sentences were then presented to 3 independent judges who were asked to say who the pronouns referred to.
 Those sentences where all 3 judges gave the intended assignment were kept for inclusion in the experiment.
 Where there was disagreement, the second clause was changed to make the pragmatic bias stronger and these modified sentences were then given to a new set of 3 independent judges to say who the pronouns referred to.
 Once again, those sentences where all 3 judges agreed were kept for inclusion in the experiment while those where there was disagreement were modified and given to 3 more judges.
 This procedure continued until there were 16 Goal First sentences and 16 Goal Second sentences in which the second clause was unanimously judged to refer to the intended antecedent in each of the 8 conditions defined by Type of Connective, Position of the Goal and Thematic Role of the Antecedent.
 The critical second clauses were all either 5 or 6 words long.
 A question was also asked about each sentence, e.
g.
 'Was it Sttiart who won the money?' For half the questions in each condition, the intended ans\\er was 'yes'.
 For the other half, it was 'no'.
 The questions were designed to encourage comprehension and to ascertain that the pronoims were assigned to the intended antecedent.
 Procedure: Subjects carried out a selfpaced reading time task.
 Each sentence was presented on a computer screen one clause at a time and subjects were instrurted to press the space bar as soon as they had read and understood a clause.
 Once the second clause had been read, the screen cleared and the question was presented.
 After answering the question by pressing one of two keys marked YES and NO, subjects were prompted to start the next trial.
 The time taken to read the clause contaming the pronoun or repeated name was recorded in milliseconds.
 The assigrunents of the pronouns was also recorded.
 Results Since two different groups of subjects completed the Pronoun and Repeated Name conditions, these two conditions were analysed separately.
 The mean reading times for the target clauses in the Pronoun sentences are shown in Table 2.
 Only times for clauses where the pronoun was assigned the intended antecedent are included.
 Analyses of variance on the data in Table 2 revealed a main effect of thematic role: clauses were read more quickly when the pronoun referred to the Goal rather than the Source (F1=8.
29, df=l,15, p<.
02; f2=6.
56, df̂ l.
60, p<.
02), and a main effect of coimective: clauses were read more quicklv in Because than in So sentences (f1=12.
71.
 df^l.
l5.
 p<.
bl; f2=10.
59, df^I,60, p<.
01).
 There was also an interaction between thematic role and surface position (F' = 14.
I8, df=l,I5.
 p<.
OI: F:=7.
25, df^l,60, p<.
OI): a surface position effect arises with Source thematic roles only.
 The interaction between Thematic Role and Connective was also significant (F^=I4.
18, df=l,15, p<.
OI; f2=8.
44.
 df=l,60, p<.
01): The facilitation for clauses 330 where the pronoun refers to the Goal is confined to the So sentences.
 Table 2: Mean reading times (in msecs) for the clauses containing pronouns.
 Surface Position of the Antecedent Connective Thematic Role of Antecedent First Second Means B E C A U S E SO Goal Source Means Goal Source Means 1657 1597 1627 1689 2066 1877 1605 1846 1725 1669 2282 1976 1631 1721 1679 2174 Table 3 shows the percentage of correct responses to the questions in the Pronoun conditions.
 A correct response is one indicating that the pronoun had been assigned to the intended antecedent.
 Table 3: Percent Correct Responses to the Questions in the Pronoun Condition.
 Connective Thematic Role of Antecedent Surface Position of Antecedent First Second Means B E C A U S E SO Goal Source Means Goal Source Means 97 89 93 89 78 83 95 83 89 84 84 84 96 86 86 80 Analyses of variance on the correct responses revealed a main effect of Thematic Role (f1=10.
13, df=l,15, p<.
01; f2=8.
33, df=l 60, p<.
01) and a marginal effect of Connective (F'=3.
91, 1,15.
 p<.
.
07; f2=5.
35, df^l,60, p<.
03).
 There were more correct responses when the pronoun referred to the Goal than when it referred to the Source, and when the sentences were connected by "because' rather than 'so'.
 No other effects were significant.
 The mean reading times for the clauses containing repeated names arc shown in Table 4 Analyses of variance on the data revealed the same two main effects as in the Pronoun sentences.
 There was a main effect of Thematic Role: clauses were read faster when the pronoun referred to Goal rather than Source (F^=4.
65, df=l,15, p<.
05; f2=7.
36.
 df^l,60.
 p<.
02)), and a main effect of connective: clauses were read faster in Because than in So sentences (F'=35.
55.
 df=l,15, p<01; f2=5.
92, dl^l,60, p<.
03).
 There was also a main effect of the position of the antecedent (f1=4.
65, df=l,15, p<.
05, f2^=6.
34, df=l,60, p<.
02).
 Reading times were slower when the antecedent was in initial rather than second position.
 In contrast to the Pronouns sentences, there was no interaction between Thematic Role and Connective (F'=1.
46, df=l,15; F ^ df=l,60), although the pattern of results is in the predicted direction.
 Table 4: Mean reading times (in msecs) for the clauses containing names.
 Connective Thematic Role of Antecedent Surface Position of Antecedent First Second Means B E C A U S E SO Goal Source Means Goal Source Means 1595 1631 1613 1692 1925 1808 1464 1495 1497 1594 1805 1699 1530 1563 1643 1865 Discussion These results support the idea that thematic role focusing and structural focusing are distinct.
 As far as thematic roles are concerned, reading times were facilitated and pronoun assignments more accurate when the antecedent was the Goal rather than the Source.
 This facilitation held for repeated names as well as pronouns.
 Structural focusing, however, produced a different patter of results depending on whether the anaphor was a pronoun or a repeated name.
 When the clause contained a pronoun, reading times were facilitated when the antecedent was mentioned first but only when it was the Source.
 This focusing effect, therefore, was modified by thematic role and only emerged when the first mentioned antecedent was the nonfocused thematic role.
 When the clause contained a repeated name, an expectancy effect was observed: Clauses were read more slowly when the name referred to the first mentioned antecedent compared to when it referred to the second mentioned antecedent, regardless of the thematic role of the antecedent.
 W e also found that thematic role focusing was modified by the type of connective, while structural focusing was unaffected by the connective.
 W e therefore conclude that thematic role focusing and structural focusing are distinct.
 The results of the present experiment appear to conflict with those of Hudson D'Zmura (1988).
 In one of her experiments, she examined structural focusing in relation to focusing due to the causal bias of the verb, and she found clear evidence of structural focusing but no e\idence of focusing due to the causal bias of the verb.
 She used two sets of materials.
 One set contained 'Agent verbs', where the causal bias was to the Agent (NPl); the other set 331 contained 'Patient verbs", where the causal bias was to the Patient (NP2).
 (These latter sentences contained what Stc\enson et al.
 called Experiencer (NPl) and Stimulus (NP2) thematic roles.
) Hudson D'Zmixra found that the first mentioned antecedent was the most accessible to a subject pronoun, regardless of its thematic role.
 However, Sle\enson et al.
 found that E.
xperiencerStimulus sentences of the kind used b} Hudson D'Zmura do not show thematic role preferences in the absence of other cues in the sentence that turn the state described b>' the verb into an event.
 In their study, the use of 'so' led to a preference of the Experiencer while the use of 'because' led to a preference for the Stimulus.
 Thus, the lack of an explicit connecti\e in Hudson D'Zmura's studj' is probably responsible for the lack of any focusing due to causal bias.
 The coimecti\e influenced the impact of thematic role focusing, as was the case in the Stevenson et al.
 study.
 The reading time ad\antage for Goal antecedents was mainly evident when the cormecti\e was so.
 So reinforces the focusing due to thematic role, while because modifies it.
 Thus, thematic role focusing, but not structural focusing, is also affected b> other elements in the sentence that direct the reader's attention to one discoiuse referent rather than another.
 W e should also note that there were differences in the content of the second clause across most of the conditions.
 This raises the possibility that the reading times are a result of s>stematic differences in the ease of comprehending these different clauses.
 W e think this is imlikely for two reasons.
 First, the materials were comprehensively tested and modified until successive sets of three independent judges agreed on the assignment of the pronoun.
 Second, by using a large number of sentences, 16 Goal first and 16 Goal second, w e reduced the likelihood of systematic differences between the conditions other than the differences due to the experimental conditions.
 Consequently, w e feel confident that the results are due to our intended manipulations.
 What do these results imply for theories of reference resolution? In centering theory, focusing depends on the ranking of Cfs according to structural aspects of the utterance.
 Following Gordon et al.
, w e have identified the highest ranked Cf as the M P in initial position.
 A n utterance also contains a Cb, which is responsible for the ejqjectancy effect.
 According to Gordon et al.
, the C b is normally a subject, and normally a pronoun that refers to the highest ranked Cf from the previous utterance that is realised in the current utterance.
 The present restilts support this view but further suggest that the Cf, as characterised b>' centering theory, is not the only form of focusing that can arise.
 Focusing also arises as a result of thematic role preferences.
 Thus, the centers that link the present utterance to subsequent ones, by providing potential antecedents for pronoims, may be either structural or semantic/pragmatic.
 The Cb, on the other hand, is unaffected by thematic role focusing.
 A n expectancy effect only arises when the antecedent is in initial position; that is, the structural focus of the preceding clause.
 Thus, the center that links the current utterance with the previous one is governed purely b>' structural factors.
 Grosz and her colleagues also distinguish between centering theory, which is a theory of local focusing, and a theory of global structure, which is a theory concerning the purposes imderlying the intentional structiue of the discoiu^se as a whole.
 Global focus is said to be responsible for the interpretation of definite descriptions (including repeated names) while local focus, the topic of centering theory, is said to be responsible for the interpretation of pronouns.
 This distinction between local and global focus may underlie the distinction between structiual and thematic role focusing.
 Since these two forms of focusing have distinguishable effects, it is likely that they arise from different mechanisms.
 Thus, as Grosz and her colleagues have argued, structural focusing depends on local effects as identified by centering theory.
 Moreover, it seems to be specifically concerned with the relationship between the C b and the siuface position of the antecedent.
 However, w e suggest that thematic role focusing is an aspect of global structure, an aspect that depends on the event structure of the situation described by the discourse.
.
 If this is the case, then oiu results fiuther suggest that the global focus affects the interpretation of pronoims as well as definite descriptions.
 Hence pronoun resolution does not lie solely in the domain of local focus.
.
 In more pragmatically based theories, such as the scenariomapping model of Sanford and Garrod (1981; Garrod, Freudenthal and Boyle, 1994), focusing is normally a fimction of background knowledge of the subject matter of the discoiuse, which determines the range of situations in which a discoxuse entity may appear.
 However, just as Grosz and Sidner distinguish between local and global focus, so Sanford and Garrod distinguish between the status of entities in the discourse and the event structure of the discourse.
 Consequently, two different mechanisms are specified that could be responsible for the two types of focusing.
 According to Sanford and Garrod, elements in a focus stack are stored in 'explicit focus' while the roles they occupy in the events described by the discourse are stored in 'implicit focus'.
 As the model stands, focusing of a discourse entity is influenced by the strength of the links between an entity and the roles the entity occupies in the discourse.
 The results of the present experiment, together with the work on structural focusing, suggest that structiu^l factors and thematic role informaUon are also crucial for focusing and have separate sources.
 Thus, structm^ factors could be said to affect the status of entities in ejqjlicit focus, while thematic role preferences affect the status of roles in explicit focus.
 This model has the advantage, compared to Grosz's work on local and global focus, that the relationship between discourse entities and the roles they fill in the described events is clearly specified, thus enabling pronoims and repeated names to both be affected by thematic role focusing.
 However, it also has the disadvantage, compared to the work of Grosz et al.
, that there is no account of the relationship between the C b and structural focusing.
 332 In summary, we have found that both pronouns and repeated names are interpreted with respect to a thematic role focus as well as with respect to a structural focus.
 However, structural focusing only affects pronouns when the antecedent is the nonfocused thematic role; while it affects repeated names when the antecedent is in initial position.
 The Cb, therefore, is only affected by structural focusing.
 W e also suggested ways in which Grosz's models of local and global focus and Sanford and Garrod's pragmatic model of discourse need to be modified to take account of these findings.
 In particular, we suggested that thematic role focusing is an aspect of the glotel focus, and that therefore the global focus, as well as the local focus, influences pronoim interpretation; and we suggested that in the pragmatic model, structural focusing affects the status of entities in e)q)licit focus while thematic role focusing affects the status of the roles in implicit focus, and that the important role of the C b also needs to be considered.
 Acknowledgements The Human Commimication Research Centre is funded by the Economic and Social Research Council of Great Britain.
 W e thank Massimo Poesio for mmierous stimulating discussions on centering theory and the two anonymous reviewers for their very helpfiil suggestions.
 References Brennan, S.
E.
, M.
 W.
 Friedman, and C.
J.
 Pollard.
 (1987).
 A centering ai^roach to pronouns.
 In Proceedings of the 25th Annual Meeting of the Association of Computational Linguistics, fp.
 155162.
 Stanford.
 Caramazza , A.
 Grober, E.
H.
, Garvey, C.
 and Yates, J.
V.
 (1977).
 Comprehension of anaphoric pronouns.
 Journal of Verbal Learning and Verbal Behaviour, 16, 601609.
 Garrod, S.
, Freudenthal, D.
 and Boyle, E.
 (1994).
 The role of different types of anaphor in the online resolution of sentences in discourse.
 Journal of Memory and Language, 33, 3968.
 Garvey, C.
 and Caramazza, A.
 (1974).
 Implicit caxisality in verbs.
 Linguistic Inquiry, 5, 459464.
 Gordon, P C , Grosz, B.
J.
 and Gilliom, L A .
 (1993).
 Pronouns, names and the centering of attention in discourse.
 Cognitive Science, 17, 311348.
 Grosz, B.
J.
 and Sidner, C.
L.
 (1986).
 Attention, Intentions and the structure of discourse.
 Computational Linguistics.
 12, 175204.
 Grosz, B.
J,, Joshi, A.
 and Weinstein, S.
 (1983).
 Providing a unified account of definite noun phrases in discourse.
 Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics.
 Association for Computational Linguistics.
 Hudson D'Zmura, SB.
 (1988).
 The Structure of Discourse and Anaphor Resolution: The Discourse Center and the Roles of Nouns and Pronouns.
 Ph.
D.
 thesis.
 University of Rochester.
 Hudson, S.
, Tanenhaus, M.
K.
 and Dell, G.
 (1986).
 In C.
 Clifton, Jr.
 (Ed.
; Proceedings of the 12th Annual Conference of the Cognitive Science Society, pp.
 96101.
 Hillsdale, NJ: Erlbaum.
 Kameyama, M.
 (1986).
 A propertysharing constraint in centering.
 In Proceedings of the 24th Annual Meeting of the Association for Computational {Linguistics, pp.
 200206.
 N e w York.
 Sanford, A.
J.
, and Garrod, S.
C.
 (1981).
 Understanding Written Language.
 Wiley, Chichester, Stevenson (1986).
 The time course of pronoun comprehension.
 In C.
 Clifton, Jr (Ed) Proceedings of the 12th Annual Conference of the Cognitive Science Society, pp.
 102109.
 Hillsdale, NJ: Erlbaum.
 Stevenson, R.
J.
, Crawley, R A .
 and Kleinman, D.
 (1994).
 Thematic roles, focus and the representation of events.
 Language and Cognitive Processes, 9, 519548.
 Walker, M , Ilda, M.
, and Cote, S.
 (1994).
 Japanese discourse and the process of centering.
 Computational Linguistics, 20(2), 193231.
 333 Question Answering in the Context of Illustrated Expository Text William B.
 Baggett Department of Psychology and the Institute for Intelligent Systems The University of Memphis Memphis, TN 38152 bagget tw@cc.
memphi s.
edu Arthur C.
 Graesser Department of Psychology and the Institute for Intelligent Systems The University of Memphis Memphis, TN 38152 agraesserOmemphis.
edu Abstract We investigated how college students answer questions about the content of illustrated expository text.
 Subjects studied illustrated texts describing causal event chains that unfold during the operation of everyday machines.
 Subjects subsequently provided written answers to questions about events occurring in each machine.
 Four types of questions were asked: why did event X occur?.
 hQw did X occur?, what are the gonsequences pf X occurring?, and what if X didn't occur?.
 In our analysis of the answer protocols, we adopted the theoretical framework of the Q U E S T model of human question answering (Graesser & Franklin, 1990).
 The present study supported predictions generated from three components of the Q U E S T model: question categorization, utilization of information sources, and convergence principles.
 Our results also revealed two novel findings.
 First, subjects had a bias toward sampling information from the text more than from the picture.
 Second, subjects tended to sample infontiation depicted in both the text and the picture.
 Introduction H o w do adults answer deepreasoning questions about the inner workings of machines after studying texts with illustrations? Figure 1 presents an illustrated text describing the workings of a cylinder lock.
 W e asked college students to study these materials at their leisure and to provide written answers to deep explanatory questions such as the following: W h y does the cylinder rotate? H o w does the cylinder rotate? What are the consequences of the cylinder rotating? What if the cylinder did not rotate? In our analysis of the answer protocols, we adopted the theoretical framework of the Q U E S T model of human question answering (Graesser & Franklin, 1990).
 The present study is the first to evaluate Q U E S T in the context of illustrated expository texts.
 The role of illustrations in text comprehension has recently received considerable attention (Glenberg & Langston, 1992; Hegarty & Just, 1993; Mandl & Levin, 1989; Mayer & Anderson, 1989; Schnotz & Kulhavy, 1994).
 However, these studies have not directly investigated h o w deep questions are answered in the context of the illustrated texts.
 Given that answers to deep explanatory questions are an important reflection of understanding (Graesser, Singer, & Trabasso, 1994; Schank, 1986), the present study investigated the mechanisms that generate answers to these questions.
 QUEST: A Model of Human Question Answering We focused on three components of the QUEST model: question categorization, information sources, and convergence principles.
 Question Categorization Q U E S T assumes (a) that there is a catalog of question categories, (b) that each question category has an associated questionanswering procedure which operates on relevant knowledge structures to generate appropriate answers, and (c) that an incoming question is assigned to one of these question categories.
 The present study investigated four question stems: why, how, whataretheconsequences.
 and whatifnot.
 Information Sources Q U E S T specifies the information sources (i.
e.
, knowledge structures) that are active in working memory after a query occurs.
 W e assumed that the text and the picture were the primary information sources available to subjects during question answering.
 Q U E S T uses conceptual graphs structures (CGS's) to represent information from both the text and the picture (Baggett, 1994).
 This representational system is similar to those of conceptual dependency theory (Schank & Abelson, 1977) and causal chain theories (Trabasso, van den Broek, & Suh, 1989).
 A C G S consists of a group of statement nodes that are related by labeled, directed arcs.
 Figure 2 gives a portion of the C G S associated with the cylinder lock materials.
 In general, a statement node contains a predicate (e.
g.
, verb, adjective, or adverb) and one or more arguments (e.
g.
, noun or an embedded proposition).
 That is, a statement node is essentially a proposition that is assigned to a category (Kintsch & van Dijk, 1978).
 The C G S in Figure 2 contains 14 nodes that represent 8 causally related events, 4 supporting states of the world, and 2 goals of the user of the device.
 334 Sprinc, CYLlNDtR Bolt Pulled Back CYLINDER LOCK When the door is closed, the spring presses the bolt into the door frame.
 Inserting the key raises the pins and frees the cylinder When the key is turned, the cylinder rotates, making the cam draw back the bolt against the spring When the key is released, the spring pushes back the bolt rotating the cylinder to its initial position and enabling the key to be withdrawn.
 KtY Turned Figure 1: Example illustrated text describing a cylinder lock.
 (From The W a y Things Work by David Macaulay.
 Compilation copyright (c) Dorling Kindersley Ltd.
, London.
 Illustration copyright (c) 1988 David Macaulay.
 Text copyright (c) 1988 David Macaulay, Neil Ardley.
 Reprinted by permission of Houghton Mifflin Company.
 All rights reserved.
) O O Insert the key (Goal 1, T) R Turn the key (Goal 2, T) Key is inserted (Event 1, T) ~^The pins rise (Event 2, T) The pins are next to the cylinder (State 1, P) ^ The cyhnder is freed (Event 3, T) The key is turned (Event 4, T P) The cyhnder is The rod is i next to a rod next to the cam y C (State 2, P) (State 3, P) Xhe cylinder rotates (Event 5, T) The cylinder is connected to the cam (State 4, P) ^ The cam rotates (Event 6, P) The cam draws back the bolt (Event 7, T P) The boh is pulled back against the spring (Event 8, T P) Figure 2: A portion of the cylinder lock materials represented as a conceptual graph structure.
 The arc categories include consequence (C), reason (R), and outcome (O).
 Each node is labeled as being depicted in the picture alone (P), the text alone (T), or both text and picture (T P).
 335 M a n y of the nodes in Figure 2 are connected by consequence arcs (or Carcs).
 Consequence arcs convey a weak sense of causality.
 Typically, a consequence arc originates from an event or state node X and terminates at an event node Y, indicating that X causes or enables Y.
 The goal nodes in Figure 2 are connected by reason arcs (or Rarcs).
 Reason arcs connect subordinate goals to their immediate parent, superordinate goals.
 That is, a reason arc originates from a goal node G and terminates at a goal node G', indicating that an agent wishes to accomplish goal G in order to facilitate accomplishing goal G'.
 Finally, the goal nodes in Figure 2 are connected to their corresponding event nodes by outcome arcs (or Oarcs).
 Typically, outcome arcs indicate that an event is the result of some goal of an agent.
 A n intentional action is the amalgamation of a goal node and an event node that signifies its successful outcome (Graesser & Clark, 1985).
 Although there are other categories of nodes and arcs (see Graesser, Gordon, & Brainerd, 1992), those described above are adequate for our current purposes.
 The C G S in Figure 2 also specifies which statement nodes come from the text (labeled 7^, the picture (labeled P), and from both the text and the picture (labeled T P).
 The process of segregating a text into statement nodes has been specified in detail (Graesser & Clark, 1985).
 W e augmented the C G S of the text by adding information contained in the picture.
 Pictures convey information about machines in at least two ways.
 First, spatial adjacencies of machine components convey "nextto" relations.
 For example, the picture in Figure 1 includes the information that "the pins are next to the cylinder.
" Thus, a state node corresponding to this relation (state node 1) was added to the C G S .
 Second, pictures convey information about the movements of some components through the use of arrows.
 For example, an arrow on the second depiction of the system in Figure 1 indicates the event, "the cam rotates.
" Thus, a corresponding event node (event node 6) was added to the CGS.
 Convergence Principles Convergence principles narrow down the set of nodes which serve as good answers to a question.
 The quality of answers was assumed to be positively correlated with the frequency of the answers produced in the question answering protocols.
 The convergence principles of Q U E S T include (1) the intersection principle, (2) the arc search procedures, and (3) structural distance.
 Intersection principle.
 The intersection principle predicts that the quality of a potential answer node increases with the number of information sources that store the node.
 That is, nodes which come from both the text and the picture are predicted to be better answers than those coming from the text alone or from the picture alone.
 Suppose event node 3 in Figure 2 were queried with a consequence question, i.
e.
.
 What are the consequences of the cylinder being freed?.
 The intersection principle predicts that events 4, 7, and 8 will be mentioned in the answer protocols more frequently than the other events and states because events 4, 7, and 8 come from both the text and the picture.
 It should be noted that intersection mechanisms also play a critical role in Anderson's A C T * model (Anderson, 1983).
 Arc search.
 Each question category has an associated arc search procedure which specifies the subset of legal paths among those paths that radiate from the queried node.
 The legal paths should include good answers to a question.
 For example, legal answers to how questions lie along paths of backward consequence arcs.
 Thus, legal answers to how questions represent causal antecedents of the queried event.
 Suppose event node 3 in Figure 2 is queried with a how question.
 Legal answers consist of state node 1 and event nodes 1 and 2, whereas all other nodes are illegal answers.
 The arc search principle predicts that legal answers are given more frequently that illegal answers.
 The strategy of answering questions by sampling relational arcs has been adopted by a number of models in AI (Lehnert, 1978; Ram, 1990; Schank & Ableson, 1977; Souther, Acker, Lester, & Porter, 1989).
 This study was the first to include whatifnot questions in tests of Q U E S T .
 It was anticipated that whatifnot questions would be answered by negated causal consequences of the queried event.
 For example, legal answers to What if the cylinder were not freed? include "The key is not turned," and "The bolt is not pulled back against the spring.
" Legal answers to consequence questions consist of causal consequences of the queried event.
 Graesser & Hemphill (1991) found that legal answers to why questions consist of both causal antecedents and causal consequences of the queried event.
 Subjects apparently developed teleological representations of mechanisms from the biological and technological sciences, as evidenced by their tendency to answer why questions in those domains with causal consequences.
 Structural distance.
 The structural distance between two nodes is the number of arcs on the shortest path between the nodes.
 Q U E S T predicts that answer quality decreases as the structural distance between the queried node and the potential answer node increases.
 According to this principle, when event node 3 in Figure 2 is queried with a how question, event node 2 is a better answer than event node 1.
 This structural distance gradient is compatible with the spreading activation mechanism in the A C T * model (Anderson, 1983).
 Note that the predicted effect of structural distance may be challenged by the presence of illustrations in the instructional materials.
 That is, illustrations may enhance subject's memories for portions of the causal sequence, which allows subjects to make more distant associations.
 Methods Subjects The subjects were 32 undergraduates from The University of Memphis.
 336 Materials Study booklets consisted of four illustrated texts on separate pages.
 The texts were excerpts from The Way Things Work (Macaulay, 1988).
 The texts described causal event chains associated with a cylinder lock, a car engine crankshat'l, a microwave oven, and a water meter.
 From each text, four events were selected for querying.
 Each subject read all of the texts, but a given subject answered questions about only one of the events associated with a text.
 W e counterbalanced the order in which subjects read the passages and the assignment of queried events to subjects.
 Procedure Subjects were instructed to study the illustrated texts at their own pace before answering any questions.
 After reading each text, they answered four questions about the text.
 Subjects were encouraged to refer back to the illustrated texts during question answering and to fill the three lines provided for answers to each question.
 Variables For all analyses, the independent variables were question category (why, how, consequence, versus whatifnot) and answer category (as described below).
 The dependent variable was the answer frequency per question.
 Most (79%) of the answers referred to explicit information so we did not analyze inferences.
 In the analyses of information sources and structural distance, each empirical answer frequency was compared to an appropriate base rate answer frequency.
 The base rate frequencies reflect random sampling of the nodes in the illustrated texts.
 The base rate frequency for each answer category was computed by multiplying the mean number of explicit answers statements subjects produced per question, 1.
7, by the proportion of C G S statement nodes in that category.
 Results & Discussion Written questionanswering protocols were analyzed along three dimensions specified by the Q U E S T model of human question answering: information sources, arc search procedures, and structural distance.
 All comparisons discussed in this section were statistically reliable, unless stated otherwise.
 Information Sources The explicit answers were segregated into those coming from the text alone, the picture alone, versus both.
 Figure 3 summarizes the results of the information source analysis.
 For each answer category (text alone, picture alone, versus both), the empirical answer frequency was compared to the base rate answer frequency for that category.
 The base rate frequencies reflect random sampling of the nodes in the illustrated texts.
 One of the provocative findings is that subjects gave answers which come from the text alone much more often 1 0.
75 Mean Answer Frequency 05 Per Question 0.
25 0M EmpincaJ Answers • Base Rate Sampling Text Picture Answer Category Both Figure 3: Empirical and base rate answer frequencies from the information source analysis.
 than their base rate availability among the total pool of information.
 Apparently, information in the text has a privileged status.
 Subjects focused on information provided in the text alone during encoding, retrieval, and/or articulation.
 In contrast, subjects gave answers which c o m e from the picture alone m u c h less often than their base rate availability a m o n g the total pool of information.
 T h u s , w h e n information w a s presented in the picture alone, subjects tended to ignore the information during study or filter it out during question answering.
 Another provocative finding is that subjects gave answers which c o m e from both the text and the picture m o r e often than their base rate availability.
 It should be noted that this base rate includes an adjustment for the double presentation of the information.
 W h y d o subjects focus on information presented in both the text and the picture over and above its double presentation? O n e explanation of this effect is quest's intersection principle.
 According to Q U E S T , a statement node represents a better answer to a question to the extent that it comes from multiple information sources.
 For example, a statement that is read in both a newspaper article and a book comes from at least two explicit information sources.
 From this point of view, the simple fact that the text and the picture are distinct information sources causes them together to have a greater than additive impact on answer frequency.
 A n alternative explanation of the latter finding comes from the dual code hypothesis (Paivio, 1971).
 According to the dual code hypothesis, memories are more likely to be recalled to the extent that they are tied to both the visual and verbal modalities.
 In summary, subjects are biased toward sampling information from the text more than from the picture.
 This finding is compatible with the results of eye tracking studies conducted by Hegarty and Just (1993).
 These studies indicate that it is the text rather than the picture that drives comprehension.
 Moreover, subjects exhibit a bias toward information coming from both the text and the picture.
 That is, the effect of presenting information in the text can be strengthened by presenting it in the picture as well.
 The 337 1.
5 Mean Answer Frequency 1 Per Question 0.
5 1.
5 LJ Aniecedenls LJ Consequences Why How Conseq.
 Question Category Whatifnot Figure 4: Empirical answer frequencies from the arc search analysis.
 latter effect is compatible with QUEST'S intersection principle and with the dual code hypothesis.
 Arc Search Procedures The explicit answers were segregated into causal antecedents versus causal consequences of the queried event.
 Figure 4 summarizes the results of the arc search analysis.
 For each question type, we compared the empirical answer frequencies of causal antecedents and causal consequences of the queried event.
 The data clearly substantiate the predictions made by QUEST'S arc search procedures.
 The arc search component correctly predicted that the legal answers for how, consequence, and whatifnot questions sample causal antecedents, causal consequences, and negated causal consequences of the queried event, respectively.
 Q U E S T accommodates both causal antecedents and causal consequences as answers to why questions, and in fact the difference in answer frequencies was not significant.
 Structural Distance The explicit answers were categorized according to the number of arcs on the shortest path between the queried node and the answer node (one, two, versus three or more).
 Figure 5 summarizes the results of the structural distance analysis.
 For each question type and each answer category, the empirical answer frequency was compared to the appropriate base rate answer frequency.
 W e focus on the frequencies of answers which are either near (one arc) or distant (three or more arcs) from the queried node.
 Again, the base rate frequencies reflect random sampling of the nodes in the illustrated texts.
 The data show some support for the predicted structural distance gradient.
 W h e n subjects answered whatifnot questions, they apparently sampled the nodes on legal paths randomly with regard to structural distance.
 For all comparisons involving why, how, and consequence questions, however, the differences were in the direction predicted by QUEST'S structural distance gradient.
 That is, the frequencies of answers which were near (one arc away from) the queried event node were higher than their I Mean Answer Frequency Per Question 0.
5 r?] Empirical Answers H] Base Rate Sampling 1 Arc 3+ Arcs 1 3 + 1 3 + Arc Arcs Arc Arcs 1 3+ Arc Arcs Why How Conseq.
 Whatifnot Question and Answer Categories Figure 5: Empirical and base rate answer frequencies from the structural distance analysis.
 respective base rates; the frequencies of answers which were distant (three or m o r e arcs a w a y ) from the queried event node were lower than their respective base rates.
 These results are consistent with the prediction that a n s w e r quality decreases as the structural distance between the queried n o d e and the potential answer n o d e increases.
 References Anderson, J.
 R.
 (1983).
 The architecture of cognition.
 Cambridge, M A : Harvard University Press.
 Baggett, W.
B.
 (1994).
 Question Answering and Illustrated Expository Text.
 Unpublished master's thesis.
 Memphis, TN: The University of Memphis.
 Glenberg, A.
M.
, & Langston, W.
E.
 (1992).
 Comprehension of illustrated text: Pictures help to build mental models.
 Journal of Memory and Language, 31, 129151.
 Graesser, A.
C.
, & Clark, L.
C.
 (1985).
 Structures and procedures of implicit knowledge.
 Norwood, NJ: Ablex.
 Graesser, A.
C.
, & Franklin, S.
P.
 (1990).
 QUEST: A cognitive model of question answering.
 Discourse Processes, 13, 279303.
 Graesser, A.
C.
, Gordon, S.
E.
, & Brainerd, L.
E.
 (1992).
 QUEST: A model of question answering.
 Computers and Mathematics with Applications, 23, 733745.
 Graesser, A.
C.
, & Hemphill, D.
 (1991).
 Question answering in the context of scientific mechanisms.
 Journal of Memory and Language, 30, 186209.
 Graesser, A.
C.
, Singer, M.
, & Trabasso, T.
 (1994).
 Constructing inferences during narrative text comprehension.
 Psychological Review, 101,37195.
 Hegarty, M.
, & Just, M.
A.
 (1993).
 Constructing mental models of machines from text and diagrams.
 Journal of Memory and Language, 32,717742.
 Kintsch, W.
, & van Dijk, T.
A.
 (1978).
 Toward a model of text comprehension and production.
 Psychological Review, 85, 363394.
 Lehnert, W.
G.
 (1978).
 The process of question answering.
 Hillsdale, NJ: Erlbaum.
 338 Macaulay, D.
 (1988).
 The way things work.
 Boston: Houghton Mifflin Company.
 Mandl, H.
, & Levin, J.
R.
 (1989).
 Knowledge acquisition from text and pictures.
 Amsterdam: North Holland.
 Mayer, R.
E.
, & Anderson, R.
B.
 (1989).
 Models for understanding.
 Review of Educational Research, 59, 4364.
 Paivio, A.
 (1971).
 Imagery and verbal processes.
 New York: Holt, Rinehart, and Winston.
 Ram, A.
, (1990).
 Knowledge goals: A theory of interestingness.
 In Proceedings of the 12th Annual Conference of the Cognitive Science Society (pp.
 206214).
 Hillsdale, NJ: Erlbaum.
 Schank, R.
C.
, Abelson, R.
 (1977).
 Scripts, plans, goals and understanding: An inquiry into human knowledge structures.
 Hillsdale, NJ: Erlbaum.
 Schnotz, W.
, & Kulhavy, R.
 (1994).
 Comprehension of graphics.
 Elmsford, NY: Pergamon Press.
 Souther, A.
, Acker, L.
, Lester, J.
, & Porter, B.
 (1989).
 Using view types to generate explanations in intelligent tutoring systems.
 Proceedings of the 11th Annual Conference of the Cognitive Science Society (pp.
 123130), Hillsdale, NJ: Erlbaum.
 Trabasso, T.
, van den Broek, P.
W.
, & Suh, S.
Y.
 (1989).
 Logical necessity and transitivity of causal relations in stories.
 Discourse Processes, 12, 125.
 339 Collaborative discovery in a scientific d o m a i n Takeshi Okada Learning Research and Development Center University of Pittsburgh Pittsburgh, PA 15260 takeshi+@pitt.
edu Herbert A.
 Simon Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 has@cs.
cmu.
edu Abstract This study compares the performance of Pairs with Single subjects in discovering scientific laws with the aid of experiments; describes differences between discovery processes of Pairs and Singles; and identifies the important contributing variables.
 36 male undergraduate science majors solved a molecular genetics task in a computer microworld called the Simulated Molecular Genetics Laboratory (Dunbar, 1993).
 Pairs were more successful in discovery than Singles and participated more actively in explanatory activities (i.
e.
, entertaining hypotheses, considering alternative ideas and justifications).
 Explanatory activities were effective only when the subjects also conducted crucial experiments.
 Explanatory activities were facilitated when paired subjects requested explanations from each other and carefully attended to them.
 Scientific discovery through collaboration is a common practice in modern science, but the processes of collaboration have not been well studied.
 There are several potential approaches to studying collaborative discovery processes, including historical case studies, psychological experiments in the lab, participatory field observation, and interviews with researchers actively involved in collaborative research.
 Each approach has its own advantages and limitations.
 As a result, combining several approaches seems most likely to produce a complete and accurate description of the processes of coU^orative scientific discovery.
 In this paper, we will repon experimental data based on the Dual Space Search Model of scientific discovery originated by Simon and Lea (1974) and developed by Klahr & Dunbar (1988).
 Our main focus is on the differences between Singles' and Pairs' discovery processes.
 W e will answer the following questions: (1) D o Pairs perform better than Singles in a scientific discovery task? (2) What are the differences between their discovery processes? (3) What variables are mainly responsible for success? Method Design The experiment has a betweensubjects factorial design (Pairs condition vs.
 Singlesubjects condition).
 Subjects Subjects were 27 male science major undergraduates at Carnegie Mellon University.
 Subjects were randomly assigned to one of the two conditions.
 Each subject had to bring a friend, who was also a male science undergraduate.
 Apparatus and task A Macintosh computer running the Simulated Molecular Genetics Laboratory (Dunbar, 1993; Dunbar & Schunn, 1990) was used.
 Using this Laboratory, subjects can learn basic concepts and techniques in molecular genetics, and conduct experiments to discover a scientific mechanism.
 The detailed explanation of the mechanism to be discovered can be found in Dunbar (1993).
 A video and two audio tape recorders were used to record the verbal protocols and the computer display.
 Procedure (1) A warm up task was administered to familiarize subjects with giving verbal protocols.
 (2) Subjects followed the instructions on the computer display to acquire basic knowledge and techniques in molecular genetics and to do a practice task.
 (i) Discovery phase Subjects' goal was to find out how 1, O, and P genes work to control the beta gene to produce the beta enzyme in a cell.
 After the first two experiments (conducted as part of the instruction) the experimenter asked the subjects to report and write down their initial hypotheses.
 Then, in the Pairs condition, subjects were told to reach a consensus on the mechanism by conducting experiments with discussion.
 In the Singles condition, they were told to find the mechanism by conducting experiments while talking aloud.
 Both Pairs and Singles were asked to report the discovery, when reached, before the camera, so that other people could review the findings.
 Each time they conducted an experiment, the computer screen displayed information about their previous experiments.
 W h e n subjects discovered the mechanism, they reported their conclusions in front of the video camera and then wrote down their conclusions.
 Results and Discussion Quality of performance To measure outcomes in terms of discovery, we rated performance (i.
e.
, subjects' final hypothesis) on a 5pointscale.
 As Table 1 shows.
 Pairs outperformed Singles (t(16)=2.
69, p<.
05), with mean scores of 2.
89 and 1.
67, respectively.
 340 mailto:has@cs.
cmu.
eduTable 1 Differences between Pairs and Singles in terms of performance and time measures Measures Discovery score (full time) Hypothetical Pairs' (see Singles' column) discovery score Reported Math S A T scores (Pairs = average score) Reported S A T scores (Math + Verbal) (Pairs = average score) Solution time (min.
) means & (SDs) Pairs 2.
89 2.
89 706.
25 1253.
00 29.
33 (0.
93) (0.
93) (30.
38) (23.
87) (14.
85) means & (SDs) Singles 1.
67 2.
17 663.
33 1246.
67 23.
02 (1.
00) (1.
08) (97.
97) (127.
85) (10.
98) poft tests <.
05 = .
06 = .
43 = .
92 = .
32 Table 2 The differences between Pairs and Singles in experimentation measures Amount Breadth of Espace search Cnjcial experiments VOTAT Measures Number of experiments Dimension search score % of types of cnjcial experiments Mean feature difference score Pairs' mean and (SD) 13.
89 (7.
54) 11.
78 (2.
33) 88.
89 (10.
54) 1.
83 (.
14) Singles' mean and (SD) 13.
89 (6.
92) 11.
44 (2.
55) 86.
67 (14.
14) 1.
70 (.
29) pofttests N.
S.
 N.
S.
 N.
S.
 N.
S.
 Reasons for superiority of Pairs over Singles In this section, we will list plausible hypotheses to explain the superior performance of Pairs over Singles, and test each hypothesis with our data.
 Hypothesis aD: Members of Pairs happened to havg higher intglUggncg.
 To test this possibility, we asked subjects to report their Math and Verbal S A T scores, and found no significant differences between the Singles' scores and the average scores for two members in each Pair (See Table 1).
 HypQthgsis (12); Pairs had better initial hypQthggeg than Singles, This hypothesis was not supported by the data.
 All Singles and all except one Pairs reported an incorrect initial hypothesis.
 Hypothesis (13): Pairs had twice as great a probabilitv as Singles of getting the right final hypothesis, even without interaction.
 We paired all combinations of Singles subjects (9x8/2 = 72 cases).
 In each case we picked the higher score of the two as the score for a hypothetical pair.
 Then, we compared the hypothetical pairs' with the real Pairs' mean and S D (See Table 1).
 Contrary to the hypothesis, the score of the real Pairs (2.
89) was better than that of the hypothetical pairs (2.
17) (t (43)=1.
84, p=.
06).
 Therefore, the superior performance of Pairs seems to depend on the members' interactions instead of just the intelligence, initial ideas, or performance of the abler member.
 Hypothesis (14): Singles.
 Pairs spent more time than Pairs might have been more motivated and spent more time than Singles.
 However, the difference between them is not statistically significant (t (16)=1.
03, p=.
32) (See Table I).
 Hypothesis (15): Pairs searched the experiment space more effectively.
 We investigated subjects' experiment space search processes using various measures adapted from Schunn & Dunbar (in preparation).
 Table 2 shows the means and SDs for each measure.
 There were no significant differences between Pairs and Singles.
 HypQthegig (1^); P^irg talked more than Singles, (See Table 3).
 Pairs talked, on average, twice as much as Singles throughout the solving process (t (16)=2.
73, p<.
05).
 W e will discuss below what they talked about.
 Hypothesis (17); Pair? entertained hypotheses more often than Singles.
 Science aims at explaining phenomena.
 Therefore, how much subjects talked about hypotheses should be a useful measure of scientific discovery.
 W e created two measures: the percent of units^ in which subjects ^ W e define a unit as the period between two adjacent experiments and also the discussion period following completion of the final experiment.
 341 Table 3 Differences between Pairs and Singles in terms of protocol measures Measures Number of words Number of hypotheses first half second half Hypothetical Pairs' number of hypotheses (see Singles) N u m b e r of different types of hypotheses first half second half Hypothetical Pairs' number of types of hypotheses (see Singles) % of units with summarizing data % of units with hypotheses % of units with prediction % of units with critique % of units with alternative hypotheses % of units with combinedjustification % of units with justification through experimental results % of units with plan for n e w experiments to test hypotheses % of units with testability of hypotheses % of units with justification using several experimental results % of units with argument about justification Hypothetical Pairs' (see Singles' column) % of units with hypotheses Hypothetical Pairs' % of units with alternative hypotheses Hypothetical Pairs' % of units with combinedjustification Hypothetical Pairs' % of units with justification through experimental results Hypothetical Pairs' % of units with plan for n e w experiments Hypothetical Pairs' % of units with testability of hypotheses Hypothetical Pairs' % of units with justification using several results Hypothetical Pairs' % of units with argument about justification means 2216.
22 29.
56 14.
56 15.
00 29.
56 10.
44 7.
11 6.
11 10.
44 48 74 31 33 25 58 41 37 9 35 24 74 25 58 41 37 9 35 24 and (SDs) Pairs (1135.
41) (13.
45) (5.
59) (9.
27) (13.
45) (3.
24) (2.
76) (3.
55) (3.
24) (21) (21) (19) (21) (26) (29) (19) (24) (8) (19) (16) (21) (26) (29) (19) (24) (8) (19) (16) means and (SDs) Singles 1090.
67 14.
00 4.
67 9.
33 28.
00 7.
78 2.
89 6.
22 13.
11 47 56 14 2 6 39 24 17 2 19 9 70 11 52 31 26 4 26 15 (489.
90) (5.
10) (2.
60) (3.
43) (6.
45) (2.
28) (1.
36) (1.
72) (2.
69) (13) (24) (13) (4) (10) (24) (11) (16) (6) (13) (10) (21) (11) (22) (9) (14) (7) (14) (10) poft tests <.
05 <.
01 <.
01 = .
10 = .
61 = .
06 <.
01 = .
93 <.
05 = .
89 = .
10 <.
05 <.
01 = .
05 = .
15 <.
05 = .
05 <.
05 = .
05 <.
05 = .
58 <.
05 = .
49 <.
05 = .
08 = .
06 = .
11 <.
05 entertained at least one hypothesis and the absolute number of hypotheses that subjects entertained throughout the entire process.
 Hypothesis (17) was supported by these analyses.
 Pairs entertained hypotheses more often than Singles (See Table 3).
 Although the difference (74% versus 56%) was not significant, it approached the 10 percent level (t (16)= 1.
74, p=.
10).
 Pairs entertained about twice as many hypotheses as Singles (29.
56 versus 14.
00; t (16)=3.
25, p<.
01).
 The difference was most salient in the first half period (14.
56 versus 4.
67; t (16)=4.
81, p<.
001).
 Hypothesis (18): Pairs entertained alternative hypotheses more often than Singles.
 To conyince other members of the scientific community, scientists have to consider alternative plausible hypotheses.
 Therefore, talking about alternatives may also be important for discovery.
 (1) We measured the percent of units in which subjects entertained alternative hypotheses.
 (2) W e measured the number of 342 Table 4 Means (SDs) of performance scores according to occurrence of crucial experiments and explanatory activities Crucial experiments High Low Totals Explanatory activities Hiah 3.
75 (0.
50) 1.
75 (0.
50) 2.
75 Low 2.
00 (1.
41) 1.
83 (0.
75) 1.
90 Totals 2.
88 1.
80 different types of hypotheses that subjects entertained throughout the entire discovery process.
 As Table 3 shows, Pairs entertained alternatiye hypotheses more often than Singles (25 versus 6; t(16)=2.
09, p=.
05), and also, a greater variety of hypotheses (in total, 10.
44 versus 7.
78; t(16)=2.
02, p=.
06).
 The difference between Singles and Pairs in variety of hypotheses was especially dramatic in the first half of the session (7.
11 versus 2.
89; t (16)=4.
12, p<.
001).
 HypQth^is (19): Pair? tflUcgd abPtit jugttfipatiQn mprg pftgn than ginglgg, As scientific claims are accepted or rejected on the basis of evidence, talk about justification may predict success in discovery.
 One measure of justification is the percentage of units in which subjects talked about iustification by experimental results.
 Another is the pgrpgntagg Qf units in which subjects mgntigngd mqrg than one experimental result to justify their hypotheses.
 A third measure is the percentage of units in which subjects planned a new experiment to test a hypothesis.
 A fourth measure is the percentage of units in which subjects talked about the testability of hypotheses.
 A fifth is the percentage of units in which subjects argued against a justification (partner's or own).
 As Table 3 shows, all of the measures just described indicate that Pairs considered justification of their hypotheses more often than Singles (1.
 Justification with results: 41 versus 24; t (16)=1.
89, p<.
05; 2.
 Justification with several results: 35 versus 10; t (16)=2.
08, p=.
05; 3.
 Experiment to test a hypothesis: 37 versus 17; t (16)=2.
07, p=.
05; 4.
 Testability: 9 versus 2; t (16)=2.
21, p<.
05; 5.
 Justification with arguments: 24 versus 15; t (16)=2.
37, p<.
05).
 W e also combined three main measures, 1, 3 and 4, to form a summary measure of justification.
 Although the difference was not statistically significant.
 Pairs considered justification more often than Singles (58 units versus39;t(16)=1.
60,p=.
13).
 Overall, data suggest that an important reason why Pairs performed better is because they participated in explanatory activities such as entertaining hypotheses (hypothesis 2.
7), talking about alternative ideas (hypothesis 2.
8), and considering justification (hypothesis 2.
7) more often than Singles.
 Variables that affect performance To determine whether the differences in behavior we have identified between Pairs and Singles cause the differences in performance, we should inquire how well such measures as entertaining hypotheses and thinking about justification predict performance.
 Although the number of subjects in each condition was too small for muUiple regression analysis with many measures, exploratory regression analyses could suggest which variables were important for discovery.
 Therefore, we computed simple regressions between performance and each measure in Table 1, Table 2, and Table 3 in each condition separately.
 Although the previous analyses would suggest that entertaining hypotheses, considering alternatives, and thinking about justification would predict performance well, there were no significant correlations between performance and the verbal protocol measures (hypotheses, alternatives, and justification).
 Instead, the experiment space search measures were strong predictors of Pairs' performance, but did not predict Singles' performance at all.
 The strongest predictor for Pairs' performance was percentage of crucial experiments, which accounted for 78 % of the variance in Pairs' performance (F (1, 7) = 24.
11, p<.
01), but only 3 % of the variance in Singles' performance (F (1, 7) = 0.
23, p=.
65).
 W e propose the following interpretation of these findings: Hypothesis (110): Due to their active participation in explanatory activities.
 Pairs could use information from experiment space search effectively in order to make discoveries.
 On the Qthgr hand, Singlg? CQuld nQt dp sp bepauge they did nQt actively participate in explanatory activities.
̂  In order to check this possibility, we divided subjects according to their scores for percentage of crucial experiments, and their mean scores for explanatory acfivities (i.
e.
, the combined score of entertaining hypothesis and thinking about justification).
 Due to the small number of the subjects.
 Pairs and Singles were combined for this analysis.
 Table 4 shows that the Pairs and Singles who both conducted all of the crucial experiments and actively participated in explanatory activities outperformed the subjects who did only crucial experiments, only explanatory activities, or neither.
 An A N O V A shows significant main effects (crucial experiments: F(l, 14)=6.
94, p<.
05; explanatory activities: F(l,14)=4.
11, p=.
06) and interaction (F(l,14)=4.
97, p<.
05).
 It appears that neither crucial experiments nor 2 Remember that Pairs' and Single's percentages of crucial experiments were nearly equal (89% versus 87%).
 343 Table 5 Differences between Pairs and Singles in terms of requests for explanation Measures % of units with requests for explanation with requests for description and summary with requests for hypothesis with requests for justifications % of units with answers to requests for explanation (A/S) with answers to requests for description and summary (A/S) with answers to requests for hypothesis (A/S) with answers to requests for justification (A/S) means and (SDs) Pairs 38 5 24 11 80 (n=9) 100 (n=9) 73 (n=8) 78 (n=7) (21) (7) (22) (8) (19) (0) (20) (40) means and (SDs) Singles 20 (21) 2 (3) 17 (19) 1 (3) 44 (37) (n=7) 100 (0) (n=7) 48 (43) (n=7) 65 (21) (n=2) pott tests = .
10 = .
32 = .
46 <.
01 <.
05 = .
15 — explanatory activities, by themselves, were enough to lead to discovery.
 These data show clearly that entertaining hypotheses and thinking about their justification play important roles in discovery, especially when the experiments are informative.
 However, before reading a final conclusion about the role of explanatory activities, we should consider whether merely participating in explanatory activities is sufficient or whether collaborative explanatory activities are necessary, for two Singles could produce as much explanatory activity as one Pair.
 To test this possibility, we again examined the discussion processes of real Pairs and Hypothetical Pairs.
 As Table 3 shows, we had found no difference between those two groups in the number of hypotheses generated.
 In the case of the number of types of hypotheses, the Hypothetical Pairs were even better than the real Pairs.
 W e also checked other discussion measures, using the higher score of two Singles as a Hypothetical Pair's score.
 As Table 3 shows, in general, the real Pairs entertained alternative hypotheses and participated in justifications more often than the Hypothetical Pairs.
 As the performance of the real Pairs was better than that of the Hypothetical Pairs, these data suggest that interactive or collaborative explanatory activities are important.
 Reasons for differences in explanatory activity Why M Pair? gntgrtain hypQthg§Q$ and jggtifigatipng more often than Singles? In this section, we will list some plausible hypotheses to account for this difference.
 Scientific explanations move from a mere description of results, which doesn't generalize beyond the specific case; to a summary of results; to causal explanation of a phenomenon; to justification of the causal explanation.
 Each level of explanation could be regarded as an answer to a specific question.
 A description of results could answer: "What was going on?" A summary of results could answer: "How did it happen?" A causal explanation could answer: "Why did it h^pen?" A justification of explanation could answer: "What evidence supports the explanation?" When people asks themselves these questions, they often utter metacognitive statements such as "I am not sure what it means" and "I wonder how it happened.
" When we speak of requests for explanation in this paper, we include such metacognitive statements in addition to explicit questions.
 Not all explanations are responses to requests for explanation, but such requests may indicate important decision points requiring conscious, reflective thinking.
 Therefore, we tested the following two hypotheses.
 Hypothesis (21): Pairs requested explanations more often than Singles.
 Table 5 shows that Pairs made more requests for explanation than Singles (38 versus 20; t (16)=1.
77, p=.
10).
 The main difference was found in the requests for justification (11 versus 1; t (16)=3.
12, p<.
01); Pairs sometimes questioned whether their hypotheses were justified, while Singles rarely did so.
 Hvpothesis (22): Pairs answered such requests more often than Singles.
 Table 5 shows that Pairs answered requests for explanation more often than Singles (80 versus 44; t (16)=2.
59, p<.
05).
 The main difference was found in the answers to requests for hypotheses, although this difference did not reach statistical significance (73 versus 48;t(13)=1.
53,p=.
15).
 These data suggest that requests for explanation play an important role in producing explanations.
 Pairs participated in such activities more often than Singles.
 General Discussion Recent studies in cognitive psychology have shown that explanation plays an important role in problem solving and learning (Chi, Bassok, Lewis, Reimann, & Glaser, 1989; Chi, de Leeuw, Chiu, & LaVancher, 1944).
 Chi and her colleagues pointed out that selfexplanation is an important activity when learning from examples and from texts in scientific domains.
 Good learners, in contrast to poor learners, explained to themselves the 344 meaning of example procedures, or the content of the text, and related the procedures or the content to problem solving goals and higher level content knowledge.
 The simple intervention of prompting selfexplanation improved students' learning dramatically.
 Although these studies focused on individual learning situations, such explanatory processes seem to be even more important for collaborative learning situations.
 Studies of collaborative learning and problem solving in developmental psychology have also found that participation in explanatory activities makes students learn successfully through collaboration (e.
g.
, Brown & Palincsar, 1989; Kruger, 1993; Teasley, 1995).
 For example.
 Brown, Palincsar and their colleagues have developed a teaching strategy called "reciprocal teaching" in order to improve students' comprehension skills.
 The reciprocal teaching strategy, which includes explanatory activities, dramatically improved the students' comprehension as well as monitoring skills.
 These studies suggest that participating in explanatory activities in social situations also improves students' learning.
 All of the recent studies on explanatory activities including the present study converge to tell us that these activities are a crucial component of successful intellectual behavior.
 Explanatory activities help people to connect pieces of information into an organized theory.
 Having others as monitors encourages people to participate in such activity, and helps them to construct their theories more actively and more deeply (Miyake, 1986).
 Conclusion Scientific discoveries often are made in social situations, and collaborative research has been emerging rapidly as the predominate form of scientific activity in many domains, but most previous studies in the psychology of science have focused on individual discovery processes.
 On the other hand, a few recent studies in developmental psychology (see Azmitia & Perlmutter, 1989) and group problem solving (see Hill, 1982; Levine and Resnick, 1993) have examined the processes of collaboration.
 Our study identifies specific problem solving processes, notably explanatory activities and appropriate data collection, that are important to successful discovery, describes how these processes are accomplished, and shows how they are facilitated by collaboration.
 It thereby takes an essential first step toward integrating work on the psychology of science with work on the psychology of collaboration in order to capture a broader view of scientific discovery.
 Acknowledgment This research was supported by the A.
 W.
 Mellon Foundation under the project title, "The literacy in science research center at CMU.
" The preparation of this paper was also supported by McDonnell Foundation C S E P Postdoctoral Fellowship for the fust author.
 W e would like to thank David Klahr, Jill Larkin, Kevin Crowley, Chris Schunn, and two anonymous reviewers for comments.
 R e f e r e n c e s Azmitia, M.
 & Perlmutter, M.
 (1989).
 Social influences on children's cognition: State of the art and future directions.
 In Reese, H.
 W .
 (1989).
 Advances in child development and behavior.
 Vol.
22.
 San Diego, CA: Academic Press.
 Brown, A.
 L.
, & Palincsar, A.
 S.
 (1989).
 Guided, cooperative learning and individual knowledge acquisition.
 In L.
 Resnick (Ed.
), Knowing, learning, and instruction.
 N e w Jersey: Lawrence Erlbaum Associates.
 Kruger, A.
 C.
 (1993).
 Peer collaboration: Conflict, cooperation, or both? Social Development, 2, 165181.
 Chi, M.
 T.
 H.
, Bassok, M.
, Lewis, M.
, Reimann, P.
, & Glaser, R.
 (1989).
 Selfexplanations: H o w students study and use examples in learning to solve problems.
 Cognitive Science, 13, 145182.
 Chi, M.
 T.
 H.
, de Leeuw, N.
, Chiu, M.
, & LaVancher, C.
 (1994).
 Eliciting selfexplanations improves understanding.
 Cognitive Science, 18, 439477.
 Dunbar, K.
 (1993).
 Concept discovery in a scientific domain.
 Cognitive Science, 17, 397434.
 Dunbar, K.
, & Schunn, C.
 D.
 (1990).
 The temporal nature of scientific discovery: The role of priming and analogy.
 In Proceedings of the Twelfth Annual Meeting of the Cognitive Science Society.
 N e w Jersey: Lawrence Erlbaum Associates.
 Hill, G.
 W .
 (1982).
 Group versus individual performance: Are N + I heads better than one? Psychological Bulletin, 91, 517539.
 Klahr, D.
, and Dunbar, K.
 (1988).
 Dual space search during scientific reasoning.
 Cognitive Science, 12, 148.
 Levine, J.
 M .
 & Resnick, L.
 B.
 (1993).
 Social foundations of cognition.
 Annual Review of Psychology, 44, 585612.
 Miyake, N.
 (1986).
 Constructive interaction and the iterative process of understanding.
 Cognitive Science, 10, 151177.
 Schunn, CD.
, & Dunbar, K.
 (in preparation).
 Priming, analogy, and awareness in complex reasoning.
 Submitted manuscript.
 Simon, H.
 A.
 & Lea, G.
 (1974) Problem solving and rule induction: A unified view.
 In L.
 W .
 Gregg (Ed.
), Knowledge and cognition.
 N e w Jersey: Lawrence Erlbaum.
 Shrager, J.
, & Langley, P.
 (1990).
 Computational approaches to scientific discovery.
 In J.
 Shrager & P.
 Langley (Eds.
).
 Computational models of scientific discovery and theory formation.
 San Mateo, California: Morgan Kaufmann.
 Teasley, S.
 D.
 (1995).
 The role of talk in children's peer collaborations.
 Developmental Psychology, 31, 207220.
 345 Collaborative Processing of Incompatible Information Carol Chan Faculty of Education Saint Mary's University Nova Scotia, Canada, B 3 H 3C3 c c h a n O h u s k y l .
 s t m a r y s .
 c a Abstract This study examined the effects of peer collaboration and investigated discourse activity employed by successful and unsuccessful learners in the domain of biological evolution.
 Participants included 108 students from grades 9 and 12 assigned to four conditions; individualassimilation, peerassimilation, individualconflict, and peerconflict.
 Depending on the condition, students were asked to think aloud or discuss with their peers eight scientific statements presented in the order which either maximized or minimized conflict.
 Several measures of prior knowledge and posttest conceptual change measures were obtained.
 There were no significant peer effects on conceptual change; a number of interaction effects indicated that peer collaboration was beneficial for older students and when conflict was maximized.
 Indepth analyses of discourse activity were conducted for four successful and four unsuccessful leamers based on posttest gain scores.
 Unsuccessful leamers tended to assimilate information from their peers as if it were something ateady known.
 Conversely, successful leamers were engaged in problemcentred discourse moves treating new information from their peers as something problematic which requires explanation.
 Contrasts between groups indicated significant differences in problemcentred discourse moves.
 A c o m m o n approach to fostering scientific understanding is to encourage students to make their ideas explicit and to compare their ideas to those of their peers.
 It is believed that engaging students in scientific discourse will help them examine their o w n perspectives, evaluate alternative conceptions, and identify conflict which could then lead to conceptual change (Lonning, 1993; Mandl, D e Corte, Bennett, & Frederich, 1990; Palincsar, Anderson & David, 1993).
 Despite much enthusiasm with collaborative science learning, empirical findings on the efficacy of peer interaction in conceptual change have been equivocal: ideational confrontation is effective with the older students, but not the younger ones (Champagne, Gunstone, Klopfer, 1985); conflict is often undetected (Dreyfus, Jungwirth, & Eliovitch, 1990); and social norms tend to outweigh theoryevidence coordination in peer learning (Pintrich, Marx, & Boyle, 1993).
 A theme of emerging interest in collaborative science learning is h o w students talk about science (Lemke, 1990).
 Research on discourse processes has shown considerable differences in h o w students approach collaborative learning situations: M a n y students engage in some kind of colloquial discourse using debilitating strategies (Eichinger & Anderson, 1992); conversely, others construct collaborative explanations in negotiating their convergent understanding (Roschelle, 1993).
 There is a need to examine h o w students construct knowledge in collaborative science learning.
 Increased attention has now been given to constructive activity in science learning (Chi, de Leeuw, Chiu, & LaVancher, in press).
 Research on knowledge building has identified two contrasting approaches to leamingproblemminimization versus problemcentred learning (Bereiter & Scardamalia, 1993).
 Whereas some students simply assimilate or reject new information to minimize belief revision, others employ a problemcentred approach, treating new information as something problematic which needs to be explained.
 Students' problemcentred approach to integrating text information has been shown to be an important predictor of posttest learning (Chan & Bereiter, 1992; Chan, Burtis, Scardamalia, & Bereiter, 1992) Since information from peers needs to be processed and interpreted, it follows that discourse moves can be conceptualized as a kind of collaborative constructive activity and analyzed based on the framework of problemcentred learning.
 Instead of merely assimilating or refuting the peer responses, students using problemcentred discourse moves jointly identify difficulties in what their peers say, formulate problems into questions of enquiry, and engage in collaborative explanation.
 If conceptual change involves learning of ontologically incompatible concepts (Chi, Slotta, & de Leeuw, 1994), problemcentred discourse moves may be important because they enable students to avoid equating new concepts with prior conceptions, to recognize difficulties with the status of the new concepts, and to collaboratively construct what they need to understand.
 This study examined collaborative science learning in the context of h o w student dyads jointly process text information which contradicts what they believe.
 The domain of investigation is biological evolution.
 The first goal was to examine whether peer collaboration fosters deeper processing activity and conceptual change, by 346 comparing an individual and a peer condition.
 In addition, comparisons were also made between two different age groups, and two groupings in which conflict was either maximized or minimized.
 The second goal was to characterize how successful and unsuccessful learners differed in their constructive discourse activity in collaborative learning.
 Specifically, we sought to examine whether successful students engaged in more problemcentred discourse moves in collaborative knowledge construction.
 Method Subjects Participants included 108 students, 54 in grade 9 and 54 in grade 12 fiom a suburban high school.
 They had no previous formal instruction in evolution, and students holding a creationist view were not included in the study.
 Test Material This paper was based on a larger study designed to examine the effects of conflictual information on conceptual change.
 A computerbased connectionist methodology was developed to provide a systematic way to present students with scientific information at different degrees of discrepancy from their beliefs (for details, see Chan & Bereiter, 1992).
 Three groups of units were included: (a) four "factorstatement" units, (b) eight "specificstatement" units, and (c) eight "probestatement" units.
 In the experiment, students were asked to rate on an 11point scale the importance of four factor statements about evolution: (1) PurposeEvolution is directed by needs and purposes of animal species; (2)Battle~Evolution is a battle of stronger species killing off weaker ones; (3) Environmental Determinism—Evolution depends on changes which occur in the environment; (4) ChanceEvolution depends on changes which first occur by chance.
 Students' ratings, which indicated their conceptions, were entered as inputs to a competitive activation network where outputs were the activation levels of a set of eight "probe" statements—scientific information which contradicts students' naive conceptions (e.
g.
, N e w characteristics arise first by chance, not by needs.
 Random changes in genetic material through mutation or genetic recombination produce new variations whether animals need them or not).
 Activation of the network allows each student's patterns of agreement and disagreement to the four factors to be used to identify whether he or she will agree with the probe statements.
 Accordingly, the experimenter could systematically provide the student with probe statements which were, in varying degrees, congruent or contradictory to his or her beliefs.
 Conditions Students were randomly assigned to one of the four conditions: (a) individualassimilation, (b) peerassimilation, (c) individualconflict, and (d) peerconflict.
 Student dyads from the same grade level read the statements together to negotiate their understanding of evolution; no elaborate instruction was given on collaboration strategies.
 Since most students held similar intuitive conceptions, they were not grouped according to differences in conceptions.
 Students in the individual condition were asked to read and think aloud about the statements.
 In the conflict conditions, students were presented with eight scientific (probe) statements in the order which was maximally conflictual to their beliefs; in the assimilation conditions, the ordering of statements was maximally congruent.
 Procedure Pretest.
 Students were asked to (a) tell what they know about evolution; (b) rate eight specific statements; (c) rate four factor statements.
 Student dyads were assessed individually on the first two tasks, and they worked together on the third one.
 Experiment.
 Students were presented with eight scientific statements, one at a time, and asked to think aloud or discuss the new information.
 They were then given the opportunity to revise their ratings of the four factor statements.
 This procedure was followed until all eight probe statements had been presented.
 Student verbalizations were tape recorded and transcribed verbatim for analyses.
 Posttest.
 Students' posttest learning was assessed by asking them to (a) finalize the ratings of the four factor statements, (b) summarize their understanding of evolution, (c) tell what else they did not understand, (c) answer two application questions, and (d) rerate the eight specificstatements.
 All except the first task were administered individually.
 Measures KnowledgeProcessing Activity.
 Students' verbal responses to each probe statement were blind rated for knowledgeprocessing activity on a 5point scale: (l)SubAssimilation  react to new information at an associative level; (2) Assimilation  reject, ignore, or conflate new information with existing beliefs; (3) Comprehension paraphrase and ask surface questions; (4) Implicit Knowledge Building consider new information as something problematic which needs to be explained; and (5) Explicit Knowledge Building  accumulate new information to construct domain understanding.
 Verbal responses from student dyads were coded separately; coding was based on the utterance which showed the highest level of knowledgeprocessing activity.
 Interrater 347 reliability is 0.
85 for the individual condition and 0.
81 for the peer condition.
 Knowledge Quality (Qualitative Measure).
 Posttest learning on summary, wonderments, nearapplication and farapplication was rated on a 5point scale ranging from intuitive, mixed to scientific understanding.
 The interrater reliability for these four measures ranged from 0.
86 to 0.
95.
 p<.
05) on this negotiated score.
 The result indicates that peers performed better than individuals in the conflict condition.
 N o significant peer effects were obtained for the specificstatement ratings.
 Taken together, these findings show that peer collaboration in itself did not promote higherlevel processing activity or posttest conceptual change.
 It was, however, more advantageous for older students and in situations when conflict was maximized.
 Specific Statement and Factor Statement Ratings (Quantitative Measures).
 Student ratings on the eight specific statements (11point scale) were obtained at pre and posttests.
 Ratings on the four factorstatements (11point scale) were also obtained at preposttests, and on each occasion when students were presented with a new probe statement.
 Results Peer Collaboration and KnowledgeProcessing Activity A three way A N O V A (Grade x Peer x Conflict) on mean knowledgeprocessing ratings showed no significant peer effects; significant grade and conflict effects were obtained.
 Further analyses of the proportions of different levels of knowledgeprocessing responses indicated significant effects for decreased assimilative (F(l,100) = 4.
76, 2<05) and increased comprehension (F (1,100) = 8.
58, Q'^.
Ol) activity favoring peer group; no differences in highlevel knowledgebuilding activity were obtained.
 There were no interaction effects.
 Peer Collaboration and Conceptual Change Peer Collaboration and Knowledge Quality.
 The four posttest qualitative measures were combined to produce a single composite score, called Knowledge Quality, using principal component analysis.
 A threeway A N O V A (Grade x Peer x Conflict) on knowledge quality showed no peer effects although there was a trend favoring grade 12 in peer conditions.
 Corresponding analyses of individual scores showed a significant peerbygrade interaction effect for summary (F (1,100) = 5.
34, E<.
05) and a marginally significant peerbygrade interaction effect for nearapplication (F (1,100)= 2.
89, 2 =.
08).
The results suggest that grade 12 students performed better in the peer condition but the effects were absent in grade 9.
 Peer Collaboration and BeliefChange Ratings.
 A threeway A N C O V A (Peer x Grade x Conflict) on posttest factor statement ratings controlling for pretest ratings showed no significant main effects.
 However, a significant peerbyconflict interaction effect was obtained (F (1,100) = 4.
25, Discourse Patterns of Successful and Unsuccessful Learners Qualitative Analysis.
 The preceding results suggest that only some students benefited from peer collaboration.
 It would therefore be important to examine what successful and unsuccessful students do differently in collaborative learning.
 In the initial analysis, an overall score was given to students' knowledgeprocessing activity in integrating text information.
 To examine how students coconstruct knowledge, indepth analyses were conducted to analyze their discourse moves based on the framework of problemcentred learning.
 Problemcentred discourse moves are operationalized as any utterances which treat information from peers and texts as problematic, in need of explanation.
 These responses do not include unelaborated questions, simple requests for help, or refutation without identifying source of difficulties.
 Excerpts from two dyads, each followed by an interpretation, provide examples of problemcentred discourse moves.
 As well, they show how successfijl and unsuccessful learners approach the collaborative learning situation.
 Dyad #1 Probe Statement: A n animal cannot evolve by adapting to its environment.
 It is the environment which selects the welladapted animals.
 A deer cannot choose to evolve long legs although long legs are important for survival.
 Some deer, however, may be b o m with longer legs which allow them to run faster.
 These individuals have a better chance of survival and leave more offspring.
 SI A: Maybe there is something to do with genes with the long legs, so a deer cannot choose to have long legs.
 However, they may be born with longer legs.
 So, that may be chance.
 So, [name of student], does it have something to do with chance? Is it possible that this card has a double meaning? (#1) SIB: Probably.
 The deer that are born with longer legs have a better chance of survival.
 It does have something to do with chance.
 (#2) SI A: But chance (card 4) is pretty high up already, would you want to change it? (#3) SIB: I think it is good (#4) SI A: / think it is fine.
 Is there a right or wrong 348 answer to it? (#5) SIB: Did we get any right? (#6) In this example, SI A initiated a problemcentred move and requested information from his peer (#1).
 Interestingly, even though his statement consisted of new information which was different from what SIB believed, the difference was not recognized.
 Instead of treating this new piece of information as problematic and attempting to explain what was said, SIB responded by giving a simple text paraphrase (#2).
 Similar to direct assimilation of new text information, SIB equated what SI A said about 'chance' with his everyday understanding (Some deer have a better chance of survival).
 Interestingly, SIB's utterance, which should have caused some problem or conflict for SI A, was simply ignored.
 SI A responded with a superficial move, treating SIB's response as satisfactory (#3).
 Enquiry was terminated and the problem was apparently settled.
 The last few moves (#4#6) suggest that the two students were merely concerned with a taskcompletion activitygetting the correct ratings.
 Dvad #2 T w o excerpts were taken from another dyad who demonstrated considerable success in advancing their knowledge in their discourse.
 S2A: I'm not sure if it's a moth, but they noticed something that became pitch black.
 (#1) S2B: It became pitch black because of what? (#2) S2A: It developed a darker color because the pollution affected the moth.
 I guess the cells go through a color change.
 So this should be higher [Card 3 environment card].
 (#3) S2B: But this [text] is saying, basically, it is not dependent on the environment.
 (#4) S2A: N o yeah.
 Wait (reread text).
 See, if this is true, I find that difficult to agree with this [text] because if there is some environmental change, it will kill the species.
 I don't know.
 (#5) In response to the probe statement, S2A recalled her prior knowledge (#1).
 S2B initiated a problemcentred move by asking S2A to explain the data (#2 ~ because of what?).
 S2A explained and constructed her argument in favor of environmental change (#3).
 S2B disagreed by pointing out the discrepancy between S2A's explanation and the new information (#4).
 A problemcentred move was coded because Dyad #2, unlike Dyad #1 who ignored new information from peers, demonstrated a careful uptake of information as S2A identified the source of difficulty (text) which posed a problem to be explained.
 Instead of assimilating the new information or providing a justification to defend her claim, S2A responded with another problemcentred move by trying to deal with the conflictuai information posed by her peer (#5).
 She reread the information {no, wait) and identified the knowledge conflict {1 find it difficult to agree with this because) even though she did not have enough information to resolve the problem then.
 In treating their peer's responses as problems that needed to be dealt with, the dyad continued to make progress in their discourse.
 S2A: So, first, what they are saying is that it cannot evolve by adapting.
.
.
Oh, I see.
 (#6) S2B: I don't.
 (#7).
 S2A: You don't.
 OK.
 What they are saying, first, they are saying the environment does not affect the adaptation of the animal.
 If the animal somehow changes, then due to its environment, it might survive.
 I think that's what they are saying.
 There is always this conflict of whether it is environment or needs which cause change, and I see that scientists say it's by chance and that .
.
.
 what do you think? (#8) .
.
.
.
 S2B: Well, it's just the fact that I still think the environment has an effect on evolution, and it (text) is saying that it's not.
 (#9) S2A: In a way, I am starting to get convinced with this.
 Just think about it this way.
 If the environment happens to be a rocky terrain, and you have an animal like a goat which climbs up the rocky terrain.
 Well, let's say, it's some sort of goat born in a sandy terrain, it probably would not survive.
 So, in other words, the best environment the animal would survive is the best suited environment, right? But the environment does not have to necessarily change for the animals to change along with it.
 Is this what they are saying? (#10) The second excerpt was based on the dyad's responses to a later probe statement.
 As S2A started to process the text information (#6), S2B responded by acknowledging her lack of understanding (#7).
 These two utterances were not coded as problemcentred moves based on our scheme because they were simply text paraphrases and requests for help.
 S2A then took the opportunity to elaborate and explain the new information to S2B.
 It is interesting to note that as S2A explained, she then detected a problem with her understanding—the conflict between different hypothesesand thus generated another problemcentred move (#8).
 As the discussion continued, this student dyad continued to deepen the discourse by posing problems to each other.
 At a later point in time, S2B stated that she still had this lingering doubt about the role of environment, which seemed to be different from what the scientists said (#9).
 S2B's problemcentred move then elicited S2A's elaborate explanation on environmental selection.
 Again, S2A did not seem to consider her explanation as definitive as she once again subject her understanding to joint enquiry 349 (#10).
 In employing problemcentred discourse moves, these two students recognized difficulties, sought out discrepancies, elicited and helped each other construct explanations.
 Quantitative Analysis.
 Analyses were conducted to contrast the discourse patterns of successful and unsuccessful learners to examine whether problemcentred moves are related to learning.
 Based on students' gain scores on factorstatement ratings, two highestachieving (4 H A ) and two lowestachieving dyads (4 L A ) were selected for indepth analyses.
 Student verbalizations across the eight probe statements were individually coded for problemcentred moves.
 The mean number of utterances were 46.
8 and 61.
5 for the highachieving and lowachieving group respectively.
 The highachieving students made fewer but more elaborate responses whereas the lowachieving ones produced many more short utterances.
 The mean number of problemcentred moves were 14.
2 for the highachieving group and 2.
0 for the lowachieving group (t(6) = 2.
9, e<.
05).
 The difference is more pronounced when proportion rather than frequency is used in the analysis (t (6) = 3.
6, e<.
02).
 These results suggest that successfiil studentdyads generated more problemcentred discourse moves in collaborative knowledge construction.
 Discussion This study examined constructive learning activity in collaborative science learning.
 Simply putting students together is not necessarily beneficial.
 Although peers engaged in more textcomprehension activities than individuals, there were no differences in deep knowledgeprocessing activity or posttest learning.
 Surfaceconstructive activities such as paraphrases may not be effective in promoting science learning (Chi et al.
, in press).
 Consistent with the positive effects for more advanced students (Champagne et al.
, 1985), the older students in this study benefited more from peer collaboration.
 There were no pretest priorknowledge differences; the results, therefore, suggest that older students were engaged in different sorts of constructive discourse activities, which facilitated their learning.
 The peerbyconflict effect on the negotiated score provides some support for the cognitive conflict hypothesis; caution needs to be taken since the effects were not carried over to the individual tasks.
 Detailed analyses are required to examine constructive discourse activity in response to contradictory information.
 Analysis of the discourse activity of successful and unsuccessful learners showed the different ways in which they approached the learning task.
 The successfiil student dyads were found to engage in more problemcentred discourse moves—recognizing difficulties, identifying problems, and constructing explanations.
 Some features of problemcentred discourse moves have been absfracted to shed light on why they may be effective in collaborative science learning.
 Problem Recognition.
 Student varied in the extent to which they attended to what their peers said.
 For example, Dyad #1 did not understand what each other were saying; they conflated information from their peers and equated it as something already known (e.
g.
, chance).
 Conversely, successful students were on the lookout for discrepancy, inconsistency and lingering doubts.
 Not only did Dyad #2 attempt to understand what each other said, they also actively sought out problems in what was said in relation to the new information.
 Problem recognition may play a role in the learning of incompatible concepts (natural selection, in this case): It helps students to refrain from direct assimilation, to identify sources of difficulties, and to create meaningful internal conflict based on the contradictory information.
 Problem Representation.
 It is now commonly accepted that experts represent problems at a deeper level, whereas novices attend only to the surface features (Chi, Glaser & Farr, 1988).
 Consistent with research on discourse processes (Roschelle, 1993), the present findings show that the expert and novice learners differed in the kinds of problems they chose to work on.
 Dyad #1 seemed concerned with the literal features of the text and the correctness of ratings.
 Dyad #2, however, were tackling a deeper problem of domain understanding as they pondered the relative importance of conflicting explanatory models {There is always this conflict of whether it is environment, needs, or chance?).
 Although the construction of deep problems does depend on prior knowledge, the expert learners were able to move towards deeper understanding by actively constructing connections among discordant pieces of text information.
 ProblemCentred Explanation.
 As students engaged in problem recognition and problem formulation, it led to another positive effect  elicitation of explanations for self and peers.
 The present data are consistent with the findings on the effects of selfexplanations (Chi et al.
, in press); problemcentred moves are one form of constructive activity which may help elicit selfexplanations.
 Evidently, students may generate inaccurate explanations in science learning due to incompatible prior knowledge.
 Nevertheless, those w h o employ problemcentred moves may benefit more compared to those w h o provide oneshot explanation to justify their beliefs or to refiite discrepant arguments from their peers.
 In viewing their knowledge as problematic and as requiring explanations, students are engaged in an ongoing process of problem recognition and conflict resolution.
 Even if they have constructed inaccurate explanations (e.
g.
, S2A, moves #3 & #5), they 350 are more likely to detect anomalies in upcoming information and revise their models continually.
 It may be said that the above analysis has not taken account of the powerful roles of social norms and structures among high school students.
 Socialcontextual variables may indeed be important in science learning; this study, however, has focused on examining what discourse activity facilitates coconstruction of knowledge.
 Although it is useful to have students talk about science, the benefits probably stem from the kinds of constructive activity undertaken in collaborative leamingwhat kind of talk promotes learning.
 This study employs a cognitive constructivist perspective to examine collaborative science learning.
 Extending earlier findings on problemcentred learning (Bereiter & Scardamalia, 1993; Chan et a!.
, 1992), there is evidence suggesting the positive effects of problemcentred discourse activity on subsequent learning.
 In order to help students move from colloquial to productive discourse, there is a need to encourage students to seek out knowledge conflict, formulate productive questions, and construct explanations in collaborative problemcentred enquiry.
 References Bereiter, C , & Scardamalia, M .
 (1993).
 Understanding expertise.
 La Salle, IL: Open Court.
 Champagne, A.
N.
, Gunstone, R.
F.
, & Klopfer, L.
E.
 (1985).
 Effecting changes in cognitive structures among physics students.
 In L.
H.
T.
 West & A.
L.
 Pines (Eds.
), Cognitive structure and conceptual change.
 Orlando, FL: Academic Press.
 Chan, C.
K.
K.
, & Bereiter, C.
 (1992, April).
 Effects of conflict and knowledge building strategy on conceptual change.
 Paper presented at the annual meeting of the American Educational Research Association, San Francisco.
 Chan, C.
K.
K.
, Burtis, P.
J.
, Scardamalia, M.
, & Bereiter, C.
 (1992).
 Constructive activity in learning from text.
 American Educational Research Journal, 29 (1), 97118.
 Chi, M.
T.
H.
, de Leeuw, N.
,Chiu, M.
H.
, & LaVancher, C.
 (in press).
 Eliciting selfexplanations improves understanding.
 Cognitive Science.
 Chi, M.
T.
H.
, Glaser, G.
, & Farr, M.
 (1988).
 The nature of expertise.
 Hillsdale, NJ; Erlbaum.
 Chi,M.
T.
H.
, Slotta, J.
D.
, & de Leeuw, N.
 (1994).
 From things to processes: A theory of conceptual change for learning science concepts.
 Learning and Instruction, 4, 2743.
 Dreyfus, A.
, Jungwirth, E.
,& Eliovitch, R.
 (1990).
 Applying the "cognitive conflict" strategy for conceptual change: Some implications, difficulties and problems.
 Science Education, 74 (5), 555569.
 Eichinger, D.
C.
, & Anderson, C.
W.
 (April, \992)Analyses of middle school students' scientific arguments in collaborative problemsolving contexts.
 Paper presented 21 the American Educational Research Association, San Francisco.
 Lemke, J.
 L.
 (1990).
 Talking science: Language, learning, and values.
 N e w Jersey: Ablex.
 Lonning, R.
A.
 (1993).
 Effect of cooperative learning strategies on student verbal interactions and achievement during conceptual change instruction in 10th grade general science.
 Journal of Research in Science Teaching, 30(9), 10871 lOI.
 Mandl H.
, DeCorte, E.
, Bennett, N.
 & Frederich, H.
F.
 (1990).
 Learning and instruction: Social and cognitive aspects of learning and instruction.
 Oxford: Pergamon.
 Palincsar, A.
S.
, Anderson, C , & David, Y.
M.
 (1993).
 Pursuing scientific literacy in the middle grades through collaborative problem solving.
 The Elementary School Journal, 93(5), 643659.
 Pintrich, P.
R.
, Marx, R.
W.
, Boyle, R.
A.
, (1993).
 Beyond cold conceptual change: The role of motivational beliefs and classroom contextual factors in the process of conceptual change.
 Review of Educational Research, 63, 167199.
 Roschelle, J.
 (1993).
 Learning by collaborating: Convergent conceptual change.
 Journal of the Learning Sciences.
 2 (3), 235276.
 351 A Theory of the Multiple Roles of Diagnosis in Collaborative Problem Solving Discourse Cynthia S.
 Gadd School of Business Administration College of William and Mary Williamsburg.
 V A 23185 c s g a d d @ m a i 1 .
 w m .
 e d u Abstract A better understanding of the nature of consultations between professionals engaging in the collaborative process of solving complex problems — expertise in use — offers the potential to reshape our ideas about how to design computer systems that can engage in collaborative problem solving with their human cohorts.
 The research reported here has sought to account for key behaviors contributing to successful consultation, as identified by a cognitive task assessment of humanhuman consultation discourse in the medical teaching rounds setting.
 W e have come to view the communication acts of the presenter/investigator as evidence of his deliberate intention to indirectly construct a particular model of the patient's case — his model — in the expert's mind, resulting in two separate but related diagnostic tasks for the expert: one at the patient level and one at the presenter/investigator level.
 This dualdiagnostic theory of expert understanding of the presenter/investigator's communication actions is partially implemented in the RUMINATE program.
 The theory provides insights into the expert's capacity to model aspects of the presenter/investigator's competence — insights that contribute to our understanding of expertise embedded in the context of collaborative problem solving discourse.
 Introduction In (Evans & Gadd, 1989; Gadd, 1995; Gadd & Pople, 1988; Gadd & Pople, 1990) w e describe a cognitive task analysis of medical rounds discourse, a form of consultation in which one of the partners, the presenter/investigator, m a y not be a domain expert but possesses a competence in the domain and has been responsible for gathering and performing the initial analyses of the data available about the problem to be solved.
 The second partner, the expert or consultant, has the benefit of years of experience solving problems in the domain, but in this instance he is reliant upon the presenter/investigator for access to m u c h of the case data.
 W e claim that such consultations require a complex model of expertise, in which skillful execution of the roles of teacher, critic, and communicator leads to superior collaborative problem solving.
 Our analysis of a large corpus of teaching rounds discourse dala^ led us to assert that m u c h of the expert behavior ^ The data set consists of eleven complete internal medicine teaching rounds cases recorded at hospitals affiliated with the observed in roimds could possibly be explained by detecting the presence of local incoherencies in the discourse relative to the expert's model of the problem state — a singlemodel approach which w e suggest is sufficient for readily recognizable divergences from the expert's model (see Evans & Gadd, 1989).
 Our analysis also indicates that there were instances when the expert focused upon the source, in addition to the presence, of incoherency, requiring a multiplemodel (expert/nonexpert) approach in which the expert seeks to uncover the reasoning processes by which the presenter/investigator has come to see the problem.
 In (Evans & Gadd, 1989) w e suggested the possibility of generating an alternative agent model from the expert model, for those situations when the singlemodel approach was inadequate;and, in (Gadd & Pople, 1988; Gadd & Pople, 1990), described an early version of a multiplemodel approach to diagnostic reasoning in collaborative discourse settings.
 In this paper, w e refine this theory of the expert's reasoning regarding the presenter/investigator's intended model of patientspecific reasoning in a clinical consultation and introduce RUMINATE, a computerbased simulation intended to demonstrate the plausibility of the theory.
 The contributions of this work are addressed in the introduction to the following section and in the conclusions.
 A Theory of the Multiple Roles of D i a g n o s i s in C o n s u l t a t i o n Stated in general terms, diagnosis is the formulation and evaluation of competing hypotheses that could accoimt for some observed behavior or evidence.
 In this model w e are proposing that the expert uses two very similar versions of this generic diagnostic process to perform inference in two distinctly different hypothesis spaces.
 These hypothesis spaces correspond to the expert's intertwined goals of a) understanding the patient's medical problem, and b) evaluating the expertise of the presenter/investigator (the person presenting the patient data, w h o m w e assume to also be the physician working up the case).
 In medical teaching University of Pittsburgh School of Medicine and Mercy Hospital in Pittsburgh, PA.
 W e also analyzed transcripts of specialty consultations, including those conducted facetoface and by telephone.
 The cognitive task analyses of the more than twenty hours of transcripts utilized techniques adapted from linguistics and discourse understanding research.
 352 rounds, caserelated observable behavior available to the expert arises from several sources — including the presenter/investigator's communication acts (usually in the form of reports of findings or manifestations of (iiscasc that are present or absent in the patient; see Figiuc 1 lor an example), a physical exam performed by the expert at the bedside, and review of imaging output and laboratory data.
 Presenter/investigator: .
.
.
 his complaints are those of u m dysphagia which is ah marked by sticking in the low retrosternal area and some pains a dull pain in that area ah the pain is dull it's not of a burning quality and it doesn't radiate any where .
.
.
 Figure 1: Example of presenter/investigator's reports Case 4 (lines 3046 in the original transcript) This research has focused upon the presenter/investigator's communication acts as the source of evidence for both diagnostic processes.
 The first diagnostic process focuses on an explanation of the patient's observed (or at least reported) medical condition, in terms of diseases that could have caused or contributed to a specific set of findings.
 The second diagnostic process, and the part of the proposed model demonstrated by the RUMINATE implementation, focuses on a very different explanation task: h o w the presenter/investigator's communication acts, in the form of reports about the patient's medical problems, can be explained in terms of plausible patterns of medical diagnostic reasoning.
 W e view the communication acts of the presenter/investigator as evidence of his deUberate intention to indirectly construct a particular model of the patient's case — his model — in the expert's mind.
 There are several key phrases in this description of the presenter/investigatorlevel of diagnosis, each of which will be discussed in turn.
 Deliberate intention.
 First, by referring to the presenter/investigator's deUberate intention w e emphasize the relationship between this research and the basic idea of the early work of Allen, Cohen, and Perrault (Allen & Perrault, 1980; Cohen & Perrault, 1979): that acts of communication were planned in order to achieve certain goals.
^ T h e presenter/investigator's presentation is the result of his deliberate intention to influence the expert's beliefs by having the expert construct a model of the patient's case that is congruent with his own, thereby demonstrating his diagnostic and commimicative competence.
 For his part, the expert is a willing constructor of such a model, since it serves his goal of evaluating the presenter/investigator's ^ Many researchers have explored the relationship between behefs, intention, and discourse plans (Carberry, 1983; Grosz & Sidner, 1986; Litman, 1985; Moore & Swartout, 1989; Pollack.
 1986).
 diagnostic and communicative competencies.
 Therefore, as he uses the presenter/investigator's communication acts to put this model together, he also judges it for completeness, lack of ambiguity, and accuracy.
 Indirect construction.
 Second, as w e discussed in our analysis of the transcript data (see Evans & Gadd, 1989), the process of diagnosis is not explicitly featured in the presenter/investigator's communication acts.
 The institutional norms of the Standard Order of Presentation (SOP) and the local topic structure of rounds discourse stipulate the terms of a contractual exchange between the expert and the presenter/investigator that can be characterized as a dialogue in which the presenter/investigator relies on indirect construction to convey his intended model.
 There are several reasons for these institutional norms, including ci) the difficulty of reconstructing the extensive diagnostic activity that was performed by the presenter/investigator prior to the presentation and b) the appropriateness of examining a specific diagnosis from multiple perspectives (e.
g.
, different physiological systems).
^ In adhering to the terms of this confractual exchange, the presenter/investigator uses the content and timing of the communication acts that comprise his presentation — his choices of which patient findings to present and when to present them — to indirecfly construct his intended model.
 Evidence interpretation.
 Finally, our reference to evidence of the presenter/investigator's deliberate intention to indirectly construct a particular model of the patient's case .
.
.
 in the mind of the expert corresponds directly to the second level of diagnostic reasoning described in the opening paragraph of this section: how the presenter/investigator's communication acts can be explained by the expert in terms of plausible patterns of patientspecific diagnostic reasomng.
 Note that in this second diagnostic process, it is the communication act of reporting a finding, rather than the content value of the finding, that serves as observed behavior or evidence in the diagnostic process.
 Although the source of evidence for both diagnostic processes is a presenter/investigator's utterance, such as "He has no jaundice," the actual evidence interpreted is different for each.
 The expert's patient diagnostic process uses the content value of the finding reported, in this case negative for jaundice, to downgrade the causal or contributory role of liver involvement.
 The expert's second diagnostic process, aimed at understanding the reasoning processes of the presenter/investigator, uses the act of reporting the finding as possible confirming evidence that the presenter/investigator has considered hver involvement as he attempted to perform his diagnosis of the patient.
 In the first case, the utterance containing the finding report impacts the expert's current understanding of the patient.
 In the second case the utterance impacts the expert's current understanding of the how the presenter/investigator intends for the expert to believe he has reasoned in his attempt to understand the patient.
 The distinction between these two diagnostic processes m a y seem subtle, but w e would argue it is essential to ^ Cf.
 (Cicourel, 1990) discussion of the social complexity of collaborative medical diagnosis.
 353 constructing a complete, multidimensional model of medical ex{x;rtise The first, diagnosing the patient, is crucial to the physician's long recognized role of medical problem solver, bringing to bear his knowledge of disease, physiology, etc.
.
 in a novel patient setting.
 The second, diagnosing the presenter/investigator, is equally crucial to the physician's role of consultant to less experienced or peer physicians, in which communication of medical knowledge (as both speaker and hearer) and evaluation of the other person's expertise are important tasks.
 Contribution.
 The dualdiagnostic model provides important insights into the relationship between the presenter/investigator's communication actions and the expert's capacity to m o d e l aspects of the presenter/investigator's competence regarding a) the presentation of information that is consistent with expectations of an institutionalized setting; and b) the appropriateness of the patientspecific reasoning he has intended to communicate by his presentation.
 Specifically, the model identifies those situations in the rounds discourse in which the expert can no longer bring his understanding of the p r o b l e m into c o n c o r d a n c e with the presenter/investigator's reports, and offers plausible alternative reasoning patterns as potential sources of the discordance.
 Our analyses of rounds discourse data indicate that these types of situations often result in expert interventions (i.
e.
, interruptions of the presenter/investigator's presentation in which the expert asks a relationshipseeking question in prelude to an explanation or Socraticstyle dialogue), and as such, are key to understanding expertise embedded in the context d" collaborative discourse.
 The following description of these two diagnostic processes, and the specific nature of their respective hypothesis spaces, contrasts the meaning and use of observed behavior as evidence in each.
 Patientlevel Diagnosis The focus of the expert's first diagnostic process is the patient's medical problem.
 In this diagnostic process, a hypothesis is formed for each disease that could be considered a candidate for explanation of the medical problem.
 The hypothesis space is m a d e up of all diseases that should be considered in an attempt to account for observed behavior or evidence, here defined as one or more medical findings and their associated values (e.
g.
, usually positive, negative, or a numeric value.
) The diagnostic process consists of forming and evaluating hypotheses about which disease(s) would best accoimt for the medical findings as they are provided as evidence.
'* Since there are often '* Although this research relies upon the hypotheticodeductive method most frequently associated with descriptions of medical problem solving, other research suggests that physicians' selection of datagathering and clinical reasoning strategies "is dependent on many factors, including knowledge, the discourse content, and the completeness and precision of information provided by the patient.
" (Patel, Evans & Kaufman, 1989, p.
 308).
 competing hypotheses^, there are situations in which quandaries arise as to which hypothesis best accoimts for the finding(s).
 A classic quandary in clinical medicine is that between assimilating a n e w finding with an existing hypothesis versus seeking an independent cause for it.
 A n example of a padentlevel quandary, derived in this case from the introduction of a positive finding of retrosternal pain, is shown in Figure 2.
 Patkntlcvel quandary Explainfinding: painretrosternal Considerboth: Assimilate w/ existing hypothesis and ^.
^__^____ Consider independent cause Consider independent cause Competinghypothesis: heart involvement Explainfinding: painretrostemal Attributedfindings: none Expectedfindings: painretrostemalradiating EKGpatternx Assimilate W existing hypothesis Existinghypothesis: esophageal involvement Explainfinding: painretrostemal stickingsensationretrostemal Attributedfindings: dysphagia Expectedfindings: painretrostemalbuniing regurgitationintomouthsour Figure 2: Patientlevel quandary The process of diagnosing the patient's medical problem includes determining what additional evidence, in the form of findings, would be useful to the expert in understanding the patient's problem.
 In the roimds setting, these additional findings (also shown in Figure 2) form a set of expectations for findings to be included in future reports by the presenter/investigator.
 Each n e w finding is interpreted with respect to its ability to increase or decrease the support for diseases in the existing hypothesis space or to change the formulation of the hypothesis space more dramatically, such as when existing patientlevel quandaries are resolved or new quandaries are created.
 T h e diagnostic process continues in this fashion, with the ultimate goal of converging on a consistent explanation of the patient's set of findings, in the form of one or more diseases.
 Presenter/investigatorlevel Diagnosis The focus of the expert's second diagnostic process is the construction and evaluation of the presenter/investigator's intended model of patientspecific reasoning.
 In this diagnostic process, a hypothesis is a pattern of reasonmg about the patientlevel diagnosis that could be attributed to the presenter/investigator, and the hypothesis space is the set of these reasoning patterns that could plausibly account for ^ This set of competing hypotheses is often referred to in clinical medicine as the differential diagnosis.
 354 the presenter/investigator's observed communication behavior — usually a report of a medical finding.
 Contrasting this form of evidence with that used at the patient diagnosis level, it is the act of reporting the finding, not the content value of the finding ( e g , jxisiiive, negative), that appears to be relevant to understanding the reasoning of the presenter/investigator.
^ In his task of constructing the model of patientspecific reasoning intended by the presenter/investigator's communication actions, our analyses suggest that the expert uses his o w n reasoning about the patient's problem as the nominal trajectory through the space of possible reasoning pattemsJ In other words, in the absence of indications to the contrary, the expert assumes the presenter/investigator's reasoning about the patient's problem should approximate his own.
 Like all default values, the expert's use of his o w n patientlevel diagnostic process as a hypothesis with respect to how the presenter/investigator has reasoned about the patient's medical problem has the potential to be disproven by subsequent evidence.
 Therefore, the expert's hypothesis space is also populated by plausible alternatives to the expert's preferred reasoning pattern.
 These alternatives m a y not be correct, in that they m a y lead to incomplete or even wrong patientlevel diagnoses, but they do provide the expert with some directions to explore if his nominal trajectory is unable to account for the presenter/investigator's subsequent utterances.
 Referring again to the point in our example when the new finding of retrosternal pain is reported, the expert's patientlevel diagnostic process formed a quandary between "assimilate with the esophageal problem", or "pursue one or more independent causes, such as heart involvement.
" However, it is also plausible that the presenter/investigator may not have considered the heart involvement at all — preferring to assimilate the pain fmding into the existing esophageal problem without consideration of any independent causes.
 The ultimate resolution of this issue is dependent upon evidence to be found in the presenter/investigator's subsequent utterances (eiflier voluntary or perhaps in response to indirect or direct questioning by the expert).
 Therefore the expert forms a second type of quandary, this one at the level of understanding the presenter/investigator's reasoning.
 This presenter/investigatorlevel quandary is between two plausible reasoning patterns, either of which could accoimt for the presenter/investigator's observed behavior: • Is he following the expert's nominal reasoning pattern (called the nominal path), in which a patientlevel quandary is created between assimilating the pain " Evidence may also arise from the failure to report an expected finding or even the act of reporting the ordering of a test without reporting its presently unavailable result.
 These sources of evidence are discussed fully in (Gadd, 1995).
 ' The expert's nominal trajectory refers to the reasoning that he has used to arrive at his current understanding of the patient, i.
e.
, his patientlevel diagnostic process.
 The nominal trajectory does not necessarily imply correctness in the absolute sense; instead it serves as a default hypothesis regarding the presenter/investigator's reasoning.
 finding with the esophageal problem or seeking an independent cause? or • Is he following an alternative pattern of reasoning (called the alternative path) in which the pain is assimilated within the esophageal problem without consideration of heart or other independent causes? In our example, this qixandary forms the current hypothesis space in the presenter/investigatorlevel diagnosis, shown in Figure 3.
 Ptesenter/investigatorlevel quandary Nominal path: Patient level quandary Alternative path: Assimilate w/existing hypothesis only —• Status: unresolved Statussupportedby: nil Patient level quandary Explainfinding: painretrosternal Considertx)th: Assimilate w/existing hypothesis and Consider independent cause Consider independent cause Competinghypothesis: heart involvement Explainfinding: painretrosternal Attributedfindings: none Expectedfindings: painretrostemalradiating EKGpatternx Assimilate w/ existing liypothesis Existinghypothesis: esophageal involvement Explainfinding: painretrosternal Attributedfindings: dysphagia stickingsensationretrostemal Expectedfindings: painretrosternalburning regurgitationintomouthsour Figure 3: Presenter/investigatorlevel quandary The presenter/investigatorlevel diagnostic process includes determining what additional evidence, in the form d" reports of findings, would be useful in furthering the expert's imderstanding of the presenter/investigator's reasoning.
 In this example, the expert can use the presence of heart fmding reports at appropriate times within the organization of the rounds presentation as evidence against the "assimilate with existing problem only" leg of his quandary about the presenter/investigator's reasoning (and the absence of such reports as evidence for the "assimilateonly" leg).
 Each new report by the presenter/investigator is interpreted with respect to its ability to increase or decrease the support for one of the competing reasoning patterns in the existing hypothesis space at this level of diagnosis.
 A new report m a y also have the effect of changing the form of the hypothesis space, by resolving a quandary at this level or causing a new one to be created.
 Quandary resolution is demonstrated in our example w h e n the finding of "no radiating quality associated with the retrosternal pain" is 355 reported.
 This report of a finding, which could indicate a heart problem such as angina but is not linked to any of the esophageal diseases, is likely to be interpreted by the expert as resolving his quandary about whether the presenter/investigator was considering heart involvement as well as esophageal involvement as a possible cause for the pain.
 In other words, the expert is able to assume, with more certainty as a result of this latest report, that the presenter/investigator's reasoning is congruent with his own.
 If, in this situation, the presenter/investigator does not report about the radiating quality of the pain before moving on to some other topic, the expert could interpret this "failed expectation" as resolving the existing quandary about the presenter/investigator's reasoning in favor of the "assimilateonly" path — or at least as supporting this alternative over his o w n preferred reasoning pattern.
 The expert has reached an evaluation point due to a perceived lack of congruence between his reasoning and that of the presenter/investigator.
 At such an evaluation point, the expert wants to explain the source of the apparent incongruence.
 H e m a y decide to intervene with a direct or indirect question to the presenter/investigator regarding consideration of heart involvement in this case.
 Or the expert m a y decide to defer action until some later point, continuing to gather evidence that m a y (or m a y not) provide insight into the source of the apparent incongruence.
 In the rounds discourses w e analyzed, evaluation points such as these appear to be an important source of the expert's discourse interventions, i.
e.
, questions or explanations.
 Finally, consider the situation if the presenter/investigator had reported ordering a complete heart workup instead of reporting the negative finding for radiating pain.
 Such a report would be of no value in the diagnosis of the patient, since it neither increases or decreases the support for any of the diseases hypothesized.
 However, it serves nicely as evidence to downgrade or eliminate the possibility that the presenter/investigator has not considered the potential causality between the retrosternal pain finding and heart involvement in his reasoning about the patient.
 In this situation, the report of ordering a diagnosticspecific procedure suggests that the presenter/investigator's reasoning and the expert's reasoning are congruent.
^ These examples of h o w three quite different resolutions to the original presenter/investigatorlevel quandary could occur serve to reiterate the points m a d e earlier about what constitutes evidence at the presenter/investigator level d" diagnosis.
 First, it is not the content value of the finding but the act of reporting it that matters since either a positive or negative value for the finding of radiating pain would have served equally well as evidence in favor of the presenter/investigator having considered heart disease.
 In our analyses of the teaching rounds transcripts (Evans & Gadd, ^ There are still some open issues here, such as does the pain have a radiating quality, is it appropriate to report a heart workup at this point in the rounds presentation (without reporting clinical evidence for doing so), and what exactly is meant by heart workup (e.
g.
, a cardiologist consult, a specific set of tests)? These issues may trigger evaluation points similar to the one described above.
 1989) w e observed that m a n y socalled "significant negatives" seem to be attributable to this type of signaling on the part of the presenter/investigator.
 Second, evidence about the presenter/investigator's reasoning can also be foimd in his failure to report a finding at an appropriate time in the rounds presentation — as demonstrated by the variation on our example in which the he does not mention the radiating quality of the pain before moving on to another topic.
 Our theory illustrates the interdependence of discourse structure and domainspecific reasoning by using transitions between segments in the S O P and between (sub)topics in the local topic structure as "forcing points" for the consideration of unreported but expected findings.
 Third, the presenter/investigator level of diagnosis m a y usefully interpret evidence that does not inform the patient level diagnostic process, such as the heart workup order.
 The interpretation of each new finding report m a y cause modifications to the presenter/investigatorlevel hypothesis space, which could occur as a result of the interpretation itself or as a result of pursuing the types of evaluation points described above.
 Following this interpretation, expectations for reports to be subsequently included in the rounds presentation are also revised.
 So the diagnostic process at this level continues, with the goal of achieving and maintaining congruence between the expert's and presenter/investigator's reasoning about the patient; or in other words, to facilitate the development of a shared understanding of the patient's medical problem.
 The RUMINATE Program The purpose of the RUMINATE program was to take what has been a fairly theoretical discussion of how consultations work and enable the level of discourse to be brought to a much more concrete level.
 The R U M I N A T E program requires several knowledge sources: knowledge about how clinicians perform patientspecific diagnostic reasoning, including a representation language for individual reasoning actions and the permissible relationships between them; knowledge about the types of uncertainty (called quandaries) that an expert clinician m a y have about the reasoning of a presenter/investigator; and knowledge about what constitutes evidence that will contribute to the resolution of quandaries that an expert clinician m a y have about the reasoning of a presenter/investigator.
 The reasoning processes perfonned by RUMINATE closely follow the presenter/investigatorlevel diagnostic reasoning process described in the previous section.
 First, RUMINATE models how an expert clinician uses both the content and timing of a presenter/investigator's communication actions to *ain insight into the presenter/investigator's patientsj)ecific diagnostic reasoning.
 This is accomplished through plan induction, in which a default reasoning path, its alternatives, and imcertainties with respect to the presenter/investigator's adherence to one or more of these paths — are inferred.
 Second, RUMINATE models how the expert clinician seeks to reduce uncertainty with respect to his insight into the presenter/investigator's patientspecific diagnostic reasoning, in the following situations: 356 • when the expert doesn't know h o w the presenter/investigator is reasoning, by assuming the presenter/investigator is following the default (is "with me") until evidence to the conumy presents itself̂ ; • w h e n the expert knows/suspects (he presenter/investigator's reasoning differs from his own, by identifying the alternative reasoning pattern and establishing an explanation task to find out its source; and • when the expert believes uncertainty has been reduced/eliminated regarding his understanding of presenter/investigator's reasoning, by establishing expectations for subsequent presenter/investigator reports that are consistent with this understanding and creating explanation tasks when they fail.
 The RUMINATE program is described fully in (Gadd, 1995), including examples of its behavior and evaluation of the coverage it provides for a range of rounds discourse exemplars.
 Conclusions The primary goal of this research has been to gain a better understanding of the nature of consultations between professionals engaging in the collaborative process of solving complex problems.
 Our focus on expertise in use, rather than isolated problem solving, has led us to consider two important aspects of communication actions in consultation settings: their intentional role within the institutional forms of discourse that characterize consultations and their specific relationship to the expert's capacity to develop a competence model of the presenter/investigator.
 Here we have presented a theory to account for a wide range of behaviors that were observed in the actual teaching rounds discourses.
 The theory was subsequently described in the concrete terms of a simulation, thereby allowing assessment of its strengths and limitations, and providing a base from which to explore imresolved issues.
 Communication settings characterized by uneven knowledge distribution, mentorship roles, institutional discourse norms, and a multiplicity of participant objectives are prevalent in professions other that medicine, such as law and business.
 In public accounting, for example, junior audit staff routinely report their field findings to more senior auditors in consultationlike sessions in which critique, advice, and assessment are active goals.
 The model proposed and explored by this research provides a basis for facilitating a supportive enviroimient for humancomputer problem solving discourse in such settings.
 Both computerbased consultants and learning enviromnents could benefit from the opportunity to gain a better shared view of the problem to be solved, through exploration of the process of domain reasoning afforded by this model.
 Acknowledgments The research reported here is part of m y dissertation, done at the Decision Systems Laboratory and the Joseph M.
 Katz Graduate School of Business at the University of Pittsburgh.
 It was funded in part by the Josiah Macy, Jr.
 Foundation Harry E.
 Pople, Jr.
, William E.
 Spangler, and Karen Locke provided helpful comments and suggestions on an earlier draft of this paper.
 References Allen, J.
 F , & Perrault, C.
 R.
 (1980).
 Analyzing Intention inVtteranccs.
 Artificial Intelligence, 15(3), 143178.
 Carberry, S.
 (1983).
 Tracking User Goals in an InformationSeeking Environment.
 In Proceedings of the Conference of the American Association for Artificial Intelligence (pp.
 200206).
 Washington, D.
C.
 Cicourel, A.
 V.
 (1990).
 The Integration of Distributed Knowledge in Collaborative Medical Diagnosis.
 In J.
 Galegher, R.
 E.
 Kraut, & C.
 Edigo (Eds.
), Intellectual teamwork: social and technological foundations of cooperative work (pp.
 221242).
 Hillsdale, NJ: L.
 Erlbaimi Assoc.
 Cohen, R.
, & Perrault, C.
 R.
 (1979).
 Hements of a PlanBased Theory of Speech Acts.
 Cognitive Science, 3(3), 177212.
 Evans, D.
 A , & Gadd, C.
 S.
 (1989).
 Managing Coherence and Context in Medical Discourse.
 In D.
 Evans & V Patel (Eds.
), Cognitive Science in Medicine, (pp.
 211255).
 Cambridge, M A : M I T Press.
 Gadd, C.
 S.
 (1995).
 R U M I N A T E : A Model of the Multiple Roles of Diagnosis in the Communication and Evaluation of Expertise.
 Doctoral dissertation.
 Pittsbiugh: University of Pittsburgh.
 Gadd, C.
 S.
, & Pople, H.
 E.
 (1988).
 A n Interpretation Synthesis Model of Medical TeachingRounds Discourse: Implications for Expert System Interaction.
 International Journalof Education Research, 1(1), 81102.
 Gadd, C.
 S, & Pople, H.
 E.
 (1990).
 Evidence from Internal Medicine Teaching Rounds of the Multiple Roles of Diagnosis in the Transmission and Testing of Expertise.
 In N.
 Fredricksen (Ed.
), Diagnostic Monitoring of Skill and Knowledge Acquisition, (pp.
 89112).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Grosz, B.
 J.
, & Sidner, C.
 L.
 (1986).
 Attention, intentions, and the structure of discourse.
 Computational Linguistics, 12(3), 175204.
 Litman, D.
 J.
 (1985).
 Plan Recognition and Discourse Analysis: A n Integrated Approach for Understanding Dialogues.
 Doctoral dissertation.
 Rochester: University of Rochester.
 Moore, J.
, & Swartout, W .
 (1989).
 A reactive approach to explanation.
 In Proceedings of the Eleventh Annual International Joint Conference on Artificial Intelligence (pp.
 15041510).
 Detroit, MI.
 Patel, V L.
, Evans, D.
 A , & Kaufman, D.
 R.
 (1989) A Cognitive Framework for DoctorPatient Interaction.
 In D.
 Evans & V Patel (Eds.
), Cognitive Science in Medicine, (pp.
 257312).
 Cambridge, M A : M I T Press.
 Pollack, M.
 (1986).
 Inferring Domain Plans in QuestionAnswering.
 Doctoral dissertation.
 Philadelphia: University of Pennsylvania.
 ^ Cf.
, discussion of "fitdeficit triggers" in (Evans & Gadd, 1989, pp.
 243245).
 357 s t r o n g S e m a n t i c Systematicity f r o m U n s u p e r v i s e d Connectionist L e a r n i n g Robert F.
 Hadley School of Computing Science Simon Eraser University Burnaby, B.
C.
, V5A 1S6 hadleyCcs.
sfu.
ca Michael B.
 H a y ward M P R Teltech Ltd.
 8999 Nelson Way Burnaby, B.
C.
, V5A 4B5 haywardfimprgate.
mpr.
ca Abstract A network exhibits strong semantic systematicity when, as a result of training, it can assign appropriate meaning representations to novel sentences (both simple and embedded) which contain words in syntactic positions they did not occupy during training.
 Herein we describe a network which displays strong semcintic systematicity in response to unsupervised tiaimng.
 During tradning, twothirds of all nouns are presented only in a single syntactic position (either as grammatical subject or object).
 Yet, during testing, the network correctly interprets thousands of sentences containing those nouns in novel positions.
 In addition, the network generalizes to novel levek of embedding.
 Successful training requires a corpus of about 1000 sentences, and network training is quite rapid.
 1.
 Introduction Fodor's and Pylyshyn's arguments (1988) to the effect that human thought and language exhibit both compositionality and systematicity are by now widely known.
 Although connectionists have questioned whether humans display these attributes in the form that F & P describe, most now agree that in some important sense humans do exhibit some form of linguistic systematicity.
 In 198990, a number of connectionists reported results which established that connectionist networks (hereafter, cnets) could exhibit forms of linguistic generalization, which, prima facie, qualify as systematicity.
 These results were obtained without recourse to mere implementation of "classical" symbolic methods, and so, it appeared that one of F<kP's major conclusions was falsified.
 However, in Hadley, 1992, 1994a, a learning based conception of systematicity was introduced, and various degrees of systematicity were distinguished, ranging from weak syntactic to strong semantic systematicity.
 Hadley (1994a) examined six different connectionist systems and argued that, in all probability, none of these systems displayed the strong forms of systematicity that humans display.
 As a consequence, it appeared that a variant of F&P's original challenge stood unscathed.
 Recently, however, some researchers claim to have satisfied Hadley's definition of strong systematicity, though not his formulation of semantic systematicity.
 In one instance (Phillips, 1994), this claim clearly requires qualification, since (as Phillips has acknowledged, personal communication) the system involved cannot process embedded sentences as required by Hadley's definition.
 In another instance (Christiansen & Chater, 1994), a claim to strong generalization is restricted to a single syntactic context (conjunctive noun phrases).
 Discussion of this claim, together with those of Niklasson & van Gelder (1994) is given in Hadley, 1994b, where reservations are explored.
 In any event, none of the work just cited addresses semantic aspects of systematicity and compositionality, although F&P's (1988) presentation of these concepts did seem to involve semantic issues (such as the capacity to understand the meaning of novel sentences and the need to banish semantic equivocation in logical inference).
 Before proceeding, it will be helpful to characterize strong semantic systematicity, as defined in (Hadley, 1994b).
 Briefly stated, we m a y say that a network exhibits strong semantic systematicity when, as a result of training, it can assign appropriate meaning representations to novel sentences (both simple and embedded) which contain words in syntactic positions they did not occupy during training.
 The training set (or corpus) involved should not only refrain from presenting all words in all syntactic positions, but should so refrain for a significant fraction of the training vocabulary.
 Furthermore, a sentence counts as novel only if it contains a word in a syntactic position (e.
g.
, subject) that it did not occupy at any level of embedding during the training phase.
 Now, given F&P's emphasis on understanding novel sentences, and our contention (Hadley, 1994a) that humans display at least strong semantic systematicity, we have sought a connectionist system which clearly displays these properties in the context of a simple recursive language.
 In the following pages, we describe a system of cnets which satisfies this requirement.
 However, we should stress that we do not see our model as a refutation of F&P's basic thesis.
 Rather, we have sought to forge a genuine synthesis between connectionist methodology and a powerful classical insight, viz.
, that activating complex semantic representations entails activating their semantic constituents.
 Significantly, representations within our model do not involve static strings, but emerge from connectionist methods not considered in F&P's 1988 paper (e.
g.
, binding nodes [Smolensky, 1990] and activation decay).
 Also, although we certainly 358 S ̂  NP V NP NP » N I N RC N —» Mary | Jane | Sally | Susan | Vicky | Fran I Abe I Bill | Carl | Dave | Earl | Fred V —>• likes I knows | treats | calls | draws | helps I races | sees RELPRO ^ who RC ̂  RELPRO V N P Figure 1: The Grammar of L.
 would not claim 'cognitive fidelity' for our model, we believe that the present research takes meaningful steps in the direction of cognitive plausibility.
 Support for this belief will emerge in later sections, but we may summarize several relevant accomplishments here: (a) The model exhibits strong semantic systematicity.
 Following training on a recursive grammar, the system successfully processes, with complete accuracy, substantially deeper levels of sentence embedding than occur during training (thus attaining level 4 in Niklasson's and van Gelder's (1994) generalization hierarchy).
 (b) During training, twothirds of all nouns are not presented in all legal positions.
 However, during testing, those nouns are each successfully presented in positions novel to those words.
 (c) When embedding is restricted to a meiximum depth of one, as occurs during training, over one million sentences are candidates for inclusion in the training corpus.
 Yet, the network is successfully trained on a subset of about one thousand sentences.
 (d) All network learning is unsupervised; forms of Hebbian training are used throughout.
 It is widely believed that Hebbian learning is probably closer to biological reality than the commonly used method of backpropagation of error.
 (e) Once training is complete, the network not only displays strong semantic systematicity (hereafter, semanticS), but a straightforward explanation of this fact exists.
 The network's behavior is transparent.
 2.
 Task and Basic Strategy A system of cnets (hereafter, simply called the 'cnet' or the 'network') is given the task of attaining semanticS in the context of learning the semantics of a simple recursive language.
 Sentence meanings (construed here as propositions) are represented within a special layer that loosely corresponds to a traditional semantic network (of.
 Schubert, 1976).
 Upon completion of training, the entire cnet should produce appropriate meaning representations in response to any sentence taken from the language L, provided embedded sentences do not occur at depths greater than level three.
 The grammar of L is given in Figure 1.
 Corresponding to each sentence of L (where the maximum level of embedding may be as great as three) is a proposition or 'meaning' representable in the semantic network.
 However, the training corpus consists of a tiny fraction of all sentences whose maximum level of embedding is one (i.
e.
, during training, no relative clause contains another relative clause).
 As each of the training sentences is presented as input, its corresponding proposition is actively represented within the semantic network.
 Sentences are presented to an input layer one word at a time, and as training progresses, associations are learned between word (or lexical) nodes in the input layer and nodes in the semantic (network) layer.
 Activation propagated from the input layer is spread within the semantic layer, where the sequencing of thematic role activation must be learned.
 3.
 Architecture and Representation Methods Before delving into representational details, we wish to stress that nodes and links within our network should not in any way be construed as the counterparts of biological objects (e.
g.
, neurons and axons).
 Rather, following Smolensky (1988), we intend that our nodes, links, and processes should be taken as fairly highlevel abstractions.
 Nodes and links, for example, might in fact correspond to patterns of activity whose biological substrates are left entirely open.
 3.
1 OveraH Structure The network is comprised of an input layer and a semantic (output) layer.
 The input layer is a linear array of 21 nodes, each node corresponding to a single lexical item (a word).
 When a word is presented as input, the corresponding lexical node is activated.
 By contrast, the semantic layer has considerable internal structure, and contains four distinct types of nodes.
 These are: concept nodes, proposition nodes (pnodes), binding nodes, and thematic site nodes.
 Pnodes also have internal structure and serve to integrate concept nodes into unified propositions.
 Lexical nodes in the input layer are fully connected, by means of tunable links, to each concept node and to the core of each pnode in the semantic layer.
 After training, concept nodes and pnodes provide semantic content for the lexical items, and for this reason are called 'semantic nodes'.
 W e recognize, of course, that semantic nodes do not possess intrinsic semantic content.
 Rather, their semantic role presumably arises through their participation in semantic grounding processes (cf.
 Hadley, 1989).
 3.
2 The Semantic Layer, Internal Structure Structure within the semantic layer is provided primarily by links between concept nodes and pnodes.
 Pnodes are of two types: master pnodes and modifier pnodes (modpnodes).
 Both types have the cognitive role of integrating concepts of objects and actions into a coherent whole.
 There is a single 'master' pnode, which unites constituents into the main proposition expressed by a complete sentence (see Figure 2).
 By contrast, modpnodes have a subservient role; they represent propositions which modify particular concept nodes.
 Modpnodes can be 'bound' to concept nodes for specific periods by means of modifier sites (see tt in Figure 2).
 In the current implementation, there are three modpnodes.
 Pnodes of each type are small networks in their own right, consisting of a core node (connected to lexical nodes in the input layer) and attached site nodes.
 Each pnode core is connected to its satellite sites by directional links, and viceversa.
 Site nodes represent various the359 Core Site Core (O) ® Master pNode Figure 2: A master pnode (a) and a modifier pnode (b).
 Site nodes are part of each pnode constellation.
 The thematic role represented by each site is indicated as follows: TT indicates a modifier site, a represents an agent site, (3 an action site, and 7 is a patient site.
 matic roles, including agent, patient, and action roles.
 In addition, modpnodes each possess a 'modifier site'.
 The thematic role associated with each site is fixed, and site nodes can enter into 'bindings' with a concept node by means of binding nodes (see below).
 The sites involved in a given pnode form a competitive, winnertakeall cluster.
 As is customary in cnet simulations, inhibitory links in all winnertakeall ( W T A ) clusters in this network remain at the virtual level.
 Links between pnode cores and sites are actual, however, and when a hitherto inactive core receives activation (from below) which exceeds its threshold, the core 'fires' and sends activation to its associated site nodes (for details, see sections 5 and 7).
 Weights on links from each core to its sites are tuned during network training when the core is prompted to fire by an activated site.
 As will emerge, this tuning enables each pnode constellation to learn the sequence in which its sites are stimulated during training.
 W e regard each pnode (which includes both core and sites) as a module having the specific cognitive function of learning sequences.
 Now, just as pnodes are of two types, so are concept nodes; they represent either actions or objects.
 Each 'action concept node' is connected to every thematic site that represents an action role.
 Similarly, each 'object concept' is connected to each agent site and each patient site.
 Every connection between a concept node and a role site is mediated by a 'binding node' (cf.
 Smolensky, 1990), which intercepts activity from the concept node to the site node (Figure 3).
 Links to various binding nodes emanate from a given site.
 Once a site enters into a binding, both that site and the effective binding node remain active, and the site will not send activation to any binding node except the one to which it is actively bound.
^ For this reason, a site can only bind with a single concept node at a time (via the mediating binding node).
 Concept nodes can enter into bindings with particular sites when their mutual binding node receives adequate input from both the site and the concept node (see section 7).
 Binding nodes reside on the connection between • O < > 6 6 Jane sees mod • pNode tlkts Mary ^We assume that connections at sites could have evolved to have this specific property.
 Figure 3: Semantic representation for 'Jane sees Bill who likes Mary'.
 Diamond shaped nodes depict binding nodes.
 Only active binding nodes are shown here.
 each pnode site and each semantically appropriate concept node.
 In order to ensure that appropriate bindings are formed, binding nodes compete in a W T A fashion (see section 7 for details).
 This competition is separate from that involving site nodes.
 However, both kinds 0/competition are essential to the formation of appropriate bindings during sentence interpretation.
 In this regard, a notable aspect of site competition is that, once a site enters into an active binding, it no longer competes with other sites.
 Given our assumption that pnodes are abstract objects, possessing a specific cognitive function, we think it plausible that thematic role sites should behave this way.
 Furthermore, this assumption is consistent with standard connectionist techniques.
 For, we need only suppose that virtual modifier links (cf.
 Feldman k Ballard, 1982) emanate from each site node to all inhibitory links coming into or leaving that site.
 W h e n a binding occurs, a binding node fires and sends activation to the involved site (see figure 3).
 As a result, the site node attains a high activation level (|3) and the site's modifier links then block any activation flow through the site's inhibitory links.
 Apart from competitive clusters involving, respectively, binding nodes and site nodes, W T A competition also occurs between semantic nodes.
 'Winning' semantic nodes are selected both during network training and testing.
 4.
 Training Data Training and test data are generated using the grammar of L.
 One hundred separate training corpora have been generated, and the model has tested successfully when trained on each.
 A given training corpus consists of 1370 sentences, with any given sentence duplicated at most once.
 Each training corpus contains 7 5 % simple (N V N ) sentences and 2 5 % complex sentences, containing relative clauses.
 The latter have a m a x i m u m embedding depth of one.
 About half of the complex sentences contain a relative clause in both the subject and object NPs.
 All 12 nouns appear in each training corpus, but only four of these nouns are permitted to appear in both subject and object positions.
 360 5.
 Network Training Successful network training requires less than one complete pass through a single training corpus.
 As previously indicated, each sentence is presented to the input layer one word at a time.
 Presentation of a word amounts to activating one of the 21 lexical nodes in the input layer.
 The appropriate lexical node is set to |1 just until the next word is presented.
 Throughout the processing of a complete sentence, the corresponding propositional representation is active within the semantic layer.
 All concept nodes and pnode cores involved in that proposition are set to their maximum activation levels (+1).
 Site nodes involved in the active pnodes are also set initially to t1, though their m a x i m u m level is |3.
 In every active propositional representation, the master pnode will be active.
 One of the three modpnodes will be randomly selected for inclusion in the representation whenever some proposition modifies a concept (this occurs only when relative clauses are present in the input).
 The network's trainable links are those occurring between the input layer and semantic layer, and those emanating from pnode cores to pnode (thematic) sites.
 Other links within the semantic layer serve to establish bindings and to spread activation.
 Every lexical input node is connected to each semantic node (i.
e.
, to the concepts and pnode cores).
 O n each 'word iteration', activation flows from an active input node to semantic nodes.
 Subsequently, activation is relayed from semantic nodes to binding nodes, and ultimately to pnode sites and cores.
 5.
1 Training Links Between Layers Each time an input word is presented, a semantic node corresponding to the word's 'meaning' will be active within the semantic layer.
 This holds true even for the relative pronoun ('who'), which not only denotes some individual each time it is used, but signals that some proposition modifies that individual.
 Thus, modpnodes are strongly correlated with occurrences of 'who'.
 However, many spurious semantic nodes will also be active when a given word appears as input.
 A simple Hebbian learning algorithm, which merely strengthened weights between simultaneously active nodes in the input and semantic layers, would suffice to discover the strongest correlations.
 However, this approach would still assign substantial weights to moderate, though spurious, correlations.
 A better method, adopted here, is to integrate Hebbian learning with a simple form of competition.
 To understand this Hebbian variant, recall that many links flow into each semantic node from the lexical layer.
 Moreover (as is common), there is a fixed m a x i m u m (11) for the sum of all weights on links coming into a semantic node.
 Initially, the weight on each of these links is .
001.
^ Each time an active input node sends activation to the semantic layer, weights are incremented on every link which connects that node to a semantic node that is active (|1) within the current propositional representation.
 Let S be any of these active semantic nodes.
 Then ^Random weights close to .
001 would serve equally well.
 For simplicity, we have chosen a uniform initial weight.
 the link (L) coming into S is incremented as follows: increment = R* .
0005 where R is the ratio of the current weight on L to the current average weight of links into S.
 Note that the ratio R can cause links with 'above average' weight to be rewarded significantly.
 As learning proceeds, the learning on winning links accelerates, and little weight is assigned to links which reflect spurious cooccurrences.
 Moreover, if many input nodes have significant correlation with a single node, as happens with the master pnode, no clear winning link emerges, since the ratio R remains near unity for most links into that semantic node.
 Training halts when all semantic nodes have reached their weight maximums, i.
e.
, when no semantic node has any weight left to distribute among its incoming links.
 Typically, this happens after 9501050 sentences have been processed.
 W h e n training is complete, links reflecting correct wordconcept associations are frequently 100 times greater than those reflecting spurious cooccurrence.
 Presently, we shall examine training which occurs within the semantic layer.
 Before doing so, a final issue is germane to the testing phase, described in section 7.
 During training, firing thresholds for semantic nodes are irrelevant, since those semantic nodes which are active in a given semantic representation have already been set to their m a x i m u m level of activation.
 However, we assume that, as semantic nodes receive varying levels of input during training, they acquire thresholds.
 Upon completion of training, the firing threshold of each semantic node is taken to be 8 0 % of the largest input stimulus ever presented to that node.
 This means that, typically, firing thresholds for semantic nodes will be above .
7.
 5.
2 Training within the Semantic Layer Within the semantic layer, training occurs at pnodes only.
 In particular, weights on links flowing from pnode cores to site nodes are tuned as a side effect of spreading activation, which is initiated at concept nodes.
 In loose analogy with training between layers, we have cissumed a fixed limit of one for the sum of all coretosite weights at each pnode.
 Learning ceases at any pnode which has reached this weight limit.
 As previously mentioned, a complete semantic representation remains active throughout the processing of a given sentence.
 Within this active representation, active concept nodes are bound to the particular thematic sites by active binding nodes (see Figure 3).
 All nodes participating in this representation are set to |1, which is the m a x i m u m for concept nodes and pnode cores.
 As each word is presented to the input layer, activation is propagated upwards to semantic nodes.
 Each semantic node receives activation equal to the weight on the link coming into that node from the active input node.
 Upon receiving this input surge (or 'boost'), semantic nodes enter into a W T A competition.
 That node whose received boost is largest will win the competition.
 W e have assumed that semantic nodes will spend their excess 'boost' when competing, but not their initial level of activation.
 Now, training within a pnode constellation occurs as 361 a side effect of a concept node's winning the W T A competition.
 For, when a concept node wins (e.
g.
, 'Jane' in figure 3), it spreads activation towards binding nodes.
 W h e n this spreading activation reaches an inactive binding node, nothing happens because a binding node will fire only when it senses activation from both a site node and a concept node.
 However, when activation from a concept node reaches any active binding node, that node fires and sends activation to the involved site node.
 Referring to figure 3, if'Jane' were selected as winner of the semantic competition, activation would reach the agent site on the master pnode.
 However, if instead 'Bill' were to win, three separate sites would receive activation, including the modifier and agent sites on the modpnode.
 For simplicity, we shall assume that the first word of the sentence, 'Jane', causes the Jane node to fire.
 Once a given site (a, in this case) receives activation from a binding node, it will jump from its current activation (11 in this case) to its m a x i m u m level, |3.
 At this point, the a site is at a higher activation level than the remaining two sites.
 However, since all sites at the current pnode are involved in active bindings, no W T A competition occurs between the sites (their mutual inhibitory links are currently blocked, as described earlier).
 Now, given that site a has just been boosted to its highest activation level, a fires towards the pnode core, but retains its 13 activation.
^ Activation received at the core causes the core to fire in turn.
 As a result, the core sends activation to each of its sites in proportion to the existing weight on the link leading from the core to the given site.
 The 'boost' now received by each site is added to the site's activation level, unless that site is already at its m a x i m u m (13) level.
 Thus far, activation levels for sites a, /?, and 7 would be, respectively, 13, (1 + j), and (1 + k), where j and k are substantially less than one.
 Consequently, the agent site, a, is at the highest level by far.
 Also, now that activation has passed along trainable links, from an active core to active sites, weight modification will occur.
 In particular, weights will be modified by adding (activation{s) * .
0005) to the existing weight on the link from core to site s.
 Clearly, in the present example, the link to site a will receive a significantly larger increment than links to /? and 7.
 Once weight modification between core and sites is complete, a new cycle begins, for the affected sites have not received sufficient activation to cause them to fire.
 If we assume that the next input word causes the 'sees' node to win, spreading activation will pass through a binding node, and cause site f3 to jump to a level of 13.
 13, in turn, will now excite the core, which will again spread activation to the sites.
 Weight modification will again occur, this time with a and /3 both at 13, while the patient site, 7, has substantially less activation.
 As a consequence, the weight into a receives another (comparatively) sizable increment, and though the weight into /3 will now be substantially augmented.
 'It is somewhat unusual for nodes to both fire and retain significant levels of activation.
 However, this assumption is consistent with connectionist principles as set forth in Feldman & BaUard (1982).
 7's weight receives a comparatively small increase.
 By the time the third cycle is completed (after processing 'Bill'), weights into agent, action and patient sites will be ordered, by descending magnitude, in the same sequence as those sites were boosted to their maximum (13) values (other things being equal).
 Due to the nature of conceptual binding, the a and 7r sites on any modpnode will always be bound to the same concept (during training).
 In such situations, if the concept node is chosen as winner of a W T A competition, both the a and n sites will receive simultaneous activation.
 Thus, those two sites will always undergo identical training.
 For this reason, weights into the a and n sites at a given modpnode will be identical, though the weights at separate pnodes will vary.
 Because a and ir sites are equally weighted with respect to a pnode's core, both sites will tie in any W T A competition between sites which occurs during the testing (i.
e.
, comprehension) phase, described in section 7.
 6.
 Test Data Once the network has been trained on a given corpus, it is tested on a separate set of over 6000 sentences.
 Of these 4000 are randomly generated; no restrictions are placed upon any word's syntactic position, aside from grammaticality.
 Three quarters of these sentences contain embedded clauses, frequently in both subject and object NPs.
 The remaining 20001 sentences all present some noun in a position it did not occupy during training (i.
e.
, the word did not occupy that position at any level of embedding during training).
 Of these (roughly) 2000 sentences, only 500 are simple sentences.
 In addition, six handcrafted sentences are included in the set.
 These handcrafted sentences test the network's ability to generalize to deep levels of embedding.
 7.
 Testing Performance Once the cnet has been fully trained, its 'comprehension' is tested on each of the 6006 sentences described in the preceding section.
 Testing of a given sentence involves the seriatum presentation of words to the network's input layer.
 In response to each word, a semantic node is activated within the semantic layer and, via spreading activation, some 'binding' will occur (i.
e.
, a binding node will be activated).
 Once the sentence has been processed, a pattern of active nodes and bindings exists within the semantic layer.
 (A node is considered active if its level of activation exceeds its firing threshold.
) This pattern of activation is compared to the sentence's correct prepositional representation, and 'perfect matches' are noted.
 The process by which thematic role sites are activated and bindings are set is somewhat complex.
 Given space limitations, we can present only an outline of this process here.
 7.
1 Sentence C o m p r e h e n s i o n  Outline.
 For each sentence in the training corpus: (1) All nodes throughout the network are initially set to zero.
 Cognitively, this might be caused by a preceding silence or by successful comprehension of the previous sentence.
 (2) The master pnode is activated, initially via its core.
 Activation spreads to the three site nodes and a W T A 362 competition ensues among the sites.
 A single site (presumably the agent site) wins and attains an activation level of +3.
 In theory, activation of the master pnode occurs just as some initial stimulus is being recognized as a word, perhaps by a 'preprocessor' which activates a particular lexical node once the word is recognized.
 (3) A lexical node is activated and activation flows from the lexical layer to the semantic layer.
 A W T A competition ensues among the semantic nodes.
 The winning node is selected as follows: If one or more previously inactive nodes surpasses it firing threshold, that node wins which surpassed its threshold by the largest amount.
 (Ties are extremely unlikely, though a unique winner would be selected in that case.
) Otherwise, that presently active node which received the largest input boost wins.
 In either case, the winner attains an activation of+1.
'* (4) If the 'winner' from step 3 was a pnode, call it P.
 P's core is now active (11).
 The following occurs: • A W T A competition ensues among P's site nodes, which are all presently unbound.
 Multiple (tying) winners are possible.
 • A winning site(s) at P is (are) chosen and assumes activation of 13.
 All other active sites and concept nodes undergo some decay (a .
01 decrement to their activation level).
 (5) Binding now occurs between the most active site (or sites, if there is a tie) and the most active concept node that can bind with that site(s).
 Activation decay ensures that the most recently activated site(s) and concept are the most active nodes.
 (6) Binding action from the previous step causes a binding node to fire.
 This in turn spreads activation to the site involved in that binding, and the site relays activation to the core of the involved pnode.
 If there are still unbound sites at that pnode, a new W T A competition is triggered among just those sites, and the winning site attains f3 activation.
 All other active sites and concept nodes undergo some decay.
 This decay ensures that correct bindings occur during and after recursive embeddings.
 (See Stevenson, 1994, for a similar use of decay in a massively parallel parser.
) (7) Return to step 3.
 8.
 Test Results As mentioned in section 4, the network has been separately trained and tested on 100 distinct training corpora.
 Each of the 100 training sessions produces a uniquely weighted cnet, which, in turn, is tested on the 6006 sentence test corpus described in section 6.
 As each sentence in each trial is tested, its output is compared to the correct 'target' representation for that sentence.
 In all cases, a perfect match occurred between the network's real and target output.
 This held true even when *This 'disjunctive' winner selection rule is consistent with a standard W T A competition among semantic nodes.
 W e merely need to assume that a node which has just surpassed its firing threshold discharges an activation greater than one, i.
e.
, greater than the 'input boost' received by presently active nodes.
 test sentences involved m a x i m u m levels of embedding (a depth of three consecutive relative clauses).
 9.
 Discussion The fundamental goal of research presented here has been to demonstrate that strong semantic systematicity can be achieved through unsupervised connectionist learning.
 In terms of the definition presented in section 1, we believe this goal has clearly been achieved.
 Not only is the trained cnet able to process sentences containing words in novel positions, but overall network behavior is transparent.
 Given the forms of Hebbian learning involved, it is clear how words become associated with their conceptual counterparts and how the proper sequence for thematic site activation is learned by pnodes.
 These aspects, together with the combinatorial power of binding nodes, explain the model's ability to process words occurring in novel syntactic positions.
 Note that training of pnode links is crucial to the resultant systematicity.
 In addition, although our model undoubtedly ignores some concerns for cognitive plausibility, we have sought to attain plausibility wherever possible.
 For example, (a) we have used unsupervised learning methods throughout, (b) relatively small training corpora have been employed, (c) most nouns were not presented in all positions during training, (d) the network generalizes to deep levels of embedding.
 References.
 Christiansen, M.
H.
 & Chater, N.
 (1994).
 Generalization and connectionist language learning.
 Mind and Language, 9, 273287.
 Feldman, J.
A.
 & Ballard, D.
H.
 (1982).
 Connectionist models and their properties.
 Cognitive Science, 6, 205254.
 Fodor, J.
A.
 &; Pylyshyn, Z.
W.
 (1988).
 Connectionism and cognitive architecture: a critical anjilysis.
 Cognition, 28, 371.
 Hadley, R.
F.
 (1989).
 A defaultbased theory of procedural semantics.
 Cognitive Science, 13, 107137.
 Hadley, R.
F.
 (1992).
 Compositionality and systematicity in connectionist language learning.
 Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society, Bloomington, Indiana, 659664.
 Hadley, R.
F.
 (1994a).
 Systematicity in connectionist language learning.
 Mind and Language, 9, 247272.
 Hadley, R.
F.
 (1994b).
 Systematicity revisited: reply to Christiansen and Chater and Niklasson and van Gelder, Mind and Language, 9, 431444.
 NiUasson, L.
F.
 & van Gelder, T.
 (1994).
 O n being systematiccdly connectionist.
 Mind and Language, 9, 288302.
 Phillips, S.
 (1994).
 Strong systematicity within connectionism: the tensorrecurrent network.
 Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, Atlanta, GA, 723727.
 Schubert, L.
 (1976).
 Extending the expressive power of semantic networks.
 Artificial Intelligence, 7, 163198.
 Smolensky, P.
 (1988).
 On the proper treatment of connectionsim, Behavioral and Brain Sciences, 11, 123.
 Smolensky, P.
 (1990).
 Tensor product variable binding and the representation of symbolic structures in connectionist systems.
 Artificial Intelligence, 46, 159216.
 Stevenson, S.
 (1994).
 A unified model of preference and recovery mechansims in human parsing.
 Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, Atlanta, GA, 824829.
 363 Pragmatic effects in zero anaphor resolution: Implications for modularity.
 Mark DurrantPeatfield^ and William MarslenWilson^ Centre for Speech and Language Department of Psychology Birkbeck College, University of London Malet Street.
 London WCIE 7HX ubjtp80@uk.
ac.
ucl^ ubjta38@uk.
ac.
bbk^ Abstract Fodor (1983) has claimed that informational encapsulation of the parser is the way the language system prevents extralinguistic factors firom slowing down first pass processing.
 However, in a naming task where the visual probe was an appropriate or inappropriate pronoun continuation to a gerundive phrase following passages in which discourse focus and verb semantics were covaried (MarslenWilson, Tyler & Koster, 1993) we found appropriateness effects which suggest a role for online pragmatic inference in top down control of the parser.
 Fodor, Garret & Swinney (1993) maintain that, though the gerund is marked as requiring a subject NP, the inferential activity underlying referent assignment does not occur until an explicit anaphor (the pronoun target) is encountered.
 As modularity predicts a cost associated with contacting real world information, assignment times to gerunds should take longer than assignments based on lexical information.
 A speeded fragment completion task was used to counter Fodor's objection to a pronoun probe and to detect differences in the times taken to make anaphor assignments.
 The two studies reported here used the original MarslenWilson et al.
 (1993) materials.
 Conect assignments in the gerundive condition ("Rurming towards.
.
.
") were cost free with the exception of the condition where the pragmatically most likely subject was not in discourse focus.
 Latencies to initiate a completion were otherwise similar regardless of whether the tobecompleted fragment contained a gerund or a disambiguating pronoun.
 Furthermore, in the absence of pragmatic constraints, assignment always favoured the highlighted entity.
 These results reproduce the critical data from the MarslenWilson et al.
 (1993) study which demonstrates context effects on first pass processing.
 Introduction For nearly two decades, several researchers have been concerned to show that there is a syntactic module that operates independently of processes that access general world knowledge.
 Fodor (1983) has been the most influential advocate of this position.
 H e argued that language interpretation could not happen so quickly if it incorporated constraints based on pragmatic inference.
 The Modularity hypothesis proposes that human syntactic processing takes place in cognitively impenetrable, input systems which are informationally isolated from nonmodular, highly penetrable central processes.
 The boundary between module and central processes falls approximately at the traditional boundary between semantics and pragmatics: between logical form and a mental model of the current discourse.
 Informational encapsulation of the parser is the way the system prevents nonlinguistic factors from slowing first pass processing.
 T w o testable claims generated from this approach concern the notion of encapsulation and processing speed.
 The first claim is that the parser is not sensitive to instructional topdown effects; it should never be controlled in firstpass processing by constraints derived from pragmatic inference.
 The second claim follows from the implications of the first.
 Because nonlinguistic factors do not slow down first pass processing, language processing activity based on automatised noninferential moduleinternal processes should be faster than activity based on pragmatic inference.
 These are strong and important claims which have stimulated a great deal of research for and against the modularity assumptions (see Altman & Steedman, 1988, MarslenWilson & Tyler, (1987) for context effects on parsing and Mitchell, 1987, for contrary evidence).
 However, Fodor (Fodor, Garret & Swinney, 1992) has singled out one study in particular as providing "the most striking current evidence for an interactionist view of parsing", where extralinguistic inferences control syntactic operations .
 This was a study reported in detail in MarslenWilson, Tyler & Koster (1993), which used crossmodal naming as an index of anaphor resolution.
 Subjects listened to three contextsetting sentences containing a single male and female protagonist as in the passage reproduced below.
 1.
 Mary lost hope of winning the race to the ocean when she heard Andrew's footsteps approaching her from behind.
 The deep sand was slowing her down.
 She had trouble keeping her balance.
 The passage was followed by a verb fragment initiated either with a personal pronoun (He overtook.
.
) or by a gerund (Overtaking.
.
).
 At the offset of this fragment a pronoun probe was visually presented which the subject had to say aloud as quickly as possible.
 This probe (e.
g.
 H I M or H E R ) was either consistent or inconsistent with the contextual interpretation of the fragment.
 Any advantage in terms of naming latency for contextually appropriate probes could only arise if the subject of the clause was established at that point and the anaphor resolved.
 T w o other conditions varied the relationship between the discourse highlighted entity and verb bias.
 The verb could be either neutral or incongruent with respect to the context and targeted antecedent.
 In all gerundive phrase conditions, the appropriate probes were named faster than inappropriate probes.
 Particularly striking was the appropriateness effect in the condition where the nonfocused entity was the most likely subject of the gerund (as in the example above).
 Pragmatic inferencing seems just as effective as an apparently more direct mapping 364 between an antecedent and an unambiguous pronoun.
 Pragmatic information instructs the parser which entity to use as subject and which to use as object.
 Another condition gave an appropriateness effect when no pragmatic constraints existed.
 Discourse focus alone is able to determine subjecthood.
 Acknowledging the theoretical importance of these results, Fodor, Garret & Swinney (1992) launched a counter attack, arguing that processes concerned with establishing pragmatic likelihood are in fact not set in motion until an overt anaphoric device such as a personal pronoun is encountered.
 The sentence is parsed and the gerund is marked as requiring a subject, but nothing more happens until an overt anaphor is encountered.
 Only then are central processes consulted to bind the gerunds to their most likely antecedents.
 Fodor et al.
 maintained that the visual pronoun probe used in the MarslenWilson et al.
 (1993) naming task acted as a trigger to initiate contextual processing.
 Resolution of a gerund therefore has to wait for a trigger.
 It does not occur online.
 To support this it was necessary to show that, given the appropriate task, there will be no evidence for online integration of verb semantics with discourse context to determine the missing subject of the gerundive.
 Fodor et al.
 (1992) used a cross modal priming task which enabled them to probe immediately after the critical gerundive phrase rather than as in the MarslenWilson et al.
 (1993) study, further downstream at the object pronoun.
 Subjects listened to passages like (2) below and named visual probes (girl/fireman) presented at key points (indicated by asterisks) in the discourse.
 The probes had appeared previously in the passage.
 The rationale here was that, if part of the discourse referred back to an antecedent, then the reactivated information would be available to mediate repetition priming.
 2.
 The fireman carried a rope towards the little girl w h o was trapped on the ledge, immobilised with fear.
 He moved very carefully*.
 Crawling cautiously* towards her* so that he could hand her the rope he managed to save her.
 There was no apparent reactivation of the antecedent immediately after the gerund.
 Naming "fireman" after hearing "crawling cautiously" was not facilitated.
 In contrast, there was some evidence for reactivation at the later position after the object pronoun.
 Fodor e/ al.
 (1992) conclude that inferential processes concerned with anaphor resolution do not occur during or immediately after the gerund.
 There are two problems with this conclusion.
 First, the effects are weak and of uncertain statistical significance.
 Second, there are problems in the interpretation of the repetition priming task used here.
 Although the task allows the experimenter to probe during the verb phrase, it does not tell one directly how or whether the processor has assigned subjecthood, but only that certain discourse entities are in some way more or less active at different probe points.
 A better task would be one that probed as soon as possible after the verb, did not use a pronoun probe and, most importantly, gave unambiguous evidence about the assignment (or not) of subjecthood.
 The task should also operate within the time frame of an online task.
 W e decided on a speeded fragment completion task.
 This fulfills the criteria and, in particular, it counters Fodor et al.
 (1992) main objection to the original study by not providing an overt pronoun probe.
 This is a task in which subjects hear a short auditory passage followed by a sentence fragment.
 O n the presentation of a neutral visual probe (a row of asterisks), subjects are required to continue or complete the fragment as rapidly as possible, saying aloud their continuation.
 The time taken to initiate an appropriate response is taken as a measure of the status and efficiency of the inferential processes leading up to the assignment.
 Note that the task differs here from the cross modal naming paradigms adopted by both Fodor gf a/.
 (1992) and MarslenWilson era/.
 (1993).
 Contextual processing is functionally required to perform the task whereas there is no intrinsic requirement for contextual processing in order to perform naming.
 Fodor's thesis suggests that the pronoun at the beginning of the pronoun fragment triggers contextual processing.
 The agent of the verb is likely to have been determined before presentation of the probe.
 For the gerund fragment, where there is no pronoun probe to trigger contextual processing, the inferential activity required to establish the appropriate antecedent in the gerund fragments can only occur on presentation of the neutral visual cue.
 If there are computational costs associated with contacting real world knowledge (which is an explicit assumption in modularity), then initiation latencies to gerund fragments should be longer, across the board, than initiation latencies to pronoun fragments.
 The alternative view supported by the MarslenWilson et al.
 (1993) study permits contextual processing to occur as the fragment is being heard.
 Subject assignment to the gerund is likely to have been completed by the time the probe is presented.
 Latencies to continue each type of fragment would be expected to be similar and w e would be justified in concluding that the processes supporting referent assignment to the gerund occurred "online".
 The task is therefore able to shed light on the speed of discourse mapping and pragmatic inference simultaneously.
 It offers the chance to distinguish between gerund and pronoun fragments in terms of processing times.
 W e used this task in a new experiment based on the stimuli and design used in the MarslenWilson et al.
 (1993) naming study.
 There were three conditions in which pragmatic bias and discourse focus were varied.
 The fragment was initiated either with a gerundive or a pronoun and was phrased in such a way that a personal pronoun was an appropriate continuation given the context.
 Stimuli representative of the three conditions are given below.
 1.
 Discourse focus with congruent verb bias.
 After the surgeon had examined the 12 year old girl with the badly broken leg, he decided that he would have to take immediate action.
 He'd had a lot of experience with serious injuries.
 H e knew what he had to do next.
 H e injected.
.
/Injecting.
.
 In condition 1 the entity focused or highlighted in the discourse is also the most pragmatically likely subject of the gerundive phrase.
 Offline written completions to this passage typically place the surgeon in subject position and the giri in object position.
 The entity focused in the discourse (the surgeon) is also most likely to be the one injecting.
 The gerund "injecting" is therefore pragmatically congruent with 365 the entity in focus.
 Of the two possible pronoun responses, "her" would be the most appropriate.
 Fodor's modified thesis suggests that the pronoun "he" in the pronoun fragment triggers contextual processing.
 The parser is permitted a glimpse of the discourse representation containing two entities, one of which is in discourse focus.
 With the gerund fragment, the parser is not permitted access to the discourse representation.
 The advantage to the pronoun fragment is therefore twofold.
 First, the inferential activity underlying assignment activity can proceed on the basis of lexically specified information which rules out a parse like "He injected him".
 Second, the fact that the male protagonist is in discourse focus suggests that "he" will remain in subject position in a future utterance.
 Assignment times in an online scenario are therefore likely to favour pronoun fragments compared to gerund fragments.
 The alternative view permits the assignment processes unrestricted access to the discourse representation and real world knowledge.
 The fragment is interpreted in light of the preceding context and an assignment is made as soon as possible.
 There is research indicating that an entity in discourse focus enjoys a unique processing status (Garrod & Sanford, 1990) so it is possible that assignment of subjecthood to the gerund would further be facilitated.
 Assignment times in the S F C task are likely to be similar for gerunds and pronouns in this condition.
 2.
 Discourse bias with neutral verb bias.
 As Bill was buying candy at the cinema, he saw an old girlfriend get in line for a ticket.
 H e had arrived at the cinema especially early.
 H e had wanted to be sure of getting a good seat.
 H e waved at.
.
AVaving at.
.
 In condition 2 either Bill, the entity in discourse focus, or the girl friend are equally likely to be waving.
 There is no pragmatic bias towards either entity.
 However, in offline pretests.
 Bill and not the girlfriend was made the subject of waving.
 This preference for the focused entity was also evident in the MarslenWilson ei al.
 (1993) naming study.
 However, because a modular view of parsing prohibits access to the structure of the discourse representation, there is no reason for the parser to choose one discourse entity in preference to the other.
 The number of assignments favouring the male protagonist following the gerund fragment would be expected to be matched equally with the number of assignments in favour of the female protagonist.
 In contrast, the alternative view which allows assignment processes to be influenced by contextual influences would predict that assignments favouring the discourse entity currently in focus would predominate because, as noted above, the focused entity is likely to remain the subject of the discourse.
 With regard to the response latencies, initiation of completion times for pronoun fragments will, as above be expected to be faster than for gerund fragments.
 Once again, the alternative view suggests that the structure of the discourse representation is accessible right from the start for both types of fragment.
 Fragment initiation times should be similar.
 3.
 Discourse bias with opposing verb bias.
 Mary lost hope of winning the race to the ocean when she heard Andrew's swift footsteps approaching her from behind.
 The deep sand was slowing her down.
 She had trouble keeping her balance.
 H e overtook.
.
/Overtaking.
.
 In condition 3, the less pragmatically likely subject of the gerund is in discourse focus.
 Given what w e have been told about the situation, Mary is not in a position to be overtaking Andrew.
 Offline written completions established Andrew as the most likely entity to be overtaking.
 Since the modular parser is not affected by the structure of the discourse representation or pragmatic constraints, the condition 3 stimuli should be treated in the same manner as stimuli in the other two conditions.
 However, this condition presents something of a problem to an unencapsulated language processor.
 A shift in discourse focus is generally signalled in some manner in normal discourse.
 This condition however makes the entity not focused in the discourse the most likely subject of the gerund without signalling the change in focus.
 Verb bias is being pitted against discourse focus.
 Though the MarslenWilson et al.
 (1993) study gave appropriateness effects for this condition, it is not clear how this will affect gerund fragment initiation latencies.
 Experiment 1 The exact procedure was as follows.
 A subject heard a short passage comprising three context setting sentences highlighting one of two discourse entities.
 The passage was followed by a continuation fragment beginning either with an overt personal pronoun or a gerund.
 A neutral visual cue (comprising a row of asterisks) presented at the offset of the fragment prompted the subject for a voiced continuation.
 Time taken to initiate a response was recorded as well the actual response.
 The intertrial interval (ITI) was 2000ms.
 For the timing of these assignment processes to fit within an "online" time scale, there should be no costs suggestive of delay or reduced efficiency in the inferential activity supporting referent assignment.
 Initiation latencies should not differ across anaphor conditions (pronoun vs gerund).
 If does capture the products of online processing, w e predict that the same pattern of results seen in the original MarslenWilson et al.
 (1993) naming paradigm would be seen here, i) the pragmatic bias exerted by the verb in the condition where the focused entity is the least likely subject of die gerund, should ensure that the nonfocused entity becomes the subject, ii) assignment of an antecedent to a gerund in a context where either entity could be a pragmatically acceptable subject, should favour the discourse highlighted entity.
 Condition Gerund Pronoun 100 99 99 80 100 100 Table 1: Experiment 1: percentage distribution of correct assignments.
 First we look at assignment patterns (Table 1) for 34 subjects tested on 36 test items (12 per condition).
 In conditions 1 and 3 an incorrect assignment is one which does not make sense given what w e know about the situation.
 In condition 2 an incorrect assignment is one which makes the non discourse focused entity the subject of the gerund.
 Incorrect assignments were very infrequent across the board for conditions 1 and 2 but accuracy drops off in condition 3 where 366 1119 1115 1178 1103 1065 1041 +16 +50 +137* there is a conflict between discourse bias and verb bias.
 In Condition 2 where the verb bias favours either discourse entity, subjecthood is almost always assigned to the discourse focused entity.
 The MarslenWilson et al.
 (1993) study also found significant ̂ propriateness effects for condition 2.
 So far, these results mirror the original MarslenWilson et al.
 (1993) study.
 Both discourse focus and verb pragmatics are sufficient to link an utterance to the discourse context in isolation.
 However, things are not so clear cut when initiation latencies are considered.
 An analysis of variance ( A N O V A ) by items (F2) on the response times showed a significant interaction between fragment typeand condition,(F2[2,33] =3.
68,p<0.
05).
 Atestfor simple effects tied down variance due to fragment type solely to condition 3.
 (F2[l,33] = 17.
72, p<0.
005).
 There were no other significant effects implying that latencies to initiate a continuation to pronoun fragments are similar to latencies to initiate continuations to gerund fragments in conditions 1, and 2.
 "Condition Gerund Pronoun Diff 1 2 J Table 2: Experiment 1: item means per condition for all correct responses initiated with a personal pronoun.
 "*" denotes p<0.
005 Discussion The data for conditions 1 & 2 challenge a central claim modularity makes.
 Responses involving inferential activity based on real world knowledge should be slower and less efficient than responses based on lookup information.
 However, the interpretation here is complicated by the finding that there was a difference in condition 3, where responses were slower following a gerundive fragment than following a pronoun fragment.
 Does this cost show that inferential activity based on real world knowledge is indeed slower and less efficient as predicted by modularity? W e think not.
 It is not that pragmatics is being used in condition 3 and not the others.
 Rather, the subject has to switch from the focused entity to the alternative entity not in focus (e.
g.
 in the example 1 given above, the listener has to switch from Mary to Andrew).
 Pragmatic evaluation is immediate and will be applied first to the most discourse salient candidate for subjecthood.
 The effect in condition 3 is in fact evidence that in conditions 1 and 2 pragmatic evaluation is also going on.
 If pragmatic evaluation was not proceeding before or at the cue points in all three conditions then there would be no effect in condition 3.
 The language processor could not identify the unsuitability of the highlighted entity until the pragmatic implications of the assignment have been realised.
 When confronted by the gerundive fragment in condition 3 the language processor assumes the subject of the gerundive will be the subject of the prior discourse.
 Hobbs (1979) has noted that 9 2 % of the time this is an accurate heuristic.
 The use here of this heuristic is supported by the comparatively large number of mistaken assignments in favour of the focused entity (20%) in condition 3.
 The longer latencies here reflect the time taken to discard the entity suggested by discourse focus and consider the alternative one.
 In summary, the data did not distinguish between the 2 types of fragment in terms of initiation latencies.
 With the exception of condition 3 there was no overall difference between initiation latencies for pronoun and gerund fragments.
 Is this because each can be related to the current discourse equally rapidly or do the long latencies conceal possible differences in timing? If so then what we are seeing might have little to do with inferring referent assignment and much to do with those processes concerned with preparing an utterance.
 If long latencies conceal real differences between pragmatic and nonpragmatic assignment activity, then speeding up the responses should increase the differences between continuation times for gerund and pronoun fragments.
 This should be especially noticeable in condition 3.
 The experiment was repeated but with modifications to make the initiation of continuation latencies much shorter.
 Subjects were instructed to say as quickly as possible just the first word that occurred to them on seeing the visual cue.
 They were advised that the word should follow on naturally from the preceding context and the fragment.
 Experiment 2 The assignment patterns (Table 3) from 36 subjects tested on the 36 test items shows that the two critical effects observed in the last study were evident also in this study.
 In Condition 2 where the verb bias favours either discourse entity, subjecthood is assigned to the focused entity.
 In Condition 3 where the verb bias favours the nonhighlighted entity, 7 4 % of the assignments were made towards the pragmatically most likely entity.
 Condition Gerund Pronoun 100 95 92 74 100 100 Table 3: Experiment 2: percentage distribution of correct assignments.
 Turning to the reaction time data (Table 4), there was no significant difference between gerund and pronoun fragment initiation latencies.
 However, a significant interaction between fragment type and condition (F2[2,32]=3.
14, p<0.
05), was seen in condition 3 (F2[l,32]= 5.
27, p<0.
05) using a comparison of simple means.
 Latencies to supply an utterance to a gerundive phrase in condition 3 were longer than for utterances based on lexically specified information.
 Condition Gerund Pronoun Diff 1 2 J Table 4: Experiment 2: item means per condition for all correct responses initiated with a personal pronoun.
 "*" denotes p<0.
003 694 703 707 710 703 674 16 0 +33* 367 Discussion Thus, despite much quicker latencies in Experiment 2, the same pattern of results was found as in Experiment 1.
 There are still no significant differences between initiation latencies for pronoun and gerund fragments.
 The latencies in Experiment 2, compare favorably with naming or other online tasks and it was clear from subject reports that they could not perform any faster.
 Finally and inconsistent with the claim that the long latencies in Experiment 1 conceal actual differences between the gerund and pronoun conditions, the differences were now much smaller.
 Although there is still a significant difference between the pronoun and gerundive condition in condition 3, the cost has been reduced to 33 msecs.
 This change is most probably a reflection for the time required to prepare an utterance.
 In the first task, subjects had to complete the fragment whereas in the second task, subjects had only to provide a single word continuation.
 General Discussion Initiation latencies are rapid enough to pick up the products of online processing.
 If there are significant differences in processing times for pronouns and gerunds then surely they would have shown up here.
 There are two possible scenarios which account for these data.
 Either the inferential activity concerned with gerundive assignment occurred as the fragment was being heard or, assignment activity occurred immediately on presentation of the neutral visual cue.
 The latter case suggests that, all things being equal, resolving gerundive fragments occurs as rapidly as pronoun fragments even when contextual processing is required.
 The former admits the possibility that contextual information is being contacted as the fragment is being parsed.
 Either of these possibilities is inconsistent with the modular framework.
 The other results replicate those observed in the MarslenWilson et al.
 (1993) study which demonstrated context effects on syntactic (intramodular) representations and enable us to reject the kind of counter attack made by Fodor and others.
 There are no linguistic cues in the gerundive phrases, yet agency is assigned on the basis of pragmatic inferential activity in condition 3, or in condition 2, on the basis of discourse focus alone.
 There is the question of whether and how the pronoun probe used in the MarslenWilson et al.
 (1993) study differs from the neutral probe used in the current experiments.
 Both probe types prompt a response from the subject but the similarities end there.
 An oven personal pronoun is bound to have more significance to a modular language processor than a row of asterisks.
 Fodor et al.
 (I992)'s modified thesis makes the appearance of an overt pronoun a necessary part of first pass processing.
 The instruction to consider the constituents and structure of the discourse representation on encountering an overt anaphor is presumably built into the language processor.
 A modular parser will act only on elements from its grammar.
 It is likely then that only an overt pronoun will suffice to initiate the instruction.
 A modular parser expecting but denied an overt pronoun as in the SFC task would have to wait until central processes took over and tried to make some sense out of the discourse representation.
 The unlikely alternative is to allow the parser to be sensitive to neutral probes as well as overt pronouns.
 Clearly then, the neutral probe cannot be considered equivalent to the pronoun in its effect on the language processor.
 MarslenWilson et al.
 (1993) argue that if there is any informational encapsulation, it is not in a module that has logical form as its output, but rather one that outputs a mental model or some other form of discourse representation.
 Such output requires background knowledge for its construction and if the output is to be "online" then the knowledge has to be accessed almost immediately.
 The experimental evidence suggests we abandon the strictly modular view, and assume that, as listeners proceed in the sentence, they attempt to construct a discourse interpretational structure directly.
 There remains the issue which was the original motivation for modularity.
 How can inferential activity based on real world information occur so rapidly? It is remarkable given the unconstrained nature of the database which must support such activity that there does not yet appear a processing penalty in using it.
 There might be constraints operating to make language processing as rapid as possible but there does not appear to be a constraint on the type of information available to a putative parser in the first few hundred milliseconds of processing.
 Acknowledgements This research was supported by a SERC studentship awarded to Mark DurrantPeatfield and by M R C , SERC and ESRC grants awarded to William MarslenWilson and Lorraine Tyler.
 M y thanks to an anonymous reviewer whose raised an interesting point.
 References Altmann, G.
 T.
 M.
 & Steedman, M.
 (1988).
 Interaction with context during human sentence processing.
 Cognition, 30, 191238.
 Fodor, J.
 A.
 (1983).
 Modularity of mind.
 Cambridge, Ma: MIT Press.
 Fodor, J.
 A.
, Garrett, M.
, & Swinney, D.
 (1993).
 A modular effect of parsing.
 Manuscript, Program in Philosophy, C U N Y Graduate Center.
 Garrod, S.
,& Sanford, A.
 (1990).
 Referential processes in reading: Focusing on roles and individuals.
 In Comprehension processes in reading.
 Eds Balota, LEA.
 Hobbs, J.
 R.
 (1979).
 Coherence and coreference.
 Cognitive 5de«ce, 3(1), 6790.
 MarslenWilson, W , & Tyler, L.
 K.
 (1987).
 Against Modularity.
 In J.
 L.
 Garfield (Eds.
), Modularity in Knowledge Representation and Natural Understanding.
 Cambridge: MIT Press.
 MarslenWilson, W.
, Tyler, L.
 K.
, & Koster, C.
 (1993).
 Integrative processes in utterance resolution.
 Journal of Memory and Language.
, 32,647666.
 Mitchell, D.
C.
 (1987).
 Lexical guidance in human parsing: Laws and processing characteristics.
 In M.
 Coltheart (Ed.
), Attention and Performance XII: The psychology of reading.
 London:Lawrence Erlbaum Associates Ltd.
 368 A Connectionist Model O f Instruction Following David C.
 Noelle & Garrison W.
 Cottrell Department of Computer Science & Engineering University of California, San Diego 9500 Oilman Drive La Jolla,CA 920930114 { d n o e l l e , g a r y } @ c s .
 u c s d .
 e d u Abstract In this paper we describe a general connectionist model of "learning by being told".
 Unlike common network models of inductive learning which rely on the slow modification of connection weights, our model of instructed learning focuses on rapid changes in the activation state of a recurrent network.
 W e view stable distributed patterns of activation in such a network as internal representations of provided advice  representations which can modulate the behavior of other networks.
 W e suggest that the stability of these configurations of activation can arise over the course of learning an instructional language and that these stable pattems should appear as articulatedattractors in the activation space of the recurrent network.
 In addition to proposing this general model, we also report on the results of two computational experiments.
 In the first, networks are taught to respond appropriately to direct instruction concerning a simple mapping task.
 In the second, networks receive instructions describing procedures for binary arithmetic, and they are trained to immediately implement the specified algorithms on pairs of binary numbers.
 While the networks in these preliminary experiments were not designed to embody the attractor dynamics inherent in our general model, they provide support for this approach by demonstrating the ability of recurrent backpropagation networks to learn an instructional language in the service of some task and thereafter exhibit prompt instruction following behavior.
 Introduction Connectionist models of human learning have focused primarily on problems of inductive generalization.
 They view learning as a process of extracting new knowledge firom the statistical properties of a long series of exemplars.
 While this covers many cases, humans exhibit other learning behaviors which defy description as induction over examples.
 In particular, we are capable of acquiring new knowledge from single highly informative events, such as tasting sushi for the first time, seeing someone operate a new coffee machine, or hearing a lecture.
 A single sentence can have profound and lasting effects on our behavior.
 Furthermore, w e are capable of integrating such rapidly acquired knowledge with knowledge gained inductively.
 If connectionism is to provide a sound computational framework for the entire range of human learning behaviors, it must be extended beyond induction.
 Towards this end, w e propose here a connectionist model of "learning by being told", and w e demonstrate a somewhat more modest model of connectionist instruction following.
 W e view "learning from instruction" as involving the demonstration of "appropriate" behavior immediately following the receipt of a linguistic directive.
 Our goal is to integrate standard connectionist learning methods with such rapid instructed learning to form a single cognitively plausible model.
 This multistrategy model should help explain both the operationalization of instruction into appropriate behavior (HayesRoth et al.
, 1980; Mostow, 1983) and the interaction effects between instructed learning and exemplarbased learning which have been observed in humans.
 Our model is based on the observation that typical connectionist weight modification techniques are inherently too slow to account for instructed learning.
 Of course, large weight changes could be made in response to instruction, but in networks using distributed representations, such rapid weight modification tends to destroy previously acquired knowledge in dramatic and unrealistic ways.
 W e focus instead on modeling a network's response to instruction as changes in its internal activation state.
 W e suggest that our prompt response to instruction is best seen as motion in activation space  as the settling of a network's activation state into a (typically novel) basin of attraction corresponding to the received instruction.
' This idea may be illustrated by the Necker cube network (McClelland et al.
, 1986), shown in Figure 1.
 This small constraint satisfaction network models our perception of the line drawing of a cube, focusing on our tendency to interpret the drawing in one of two distinct ways.
 The processing elements in this network represent particular depth assignments, "front" or "back", for each vertex in the cube.
 Connection weights are selected so as to embody constraints on the interpretation of vertices.
 The result is a recurrent attractor network with two major basins of attraction in activation space.
 In other words, there are two main configurations of unit activations which are stable over time  one configuration for each interpretation of the Necker cube drawing.
 Given some starting levels of activation for the processing elements, the network will tend to settle into one of these attractor basins, forming a coherent internal representation of the cube in activation space.
 W e may bias the network toward one interpretation over the other by providing input activation to the appropriate units.
 B y manipulating the input to the units on one side, we can cause the network to rapidly move from one attractor basin to the next.
 Similarly, humans can be told to see the cube in a different way, and this input can change their perception of it.
 The reception of direct instruction may be viewed as a process similar to that embodied in this Necker cube example.
 In the case of instruction, natural language advice is to be 'Thanks are due to Paul Churchland for this notion (Churchland, 1990).
 369 / r ~ v i I*—t^ BEHAVIOR 1 Domain Task k 1 ^ SENSES J V^ Plan Network PLAN \ .
 1 ADVICE V— Figure 1: Necker Cube And Attractor Network Figure 2: Generic Instructable Network Architecture rapidly transformed into a coherent internal representation in activation space  a representation which may then be used to modulate the behavior of other networks in the performance of their tasks.
 A s in the Necker cube system, w e may encode these internal representations in the attractors of a recurrent network.
 Learning an instructional language may be seen as training the weights of such an attractor network so as to form a distinct basin of attraction for every meaningful sequence of advice.
 Most of these articulated attractors^ need not be explicitly trained over the course of language learning, but they may come into existence, nonetheless, via interactions between trained attractors.
 In this way, some "spurious" attractor basins may actually be seen as serendipitous basins in that, while not explicitly trained, they have interpretations that "make sense" in the behavioral domain of the network.
 Thus, once the language of instruction is learned, such an attractor network may rapidly encode novel advice simply by moving to the corresponding basin of attraction.
 As in the Necker cube network, this motion in activation space may be driven by appropriate input activation.
 Following the lead of many connectionist models of natural language processing (Cottrell, 1989; Elman, 1990; St.
 John and McClelland, 1990), w e may encode linguistic instructions as temporal sequences of such input activity, allowing advice to "push" the network into the appropriate basin of attraction.
 For this strategy to work, such an instructable network must support a distinct stable configuration of activation levels for every instruction sequence which might be presented.
 If such a combinatorial set of attractors is not present, the network will be limited in the number of different instruction sequences that it can understand and operationalize.
 With articulated attractors in place, however, novel instructions may be quickly molded into a coherent activationbased modulating force on some task behavior.
 Note that this strategy of modeling instructed learning in activation space leaves weight modification in the capable hands of standard connectionist inductive learning algorithms.
 This allows instruction and induction to proceed in tandem to solve complex learning problems.
 Also, in addition to weight modifications based on behavioral feedback, Hebbian learning may be used to strengthen and deepen attractors which are ^These have also been called componential attractors (Plaut and McClelland, 1993).
 regularly visited.
 Such weight changes would increase the likelihood of visiting those attractors in the future, making c o m m o n instructional memories easy to instantiate.
 Our approach may be illustrated by a generic network architecture, shown in Figure 2.
 In that diagram, boxes represent layers of processing elements, and arrows between boxes represent complete interconnections between layers.
 Temporal streams of tokens in an instructional language are presented at the advice layer, and this input activity is used to direct the settling of the attractor network at the plan layer.
 The stable configuration of activity levels at thep/a/i is then used to modulate the behavior of a task oriented network, much like the "plan" layer of a Jordan network (Jordan, 1986).
 The connection weights may be trained using a standard inductive learning technique, such as backpropagation, with an error signal provided only on actual task performance.
 This allows the language of instruction to be learned in the service of a task (St.
 John, 1992).
 Such inductive learning may also be used to shape task performance through experience.
 Once the instructional language is learned, however, new behaviors may be elicited at the speed of activation propagation, without further weight modification, simply by presenting a novel stream of advice.
 In summary, our general strategy involves: • encoding instructions as temporal input sequences; • training a recurrent network (the plan network) to form combinatorial representations of these sequences in its basins of attraction  representations shaped by error feedback from another network (the domain task network), which uses activity in the plan network to modulate the performance of some specific task; • providing further inductive training as appropriate, allowing for the interaction of exemplarbased inductive learning with learning from instruction.
 This paper presents an initial examination of this approach to instructed learning.
 Of particular interest is the plausibility of the claim that a connectionist network may be trained to promptly transform a temporal sequence of instructions into appropriate behavior in some domain.
 To test this assertion, some networks were made to follow instructions concerning a combinatoric discrete mapping task and others were trained to immediately implement algorithmic instructions for binary arithmetic.
 These networks were constructed without the ben370 efit of stable attractors at the plan layer, so activity at that layer was artificially "frozen" once advice was received (St.
 John and McClelland, 1990).
 The utility of articulated attractors at the plan layer will be the primary focus of future work.
 The details of these two experiments are presented below, following a brief overview of related work.
 Alternative Approaches We are not the first to propose a technique for the direct instruction of connectionist models.
 Indeed, early connectionist networks using "localist" approaches were frequently "instructed" through the direct assignment of network parameters by knowledgeable researchers.
 This was possible since the networks involved parameters with well understood semantics.
 In such a framework, "instruction" was essentially "programming", involving the specification of processing elements, connections between elements, and specific connection weights.
 Some systems automated a large portion of this process, allowing symbolic rules to be directly compiled into network parameters (Cottrell, 1985; Davis, 1989).
 The main drawback of this "weight compilation" approach is the constraint that it places on the representationzd schemes available to the network.
 Specifically, since the semantics of network components are fixed, networks of this kind are not free to form arbitrary distributed representations appropriate for the demands of the task.
 Some researchers have generated network models which are instructable in this "weight compilation" manner but are still free to develop arbitrary internal distributed representations through inductive training.
 In general, networks of this kind may only be instructed before inductive training begins, because standard connectionist learning methods often change the representational nature of weight values in hard to predict ways, making the direct manipulation of those weights in response to instruction quite problematic.
 One solution to this problem involves occasionally normalizing weight values back to configurations which are "meaningful" to the weight compilation process.
 This may be done by identifying and extracting the "rules" embodied in the trained network and then resetting weight values to encode exactly those extracted rules.
 Once reset in this way, new instructions may be incorporated into the network and the process of inductive learning may begin again.
 Weight compilation approaches of this kind have been successfully used to encode propositional logic rules (Towell and Shavlik, 1994), "fuzzy" classification rules (Tresp et al.
, 1993), simple mapping rules (McMillan et al.
, 1991), the transitions of finite state automata (Giles and Omlin, 1993), and advice for an agent in an artificial environment (Maclin and Shavlik, 1994).
 Unfortunately, none of these models provide a connectionist explanation for how instructions are compiled into the network.
 Also missing is a connectionist mechanism for the rule extraction process which is needed to "reset" the semantics of weight values.
 Both of these processes, compilation and extraction, require the direct manipulation of the processing elements and the global coordination of weight values.
 While a connectionist explanation for these dynamic global restructuring processes may be possible, it is not clear what form such an explanation would take.
 Perhaps the most important criticism of these models, however, is that the "language of thought" is preordained by the researcher.
 In order to continue to receive instruction after inductive learning has begun, the models must continuously reformulate their knowledge in the terminology of explicit linguistic instruction.
 Inductively learned nuances are discarded during rule extraction, leaving these models with a behavior that is consistently analogous to symbolic rule following.
 In essence, these models are trapped in the first stage of skill acquisition and cannot escape (Rumelhart and Norman, 1978).
 By placing instructions in activation space, all of these problems may be avoided.
 Inductive weight modifications and instruction following may proceed simultaneously, and they may complement or interfere with each other in complex ways.
 Instructed Associations A number of initial experiments have been conducted, focusing solely on the ability of recurrent backpropagation networks (Rumelhart et al.
, 1986) to learn to operationalize instruction.
 In particular, issues concerning the benefits of attractor network dynamics for generalization to novel advice have been left for later inquiries.
 For these initial experiments, unit activations at the plan layer are artificially "frozen" in order to provide a stable internal representation of input instruction sequences.
 The goal of these early experiments is to demonstrate that a language of instruction may be learned inductively solely from error feedback on actual task performance.
 Our first experiment focuses on the ability of these networks to learn to follow instructions concerning a simple associational mapping.
 Our domain task involves mapping inputs from a finite set into outputs from the same set.
 Correct mapping behavior is not specified by a collection of labeled examples, however, but by the direct communication of mapping rules.
 These rules may be viewed as statements such as, "When you see rock, say paper.
" Upon presentation of such rules, the network is to immediately change its behavior accordingly.
 Inductive training is used during an initial phase in which the network learns the instructional language, but once this initial training is complete, instruction following may proceed without weight modification.
 Also, this initial training phase exposes the model to only a fraction of the possible mappings, and the network is expected to generalize its instruction following behavior to novel instruction sequences.
 The model, inspired by the architecture of the Sentence Gestalt network (St.
 John and McClelland, 1990), is shown in Figure 3.
 The boxes represent layers of sigmoidal processing elements and arrows between boxes represent complete interconnections between layers.
 Layer sizes are shown in parentheses.
 Symbolic instruction tokens, each encoded as localist "1outofN" activation vectors, were presented sequentially at the advice input layer, and activation was propagated through the recurrent "Plan Network" to produce a pattern of activation at the plan layer.
 Each mapping rule was encoded as a sequence of three of these instruction tokens (a delimiter followed by the input/output pair) and each complete mapping consisted of three such rules.
 For example, the nine token advice sequence: ^ ROCK PAPER => SCISSORS ROCK 371 oirrpiiT(.
ii (10) Mapping Nelwork L INPIT (3) Plan Network PLAN (20) (20) ADVICE (4) Epochs T o 1 0 0 % Accuracy 5CXX)t P 4000? 3(X)0i |_2000^ S 10000 20 40 60 80 100 Training Set Size Generalization Accuracy 1000 20 40 60 80 100 Training Set Size Instructable Mapping Network Figure 3: Instructable Mapping Network: Architecture, Training Time, & Generalization => P A P E R S C I S S O R S was used to communicate the three rules, "when you see ROCK, say PAPER", "when you see S C I S S O R S , say ROCK", and "when you see PAPER, say SCISSORS".
 W h e n the presentation of a sequence of instruction tokens was complete, the activation at the plan layer was "frozen" and used to modulate the behavior of the "Mapping Network" as it performed the desired mapping.
 Input tokens, also encoded in a localist fashion, were presented at the input layer, and the network's response was read from the output layer.
 During the initial training phase, mean squared error was then computed at the output layer, based on the most recently presented instructions, and this error was backpropagated to allow for weight modifications throughout the network.
 The details of this training procedure were much like those of the Sentence Gestalt model.
 In particular, error was backpropagated through recurrent connections for only a single time step, and error was computed after the presentation of each instruction token.
 A learning rate of 0.
05 was used, with no momentum.
 This initial inductive training period was ended when perfect performance was achieved on a training set of instruction sequences, or when this training set had been presented 5000 times.
 Training sets of nine different sizes were examined, and five different random initial weight sets were used.
 Almost all of these trials resulted in 1 0 0 % accuracy on the training set within the limit of 5000 epochs.
 In other words, these networks consistently learned to operationalize the instructions on which they were trained.
 As shown in Figure 3, generalization performance was also good, with accuracy values on nontraining set instruction sequences appearing well above the chance level of 3 3 % correct.
 Note that training set size is expressed in this figure as a percentage of the total number of possible instruction sequences.
 Three discrete inputs gave 27 possible mappings.
 For each mapping, there were 6 possible permutations of the mapping rules, for a total of 162 possible instruction sequences.
 While very simple, this discrete mapping task poses interesting problems for inductive connectionist learning.
 Appropriate system behavior depends entirely on the given instructions.
 There are no other environmental regularities for the network to discover during training.
 Once completely trained to "understand" the instructional language, the network is required to modify its behavior immediately upon receipt of new instructions, without further weight modification.
 The way in which this discrete mapping problem forces the network to generalize in a systematic manner over the space of instruction sequences makes this a difficult learning problem, and it also makes it an ideal domain in which to test the power of the proposed network architecture.
 The results demonstrate that associational mapping instructions can indeed be operationalized by networks of this kind.
 However, these results also suggest a need for a mechanism to improve generalization performance (Noelle and Cottrell, 1994)  a need which might be met by the incorporation of an attractor network at the plan layer.
 Instructed Algorithms Our second experiment extends our task domain into the realm of sequential procedures.
 The goal is to demonstrate the ability of these recurrent networks to handle instructions concerning complex sequences of action.
 To this end, we focus on the domain of arithmetic on arbitrarily large binary integers.
 In previous work it was shown that recurrent neural networks may be inductively trained to perform a systematic procedure for multicolumn addition (Cottrell and Tsung, 1993).
 Here w e wish to examine the possibility of modulating such algorithmic behavior through direct instruction.
 Instructional tokens, each representing some atomic action, are to be used to communicate a sequential method for binary addition or subtraction to a network, and that network is to be trained to immediately implement the specified procedure.
 The general structure of the Cottrell & Tsung addition model was used as the basis of our "Arithmetic Network", shown in Figure 4.
 Under this approach, arithmetic was seen as the iterative transformation of a written representation of two argument integers.
 The two numbers are assumed to be written so that columns align, and an attentional mechanism is assumed to focus processing on one digit column at a time.
 Solving an arithmetic problem involves iteratively performing a sequence of actions for each column and then attending to the next.
 In terms of the network architecture, the digits input layer contained a representation of the two digits in the current column (plus an extra input unit to signal when no columns remained).
 The actions output layer specified the action to be taken on the current time step, which was one of: "write a given digit as the result for the current column", "announce a carry or borrow", "move to the next column", or "announce 372 ACTION (5) (20) Arithmeiic Network DIGITS (3) Plan Nelwork PLAN (10) Z E I (10) ADVICE (8) Ciincnt Column 1 0 0 + 0 0 1 1 1 0 0 1 101 1 10 Problem Format Accuracy During Training 0 t/3 .
2 80u t o U 40c 1 0/ ^ —•—Training • Generalization 500 1000 1500 Epochs Insiruciable Arithmetic Network Figure 4: Instructable Arithmetic Network: Architecture, Task Format, & Learning Curve completion of the current problem".
 The "Arithmetic Network" included a recurrent hidden layer, which was needed both to produce a sequential output and to "remember" the potential presence of a carry or borrow from the processing of the previous column.
 A s in the discrete mapping experiment, the behavior of this domain task network was to be specified by a stream of input instruction tokens.
 Different instruction sequences could specify different orderings for sets of standard actions (e.
g.
, announcing the carry before or after recording the digit sum) or could specify completely different arithmetic operations (e.
g.
, subtraction rather than addition).
 Each sequence described three actions which were to be applied in the given order to each column of digits.
 For example, the usual form of addition was specified as, " W R I T E  S U M A N N O U N C E  C A R R Y NEXTCOLUMN".
 Only six such instruction sequences constituted meaningful procedures: ANNOUNCECARRY WRITESUM NEXTCOLUMN WRITESUM NEXTCOLUMN ANNOUNCEPREVCARRY WRITESUM ANNOUNCECARRY NEXTCOLUMN ANNOUNCEBORROW WRITEDIFF NEXTCOLUMN WRITEDIFF NEXTCOLUMN ANNOUNCEPREVBORROW WRITEDIFF ANNOUNCEBORROW NEXTCOLUMN Despite the extremely small size of this set of possible algorithms, making generalization unlikely, the last of the subtraction sequences was avoided during the initial training phase, to be used, instead, as a test of generalization.
 Still, the primary goal was to have the network exhibit appropriate behavior when presented with any one of the training set instruction sequences.
 This network was operated and trained in much the same manner as the discrete mapping network.
 Instruction tokens were presented sequentially at the advice input layer, using a localist code, and activity was propagated through the "Plan Network" to produce a plan layer activation vector representing the entire instruction sequence.
 Activation at the plan layer was then "frozen" and used as an input to the "Arithmetic Network", which then performed the specified procedure on a collection of binary number pairs.
' Training was conducted as in the discrete mapping network, with error computed after the presentation of each instruction token and backpropagated through recurrent connections for only a single time step.
 A large number of experiments were conducted using this architecture and task, varying hidden layer sizes and details of the training regimen.
 As Figure 4 demonstrates, it was possible to achieve perfect performance on the training set of instruction sequences, but generalization was essentially not achieved.
'' Still, the primary goal of this experiment was attained.
 The resulting model was capable of performing a number of different versions of addition and subtraction, and it could immediately modify its behavior, without weight adaptation, to match one of these algorithms upon presentation of the appropriate instructions.
 This experiment has shown that the proposed connectionist framework is sufficient to allow complex temporal behaviors to be modulated by input advice.
 Conclusion As an initial small step towards a comprehensive model of human learning, w e have proposed a connectionist framework for "learning by being told".
 Our approach views linguistic advice as temporal input streams to a recurrent network, and the operationalization of that advice is seen as motion in the activation space of that network.
 "Meaningful" instruction sequences are internally represented by stable articulated attractors in that space, and these attractors arise either in the process of learning the instructional language or in later Hebbian modifications resulting from the repeated instantiation of neighboring attractors.
 By locating instructed learning in activation space, our framework avoids the problems inherent in "weight compilation" approaches, and provides a means for integrating induction and instruction.
 In this paper, w e have put off an examination of attractor dynamics and have focused, instead, on establishing the ability of connectionist networks to inductively learn an instructional language.
 W e have demonstrated successful instruction following behavior in both a combinatoric mapping task and in a domain involving the performance of systematic procedures.
 In both domains, networks inductively acquired 'Typically, all number pairs of up to three digits in length were used to provide training problems.
 "•The accuracy measurement shown in Figure 4 is a measure of correct actions over time.
 The displayed 7 4 % generalization accuracy shows that many actions were performed correctly, but it masks the fact that systematic mistakes on the test set instruction sequence kept the network from attaining the complete correct answer for even a single subtraction problem when given this instruction sequence.
 373 the ability to operationalize instructions, with error feedback provided only for actual behavior on the task.
 The requirements of the domain drove the representational structure at the plan layer.
 The ability of these networks to understand novel instruction sequences was also quite reasonable, especially considering their limited exposure to the instructional language, but there is still much room for improvement here.
 In particular, the utility of attractor network dynamics for generalization to novel advice sequences, a key feature of our model, has not yet been tested.
 W e conjecture that the introduction of an attractor network at the plan layer will give rise to articulated attractors in activation space and that these will facilitate systematic generalization to novel sequences of instruction.
 Examining this claim will be the primary aim of future work.
 If connectionism is to provide a unified modeling framework for human learning, it must incorporate a variety of learning strategies.
 Inductive generalization forms a natural foundation for such a framework, since so many learning problems may be expressed in terms of statistical induction.
 Instructional learning is a natural partner for induction, since it is strong where induction is weak.
 Learning from instruction is fast compared to inductive learning, and its resistance to negative contingencies makes it especially useful for learning difficult behaviors with delayed rewards.
 Perhaps most importantly, linguistic instruction is a primary means of efficiently transferring the vast collection of accumulated cultural knowledge to each individual.
 Learning from instruction has become a critical component of human development, so it is natural to make it a central focus of efforts in cognitive modeling.
 References Churchland, P.
 M .
 (1990).
 Talk presented at the Konnektionismus in Artificial Intelligence und Kognitionsforschung conference.
 Salzburg, Austria.
 Cottrell, G.
 W .
 (1985).
 Parallelism in inheritance hierarchies with exceptions.
 In Proceedings of the Eighth International Joint Conference on Artificial Intelligence, pages 194202, Los Angeles.
 Cottrell, G.
 W.
 (1989).
 A Connectionist Approach to Word Sense Disambiguation.
 Research Notes in Artificial Intelligence.
 Morgan Kaufmann, San Mateo.
 Cottrell, G.
 W .
 and Tsung, F.
S.
 (1993).
 Learning simple arithmetic procedures.
 Connection Science, 5(l):3758.
 Davis, L.
 (1989).
 Mapping classifier systems into neural networks.
 InTouretzky, D.
 S.
, tdiiov.
 Advances in Neural Information Processing Systems I, pages 4956, San Mateo.
 Morgan Kaufmann.
 Elman, J.
 L.
 (1990).
 Finding structure in time.
 Cognitive Science, 14:179211.
 Giles, C.
 L.
 and Omlin, C.
 W.
 (1993).
 Rule refinement with recurrent neural networks.
 In 1993 IEEE International Conference on Neural Networks, pages 801806, San Francisco.
 IEEE Neural Networks Council.
 HayesRoth, F, Klahr, P, and Mostow, D.
 J.
 (1980).
 Advicetaking and knowledge refinement: A n iterative view of skill acquisition.
 Technical report.
 Rand Corporation.
 Jordan, M .
 I.
 (1986).
 Serial order: A parallel distributed processing approach.
 Technical report.
 Institute for Cognitive Science, U C S D .
 Maclin, R.
 and Shavlik, J.
 W.
 (1994).
 Incorporating advice into agents that learn from reinforcements.
 In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI94), pages 694699, Menlo Park.
 A A A I Press.
 McClelland, J.
 L.
, Rumelhart, D.
 E.
, and the P D P Research Group (1986).
 Parallel Distributed Processing: Explorations in the Microstructure of Cognition, volume 2.
 The M I T Press, Cambridge.
 McMillan, C , Mozer, M .
 C , and Smolensky, P (1991).
 The connectionist scientist game: Rule extraction and refinement in a neural network.
 In Proceedings of the 13th Annual Conference of the Cognitive Science Society.
 Mostow, D.
 J.
 (1983).
 Machine transformation of advice into a heuristic search procedure.
 In Michalski, R.
 S.
, Carbonell, J.
 G.
, and Mitchell, T.
 M.
, editors.
 Machine Learning: An Artificial Intelligence Approach,\o\\ime.
 1, pages 367403.
 Tioga Publishing Company, Palo Alto.
 Noelle, D.
 C.
 and Cottrell, G.
 W.
 (1994).
 Towards instructable connectionist systems.
 In Sun, R.
 and Bookman, L.
, editors, Computational Architectures Integrating Neural And Symbolic Processes.
 Kluwer Academic Publishers, Boston.
 Plaut, D.
 C.
 and McClelland, J.
 L.
 (1993).
 Generalization with componential attractors: Word and nonword reading in an attractor network.
 In Proceedings of the 15th Annual Conference of the Cognitive Science Society.
 Rumelhart, D.
 E.
, Hinton, G.
 E.
, and Williams, R.
 J.
 (1986).
 Learning internal representations by error propagation.
 In Rumelhart, D.
 E.
, McClelland, J.
 L.
, and the PDP Research Group, editors.
 Parallel Distributed Processing: Explorations in the Microstructure of Cognition.
 The M I T Press, Cambridge.
 Rumelhart, D.
 E.
 and Norman, D.
 A.
 (1978).
 Accretion, tuning, and restructuring: Three modes of learning.
 In Cotton, J.
 W.
 and Klatzky, R.
, editors.
 Semantic Factors in Cognition.
 Erlbaum, Hillsdale.
 St.
 John, M .
 F.
 (1992).
 Learning language in the service of a task.
 In Proceedings of the 14th Annual Conference of the Cognitive Science Society.
 St.
 John, M .
 R and McClelland, J.
 L.
 (1990).
 Learning and applying contextual constraints in sentence comprehension.
 Artificial Intelligence, 46(l2):217257.
 Towell, G.
 G.
 and Shavlik, J.
 W.
 (1994).
 Refining symbolic knowledge using neural networks.
 In Michalski, R.
 S.
 and Tecuci, G.
, editors, Machine Learning: A Multistrategy Approach, volume 4, pages 405429.
 Morgan Kaufmann, San Mateo.
 Tresp, v.
, Hollatz, J.
, and Ahmad, S.
 (1993).
 Network structuring and training using rulebased knowledge.
 In Hanson, S.
 J.
, Cowan, J.
 D.
, and Giles, C.
 L.
, editors.
 Advances in Neural Information Processing Systems 5, San Mateo.
 Morgan Kaufmann.
 374 Using IntonationallyMarked Presuppositional Information in O n  L i ne Language Processing: Evidence from E y e M o v e m e n t s to a Visual M o d e l Julie C.
 Sedivy Dept.
 of Linguistics University of Rochester Rochester, N Y 14627 sedivyQpsych.
rochester.
edu Michael K.
 Tanenhaus Dept.
 of Brain & Cognitive Sciences University of Rochester Rochester, N Y 14627 mtan@psych.
rochester.
edu Michael SpiveyKnowlton Dept.
 of Brain & Cognitive Sciences University of Rochester Rochester, N Y 14627 spiveyOpsych.
rochester.
edu Kathleen Eberhard Dept.
 of Brain & Cognitive Sciences University of Rochester Rochester, N Y 14627 eberhardOpsych.
rochester.
edu Gregory N.
 Carlson Dept.
 of Linguistics University of Rochester Rochester, N Y 14627 carlson@ling.
rochester.
edu Abstract This study evaluates the effect of presuppositional information associated with contrastive stress on online language processing.
 An eyetracking methodology was used, in which eye movement latencies to real objects in a visual display are taken as a measure of online reference resolution.
 Results indicate that presupposed contrast sets are being computed online, and can be used to speed reference resolution by narrowing the referential domain of an utterance.
 In addition, presupposed contrast sets appear to play a role in managing attention in the processing of a discourse.
 I n t r o d u c t i o n There is a growing awareness in the field of formal semantics that presuppositional phenomena, which have traditionally been relegated to an extralinguistic pragmatic component, are in fact necessary for a complete semantic characterization of a variety of linguistic constructions.
 The recent theoretical emphasis on the interplay between asserted and presupposed levels of meaning leads to some interesting questions regarding the interaction of these levels of meaning in the online processing of language.
 For instance, it becomes important to determine whether presuppositional information is readily accessible to the processing system, and if so, whether it is available online for immediate interpretation.
 Some recent psycholinguistic work indicates that specific presuppositions associated with the interpretation of definite noun phrases have immediate effects on the resolution of temporary syntactic ambiguities (e.
g.
 Altmann & Steedman, 1988; Britt, 1994; Grain & Steedman, 1985; SpiveyKnowlton & Sedivy, in press).
 This paper is primarily concerned with the processing role of presuppositional information in the interpretation of contrastive focus.
 Recent semantic analyses have converged on a representation of contrastive focus involving the integration of asserted and presupposed information (e.
g.
 Rooth, 1992; Kratzer, 1991; Krifka, 1991).
 In parUcular, these theories have attempted to formalize the general observation that contrastive focus constructions are used not only to provide information about the material that is focused, but also to provide information about the relationship between the focused element and some presupposed set of contrasting entities.
 For instance, if a speaker were to assert " J O H N likes tofu", with contrastive stress on "John" (as indicated by capital letters), this utterance would likely be understood as drawing a comparison between John's attitudes towards tofu on the one hand, and those of a presupposed and contextually salient group of people on the other hand.
 This understanding arises from an interaction between asserted and presupposed levels of meaning.
 The dual representation of meaning is crucial to current semantic approaches to contrastive focus.
 This can be seen by observing the semantic effects of varying the placement of focus.
 For instance, a sentence such as "John only likes T O F U for breakfast" can be paraphrased as meaning that there are no foods that John likes for breakfast other than tofu.
 The lexical content of the sentence (and therefore its asserted propositional content) can be kept unchanged while varying the location of the focus (which reflects a change in the presuppositional content) as in the sentence "John only likes tofu for B R E A K F A S T ' which means roughly that there are no meals other than breakfast for which John enjoys eating tofu.
 This change in the presuppositional information exerts a clear change in the semantics of the sentence.
 Thus, the former sentence is automatically false under conditions where John also likes to eat eggs for breakfast, whereas the latter can be true under the same conditions.
 In order to capture the truth conditional effects of focus, Rooth's (1992) analysis makes use of the pragmatic notion of a presupp)osed contrast set against which the asserted content must be 375 mailto:mtan@psych.
rochester.
edumailto:carlson@ling.
rochester.
eduevaluated.
 The contrast set is derived essentially by replacing the focused element in the sentence with a variable.
 With respect to the sentence "John only likes T O F U for breakfast", the contrast set consists of entities that can serve as the variable for x in "John eats x for breakfast" (i.
e.
 foods that can be eaten for breakfast).
 The contrast set serves as the input domain for the interpretation of the focussensitive word "only", yielding an interpretation which states that, of the members of the contrast set, tofu is the only entity that John likes to eat for breakfast.
 In the sentence "John only eats tofu for B R E A K F A S T ' , on the other hand, the contrast set consists of meals that might involve the eating of tofu.
 This discussion of the analysis of focus demonstrates the central role of presuppositionallybased information in arriving at a semantic analysis of focusrelated constructions.
 The centrality of presuppositional information suggests a more prominent role for presupposition than has frequently been assumed.
 In particular, it suggests that semantic interpretation m a y be representationally, and perhaps temp)orally dependent uf)on the processing of certain kinds of pragmatic information.
 In traditional processing models (e.
g.
 Forster, 1979), it has been claimed that pragmatic information is processed at the latest stage of language processing.
 In this paper, w e will present experimental evidence from eye movements to objects in a visual model which suggest that presuppositional information that is intonationally marked is used immediately in the mapping of referential phrases to real objects in a visual model.
 E x p e r i m e n t 1: E v i d e n c e for C o n t r a s t Sets in O n  L i n e Processing The study reported in this paper makes use of a new eyetracking technique that is currently being adapted fix use in experimental work with spoken language (Tanenhaus, SpiveyKnowlton, Eberhard & Sedivy, in press).
 This technique employs an eyetracking device that is mounted onto a helmet and worn by the subject throughout the experiment, allowing for unrestricted head movement by the subject.
 The subject sits in front of an array of objects presented on a tabletop or upright board and manipulates objects in response to instructions from the experimenter.
 The objects in the visual display correspond to the discourse referents in the experimental instructions.
 The eye movements of the subject are monitored throughout the experiment, allowing for precise observation of the location of the subject's gaze and the point in time at which eye movements are launched in response to the experimenter's instructions.
 A number of factors together make this methodology particularly wellsuited for studying the online interpretation of referential phrases.
 First of all, the methodology relies on the subject being required to carry out an action that is closely linked with an experimental instruction.
 This ensures that the visual context is highly relevant for the interpretation of the target utterance.
 Second, this paradigm results in an eye movement record that is highly informative, as people typically look at an object before reaching for it (Ballard, Hayhoe & Pelz, 1995).
 Thus, it is possible to get a very precise indication of which object in the display is being understood as the intended referent in the experimental instruction, and how long it takes the subject to process the referential phrase and launch an eye movement, (i.
e.
 a saccade) to the understood referent.
 In addition, this experimental paradigm exploits the highly incremental nature of language processing.
 It is clear from the eye movement records that subjects attempt to make early commitments to referents based on an integration of the linguistic input and the visual cues available in the display.
 Eye movements to objects are very closely timelocked to the point in the utterance where the referent becomes unique with respect to the alternative possibilities defined by the visual context together with the speech input.
 In a study reported in Tanenhaus et al.
 (in press), subjects were instructed to touch objects that were distinguished by marking, color, and shaj)e.
 For instance, in a display consisting of a plain red square, a plain yellow rectangle, a plain blue square and a plain pink square, the referent in the instruction "Touch the plain red square" can be unambiguously identified at the word "red", as there is only one object in the display that is both plain and red.
 However, if the display contains more than one object that is both plain and red (e.
g.
 a plain red square and a plain red rectangle), the point of disambiguation occurs only following the word "square".
 The eye movement record showed a strong sensitivity to the point of disambiguation, with the mean time to launch a saccade to the target object being 250 m s from the end of the word that disambiguated the referent.
 The weighing of possible alternatives compatible with the speech input at a certain point in time is seen even more dramatically in some more recent experimental manipulations using more complex displays and longer referential phrases (Eberhard, Tanenhaus, SpiveyKnowlton & Sedivy, 1995).
 Under these conditions, we observe eye movements before the point of disambiguation to objects whose visual properties are consistent with the Unguistic description to date.
 In the present study, w e explored the contribution of presuppositions involved in the interpretation of contrastive focus to online processing of referential expressions.
 Unlike the referential presuppositions associated with definite expressions, presuppositional information related to conuastive focus is typically encoded intonationally, rather than lexically.
 This allows for the opportunity to examine the effects of prosodically marked information on language processing.
 In particular, this study focused on the potential of presuppositional contrast sets to provide constraining information allowing for early disambiguation of referential phrases.
 T o see how this is possible, consider the example experimental display (la) in Figure 1 below.
 The point of disambiguation for this display in conjunction with the instruction "Touch the large red square" is at the word "red".
 However, when contrastive stress is used, as in the instruction "Touch the L A R G E red square", a contrast set is presumably computed, which consists of the large and small red squares (by virtue of replacing the focused word "large" with a variable).
 If a ccmtrast set consisting of objects differing only in size is computed 376 quickly enough, and is taken to be the relevant domain of reference, the phrase now beawnes disambiguated prior to the word "red", rather than following it, as the relevant domain has only one large object.
 In this experiment, we looked for evidence of the online computation of contriist sets, and their effect on the incremental interpretation of referential expressifflis.
 W e predicted that conuastive stress would speed the launching of saccades to a referent in a visual model in which the intended referent becomes unique at an earlier point in the speech stream due to the availability of a sufficiently restricted contrast set, as is the case in Figure la.
.
 This facilitatory effect of contrastive stress should not be observed for a visual display in which contrastive stress does not allow for sufficient domain restriction to provide early disambiguation, as in Figure lb, where the entire display serves as the referential domain, even when accompanied by an instruction involving contrastive stress on the size adjective.
 I.
a yellow red l.
b o blue red squares, and triangles).
 For nine of the fifteen subjects tested, each experimental display contained a pair of objects differing only in size, as in Figure 1 above.
 These displays were coupled with sets of experimental instructions spoken by the experimenter.
 There were three instructions accompanying each display, with only the first counting as a critical instruction.
 Each set of three instructions was preceded by the instruction "Look at the cross", in order to make sure that the subject fixated on the same place preceding each critical trial.
 Critical commands varied systematically as to whether or not they contained contrastive stress.
 Half of the instructions were uttered with contrastive stress on the size adjective (e.
g.
 Touch the L A R G E red square"), and the other half of the instructions were uttered with neutral intonation.
 There were six items in each of the two cells.
 W e predicted that eye movement latencies would be shorter when the accompanying instruction was uttered with contrastive stress than when it received neutral intonation.
 For a subset of the subjects, w e included experimental displays of two types: either the display contained one pair of objects differing only in size, as in Figure la (i.
e.
 one potential contrast set), or it contained two pairs of minimally contrasting objects, (i.
e.
 two potential contrast sets).
 Displays containing two potential contrast sets were included in order to rule out an alternative account of the same effect, in which the facihtatory effect of contrastive stress on the size adjective is due to an increase in the salience of the size dimension, and therefore an increase in the activation of the subset of large entities, of which the target referent was a member.
 For these displays, the increased salience account predicts that there should be equal facilitation due to stress for both display types, as the number of large objects is equal in both types.
 However, under the contrast set hypothesis, contrastive stress should not result in faster saccade latencies for displays such as Figure lb, as both contrast sets must be considered as potential domains, which is equivalent to considering the entire display.
 The stress manipulation was aossed with the display type manipulation, yielding four cells with three items in each cell.
 W e predicted an interaction between the presence or absence of contrastive stfess and display type.
 All of the experimental displays were embedded with an equal number of filler displays and accompanying sets of instructions.
 Procedure Figure 1: T w o example visual displays serving as visual contexts for instructions in Exp.
l Materials The visual displays made use of arrangements of four cardboard shapes varying along the dimensions of size (large and small), color (red, yellow and blue), and shape (circles, While the subject followed instructions to touch objects in the workspace, eye movement data was recorded using a lightweight Applied Scientific Laboratories (ASL) headmounted videobased tracking system.
 The camera provides an infrared image of the eye at 60 Hz.
 Monocular eye position is determined by monitoring the locations of the center of the pupil and the cornea reflection.
 A scene camera is mounted on the side of the helmet, providing an image of the subject's field of view.
 Calibration is carefully monitored throughout each trial, and minor adjustments are occasionally made between trials.
 377 A V C R record was made for each experimental trial, consisting of the instructions spoken by the experimenter into a microphone, as well as the subject's momentbymoment gaze fixation superimposed over the scene camera image.
 Results Latency data for trials in which the initial fixation was to the correct object was analyzed from the video tapes by identifying the beginnings and ends of critical words in the speech stream for each trial, and noting the time lapse between the critical speech points and the onset of a saccade to the intended object.
 Latencies were measured from the onset of the coIcm" adjective Results of the experiment conformed to the predictions generated by the hypothesis that contrast sets are used online to constrain the interpretation of referential expressions.
 W h e n the size adjective on the first instruction was uttered contrastively, latencies to launch a saccade to the correct referent were an average of 431 m s compared to 545 m s when the instruction had neutral intonation.
 This difference was reliable (F(l,14)=6.
17, p<.
05).
 In addition, an A N O V A on the subset of six subjects for w h o m we included displays containing two potential contrast sets showed a reliable interaction between display type and intonation type (F( 1,5)= 18.
04, p<.
01).
 W h e n the display contained only one potential contrast set, launch latencies were 472 ms.
 with contrastive stress, compared to 635 ms.
 with neutral intonation, whereas for displays containing two potential contrast sets, the mean latencies were 588 ms.
 with contrastive stress and 555 ms.
 with neutral intonation.
 Discussion Results of this experiment show that under conditions where the relevant contextual presuppositions required for interpreting contrastive focus are met, the presence of contrastive stress can facilitate the interpretation of referential phrases.
 The facilitatory effect of contrastive stress is observed only in visual displays in which computing a contrast set allows for a restriction of the referential domain.
 This data pattern rules out an account in which the effect of contrastive stress is limited to an increase in the salience of the focused property, without reference to a contrast set.
 These results provide experimental evidence for a central role of presupposition in interpreting language online.
 E x p e r i m e n t 2: Attentional function of contrast sets As discussed above, the communicative goal of contrastive focus is to provide information about the relationship between the focused element and the set of contrasting entities, as well as to provide information about the focused element.
 In recognition of the heavy informational load associated with contrastive focus, a number of psycholinguistic studies have investigated the allotment of attentional resources to focused material.
 These studies have found that greater resources are allotted to focused material than unfocused material.
 For instance, Birch & Rayner (1994) demonstrate that more time is spent reading noun phrases that are clefted (in focus position) than identical noun phrases that occur in presuppositionally neutral sentences.
 Cutler & Fodor (1979) show that subjects are faster to respond to a target phoneme occurring at the onset of a focused word than an unfocused word.
 In addition, recall of focused material is superior to recall of unfocused material (Birch & Gamsey, in press; Singer, 1976).
 However, to date, there have been no studies examining the attentional status of entities in the contrast set that are not explicitly referred to in the utterance.
 Given the crucial contribution of the contrast set to the interpretation of contrastive focus constructions, it is reasonable to hypothesize that the inclusion of an entity in the contrast set heightens its sahence.
 W e carried out a second experiment to investigate this hypothesis.
 Materials and Procedure This experiment used the same eyetracking technique that was used in Experiment 1.
 W e reasoned that differences in the attentional salience of referents would be reflected in the ease of locating individual objects in the display, with highly salient objects taking less time to locate than less salient objects.
 W e hypothesized that contrastive focus would serve to heighten the salience of contrast set members, resulting in shorter eye movement latencies.
 As in the previous experiment, w e used displays of four cardboard shapes arranged around a central fixation cross.
 All of the experimental displays in this experiment contained one minimal pair of shapes differing only in size, as in Figure la above.
 Each target instruction was preceded by an instruction to look at one member of the minimal pair.
 The stress pattern of this instruction was manipulated such that half of the instructions were uttered with contrastive stress on the size adjective (e.
g.
 "Touch the L A R G E red square", with reference to Figure la above), and half of the trials were uttered with neutral intonation.
 The immediately following target instruction manipulated the identity of the target referent.
 In half of the trials, the target referent was the contrasting object (e.
g.
 "Now touch the small red one"), and in the other half, it was an object that was outside of the contrast set, but that had the same value for the size dimension as the contrasting object (e.
g.
 "Touch the small yellow triangle").
 For both target referents, the point of disambiguation was at the word following the size adjective (i.
e.
 "one" and "yellow" respectively).
 These two manipulations were crossed, to yield four cells, with four items in each cell.
 16 filler trials were added, which were similar in structure to the experimental trials, and constructed such that, over the course of the experiment, the 378 second instruction in tbe set referred to each object in the display with equal probability, to discourage probabilitybased strategies.
 W e predicted that contrastive stress on the first instruction would speed eye movement latencies lor contrast set members.
 However, contrastive stress should have no effect on eye movement latencies for instructions referring to unrelated objects outside of the contrast set.
 Results and Discussion Results thus far (based on six subjects) are preliminary, but suggestive.
 As predicted, the presence of contrastive stress preceding an instruction referring to the contrast member speeded eye movement latencies (216 m s after the onset of the disambiguating word for the contrastive stress condition versus 387 m s for the neutral stress condition).
 In addition, there was no facilitation of stress for instructions referring to an object that could not be construed as belonging to the contrast set (435 m s with contrastive stress versus 419 m s with neutral intonation).
 A statistical analysis indicates that the interaction between intonation type and referent type is marginally significant by subjects (F(l,5)=6.
3; p<0.
06).
 This data pattern lends support to the hypothesis that contrastive focus serves to raise the salience of objects that belong to the contrast set, despite the fact that these objects have not been explicitly referred to.
 The heightened salience is seen in the rapid resolution of subsequent reference to these objects.
 General Discussion Much of the research in language comprehension over the last two decades has emphasized the incremental nature of language processing, showing evidence that linguistic information begins to be processed as it becomes available in the speech stream (e.
g.
 MarslenWilson, 1975).
 The incremental property of the human language processor, however, introduces a specific problem for the processing system: that of temporary indeterminacy in the speech stream, such that linguistic information must frequently be processed before there is sufficient information in the input to exclude all but a single interpretation of the input.
 A great deal of the literature in language processing has focused on the problem of temporary structural indeterminacy, and the mechanisms by which the human processor resolves such indeterminacies (see Frazier, 1987; Tanenhaus & Trueswell, in press, for overviews).
 T w o general accounts can be seen as representing the poles of this debate: serial models in which syntactic processing is autonomous and precedes the processing of semantic and pragmatic information (Forster, 1979, Frazier, 1987), and constraintbased models in which different sources of linguistic and nonlinguistic information interact to settle on one of a number of competing interpretations (MacDonald et al.
,1994; Tanenhaus et al.
, in press b).
 The debate has revolved largely around evidence for or against syntactic parsing preferences which compute a firstpass default analysis based solely on syntactic information, and impervious to information of a semantic or pragmatic nature.
 Implicit in much of this debate has been the assumption that the primary task of the human language processor is to recover the appropriate linguistic structure of the input.
 Work in the headmounted eyetracking paradigm, in which eye movements to a visual model are monitored, has demonstrated that another form of indeterminacy arises that is a result of the task of mapping referential expressions to objects in a model, rather than the result of a structural ambiguity (Eberhard et al.
, 1995; Tanenhaus et al.
, in press a, b).
 This mapping is also highly incremental in nature.
 Evaluation of the objects in the model against the properties denoted by modifiers in the referential phrase begins immediately, and does not depend upon the complete construction of the referential phrase as a syntactic unit.
 Indeed, it has been shown that information regarding the contextual model to which referential expressions must be mapped plays a crucial role in the resolution of structural ambiguities (e.
g.
 Altmann & Steedman, 1988; SpiveyKnowlton, Trueswell & Tanenhaus, 1993; Tanenhaus et al.
, in press b).
 The emphasis on the modelbased aspect of language comprehension yields a rich opportunity for examining the resolution of indeterminacies that are referential, rather than structural, in nature.
 In the present study, w e have begun to evaluate the role of presuppositional information in the resolution of this type of indeterminacy.
 The results of the two experiments reported here support the centrality of presuppositional information in language interpretation.
 Specifically, these studies provide evidence for the use of presupposed contrast sets in establishing reference to objects in a visual model.
 The results of Experiment 1 further show that contrast sets are computed rapidly enough to be useful in the highly incremental interpretation of referential phrases.
 The results of Experiment 2 suggest that, in addition to their relevance for resolving temporary indeterminacies of reference, contrast sets have an important function in managing attention in the interpretation of a discourse.
 These data focus on the issue of referential, rather than structural indeterminacy.
 As such, they do not bear directly on the debate as to whether syntactic ambiguity resolution is serial or constraintbased, as the predictions of the serial account have hinged crucially on the presence of parsing preferences in temporarily ambiguous constructions.
 However, the results in Experiment 1 do suggest that complex presuppositional information is computed and used extremely rapidly in order to resolve referential indeterminacies.
 This certainly lends plausibility to accounts in which multiple constraints are rapidly integrated at the earliest stages in processing.
 In addition, these results are also congenial for recent trends in areas of semantics in which presuppositional information plays a central role in semantic interpretation.
 Specifically, the rapid interaction between lexical/semantic information pertaining to the properties of a referent and presupposed information regarding possible contrast sets lends plausibility to the interaction between levels of representation that is found in recent semantic work on contrastive focus.
 379 Acknowledgements Thanks to Dana Ballard and Mary Hayhoe for encouraging us to use their laboratory, to Jeff Pelz for teaching us how to use the equipment, and to Kenzo Kabashi for assistance in data collection.
 This work was supported by NIH resource grant 1P41RR09283; NIH grant HD27206 to M.
 Tanenhaus, a SHHRC Doctoral Fellowship to J.
 Sedivy, and NSF Fellowship to M.
 SpiveyKnowlton.
 References Altmann, G & Steedman, M.
 (1988) Interaction with context during human sentence processing.
 Cognition, 30, 191328.
 Birch, T.
 & Rayner, K.
 (1994).
 Paper presented at the 1994 meeting of the Psychonomics Society, St.
 Louis, MO Birch, T.
 & Gamsey, S.
 (In press).
 The effect of focus on memory for words in sentences.
 Journal of Memory and Language.
 Ballard, D.
, Hayhoe, M & Pelz, J.
 (1995).
 Memory representations in natural tasks.
 Journal of Cognitive Neuroscience, 7, 6882.
 Britt, M.
 A.
 (1994).
 The interaction of referential ambiguity and argument structure in the parsing of prepositional phrases.
 Journal of Memory and Language, 33, 251283.
 Grain, S.
 & Steedman, M.
 (1985).
 On not being led up the garden path.
 In Dowty, Kartunnen & Zwicky (eds.
).
 Natural Language Parsing.
 Cambridge U Press: Cambridge, M A .
 Cutler, A.
 & Fodor, J.
A.
 (1979).
 Semantic focus and sentence comprehension.
 Cognition, 7, 4959.
 Eberhard, K.
, Tanenhaus, M.
, SpiveyKnowlton, M.
, & Sedivy, J.
 (1995).
 Investigating the timecourse of establishing reference: Evidence for rapid incremental processing.
 Paper presented at the 8th Annual C U N Y Sentence Processing Conference, Tucson, AZ.
 Forster, K.
 (1979).
 Levels of processing and the structure of the language processor.
 In Cooper & Walker (eds.
), Sentence Processing.
 Hillsdale, NJ: Lawrence Exlbaum Associates.
 Frazier, L.
 (1987).
 Sentence processing: A tutorial review.
 In M.
 Coltheart (Ed.
), Attention and Performance (pp.
 559586).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Kratzer, 1991.
 The representation of focus.
 In von Stechow & Wunderlich (eds.
), Semantik: Ein Internationales Handbuch der zeitgenossichen Forschung.
 Berlin: Walter de GruytCT.
 Krifka, M.
 (1991).
 A compositional semantics for multiple focus constructions.
 Proceedings of Semantics and Linguistic Theory (SALT) 1.
 Cornell Working Papers, 11.
 MacDonald, M.
, Pearlmutter, N.
, & Seidenberg, M.
 (1994).
 The lexical nature of syntactic ambiguity resolution.
 Psychological Review, 101, 676703.
 MarslenWilson, W.
 (1975).
 Sentence percpetion as an interactive parallel process.
 Science, 189, 226228.
 Rooth, M.
 (1992).
 A theory of focus interpretation.
 Natural Language Semantics, 1 75116.
 Singer, M.
 (1976).
 Thematic structure and the integration of linguistic information.
 Journal of Verbal Learning and Verbal Behavior, 15, 549558.
 SpiveyKnowlton, M.
, Trueswell, J.
, Tanenhaus, M.
 (1993).
 Context effects in syntactic ambiguity resolution.
 Canadian Journal of Epxerimental Psychology, 47, 276309.
 SpiveyKnowlton, M.
 & Sedivy, J.
 (in press).
 Parsing attachment ambiguities with multiple constraints.
 Cognition.
 Tanenhaus, M.
, SpiveyKnowlton, M.
, Eberhard, K.
 & Sedivy, J.
 (in press a).
 Using eye movements to study spoken language comprehension.
 In T.
 Inoui & J, McClelland (eds.
), Attention & Performance XVL Tanenhaus, M.
, SpiveyKnowlton, M.
, Eberhard, K.
 & Sedivy, J.
 (in press b).
 Integration of visual and linguistic information in spoken language comprehension.
 Science.
 Tanenhaus, M.
, & Trueswell, J.
 (In press).
 Sentence comprehension.
 In J Miller & P.
 Eimas (Eds.
), Handbook of Perception and Cognition: Volume 11.
 New York: Academic Press.
 380 H o w to M a k e the Impossible S e e m Probable Philip N.
 JohnsonLaird Department of Psychology IMnceton University Green Hall Princeton, NJ 08544 phil@clarity.
princeton.
edu Fabien Savary Department of Psychology Princeton University Green Hall Princeton, NJ 08544 fabien@phoenix.
Princeton.
edu Abstract The mental model theory postulates that reasoners build models of the situations described in premises.
 A conclusion is possible if it occurs in at least one model; it is probable if occurs in most models; and it is necessary if it occurs in all models.
 The theory also postulates that reasoners represent as much information as possible in implicit models.
 Experiment 1 showed that, as predicted, conclusions about possible situations tend to correspond to explicit models rather than to implicit models.
 Experiment 2 yielded a discovery: there are illusory inferences with conclusions that seem plausible but that are in reality gross errors.
 In such cases, as the model theory predicts, subjects judge as the more probable of two events one that is impossible.
 For example, given that only one of the following two assertions is true: There is a king or an ace in the hand, or both.
 There is a queen or an ace in the hand, or both.
 subjects judge that the ace is more likely to be in the hand than the king.
 In fact, it is impossible for an ace to be in the hand.
 Introduction Consider the following problem: If there is a king or a queen in the hand then there is an ace in it.
 Which is more likely to be in the hand: a king or an ace? Most people respond correctly that the ace is more likely to be in the hand than the king.
 Such judgments have not hitherto been studied in the psychological laboratory, and there is only one theory that purports to explain them  the theory of mental models.
 This theory also predicts that certain premises should give rise to what we call illusory inferences.
 These yield conclusions that nearly everyone draws, that seem plausible, and yet that are egregious errors.
 Our plan in what follows is, first, to outline the theory of mental models; second, to describe a study that corroborates its account of inferences about what is possible; and, third, to describe the study that confirmed the existence of illusory inferences.
 The Mental Model Theory of Reasoning The theory of mental models (see e.
g.
 JohnsonLaird and Byrne, 1991) postulates that reasoning  deductive or inductive  is a process in which reasoners first represent the truth conditions of premises, and then use this representation together with their semantic and general knowledge to construct mental models of the relevant situations.
 These models may take the form of visual images, but their critical feature is their structure.
 Thus, a simple conjunction: There is a king in the hand and there is a queen in it too calls for a single model, which we represent in the following diagram where 'K' denotes a king and 'A' denotes an ace: K A Likewise, the exclusive disjunction: There is a king or there is an ace, but not both calls for two alternative models (one for each possibility), which we represent in the following diagram: K A where each line represents a separate model.
 The representation of explicit information is kept to a minimum so as not to overload working memory.
 The models of the disjunction are thus partially implicit because they do not make explicit that an ace does not occur in the first model and that a king does not occur in the second model.
 Reasoners thus need to make a mental 'footnote' that the first model exhausts the hands in which a king occurs and the second model exhausts the hands in which an ace occurs.
 (JohnsonLaird and Byrne, 1991, used square brackets to represent such a footnote, but we will forego that notation here.
) The footnote, provided it is remembered, can be used to make the models wholly explicit if necessary: K ^ A ^ K A where '—i' denotes negation.
 The same general principles underlie the initial representation of a conditional: If there is a king then there is an ace.
 Individuals grasp that the conditional means that both cards may be in the hand, which they represent in an explicit model, but they defer a detailed representation of the case where there is qqI a king in the hand, which they represent in a wholly implicit model denoted here by an ellipsis: K A Reasoners need to make a menial footnote that hands in which a king occurs are exhaustively represented in the explicit model, and so a king cannot occur in the hands represented by the implicit model.
 But, since hands containing an ace are not exhausted in the explicit model, they may, or may not, occur in the hands represented by the implicit model.
 381 mailto:phil@clarity.
princeton.
edumailto:fabien@phoenix.
Princeton.
eduBecause assertions may include several connectives, e.
g.
 "A or B, and C or D", ihe program simulating the mental model theory is recursive, and depends ultimately on the principles for conjunction and negation.
 The conjunction of two sets of models (corresponding to assertions conjoined by 'and') calls for the pairwise combination of each member of one set with each member of the other set.
 The principles of conjunction are summarized in Table 1.
 Negation, in principle, calls for the construction of the complement of a set of models, but in practice is more complicated.
 In general, if a conclusion holds in all the models of the premises, it is necessary: if it holds in most of the models, it is probable: and if it holds in at least one model, it is possible.
 Table 1: To form a conjunction of two sets of models: use the appropriate principle for each pairwise combination.
 l.
For two explicit models, conjoin their elements, dropping any duphcates, e.
g.
: A B a n d B C = > A B C If one model (bearing in mind any footnote) contains an element.
 A, that contradicts an element, .
A, in the other, the result is the null model (akin to the empty set).
 W h e n reasoners conjoin two separate premises, they tend to drop propositions that they know categorically, e.
g.
: A and A B => B, if A is categorical.
 2.
The conjunction of an implicit model with an explicit model is, in principle, constrained by any footnotes on the sets of models (and follows principle 1).
 If the footnotes have been forgotten, then the result is the explicit model, e.
g.
: .
 .
 .
 and B C => B C unless this model is already a member of the set of models containing the implicit model, in which case the result is the null model.
 3.
The conjunction of two implicit models should also be constrained by footnotes (and principle 1).
 If the footnotes have been forgotten, then the result is an implicit model: .
 .
 .
 and .
 .
 .
 => .
 .
 .
 unless one has already been formed from the conjunction.
 Previous studies have corroborated the predictions of the model theory about valid deductions, and, in particular, they have shown that the greater the number of models that have to be constructed to draw a necessary conclusion, the harder the task is  it takes longer and is more prone to error (see e.
g.
 JohnsonLaird and Byrne, 1991).
 Mental Models and Possibility A conclusion describes a possible state of affairs if at least one model of the premises supports it.
 The theory predicts that such conclusions should correspxjnd to explicit models of the premises rather than to implicit models.
 For example, the premise: There is an 'A' on the blackboard or there is a '2', or both has the explicit models: 2 A 2 Hence, if subjects have to describe the contents of a possible blackboard, their response should match one of these three models rather than be, say, 'A not2*, which is logically correct but which contains an item that is not in an explicit model.
 In the first stage of Experiment 1, we tested 26 Princeton students with such premises.
 W e rejected three subjects because they failed to follow the instructions: they tended to describe several alternatives rather than just one.
 Table 2 summarizes the results.
 It treats the premises as though they had the same content; in fact, the subjects saw each letternumber combination only once.
 Most of the "other" responses merely included letters other than those mentioned in the premise.
 The data bore out the prediction: 17 out of 23 subjects made a majority of responses corresponding to explicit models (Sign test, with one tie, p < .
01).
 Table 2: The percentages of responses to the eight premises in the first stage of Experiment 1.
 The subjects (n = 23) described one possibility given the truth of the premise.
 Percentages in bold are for the responses predicted to be the most frequent by the model theory.
 Type of premise A i f B A only if B A if and only if B A a n d B A or B, or both A or B, not both not both A and B neither A nor B Responses and their percentages A 15 13 0 0 39 28 46 0 B 7 11 18 6 9 44 24 2 AB 56 54 54 57 41 0 0 0 other 22 22 28 37 11 28 30 98 In stage 2 of Experiment 1, the subjects again responded with a possible state of affairs, but each trial was based on two premises, which both had to be taken into account in the response.
 Table 3 summarizes the results.
 "Other" responses included again unmentioned letters, the letter "C" alone, negated literals, and responses naming specific numbers of letters.
 Once again, however, 17 out of the 23 subjects draw a majority of conclusions corresponding to explicit models (Sign lest, p < .
02).
 W e draw two morals from the experiment.
 First, logicallyuntrained individuals can draw correct conclusions about what is possible both from single premises and from pairs of premises.
 Second, as the model theory predicts, their conclusions tend to correspond to explicit models.
 Illusory Inferences about Probabilities The computer program implementing the model theory predicted the existence of a novel category of inferences that have a striking property: their initial models yield a 382 Table 3: The percentages of responses to the eight problems in stage 2 of Experiment 1.
 The subjects stated what was possible given the truth of the premises.
 Bold responses are those predicted by the model theory.
 Type of problem Responses and their percentages A B AB AC BC ABC Other l.
AifandonlyifB 0 9 2 0 0 70 19 C if and only if A 2.
AifB 0 7 0 0 0 76 17 Cif A 3.
AorB,notboth 18 2 4 4 52 0 20 C if notA 4.
AorB,orboth 2 5 28 0 41 0 24 C if not A S.
notbothAandB 7 17 2 54 0 0 20 C if and only if A S.
notbothAandB 4 9 2 2 57 0 26 C if not A 7.
AorB,notboth 4 33 0 46 0 0 17 B or C, not both S.
AorB.
orboth 4 11 9 2 4 57 13 B or C, or both conclusion that is opposite to the one supported by the fully explicit models of the premises.
 Hence, if the theory is correct, these inferences should give rise to an illusion: nearly everyone should draw the same conclusion, it should seem obvious, and yet it will be totally wrong.
 In this section, w e will outline the model theory's predictions and describe some corroboratory results.
 Here is an example of an illusory inference:1.
 Suppose that only one of the following assertions is true about a hand of cards: There is a king or an ace in the hand, or both.
 There is a queen or an ace in the hand, or both.
 Which is more likely to be in the hand: a king or an ace? The models of the first premise are: K A K A and the models of the second premise are: Q A Q A The assertion that only one of the two premises is true calls for an exclusive disjunction of them, and an exclusive disjunction, X or else Y, has the following initial models: X Y Hence, the initial models of the premises merely include all the models above.
 The probability of an event is estimated on the basis of the proportion of models in which it holds (JohnsonLaird, 1994), i.
e.
 reasoners will tend to assume that models are equiprobable.
 Hence, they will respond that the ace is more probable than the king.
 If they made no such assumption, they would conclude that the problem is indeterminate, e.
g.
 the probability of the king alone could be greater the probabilities of all the other models s u m m e d together.
 Both of these responses are wrong, however.
 What has gone wrong? The two disjunctions are in an exclusive disjunction, and so when one is true, the other is false.
 W h e n the first disjunction is false there is neither a king nor an ace, and when the second disjunction is false there is neither a queen nor an ace.
 In fully explicit models, the first disjunction is combined with the negation of the second disjunction, and the second disjunction is combined with the negation of the first disjunction.
 Hence, the fully explicit models of the premises are: K ^ Q ^ A ^ K Q ^A The king is possible, but the ace is impossible, and so the correct response is that the king is more probable.
 W e also used an illusory inference based on conditionals: 2.
 Suppose that only one of the following assertions is true about a hand of cards: If there is a king in the hand then there is an ace.
 If there is a queen in the hand then there is an ace.
 Which is more likely to be in the hand: a king or an ace? The initial models suggest that the ace is more probable than the king, but the fully explicit models show that an ace cannot occur in the hand, and so the king is actually more probable than the ace.
 W e gave 24 Princeton students the two illusory inferences together with two inferences that the model theory predicts will elicit the correct responses (because the initial models support the same conclusion as the fully explicit models).
 Each subject received the four problems in a different order, and each problem was based on a different set of cards.
 The results are summarized in Table 4.
 The subjects were correct on 7 1 % of the control problems, but only on 1 7 % of the illusory inferences.
 20 out of the 24 subjects were more accurate with the control inferences than with the illusory ones, and there were two ties (Sign test, p < .
001).
 Overall, 21 out of the 24 subjects chose as more probable for one or both of the illusory problems a card that could not occur in the hand.
 Table 4: The percentages of responses to illusory and control inferences.
 Correct responses are in bold.
 Type of problem Percentages of responses ckrf̂  IririCT *»niii_nrr»ViQKlA Illusory inferences: l.
Only one assertion is true: king or ace, or both.
 queen or ace, or both.
 Which is more likely: king or ace? 2.
 Only one assertion is true: If king then ace.
 If queen then ace.
 Which is more likely: ace or king? Control inferences: 3.
1f king then ace.
 Which is more likely: king or ace? 4.
 If king or queen then ace.
 Which is more likely: ace or king? agg king equiprobablg 75 21 4 79 13 8 62 17 21 79 17 383 Conclusions The model theory was originally developed as an account of how people draw logically necessary conclusions.
 But, the theory also provides an obvious mechanism for reaching conclusions about what is possible or what is probable: a situation is possible if it holds in at least one model of the premises, and it is probable if it holds in most models of the premises (JohnsonLaird, 1994).
 The twist in these predictions is that reasoners are likely to use implicit models and to forget the mental footnotes that constrain their contents.
 It follows that a conclusion about what is possible should tend to correspond to an explicit model because implicit models have, by definition, no immediately available content.
 Our first experiment confirmed this prediction.
 It is worth emphasizing that the prediction is based on the models needed for deduction, that is, we did not develop a new theory to account for reasoning about possibilities.
 The same prediction might be derived from a theory based on formal rules of inference (e.
g.
 Rips, 1994), but such a theory will have to introduce special 'modal' rules for dealing with possibilities.
 The model theory predicted that there should be illusory inferences, and our results show that they exist.
 Colleagues who have succumbed to an illusion have suggested that they perhaps misinterpreted the assertion: "Only one of the following assertions is true", and that they took it to mean (1) that one assertion was true and the other was of unknown truth value, or (2) that the two assertions were in an inclusive disjunction, or (3) that the two assertions were in a conjunction.
 A recent unpublished study shows that none of these hypotheses is correct.
 The first two hypotheses are equivalent: an assertion of an unknown truth value is either true or false, and models of a disjunction, X ot Y, that take the form: Xand(Yor^Y) (XorOC)andY are equivalent to those of an inclusive disjunction: X Y X ^Y ^X Y In our recent study, we examined the following illusion: Only one of the following assertions is true: If there is a king in the hand then there is an ace.
 If there isn't a king in the hand then there is an ace.
 Nearly everyone judged that the hand is more likely to contain an ace than a king; in a separate condition of the experiment, they also deduced that the ace was in the hand.
 In fact, it is impossible for there to be ace in the hand.
 But, an inclusive disjunction of the two conditionals yields a tautology (there is or isn't a king in the hand, and there is or isn't an ace in the hand), and this interpretation cannot predict the illusion.
 The third hypothesis  that subjects treat the connective as a conjunction ~ is also refuted by the same study.
 It included a control problem of the form: Onlv one of the following assertions is true: If there is a king in the hand then there is an ace.
 If there is a king in the hand then there isn't an ace.
 The model theory predicts that subjects using implicit models should resp)ond that the king is more probable than the ace, which is the correct response.
 If the main connective is interpreted as a conjunction, however, the king is impossible because it yields a contradiction, and so subjects should respond that the ace is more likely.
 Only 10% of the subjects made this response.
 Errors in reasoning in previous studies can be explained in terms of failures to retrieve appropriate rules of inference (e.
g.
 Braine and O'Brien, 1991; Rips, 1994), or in terms of failures to consider all possible models of the premises (e.
g.
 JohnsonLaird and Byrne, 1991).
 Illusory inferences, however, are not a result of such oversights.
 What is novel about them is that a conclusion that nearly everyone draws is totally wrong: what is judged more probable of two alternatives is impossible.
 The illusions are predicted by the model theory, but the illusory deductions appear to refute the theories based on rules of inference (Braine and O'Brien, 1991; Rips, 1994), which contain only rules that yield valid conclusions.
 Hence, these theories have no way to explain the systematically invalid conclusions that individuals draw to illusory inferences.
 W e have only just begun to explore the space of possible premises in search of illusory inferences.
 They are relatively rare, but there are illusions based on other connectives apart from exclusive disjunction, e.
g.
 "and", and "if and only if.
 All the illusions seem to arise because human reasoners rely on implicit models, and so they overlook cases in which a state of affairs does not hold.
 To rely on as little explicit information as possible is a sensible solution to the allpervasive problem of limited processing capacity.
 Just occasionally, however, the lack of explicit information leads human reasoners into the illusion that they grasp a set of possibilities that is in fact beyond them.
 Acknowledgements We thank Ruth Byrne, Jack Gelfand, Sam Glucksberg, Danny Kahneman, Geoffrey Keene, Joel Lachter, Rick Lewis, and Eldar Shafir, for their advice.
 The research was carried out with support from the James S.
 McDonnell Foundation and from Fonds pour la Formation de Chercheurs et I'aide a la Recherche (Quebec).
 References Braine, M.
D.
S.
, and O'Brien, D.
P.
 (1991) A theory of If: A lexical entry, reasoning program, and pragmatic principles.
 Psychological Review, 98, 182203.
 JohnsonLaird, P.
N.
 (1994) Mental models and probabilistic thinking.
 Cognition, 50, 189209.
 JohnsonLaird, P.
N.
, and Byrne, R.
MJ.
 (1991) Deduction.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Rips, L.
J.
 (1994) The Psychology of Proof.
 Cambridge, M A : M I T Press.
 384 T h e Temporality Effect in Thinking about W h a t Might H a v e Been Ruth M.
J.
 Byrne & Ronan Culhane Psychology Department, University of Dublin, Trinity College, Dublin 2, IRELAND nnbyrne@vaxl.
 ted.
 ie Alessandra Tasso Psychology Department, University of Padua, ITALY psico06@ipdunivx.
unipd.
it Abstract When people think about what might have been, they construct a mental representation of the actual state of affairs, and they generate an imaginary alternative by carrying out minimal mutations to it.
 When they think about how an undesirable outcome might have been avoided, they mutate the events leading to the outcome in regular ways, for example, they undo the more recent event in a series of independent events.
 W e describe a computer simulation of the cognitive processes that underlie these effects of temporality on counterfactual thinking that is based on the idea that reasoners construct contextualized models.
 W e report the results of two experiments that show that the temporality effect arises because the first event provides the context against which subsequent events are interpreted.
 The experiments show that when the contextualizing role of the first event is decoupled from its temporal order the effect is eliminated, for both bad and good outcomes.
 The results rule out an alternative explanation based on the idea that the more recent event is 'fresh' in mind.
 The context effect in temporal mutability may shed light on the remaining primary phenomena of counterfactual thinking.
 Thinking about Imaginary Situations Thinking about what might have been — counterfactual thinking ~ depends on the comparison of an event with an imaginary alternative.
 People think about what might have been when they mull over the past, imagining how a situation could have turned out differently, e.
g.
, 1.
 If I had chosen a 4 instead of a 5,1 would have won the lottery.
 They also engage in similar hypothetical thinking when they speculate about the future, e.
g.
: 2.
 If I were to buy lots of tickets, my chances of winning the lottery would be better.
 Counterfactual thinking allows us to think about situations that are different from the actual one and to go beyond reflections about the actual past or the predictable future.
 It is closely related to conditional reasoning (e.
g.
, Byrne, 1989a; 1989b; Byrne and JohnsonLaird, 1992) and to suppositional reasoning (e.
g.
, Byrne, Handley, and JohnsonLaird, 1995).
 But, the essence of counterfactual thought is the comparison between an actual situation and a temporarily supposed counterfactual one (e.
g, Byrne and Tasso, 1994).
 Thinking about imaginary alternatives is central to higherlevel cognition — problem solving, creativity, reasoning, and decisionmaking (e.
g.
, Ginsberg, 1986; Macrae, 1992; Miller and McFarland, 1987; Roese, 1994).
 It underlies the construction of subgoals in problemsolving; it underlies planning and intention, and thus the concepts of change and improvement at the heart of creativity; and it underlies the search for counterexamples in reasoning, that is, the search for alternative situations in which the premises of an argument could be true but the conclusion false.
 The primary purpose of counterfactual thinking is to enable us to learn.
 W e carry out comparisons between factual and imaginary situations to work out h o w a chosen situation could have turned out better (or worse) and so w e have the capacity to learn from our mistakes (or our good fortune).
 As a result, w e can develop our o w n theories of the causes of an outcome, and how to avoid similar outcomes in the future.
 Indeed, counterfactual thinking m a y underlie causal understanding (e.
g.
, Chisholm, 1946; Goodman, 1973; Mackie, 1973; Skyrms, 1980), and causal attributions (e.
g.
, McGill and Klein, 1993; Wells and Gavanski, 1989), and it is crucial to scientific, legal, and social progress (for a review see Kahneman and Miller, 1986).
 Moreover, counterfactual thinking gives rise to emotional experiences such as regret, blame, guilt, and worry, as well as hope, surprise, relief, and wonder (e.
g.
.
 Landman, 1987; Johnson, 1986).
 These emotions emerge from the comparison of an actual situation to an imaginary alternative.
 The functions of counterfactual thinking are varied and widespread, and w e suggest that its key purpose is to release the human mind from the limitations of facts.
 What the mind does when it engages in counterfactual thinking is to compare facts to their imaginary alternatives.
 T w o key questions have been addressed in trying to understand counterfactual thinking.
 One concerns h o w w e make inferences from imaginary situations, and in particular, whether counterfactual reasoning is similar to 385 mailto:psico06@ipdunivx.
unipd.
itfactual reasoning (e.
g.
, Byrne and Tasso, 1994; Lewis, 1973; Stalnaker, 1968).
 The other concerns how we generate imaginary scenarios (e.
g.
, Kahneman and Tversky, 1982; Kahneman and Miller, 1986).
 It is this second question that w e focus on in the current paper.
 W h e n people undo an actual situation to create an imaginary one, their mutations are systematic and minimal (e.
g.
.
 Pollock, 1986).
 W h e n they think about how an outcome could have turned out differently, they tend to undo exceptional features, that is, actions that are unusual for the specified person rather than actions that are routine for them (e.
g.
, Kahneman and Tversky, 1982), although the exceptionality effect is modulated by how exceptional the outcome itself is (e.
g.
, Gavanski and Wells, 1989; Bouts, Spears, and Van der Pligt, 1992).
 People tend to undo the first cause in a causal sequence that led to the outcome rather than subsequent causes (e.
g.
.
 Wells, Taylor, and Turtle, 1987).
 They tend to undo actions that a person carried out, e.
g.
 switching stock to a (subsequently deteriorating) company, rather than inactions, e.
g.
, leaving stock in a (subsequently deteriorating) company (e.
g.
, Kahneman and Tversky, 1982; Landman, 1987).
 They undo events under an individual's voluntary control, e.
g.
, stopping at a pub for a drink, rather than events outside their control, e.
g.
, a fallen tree in the road (e.
g.
, Girotto, Legrenzi, and Rizzo, 1991).
 Finally, they tend to undo the most recent action or event rather than an earlier one in an independent sequence of events (Miller and Gunasegaram, 1990).
 Most researchers agree that the mutability of an element in a representation  how easy it is to undo that aspect of the representation — depends on how easy it is to think of alternatives to it.
 The question then becomes, what determines how easy it is to think of an alternative to a particular element in a representation? Our aim in the current paper is to outline a theory of counterfactual thinking that answers this question.
 W e will sketch a computational simulation that captures the spirit of the theory, and report the results of two experiments that test its claims.
 W e will describe the theory with reference to Miller and Gunasegaram's temporality effect, and so it is to a more detailed description of this effect that we now turn.
 Temporal Mutability Consider the following scenario (from Miller and Gunasegaram, 1990, p.
 1111): 3.
 Imagine two individuals (Jones and Cooper) who are offered the following very attractive proposition.
 Each individual is asked to toss a coin.
 If the two coins come up the same (both heads or both tails), each individual wins £1,000.
 However, if the two coins do not come up the same, neither individual wins anything.
 Jones goes first and tosses a head; Cooper goes next and tosses a tail.
 Thus, the outcome is that neither individual wins anything.
 When asked to undo the outcome, more than 80% of subjects agreed that the alternative of Cooper tossing a head came more readily to mind than Jones tossing a tail (Miller and Gunasegaram, 1990).
 They also judged that Cooper would experience more guilt, and would tend to be blamed more by Jones.
 Logically, of course, neither party should be considered more mutable, or more likely to experience any more guilt or desire to blame than the other, because the event is one of chance.
 The temporality effect has been postulated to play a role in many everyday judgements, such as the tendency for blackjack players to be averse to playing on the last box, the tendency for teams to sport their faster runner last in a relay race, and for people to wager more on their predictions than their postdictions (Miller and Gunasegaram, 1990).
 W e suggest that temporality affects mutability because of the mechanisms that underlie the construction of mental representations of actual and imaginary situations.
 What cognitive mechanisms could give rise to the temporality effect? W e suggest that earlier events in a sequence provide the context against which subsequent events are interpreted.
 W h e n reasoners construct a model of a situation, they try to represent as little as possible because of working memory constraints, and so some information is represented explicitly and some information is represented only implicitly (see JohnsonLaird and Byrne, 1991).
 W e suggest that in scenarios such as the cointoss one, the earlier event in a sequence initializes the model, that is, it identifies what the model is about and provides the cornerstone of its foundation.
 In this way, the earlier event in a sequence provides the context that ensures the coherency of the model.
 The contextualizing event in a model may configure and constrain the subsequent elements that are inserted into it.
 In everyday thinking, people's models may be continually changing to deal with new situations, and the cornerstone of a new situation may initialize a new model.
 Because the early event in the cointossing scenario provides the foundation stone of the model, it cannot be mutated without weakening the entire structure.
 For example, when reasoners attempt to undo the outcome that neither individual won any money in the cointossing scenario, they could fleshout their models to be consistent with a number of counterfactual scenarios, e.
g, Jones could have tossed tails instead of heads; or alternatively.
 Cooper could have tossed heads instead of tails.
 But, the temporality effect shows that people tend to fleshout their models to be consistent with just one of the options: the one in which the contextualizing element of the model — the first event — is left untouched.
 W e suggest that it is possible to decouple the contextualizing role of the first event from its position in the sequence.
 If our explanation based on contextualized models is correct, then a separate context event prior to the two target events should result in both the first and second target event being perceived to be equally mutable.
 W e constructed scenarios based on the following sort of content: 4.
 Imagine two individuals (Jones and Brady) who take part in a television game show, on which they are offered the following very attractive proposition.
 Each individual is given a shuffled deck of cards, and each one picks a card from their own deck.
 If the two cards they pick are of the same colour (i.
e.
 both from black suits or both from red suits) each individual wins £1,000.
 However, if the two cards are not the same colour, neither individual wins anything.
 386 Jones goes first and picks a black card from his deck.
 At this point, the gameshow host has to stop the game because of a technical difficulty.
 After a few minutes, the technical problem is solved and the game can be restarted.
 Jones goes first again, and this time the curd that he draws is a red card.
 Brady goes next and the card that he draws is a black card.
 Thus, the outcome is that neither individual wins anything.
 The technical hitch device allows us to manipulate the stagesetting independently of the plays of the first and second player.
 According to our explanation, the first players prehitch choice provides the context against which the subsequent events are interpreted.
 Either of the posthitch events is an initial candidate for mutability.
 Reasoners compute the similarity of the events to the context: each of the posthitch events share some properties with the context and differ from it on others  the first event shares the same player with the context, but differs in the colour of the card drawn; the second event shares the colour of the card drawn with the context, but differs in the identity of the player (and for simplicity, we assume that the player and the colour of the card drawn are equally salient).
 Because the events are both dissimilar from the context, either one is mutable.
 W e predict that the temporality effect will be eliminated for this sort of scenario.
 In the next section w e report computational and experimental evidence in support of this view.
 The Production of Imaginary Models W e have written a computer program in LISP to simulate the cognitive processes that w e suggest reasoners rely on when they think counterfactually, in the colourcard task described in 4 earlier.
 The program is called I M P (for Imaginary Models Production), and it generates imaginary scenarios.
 It identifies the most mutable event by comparing the events to the context, and it undoes the event by calibrating it to the context.
 The program takes as input a list of assertions of the following sort: 5.
 Jones picked black There was a technical hitch Jones picked black Brady picked red It produces as output a set of models of the actual situation: 6.
 Jones black / Jones black Brady red where the symbol"/" is a languagelike tag corresponding to a technical hitch (see JohnsonLaird and Byrne, 1991, for comments on the use of propositional tags in models).
 It also produces a set of models corresponding to the counterfactual situation constructed by mutating the most mutable event: 7.
 Jones black / Jones black Brady black The core of the program lies in a suite of mutability functions that identify the most mutable event by comparing it to the context event, and a suite of undoing functions that construct a counterfactual scenario by calibrating the most mutable event to the context.
 The main computation carried out by the mutability procedures is a comparison of each of the events with the context.
 Each event is compared with the context in terms of whether they share a c o m m o n actor and whether they share a c o m m o n card colour.
 The most mutable event is selected according to the following two principles: if one event is identical to the context, the other event is the most mutable; whereas if both events are dissimilar from the context they are both mutable (for further details, see Byrne, Culhane, and Tasso, 1995).
 For example, when the program is given the sentences in 5 earlier, it identifies the second event, in which Brady picked red, as the most mutable.
 Each of the two events is compared to the context: the first event is identical to the context and so it is immutable, the second event differs from the context and so it is the most mutable.
 The main computation carried out by the undoing procedures is a comparison of the most mutable event to the context in order to alter it according to the following two principles: if they differ in the colour of the card picked (and so the actual scenario must be one in which the players lost), the most mutable event is made the same as the context in this respect (so that the counterfactual scenario is of a winning game); otherwise (the actual scenario is one in which the players won), the most mutable event is made different from the context (so that the counterfactual scenario is of a losing game).
 For example, the program produces a counterfactual scenario in which Brady picked black instead of red for the sentences in 5 earlier.
 It compares the colour of the card that Brady picked in the game with the colour of the card in the context event and because they differ, it changes Brady's choice to be the same as the context.
 The program is designed to simulate the known effects of temporal order on counterfactual mutations.
 It produces the temporal order effect when it is given sentences in which there is no technical hitch: it identifies the first event as being the context, as well as being the first target event.
 It implements our ideas on the mental representations and cognitive processes that lead to the effects of temporality on mutability.
 The theory embodied in the computer program makes predictions about a variety of situations in which the temporality effect will occur and situations in which it will be eliminated.
 The program simulates these effects and w e have corroborated the predictions empirically as w e will now outline.
 Contextualized Models a n d T e m p o r a l Mutability W e have carried out a series of experiments to test the role of contextualized representations in temporal mutability and w e report the results of two experiments here.
 The first experiment was designed to test two alternative explanations of the role of temporahty in the mutability of events.
 Our suggested explanation emphasises the nature of the mental representations that reasoners construct: the earlier event provides the context against which the subsequent events are interpreted, and so the earlier event is not available for 387 mutation.
 The contextualizing role of the first event can be separated from its temporal position in the sequence by the 'technical hitch' scenario described earlier.
 W e predict that the temporality effect will occur when the first target (posthitch) event is the same as the context (prehitch) event (i.
e.
, Jones draws black on each occasion), and we predict that the effect will be eliminated when the first target event is different from the context event (i.
e.
, Jones draws black prior to the hitch, and draws red the next time).
 W e compared our explanation to an alternative one.
 An alternative possibility is that the more recent event is "fresh" in mind: it is encountered first in a backward search through the entries to the representation.
 Such a lastin, firstout principle may operate because of working memory constraints.
 A different set of predictions follows from this view.
 The second event is the more recent one in both of the technical hitch scenarios, regardless of the similarity or dissimilarity of the first target event to the context event, and so the temporality effect should be observed in each version.
 W e tested these alternative explanations in an experiment in which 75 undergraduate students from various departments in Trinity College, University of Dublin participated voluntarily.
 W e gave the differentcontext version of the scenario described in 4 earlier to a group of 36 subjects: In this version, Jones draws black prior to the hitch, and he draws red after the hitch is resolved; Brady draws black.
 W e gave the samecontext version to another group of 39 subjects: In this version Jones draws black prior to the hitch, and he draws black after the hitch is resolved; Brady draws red.
 The subjects completed the sentence "Jones and Brady could each have won £10(X) if only one of them had picked a different card, for instance if.
.
.
" They also answered two questions about who they would predict would experience more guilt, and who will blame the other more.
 W e expected that their beliefs about the players emotions would correspond to their beliefs about the mutability of the individuals.
 The results corroborated our proposal that the temporality effects arise because the first event provides the context against which the subsequent events are interpreted (see Byrne, et al, 1995, for details).
 As Table 1 shows, in the samecontext condition more subjects undid the second event overall (59%)' rather than the first (23%); whereas in the differentcontext condition the effect was eliminated (44% versus 4 2 % ) and this interaction is reliable [Meddis (1984) quicktest z' (n = 63) = 1.
64, p < 0.
05].
 W e found a similar pattern of results for the answers to the questions about emotions.
 More subjects attributed guilt to the second player than to the first in the samecontext version (77% versus 10%), but not in the differentcontext version [44% versus 3 1 % ; Meddis quicktest z' (n = 61) = 2.
59, p < 0.
01].
 More subjects considered that the first player would blame the other more than the second in the samecontext version ( 5 1 % versus 1 3 % ) ; unexpectedly, more subjects also ' The percentages are based on a combined score, e.
g.
, 5 9 % is based on the undoings of the second event only (i.
e.
, "if Brady drew black") combined with the undoings of the second event followed by the first event (i.
e.
, "if Brady drew black or Jones drew red")  see Byrne, et al (1995).
 The pattern of results remains essentially the same when the analysis is based on the former alone.
 considered the first player to blame the other more in the differentcontext version [ 5 0 % versus 2 5 % ; Meddis quicktest z (n = 52) = 1.
07, p = nonsignificant], [However, in a subsequent experiment based on related materials, the elimination of the temporality effect was observed for questions about both guilt and blame, as well as for the sentence completion task (see Byrne et al, 1995)].
 The experiment shows that the temporality effect arises because of the contextualizing role of the first event in the construction of a mental representation, and it is eliminated when the context is decoupled from the serial position of the event.
 The results go against the alternative explanation that the temporal order effect arises because of the recency of the second event's entry into the representation.
 The results lend support to our suggestion that reasoners construct minimal models that are based on a solid foundation, the cornerstone laid by the earlier events in a sequence.
 Table 1: The percentages of mutations of the first event and the second in Experiment 1.
 Context Undoing Second First Guilt Second First Blame Second First Same Black.
.
hitch; Black.
.
Red 59 23 77 10 13 51 Different Black.
.
hitch; Red.
.
Black 44 42 44 31 25 50 T e m p o r a l IMutability a n d G o o d O u t c o m e s Previous research has shown that various phenomena, such as the tendency to mutate exceptional events rather than normal ones, occur as readily for undoing positive outcomes as for negative ones (see also Landman, 1987; Johnson, 1986).
 Counterfactual thinking is not only for learning from mistakes but also for learning from our good fortunes.
 Our aim in the next experiment was to provide the first test of whether temporality affects situations of good fortune as well as situations of bad fortune.
 W e relied on a scenario similar to that in the first experiment, but in this version, the individuals won.
 W e predict that the temporality effect will be observed with situations of good fortune: according to our view reasoners compare the two target events to the context in terms of the similarity of both the actor and the colour of the card drawn.
 For example, in one of the scenarios in the experiment, Jones draws red prior to the hitch, and he draws 388 red after the hitch is resolved; Brady draws red.
 The first event is identical to the context in both actor and card colour; the second event differs in terms of actor, and so it is more mutable.
 An alternative account makes a different prediction.
 A possible explanation for the temporality effect and its elimination in the previous experiment is that reasoners mutate the 'oddoneout' in a sequence.
 Reasoners undo whichever of the two target events is the oddoneout of the three events in terms of the colour of the card drawn, in other words cardcolour is the salient comparisonpoint in these scenarios.
 According to this view, of course, the temporality effect should only occur in situations where there is an oddoneout, and so there should be no temporality effect in situations where the individuals win (because the two target events contain the same colour card).
 Our first aim in the experiment was to test these two alternative explanations.
 O n the assumption that temporality would affect mutability in situations of good fortune, our second aim was to show that the temporality effect can be eliminated in the manner established in the previous experiment, when both target events differ from the context.
 W e tested these alternative explanations in an experiment in which 94 subjects from Trinity College, University of Dublin participated voluntarily.
 W e presented one group of 46 subjects with a scenario in which Jones draws red prior to the hitch, and he draws red after the hitch is resolved; Brady draws red.
 Thus, the outcome is that each individual wins £1000.
 W e gave a second group of 48 subjects a version of the story in which Jones draws black prior to the hitch, and he draws red after the hitch is resolved; Brady draws red.
 In this case both events are dissimilar from the context: the first event differs in the colour of the card, and the second event differs in both the colour of the card and the actor.
 W e expect that both events are mutable and so there should be no temporality effect.
 The subjects completed the following fragment: "After the draw both Jones and Brady reflected on how lucky they had been.
 After all, if one of them had picked a different card they might neither have won the £1000; for instance, if.
.
.
" They also answered the question "Who would you predict would experience more relief at having won — Jones or Brady?" Table 2: The percentages of mutations of the first event and the second in Experiment 2.
 Context Undoing Second First Relief Second First Same Red.
.
hitch; Red.
.
Red 59 26 59 35 Different Black.
hitch; Red.
.
Red 33 38 42 44 The results corroborated both our predictions, as Table 2 shows.
 In the samecontext condition more subjects undid the second event (59%) rather than the first (26%); whereas in the differentcontext condition the effect was eliminated 133% versus 3 8 % ; Meddis quicktest z' (n = 73) = 1.
9, p < 0.
05].
 More subjects attributed relief to the second player than to the first in the samecontext version (59% versus 35%), but not in the differentcontext version ( 4 2 % versus 4 4 % ) , although the interaction misses reliability [Meddis quicktest z (n= 84) = 1.
29, p = nonsignificant].
 The experiment shows that temporality affects mutability in situations of good fortune as well as situations of bad fortune.
 It corroborates our suggestion that reasoners compare the target events to the context event in terms of both the actor and the colour of the card, and not just in terms of the colour of the card, as the oddoneout explanation suggests.
 It also shows that the effect can be eliminated readily by decoupling the contextualizing role of the first event from its position in the sequence.
 Conclusions W e have outlined a theory of counterfactual thinking about what might have been that is based on the idea that reasoners construct a model of the actual situation and produce an imaginary alternative by making minimal mutations to it.
 Our theory suggests that the temporality effect on mutability — the tendency for people to undo the more recent event in a series of independent events — arises because of the nature of the mental representations that people construct.
 W e suggest that the first event in a sequence plays a contextualizing role, providing the cornerstone for the model, and so it is immutable.
 W e have implemented this theory in a computer program and w e have carried out several experiments that show that when the contextualizing role of the first event is separated from its position in the sequence of target events, the effect is eliminated.
 W e have corroborated our view that the mutability of events depends on cognitive mechanisms such as the contextualization of models for one sort of problem in this series of experiments.
 W e suggest that the influence of context in the construction of models of counterfactual scenarios may have implications for our understanding of the other primary phenomena of counterfactual thinking.
 Acknowledgements This research was supported by a grant from the Arts and Social Sciences Benefactions Fund of Trinity College, University of Dublin awarded to Ruth Byrne.
 W e are grateful to Mark Keane, Phil JohnsonLaird, and Susana SeguraVera for their help.
 References Bouts, P.
, Spears, R.
, and van der Plight, J.
 (1992).
 Counterfactual processing and the correspondence between events and outcomes.
 European Journal of Social Psychology, 22, 387396.
 Byrne, R.
M.
J.
 (1989a).
 Suppressing valid inferences with conditionals.
 Cognition, 31, 6183.
 389 Byrne, R.
M.
J.
 (1989b).
 Everyday reasoning with conditional sequences.
 Quarterly Journal of Experimental Psychology, 41 A, 141166.
 Byrne, R.
M.
J, and JohnsonLaird, P.
N.
 (1992).
 The spontaneous use of prepositional connectives.
 Quarterly Journal of Experimental Psychology, 44A, 89110.
 Byrne, R.
M.
J.
, Handley, S.
J.
, and JohnsonLaird, P.
N.
 (1995).
 Reasoning with suppositions.
 Quarterly Journal of Experimental Psychology.
 In press.
 Byrne, R.
M.
J, and Tasso, A.
 (1994).
 Counterfactual reasoning: inferences from hypothetical conditionals.
 In A.
 R a m and K.
 Eiselt (Eds).
 Proceedings of the sixteenth annual conference of the Cognitive Science Society.
 Hillsdale: Erlbaum.
 Byrne, R.
M.
J.
, Culhane, R.
 and Tasso, A.
 (1995).
 Cognitive Processes in Imaginary Thinking: Mutability and Temporality in Counterfactual Scenarios.
 Mimeo, Trinity College, University of Dublin, Ireland.
 Chisholm, R.
M.
 (1946).
 The contrarytofact conditional.
 Mind,LV, 289307.
 Gavanski, I.
 and Wells, G.
L.
 (1989).
 Counterfactual processing of normal and exceptional events.
 Journal of Experimental Social Psychology, 25, 314325.
 Ginsberg, M .
 L.
 (1986).
 Counterfactuals.
 Artificial Intelligence, 30, 35  79.
 Girotto, v.
, Legrenzi, P.
, and Rizzo, A.
 (1991).
 Event controllability in counterfactual thinking.
 Acta Psychologica, 78,111133.
 Goodman, N.
 (1973).
 Fact, Fiction and Forecast.
 Third Edition.
 N e w York: BobbsMerrill.
 Johnson, J.
 (1986).
 The knowledge of what might have been: affective and attributional consequences of near outcomes.
 Personality and Social Psychology Bulletin, 12,5162.
 JohnsonLaird, P.
N.
 and Byrne, R.
M.
J.
 (1991).
 Deduction.
 Hove, U K , and Hillsdale, N.
J.
: Erlbaum.
 Kahneman, D.
 and Miller, D.
 (1986).
 Norm theory: Comparing reality to its alternatives.
 Psychological Review, 93, 136153.
 Kahneman, D.
, and Tversky, A.
 (1982).
 The simulation heuristic.
 In D.
 Kahneman, P.
 Slovic, and A.
 Tversky (Eds.
), Judgement under uncertainty: heuristics and biases, (pp.
 201208).
 N e w York: Cambridge University Press.
 Landman, J.
 (1987).
 Regret and elation following action and inaction: affective responses to positive versus negative outcomes.
 Personality and Social Psychology Bulletin, 13,524536.
 Lewis, D.
 (1973).
 Counterfactuals.
 Oxford, Blackwell.
 Mackie, J.
L (1973).
 Truth, probability, and paradox.
 Oxford: Clarendon.
 Macrae, C.
 N.
 (1992).
 A tale of two curries: counterfactual thinking and accidentrelated judgements.
 Personality and Social Psychology Bulletin, 18, 8487.
 McGill, A.
L.
 and Klein, J.
G.
 (1993).
 Contrastive and counterfactual reasoning in causal judgement.
 Journal of Personality and Social Psychology, 64, 897905.
 Meddis, R.
 (1984).
 Statistics using ranks.
 Oxford: Basil Blackwell.
 Miller, D.
T.
 and Gunasegaram, S.
 (1990).
 Temporal order and the perceived mutability of events: implications for blame assignment.
 Journal of Personality and Social Psychology, 59, 1111 1118.
 Miller, D.
T.
 and McFarland, C.
 (1987).
 Counterfactual thinking and victim compensation: a test of norm theory.
 Personality and Social Psychology Bulletin, 12, 513519.
 Pollock, J.
L.
 (1986).
 Subjunctive Reasoning.
 Dordrecht: Reidel.
 Roese, N.
J.
 (1994).
 The functional basis of counterfactual thinking.
 Journal of Personality and Social Psychology, 66,805818.
 Skyrms, B.
 (1980).
 Causal Necessity.
 N e w haven: Yale University.
 Stalnaker, R.
 C.
 (1968).
 A theory of conditionals.
 In N.
 Rescher (Ed.
), Studies in logical theory.
 Oxford: Basil Blackwell.
 Wells, G.
L.
, and Gavanski, I.
 (1989).
 Mental simulation of causality.
 Journal of Personality and Social Psychology, 56, 161169.
 Wells, G.
L.
, Taylor, B.
R.
, and Turtle, J.
W.
 (1987).
 The undoing of scenarios.
 Journal of Personality and Social Psychology, 53,421430.
 390 Gestures Reveal Mental Models of Discrete and Continuous C h a n g e Martha Wagner Allbali Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 alibali@andrew.
emu.
edu Miriam Bassok Department of Psychology University of Chicago Chicago, Illinois 60637 mbmb@ccp.
spc.
uchicago.
edu Karen L.
 Olseth Department of Psychology University of Chicago Chicago, Illinois 60637 klol@inidway .
uchicago.
 edu Sharon Syc Department of Psychology Northeastern Illinois State University Chicago, Illinois 60625 Susan GoldinMeadow Department of Psychology University of Chicago Chicago, Illinois 60637 sgsgQmidway.
uchicago.
edu Abstract In studies of analogical transfer, subjects sometimes fail to recognize that problems are structurally isomorphic because of differences in the problems' content.
 One potential explanation for this finding is that differences in content lead subjects to infer that the problems have different structures.
 This interpretation would be supported by evidence that subjects construct differing mental models for structurally isomorphic problems.
 In this study, we show that subjects' gestures reveal their mental models of problems that involve discrete and continuous change.
 Four subjects talked out loud as they solved a set of four problems that involved constant change.
 All subjects produced gestures as they spoke, and their gestures revealed both continuous and discrete mental models of the manner of constant change.
 On problems constructed to evoke mental models of continuous change, subjects tended to produce gestures that incorporated smooth, continuous motions.
 On problems constructed to evoke mental models of discrete, incremental change, subjects tended to produce gestures that incorporated repeated, sequential, discrete motions.
 Subjects' gestures sometimes provided more explicit cues to their mental models than did their speech.
 The results indicate that subjects sometimes constructed differing mental models for structurally analogous problems.
 Introduction People often fail to recognize that a previously learned solution procedure can be used to solve a problem at hand.
 For example, in studies of analogical transfer, subjects sometimes fail to recognize that problems are structurally isomorphic because of differences in the content or "cover stories" of the problems (Gick & Holyoak, 1980; Holyoak & Koh, 1987).
 O n e potential explanation for this finding is that differences in content lead subjects to infer that the problems have different structures (Bassok & Olseth, 1995; Bassok, W u , & Olseth, 1995).
 This interpretation would be supported by evidence that subjects construct distinct mental models for structurally isomorphic problems.
 In this paper, w e describe a new method for gaining access to subjects' mental models of problems.
 This method involves examining the gestures that subjects spontaneously produce when they describe their reasoning about the problems.
 It is widely accepted that verbal protocols can provide an accurate and informative account of ongoing cognitive processes (Ericsson & Simon, 1993).
 A s w e report in this paper, when subjects provide such protocols, they often gesture spontaneously as they speak.
 In recent years, several investigators have claimed that, like speech, spontaneous gestures are a window through which speakers' mental processes can be viewed (GolditiMeadow, Alibali, & Church, 1993; Kendon, 1980; McNeUI, 1985; McNeill, 1992).
 Such studies have shown that, much of the time, the information that speakers express in gesftires is identical to the information they express in speech.
 W h e n gestures match speech in this way, they can provide additional validation for claims made on the basis of subjects' speech.
 At other times, however, the information that speakers express in gestures differs from the information they express in speech (Church & GoldinMeadow, 1986; McNeUl, 1992; Perry, Church, & GoldinMeadow, 1988).
 W h e n gestures mismatch or supplement speech, they can provide information about cognitive processes that speakers do not verbalize.
 If gestures do in fact yield evidence about subjects' mental models of problems, this evidence m a y actually be more compelhng than evidence gleaned from verbal protocols.
 This is because, when problems are presented in words, the 391 mailto:alibali@andrew.
emu.
edumailto:mbmb@ccp.
spc.
uchicago.
eduwords of the text can influence the words subjects use when describing suid solving the problems in speech.
 Spontaneous gestures, in contrast, are not "modeled" for subjects when a problem is presented as text.
 Thus, if subjects' gestures reveal mental models, they will provide compelling evidence that subjects have actively constructed such models.
 There is reason to believe that a study of the spontiuieous gestures subjects produce during verbal protocols will indeed be fruitful.
 Previous studies have shown that most people spontaneously gesture when they explain their reasoning about a problem.
 Moreover, gestures pnxluced during problem explanations typically convey specific aspects of the problems being explained, or specific strategies for solving those problems.
 Such substantive gestures have been observed in a variety of age groups and on a variety of tasks.
 These include preschoolers and elementary school children reasoning about counting tasks (Graham, 1994), Piagetian conservation tasks (Church & GoldinMeadow, 1986), mathematical equivalence problems (Alibali & GoldinMeadow, 1993; Perry, et al.
, 1988), and seasonal change problems (Crowder & Newman, 1993); adolescents reasoning about Piagetian bending rods tasks (Stone.
 Webb, & Mahootian, 1991); adults reasoning about problems involving gears (Perry & Elder, 1995); and subjects of many age groups reasoning about moral dilemmas (Church, SchonertReichl, Goodman, Kelly, & AymanNolley, 1995; Goodman, Church, & Schonert, 1991).
 Thus, gesture has proven to be a valuable tool for studying cognitive processes at a variety of developmental stages, and in a variety of domains.
 In the present study, we examined the gestures that adult subjects spontaneously produced when solving word problems that involve constant change (e.
g.
, changes in speed or rate of population growth).
 Bassok and Olseth (1995) have argued that, when solving constant change problems, subjects construct mental models of the manner in which the entity in the problem changes (i.
e.
, continuously or discretely).
 They taught subjects a procedure for solving a problem in which an entity changed either continuously (e.
g.
, speed) or discretely (e.
g.
, monthly investments in a savings account).
 Subjects then attempted to solve analogous transfer problems in which the manner of change differed.
 Subjects frequently and spontaneously transferred solution procedures learned for discrete change problems to continuous change problems; however, they rarely transferred solution procedures learned for continuous change problems to discrete change problems.
 Based on these patterns of transfer, Bassok and Olseth argued that subjects constructed differing mental models of the process of change for discrete and continuous problems.
 The present study seeks to establish a new and more direct method for assessing the mental models that subjects construct when solving problems that involve constant change.
 The goal of the study was to investigate whether subjects' spontaneous gestures provide direct evidence that they construct different mental models for problems involving discrete and continuous change.
 Method Participants Participants were four University of Chicago students, 2 males and 2 females.
 All were native English speakers.
 Each was paid $6 for participating.
 Procedure Each subject solved a set of four structurally isomorphic word problems that involved constant change (see Table 1).
 The set consisted of two problems that were constructed to evoke models of continuous change (Continuous problems), and two that were constructed to evoke models of discrete change (Discrete problems).
 Each subject was presented with the word problems on paper, one at a time.
 For each problem, the subject was asked to read the problem aloud, and then to talk out loud as he or she solved the problem.
 The session was videotaped so that subjects' verbal protocols and gestures could later be analyzed.
 Table 1 Problems Used in the Study Continuous Problems It takes 35 minutes to inflate a hot air balloon.
 The rate at which the hot air is pressed into the balloon increases steadily from 10 liters/minute at the beginning of the first minute to 80 liters/minute at the end of the 35th minute.
 H o w many liters of hot air are pressed into the balloon over the 35 minute period? The speed of an airplane inaeases at a constant rate during a period of 12 minutes from 10 miles/minute to 34 miles/minute.
 What distance, in miles, will the plane travel during the 12 minute period? Discrete Problems A bookcase has 6 shelves.
 The number of books on each successive shelf from top to bottom increases by a constant from the number of books on the shelf above it.
 If there are 15 books on the top shelf and 45 books on the bottom shelf, how many books total are in the bookcase? For a lecture, 10 rows of chairs have been arranged in a lecture hall.
 The chairs have been set up such that the number of chairs in each row increases by a constant from the number of chairs in the previous row.
 If there are 25 chairs in the first row and 115 chairs in the 10th row, how many chairs total are there in the lecture hall? Coding Each subject's verbal protocol was broken into clauses.
 Each clause of the verbal protocol and each spontaneous gesture were coded as described in the following sections.
 392 For clauses that were accompanied by gestures, the relationship between gesture and speech was evaluated.
 Coding speech.
 Each verbal clause was coded in terms ol whether it indicated a specific manner of change, iind il so, which type.
 Thus, each clause was classified as providing cues for a Continuous model, a Discrete model, or Neither model.
 The following verbal cues were taken as evidence of a Continuous mental model: (1) mention of the values in the problem using ratelike units; (2) reference to the entire period of time involved in the problem; (3) references to averaging and/or multiplying; (4) explicit references to rates.
 The following verbal cues were taken as evidence of a Discrete mental model: (1) mention of the values in the problem using amountlike units; (2) reference to the individual units of time involved in the problem; (3) references to dividing and/or repeated addition; (4) explicit references to "the constant".
 Note that many of these verbal cues are also present in the problem texts.
 Coding criteria and examples are presented in Table 2.
 Table 2 Coding Categories and Examples Speech Codes Continuous Discrete "It started at 10 liters per "At fu^t there were 10 liters" minute" "Over the 12minute period.
.
.
" "In each of the 12 minutes.
.
.
" "The average is 70, times 10 "90 divided by 9 is 10, so rows" you have to keep adding 10" "The number of books was "The constant was 6" going up at a constant rate" Gesture Codes Continuous Discrete Right hand palm arcs Right hand point, taps table smoothly upward in neutral four times, moving left to space in front of subject.
 right.
 Right hand point sweeps Right hand palm makes diagonally across table top three short hops extending away from self from self into neutral space.
 Coding gesture.
 The stream of manual movement was broken down into individual gestures using criteria developed in previous work (Church & GoldinMeadow, 1986).
 The h;indshape, motion, hand placement, and hand orientation used in each gesture were uiuiscribed without access to the audio portion of the tape (i.
e.
.
 with the sound turned off).
 Each gesture w;is then cUissified as conveying a Continuous model, a Discrete model, or Neither model.
 Gestures that incorponaed a smooth, continuous motion (e.
g.
, sweeping.
 arcing, dragging, sliding or lifting) were coded as Continuous.
 Gestures that incorporated a sequence of discrete movements (e.
g.
, a sequence of at least 3 hops, taps, points, traces, beats, wrist rotations, or finger extensions) were coded as Discrete.
 Gestures that incorporated a zigzagging or spirsding motion that moved out from the body were also coded as Discrete.
 All other gestures were coded as indicating Neither model.
 These included simple beat (accent or emphasis) gestures, points, flicks, gestures that traced numbers on the table or in the air, and iconic (representational) gestures that did not convey the manner of change (e.
g.
, gestures that depicted the range of values in a problem by indicating two locations in space).
 Examples of gestures that convey Continuous and Discrete models are presented in Table 2.
 Coding the relationship between gesture and speech.
 For clauses that included both speech and gesture, and that conveyed a model in at least one of the two modalities, the relationship between gesture and speech was identified.
 This relationship was classified as one of four types: (1) SpeechGesture Match, in which speech and gesture provide cues for the same model, (2) Speech Explicit, in which speech provided a cue for one of the models, but gesture did not, (3) Gesture Explicit, in which gesture provided a cue for one of the models, but speech did not, and (4) SpeechGesture Mismatch, in which speech and gesture provided cues for different models.
 Results Did subjects gesture when they described how they solved the problems? W e fu^t examined whether subjects produced gestures along with their verbal protocols.
 Indeed, all four subjects gestured on every one of the four problems.
 Subjects varied in how much they spoke, and in how often they produced gestures as well as speech.
 The total number of clauses subjects produced across the four problems ranged from 88 to 145 (M=124, SD=26.
5), and the raw number of gestures produced ranged from 28 to 93 (M=56, SD=27.
4).
 Subjects produced gestures as well as speech in an average of 4 4 % of all clauses (range 3 2 % to 6 4 % , S D = 1 4 % ) .
 Did subjects' speech convey continuous and discrete mental models of change? Next, we examined whether subjects' verbal protocols provided cues for distinct continuous and discrete mental models of the process of change.
 W e isolated the verbal clauses that were "marked" in the sense that speech conveyed a cue for one of the two models.
 W e then examined whether subjects tended to use clauses marked by Discrete cues most often on the Discrete problems, and clauses marked by Continuous cues most often on the Continuous problems.
 Recall that the problem texts provided many such verbal cues.
 As seen in Table 3, Panel A.
 subjects produced more clauses marked by Discrete cues than by Continuous cues when solving the Discrete problems.
 All four subjects followed the expected pattern, and the pattern differed 393 significantly f m m chance performance (i(3)>10.
0, p<0.
001).
 Subjects also produced more clauses marked by Continuous cues than by Discrete cues when solving the Continuous problems, as seen in Panel B.
 Three of the four subjects showed the predicted pattern.
 The remaining subject (TM) produced predominantly clauses marked by Discrete cues, suggesting that she had constructed a discrete mental model for the continuous problems.
 Because T M showed a pattern opposite from the other subjects, the trend toward greater use of clauses marked by Continuous cues on the Continuous problems did not attain significance (t(3)=2.
14, 0.
05<p<0.
10, onetailed).
 s\i\)m.
 Table 3 Proportion of Marked Clauses that Contained Cues for Each Model Continuous A: Discrete Problems TM CF SW GC Mean Proportion 0.
03 0.
00 0.
04 0.
00 0.
02 B: Continuous Problems TM CF SW GC Mean Proportion 0.
36 1.
00 1.
00 0.
75 0.
78 Discrete 0.
97 1.
00 0.
96 1.
00 0.
98 0.
64 0.
00 0.
00 0.
25 0.
22 N (Marked Clauses) 35 30 26 16 22 19 21 16 Did subjects' gestures convey continuous and discrete mental models of change? Next, we examined whether, like their speech, subjects' gestures also provided evidence for distinct continuous and discrete mental models of the process of change.
 Over the set of four problems, every one of the four subjects produced some gestures that conveyed each model.
 O n average, 1 0 % of each subject's total corpus of gestures conveyed a Continuous model (range 4 % to 20%) and 1 9 % of each subject's gestures conveyed a Discrete model (range 9 % to 32%).
 The remaining gestures conveyed Neither model.
 We isolated the gestures that were "marked" in the sense that they conveyed a cue for one of the two models.
 W e then examined whether subjects tended to use Discrete gestures most often on Discrete problems, and Continuous gestures most often on Continuous problems.
 As seen in Table 4, Panel A, subjects were indeed more likely to produce Discrete gestures when solving the Discrete problems.
 All four subjects followed the predicted pattern.
 Even given the small sample size, the pattern differed significantly from chance (t(3)=9.
76, I2<0.
001, onetailed).
 Subjects were also more likely to produce Continuous gestures when solving the Continuous problems, as seen in Panel B.
 Indeed, three of the four subjects produced absolutely no Discrete gestures when solving the Continuous problems.
 The remaining subject (TM) produced predominantly Discrete gestures.
 Thus, like her speech, TM's gestures indicate that she constructed a discrete mental model for the continuous problems.
 In fact, ha gestures reveal the pattern more strongly than her speech.
 Because TM's pattern differed from the other subjects, the trend toward greater use of Continuous gestures for the Continuous problems did not attain significance (t(3)=1.
27, .
05<p<0.
15, onetailed).
 Subject Table 4 Proportion of Marked Gestures that Conveyed Each Model Cpntinypi Gestures A: Discrete F*roblems TM CF SW GC Mean Proportion 0.
12 0.
17 0.
27 0.
17 0.
18 B: Continuous Problems TM CF SW GC Mean Proportion 0.
12 1.
00 1.
00 1.
00 0.
78 js Discrete Gestures 0.
88 0.
83 0.
73 0.
83 0.
82 0.
88 0.
00 0.
00 0.
00 0.
22 N (Marked Gestures) 17 6 11 6 17 1 6 3 W e also examined whether individual subjects differentiated between the two types of problems in their gestures.
 As noted, subject T M did not systematically differentiate between the two types of problems; she appeared to represent both problems as involving discrete change.
 Subject S W , in contrast, tended to produce Continuous gestures on Continuous problems, and Discrete gestures on Discrete problems (x2=8.
24, p<.
001).
 The remaining two subjects also showed the predicted pattern, but produced too few gestures to analyze at the individual level.
 394 Did speech and gesture always convey the s a m e mental model? Next, we examined whether subjects tended to convey tlic same mental model in speech and in the accoinpimying gesture.
 Studies of children's cognitive development hiive shown that, during transitional periods in the process of acquiring concepts, children often express one strategy for solving a problem in speech, and a second strategy in the accompanying gesture (Alibali & GoldinMeadow, 1993; Church & GoldinMeadow, 1986; Perry, et al.
, 1988).
 Thus, when children consider multiple (potentially conflicting) strategies for solving problems, their speech and gestures often mismatch.
 W e hypothesized that the adult subjects in our study might also sometimes consider multiple models for a given problem.
 Like the children in the studies described above, they might also produce gesturespeech mismatches when solving constant change problems.
 Alternatively, their gestures could provide evidence for a particular model when the accompanying speech did not.
 Finally, subjects' gestures could provide converging evidence for the model indicated in the accompanying speech.
 Table 5 Relationship Between Speech and Gesture Subject & Problem Type TM C D CF C D SW c D GC C D Match Speech Explicit 0.
27 0.
40 0.
30 0.
48 0.
50 0.
50 0.
19 0.
77 0.
50 0.
00 0.
38 0.
48 0.
11 0.
67 0.
50 0.
00 Gesture Explicit 0.
23 0.
21 0.
00 0.
04 0.
50 0.
05 0.
22 0.
50 C=Continuous, D=Discrete Mismatch 0.
10 0.
00 0.
00 0.
00 0.
00 0.
10 0.
00 0.
00 N 30 33 2 26 6 21 9 6 To explore these possibilities, w e identified the relationship between speech and gesture in all clauses in which at least one modality (i.
e.
, eidier speech or gesture or both) provided a cue for one of the models.
 As seen in Table 5, subjects produced very few clauses in which speech conveyed one model and gesture conveyed the other (Mismatch responses).
 However, clauses in which gesture explicitly conveyed one of the models while speech conveyed no model were relatively frequent.
 Individuals differed in how frequently they produced such Gesture Explicit clauses: one subject produced almost none, while others produced them quite regularly.
 T w o of the subjects (SW and G C ) firequently produced such clauses for one problem type and not the other.
 Most interesting, on problems where these subjects frequently produced Gesture Explicit clauses, they never produced Speech Explicit clauses.
 This opens the possibility that for some individuals, mental models of some problem types may be more readily accessible to gesture than to speech.
 Alternatively, speakers may choose to express certain aspects of their mental models in speech, and other aspects in spontaneous gestures.
 It is also worth noting that gesture often provided converging evidence for the mental model cued in the accompanying speech (i.
e.
, in Match responses).
 In these responses, gesture provides independent verification that the subject is not simply mimicking the verbal cues provided in the problem text, but has actively constructed the model expressed in speech.
 Discussion This study has shown that subjects' spontaneous gestures can reveal their mental models of discrete and continuous change.
 All four of the subjects studied gestured as they solved constant change problems, and their gestures revealed both continuous and discrete mental models of the manner of constant change.
 O n problems constructed to evoke mental models of continuous change, subjects tended to produce gestures that incorporated smooth, continuous motions, while on problems constructed to evoke mental models of discrete, incremental change, subjects tended to produce gesture that incorporated repeated, sequential, discrete motions.
 Most important, subjects' gestures sometimes provided more explicit cues to their mental models than did their speech.
 These results demonsti^te that, in this domain as well as others, gesture can be a compelling source of data about ongoing cognitive processes.
 These results also have implications for theories of analogical transfer.
 Such theories offer two different explanations for the finding that subjects sometimes fail to recognize that a previously learned solution procedure can be used to solve a problem at hand.
 The traditional account, sometimes called the interference account, holds that problem content interferes with subjects' ability to recognize that two problems share the same structure (Genmer, 1983, 1989; Gick & Holyoak, 1980).
 According to this view, subjects fail to transfer a solution procedure because they fail to recognize that the base and target problems are structurally the same.
 The interpretative account, in contrast, holds that differences in content lead subjects to infer that the problems have different stiuctures (Bassok & Olseth, 1995).
 According to this view, subjects fail to transfer because they actively construct different mental models for the base and target problems.
 The two accounts differ crucially in terms of the processes they impute to problem solvers: The interference account holds that subjects simply do not recognize structural similarities, while die interpretative account holds that subjects actively construct differing mental models for isomorphic problems.
 In this study, subjects' spontaneous gestures revealed that they had constructed different continuous and discrete models for sttiJCturally isomorphic constant change problems.
 Thus, these results support the claim that subjects actively 395 construct different mental models for different types of problems.
 These findings suggest that the mental representations that subjects actively construct may indeed inhibit them from transferring solution procedures to analogous problems.
 In this way, evidence from gesture supports the interpretative explanation for the failure of analogical transfer.
 Acknowledgments This research was supported by a University of Chicago Social Sciences Divisional Research Grant to Miriam Bassok, and by a grant from the Spencer Foundation to Susan GoldinMeadow.
 W e thank Michael Kang for assistance transcribing the videotapes.
 R e f e r e n c e s Alibali, M.
 W.
, & GoldinMeadow, S.
 (1993).
 Transitions in learning: What the hands reveal about a child's state of mind.
 Cognitive Psychology, 25, 468523.
 Bassok, M.
, & Olseth, K.
 L.
 (1995).
 Objectbased representations: Transfer between cases of continuous and discrete models of change.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, in press.
 Bassok, M.
, W u , L.
L.
, & Olseth, K.
 L.
 (1995).
 Judging a book by its cover: Interpretative effects of content on problemsolving transfer.
 Memory & Cognition (in press).
 Church, R.
 B.
, SchonertReichl, K.
, Goodman, N.
, Kelly, S.
 D.
, & AymanNoUey, S.
 (1995).
 The role of gesture and speech communication as reflections of cognitive understanding.
 Journal of Contemporary Legal Issues, in press.
 Church, R.
 B.
, & GoldinMeadow, S.
 (1986).
 The mismatch between gesture and speech as an index of transitional knowledge.
 Cognition, 23, 4371.
 Crowder, E.
 M.
, & Newman, D.
 (1993).
 Telling what they know: The role of gesmre and language in children's science explanations.
 Pragmatics and Cognition, 1, 341376.
 Ericsson, K.
 A.
, & Simon, H.
 A.
 (1993).
 Protocol analysis: Verbal reports as data.
 Cambridge, M A : M I T Press.
 Gentner, D.
 (1983).
 Structuremapping: A theoretical framework for analogy.
 Cognitive Science, 1, 155170.
 Gentner, D.
 (1989).
 The mechanisms of analogical reasoning.
 In S.
 Vosniadou & A.
 Ortony (Eds.
) Similarity and analogical reasoning (pp.
 199241).
 Cambridge: Cambridge University Press.
 Gick, M .
 L.
, & Holyoak, K.
 J.
 (1980).
 Analogical problem solving.
 Cognitive Psychology, 12, 306355.
 GoldinMeadow, S.
, Alibali, M .
 W.
, & Church, R.
 B.
 (1993).
 Transitions in concept acquisition: Using the hand to read the mind.
 Psychological Review, 100(2), 279297.
 Goodman, N.
, Church, R.
 B.
, & Schonert, K.
 (1991).
 Moral development and gesture: What can the hands reveal about moral reasoning? Paper presented at the annual meeting of the Jean Piaget Society, Philadelphia, PA.
 Graham, T.
 A.
 (1994).
 The role of gesture in learning to count.
 Paper presented at the annual meeting of the Jean Piaget Society, Chicago, Illinois.
 Holyoak, K.
 J.
, & Koh, K.
 (1987).
 Surface and structural similarity in analogical transfer.
 Memory and Cognition, 15, 332340.
 Kendon, A.
 (1980).
 Gesticulation and speech: Two aspects of the process of utterance.
 In M.
 R.
 Key (Ed.
), Relationship of verbal and nonverbal communication (pp.
 207228).
 The Hague: Mouton.
 McNeill, D.
 (1985).
 So you think gestures are nonverbal? Psychological Review, 92, 350371.
 McNeill, D.
 (1992).
 Hand and mind.
 University of Chicago Press.
 Perry, M.
, Church, R.
 B.
, & GoldinMeadow, S.
 (1988).
 Transitional knowledge in the acquisition of concepts.
 Cognitive Development, 3, 359400.
 Perry, M.
, & Elder, A.
 D.
 (1995).
 Knowledge in transition: Adults' developing understanding of a principle of physical causality.
 Under review.
 Stone, A.
, Webb, R.
, & Mahootian, S.
 (1991).
 The generality of gesturespeech mismatch as an index of transitional knowledge: Evidence from a controlofvariables task.
 Cognitive Development, 6, 301313.
 396 A Cognitive Analysis of the T a s k D e m a n d s of Early Algebra Hermina J.
 M .
 Tabachneck HCI Institute School of Computer Science Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213 tabachneckicmu.
edu Kenneth R.
 Koedinger HCI Institute School of Computer Science Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, PA 15213 koedinger@cmu.
edu Mitchell J.
 Nathan Learning Technology Center Vanderbilt University Box 45 Peabody Nashville TN 37203 natharunj @ctrvax.
 vanderbilt.
edu Abstract Mathematical problems presenting themselves in the workplace and in academia are often solved by informal strategies in addition to or instead of the normative formal strategies typically taught in school.
 By itself this observation does little to tell us whether, when and how much these techniques should be taught.
 To ground arguments about the appropriate role of altemative problemsolving techniques in education, we need to first understand the demands of the tasks they address.
 Our focus here is on algebra and prealgebra, or, more specifically, on the set of problems that resist solution by more elementary arithmetic methods.
 W e present a task analysis of this set of problems that is based on the identification of mathematical and situational problem difficulty factors.
 These factors provide a framework for comparing the candidate representations and strategies to meet the demands of more complex problems.
 W e summarize the altemative techniques that have been observed in effective problem solving and discuss their relative strengths and weaknesses.
 The task analysis along with this comparative analysis provides a basis for hypothesizing developmental sequences and for informing instmctional design.
 Rethinking Normative Algebra Human reasoning has often been shown to exhibit certain biases that seem irrational when compared with normative standards (e.
g.
, Kahneman & Tversky, 1973; Wason & JohnsonLaird, 1972).
 However, reasoning approaches that appear irrational in the context of a narrow set of tasks and norms can turn out to be quite rational when understood within the context of the broader set of task demands to which they are adapted (Anderson, 1990, p.
 35 and Polk, 1992 provide such responses respectively to the examples above).
 For reasoning domains that are taught in school, like mathematics, it is rational, at least at first blush, to take the schooled strategies as normative.
 However, there is much current activity among educators and cognitive scientists in rethinking school objectives, particularly in mathematics ( N C T M , 1989).
 Many of these efforts have been driven by the empirical observation that people often effectively solve mathematical problems using means other than the schooltaught approaches (e.
g.
, Carraher, Carraher, & Schlieman, 1987; Hall, Kibler, Wenger, and Truxaw, 1989; Resnick, 1987).
 Nevertheless, there are also strong advocates for an emphasis on basic formal skills (e.
g.
.
 Geary, 1995).
 To put this debate on more solid footing, what is needed is an analysis of the task demands for mathematical problem solving and an analysis of the role of both formal and informal approaches in meeting these demands.
 W e have performed a task analysis with the following objectives: 1) to characterize the scope of the task environment and identify the task demands placed on a mathematics problem solver; 2) to present a comparative analysis of the features of the available problemsolving representations and strategies for meeting these demands; and 3) to discuss the implications of this work for specifying a developmental model of mathematical competency that can inform instructional design.
 This analysis is targeted at algebra and prealgebra level math.
 Scope of the Investigation The objectives of mathematics instruction beyond arithmetic are largely twofold; (1) to further develop and refine students' mathematical problemsolving capabilities for everyday life and (2) to prepare students for further studies, particularly in the mathematical sciences.
 There is an apparent conflict between the symbolic focus of academic math and the recognition that informal nonsymbolic methods are used frequently out of school.
 However, this dichotomy is more apparent than real.
 Symbolic methods can improve workplace effectiveness and informal methods have always been a part of effective academic science.
 The recognition that techniques besides symbolic algebra are effective does little to tell us whether, when and how much these techniques should be taught.
 W e need a broader conception of algebra, but also we need a basis for making decisions like these.
 W e need to know what these alternative techniques are good for and what are their limitations.
 To start such an investigation, we need to understand what environmental demands these strategies meet.
 One might characterize these demands as just those tasks that symbolic algebra was designed to address.
 But using "algebra" in this characterization is circular and overconstrained.
 Instead, we characterize the scope of the task environment as those tasks for which arithmetic techniques are inadequate or unacceptably inefficient.
 What problems are beyond the reach of arithmetic techniques depends both on the achievement level of the solver and on the particulars of the problem.
 W e can, 397 mailto:koedinger@cmu.
eduhowever, characterize the difficulty factors that stretch the limits of arithmetic effectiveness and thus, provide likely features for estimating when more advanced methods may be appropriate.
 Tax Paid INFER Tax rate = 6% GIVEN Taxable Income INFER Effective tax rate = 5% GIVEN Income "NKNDWN Amount untaxed = $10,000 Figure 1: Directed quantitative network for problem PO Task D e m a n d s of Early Algebra In analyzing the task of mathematical problem solving it is useful to distinguish between "the quantitative structure of related mathematical entities and the situational structure of related physical entities within a problem" (Hall, et al.
, 1989, p.
 227).
 Before discussing difficulty factors related to quantitative and situational structure, we begin by presenting a scheme for aiding the analysis.
 Directed Quantitative Networks We use a modified "quantitative network" representation (cf.
 Hall, et al.
, 1989; Shalin & Bee, 1985) as an analytic tool for summarizing and clarifying our investigation.
 Figure 1 shows a directed quantitative network for the following problem': PO.
 One plan for a state income tax requires those persons with income of $10,000 or less to pay no tax and those persons with income greater than $10,000 to pay a tax of 6 percent only on the part of their income that exceeds $10,000.
 A person's effective tax rate is defined as the percent of total income that is paid in tax.
 Based on this definition, could any person's effective tax rate be 5 percent? The network in Figure 1 shows one way in which the underlying quantities and arithmetic constraints in this problem can be represented.
 Quantities are represented as nodes and constraints as 3part directed relations where the 1A problem from the 1992 NAEP for which only 3% of US twelve graders provided a satisfactory solution and explanation (NAEP, 1993).
 quantity at the arrow is the output and the other two quantities are inputs that are combined with the arithmetic operation to produce the output.
 For example, the constraint at the top has Taxrate and Taxableincome as inputs and Taxpaid as the output computed by multiplying the inputs.
 Some constraints and quantities are explicitly mentioned in a problem, while others (e.
g.
 Taxable income) are implied.
 Some Quantitative Factors ResultUnknown vs.
 StartUnknown Problems Literature on elementary word problem solving shows that problem difficulty is strongly affected by the position of the unknown quantity within the problem statement (e.
g.
, Hiebert, 1982; Staub & Reusser, in press).
 Problems like PI in which the unknown quantity is the result of the events being described, tend to be significantly easier than problems like P2 in which the unknown quantity is a start or transition state in the events being described: PI.
 Mary had 3 marbles.
 Then John gave her 5 marbles.
 How many marbles does Mary have now? P2.
 Mary had some marbles.
 Then John gave her 3 marbles.
 Now Mary has 5 marbles.
 How many marbles did Mary have in the beginning? Riley and Greeno (1988) found that while 1st and 3rd grade students were 100% correct on PI, they were 3 3 % and 9 5 % correct, respectively, on P2.
 This unknown position effect can be captured within the directed quantitative network.
 Problems are more difficult when the unknown is an input to a constraint.
 Problem PO becomes a resultunknown if income is given.
 Mathematical Complexity Although 3rd graders can solve certain startunknown problems, like P2, there are numerous other factors that can quickly put startunknown problems out of reach of elementary students and even many adults.
 A striking example of this is a local business executive who was struggling with a problem like P3.
 P3.
 80% of some number is 100.
 What is the ntimber? He needed to do a series of calculations where he knew the result (e.
g.
, $100) of taking 8 0 % of some number and wanted to find that number.
 While the solution procedure of dividing the $1(X) by 0.
8 is analogous to subtracting 3 from 5 in P2, this problem proved daunting.
 The relevant dimension here is that changing the type of the numbers in a problem (e.
g.
, from integers to percents) makes it more difficult to determine the appropriate inversion operation.
 Had the problem been 15 times some number is 100, he would have had little trouble deciding to divide.
 Anderson, Reder, & Ritter (in preparation) provide experimental evidence for this difficulty factor.
 The number of arithmetic operators in the problem is another difficulty factor.
 Problem P4 is a startunknown problem where two operations, multiplication and addition, are needed to get to the result.
 P4.
 When Ted got home from his waiter job.
 398 he multiplied his hourly wage by the 6 hours he worked that day.
 Then he added the $66 he made in tips and foiand he earned $81.
90.
 How much per hour does Ted make? A similar one operator problem (e.
g.
, without the lip) is straightforward.
 However, in a study of urban high school students (Koedinger & Tabachneck, 1995), two operator startunknown problems like P4 were solved only 5 9 % of the time.
 They were substantially more difficult than analogous resultunknown problems that were solved 7 3 % of the time.
 While the Riley and Greeno (1988) study showed the effect of unknown position on one operator problems nearly disappearing by 3rd grade, with the added complexity of two operator problems this effect appears again even for much older students.
 Connected vs.
 Disconnected Problems Bednarz and Janvier (in preparation) make a distinction between "connected" and "disconnected" problems to shed light on "the passage from arithmetic to algebra".
 In connected problems "a relationship can be easily established between two quantities thus leading to the possibility of arithmetic reasoning" while disconnected means "no direct links (or bridges) can be directly established between the known quantities" (Bednarz & Janvier, in preparation, p.
 10).
 P5.
 Connected problem: Albert has 4 times as many stamps as Judith and 7 times as many as Sophie.
 If Albert has 504 stamps, how many do the three children have altogether? P6.
 Disconnected problem: 380 students are registered in sports activities for the season.
 Basketball has 76 more students than skating and swimming has 114 more than basket ball.
 How many students are there in each of the activities? The difference in difficulty between connected and disconnected problems is large.
 For example, Bednarz and Janvier report that their middle school age subjects (12 to 13) were 8 2 % correct on the connected problem P5 and only 5 % correct on the disconnected problem P6.
 The disconnectedness dimension has been used as a way of distinguishing between arithmetic and algebra problems (Kieran, 1992, p.
 393); however, it seems clear that some connected problems, like P3 and P4 above, require mathematical power at or beyond the edge of arithmetic competency.
 Quantitative networks can be used to provide a more precise definition of the connecteddisconnected distinction.
 A problem is connected when a solution can be found by successively propagating the results from constraints with two known values.
 Problem PO is disconnected because there are no constraints with two known values.
 However, if the Taxrate were unknown and Income given, it would be connected (but not resultunknown).
 S o m e Situational Factors Situational Facilitation P7.
 Situational facilitation: There are 5 birds and 3 worms.
 How many birds won' t get a worm? P8.
 Neutral: There are 5 birds and 3 worms.
 How many more birds are there than worms? Consider problems P7 and P8.
 Problem P7 provides situational support for the computation as it suggests a onetoone matching solution strategy.
 Nursery school students were 8 3 % correct on P7 but only 1 7 % correct on P8 (Hudson, 1983).
 These problems are clearly within arithmetic competence; however, they nicely illustrate the kinds of situational facilitation that can occur at any level.
 Examples that go beyond arithmetic competence will be given below.
 Quantitative networks do not capture situational facilitation, except to the extent that a implicit constraint or quantity is more likely to be included in the problem solver's conception of the problem when there is appropriate situational support (Nathan & Resnick, 1993).
 Problem Presentation and Context The mention of "story problems" elicits groans of pain among students and their purported difficulty is ingrained in America culture, so much so that story problems are standard stock for cartoons (e.
g.
, Gary Larson's "Library from Hell" which has only story problem books).
 Cummins, et al.
 (1988) comment on this widespread belief: "as students advance to more sophisticated domains, they continue to find word problems in those domains more difficult to solve than problems presented in symbolic format (e.
g.
, algebraic equations)".
 However, the empirical support for this belief is unclear.
 A recent study with ninth graders (Koedinger & Tabachneck, 1995) showed that, all other things being equal, story problems were easier to solve than the analogous algebraic equations.
 Students were only correct 5 0 % of the time when solving algebraic equations, like P9.
 They were much better (75% correct) with the addition of a story context, like PIO.
 P9.
 (X  64) / 3 = 26.
5 PIO.
 After hearing that Mom won a lottery prize, Bill took the amount she won and subtracted the $64 that Mom kept for herself.
 Then he divided the remaining money among her 3 sons giving each $26.
50.
 How much did Mom win? Pll.
 Starting with some number, if I subtract 64 and then divide by 3, I get 26.
5.
 What number did I start with? Carraher et al.
 (1987) found a similar effect with 3rd graders on one operator resultunknown problems.
 They attributed students' relative success on word problems (56%) versus analogous symbolic problems (38%) to effects of "context".
 Followup studies by Baranes, Perry, and Stigler (1989) refined this notion to conclude that it is "relevant 399 context" that counts.
 However, a second result from Koedinger and Tabachneck (1995) suggests that there may be more going on here.
 Students did as well on situationfree verbally stated equations like PI 1 (74% correct) as they did on word problems like PIO.
 The advantages may derive from students' familiarity with words as representations of procedures rather than from any situational content.
 Problems that present themselves in natural settings may provide opportunities for situational facilitation that are not present or not as likely in the verbally presented problems in the classroom or laboratory.
 For example, students' nonsensical answers (e.
g.
, 311/3 buses) on test problems like the wellknown buses problem (PI2) seem less likely if given a real setting (cf.
 Silver & Shapiro, in press).
 P12.
 An army bus holds 36 soldiers.
 If 1,128 soldiers are being bused to their training site, how many buses are needed? Despite much emphasis on situational factors in cognition, there are a number of large gaps in what w e know about the characteristics of the everyday/workplace task environment.
 Our analysis has mostly focused on verbally presented problems in classroom and laboratory contexts.
 There is no strong evidence at this point to believe that this analysis will not be applicable to naturally presented problems.
 But, this is an area worth further investigation.
 Table 1 summarizes difficulty factors w e identified.
 Problems characterized by easier values of these factors tend to be arithmetic problems.
 Problems with harder values tend to require competence beyond arithmetic.
 Table 1.
 Difficulty Difficulty Factors Unknown position Connectedness Number of operators Number types of quantity Kinds of operators Numberfact facilitation Situational factors factors that push Arithmetic Easier .
 .
 .
 Harder result start connected disconnected one many integer real complex + * / A facilitate neutral inhibit facilitate neutral inhibit C o g n i t i v e R e p r e s e n t a t i o n s a n d Strategies Although mathematics instruction tends to focus overwhelmingly on symbolic representations and computational procedures of problem solving (e.
g.
, Leinhardt, 1988), students use a variety of alternative methods to address problems.
 In one study, grade 5 children without training used a trialanderror strategy exclusively in solving mathematics problems (Lester, 1980).
 Even matriculated adults with many years of experience using symbolic representations, spontaneously use alternate methods such as guessandcheck or proportional reasoning for solving more complex problems (e.
g.
.
 Hall et al.
, 1989; Tabachneck, et al.
, 1994).
 There is mounting evidence that students' alternative ways of quantitative reasoning are more complex and efficacious than has been previously suggested in the misconceptions literature (e.
g.
.
 Smith, diSessa, & Roschelle, 1993).
 The fundamental difficulty of problems that push a student to go beyond arithmetic calculations is that it is not possible to produce a solution by propagating given values through the directional constraints implied by the problem.
 There are two distinguishable classes of problemsolving methods for dealing with this difficulty.
 The first class of methods is generate and test: generate a candidate value for one or more unknowns, propagate it through the constraints, test whether they are met, and if necessary iterate.
 The second class of methods is constraint untangling: reverse the directionality of the constraints and otherwise transform them so that it becomes possible to forward propagate the given values to produce a solution.
 In constraint untangling, the objects of manipulation are the constraints themselves.
 In arithmetic and generateandtest, the constraints are procedures to follow and the quantities they relate are the objects of manipulation.
 The process of objectifying arithmetic procedures as objects of manipulation evolved over thousands of years in the historical development of algebraic technique and notations (Sfard & Linchevski, 1993).
 It is perhaps no surprise that this transition is quite difficult for students.
 Other things equal these methods are at opposite ends of the "preparation vs.
 deliberation tradeoff (Newell, 1990, p.
 102).
 Generate and test methods can be performed with less knowledge (less learning time investment), but tend to be less efficient and require greater deliberation.
 Constraint untangling methods can be quite efficient, but require significant learning time.
 Table 2: Strategies vary by reasoning method and representation.
 Representational formats Methods i Generate And Test Constraint Untangling symbolic verbal diagram situational Plugin Guess& Enumerate Modelcheck based Algebra Verbal Diagram Use objects algebra annotate Ratio As illustrated in Table 2, both classes of methods have instances in a variety of different representational formats.
 For instance, constraint untangling done in the symbolic format is the traditional algebra strategy.
 A n illustration of this strategy is shown in the first column of Table 3.
 The next two columns illustrate constraint untangling in two other representational formats which have been observed in studies of verbal and written problemsolving protocols (Hall et al.
, 1989; Tabachneck et al.
, 1994).
 Only the transformations within a given representation are illustrated.
 The difficult process of translating a given problem to one of these solutionenabling representations is addressed below.
 400 Table 3: Instances of the constraint untangling method in three different representational formats on isomorphs of the problem: "I paid $38 for jeans.
 I got them at a 20% discount.
 How much did I save?".
 Algebra p .
2p = 38 .
8p = 38 p = 38/.
8 = 47.
5 s = p38 s = 9.
5 Verbal algebra The original price minus 2 0 % is $38.
 So, 8 0 % of the original price is $38.
 To get the original price, divide $38 by .
8 which is 47.
5.
 The amount saved is the original price minus $38.
 That's $9.
50.
 Oiagram annotation P 38 P 38 .
8p 47.
5 P 38 .
8p 47.
5 P •2p •2p •2p 38 .
2p .
8p 47.
538 47.
5 P 38 .
8p •2p 9.
5 Generic operator Given Forward constraint propagation (Simplify) Backward constraint propagation (Unwind) Given Constraint combination (Substitute and Simplify) When the generate and test method is applied to a symbolic representation, the resulting strategy is termed "plugin" or "plugandchug", and is commonly used with algebraic formulae.
 The verbal method is a commonly invented method used by students across grade levels (e.
g.
, Lester, 1980).
 The situationbased method reflects an attempt on the part of the solver to model or simulate the events of the problem by, for example, examining earnings at one dollar, then two, etc.
 These methods, while conceptually simple and easily invented by students of a wide range of achievement levels, are quite powerful, and lie at the core of numerical methods throughout statistics and analytical geometry.
 Along the representational format dimension there is a conciseness vs.
 elaboration tradeoff.
 Symbolic representations are more concise and abstracted from the problem situation, while situational representations are elaborated with information that is often redundant to, but not essential for the computational process.
 This redundancy has clear advantages, though.
 Students who are otherwise quite capable of algebra equation solving (who have paid the preparation price), nevertheless are quite susceptible to difficulties with translation (Hall, et al.
, 1989).
 Compensatory Benefits of R e d u n d a n t Representations It stands to reason that different representations and strategies are effective for different kinds of environmental demands.
 Verballybased strategies are highly effective at highlighting errors due to mistranslation; diagrammatic strategies, for capturing spatial relations; symbolic strategies, for supporting computation; situational strategies, for simulating processes.
 In other words, there is no single representation or strategy that is universally effective.
 Tabachneck et al.
 (1994) found correlational evidence that the use of multiple strategies during nonroutine problem solving yields greater solution success (80%) than the use of a single strategy (40%).
 Implications for Instructional Design The difficulty factors can be used to hypothesize a developmentally appropriate problem sequence.
 Teachers can use these factors to diagnose a student's zone of proximal development (eg.
.
 Brown, 1994) and select problems that are within reach of the student yet present demands that pull her toward more sophisticated mathematical strategies.
 Introduction of symbolic strategies can provide students with greatly enhanced mathematical power.
 Nevertheless, teachers should support and 401 encourage students in continued use and reference to their own informal strategies.
 While often less powerful or general, these informal strategies provide an important source of redundancy that aids students in sensemaking, reducing the chance of error and providing a source for selfsupervised learning.
 Acknowledgement This research was supported by a grant to these authors from the James S.
 McDonnell Foundation program in Cognitive Studies for Educational Practice, grant #9511.
 References Anderson, J.
R.
 (1990) The adaptive character of thought.
 Hillsdale,NJ: Lawrence Erlbaum.
 Anderson, J.
 R.
, Reder, L.
 M.
, & Ritter, S.
 (in preparation).
 Algebraic slips: A working memory explanation.
 Brown, A.
 L.
 (1994).
 The advancement of learning.
 Educational Researcher, 23, 8, 412.
 Baranes, R.
, Perry, M.
, and Stigler, J.
 W .
 (1989).
 Activation of realworld knowledge in the solution of word problems.
 Cognition and Instruction, 6 287318.
 Bednarz, N.
 & Janvier, B.
 (in preparation).
 Algebra as a problem solving tool: Continuities and discontinuities with arithmetic.
 Carraher, T.
 N.
, Carraher, D.
 W.
, & Schlieman, A.
 D.
 (1987).
 Written and oral mathematics.
 Journal for Research in Mathematics Education, 18 8397.
 Cummins, D.
 D.
, Kintsch, W.
, Reusser, K.
, & Weimer, R.
 (1988).
 The role of understanding in solving word problems.
 Cognitive Psychology, 20, 405438.
 Geary, D.
 C.
 (1995).
 Reflections of evolution and culture in children's cognition: Implications for mathematical development and instruction.
 American Psychology, 50, (1), 2437.
 Hall, R.
, Kibler, D.
, Wenger, E.
, & Truxaw, C.
 (1989).
 Exploring the episodic structure of algebra story problem solving.
 Cognition and Instruction, 6, 223283.
 Hiebert, J.
 (1982).
 The position of the unknown set and children's solutions of verbal arithmetic problems.
 Journal for Research in Mathematics Education.
 13, 5, 341349.
 Hudson, T.
 (1983).
 Correspondences and numerical differences between disjoint sets.
 Child Development, 54, 8490.
 Kahneman, D, & Tversky, A.
(1973).
 On the psychology of prediction.
 Psychological Review, 80, Til251.
 Kieran, C.
 (1992).
 The learning and teaching of school algebra.
 In D.
 Grouws (Ed.
), Handbook of Research in Mathematics Teaching and Learning (pp.
 390419).
 N ew York: MacMillan Publishing Company.
 Koedinger, K.
R.
, & Tabachneck, H.
J.
M.
 (1995).
 Verbal reasoning as a critical component in early algebra.
 Paper presented at the 1995 annual meeting of the American Educational Research Association, San Francisco.
 Leinhardt, G.
 (1988).
 Getting to know: Tracing students' mathematical knowledge from inuition to competence.
 Educational Psychologist, 23(2), 119144 Lester, F.
 K.
 (1980).
 Research on mathematical problem solving.
 In R.
 J.
 Shumway (Ed.
) Research in Mathematics.
 National Council of Teachers of Mathematics.
 Nathan, M.
 J.
, & Resnick, L.
 B.
 (1993) Inferencemaking during word problem solving.
 European Association For Research on Learning and Instruction (EARLI), Aug.
, 1993 (AixenProvence, France).
 National Assessment of Educational Progress (1993).
 Can students do mathematical problem solving? Report # 23FROl.
 Washington DC: National Center for Educational Statistics.
 National Council of Teachers of Mathematics (1989).
 Curriculum and Evaluation Standards for School Mathematics.
 Reston, VA: The Council.
 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M A : Harvard University Press.
 Polk, T.
A.
 (1992) Verbal Reasoning.
 Dissertation, Carnegie Mellon University School of Computer Science # C M U CS92178.
 Resnick, L.
 B.
 (1987).
 Learning in school and out.
 In Educational Researcher, 16 (9).
 Riley, M.
S.
, & Greeno, J.
G.
 (1988).
 Developmental analysis of understanding language about quantities and solving problems.
 Cognition and Instruction, 5, 49101.
 Shalin, V.
, & Bee, N.
V.
 (1985).
 Analysis of the semantic structure of a domain of word problems.
 (Tech.
 Rep.
 No.
 APS20).
 Pittsburgh: University of Pittsburgh, Learning Research and Development Center.
.
 Silver, E.
 A.
 & Shapiro, L.
 J.
 (1992).
 Examinations of situationbased reasoning and sensemaking in students' interpretations of solutions to a mathematics story problem.
 In J.
P.
Ponte, J.
F.
 Matos, J.
M.
 Matos & D.
 Femandes (Eds.
), Mathematical Problem Solving and New Information Technology: Research in Contexts of Practice.
 SpringerVerlag.
 Sfard, A.
 & Linchevski, L.
 (1993).
 The gains and pitfalls of reification: The case of algebra.
 Educational Studies in Mathematics, 00: 138.
 Smith, J.
 P.
, m.
, diSessa, A.
 A.
, & Roschelle, J.
 (1993).
Misconceptions reconceived: A constructivist analysis of knowledge in transition.
 Journal of The Learning Sciences, 3(2).
 115164.
 Staub, F.
 C.
 & Reusser, K.
 (in press).
 The role of presentational structures in understanding and solving mathematical word problems.
 In C.
A.
 Weaver, S.
 Mannes & R.
C.
 Fletcher (Eds.
), Discourse Comprehension: Essays in Honor of Walter Kintsch.
 Hillsdale, N.
J.
: Lawrence Erlbaum Associates, in press.
 Tabachneck, H.
 J.
 M.
, Koedinger, K.
 R.
, & Nathan, M.
 J.
 (1994).
 Toward a theoretical account of strategy use and sensemaking in mathematics problem solving.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Erlbaum.
 Verschaffel, L.
, De Corte, E.
 & Lasure, S.
 (1994).
 Realistic considerations in mathematical modeling of school arithmetic word problems.
 Wason, P.
C.
 & JohnsonLaird, P.
N.
 (1972).
 Psychology of reasoning: structure and content.
 Cambridge, M A : Harvard Press.
 402 ProblemBased Learning: Development O f Knowledge A n d Reasoning Strategies Cindy E.
 Hmelo EduTech Institute Georgia Institute of Technology College of Computing AUanta, G A 303320280 Phone: 4048949104 ceh@cc.
gatech.
edu Abstract Problembased learning (PBL) reflects new conceptions of learning that have grown out of theory and research in cognitive science.
 PBL has been used in medical schools to enhance the development of clinical reasoning skills and to promote the integration of basic biomedical sciences with clinical applications.
 In this study, the effect of PBL on the development of clinical reasoning strategies, use of scientific knowledge, and accuracy are examined on a causal explanation task.
 Students in problembased curricula were compared with students in traditional medical curricula.
 The results indicate that PBL plays a role in facilitating the development of expertise.
 In PBL, students learn through the transfer of hypothesisdriven reasoning skills that result in more coherent explanations.
 The PBL students are better able to apply their science knowledge than nonPBL students, leading to greater accuracy of hypotheses.
 P r o b l e m  b a s e d learning Learning from cases has been proposed and implemented in several forms to help students learn complex, illstructured domains (e.
g.
, Barrows, 1985; Williams, 1993).
 Learning from cases situates knowledge in the context of use (J.
 S.
 Brown, CoUins, & Duguid, 1989).
 One type of casebased instruction is problembased learning.
 In medical schools, problembased learning (PBL) is becoming widely used to replace the first 2 years of science courses.
 Instead of the traditional lecturebased format, students learn biomedical science through solving problems.
 This study examines the cognitive effects of traditional and problembased medical curricula on firstyear medical students.
 The effects examined are related to the cognitive goals and activities that take place in P B L classrooms.
 PBL includes among its goals 1) developing scientific understanding through cases and 2) developing clinical reasoning strategies.
 Cognitive theories of situated cognition and transferappropriate processing suggest that these goals should be met (J.
 S.
 Brown et al.
, 1989; Schmidt, 1993).
 At a general level, the expectation is that PBL will produce physicians who, when faced with a novel or difficult case, can use their basic science knowledge to assist them in understanding the problem.
 In some regards then, P B L may be viewed as a design experiment that tests situated theories of learning (A.
 Brown, 1992).
 The next section of this paper will describe P B L in more detail followed by a discussion of a cognitive approach to understanding the effects of PBL.
 In PBL, small groups of 57 students and a facilitator meet to discuss a patient case.
 The students receive an initial scenario and then must question the facilitator to get additional case information.
 At several points in the case, the students pause to consider the data they have collected so far, to generate questions about the data, and to hypothesize about underlying causal mechanisms for the patient's problems.
 The students must also identify issues that they do not understand and need to learn more about.
 After considering the case with their naive knowledge, the students independently research the learning issues they have identified.
 They then share what they learned, reconsider their hypotheses and/or generate new hypotheses in light of their new learning.
 The cases for PBL are carefully chosen to cover particular learning objectives in basic biomedical science.
 Topics are revisited from several cases.
 This is intended to allow the students to learn basic sciences in a manner that integrates the science with its clinical applications.
 By situating science learning in clinical situations, the learners should be better able to recall that information in the future (e.
g.
, Adams, Kasserman, Yearwood, Perfetto, Bransford, & Franks, 1988).
 Also, by tying the scientific principles to the cases they are working on, the students are generating selfexplanations that should result in the construction of more coherent mental models of the underlying science (Chi, Bassok, Lewis, Reimann, & Glaser, 1989; Patel & Kauffman, 1993).
 In addition, students may be building a Hbrary of cases that they can use in subsequent reasoning (Kolodner, 1993).
 Moreover, by revisiting concepts through multiple cases, cognitive flexibility may be promoted (Spiro, Coulsen, Feltovich, & Anderson, 1988).
 To understand the effects of PBL, students were asked to generate causal explanations to clinical cases.
 Their explanations were evaluated for accuracy, coherence, reasoning strategies, and use of science.
 403 mailto:ceh@cc.
gatech.
eduMethods Students from two medical schools participated in this study.
 At School A, a midwestern medical school, 35 firstyear students participated.
 Sixteen students were from the school's traditional curriculum and 19 were from the P B L curriculum.
 The students in the fraditional curriculum spent approximately 40 hours a week in lecture and laboratory courses in the basic biomedical sciences whereas the P B L students had two 3hour sessions for their P B L group meetings and a third optional 1hour session a week where resource faculty were available to answer questions.
 At School B, a southern medical school, 39 students participated in the study.
 O f these, 19 students were in a P B L elective and 20 students were in a different elective.
 In School B, these electives were in addition to a traditional curriculum.
 So the P B L students at school B had 1 hours a week of their P B L elective in addition to 40 hours of traditional lecture and laboratory classes.
 The actual P B L group meetings were very similar at the two schools except that the School A students had a much more intense P B L experience than the School B group.
 Students were paid $45 for participating in 3 twohour sessions during their first year of medical school.
 The sessions took place before the start of classes, after 3 months, and after 7 months of medical school.
 The students' task was to generate pathophysiological explanations for the mechanisms underlying a medical case.
 The cases were presented in 5 segments: presenting information, history, physical examination, laboratory data, and hospital course.
 Students were asked to generate explanations after each part of the case.
 At each session, the subject received 2 cases.
 Six different cases were used that covered a variety of body systems and disease processes.
 Students were randomly assigned to 6 different cases in orders that were counterbalanced across conditions.
 The problemsolving protocols were coded for coherence, science use and accuracy.
 In addition, the directionality of reasoning was coded.
 A random sample of 2 0 % of the protocols was scored by a second independent rater blind to condition.
 Interrater agreement was 91.
6%.
 R e s u l t s Problemsolving The problemsolving analyses examined the products and processes of the subjects' problemsolving.
 The data were sununed across the sections of the case for the purpose of these analyses.
 All quantitative analyses were conducted using a 3 x 2 x 2 x 2 (Time of test x Order of problem x Site X Curriculum) A N O V A .
 For qualitative analyses, the same factors were used in a loglinear analysis.
 Because students selfselect into PBL, an analysis of preexisting differences was conducted.
 There was no effect of curriculum on M C A T scores, undergraduate G P A , age, or prior experience in health care.
 There were differences between the two sites, with the students at School B scoring higher on the M C A T and G P A measures, whereas the School A students had more prior health care experience.
 However, this suggests that upon entrance into medical school, the P B L and nonPBL students were equivalent on these criteria.
 Directionality of reasoning The reasoning strategies were of four types: datadriven (forward) reasoning, hypothesisdriven (backward) reasoning, other relational reasoning, and unjustified assertions.
 In the P B L sessions, the students are taught to use hypothesisdriven reasoning but early in the year when the students do not know very much, they may either unsuccessfully use datadriven reasoning or they may not justify their assertions at all.
 Preliminary research suggested that these measures help distinguish P B L from nonPBL students (Hmelo, Gotterer, & Bransford, 1994).
 Datadriven reasoning involves reasoning from the data to a hypothesis whereas hypothesisdriven reasoning involves using a hypothesis to explain the data.
 A n example of a datadriven reasoning statement is "If he has an elevated blood sugar, then he must have diabetes.
" "Because he has diabetes, he has an elevated blood sugar" is an example of a hypothesisdriven reasoning statement.
 This is the type of reasoning that is modeled in a problembased curriculum.
 Other relations may also be expressed, for example, "He has an infection in association with diabetes.
" In this case, the directionality of reasoning is unclear.
 Subjects may also assert causes without justifying them.
 These are statements such as "He is diabetic" without any explanations to support the hypothesis.
 Although datadriven reasoning is more characteristic of experts, it is inappropriate for novices who have an insufficient knowledge base (Patel & Kauffman, 1993).
 In PBL, students are taught to use hypothesisdriven reasoning to construct explanations that account for all of the data.
 Thus w e predicted that the P B L smdents would be more likely to use hypothesisdriven reasoning than conventional (nonPBL) students because that is the strategy they were taught.
 Prior research has demonstrated that traditional medical students were more likely to use datadriven reasoning although there is not a clear theoretical basis for this result (Patel et al.
, 1993).
 Loglinear analyses were conducted to analyze these data.
 The P B L students increased their use of hypothesisdriven reasoning relative to the nonPBL students over the course of the year (jc^(4)=42.
\0, /K.
OOl) but simple effects tests indicated that both the P B L and nonPBL groups increased their use of hypothesisdriven reasoning over the course of the year (;f2(4)=20.
34, p<.
001 and ;t2(4)=54.
86, p<.
001, respectively).
 Figure la illustrates this effect by showing the percentage of students using hypothesisdriven reasoning 404 as their dominant form of reasoning.
 There w a s no consistent effect across conditions and time for datadriven or otherrelational reasoning.
 T h e change in dominant use of unjustified assertions is s h o w n in Figure lb.
 Overall, ihinumber of unjustified assertions decreased over lime a.
s iljc students generated m o r e elaborate explanations (22(4)=25.
02, p<.
001).
 Time 1 Time 2 Time 3 Figure la: Dominant use of HypothesisDriven Reasoning « 40 nofiPBL Time 1 Time 2 Time 3 Figure lb: D o m i n a n t use of unjustified assertions Coherence To measure the coherence of an explanation, the number of findings that the subjects used in their longest reasoning chain was measured.
 A fragmented explanation that only deals with a single finding is less coherent than longer statements that include multiple findings.
 A finding was counted if it was a repetition of data given in the case or a low level interpretation of that data (e.
g.
, an elevated heart rate).
 For example, "A decreased bicarbonate level would cause a metabolic acidosis resulting in an increased respiratory rate" contains 2 findings.
The results, shovra in Figure 2 indicate that, there is an interaction of Curriculum x Site X both linear and quadratic trends for Time (F(l,68)=5.
16, u<.
05, M S £ = 0.
37 and F(l,68)=5.
96, £=.
05, MSc = 0.
36 , respectively).
 Further evaluation was therefore conducted separately for each site.
 At School A, there was differential change over time (Curriculum x linear trend for Time F(l,31)=9.
20, fi<.
005, M S ^ = 0.
49, Curriculum x quadratic trend for Time F(l,68)=5.
16, E<.
05, M S g = 0.
37).
 This effect occurred becau.
se of the linear increase in the number of findings used over time for the P B L students (£(1,31)=29.
47, I2<001) 2.
501 Number of Findings en o ui o o o o o rr U.
UU 1 — Time ^ ^ _ _ ^ ^ _ ^ ^ ^ P ^ 3 = r r r ^ 1 1 Time 2 Time C a  ASchool A nonPBL  School A PBL School B nonPBL  School 8 PBL Figure 2: Coherence: N u m b e r of findings per reasoning chain whereas there was no significant change over time for the n o n P B L students.
 The results of this measure indicate that the P B L students have a big improvement in coherence from Time 1 to Time 2 which they sustain until T i m e 3.
 T h e n o n P B L students do not show any change.
 There was no evidence of a PBL effect for change over time in the School B students.
 T h e School B students as a showed an overall improvement in the number of findings that they accounted for over the course of the year.
 This improvement was seen as a linear increase over time (F(l,37)=20.
64, iK.
OOl, M S e = 0.
28).
 Accuracy Accuracy was measured at each point in the case.
 If the P B L students are constructing causal models and acquiring a library of cases from which to reason, they should become more accurate over the course of the year.
 The nonPBL students should also become more accurate over the year if they are able to apply their increased knowledge to patient cases.
 One point was given for a partially accurate score (i.
e.
, a superordinate hypothesis, such as Tuberculosis in a case of Disseminated Tuberculosis) and 2 points were given for a fully accurate hypothesis.
 A subject who considered a fully accurate hypothesis from the start of the case could score 10 points for accuracy.
 A subject who fust considered the correct hypothesis in the lab portion of the case and carried that hypothesis through the hospital course could score 4 points.
 A contrast that tested a Curriculum x Linear trend across time effect was significant, indicating that the P B L students showed a different rate of improvement in accuracy than the nonPBL students (F(l,68) =4.
69, j2<.
05, MSe=6.
12), as illustrated in Figure 3.
 405 http://becau.
seThis interaction occurred because there was an increase in accuracy over time for the P B L students (F(l,68)=22.
68.
 c <.
001) but the n o n P B L students did not show significant improvement.
 This indicates that the P B L students were correctly applying their knowledge to clinical cases whereas the n o n P B L students did not show improvement.
 5.
00 X 4.
50 4.
00 (0 3.
002.
501.
501.
00 •nonPBL 0.
50 • Time 1 Time 3 Time 2 Figure 3: Accuracy One explanation for these results might be that the PBL students had experiences with the types of cases that were used in this study.
 A followup analysis on the Time 3 results which used casespecific experience (as reported by the students) as a factor still showed a difference favoring the P B L students (F(l,64)=11.
53; ik.
001, MS4=9.
35).
 This suggests that there is a beneficial effect of P B L , beyond the experience it provides with specific cases.
 Moreover, case experience was also a significant factor in determining accuracy (F(l,64)=20.
32, e<.
001).
 Science use Because one of the goals of PBL was to learn science, it is important to measure whether students used science information in their explanations.
 Use of science concepts was scored 01 for each section of the case and then totaled across the case so the m a x i m u m score was a 5 for this measure.
 A n example of an explanation coded as a 1 for science use is: " she seems to have something in her left atrium.
 Whatever it is seems to be blocking the movement of blood from the left atrium into the left ventricle.
 This would explain the enlarged L A .
 It would continue to fill with blood coming from the lungs, but would not be able to relieve the tension by giving all of the blood to the L V .
 In other words, the L A would have to accommodate more and more blood resulting in hypertrophy.
 " In this example the subject used her knowledge of anatomy to explain w h y the heart was enlarged in this specific case.
 A loglinear analysis revealed a threeway Curriculum x Time x Site interaction suggesfing that the Curriculum x Time effect was different at each site (x2(4)=21.
13, q <.
001).
 T o clarify the nature of these effects, simple effects tests were conducted within each site.
 At both School A and B, there were significant Curriculum x Time interactions (X2(4)=338.
20, u <.
001 and x2(4)=141.
37, e <.
001, respectively) indicating that at both sites the P B L students became more likely to use science concepts in their responses, but the nature of the Curriculum x Time interaction was different at the two sites.
 Figures 4a and 4b illustrate the nature of this differential change.
 At School A, the number of nonPBL students who used science concepts only once remained steady between Time 1 and Time 2 and dropped slightly at T i m e 3, but there was a small but steady increase in the number of students w h o used science concepts at several points in the case throughout the duration of the study.
 The P B L students had a large increase between Time 1 and Time 2 in subjects using science concepts both at 1 point in the case and at 2 or more points.
 At Time 3, the number of students w h o used science concepts once during the case drops but this is probably because those students w h o used science once during the case at Time 2 used science concepts more frequently at Time 3.
 °  Sc*>oo( A rwnPBL • Sc*K»(AF=BL A —  SchodBnonPei * School BPBl.
 Figure 4a: U s e of science concepts in a single section of the case 70 60 • (A S30.
 1 20.
 1 0 ' ' r  ^ / / •'/'' / '•*"' / (̂ '̂̂  / ^"" Tim« 1 Tim« 2 ^A O Tima 3 «»• S*oolAnonPBL ^ School B nonPBL Figure 4b: U s e of science in t w o or m o r e sections of the case 406 At School B, between Time 1 and Time 2, both the nonPBL students and the P E L students showed a large increase in the number of students using science concepts al least once, but the nonPBL students maintained the sanii; numbers at time 3 whereas the P B L students show a decrease in the number of students using science concepts al this level.
 Figure 4b helps clarify this because it can be seen that the number of students using science concepts in two or more sections of the case increased steadily for the nonPBL students but did not increase by much until Time 3 for the P B L students when they surpassed the nonPBL students.
 Clearly, at School A, P B L has improved access to scientific information for these students in the context of clinical cases relative to the nonPBL students.
 At School B, although the results are not clear cut, there is a trend toward the P B L students using science concepts more frequently than the nonPBL students in explaining these cases.
 Discussion In this study, many changes were found that resulted from the type of curriculum that the students participated in.
 The reasoning suategies that the students learn and transfer to new problems (i.
e.
, hypothesisdriven reasoning) helps them construct the knowledge structures that are used in the early development of expertise.
 Early development of medical expertise is characterized by the development of elaborated causal networks that explain diseases in terms of general pathophysiological processes (Schmidt et al.
, 1990).
 Through extensive application of this knowledge, the networks become compiled and are subsumed under diagnostic labels (Schmidt et al.
, 1990).
 By promoting the use of hypothesisdriven reasoning strategies, P B L may accelerate this development.
 The same argument may be extended to the knowledge compilation stage as the P B L students have a greater opportunity to apply their knowledge to clinical cases.
 In addition, learning to use causal knowledge appropriately will be important as the students become experts and face difficult problems that require them to use their causal knowledge (e.
g.
, Norman et al.
, 1994).
 Although the data reported in this study show some of the outcomes associated with PBL, they do not explain h o w learning occurs.
 Research in cognitive science offers some explanations that are consistent with the results obtained.
 In PBL, learning occurs through collaborative discussion.
 The development of causal models is facilitated in P B L as students activate their prior knowledge in P B L groups, enhancing the processing of new information (Schmidt, 1993).
 Group discussion encourages students to articulate their knowledge and theories.
 These discussions use hypothesisdriven reasoning which serves the function of selfexplanations which itself is a learning mechanism as students connect abstract knowledge to clinical applications (Chi et al.
, 1989).
The nature of hypothesisdriven reasoning allows students to learn to filter relevant from irrelevant information.
 One result of this is a coherent understanding.
 Mental models are constructed and restructured in response to the problem posed and students' explanations of the phenomena to be understood.
 In later discussions, as the group seeks to further understand the causal mechanisms underlying the case, further tuning of the mental models occurs (Schmidt, 1993).
 If students in P B L construct elaborated causal models of biomedical science that are integrated with clinical cases, then their ability to generate more coherent causal explanations should increase over time.
 The results of this study suggest that this is occurring and that hypothesisdriven reasoning m a y be the mechanism.
 Coherence in reasoning is an important metric to use.
 A coherent explanation has no loose ends and accounts for all the information.
 Furthermore, increasing coherence is found in expert reasoning.
 In a study of radiologists, a similar measure of coherence revealed an increase with expertise (Lesgold, Rubinson, Feltovich, Klopfer, & Wang, 1988).
 Senior radiologists chunked more findings together than residents.
 This suggests that experts do more inferential thinking and end up with a more coherent representation of the patient.
 Novice's explanations, with less data accounted for, suggest a more fragmented representation.
 Transferappropriate processing is another mechanism that has been proposed to explain the effectiveness of PBL.
 Because students learn science in the context of clinical problems, they should be more likely to recall that information in clinical practice (Adams et al.
,1988, Needham & Begg, 1991).
 In this study, explanations were examined for concepts or facts from the biomedical sciences as an indication that students were integrating science information.
 The results showed that P B L students became increasingly likely to use science in their explanations, particularly in the fulltime P B L program.
 This is consistent with other work as well (Hmelo et al, 1994, Patel et al, 1993).
 For example, in Patel et al.
 (1993), P B L and conventional students were asked to construct causal explanations and integrate relevant basic science information into their thinkaloud explanations.
 The P B L students incorporated more of the science information into their explanations and generated more hypothesisdriven explanations than the conventional students.
 It is tempting to conclude that the P B L students learned to use science as a tool for understanding, but fiirther research is needed to investigate this issue.
 Another possible mechanism for the effects of P B L is that the students acquire a library of cases from which to reason (Kolodner, 1993).
 The posthoc analysis of the accuracy data suggest that specific experience accounts for part of the accuracy effect but that there is an influence of P B L beyond this.
 Further investigation is needed to better understand the effect of P B L on casebased reasoning.
 Conclusions P B L has clearcut cognitive effects that are related to the 407 intensity of the P B L experience.
 For School A, the fully problembased curriculum, the students constructed coherent models of science that were integrated with the cases they are studying.
 At School B, the results were not as clear.
 There were PBL effects for science use, use of hypothesisdriven reasoning, and accuracy.
 Further research needs to be done to examine the role of the specific cases used and the development of misconceptions that may occur in these studentdirected groups.
 Nonetheless, P B L holds the promise of powerful cognitive benefits for learners.
 Acknowledgments This work was part of the author's dissertation research.
 This research was supported by grants from the Vanderbilt University Graduate School, American Psychological Association, and the Rush Medical College Alternative Curriculum.
 I also thank Nathalie Cot6 for doing the reliability coding for this study.
 References Adams, L.
, Kasserman, J.
, Yearwood, A.
, Perfetto, G.
, Bransford, J.
, & Franks, J.
 (1988).
 The effect of fact versus problem oriented acquisition.
 Memory and Cognition, 16, 167175.
 Barrows, H.
(1985).
 How to design a problembased curriculum for the preclinical years.
 N Y : Springer.
 Brown, A.
 L.
 (1992).
 Design experiments: Theoretical and methodological challenges in creating complex interventions in classroom settings.
 Journal of the Learning Sciences, 2, 141178.
 Brown, J.
 S.
, Collins, A.
, & Duguid, P.
 (1989).
 Situated cognition and the culture of learning.
 Educational Researcher, 18{l), 3241.
 Chi, M.
T.
H.
, Bassok, M.
, Lewis, M.
 W.
, Reimann, P.
, & Glaser, R.
 (1989).
 Selfexplanations: H o w students study and use examples in learning to solve problems.
 Cognitive Science, 13, 145182.
 Elstein, A.
 S.
, Shulman, L.
S.
, & Sprafka, S.
A.
 (1978).
 Medical problem solving: An analysis of clinical reasoning.
 Cambridge M A : Harvard University Press.
 Hmelo, C.
 E.
, Gotterer, G.
 S.
, & Bransford, J.
 D.
 (April, 1994).
 The cognitive effects of problembased learning: A preliminary study.
 Presented at American Educational Research Association annual meeting.
 N e w Orleans LA.
 Kolodner, J.
 L.
 (1993) Case Based Reasoning.
 San Mateo CA: Morgan Kaufinann Publishers.
 Lesgold, A.
, Rubinson, H.
, Feltovich, P.
, Glaser R.
, Klopfer, D.
, Wang, Y.
 (1988).
 Expertise in a complex skill: Diagnosing xray pictures.
 In M .
 T.
 H.
 Chi, R.
 Glaser, & M .
 J.
 Farr (Eds.
), The nature of expertise.
 Hillsdale NJ: Eribaum.
 Needham, D.
 R.
, & Begg, I.
M.
 (1991).
 Problemoriented training promotes spontaneous analogical transfer.
 Memoryoriented training promotes memory for training.
 Memory and Cognition, 19, 543557.
 Norman, G.
, Trott, A.
, Brooks, L.
, & Smith, E.
 K.
 (1994).
 Cognitive differences in clinical reasoning related to postgraduate training.
 Teaching and Learning in Medicine, 6, 114120.
 Patel, V.
 L.
, Groen, G.
J.
 & Norman, G.
R.
 (1993).
 Reasoning and insuuction in medical curricula.
 Cognition and Instruction.
 70,335378.
 Patel, V.
 L.
 & Kauffman, D.
 R.
 (1993).
 Development of knowledgebased reasoning strategies with medical training (Technical Report No.
 CME93CS3).
 Cognitive Studies in Medicine: Centre for Medical Education.
 McGill University.
 Schmidt, H.
G.
 (1993).
 Foundations of problembased learning: Some explanatory notes.
 Medical Education, 27, 422432.
 Schmidt, H.
 G.
, Norman, G.
 R.
, & Boshuizen, H.
 P.
 A.
 (1990).
 A cognitive perspective on medical expertise: Theory and implications.
 Academic Medicine, 65, 611621.
 Spiro, R.
 J.
, Coulsen, R.
 L.
, Feltovich, P.
 J.
, & Anderson, D.
 K.
 (1988).
 Cognitive flexibility theory: Advanced knowledge acquisition in illstructured domains.
 In presented Proceedings of the Tenth Annual Conference of the Cognitive Science Society.
 Williams, S.
 M .
 (1993).
 F*utting casebased learning into context: Examples from legal, business, and medical education.
 Journal of the Learning Sciences, 2, 367427.
 408 C a n MiddleSchool Students Learn to Reason Statistically T h r o u g h Simulation Activities? Helena P.
 Osana osana@macc.
wise.
edu Sharon J.
 Derry sderry@macc.
wisc.
edu Department of Educational Psychology University ofWisconsinMadison 1025 W Johnson Street Madison, Wisconsin 53706 Joel R.
 Levin levin@macc.
wise.
edu Abstract This paper describes the implementation and quasiexperimental evaluation of a threeweek instructional project designed in accordance with theories and assumptions of constructivism and socially situated cognition.
 Our goal was to develop students' ability to reason about reallife problems, where "good reasoning" was conceptualized in terms of a normative thinking model derived from cognitive research in decision making, probabilistic reasoning, and argumentation.
 In the spring of 1994, students in two middle school classrooms worked in teams that collected evidence, constructed arguments, and prepared presentations while engaged in activities that culminated in a mock legislative hearing.
 Through instruction and mentoring, students were encouraged to use statistics and probability as tools for reasoning.
 The effectiveness of the program was evaluated by comparing the written arguments of students from the two treatment classrooms with those of students from eight comparison classrooms.
 Students' arguments were scored in terms of how well they captured essential features of model reasoning and avoided particular thinking fallacies.
 That the reasoning abilities of students developed through social negotiation and shared problem solving was suggested by findings showing significant differences in performance between treatment and comparison classrooms.
 This study examined the effects of a threeweek instructional unit implemented in two middleschool classrooms during the spring of 1994, for the purpose of improving students' individual and social thinkmg skills within realworld problem contexts.
 Our instructional approach assumed that theories of probability and statistics provide reasonable normative models upon which to build knowledge about "good thinking," an assumption supported by scholarly argument, theory, and empirical research (Kahneman &.
 Tversky, 1973; Kuhn, 1991; Nickerson, 1991).
 Our approach also assumed that processes of social negotiation and shared problem solving within meaningful, activityoriented environments are integral components of "realworld" apprenticeship that can and should oe modeled in the classroom (Brown, Collins, & Duguid, 1989; The Cognition and Technology Group at Vanderbiit, 1990; Dewey, 1938; Greeno, 1989; Lave, 1991; Resnick, 1987; Vygotsky, 1978).
 The idea that all learning is situated, in that it emerges from the physical, cognitive, and social contexts in which it occurs, permeated our research efforts.
 W e draw from researchers who have pointed to the importance of context and culture in the attempt to understand children's thinking, and from classroom research that appropriates the socially situated cognition perspective (see Brown & Campione, 1990; Lave, 1992; Resnick, Salmon, Zeitz, Haley Wathen, & Holowchak, 1993).
 Consistent with these views, students in our study were introduced to concepts about argument, evidence, statistics, and research, as these concepts were needed to help them make sense of issues that arose during viewing and discussion of a popular film (Lorenzo's Oil).
 Then, students were expected to employ and extend this knowledge in the context of smallgroup research activity that required them to take a position on a particular issue that was present in the news of the time  government regulation of the vitamin and dietary supplement industry.
 Finally, students were required to present and defend their arguments and counterarguments within the context of a fourday mock legislative hearing wherein the fate of a proposed regulatory Bill was decideoT During activities, researchers and teachers were present in the classrooms as mentors w h o attempted to coach and scaffold students' transitions from novices to more skilled reasoners (Collins, Brown, & N e w m a n , 1989).
 Our study can appropriately be viewed as a "design experiment' (Brown, 1992) in that it tested the efficacy of instructional design based on the theoretical assumptions outlined above.
 A s the activities and simulation format obliged students to work collaboratively in small groups within the context of particular problems, and as relatively little direct instruction was provided, w e hoped that students would be able to construct useful knowledge through social negotiation and shared problem solving, and that this knowledge would enable them to reason more effectively about realworld problems.
 W e hypothesized that the students would acquire greater understanding of the inherent uncertainty in the world, and would acquire knowledge of probability and statistics as tools for thinkmg about problems.
 To obtain evidence regarding the effects of instruction, w e compared both the individual and social reasoning of students w h o received the intervention to that of students from comparison classrooms that did not participate in the program.
 The basis for this comparison was students' written responses to questions about fictional court scenes.
 Based on a detailed coding system derived from our theoretical analysis of what constitutes good and fallacious thinking in these contexts, student responses were coded by trained raters for evidence of statistical and nonstatistical thinking.
 Mean comparisons between treated and nonUeated classrooms indicated that a nondirect, simulationbased instructional approach can foster maturation of students' reasoning,skills.
 Details follow.
 Method The investigation was conducted in a racially integrated and socioeconomically diverse middle school in the Midwest.
 Ten intact, homebase classrooms in the eighth grade participated in the study.
 These classes had not been constituted with respect to ability, race, or socioeconomic status.
 409 mailto:osana@macc.
wise.
edumailto:sderry@macc.
wisc.
edumailto:levin@macc.
wise.
eduT w o of the 10 classrooms received the instructional treatment.
 One social studies teacher and one science teacher offered their homebase classes for the administration of the intervention.
 The remaining eight classrooms served as comparison classrooms.
 Pretest and posttest measures were admmistered to all classes to measure the development of statistical reasoning in the treatment groups.
 In addition, videotape data were collected during the instructional simulation in the two treatment classrooms, although the current paper will focus primarily on the quantitative analysis.
 Pretest and Posttest Instruments All students in the 10 classrooms received a paperandpencil pretest one week before the start of the instructional treatment.
 There were two forms of the test; half the students received one form and the other half received the other.
 Each form consisted of a transcript of a fictional courtroom drama (inspired by the popular television show, "Law and Order"), followed by two questions requiring students to take a side or position on the drama and then to provide written justifications for their position.
 O f the two questions, one required statistical thinking for an appropriate justification; the other did not.
 W e were interestea in testing whether or not statistical knowledge, if learned, would be inappropriately generalized; that is, whether or not the students would apply statistical reasoning to a situation where it was not appropriate.
 The first form of the test (the Andrevil Trial) involved a boy named Kenny w h o suffers from a severe form of cancer.
 His mother voluntarily agreed to allow her son to participate in Dr.
 Birch's experiment in which an experimental drug, Andrevil, is tested.
 In the scene, Kenny and his mother are suing the doctor because Kenny's condition had only deteriorated throughout the course of the experiment.
 The doctor wishes to complete his experiment (with Kenny as a participant) and arrive at a valid conclusion about the effects of the drug.
 In the second version (John's Trial), a voung boy is tried in adult court for violently harming a friend.
 The lawyer defending him argues that John is not responsible for his actions because he possesses an extra ychromosome, a condition shown in the 1960s and 1970s to be linked to violent behavior.
 The prosecuting attorney claims that the results of those studies are inconclusive and thus cannot be used as evidence in the case.
 The posttest was administered approximately 10 days after the instructional intervention had been implemented.
 Students who received the Andrevil Trial on the pretest received John's Trial on the posttest, and vice versa.
 Testing Procedure To enable us to assess the effects of treatment on both individual and social reasoning, students were either tested individually or in groups.
 With each classroom, a random sample of 4 to 5 students was chosen to take the pretest individually in the library.
 The remaining students in the two treatment classrooms had been assigned to instructional groups by their teacher, and these were maintained during testing.
 In the comparison classrooms, the students were randomly assigned to groups of 4 to 5 students.
 In the library, the stucients were told to work without communicating with their neighbors.
 They were given 12 minutes to read the text, and 5 minutes to respond to the questions.
 The students working in small groups in the classrooms were given 12 minutes to discuss the story amongst themselves, but each student was required to provide individual responses to the questions, and was given a separate response sheet with which to do so.
 Students were given 5 minutes to respond to the questions, but were permitted to discuss their answers with other group members.
 Instructional Intervention In each of the two treatment classrooms, the intervention lasted approximately three weeks.
 Each teacher offered one 70minute class period each day during this 3week period.
 These 70 minutes consisted of the students' regular 50minute class time with the addition of a 20minute homebase period.
 The first four days of the instruction concentrated on viewing and discussing important issues raised in the film Lorenzo's Oil.
 This film served as a vehicle for introducing topics related to reasoning with stafistics and probability, evidence and argumentation, and medical research.
 Smallgroup discussion guides were designed to encourage appropriate thinking about important statistical and scientific issues.
 Class discussions following smallgroup activities were orchestrated by the teacher and project researchers.
 The next three days consisted of three instructional units that focused on statistical concepts, evidence and argumentation, and effective communication of data and arguments, respectively.
 These units were taught by the project researchers in collaboration with the teachers.
 During the next eight days, students participated in the simulation activity.
 They were placed in small groups that represented interest groups that actually existed within the community: those w h o opposed regulation, those who were in favor of regulation, ana triose who held balanced positions on the issue, such as the legislature and the press.
 Within each group, each student played the part of a particular m e m b e r of the community, and their duties and responsibilities were outlined.
 In general, students remained in tne same groups for both instruction and testing.
 The legislative group was asked to draft a bill proposing some form of regulation of the vitamin and dietary supplement industry.
 The ultimate responsibility of the legislature was to decide the fate of this bill after considering arguments presented during a fourday mock legislative hearing by the pro and antiregulation groups.
 Before the hearing, the students in pro and antiregulation groups worked within their groups studying data pertaining to the issue (made available to them by the researchers), developing arguments and counterarguments, and preparing to present their positions at the hearing.
 The teacher and the project researchers mentored the activities of small groups.
 The aim of mentoring was to help keep the students motivated, structure their activities, remind them of pertinent statistical concepts, and monitor their metacognitive strategies.
 Analysis and Results A few introductory comments must be made before reporting the results of this study.
 First, it was not possible to assign the 10 participating eighthgrade classrooms to treatment and control conditions.
 This, in the face of positive effects, of course limits our ability to argue that the intervention directly caused the improvement in statistical reasoning abilities in the two treatment classrooms.
 To the greatest extent possible, this limitation was addressed in our statistical analyses.
 Second, the individual students in the 10 classrooms were not regarded as the "units of analysis" (see Levin, 1992) because withinclassroom independence among students could not be reasonably assumed.
 Indeed, one objective of the study was to help the students build cooperative reasoning skills.
 The treatment required that the students work together in small groups within each classroom; the performance of the individuals engaged in these joint problemsolving activities affected the thinking and learning of the other stuaents in the class, both during the simulation and while being tested.
 Therefore, classrooms served as the units of analysis for this study.
 The first results reported are based on students' responses to the statistical question on both the pretest and posttest measures (as opposed to the nonstatistical question).
 The analyses for both pretest and posttest performance were 410 conducted with testing condition (individual versus group testing) and story version (the Andrevil Trial and John s Trial) as two witninclassroom factors.
 For further details regarding the analyses conducted, see Derry, Osana, Levin, & Jones (in press).
 Scoring The written responses on both the pretest and posttest were coded using a scheme developed by the researchers.
 This assessment rubric was based on a theoretical model for good reasoning representing a synthesis of research and theory on normative thinking models, statistical reasoning, and evidential argument (e.
g.
, Kahneman & Tversky, 1973; Konold, 1989; Kuhn, 1991; Shaughnessy, 1992).
 The scheme comprised 13 categories, eacn one representing one way in which an argument can be (correctly or incorrectly) supported.
 More specifically, categories were assigned for usmg correlational reasoning, for considering the degree of strength of relationships, and for referring to specific counterpositive evidence.
 Categories were also developed for recognizing the distinction between real and chance relationships, for noting that correlation does not imply causation, for taking into account methodological quality of the research, for realizing that further research might be needed before conclusions can be drawn, and for commenting on any risk/benefit tradeoffs.
 Categories were additionally developed for responses that included elements of deterministic reasoning (Konold, 1989) and unsubstantiated opinion.
 For a complete description of this scoring scheme, see Derry et al.
 (in press).
 Point values were assigned to each of the categories in the scoring scheme.
 Higher values were attached to the categories that were central to model responses developed for each story (Andrevil Trial and John's Trial).
 Negative point values were assigned to undesirable responses.
 A n overall score was computed for each student and each question by summing together the values representing points awarded or subtracted for a particular response.
 Student scores were in turn averaged to obtain a smallgroup mean, and these were averaged to obtain a mean for the class.
 Findings Statistical question.
 There was no significant difference between the mean of the experimental classrooms on the pretest and the mean of the comparison classrooms, F < 1.
 (Missing data for one of the repeated measures cells required that one comparison classroom be dropped from this analysis).
 The analysis of posttest performance was conducted after adjusting students' posttest scores by their corresponding pretest scores (Levin & Serlin, 1993).
 All subsequent results reported here are based on these adjusted posttest scores.
 The mean on the posttest for the experimenta classrooms (3.
61) was statistically higher than the mean for the comparison classrooms (2.
27), L(7) = 2.
21, p = .
032, onetailed  a result confirmed by an exact permutation test.
 In addition, the main effect of story version was found to be statistically significant, with the mean of the posttest scores on the Andrevil Trial (3.
88) higher than the corresponding mean on John's Trial (2.
00), L U ) = 3.
19, p = .
015.
 The main effect of testing condition was found not to be significant, and no interactions were detected.
 Nonstatistical question.
 We were interested in seeing whether or not the students who received the instructional intervention would overgeneralize their knowledge and apply statistical reasoning to the nonstatistical question on the josttest.
 In other words, did these students transfer their cnowledge of statistics to a situation in which statistical reasoning was not appropriate? The answer to this question, it seems, is no.
 The students in the treatment classrooms were compared to the performance of the students in the comparison classrooms on the posttest.
 Again, the classrooms were used as the units of ana ysis and testing format was the within classroom factor.
 Virtually no students in any of the 10 classrooms w h o received John's Trial on the posttest used statistical reasoning on the nonstatistical question.
 For the Andrevil Trial, no statistical difference was found between the nonstatistical question mean of the posttest scores for the two experimental classrooms (1.
37) and the corresponding mean for the eight comparison classrooms (1.
24), L < 1 in absolute value.
 Discussion Possessing welldeveloped higherorder thinking skills and reasoning abilities is becoming increasingly important in the face of the complex problems of our constantly changing world.
 Thinking about, and considering solutions to, social and scientific problems requires not only knowledge and information from various domains, but also processoriented skills such as thinking statistically and making reasoned decisions.
 Furthermore, problems that are complex and uncertain in nature cannot he solved by one person working alone; they require the planning, evaluating, and decision making or people working in teams.
 Dealing with problems of global proportions, such as A I D S and overpopulation, or even problems of local interest, such as building a new school in the community, demands the joint knowledge and problemsolving efforts of various people.
 It has become imperative, therefore, to examine whether and how such complex reasoning skills can best be developed by schools.
 This was the purpose of our study, which constituted a "design experiment that tested an approach to thinkingskills education based on socially situated cognition.
 W e hypothesized that students would develop statistical reasoning abilities, knowledge about effective argumentation, and collaboration skills, by engaging in an activity that simulated realworld practice.
 When their arguments were judged against models of good thinking grounded in cognitive research on statistical reasoning and evidential argument, students in two classrooms that participated in our threeweek instructional program performed statistically better than students in eight comparison classrooms that did not participate.
 Also found was that the students who participated in the instructional urogram did not inappropriately transfer what they had earned.
 They apparently were able to discriminate between contexts in which statistical reasoning was appropriate and contexts in which it was not.
 As mentioned earlier, w e cannot draw definite causal conclusions from the results.
 W e maintain, however, that the results suggest that our instructional intervention was instrumental in helping students build statistical reasoning abilities, as well as develop knowledge about argumentation and collaboration.
 To strengthen the claim that our intervention contributed to student learning, this study needs to be replicated with various improvements.
 Other than ensuring the equivalence of treatment and control groups through randomization, refinements to the instructionalunits, the simulation activities, and the materials provided to the students are needed.
 T o the extent that our study represented a quasiexperimental test of instructional design based on a "situated social practice model" (Derry & Lesgold, in press), our results should encourage educators who believe that effective thinkingskills instruction should emulate the mentored, situated, social interactions that foster natural evolution of individual and social thinking abilities.
 Acknowledgments Funding for this project was provided by the National Center for Research in Mfathematical Sciences Education.
 The authors acknowledge significant contributions by Velma Hamilton Middle School Teachers T o m Bauer, K i m 411 Vergeront, Doris Dubielzig, and Joan Unmacht.
 W e also thanK Leona Schauble for her assistance with instruction and for many valuable suggestions throughout the project.
 Jasmina Milinkovic is thanked for help in planning and data collection.
 Ian Duncan, of the University of WisconsinMadison Department of Veterinary Medicine, is thanked for his presentation on A L D and the film "Lorenzo's Oil".
 References Brown, A.
 L.
 (1992).
 Design experiments: Theoretical and methodological challenges in creating complex interventions in classroom settings.
 The Journal of the Learning Sciences.
 2.
 141178.
 Brown, A.
 L.
, & Campione, J.
 C.
 (1990).
 Communities of learning and thinking, or a context by any other name.
 Human Development.
 21, 108125.
 Brown, J.
 S.
, & Collins, A.
, & Duguid, P.
 (1989).
 Situated cognition and the culture of learning.
 Educational Researcher.
 18(1).
 3242.
 The Cognition and Technology Group at Vanderbilt (1990).
 Anchored instruction and its relationship to situated cognition.
 Educational Researcher, 19 (6), 210.
 Collins, A.
, Brown, J.
 S.
, & Newman, S.
 E.
 (1989).
 Cognitive apprenticeship: Teaching the crafts of reading, writing, ana mathematics.
 In L.
 B.
 Resnick (Ed.
), Knowing, learning, and instruction.
 Essays in honor of Robert Glaser (pp.
 453494).
 Hillsdale, NJ: Erlbaum.
 Derry, S.
 J.
, & Lesgold, A.
 (in press).
 Instructional design: Toward a situated social practice model.
 In D.
 C.
 Berliner & R.
 C.
 Calfee (Eds.
), Handbook of educational psychology.
 New York: Macmillan.
 Derry, S.
 J.
, Osana, H.
 P.
, Levin, J.
 R.
, & Jones, M.
 (in press).
 Statistical gaming.
 To appear in S.
 Lajoie (Ed.
), Reflections on statistics: Agendas for learning, teaching and assessment in K12.
 Hillsdale, NJ: Erlbaum.
 Dewey, J.
 (1938).
 Experience and education.
 N e w York: Collier Books.
 Greeno, J.
 G.
 (1989).
 A perspective on thinking.
 American Psychologist.
 44 (2), 134141.
 Kahneman, D.
, & Tversky, A.
 (1973).
 On the psychology of prediction.
 Psychological Review.
 80.
 pp.
 23751.
 Konold, C.
 (1989).
 Informal conceptions of probability.
 Cognition and Instruction.
 6.
 5998.
 Kuhn, D.
 (1991).
 The skills of argument.
 New York: Cambridge University Press.
 Lave, J.
 (1991).
 Situated learning in communities of practice.
 In L.
 B.
 Resnick, J.
 M.
 Levine, & S.
 D.
 Teasley (Eds.
), Perspectives on socially shared cognition (pp.
 6384).
 Washington, D.
 C : American Psychological Association.
 Lave, J.
 (1992).
 Word problems: A microcosm of theories of learning.
 In P.
 Light & G.
 Butterworth (Eds.
), Context and cognition: Ways of learning and knowing (pp.
 7492).
 Hillsdale, NJ: Lawrence Erlbaum.
 Levin, J.
 R.
 (1992).
 On research in classrooms.
 MidWestern Educational Researcher, 5, 26, 16.
 Levin, J.
 R.
, & Serlin, R.
 C.
 (1993, Apr.
).
 No wav to treat a classroom: Alternative unitsappropriate statistical strategies.
 Paper presented at the annual meeting of the American Educational Research Association, Atlanta.
 Nickerson, R.
 S.
 (1991).
 Modes and models of informal reasoning: A commentary.
 In J.
 F.
 Voss, D.
 N.
 Perkins, & J.
 W .
 Segal (Eds.
), Informal reasoning and education (pp.
 291  309).
 Hillsdale, NJ: Lawrence Erlbaum.
 Resnick, L.
 B.
 (1987).
 Learning in school and out.
 Educational Researcher.
 16.
 1320.
 Resnick, L.
 B.
, Salmon, M.
, Zeitz, C.
 M.
, Haley Wathen, S.
, & Holowchak, M.
 (1993).
 Reasoning in conversation.
 Cognition and Instruction.
 11 (3 & 4), 347364.
 Shaughnessy, J.
 M.
 (1992).
 Research in probability and statistics: Reflections and directions.
 In D.
 A.
 Grouws (Ed.
) Handbook of research on mathematics teaching and learning (pp.
 465494).
 Reston, VA: National Council of Teachers of Mathematics.
 Vygotsky, L.
 S.
 (Trans.
, 1978).
 Mind in society: The development of higherpsychological processes (M.
 Cole, V.
 JohnSteiner, S.
 Scribner, & E.
 Souberman, Eds.
 and Trans.
) Cambridge, M A : Harvard University Press.
 412 Calculation a n d Strategy in the Equation Solving T u t o r Steven Ritter Department of Psychology Camegie Mellon University Pittsburgh, Pa.
 15213 sritter@cmu.
edu John R.
 Anderson Department of Psychology Camegie Mellon University Pittsburgh, Pa.
 15213 j a@ andrew.
emu.
edu Abstract This paper examines performance on an intelligent tutoring system designed to teach students in a firstyear algebra class to solve simple linear equations.
 W e emphasize the effects of requiring students to complete lowlevel arithmetic operations on higherlevel strategic decisions.
 On aX + b = c problems, students who were required to perform arithmetic became less likely to solve such problems by first dividing by a than students who were not required to perform the arithmetic required to carry out the ojjeration.
 The shift away from this strategy is in keeping with the predictions of ACTR.
 W e discuss these results in terms of the educational implications of providing computational tools to students learning basic mathematics.
 Introduction The availability of lowcost calculators has changed the way mathematics is taught.
 Where arithmetic skills such as long division were once given strong emphasis in the early grades, they are now seen as less important, on the assumption that students in higherlevel mathematics courses will have access to calculators.
 A similar transformation can be expected in high school algebra classes as lowcost calculators capable of complex symbol manipulation become available (Fey, 1989).
 The reaction to these changes has been mixed.
 O n the one hand, many educators welcome the availability of such tools, believing that they will allow students to concentrate on more suategic problemsolving skills and the conceptual structure of the domain rather than being held back by the requirement that they master the rather lowlevel skills now being performed by calculators.
 On the other hand, many educators worry that students cannot really understand mathematical problemsolving skills without a firm grounding in the basic skills of arithmetic and symbol manipulation.
 Without knowledge of the basic skills, the argument goes, students' problem solving becomes an exercise in applying a meaningless (to the student) algorithm.
 Our focus here is on a more subtle effect of the loss of the use of lowlevel skills on higherlevel tasks.
 W e look at how the requirement that students perform arithmetic computations affects their strategic planning when they solve equations.
 Our data shows that students w h o were released from the requirement to perform arithmetic computations when they solve problems of the form aX+b=c were more likely to divide by the coefficient a as a first step to solving the problem.
 Furthermore, we show that students who were so biased were at a disadvantage when asked to solve such problems in a context where they were required to perform the arithmetic calculations.
 The disadvantage results not from an inability to complete the arithmetic but from a learned bias to use a strategy that is less effective in the new context.
 Our data is taken from performance on an intelligent tutoring system designed to teach students in a firstyear algebra class to solve simple linear equations.
 The tutor provides assistance intermediate between unassisted equation solving with pencil and paper and a more powerful system in which students can solve equations simply by pushing a "solve" key.
 In some conditions, students are required to complete the arithmetic operations required to solve problems.
 In other conditions, the computercalculates these operations for the students.
 Overview of the Tutor The Equation Solving Tutor (EST) is one of a class of ACTbased modeluacing tutors developed using the Tutor Development Kit (Anderson and Pelletier, 1991).
 Such tutors contain an expert system capable of solving problems in the domain.
 W h e n students perform an action, the tutor checks to see if the action is one that the expert system would take in this situation.
 If so, the student proceeds uninterrupted.
 If not, the tutor signals an error.
 Errors can be signaled in one of two ways.
 In "immediate feedback" mode, the tutor beeps when it detects an error, and it removes the offending action.
 In "flag feedback" mode, the tutor beeps but the erroneous action remains.
 The action is printed in a different style than correct actions, so that students can immediately identify their error.
 None of the analyses presented here were affected by feedback mode, so we combine data from the two modes.
 At any time, the student can ask for help, which the tutor gives by examining the action the expert system would take in the student's situation.
 Some additional rules, called "buggy rules," are used to identify and give immediate remediation for common student errors.
 The tutor tracks the students competence on a number of underlying skills (corresponding to rules in the expert system), so that it can 413 mailto:sritter@cmu.
edupresent problems tailored to address weaknesses in the student's understanding (Corbett and Anderson, 1992; Anderson and Corbett, 1993).
 The tutor presents students with a linear equation which they are to solve (see Figure 1).
 A menu offers them four choices for transforming the equation: "Add to both sides," "Subtract from both sides," "Divide both sides" and "Multiply both sides.
" After picking any of these options, the student is prompted for a value to add, subtract, multiply or divide.
 Three additional options are available for simplifying an equation: "Combine like terms," "Reduce fractions," and "Multiply through.
" Students need to qualify these actions by indicating whether the simplification should be performed on the left side, right side or both sides of the equation.
 In addition to these items, there are menu options which can be used to distribute, convert fractions to decimals, indicate completion of the problem, undo the last step or ask for help.
 S t u d e n t s Students taking Algebra I in three of the Pittsburgh Public Schools used the tutor.
 146 students at Langley High School used the tutor for four consecutive class periods in December of 1993.
 204 students at Brashear and Carrick High Schools used the tutor for four class periods in March and April of 1994.
 Since the Langley students used the tutor earlier in the school year, and since there were some modifications to the tutor before it was used at Brashear and Carrick (noted below), w e report results from Langley separately from those from the other schools.
 At all schools.
 the classes emphasized algebraic problem solving rather than the kind of symbol manipulation being taught by the EST, so the majority of students' class instruction in equation solving was with EST.
 Calculation Conditions The requirement that students perform arithmetic calculations in the context of solving problems varied between classes.
 The two main calculation conditions will be referred to as "computercalculates" and "studentcalculates.
" In the computercalculates condition, students needed to specify the strategic actions required to solve the equation, but they did not have to compute the results of this action.
 For example, if the equation was X=10/32/3, the student could pick "Combine like terms [right side]" and the computer would respond with X=8I3.
 In contrast, in the studentcalculates condition, after specifying "Combine like terms [right side]", the student would be prompted with X = R I G H T .
 The student then needed to click on the word "RIGHT" and type the resulting right side.
 At Brashear and Carrick High Schools, there were two computercalculates conditions.
 In the "student simplifies" variant, the computer carried out calculations without simplifying the equation.
 For example, if a student indicated that the tutor should "Subtract 3 from both sides" of the equation X+3=10, the tutor would respond with X+33=103.
 The student then needed to pick "Combine like terms [both sides]" to see the final equation, X = 7.
 In the "tutor simplifies" variant, the computer responded to the "Subtract 3 from both sides" command with the final equation.
 At Langley High School, only the "student simplifies" variant Solver Students Rdd to both sides.
.
.
 Subtract from both sides.
.
.
 Multiply both sides.
.
.
 Diuide both sides.
.
.
 Combine Like Terms.
.
.
 Multiply Through.
.
.
 Reduce Fractions.
.
.
 Distribute Conuert fraction to decimal Done Undo last step HELP El 21+3 = 11 Subtract 3 2X = 113 = RIGHT Figure 1: The menu and main window of E S T in calculate, flagfeedback mode.
 The highlighted actions have been identified as errors by the tutor 414 of the computercalculates condition was used.
 Since our interest here is in the difference between the sludcnicalculates and computercalculates conditions, in most cases, our data combines the "tutor simplifies" and "siudciu simplifies" variants.
 In the studentcalculates condition, students could (but did not have to) enter a simplified version of the equation.
 For example, a student in the studentcalculates condition, after subtracting 4 from both sides of X+4=10 would be prompted with L E F T = R I G H T .
 The student could then click on the word L E F T and enter X and click on the word R I G H T and enter 6.
 In practice, the vast majority of students chose to enter the simplified version of the equation.
 Choosing to subtract 4 from both sides will be referred to as a strategic action.
 Entering the results "X" and "6" will be referred to as calculations.
 Students in the studentcalculates condition were able to use a standard (nonsymbolic) calculator if they wished.
 Thus, the difference between the calculation conditions was not so much that students in the studentcalculates condition needed to rely on their arithmetic skills but that they needed to understand not only which strategic actions were appropriate but how to carry out these actions.
 For example, a student in the studentcalculates condition might know that subtracting 4 is the appropriate action in X + 4 = 1 0 but may not understand the way that subtracting 4 transforms the equation.
 In the computercalculates condition, the student can give the "subtract 4" instruction and let the computer show the result.
 In the studentcalculates condition, the student needs to understand the effect of that action.
 Procedure Students were administered a paperbased pretest by their teachers the day before starting the tulor^.
 In their first day using the tutor, the teacher guided students through the first two or three problems.
 After that, they were free to work at their own pace.
 Although students were encouraged to ask the tutor for help when they had problems, the teacher was available to help students individually.
 Following the four class days on the tutor, a paperbased posttest identical in format to the pretest was given.
 Students were allowed to use nonsymbolic calculators on the pre and posttests.
 Curriculum Students progressed from easier to more difficult problems.
 In each section, students had to complete a small number of required problems.
 If a student did not demonstrate mastery of the skills being uaced in the section (as determined by the knowledge tracing algorithm described in Corbett and Anderson, 1992), additional problems targeted at the deficient skill were given until mastery was demonstrated.
 ^Due to scheduling problems, three of the classes at Langley High School did not take pre or posttests.
 Taking absenteeism in other classes into account, data from the pre and posttests is based on 70 students at Langley and 127 students at Brashear and Carrick.
 Since the amount of time students spent on the tutor was limited, students progressed to different levels of achievement.
 The curriculum used at Brashear and Carrick High school differed from that used at Langley, primarily in that problems presented in the first section at Langley were split into three sections at Brashear and Carrick.
 The curriculum is summarized in Table 1.
 Predictions The contrast between the calculation conditions provides us with a chance to see whether the requirement that student perform arithmetic calculations affects decisions at the strategic level.
 Consider the equation 3X+4=10.
 In order to solve for X, we need to isolate the X term (by subtracting 4 or adding 4) and remove the coefficient of X (by dividing by 3 or multiplying by 1/3).
 Typically, students isolate the X term first, perhaps because doing so avoids creating the intermediate fractions 4/3 and 10/3.
 This can be an important consideration for students who have difficulty manipulating fractions.
 In the computercalculates condition, however, there is little incentive to isolate the X term first, since the computer will take care of combining the fractions.
 According to the A C T  R theory (Anderson, 1990), productions are selected based on their expected utility.
 This utility, in turn, depends on an estimate of the probability that the production will succeed and an estimate of the probability that the goal will be reached, given that the production succeeds.
 Thus, the theory predicts that students choosing between the "subtract first" and the "divide first" strategy will consider both the probability that they will be able to specify the first operation and the probability that, if they specify that operation correctly, they will still be able to correctly solve the problem.
 This leads to four predictions: 1.
 Although students may be initially biased to use the subtractfirst strategy, this bias should be no stronger in the studentcalculates condition than in the computercalculates condition.
 2.
 Since the "dividefirst" strategy creates fractions (with which students typically have trouble), students in the studentcalculates condition will have difficulty completing problems which they have started with that strategy.
 In the computercalculates condition, in contrast, the presence of fractions causes no special difficulties.
 Thus, students in this condition will likely succeed with the dividefirst suategy.
 3.
 Students in the studentcalculates condition will be unlikely to return to the dividefirst strategy on subsequent problems, since they have experienced failure with the strategy.
 Students in the computercalculates condition will return to the dividefirst strategy, since they are successful with it.
 4.
 Students in the computercalculates condition who are successful using the dividefirst strategy will be less successful on the paperbased posttest, where the strategy is less effective.
 415 R e s u l t s Table 2: Percentage of student using dividefirst strategy on at least one problem Initial Bias In prior instruction on equation solving, students have likely been told to use the subtractfirst strategy.
 Thus, w e should expect to see many students use that strategy exclusively.
 If students understand the way that the effectiveness of the dividefirst strategy varies with calculation condition, w e might expect students in the computercalculates condition to try the strategy more often than those in the studentcalculates condition.
 In order to assess the relative bias against the dividefirst strategy in the two conditions, w e measured the percentage of students using the dividefirst strategy on at least one problem.
 As shown in Table 2, there was no initial bias at Langley ( X (1)<1).
 but at Brashear and Carrick, students in the computercalculates condition were more likely to try the dividefirst strategy, X (1)=20.
0, p<.
01.
 Since Brashear and Carrick students were tested later in the year, it may be the case that they already had enough experience with these types of problems to understand the implications of the dividefirst strategy.
 However, overall, as predicted, subjects showed a bias against the dividefirst strategy, and this bias was stronger in the calculate condition.
 School Langley Brashear/Carrick Studentcalculates 24 19 C o m p u t e r calculates 29 49 Effectiveness of dividefirst strategy W e consider a stfategy to be effective if a student is able to completely solve a problem following that strategy.
 A failure of the suategy is recorded if, for example, a student starting by dividing by the coefficient of X and then selected "undo last step" and continued by subtracting the constant and later dividing by the coefficient of X.
 As expected, students in the "nocalculate" condition were much more successful in the dividefirst strategy than students in the "calculate" condition (at Langley, X (1)=55.
5; at Brashear and Carrick, ;t^(l)<56.
7, both p<.
01).
 Table 3: Percentage of problems started with dividefirst strategy that were completed with that strategy School Langley Brashear/Carrick Studentcalculates 32 50 C o m p u t e r calculates 84 97 Table 1: Curriculum used with the E S T Section 1.
 Addition and subtraction, integers 2.
 Multiplication and division, integers dividing evenly (included in section 1 at Langley) 3.
 Multiplication and division, integers not dividing evenly (included in section 1 at Langley) 4.
 Singletransformation, decimals 5.
 T w o transformations, integers 6.
 T w o transformations, decimals 7.
 Variables on both sides, integers and decimals (at Langley, fractions problems were included) 8.
 Singletransformation, fractions (not used at Langley) 9.
 T w o transformations, fractions (at Langley, this section came before the "variables on both sides" section) 10.
 Distribution, decimals, fractions and integers 11.
 Variable in the denominator of a fraction, integers, fractions and decimals Example problems 13 = lItX Y+4=20 Y=20 25=5X 6Y=36 4Y=27 3X=20 Y2.
5= 11.
13 3.
9 = 8.
43X 6Y11 = 10 8 = 92(Y 3.
08+83.
09Y = 8.
28 36.
65 = 49.
530.
59Y 4llY = 722Y 9.
47(7.
88Y = 88.
493.
1 lY 4Y/3 = 20 Yil/2=30 1/3 = 4Y/7(7/12 3 = lli8Y/5 8.
61 = 12.
36(1.
69X43.
33) 7 = 63(7+71X) 15.
85/(92.
85Y) = 55.
94 8/(llY) = 6/5 416 Subsequent use of dividefirst strategy The ACTR theory predicts that students who have failed to solve a problem with the dividefirst strategy will be unlikely to return to this strategy.
 As Table 4 shows, this prediction is confirmed.
 Note that following the dividelirst strategy in the calculate condition requires (at least) two separate productions: one to select the action to perform ("divide by the coefficient") and another to perform the division (e.
g.
 divide 3X by 3 to get X).
 Students' change of strategy is not based their failure to correctly select the action; in fact, it is by the correct specification of this action that we classify students as having started to solve with the dividefirst strategy.
 Rather, the students' failure is in the later calculation production.
 Nevertheless, the next time students are in this situation, they are less likely to use the dividebycoefficient selection production.
 In ACTR's terms, the estimate of the selection production's success increases (since it was successfully executed), but the estimate of the probability of reaching the goal, given the production's success, decreases because of later difficulties in performing the division.
 Table 4: Number of times students return to dividefirst strategy after using it once School Langley Brashear/Carrick Studentcalculates 0.
36 0.
86 C o m p u t e r calculates 2.
06 4.
89 Performance on the posttest Finally, we predict that students in the nocalculate condition who tried the dividefirst strategy on the tutor will perform worse on the posttest than students in the calculate condition who tried the dividefirst strategy.
 This is because students in the nocalculate condition will be encouraged to use the strategy on the posttest while subjects in the calculate condition will be discouraged from using the strategy.
 W e also assume that the strategy will be relatively ineffective on the paperbased posttest (as it was in the "calculate" condition on the tutor).
 The posttest data for students who attempted the dividefirst strategy are presented in Table 5.
 A n analysis of variance shows no effect in the Langley data, F(1,32)<1.
 The Brashear and Carrick data show a significant effect, F(l,52)=5.
31, p<.
05.
 At Brashear and Carrick, students in the calculate condition who tried the dividefirst strategy (and likely failed ai the strategy) benefited more from the tutor than students who never uicd it at all (34% vs.
 17%).
 At Langley, students who never û ied the dividefirst strategy benefited more from the tutor (a 3 8 % improvement) than students who tried it in either condition.
 Table 5: Percent improvement from pre to posttest for students who tried the dividefirst stfategy School Student Computercalculates calculates Langley 9 12 Brashear/Carrick 34 13 D i s c u s s i o n This study used data from a computerbased tutoring system to explore how the requirement that students perform arithmetic calculations while solving equations affects the highlevel strategies they follow.
 Our results show a shift in strategy that is consistent with the predictions of the A C T  R theory.
 The shift is somewhat unusual in that it dejjends on a decrease in the probability of reaching the goal following the successful application of a production, rather than a shift away from using the production following a failure of the production itself.
 While our data shows that students w h o were biased towards the dividefirst strategy were at a disadvantage on a paperbased posttest, we must be cautious about making any conclusions based on these data about the proper use of technology in the mathematics classroom.
 Overall, we found no significant differences due to calculation condition in posttest scores (Fs at both Langley and Brashear and Carrick were less than 1.
0).
 Freeing students from having to perform arithmetic calculations has some benefits, as well.
 Students in the computercalculates condition advanced further in the curriculum in their four days on the tutor (significantly at Brashear and Carrick: F(l,147) = 44.
3, p<.
01; nonsignificantly at Langley).
 W e may also question whether performance on a paperbased test constitutes a reasonable measure of performance in a world where powerful calculators are becoming more and more available.
 Finally, while w e have demonstrated that the computercalculates condition biased some students to use a lesseffective strategy on paper, we have not shown that they suffer in their understanding.
 The fact that students at Brashear and Carrick who used the dividefirst strategy and failed tended to perform better on the posttest than those who never tried it provides an intriguing hint, however.
 It is possible that, through their failure, they gained a better understanding of how the different strategies work.
 W e are currently conducting research to explore this possibility.
 References Anderson, J.
R.
 and Corbett, A.
T.
 (1993).
 Tutoring of cognitive skill.
 In J.
R.
 Anderson, Rules of the Mind (pp.
 235255).
 Hillsdale, NJ: Erlbaum.
 Anderson, J.
R.
 and Pclletier, R.
 (1991).
 A development system for modeltracing tutors.
 In Proceedings of the International Conference of the Learning Sciences, 1 8.
 Anderson, J.
R.
 (1990).
 The Adaptive Character of Thought.
 Hillsdale, NJ: Erlbaum.
 Anderson, J.
R.
, Conrad, F.
G.
 and Corbett, A.
T.
 (1993).
 The LISP tutor and skill acquisition.
 In J.
R.
 Anderson, Rules of the Mind (pp.
 143164).
 Hillsdale, NJ: Erlbaum.
 417 Corbett, A.
T.
 and Anderson, J.
R.
 (1989).
 Feedback timing and student control in the LISP Intelligent Tutoring System.
 Proceedings of the Fourth International Conference on AI and Education, 6472.
 Fey.
 J.
T.
 (1989).
 School algebra for the year 2000.
 In Research Issues in the Learning and Teaching of Algebra (pp.
 199213).
 Reston, VA: National Council of Teachers of Mathematics.
 418 Using a WellStructured Model to Teach in an IllStructured D o m a i n Vincent Alevcn and Kevin D.
 Ashley University of Pittsburgh Intelligent Systems Program, School of Law, and Learning Research and Development Center Pittsburgh, Pennsylvania 15260 a l e v e n + ® p i t t .
 e d u , a s h l e y + « p i t t .
 e d u Abstract Our goal is to develop a tutoring system, called CATO, that teaches law students skills of making arguments with cases.
 CATO's domain model provides a plausible account of legal arguments with cases, but is limited in that it does not represent certain background knowledge.
 It is important, however, that students leam to apply and integrate this background knowledge when making arguments with cases.
 Given that modeling this background knowledge is difficult in an illstiuctured domain like legal reasoning, it is worth exploring how effectively one can teach with a model that represents argument structure but relatively little background knowledge.
 The CATO instructional envirormient, comprising a case database and retrieval tools, enables students to apply the CATO model to a specific problem.
 In a formative evaluation study with 17 beginning law students, we compared instruction with the CATO environment, under the guidance of a human tutor, against more traditional classroom instruction not based on the CATO model.
 W e found that humanled instruction with CATO is as good as, but not better than, classroom instruction.
 However, answers generated by the CATO program received higher grades than the students' answers, suggesting that the model can potentially be employed to teach even more effectively.
 Examples drawn fitom protocols show that students were able to use the CATO model flexibly and integrate background knowledge appropriately, at least when guided by a human tutor.
 Introduction In this paper, we report a formative evaluation study of CATO, a computerbased instructional environment for teaching law students skills of making arguments with cases.
 C A T O is based on a computational model of casebased legal argumentation developed in previous research (Ashley, 1990; 1991).
 Legal experts find that arguments based on the CATO model are reasonable, even if they are not always optimal, and that the model provides a plausible account of legal arguments with cases (Rissland, 1990).
 O n the other hand, the model does not represent all types of casebased arguments; nor does it repjresent all background knowledge that human reasoners bring to bear.
 And while the model provides criteria for saying that some arguments are better than others, arguments that do not conform to the model may be reasonable, too, occasionally even better than arguments based on the model.
 W e believe that these characterisThis work is supported by an NSF Presidential Young Investigator Award and grants from the National Center for Automated Information Research, West Pubhshing Company and Digital Equipment Corporation.
 tics are exactly what one would expect in an illstructured domain like legal reasoning.
 Many authors, however, seem to imply that the fact that certain knowledge is not included in a domain model makes it unfit for teaching.
 In order to use the M Y C I N knowledge base for teaching, much knowledge had to be made explicit (Clancey, 1983).
 Also, if a domain model is to be used as a "standard" to evaluate student behavior (Wenger, 1987), the model must be capable, at minimum, of generating all reasonable solutions.
 The domain model of a modeltracing tutor, for example, must generate all solution paths that are worth teaching (Anderson, et al.
, 1990).
 In a domain like legal reasoning, however, one cannot reasonably expect to represent aU background knowledge.
 This domain is illstructured and indeterminate.
 Provably correct answers do not exist.
 The domain involves large amounts of knowledge, legal knowledge as well as knowledge about the regulated domain (e.
g.
, the corporate world), neither of which can be easily circumscribed.
 In light of these difficulties, one has to ask: What contribution can an ITS make in a domain like the current? What knowledge needs to be represented and what can be left unrepresented, and with what effect on instructional efficacy? And if certain knowledge is not represented in a form that the program can understand, is it usefiil to make it available through other means? In this research, w e explore the hypothesis that one can provide useful computerbased practice with a model of casebased argumentation that includes mosdy argumentation knowledge, but contains relatively little knowledge about the legal domain.
 A priori, this hypothesis seems reasonable.
 The C A T O model enables a program to compute the relevance of cases and to generate reasonable arguments.
 Also, the model seems to provide a useful conceptual fiamework for comparing and contrasting cases and making arguments with cases.
 Nonetheless, there is a danger that smdents will rely on the model too much and apply it without drawing on their background knowledge.
 The model is a useful stereotype, but like all stereotypes, it can be overused, taken too seriously, applied too mechanically.
 W e investigated whether a human tutor could employ the C A T O model and instructional environment to teach argumentation skills to beginning law students.
 In a controlled experiment, we compared humanguided instruction with C A T O against classroom instruction that teaches the same material without the use of the C A T O model or tools.
 In this paper, w e describe the C A T O model of casebased argumentation, present the results of oiu" exj)eriment, and discuss examples in which students used the model intelligently, integrating their background knowledge in their arguments.
 419 Aries (p) F4 AgreedNotToDisclose (P) F6 SecurityMeasures (p) F18 IdenticalProducts (p) Ahes (p) Motorola Eaton (d) FlB(p) F16 (d) FUld) FtO (d) Motorola F2 BribeEmployee (p) F4 AgreedNotToDisclose (p) FS AgreementNotSpecific (d) F6 SecurityMeasures (p) F10 SecretsDisclosedOutsiders (d) F17 InfolndependentlyGenerated (d) F20 InfoKnownToCompetitors (d) Eaton (d) F4 AgreedNotToDisclose (p) FS AgreementNotSpecific (d) F6 SecurityMeasures (p) F16 InfoReverseEngineerable (d) F17 InfolndependentlyGenerated (d) F20 InfoKnownToCompetitors (d) Legend (p) Case won by plaintiff; factor favors plaintiff.
 (d) Case won by defendant; factor favors defendant.
 Figure 1: Comparing and contrasting cases in terms of factors.
 C a s e  B a s e d R e a s o n i n g in the Legal D o m a i n While one may think of the law as a system of rules, attorneys very frequently reason with cases: in order to evaluate h o w a problem should be decided, they compare and contrast it to past cases.
 A legal problem is a "fact situation," described in narrative text, about which a legal dispute has arisen.
 The issue to be decided is whether the plaintiff is entitled to some form of legal relief against the defendant.
 Attorneys employ cases for two reasons: Where the legislamre has not provided a detailed statute, an attorney must look to court decisions to determine what the law is and how it has been applied.
 In stamtory domains, attorneys use cases to interpret opentextured terms for which the statute provides no definition.
 Skills of reasoning with cases are important in other domains as well, including practical ethics, business, and political science.
 The C A T O model covers arguments analogizing a problem to past cases and arguments in which past cases are used to emphasize strengths, downplay weaknesses, and cover the opponent's bases (i.
e.
, the weaknesses that the problem presents).
 It also covers responses to such arguments by distinguishing or citing counterexamples.
 The C A T O model provides an abstract argument plan to guide the organization of an overall argimient supported by multiple cases, and a set of relevance criteria for selecting the cases (from any given set of candidates) that will make the most effective argument (Aleven and Ashley, 1993; Ashley and Aleven, 1992).
 In the C A T O model, cases are represented as sets of factors, abstractions of facts that tend to influence the outcome of a legal claim (Ashley, 1990).
 Figure 1 illustrates how an arguer can make arguments about the Motorola problem by comparing and contrasting it to past cases in terms of factors.
 Motorola involved a claim for trade secrets misappropriation; the plaintiff complains that the defendant (often a corporate competitor) has used plaintiffs trade secret (often, valuable product development information) to gain an unfair competitive advantage.
 Let us assume that an arguer has read the narrative description of the Motorola facts and decided that the following factors apply: O n the one hand, it helps the plaintiff that it secured a nondisclosure agreement from the defendant (F4), that it took measures to keep its information secret (F6), and that defendant tried to lure away plaintiff employees by offering a bribe (F2).
 O n the other hand, in defendant's favor, the nondisclosure agreement was not specific as to what plaintiff regarded as its secret (F5), the plaintiff disclosed its alleged secret to outsiders (FIO), the information was known to competitors (F20), and the defendant developed its information through its o w n efforts (F17).
 The Venn diagram indicates h o w Motorola's factors compare to those of two other cases: Aries, a case won by the plaintiff, and Eaton, a case w o n by the defendant.
 The plaintiff in Motorola can cite Aries to support an argument that it should win.
 Aries shares two factors with Motorola: F4 AgreedNotToDisclose and F6 SecurityMeasures, both of which favor the plaintiff.
 Plaintiff can analogize Motorola to Aries, citing the shared factors as relevant similarities and arguing, in effect, that these factors warrant a favorable decision in Motorola (as they did in Aries).
 The defendant, however, can respond by distinguishing Aries, pointing out the relevant differences, that is, the factors that Aries and Motorola do not share and that push to an opposite result in each case.
 For example, in Aries, the defendant developed a product that was identical to plaintiffs (F18).
 This was not so in Motorola.
 Also, Motorola has four prodefendant factors that do not apply in Aries, as is clear from tiie Venn Diagram (F5, FIO, F17, F20).
 The presence of these opposing factors, defendant argues, warrant opposite outcomes in the two cases.
 The defendant can make an even more devastating response to plaintiffs argument citing Aries: It can cite the Eaton case, which was won by the defendant, as a counterexample.
 Notice that Eaton shares a more inclusive set of factors with the Motorola problem than does Aries: It has all factors that Aries shares with Motorola, but shares additional factors with Motorola as well (namely, F5, F17, and F20).
 W h e n these additional shared factors are taken into account, defendant argues, a decision in favor of the defendant is warranted, as it was in Eaton.
 The instructional goal in C A T O is for students to learn to make the types of arguments covered by the C A T O model and to make better use of commercially available case law databases to find cases to cite in such arguments.
 Currentiy, the C A T O environment provides tools and resources that help students apply tiie C A T O model to make arguments about a problem; it does not do any active mtoring.
 It provides a database containing, for each of 45 trade secrets 420 cases, a list of factors and a textual summary of the case (a "squib").
 C A T O also provides tools for retrieving, displaying and comparing cases in terms of factors.
 The C A T O query language enables students to retrieve cases from CATO's database with any boolean combination of factors.
 C A T O can list the factors for a case retrieved from the database, and can display a comparison of the factors of two cases, marking the shared factors and the distinctions.
 C A T O is based on a knowledge base implemented in Loom (Ashley and Aleven, 1994).
 As is described in the next section, students (guided by a human tutor) have used these tools to develop casebased arguments about legal problems.
 While the C A T O model supports useful argumentmaking, it is a simplification.
 Attorneys do not use a fixed vocabulary of factors to represent and compare cases; they are free to invent their own terms to characterize the legally relevant facts.
 They draw on various types of legal knowledge to reason about why certain facts matter and employ knowledge about the corporate world to interpret the narrative descriptions of cases.
 The C A T O model does not include background knowledge related to what factors mean and why they matter, at least not in a form that C A T O can handle.
 It is important that students learn to apply and integrate this background knowledge when they make arguments with cases.
 W e make some of it available through a preparatory lecture, by providing textual summaries of cases, through the names of factors, and via a human tutor.
 (It is our goal, however, that students will use C A T O without a human tutor.
) It is our impression that it is not very difficult for students to understand what an individual factor means or why it matters.
 The problem is invoking this knowledge at the right time while making arguments with cases.
 The question, then, is whether the C A T O conceptual framework prompts students to integrate their background knowledge appropriately.
 An Experiment with the CATO system We conducted a formative evaluation study to investigate whether beginning law students learn useful argumentation skills as a result of practice with the C A T O system, under the guidance of a human mtor (Kevin Ashley).
 W e compared humanled C A T O instruction against classroom instruction that teaches the same material, but without using the C A T O model or system.
 The design of this experiment is somewhat unusual, compared to other evaluation studies of ITSs (Shute and Regian, 1993), in that a human tutor is involved in the CATO instruction.
 Obviously, this means that any observed improvement in smdents' learning cannot be attributed to CATO alone.
 However, given that only the C A T O model but not the C A T O tools had before been used for tutoring', we wanted to see if a human tutor, "constrained" to using these tools, could succeed.
 Also, we wanted to generate protocols of teaching with these tools.
 The subjects in the experiment were firstsemester law students of the University of Pittsburgh School of Law, di' In a previous study, a human tutor used a lesson plan and computergenerated examples based on the model (Ashley and Aleven, 1992).
 The students did not use the CATO tools.
 vided into an experimental group comprising 7 students, and a control group of 10 students.
 At the start of the experiment, all students received preparatory instruction ahout trade secrets law and about die use of the Westlaw legal information retrieval system.
 All students then took a written, takehome pretest exam involving argumentmaking and casefinding questions, designed to test students' skills in making arguments with cases and framing queries to find relevant cases using Wesdaw, a commercially available case law database.
 Each student in the experimental group participated in two twohour sessions of instruction with CATO.
 During these sessions, students worked in pairs, guided by a human tutor.
 At the start of their first session, the tutor introduced students to CATO's case representation scheme and query language, showing sample factors, cases, and queries.
 The rest of the time, the smdents used the C A T O tools to analyze two trade secrets problems and outline an argument with cases selected from CATO's database.
 After reading the narrative description of the problem facts, students selected C A T O factors to represent the factual strengths and weaknesses present in the problem.
 They then used the C A T O query language to implement general research strategies aimed at finding cases to cite in an argument (i.
e.
, cases that share interesting sets of factors with the problem).
 All students were able, witii a small amount of trial and error, to retrieve relevant cases from the C A T O database.
 (As noted below, the human tutor prompted the smdents in various ways to use the C A T O tools.
 Vincent Aleven handled all student interaction with the C A T O program, for example, typing the queries that the students dictated.
) The students also used the C A T O tools to make initial judgments of what the retrieved cases mean and whether they are relevant to the problem.
 They inspected the applicable factors of the retrieved cases to get a first impression of the legally relevant facts of each case.
 They judged the relevance of the retrieved cases by comparing and contrasting them to the problem, in terms of factors.
 W h e n a case seemed relevant, based on its factors, the students read the squib (i.
e.
, narrative summary of the case), in order to verify their initial relevance judgment and decide whether to cite the case in an argument.
 All smdents were able to outline a convincing argument.
 The human tutor's main role was to guide the students during this process, that is, to get the students to use the C A T O tools and to help them interpret what they had found with the tools.
 He exerted a fair amount of control.
 H e often suggested things that the smdents could do next.
 H e confirmed that students had made good arguments or made accurate evaluations of a case's relevance.
 He summarized arguments that students made in ways that made it clear how they relate to the C A T O model.
 He also helped students keep track of the overall state of their arguments under development and sometimes helped them see how different cases fit into an overall argument.
 However, he did not force students to follow any specific research strategy.
 He did not suggest any specific queries to try, nor did he insist that smdents agree with his own evaluations of the relevance of cases, or make any arguments he may have had in mind.
 Also, he did not demonstrate the overall process, nor did he engage in argument exchanges with the students.
 H e also did not engage in long discourses 421 Experimental Group Average Control Group Average C A T O score Pretest Posttest argumentmaking 52 56 68* argumentmaking and casefinding 45 50 argumentmaking 41 46 78* argumentmaking and casefinding 42 45 Table 1.
 Percentage of maximum score on pretest and posttest, denotes highest score.
 about legal argumentation or trade secrets law.
 In short, the C A T O instruction focused students on the importance of comparing and contrasting cases and gave them practice in a process of making arguments with cases.
 The control group students were taught the same material in a classroom setting, which did not involve the C A T O model or tools.
 Instead, students used the Westlaw database to retrieve relevant cases .
 The control group instruction thus comprised a more traditional way of teaching the same material, using regular tools, but was not part of the regular legal curriculum.
 W e organized two twohour sessions with the control group students, led by legal methods instructors of the University of Pittsburgh School of Law.
 Each session started with a lecture about legal research and argumentation, focusing on the use of cases in arguments.
 The students then analyzed the same two trade secrets problems as the experimental group.
 Each student used the Westlaw legal information retrieval system to find cases that are relevant to the problem.
 In a group discussion led by the instructor, the students considered how the cases they retrieved could be used in an argument.
 During the second session, students engaged in an oral argument exchange, citing the cases they had retrieved.
 All students then took a written, takehome posttest exam containing the same types of questions as the pretest.
 The pretest and posttest answers were graded by legal methods instructors (not those who conducted the control group sessions), who were not familiar with the C A T O model.
 The grading criteria were compatible with the C A T O model, but were not phrased specifically in terms of the C A T O model.
 For the argumentmaking questions, we included in the materials to be graded a set of answers generated by CATO, without informing the graders.
 The results, shown in Table 1, can be summarized as follows: (1) Overall, the control group performed slightly better on the pretest and posttest than the experimental group, but the difference was not statistically significant.
 (2) The answers generated by C A T O were graded higher than any smdent's answers.
 (The fact that the posttest scores are lower 2 The Westlaw database contains the opinion of virtually every case ever published.
 The opinions are the official documents produced by the courts; they are many times longer than the squibs used in the CATO instruction.
 Westlaw's fulltext retrieval system enables users to retrieve documents based on the words that appear in them.
 than the pretest scores does not convey any useful information, because the tests were graded by different graders and were not equally difficult.
) W e interpret the first finding as saying that instruction with C A T O (under the guidance of a human tutor) was as good as, but not better than, classroom instruction.
 The second finding suggests that the students did not learn everything there is to learn about the C A T O model and therefore, that the C A T O model can potentially be employed more effectively to teach students than it was in the experiment.
 O n the other hand, it may simply be that CATO's answers were easier to understand because they were better organized or even printed.
 Examples of Students' Using the CATO Model a n d Tools In this section, we show examples that illustrate that students (at least when guided by a human tutor) were able to use the C A T O model and tools as a useful conceptual framework.
 At the same time, the examples illustrate that students were able to integrate knowledge about factors that is not represented explicitly in the C A T O model.
 The students in the first example use their knowledge about the meaning of factors to improve on CATO's argument based on factors.
 They considered how they could use Eaton, a case won by the defendant, in an argument on behalf of the defendant in Motorola.
 O n the one hand, Eaton is very similar to Motorola (their factors overlap considerably, as the Venn diagram in Figure 1 indicates) and therefore a good case to cite for the defendant.
 O n the other hand, plaintiff can respond by distinguishing Eaton, drawing attention to the distinguishing factors F16 InfoReverseEngineerable in Eaton and F2 BribeEmployee in Motorola.
 In other words, C A T O would have made the following argument: Eaton is distinguishable, because in Eaton, plaintiffs information could be discovered through reverse engineering, that is, analyzing plaintiffs product (F16), while this was not so in Motorola.
 Also, in Motorola, the defendant offered plaintiffs employees a salary increase if they would switch employment (F2).
 This was not so in Eaton^.
 However, the smdents made convincing arguments that these seeming distinctions were of no account, reasoning ^ Cunently, C A T O does not display Venn diagrams, but displays a comparison of the factors of two cases in list format.
 422 about the meaning of the factors, using their knowledge about the corporate world, and taking into account the specific facts behind the factors (which they read in the squib).
 They claimed that the presence of factor F16 InfoReverseEngineerable in Eaton did not make much difference in light of the other factors and therefore should not be regarded as a distinction.
 They reasoned that where information is known in an industry (F20), as in Eaton and Motorola, it is immaterial whether that information is also reverseengineerable (F16), because this hardly makes it any more widely available than it is aheady.
 They also argued that the facts related to the F2 BribeEmployee factor in Motorola were not so extreme that they should be regarded as a strength on the part of the plaintiff or a way of distinguishing Motorola from Eaton.
 The Motorola squib said that plaintiffs employees "received substantial salaries and bonuses" when they switched employment.
 The students reasoned diat this should not be interpreted as an attempt to bribe them to bring trade secrets: "I think it would be fairly easy for the defendant to say .
.
.
 that in a marketoriented situation bonuses and salaries were being made to encourage .
.
.
 [plaintifTs former employees] to come over to the company.
 Not necessarily for any devious means but just because they were skilled workers .
.
.
" In sum, the smdents were able to improve on the C A T O conceptual framework, applying knowledge not represented in the C A T O model.
 C A T O framed the argument; the students went beyond the model in evaluating, augmenting, and critiquing the argument.
 That is good behavior to encourage.
 Also, just making an argument naturally encourages a response.
 In the second example, a student use factors to formulate a general theory about trade secrets law and to test it against cases.
 Formulating and testing theories is an important aspect of legal scholarship, closely related to argumentation, so this was a valuable exercise.
 Reflecting on the meaning of the factors in the Motorola problem (see Figure I), he noticed that certain factors were at odds, and went on to predict how courts would resolve this conflict: Student Actually, aren't the Motorola factors contradictory in saying that there were security measures [F6] but yet the secrets were disclosed [FIO] and the information was known to competitors [F20] ? Tutor D o you think that ever happens, that you have fact situations with contradictions of that nature? Student Yeah.
 I guess, I would think that though when those two contradict, the secrets being disclosed [FIO] would cancel out the .
.
.
 they would make it irrelevant that there were security measures [F6], because the only point for security measures is to keep the information secret and once the information is not secret, what's the point of security measures? Tutor H o w would you test that? Student As far as, if that's true, you would do a search for [ cases with ] F6 and FIO or F20.
 .
.
.
 according to m y theory, all those cases should go for die defendant.
 When the student executed the query, he found—much to his surprise—that not all retrieved cases were consistent with his prediction.
 By looking at the factors of one of the retrieved cases, he was able to refine the theory, as is described in (Aleven and Ashley, 1994).
 This example illustrates that smdents can do interesting things with factors by applying knowledge that is not represented in CATO.
 C A T O could not have produced the same behavior.
 Nonetheless, it evoked the behavior: The case representation in terms of factors prompted the smdent to make a prediction.
 The rationale for his theory was based on the meaning of the factors, which is not represented in the C A T O model.
 But C A T O enabled him to test his theory against a particular database of cases; this would have have been difficult to achieve with a fulltext retrieval system (Aleven and Ashley, 1994).
 W e hope that the examples provide a sense of what the background knowledge is and why it is important.
 At one level, it is difficult to see how an exercise like the current would make sense at all to students if they did not have at least a superficial undersunding of what the factors mean and why they matter.
 For example, an argument by analogy is compelUng only if the similarities between the analogs are relevant to the conclusion.
 Otherwise, the response will simply be: "So what if the plaintiffs in both cases had blue eyes? What does that have to do with anything?" In other words, to understand analogies in terms of factors, one must understand why the factors matter.
 The same can be said about other types of arguments, for example, distinguishing.
 This is why w e were concerned that C A T O does not represent the background knowledge about what the factors mean, and why we were pleased to find that students found it quite natural to analogize and distinguish cases in terms of factors and were able to use background knowledge about factors to make arguments that are not captured in the C A T O model.
 In each protocol, w e found between 4 and 10 instances of smdents' applying knowledge that is not represented in CATO.
 Although not all examples are as clear and striking as the ones presented here, they indicate that students are able to integrate their background knowledge withm the C A T O conceptual framework, at least when guided by a human tutor.
 Discussion and Conclusions In our research project, we explore the hypothesis that an ITS can teach skills of making arguments with cases, using a domain model that contains concepts of reasoning with cases, but relatively little of the background knowledge on which human reasoners draw.
 The background knowledge that we do represent is important, namely, the factors that influence the outcome of the legal cases.
 However, w e do not represent knowledge related to what the factors mean or why they matter, at least not in a form with which the program can reason.
 Given that it is difficult to represent the background knowledge, it is worth investigating how far one can carry mtoring in the absence of much explicitly represented background knowledge.
 C A T O is similar to Belvedere, an instructional environment for teaching scientific argumentation (CavalliSforza and Suthers, 1994).
 Both are examples of programs that make explicit a structure for argumentation and employ it to teach certain skills of analysis £uid argumentation.
 The pro423 grams can reason with the argumentation structure to varying degrees.
 C A T O can evaluate the relevance of cases and make arguments; Belvedere can interpret argument structure to suggest where an argument should be extended.
 They do not, however, have very complete representations of the background knowledge upon which human practitioners draw in analyzing problems or making arguments.
 Nor can these programs interpret most free form arguments generated by humans.
 The question for them is, how successfully can they employ the argumentation structure to teach the analytical and argumentation skills despite the lack of background knowledge or understanding of students' arguments.
 C A T O employs cases in constructing arguments.
 Though also casebased, casebased teaching programs developed at Northwestern University (Kass, et al.
, 1993; Edelson, 1992), do not purport to teach analytical and argumentation skills.
 They do not employ a structure of argumentation.
 Instead, their aim is to teach a set of cases, presenting them in a context where they are most likely to be of interest to the student.
 But Hke C A T O , they represent fairly little of the background information humans employ in interpreting the cases.
 W e conducted a formative evaluation study to investigate whether a human tutor can employ the C A T O model and tools to teach argumentation skills.
 The mtor guided students in analyzing legal problems and developing an argument outline.
 Stodents used CATO's vocabulary of factors to represent the strengths and weaknesses present in a problem, used the C A T O query language to retrieve cases that share interesting factors with the problem, and used CATO's tools for comparing cases in terms of factors to interpret what the retrieved cases mean and whether they are relevant.
 The hum a n mtor exerted a fair amount of control, but his role was constrained to getting the students to use the C A T O tools and helping them to interpret what they had found with the tools.
 W e made some background knowledge available through preparatory instruction in classroom format, through textual representations of the cases, and via the human tutor.
 W e found that the C A T O instruction was as effective as more traditional classroom instruction.
 Arguments generated by C A T O were scored higher than students' arguments, suggesting that the model can be used to teach even more effectively.
 Examples drawn from the protocols of C A T O instruction indicate that, equipped with some background knowledge, students applied the model flexibly, as a useful conceptual framework, and were able to integrate the background knowledge into their arguments.
 Admittedly, w e cannot rule out the possibihty that it was mostly the human tutor's skills and background knowledge that enabled students to do so.
 However, as the examples illustrate, students often applied background knowledge on their own initiative.
 The challenge for the future is to extend C A T O so that students can use it without needing the continuous guidance of a human tutor.
 C A T O will have a process model and will use this to guide students in constructing arguments.
 It will generate (written) arguments and explanations of the relevance of cases (Ashley and Aleven, 1994), so that students can compare their o w n solutions against those based on the C A T O model.
 Also, C A T O will use small, carefully selected collections of cases to illustrate argumentation issues and provide focused exercises (Ashley and Aleven, 1992).
 With these extensions in place, C A T O will provide some of the control that the human tutor provided, for example by suggesting things to do next.
 However, it will not be able to summarize students' arguments or relate them to the CATO model, as the human tutor did.
 Instead, it will present the C A T O solutions for students to compare against their own.
 Also, C A T O will not be able to demonstrate the use of the background knowledge or detect situations where students use it unproductively.
 Future evaluation studies will bear out whether such a system will help students learn to use the C A T O conceptual framework effectively and integrate their background knowledge to make good arguments.
 References Aleven, V.
 and Ashley, K.
 D.
 (1994).
 An Instructional Environment for Practicing Argumentation Skills.
 In AAAI94: Proceedings of the Twelfth National Conference on Artificial Intelligence, 485^92.
 Menlo Park, CA: AAAI Press.
 Aleven, V.
 and Ashley, K.
 D.
 (1993).
 What Law Students Need to Know to WIN.
 In Proceedings of the Fourth International Conference on Artificial Intelligence and Law, 152161.
 New York: ACM.
 Anderson, J.
 R.
; Boyle, C.
 F.
; Corbett, A.
 T.
; and Lewis, M.
 L.
 (1990).
 Cognitive Modeling and Intelligent Tutoring.
 Artificial Intelligence, 42: 7^9.
 Ashley, K.
 D.
 (1990).
 Modeling Legal Argument: Reasoning with Cases and Hypotheticals.
 Cambridge, M A : MIT Press.
 Ashley, K.
 D.
 (1991).
 Reasoning with Cases and Hypotheticals in HYPO.
 International Journal of ManMachine Studies, 34, no.
 6: 7537%.
 Ashley, K.
 D.
, and Aleven, V.
 (1994).
 A Logical Representation for Relevance Criteria.
 In Topics in CaseBased Reasoning; Selected Papers from the First European Workshop, EWCBR93, edited by S.
 Wess, K.
 D.
 Althoff, and M.
 M.
 Richter, 338352.
 Lecture Notes in Artificial Intelligence, 837.
 Berlin: SpringerVerlag.
 Ashley, K.
 D.
 and Aleven, V.
 (1992).
 Generating Dialectical Examples Automatically.
 In AAAI92: Proceedings of the Tenth National Conference on Artificial Intelligence, 654^60.
 Menlo Park, CA: AAAI Press.
 CavalliSforza, V.
 and Suthers, D.
 D.
 (1994).
 Belvedere: An Environment for Practicing Scientific Argumentation.
 In Working Notes, AAAI Workshop on Computational Dialectics, edited by R.
 P.
 Loui and T.
 Gordon, 39^4.
 Sponsored by AAAI, 1994.
 Clancey, W .
 J.
 (1983).
 The epistemology of a rulebased expert system: a framework for explanation.
 Artificial Intelligence, 20, no.
 3:215251.
 Edelson, D.
 C.
 (1992).
 When Should A Cheetah Remind You of a Bat? Reminding in CaseBased Teaching.
 In AAAI92: Proceedings of the Tenth National Conference on Artificial Intelligence, 667672.
 Menlo Park, CA: AAAI Press.
 Kass, A.
; Burke, R.
: Blevis, E.
; and Williamson, M.
 (1993).
 Constructing Learning Environments for Complex Social SkiUs.
 The Journal of the Learning Sciences, 3, no 4: 387427.
 Rissland, E.
 L.
 (1990).
 Artificial Intelligence and Law: Stepping Stones to a Model of Legal Reasoning.
 Yale Law Journal 99: 19571982.
 Shute, V.
 J.
, and Regian, J.
 W .
 (1993).
 Principles for Evaluating Intelligent Tutoring Systems.
 Journal of Artificial Intelligertce and Education, 4, no.
 2/3, 245271.
 Wenger, E.
 (1987).
 Artificial Intelligence and Tutoring Systems: Computational and Cognitive Approaches to the Communication of Knowledge.
 Los Altos, CA: Morgan Kaufmann.
 424 Causal Paradox: W h e n A Cause Simultaneously Produces and Prevents an Effect Michael R.
 Waldmann Max Planck Institute for Psychological Research Leopoldstr.
 24, 80802 Munich, Germany waldmann@mpipfmuenchen.
mpg.
de York Hagmayer Department of Psychology, University of Tubingen Friedrichstr.
 21, 72072 Tubingen, Germany york.
hagmayer@student.
unituebingen.
de Abstract Many philosophers and psychologists argue that causal inferences are solely based on the observation of contingencies between potential causes and effects.
 By conuast, causalmodel theory postulates that the interpretation of the learning input is governed by prior causal assumptions.
 Simpson's paradox is an example of this basic claim of causalmodel theory.
 Identical observations may result in dramatically different causal impressions depending on the partitioning of the event space.
 Two experiments are presented that show that participants' assessment of a contingency between a potential cause and an effect is moderated by their background assumptions about the causal relevance of additional variables, and the ordering of the learning items.
 Despite the fact that all participants received identical learning inputs, participants' assumptions about the causal relevance of an additional grouping variable led either to the impression that the cause facilitated the effect or to an impression that it prevented the effect.
 Thus, the acquisition of new causal knowledge is crucially dependent on causal knowledge that is already available at the outset of the induction process.
 Introduction Causal Induction as BottomUp Contingency Learning The ability to acquire causal knowledge belongs to our most central cognitive competencies.
 W e would hardly be able to survive without knowledge about systematic relationships between events.
 Causal knowledge allows us to anticipate harmful or gratifying events, or to plan actions to achieve goals.
 Despite the fact that a large number of philosophers and psychologists have analyzed the concept of causality, no agreement has been accomplished so far.
 The main question of how we distinguish causal relations from accidental sequences of events remains largely unanswered.
 In the past 30 years, philosophers and psychologists have become increasingly interested in probabilistic notions of causality.
 Our knowledge about causal facts, such as "Aspirin relieves headache" or "Smoking causes lung cancer", is often based on the observation of probabilistic relations.
 A number of philosophers have proposed a notion of causality that reduces causal relations to observable statistical laws (e.
g.
, Eells.
 1991; Salmon, 1971; Suppes, 1970).
 Roughly, it has been proposed that causes raise the probabilities of their effects.
 This idea has been adopted by psychologists w h o propose that causal induction involves the acquisition of knowledge about contingencies between causes and effects (Jenkins & Ward, 1965; Wasserman, Chatlosh & Neunaber, 1983).
 Formally, an (unconditional) contingency can be defined as the difference between the conditional probability of a target effect E given the presence of a potential causal factor C and its probabiUty given the absence of the factor (i.
e.
, p(E\C)  p{E\~Q).
 If this difference is greater than 0, the contingency suggests that C is a facilitatory cause, if it is smaller than 0 then C may be inhibitory for the occurrence of the effect.
 Typically, it has been assumed that these probabilities are estimated on the basis of stored frequency information (Cheng & Novick, 1992; Melz, Cheng, Holyoak, & Waldmann, 1993).
 However, a different approach assumes the acquisition of associative weights (Wasserman, Elek, Chadosh, & Baker, 1993).
 Chapman and Robbins (1990) have proven, however, that, at least in situations with one single cause and one effect, the asymptotic associative weight obtained by the RescorlaWagner learning rule (Rescoria & Wagner, 1972) corresponds to the results of applying the contingency rule.
 Thus, associative as well as statistical learning theories model causal induction as bottomup learning about statistical contingencies.
 Unconditional contingencies are only a rough characterization of the theory of probabilistic causality.
 Unconditional contingencies may even be observed between events that are not directly causally related, or the contingencies may not express the true causal relation between the two events.
 Problems always occur when there are additional causal factors which are correlated with the two observed events.
 These additional factors may be the cause for spurious correlations, or they may alter the observed statistical relation and therefore convey a wrong impression of the true causal relation.
 Philosophers (e.
g.
, Cartwright, 1983; Eells, 1991; Salmon, 1980) and cognitive psychologists (Cheng & Novick, 1992; Cheng, 1993; Melzetal.
, 1993; Waldmann & Holyoak, 1992) have therefore suggested conditional contingencies as indicators of causality.
 Conditional contingencies assess the contingencies between two events C, E conditional upon alternative causal factors K, being kept constant, i.
e.
 as p{E\C.
K,.
K2.
.
.
.
K„) p{E\~C.
K,.
K2.
 .
.
.
K„ ).
 A n isolated period denotes an "and", and each A", a choice between the presence or the absence of the factor.
 For example, suppose w e want to test the hypothesis that smoking (C) causes heart disease (£).
 Furthermore, we assume that smoking is correlated with coffee drinking which may also be a cause of heart disease.
 In order to test our hypothesis, w e should assess the conditional contingencies between smoking and heart disease in the subpopulation of coffee drinkers (K,) 425 mailto:waldmann@mpipfmuenchen.
mpg.
demailto:york.
hagmayer@student.
unituebingen.
deand people w h o do not drink coffee i~K,).
 If w e then discover that smoking equally leads to heart disease in both subpopulations, w e may conclude that smoking is an independent cause of this disease.
 CausalModel Theory No attempt to reduce causa! laws to purely statistical relations has so far been successful (see Cartwright, 1983, 1989; Eells, 1991).
 One of the reasons for this failure is the fact that statistical relations are typically insensitive to one of the most fundamental properties of causal relations, causal priority: W e k n ow that causes precede their effects, and not the other way around.
 By contrast, contingencies are typically symmetric.
 In situations in which a cause raises the probability of its effect, it is ceteris paribus true that the effect raises the probability of its cause.
 Thus, probabilistic relations do not represent the fundamental property of causal priority.
 In more complex situations with multiple causes and effects, the interpretation of the observed statistical evidence is crucially dependent on the assumed pattern of causal directionality.
 Waldmann and Holyoak (1992) have therefore proposed the causalmodel theory which postulates an interaction between hypothesized causal models and the learning input.
 The main idea is that the structure of causal models directs the interpretation of the learning input which in turn may modify the initial causal model.
 Statistical information about conditional and unconditional contingencies is still important but causalmodel theory postulates a "tight coupling" (Wisniewski & Medin, 1994) between bottomup input and topdown assumptions.
 The impact of prior assumptions about causal directionality has been demonstrated in a number of experiments.
 In general, these experiments have shown that identical learning inputs were treated differently depending on the structure of the causal model invoked for the interpretation of the learning experiences (Waldmann & Holyoak, 1990, 1992; Waldmann, Holyoak, & Fratianne, in press).
 Previous work on the impact of topdown processes has demonstrated the impact of domainspecific knowledge on causal induction and learning (Chapman & Chapman, 1969; Medin, Wattenmaker, & Hampson, 1987; Pazzani, 1991).
 In general, these studies have shown that people use domainspecific, prior knowledge about relations between specific entities in learning situation.
 This knowledge may help people see relations in the learning material they otherwise would have missed (Medin et al.
, 1987; Pazzani, 1991).
 Furthermore, prior knowledge that is incompatible with the learning input may also lead to distortions and selective processing (Chapman & Chapman, 1969).
 Even though causalmodel theory is compatible with these types of knowledge influences, its major focus is on more abstract topdown influences.
 For example, knowledge about the causal direction between two events does not have any implications about the strength of the causal relation between these events.
 Thus, this type of knowledge does not lead to selective processing and distortions as in the cases in which specific knowledge about the strength of relations is directly transferred.
 Nevertheless, Waldmann et al.
 (in press) showed that abstract knowledge about patterns of causal directionality strongly affects the ease of learning of otherwise identical learning material.
 Simpson's Paradox Causal directionality is only one aspect of abstract prior causal knowledge that influences the interpretation of the learning input.
 A further problem of purely statistical theories of causality is a consequence of the fact that contingencies between two events may be affected by other causal factors.
 O n e solution for this problem, the conditional contingency approach, has already been mentioned.
 According to this theory, contingencies should not be computed over the universal set of events but over subsets of events.
 However, Cartwright (1983) points out that this method only yields correct results when the subsets are properly selected (see also Cheng, 1993).
 Conditionalizing on the wrong variables may lead to erroneous contingency estimates.
 A n instance of this problem is known in the philosophical and statistical literature as Simpson's paradox (see Cartwright, 1983; Eells, 1991; Simpson, 1951).
 Simpson's paradox describes the fact that a given contingency between two events which holds in a given population can disappear or even be reversed in all subpopulations, when the population is partitioned in certain ways.
 Cartwright (1983) cites a study on the graduate admissions of Berkeley that demonstrates the problem (Bickel, Hammel, & O'Connell, 1977).
 The graduate school of Berkeley was accused of discriminating against women.
 And indeed, at first sight the probabilities seemed to support the causal hypothesis that being a woman causes one to be rejected at Berkeley: the probability of admissions were higher for male students than for female students.
 However, the researchers looked at the data more carefully.
 W h e n the admissions were analyzed separately for each department, one by one, the correlation between gender and admission completely disappeared.
 The reason for this was that w o m e n tended to apply to departments with higher rejection rates.
 Department by department women were admitted in the same ratio as male applicants, whereas across all the departments proportionally fewer w o m en were admitted.
 Table 1: A n example for Simpson's paradox.
 The Berkeley admission problem (after Eells, 1991, p.
 63).
 Male Female Dept.
 1 81/90 9/10 Dept.
 2 2/10 18/90 Total 83/100 27/100 Table 1 from Eells (1991, p.
63) gives an example of how this can happen.
 In this example.
 Department 1 accepts 9 0 % of the female and of the male applicants.
 Department 2 only accepts 2 0 % of the female and the male applicants.
 Thus, within each department male and female applicants are accepted in the same proportions.
 However, more female applicants apply to Department 2 which is harder to get in.
 Therefore, overall, across all departments, more than three times as many male applicants (83%) are admitted than female applicants (27%).
 This example may lead to the methodological suggestion that it is always a good idea to partition into subsets of events, and compute conditional contingencies.
 However, this strategy may also lead to false assessments.
 The reason why in the Berkeley 426 admissions case the analysis should be based on the department level is that the departments are causally relevant for the effect under investigation.
 The departments decide about the admissions, and not the whole university.
 If, by contrast, it had been shown that the contingencies reverse when the applicants were partitioned on the basis of their roller skating skills, this would not count as an argument against sex discrimination (Cartwright, 1983).
 Only partitions by causally relevant variables are relevant for evaluating causal laws.
 If causally irrelevant variables also mattered, almost any contingency can be obtained by choosing the right partition of the event space.
 What this example shows is that causal induction is crucially dependent on prior causal knowledge.
 N e w causal relations may be induced using contingency estimates.
 However, the contingencies only reflect causal relations when the observations are partitioned on the basis of causally relevant rather than irrelevant variables.
 The causal relevance of these partitioning variables has to be established prior to the new induction task.
 Thus, Simpson's paradox exemplifies the basic assumption of causalmodel theory that the interpretation of the learning input is based on prior assumptions about general properties of the causal situation.
 Simpson's paradox is an interesting example of h o w specific knowledge interacts with abstract causal strategies.
 It is true that knowledge about the causal relevance of the partitioning variable is domainspecific (e.
g.
, the fact that departments decide about admissions).
 However, unlike in the previous research on transfer of specific knowledge, this type of knowledge does not directly bias estimates about the strength of the causal relation between the target cause (e.
g.
, sex of applicants) and the target effect (e.
g.
, admission).
 In order to get the correct results, abstract knowledge has to be activated that conditional contingencies based on causally relevant subgroups should be computed.
 Interestingly, the dramatic reversals obtained in situations exemplifying Simpson's paradox are not due to selective processing of individual cases or distortions of the contingency judgments.
 They rather are a natural consequence of unbiased processing of differentially grouped cases.
 The following two experiments are designed to assess whether participants are sensitive to the potential impact of causally relevant as opposed to causally irrelevant grouping variables when assessing contingencies between a putative cause and an effect.
 Experiment 1 Method Participants' task in this experiment was to assess the strength of the causal relation between the irtadiation of tropical fruit and the quality of the fruit.
 Participants received written instructions in which they were told that importers of tropical fruit are trying to improve the quality of the fruit by irradiating them.
 However, so far it is unknown whether the irradiation has a positive, a negative, or no effect on the quality of the fruit.
 T o assess the efficacy of irradiation participants received information about the quality of samples of fruit that either had or had not been irradiated.
 The participants were handed a twopage list which contained information about 80 samples of fruit.
 Each sample was represented on one line, and for each sample participants could see whether or not the sample had been irradiated ("yes" or "no"), and whether the quality of this sample was "good" or "bad".
 Participants were instructed to study the list carefully in order to be able to assess whether irradiation has an effect or not.
 They were requested to express their impression on a rating scale that ranged from 10 ("irradiation leads to a strong deterioration of the quality") to iIO ("irradiation leads to a strong improvement of the quality").
 Participants were assigned to one of three conditions.
 Participants in all conditions saw the same list with the 80 cases, and received the same rating instructions.
 Thus ail participants were requested to rate the strength of the causal relation between irradiation and quality of fruit.
 The only difference was that in two of the conditions an additional grouping variable was mentioned which either was causally relevant or irrelevant.
 The third condition represents a control condition in which no grouping variable was introduced.
 Participants in the condition with the causally relevant variable were told that there are two types of fruit, Taringes and Mamones.
 Additionally it was pointed out that it was expected that irradiation affects these two types of fruit differently.
 Furthermore, information was added to the list which indicated that one of the two pages showed Taringes, and the other page Mamones.
 In the condition with the causally irrelevant grouping variable, participants were told that, due to the large number of tests, the samples of fruit described on the two pages were randomly assigned to two different investigators.
 The participants in this condition saw the same list as in the condition with the causally relevant variable except that "Mamones" and "Taringes" were respectively replaced by "A" and "B" as a shorthand for the two investigators.
 Table 2: Relative frequency of fruit with good quality after irradiation and no irradiation within and across the subcategories A and B of the grouping variables.
 irradiation no irradiation A 16/36 (.
44) 3/4 (.
75) B 0/4 (.
00) 5/36 (.
14) Total 16/40 (.
40) 8/40 (.
20) In order to test whether participants' contingency judgments reflect their prior assumptions about the additional grouping variables, the organization of the list corresponded to a variant of Simpson's paradox.
 Table 2 displays h o w the cases were distributed.
 The table displays the proportion of fruit that were of good quality after they were irradiated, and the proportion of fruit that were good without being irradiated.
 For example, within subgroup A 36 fruit samples were presented that were irradiated.
 4 4 % of these samples (i.
e.
, 16 out of 36) had good quality after irradiation.
 As can be seen in Table 2, the arrangement of the cases resulted in a reversal of the sign of the contingencies within as opposed to across the grouping variable.
 Disregarding the grouping variable yields a positive contingency between irradiation and quality of fruit (.
40  .
20 = .
20).
 By contrast, the contingency within each of the subgroups is negative (A: .
44  .
75 = .
31; B: .
00 .
14 = .
14).
 For half of the participants, the mapping 427 between irradiation and quality of fruit was switched so that these participants saw a symmetric situation with a negative overall contingency, and positive contingencies within the subgroups.
 It was exf)ected that participants in the control condition w h o did not receive any grouping information should rely on the total proportions.
 Thus, participants w h o received the arrangement displayed in Table 2 should get the impression that irradiation raises the quality of fruit.
 The two other conditions are more interesting.
 If participants' behavior conformed to the normative suggestions regarding contingency assessments, they should conditionalize the contingency estimates on causally relevant grouping variables.
 Thus, it may be expected that participants in the condition with the causally relevant grouping variable would assess the causal impact of irradiation separately for each subgroup (Mamones and Taringes).
 Since the contingencies within each subgroup are negative, participants should get the overall impression that irradiation lowers the quality of fruit.
 Since participants in all conditions were requested to give an overall assessment, it was expected that participants would average the impressions they obtained for each subgroup.
 Finally, participants in the condition with the irrelevant grouping variable (A and B ) should, according to normative standards, ignore this variable.
 Thus their assessments should be similar to the ones obtained in the control condition.
 Results Table 3 shows the results of this experiment based on 36 students from the University of Tubingen.
 The signs of the ratings of the group w h o saw the negative overall contingency were reversed so that the two subgroups were comparable.
 Table 3: Mean ratings of the causal relation between irradiation and quality of fruit in the control condition, and the conditions with the causally relevant and irrelevant grouping variable.
 Experiment 2 Method relevant 4.
33 irrelevant 5.
17 control 4.
75 The results show that participants behaved according to normative standards.
 The ratings in the control condition and in the condition with the irrelevant grouping variable were positive, and statistically indistinguishable from each other.
 Thus, participants in these two conditions believed that irradiation raises the quality of fruit.
 This finding indicates that participants based their assessments on the total distribution of cases while disregarding subgroups.
 B y contrast, participants in the condition with the causally relevant grouping variable got the impression that the cause prevents the effect.
 These participants concluded that irradiation lowers the quality of fruit.
 The negative mean rating indicates that many participants computed contingencies for each subgroup separately before these contingency estimates were integrated.
 The ratings of this group were very different from the ratings of the two other groups, F(l, 33) = 71.
!,/?<.
001, A/5£ = 9.
71.
 In Experiment 1 two different grouping variables were compared, type of fruit (Mamones and Taringes) and investigators (A and B).
 Experiment 2 attempted to replicate the results of Experiment 1 with a grouping variable that was kept constant across the two conditions.
 Thus, all participants saw identical cases, received identical rating instructions, and were informed about identical subcategories.
 Participants were told that their task was to assess the causal efficacy of a new watering technique tried on different plants from the North African desert.
 T w o instruction conditions were compared which only differed in one sentence.
 In both conditions, it was pointed out that the watering technique is applied to two types of plants, Eleusina and Setaria.
 But only in one of the two conditions the hint was added that the technique might have different effects on the two plant types.
 (This manipulation is less strong than in Experiment 1 because participants in the condition without the hint may still believe that the type of plant is causally relevant.
) Similar to Experiment 1, participants received a list of 80 cases which provided participants with information about the type of plant ("Eleusina" or "Setaria"), whether the plant was watered or not ("yes" vs.
 "no"), and whether the particular plant grew (+) or not ().
 Again, participants' task was to rate on a rating scale between (10 and 10 whether watering generally leads to an improved or decreased growth of the plants.
 The assignment of the cases to the two subcategories corresponded to Table 2.
 Thus, calculating contingencies for each subgroup separately should cause the impression that watering leads to decreased growth of the plants, whereas disregarding the two plant types should lead to the impression that applying the new watering technique actually helps the plants to grow.
 Experiment 2 also introduced a second factor, the ordering of the cases.
 One condition presented the information about the two plants in a blocked fashion.
 Thus, on one page all the Eleusinas and on the other page all the Setarias were listed.
 In the second condition, the presentation of the cases was unordered.
 O n both pages information about the two plant types was given in a random order.
 It was expected that the hint about the causal relevance of the grouping variable should have particularly strong effects in the condition in which the cases were not grouped.
 Separating out the two groups is much harder in this condition so that participants should only attempt to calculate separate contingencies when they believed it was absolutely necessary.
 By contrast, the blocked presentation of the two groups makes the grouping variable more salient as a potential causal factor even when no hint was given.
 Again for half of the participants the sign of the observed contingencies was reversed (their ratings were recoded for the analyses).
 Results Table 4 shows the results based on 48 participants from the University of Tubingen.
 This table displays participants' mean ratings of the causal efficacy of the new watering technique in the conditions with and without the hint about the potential causal relevance of Eleusinas and Setarias, and in the conditions with blocked versus unordered presentation of the two plant types.
 The negative mean ratings in three of the four 428 conditions indicate that many participants assumed that plant type is causally relevant even when no explicit hint was given.
 In the two conditions with the blocked presentation of the cases participants tended to give negative ratings which indicate that they assessed the contingencies for each plant type separately before the two contingency estimates were mtegrated.
 The ratings of these two groups did not differ significantly (F<1).
 Grouping the cases apparently led to the impression that the plant type may be causally relevant even when no explicit hint was given.
 However, in the groups in which the cases were presented in an intermixed fashion, omitting the hint about the causal relevance resulted in a significant shift of the ratings toward the positive side, F (1, 44) = 11.
2, p < .
01, M S E = 11.
2.
 Thus, participants tended to ignore the subgroups when the groups were not very salient, and when no hint about the causal relevance of the grouping variable was given.
 Overall, this pattern of results yielded a reliable interaction between the factors hint and amount of grouping, F (1, 44) = 6.
25, p < .
025, M S E = 11.
2.
 Table 4: Mean ratings of the causal relation between watering and plant growth in the groups with or without the hint about the causal relevance of the plant type, and with or without categorybased groupings of the cases.
 grouped ungrouped with hint 2.
33 3.
75 without hint 2.
58 .
83 Discussion Simpson's paradox is an example of the basic assumption of causalmodel theory that the interpretation of the learning input is crucially dependent on prior causal knowledge.
 Identical cases may result in dramatically different causal impressions depending on the partitioning of the event space.
 Unlike experiments that demonstrate direct influences of domain specific knowledge about causal relations, Simpson's paradox is an example of the importance of abstract causal knowledge.
 Even though knowledge about the causal relevance of the grouping variables is domain specific, this knowledge does not directly predetermine the strength of the causal relation that is being assessed.
 Rather, more abstract kinds of knowledge about interactions between contingency assessments with the causal relevance of partitioning variables has to be invoked.
 The two experiments showed that participants' assessment of a contingency between a potential cause and an effect is moderated by their background assumptions about the causal relevance of additional variables, and the mode of presentation of the learning items.
 Despite the fact that the participants of the experiments received identical learning inputs, participants' assumptions about the causal relevance of an additional grouping variable led either to the impression that the cause facilitated the effect or to an impression that it prevented the effect.
 These results demonstrate that the acquisition of new causal knowledge is based on old causal knowledge which is already available at the outset of the induction process.
 References Bickel, P.
 J.
, Hammel, E.
 A.
, & O'Connell, J.
 W.
 (1977).
 Sex bias in graduate admissions: Data from Berkeley.
 In W .
 B.
 Fairley & F.
 Mosteller (Eds.
), Statistics and public policy.
 Reading, M A : AddisonWesley.
 Chapman, L.
 J.
, & Chapman, J.
 P.
 (1969).
 Illusory correlation as an obstacle to the use of valid diagnostic signs.
 Journal of Abnormal Psychology, 74, 271280.
 Cheng, P.
 W .
 (1993).
 Separating causal laws from causal facts: Pressing the limits of statistical relevance.
 In D.
 L.
 Medin (Ed.
), The psychology of learning and motivation (Vol.
 30, pp.
 215264).
 San Diego: Academic Press.
 Cheng, P.
 W.
, & Novick, L.
 R.
 (1992).
 Covariation in natural causal induction.
 Psychological Review, 99, 365382.
 Cartwright, N.
 (1983).
 H o w the laws of physics lie.
 Essay J.
 Oxford: Clarendon Press.
 Cartwright, N.
 (1989).
 Nature's capacities and their measurement.
 Oxford: Clarendon Press.
 Chapman, G.
 B.
, & Robbins, S.
 J.
 (1990).
 Cue interaction in human contingency judgment.
 Memory & Cognition, 18, 537545.
 Eells, E.
 (1991).
 Probabilistic causality.
 Cambridge: Cambridge University Press.
 Jenkins, H.
 M.
, & Ward, W .
 C.
 (1965).
 Judgment of contingency between responses and outcomes.
 Psychological Monographs, 79 (whole volume X).
 Medin, D.
 L.
, Wattenmaker, W .
 D.
, & Hampson, S.
 E.
 (1987).
 Family resemblance, conceptual cohesiveness, and category construction.
 Cognitive Psychology, 19, 242279.
 Melz, E.
 R.
, Cheng, P.
 W.
, Holyoak, K.
 J.
, & Waldmann, M .
 R.
 (1993).
 Cue competition in human categorization: Contingency or the RescorlaWagner learning rule? Comments on Shanks (1991).
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 19, 13981410.
 Pazzani, M.
 J.
 (1991).
 Influence of prior knowledge on concept acquisition: Experimental and computational results.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 17, 416432.
 Rescorla, R.
 A.
, & Wagner, A.
 R.
 (1972).
 A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement.
 In A.
 H.
 Black & W .
 F Prokasy (Eds.
), Classical conditioning IL Current research and theory (pp.
 6499).
 N e w York: Appleton CenturyCrofts.
 Salmon, W .
 (1971).
 Statistical explanation.
 In W .
 Salmon (Ed.
), Statistical explanation and statistical relevance.
 Pittsburgh: University of Pittsburgh Press.
 Salmon, W .
 C.
 (1980).
 Probabilistic causality.
 Pacific Philosophical Quarterly, 61, 5074.
 Simpson, E.
 H.
 (1951).
 The interpretation of interaction in contingency tables.
 Journal of the Royal Statistical Society, Ser.
B, 75,238241.
 Suppes, P.
 (1970).
 A probabilistic theory of causality.
 Amsterdam: North Holland.
 Waldmann, M.
 R.
, & Holyoak, K.
 J.
 (1990).
 Can causal induction be reduced to associative learning? Proceedings of the Twelfth Annual Conference of the Cognitive Science 429 Society (pp.
 190197).
 Hillsdale, NJ: Erlbaum.
 Waldmann, M.
 R.
, & Holyoak, K.
 J.
 (1992).
 Predictive and diagnostic learning within causal models: Asymmetries in cue competition.
 Journal of Experimental Psychology: General, 121, 222236.
 Waldmann, M.
 R.
, Holyoak, K.
 J.
, & Fratianne, A.
 (in press).
 Causal models and the acquisition of category structure.
 Journal of Experimental Psychology: General.
 Wasserman, E.
 A.
, Chatlosh, D.
 L.
, & Neunaber, D.
 J.
 (1983).
 Perception of causal relations in humans: Factors affecting judgments of responseoutcome contingencies under freeoperant procedures.
 Learning and Motivation, 14, 406432.
 Wasserman, E.
 A.
, Elek, S.
 M.
, Chatlosh, D.
 L.
, & Baker, A.
 G.
 (1993).
 Rating causal relations: Role of probability in judgments of responseoutcome contingency.
 Journal of Experimental Psychology: Learning, Memory, andCognition, 19, 174188.
 Wisniewski, E.
 J.
, & Medin, D.
 L.
 (1994).
 On the interaction of theory and data in concept learning.
 Cognitive Science, 18, 221281.
 430 Alternative Approaches to Causal Induction: T h e Probabilistic Contrast Versus the RescorlaWagner M o d e l Aaron S.
 Yarlas Department of Psychology U.
 of California, Los Angeles Los Angeles, C A 90025 y a r l a s @ p s y c h .
 u c l a .
 e d u Patricia W .
 C h e n g Department of Psychology U.
 of California, Los Angeles Los Angeles, C A 90025 c h e n g S p s y c h .
 u c l a .
 e d u Keith J.
 Holyoalc Department of Psychology U.
 of California, Los Angeles Los Angeles, C A 90025 h o l y o a k @ p s y c h .
 u c l a .
 e d u Abstract Rescorla and Wagner's (1972) model of associative learning ( R W M ) and Cheng and Novick's (1990, 1991, 1992) Probabilistic Contrast Model (PCM) represent competing approaches to modeling the covariation component of human causal induction.
 Given certain patterns of environmental inputs to the learner, these models sometimes make contradictory predictions about what will be learned.
 Some of these situations have been tested in Pavlovian conditioning experiments using animal subjects.
 W e interpret these results according to PCM, and find that they are consistent with the predictions of the model.
 The current experiment implements similar experimental designs as a causal inference task involving humans as subjects.
 Two experimental conditions were compared to examine each model's predictions regarding when the extinction of conditioned inhibition will occur.
 In one condition, the R W M predicts that a previously perceived inhibitory stimulus will be judged as less inhibitory, whereas the P C M predicts that subjects will not change their causal judgments; in the second condition, the two models make the reverse claims.
 The data provide strong evidence favoring the PCM.
 Introduction Causal induction allows people and other animals to predict and control the environment, a necessary task for survival.
 How does causal induction occur? What mechanisms are jsed to induce the causal relation between variables? A necessary component of causal induction is the jvaluation of covariation between a candidate cause and an :ffect.
 T w o variables that covary tend to be both present or 30th absent.
 T w o broad classes of models of covariation earning within causal contexts have been proposed.
 One ipproach is based on extending associative learning models nitially applied to Pavlovian conditioning in animals.
 The extension is supported by evidence of striking parallels between phenomena observed in studies of causal induction n people and Pavlovian conditioning in animals (e.
g.
, :hapman & Robbins, 1990; Gluck & Bower; 1988; Shanks ?c Dickinson, 1987; Wasserman, 1990).
 The most nfluential associative model has been the RescorlaWagner 1972) model of conditioning ( R W M ) , which is a version of he delta rule used to implement learning in many ;onnectionist networks (Sutton & Barto, 1981).
 A second approach to modeling causal induction has been influenced by treatments in the philosophical and artificialintelligence literatures (e.
g.
, Cartwright, 1989; Pearl, 1988).
 The latter approach has produced models based in part on statistical relations between causes and their effects, as characterized by variants of contingency theory (e.
g.
, Cheng & Novick, 1990; Gallistel, 1990).
 One formulation of contingency theory, the Probabilistic Contrast Model (PCM) of Cheng and Novick (1990, 1991, 1992), has been extended by Cheng and Holyoak (in press).
 These alternative theoretical approaches have sparked vigorous debate in the literature (Melz, Cheng, Holyoak & Waldmann, 1993; Shanks, 1991).
 The present paper presents a preliminary report of two experimental tests of the R W M and the P C M within causal contexts.
 For many situations, these two models make similar predictions regarding the causal relations a learner would infer.
 However, for other situations the two models make diametrically opposite predictions about the causal judgments learners will make.
 W e will report the results of two experimental tests that discriminate between the predictions of the two models.
 RescorlaWagner Model The RWM was first proposed to explain various data patterns that had been found in the Pavlovian conditioning literature.
 The R W M represents the learning of an association by the change in strength of the connection between a conditioned stimulus /' (e.
g.
, a flash of light) and an unconditioned stimulus j (e.
g.
, a shock).
 In addition to the particular stimuli present (e.
g.
, a tone), the stimuli are assumed to include one that represents a context present in every event (e.
g.
, the conditioning cage).
 In causal terms, each (' is a candidate cause, andj is the effect.
 Quantitatively, the R W M is represented by the learning rule AV,^=a,p, A ,  X ^ (1) where AV,, is the change in associative strength between / and j as a result of the current event, a, and P, are rate parameters that respectively depend on the salience of / (e.
g.
, the brightness of the light) and y (e.
g.
, the intensity of the shock), and A is the desired output corresponding to the 431 mailto:yarlas@psych.
ucla.
edumailto:holyoak@psych.
ucla.
eduactual outcome (the presence or absence of the unconditioned stimulus).
 Typically, if the outcome is present, X^ is defined as 1; if the outcome is absent, this value is 0.
 £Vi,, defined as the sum of the current strengths of associations to j from all n stimuli present in that event, is the actual output of the network predicting the outcome.
 Learning consists of reducing the discrepancy between the actual outcome (A.
) and the expected outcome CLVij) until this discrepancy approximates zero.
 The strengths that are updated according to Equation 1 are equivalent to weights on the links in a twolayered connectionist network, with the predicting stimuli being represented on the input layer and the predicted outcome on the output layer.
 A n important assumption of the R W M is that if stimulus i is not present during the event, its associative strength remains unchanged (i.
e.
.
 Equation 1 applies only for those stimuli that are present on a given trial).
 The equivalent assumption in deltarule learning is that the strengths of weights from input units with 0 activation are not revised.
 Probabilistic Contrast M o d e l The PCM was proposed by Cheng and No vie k (1990, 1991, 1992) to explain the apparent biases that occur when people make causal judgments.
 This model extends Kelley's (1967) covariation model.
 Kelley (1967) proposed that people are intuitive scientists, who make causal attributions based on a covariation principle analogous to the analysis of variance.
 Cheng and Novick (1990) proposed that this principle involves contingency (or contrast), such as that suggested by Jenkins and Ward (1965).
 Unlike previous contingency models in psychology, however, the P C M assumes that contingency is computed over a focal set, which is a set of events a learner considers relevant to the evaluation of the candidate cause.
 Cheng and Holyoak (in press) reviewed evidence suggesting that when the information is available, the focal set is one in which all alternative plausible causal agents are held constant.
 That is, the learner often computes the conu^ast for a candidate cause conditional on the constant presence or absence of alternative plausible causes.
 The P C M determines the causal relation between a candidate cause and an effect by contrasting the probabilities of the effect being present when the candidate cause is present versus absent within the focal set.
 A maineffect contrast, Ap,, which evaluates a candidate cause involving a single factor i", is defined as ^ , = P ,  P; (2) where p, is the proportion of events for which the effect occurs when factor / is present, and p is the proportion of events for which the effect occurs when factor / is absent (The proportions are estimates of the corresponding conditional probabilities.
) If Ap, is noticeably positive, we perceive / to be an excitatory cause of the effect.
 If A/7, is noticeably negative, w e perceive / as preventing or inhibiting the effect.
 If Ap, is not noticeably different from zero, w e perceive / as having no causal relation with the effect.
 Conditioned Inhibition A phenomenon involving multiple stimuli that is predicted by both models is the acquisition of conditioned inhibition (Rescoria, 1969).
 In the standard design, a stimulus A (e.
g.
, a light flash) is first paired with an outcome (e.
g.
, a shock), so that A becomes excitatory.
 Then, a compound stimulus consisting of A together with a novel stimulus X (e.
g.
, a tone) is repeatedly presented, with the A X combination signaling absence of the outcome.
 Exposure to these events causes X to be perceived as inhibiting the outcome.
 The R W M predicts the conditioned inhibition of stimulus X because there is a discrepancy between the actual outcome given the compound A X (shock absent) and the expected outcome based on previous trials with A alone (shock present).
 This discrepancy leads to a reduction in the strength of X, which must become negative to offset the positive strength of A.
 Note that the P C M also predicts the conditioned inhibition of X.
 The contrast for X  the difference between the probability of the shock occurring when both the light and tone are present, and the probability of the shock when the light is present and the tone absent (i.
e.
, P(EiA.
X) P(EIA.
 X)) — is negative.
 Thus, both models predict that X will be judged inhibitory, consistent with Rescorla's (1969) finding using animal subjects.
 Although both models can account for the acquisition of conditioned inhibition, they make radically different predictions regarding the extinction of conditioned inhibition.
 The extinction of a conditioned inhibiting stimulus (such as X described above) occurs when new information leads to X no longer being perceived as preventative.
 The R W M predicts that conditioned inhibition will be extinguished by a "direct" procedure, in which a conditioned inhibiting stimulus X is later presented alone with the outcome absent.
 The R W M predicts that the inhibitory strength of the stimulus will become less negative (eventually reaching asymptote at a strength of zero), as the R W M revises the strength of a stimulus that is present to reduce the discrepancy between the actual and expected outcomes.
 The model therefore predicts that X will be extinguished as an inhibitor in the direct procedure.
 In contrast, the P C M predicts that the inhibitory value of X will remain unchanged, as the relevant conditional contrast mentioned earlier, P(EIA.
X)  P(EIA.
X), yields an unchanged negative number despite the intervening experience with X in the absence of A.
 Experiments using this design with animals have yielded support for the predictions of the P C M , in that the direct procedure fails to extinguish conditioned inhibition.
 ZimmerHart and Rescoria (1974) conducted several experiments with rats as subjects, and found that when a previously inhibiting stimulus was presented alone with no outcome, it retained its inhibiting strength in later trials when paired with a novel excitatory stimulus.
 The predictions of the two models are reversed for an "indirect" extinction procedure in which a previously excitatory stimulus A, which had been inhibited by a preventative stimulus X, is at a later time no longer paired with the presence of the outcome (i.
e.
, the excitatory power of A is extinguished).
 Given this information, the R W M 432 predicts that the inhibitory strength of X will remain unchanged because the R W M cannot update stimuli that are not present, and X is never present during the interval in which the excitor A is extinguished.
 The P C M , however, predicts that the inhibitory value of X will be attenuated, due to the fact that the relevant conditional contrast, P(EIA.
X) P(EIA.
 X ) , which had been negative when A was excitatory, approaches 0 given the subsequent events (the value of the first term remains at 0, while the value of the second shifts from 1 toward 0).
 Studies of animal conditioning (Kaplan & Hearst, 1985; Lysle & Fowler, 1985; Miller & Schachtman, 1985) have yielded results consistent with the predictions of the P C M , as conditioned inhibition is extinguished under the indirect procedure.
 It thus appears that the P C M provides a more accurate model of Pavlovian conditioning than does the R W M , in that the former model is more congruent with the results of several major animal conditioning studies.
 To evaluate these alternative models as explanations of causal inference, however, it is necessary to investigate the acquisition and extinction of conditioned inhibition by human subjects who are faced with causal relations.
 Moreover, previous studies have not directly compared the impact of the direct and indirect procedures on extinction of conditioned inhibition within the same experiment.
 Accordingly, the present study compares extinction of conditioned inhibition for humans given a causal inference task under both the direct and the indirect procedures.
 Method Subjects Sixtyone students in undergraduate psychology courses at the University of California, Los Angeles, served as subjects in exchange for course credit.
 Design and Procedure Subjects were given a cover story in which they were told that an outcome (a disease called D S E ) was either caused, prevented, or not affected by five candidate causes representing biochemical substances called "endomins," which were said to sometimes be produced by the body.
 The five candidates were labeled P, Q, R, S and T for subjects (with appropriate counterbalancing); here we will use the more mnemonic labels E,, Ej, E3, I, and U, where E indicates an excitatory cause, I an inhibitor, and U a candidate unrelated to the outcome.
 These candidates were associated with the outcome in specific covariational relationships, which were to be induced by subjects through trialanderror learning.
 Candidates E p Ej, and E3 were all causes of the disease, in that when these candidates were present with all other candidates absent, the disease was always present.
 The disease was always absent when no candidates were present.
 Candidate I was an inhibitory cause, in that when it was presented in tandem with either cause E] or E2, the disease was no longer present.
 Candidate U was irrelevant to the disease, in that the disease was always absent (at its baseline) when U was present, just as when U was absent.
 In the learning phase of this experiment, all subjects were given a series of learning trials in which they were expected to induce, by making use of feedback, the appropriate causal values for each candidate.
 All subjects were then tested, using two different measures, for learning of these causal relations.
 The first measure presented subjects with nine combinations of the various endomins (E,, Ej, E3,1, U, E, & Ej, E, & I, E2 & I, and E3 & I) and asked subjects to predict the number of patients out of one hundred who would contract the disease given each of these nine combinations.
 Note that two of these combinations (I alone, and E3 & I) were not presented during the learning trials.
 The second measure presented only the five single endomins, and asked the subject to indicate (by circling one choice) whether each endomin causes, prevents, or has no effect on the disease.
 The purpose of using two measures was to examine two different types of causal judgments that could be made.
 The first measure was implicit, in that it assessed the inhibitory power of candidate I (the candidate of interest) by subjects' predictions regarding the outcome given that I is presented with a newly paired excitatory cause (E3).
 The second measure, in contrast, was explicit in that it required subjects to make a direct causal judgment.
 The R W M and P C M make the same predictions regarding what subjects will learn during the initial learning phase.
 In particular, I should be judged as inhibitory.
 In the extinction phase, which immediately followed, subjects were divided into three groups.
 In the control group, all subjects were given additional trials of some information that had been presented in the initial learning phase; the purpose of this group was to provide a baseline for comparison.
 In the direct extinction condition, which was modeled after the conditions in the ZimmerHart and Rescorla (1974) study, subjects were presented with new trials in which the previously inhibitory cause (candidate I) was now presented alone in the absence of the disease.
 In the indirect extinction condition, which was based on the conditions used in the studies of Kaplan and Hearst (1985), Lysle and Fowler (1985), and Miller and Schachtman (1985), subjects received trials in which two previously excitatory causes (E, and E2) were now paired with the absence of the disease.
 Candidate I was not presented during the indirect extinction phase.
 Subjects completed the two measures of causal efficacy in the middle and at the end of the extinction phase.
 The measurements were taken twice in this phase to determine whether subjects had reached asymptote in their causal judgments after the extinction procedure.
 433 Implicit Scale Explicit Scale 100 •• 75 •• 50 • 25 0 Control Group 1 J 0.
5 + Learning Extinction 1 Extinction 2 + + 0.
5 1 I Learning Extinction 1 Extinction 2 100 T 75 50 •25 Direct Extinction Condition 1 T 0.
5 • 0.
5 •• Learning Extinction 1 Extinction 2 Learning Extinction 1 Extinction 2 100 r 75 50 25 • Indirect Extinction Condition 1 T 0.
5 Learning Extinction 1 Extinction 2 0.
5 1 L Learning Extinction 1 Extinction 2 Figure 1: Left column: means for all conditions for the implicit scale (number of patients out of 100 w h o were judged as having the disease w h e n E3 & I are present); right column: means for the explicit scale based on causal ratings for candidate I (causes = 1; no effect = 0; prevents = 1).
 434 Results The bar graphs in the left column of Figure 1 present the results for the implicit measure of the inhibitory power ol candidate I across the three test phases (learning, cxiinction 1, extinction 2): the mean predicted frequency of the disease (maximum of 100) for cases exhibiting the I & E3 combination.
 The bar graphs in the right column of Figure 1 depicts the parallel set of results for the explicit measure: the mean causal rating for candidate I on a scale from 1 (causal) to 1 (preventative).
 The overall pattern of results was qualitatively the same for both causal measures.
 For each measure, a 3 x 3 analysis of variance with condition (control, direct procedure, indirect procedure) and test phase (learning, first extinction phase, second extinction phase) as independent variables was performed.
 Both measures yielded a significant interaction between condition and test phase, F (4, 116) = 14.
82, p < .
001 for the implicit measure, and F (4, 116) = 6.
83, p < .
001 for the explicit measure.
 Orthogonal contrasts were then used to assess whether the perceived causal power of I changed from the learning phase to the two extinction phases (collapsing across the latter).
 Neither the control condition nor the direct extinction procedure yielded any change across the test phases on either measure.
 Both the implicit and the explicit scales revealed that candidate I was perceived as an inhibitor (preventative) of the disease after the initial learning phase, and its inhibitory power remained constant across the later phases.
 The results for the indirect extinction condition were strikingly different.
 As the P C M predicts, the inhibitory power of I decreased markedly from learning to extinction, F (1, 58) = 69.
83, p < .
001 for the implicit measure, and F (1, 58) = 25.
29, p < .
001 for the explicit measure.
 Discussion The results from the present study clearly favor the PCM over the R W M as an account of the conditions under which the causal analog of conditioned inhibition can be extinguished.
 The direct procedure of presenting the inhibitory cause alone in the absence of the effect had no impact at all on its perceived preventative power, whereas the indirect procedure of extinguishing the causal power of a previously excitatory cause essentially eliminated the perceived preventative power of the inhibitory candidate.
 These two results each undercut a basic assumption of the R W M and related connectionist learning models.
 The former undercuts the assumption that the associative strengths of stimuli that are present are revised to reduce the discrepancy between the actual and expected outcomes.
 Contrary to this assumption, our results show that despite such a discrepancy during a period in which only one stimulus (I) was present, the associative strength of that stimulus was not revised.
 The latter result undercuts the assumption that only stimuli that are actually present (i.
e.
, have nonzero activation) have their associative strengths revised.
 Contrary to that assumption, the present experiment shows that the strength of a stimulus (I) was reduced during a period in which it was never presented.
 Conversely, these findings support a basic claim of statistical contingency models, namely, that causal judgments are sensitive to the contrast between the probabilities of the effect in the presence versus the absence of a candidate cause, when other causes are held constant.
 The present results extend the comparable findings obtained in several classic experiments on Pavlovian conditioning (Kaplan & Hearst, 1985; Lysle & Fowler, 1985; Miller & Schachtman, 1985; ZimmerHart & Rescorla, 1974).
 The present study is the first to compare the direct and indirect extinction procedures within a single experiment.
 In addition, the present study is the first to test either procedure with human subjects under a causal inference context, rather than animal subjects in Pavlovian conditioning.
 Our findings reveal that sensitivity to the indirect extinction procedure generalizes from laboratory animals to humans, and from conditioning to explicit, as well as implicit, causal judgments.
 Our results thus support the contention that the evaluation of covariation in causal contexts is based on sensitivity to statistical information that goes beyond the kind of information implicitly tallied by associationistic models of learning.
 Acknowledgments This material is based upon work supported under a National Science Foundation Graduate Research Fellowship to the first author, and National Science Foundation Grant D B S 9121298 to the second author.
 W e thank JooYong Park and Charles Wharton for their assistance.
 References Cartwright, N.
 (1989).
 Nature's capacities and their measurement.
 Oxford: Clarendon Press.
 Chapman, G.
 B.
, & Robbins, S.
 I.
 (1990).
 Cue interaction in human contingency judgment.
 Memory & Cognition, 18, 537545.
 Cheng, P.
 W.
, & Holyoak, K.
 J.
 (in press).
 Complex adaptive systems as intuitive statisticians: Causality, contingency, and prediction.
 In J.
A.
 Meyer & H.
 Roitblat (Eds.
), Comparative approaches to cognition.
 Cambridge, M A : MIT Press.
 Cheng, P.
 W.
, & Novick, L.
 R.
 (1990).
 A probabilistic contrast model of causal induction.
 Journal of Personality and Social Psychology, 58, 545567.
 Cheng, P.
 W.
, & Novick, L.
 R.
 (1991).
 Causes versus enabling conditions.
 Cognition, 40, 83120.
 Cheng, P.
 W.
, & Novick, L.
 R.
 (1992).
 Covariation in natural causal induction.
 Psychological Review, 99, 365382.
 Gallistel, C.
 R.
 (1990).
 The organization of learning.
 Cambridge, M A : M I T Press.
 Gluck, M.
 A.
, & Bower, G.
 H.
 (1988).
 From conditioning to category learning: An adaptive network model.
 Joumalof Experimental Psychology: General, 117, 227247.
 Jenkins, H.
, & Ward, W .
 (1965).
 Judgment of contingency between responses and outcomes.
 Psychological Monographs, 79, 117.
 Kaplan, P S.
, & Hearst, E.
 (1985).
 Contextual control and excitatory versus inhibitory learning: Studies of extinction, reinstatement, and interference.
 In P.
 D.
 435 Balsam & A.
 Tomie (Eds.
), Context and li'cirning (pp.
 195224).
 Hillsdale.
 NJ: Erlbaum.
 Kelley, H.
H.
 (1967).
 Attribution theory in social psychology.
 In D.
 Levine (Ed.
).
 Nebraska symposium on motivation (Vol.
 15.
 pp.
 192238).
 Lincoln: University of Nebraska Press.
 Lysle.
 D.
 T.
, & Fowler, H.
 (1985).
 Inhibition as a "slave" process: Deactivation of conditioned inhibition through extinction of conditioned excitation.
 Journal of Experimental Psychology: Animal Behavior Processes, 11, 7194.
 Melz.
 E.
 R.
.
 Cheng, P W.
.
 Holyoak, K.
 J.
, & Waldmann, M .
 R.
 (1993).
 Cue competition in human categorization: Contingency or the RescorlaWagner rule? Comments on Shanks (1991).
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 19, 13981410.
 Miller, R.
 R.
, & Schachtman, T.
 R.
 (1985).
 Conditioning context as an associative baseline: Implications for response generation and the nature of conditioned inhibition.
 In R.
 R.
 Miller & N.
 E.
 Spear (Eds.
).
 Information processing in animals: Conditioned inhibition (pp.
 5188).
 Hillsdale, NJ: Erlbaum.
 Pearl, J.
 (1988).
 Probabilistic reasoning in intelligent systems.
 San Mateo, CA: Morgan Kaufmann.
 Rescorla, R.
 A.
 (1969).
 Conditioned inhibition of fear.
 In W .
 K.
 Honing & N.
 J.
 Mackintosh (Eds.
), Fundamental issues in associative learning.
 Halifax: Dalhousie University Press.
 Rescorla, R.
 A.
, & Wagner, A.
 R.
, (1972).
 A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonrcinforcement.
 In A.
 H.
 Black & W .
 F.
 Prokasy (Eds.
), Classical conditioning 11: Current research and theory (pp.
 6499).
 New York: AppletonCenturyCrofts.
 Shanks, D.
 R.
 (1991).
 Categorization by a connectionist network.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 17, 433443.
 Shanks.
 D.
 R.
.
 & Dickinson, A.
 (1987).
 Associative accounts of causality judgment.
 In G.
 H.
 Bower (Ed.
), The psychology of learning and motivation, (Vol.
 21, pp.
 229261).
 New York: Academic Press.
 Sutton, R.
 S.
, & Barto, A.
 G.
 (1981).
 Toward a modern theory of adaptive networks: Expectation and prediction.
 Psychological Review, 88, 135170.
 Wasserman, E.
 A.
 (1990).
 Attribution of causality to common and distinctive elements of compound stimuli.
 Psychological Science, 1, 298302.
 ZimmerHart, C.
 L.
, & Rescorla, R.
 A.
 (1974).
 Extinction of Pavlovian conditioned inhibition.
 Journal of Comparative and Physiological Psychology, 86, 837845.
 436 Biases in Refinement of Existing Causal Knowledge Wookyoung Ahn Department of Psychology University of Louisville Louisville, K Y 40292 wkahnOOlOhomer.
louisville.
edu Raymond J.
 Mooney Department of Computer Sciences University of Texas Austin, TX 78712 mooneyOcs.
utexas.
edu Abstract This study describes a psychological experiment on biases that people exhibit in refining probabilistic causal knowledge.
 In the experiment, the effect of background knowledge was shown by manipulating the causal structure of prior knowledge provided to the subjects.
 It was found that later training instances affected the refinement of the background knowledge in different ways depending on the causal model initially given to the subjects.
 The two biases found in the current experiment are (1) knowledge refinement was conservative in the sense that background knowledge was modified as little as possible to account for the observed data and (2) weakening of an existing causal relationship resulted in automatic strengthening of a related causal relationship.
 Introduction How do people revise their existing knowledge given new observations that do not clearly fit with their initial knowledge? In most natural situations, at least some prior knowledge of relevant causal mechanisms is available to explain external stimuli.
 In certain cases, some relevant causal knowledge is available but new causal relationships may need to be inferred in order to fully account for the observed data.
 The current study investigates the specific nature of knowledge refinement as a learner acquires new training instances that cannot be fully explained by existing knowledge.
 Need for psychological studies on biases in knowledge refinement Research in both machine learning and psychology has revealed the important role that prior knowledge plays in learning.
 Psychological research has demonstrated that subjects' learning is greatly affected by their naive theories and existing domain knowledge (Murphy & Medin, 1985; Ahn, Brewer, & Mooney, 1992; Pazzani, 1991).
 Depending on the presence or absence of relevant background knowledge, subjects learn different concepts from the same examples (Wisniewski, 1989).
 Meanwhile, machine learning research has developed algorithms that learn more accurate concepts from fewer examples when given relevant background knowledge in the form of an approximate domain theory (Mooney, 1993; Pazzani, 1991; Pazzani & Kibler, 1992; Towell, Shavlik, & Noordewier, 1990).
 Although these studies have clearly demonstrated that prior knowledge greatly affects human learning, most of this research have ignored how prior knowledge is modified by experience.
 For example, Pazzani (1991) presented empirical results on how prior causal knowledge influenced categorization and also developed a computational model of this process; however, he did not address the issue of how existing causal knowledge itself is affected by conflicting data.
 Nonetheless, theories concerning biases of knowledge revision are in great demand in knowledge engineering.
 It is generally agreed that the primary difficulty with developing robust knowledgebased systems is the knowledge acquisition bottleneck (i.
e.
, the complexity of extracting and encoding the domain knowledge needed to perform the task).
 Knowledgebased systems are typically developed by first interviewing an expert in order to obtain an initial set of rules.
 Next, the knowledge base is incrementally improved in a laborious process referred to as knowledgebase refinement.
 Typically, a set of sample problems is used to detect errors in the knowledge base and corrections are determined during a timeconsuming consultation with the expert.
 Recent research in theory refinement attempts to automate the laborious process of knowledge refinement by using various machine learning techniques to automatically revise an existing, approximate knowledge base to fit a set of empirical data (Ginsberg, Weiss, & Politakis, 1988; Ourston & Mooney, 1990; Towell et al.
, 1990; Koppel, Feldman, & Segre, 1994).
 The current study provides initial data revealing important biases that humans display in revising their existing knowledge.
 Specifically, it focuses on the revision of probabilistic causal knowledge, in which underlying causes (e.
g.
 diseases) probabilistically manifest certain effects (e.
g.
 symptoms).
 Such knowledge can be formally represented as a Bayesian network (Pearl, 1988).
 The question is how the strength of existing causal relationships and the addition of new causal links are 437 affected by new evidence that is not fully consistent with existing causal knowledge.
 Main Claim Our general predictions are that changes are conservative (i.
e.
, background knowledge is modified as little as possible to account for the observed data) and that changes in the strengths of known causal links are preferred to inferring new causal connections.
 Therefore, as long as existing knowledge is consistent with the observed data, a new piece of causal knowledge will not be acquired even if this new causal explanation would be more parsimonious.
 Ahn, Kalish, Medin, and Gelman (1995) have also demonstrated a similar point using an informationseeking paradigm in causal reasoning.
 In this study, subjects received event descriptions and were instructed to ask questions in order to explain the events.
 The subjects tended to seek out information that would provide evidence for or against hypotheses about underlying mechanisms with which they were already familiar.
 In contrast, previous psychological models on causal attributions have emphasized that the most critical and necessary information in causal attributions is information about covariation between candidate causes and effects (e.
g.
, Cheng & Novick, 1992; Kelley, 1967, 1971).
 These models tended to focus on the bottomup processes of acquiring novel causal relationships rather than on the topdown processes of utilizing existing causal knowledge.
 However, Ahn et.
 al's results showed that people did not seek out a novel causal relationship between arbitrary factors by relying solely on covariation information.
 Rather, people attempted to seek out evidence for causal mechanisms with which they were already familiar, a result which supports the idea that people are conservative in learning new causal relationships.
 Experiment The current experiment investigates under what conditions people add new causal connections to prior domain knowledge as opposed to modifying the strength of existing connections.
 Methods Subjects received background knowledge in the form of one of three causal models as shown in Figure I.
 In these models, A, B, C and/or D are symptoms caused by two new diseases, X and Y.
 In all of the conditions, subjects were told that disease X caused symptoms A and B 7 0 % of the time (indicated by solid arrow lines in the figure) and symptom C 2 0 % of the time (indicated by dotted arrow lines in the figure) and that disease Y caused symptoms B and C 70 % of the time and symptom A 2 0 % of the time.
 The difference between the three causal structures lies in the causal relationship between symptom D and the diseases.
 In the indirectcause condition, symptom D was caused by symptom B, and therefore also indirectly caused by diseases X and Y; in the directcause condition, symptom D was caused directly by diseases X and Y; and in the nocause condition, there was no known cause for D.
 Finally, the subjects were told that both diseases were equally likely to occur a priori.
 After learning these causal structures, the subjects judged the likelihood of various and in the nocause factors given various configurations of other factors.
 There were six test items; P(X|B), P(Y|B), P(X|B and no D), P(Y|B and no D), P(X|A), and P(Y|C).
 For example, for P(X|B), the subjects were asked, "What is the probability that a person who exhibits symptom B has disease X? %" X Y Indirect Cause Condition DirectCause Condition X Y No Cause Condition < 70 % causal relationship ^ 20 % causal relationship Figure 1.
 Causal models used in each condition 438 Then, subjects in all conditions received information on a set of training cases which were described as data gathered afterwards.
 These training cases were constructed in such a way that symptom D was more associated with disease X than with disease Y.
 The actual description of the training cases was; 70% of patients with symptom D had disease X; 30% had disease Y.
 7 5 % of patients with symptoms D and B had disease X; 2 5 % had disease Y.
 6 0 % of patients with symptoms D and C had disease X; 4 0 % had disease Y.
 2 0 % of patients with symptom C but not D had disease X, 8 0 % had disease Y.
 After that, the subjects judged the likelihood of the test items again.
 While making these judgments, the subjects were provided with the figure of the initial causal structure and the description of the new training cases.
 Therefore, in making all these judgments, there was no demand on memory.
 Prediction cause condition would not construct a new causal link betv X and D because D could aheady be explained as an indi effect of X through B.
 O n the other hand, subjects in nocause condition would infer a new direct causal connec between X and D in order to account for the data.
 ' difference would be reflected in the increase in the estimat P(X|D, not B); More specifically, the increase should be in the indirectcause condition than the nocause condit since the absence of B would indicate that D did not cc about as a sideeffect of X causing B; whereas the absenci B would not affect a direct connection between X and D the nocause condition.
 As in the indirectcause condition, the subjects in direct condition would not need to construct a new 1 between X and D because this relationship is ake, explained by the existing causal link.
 Therefore, the incre in the estimate of P(X|D, not B) should be similar in indirectcause and the directcause condition.
 In addition the nocause condition had acquired a direct causal 1 between X and D through the training instances, their secc rating on P(X|D, not B) should be similar to the second rat of the directcause condition.
 As a result, the directcai condition serves as a baseline group for the other t conditions.
 The basic prediction was that subjects in the indirectTable 1.
 Results of the Nocause condition Test! Test2 Testl  Test2 P(X|B) 55.
3 65.
0 9.
7 P(Y|B) 55.
3 42.
4 12.
9 P(X|D,noB) 19.
4 58.
5 39.
1 P(Y|D,noB) 19.
4 37.
9 18.
5 P(X|A) 62.
4 61.
2 1.
18 P(Y|C) 60.
6 65.
6 5.
0 Table 2.
 Results of the Indirectcause condition Testl Test2 Testl Test2 P(X|B) 57.
4 68.
4 11.
1 P(Y|B) 55.
0 41.
4 13.
7 P(X|D,noB) 37.
9 41.
9 3.
9 P(Y|D,noB) 33.
2 29.
4 3.
8 P(X|A) 64.
7 70.
0 5.
3 P(Y|C) 65.
3 59.
1 6.
2 439 Table 3.
 Results of the Directcause condition Test I Test2 Testl Test2 P(X|B) 57.
7 58.
2 0.
5 P(Y|B) 53.
5 42.
9 10.
5 P(X|D,noB) 45.
8 53.
7 7.
9 P(Y|D,noB) 44.
6 36.
9 7.
7 P(X|A) 65.
0 58.
8 6.
2 P(Y|C) 50.
2 71.
2 20.
92 Results a n d Discussion Tables 13 summarize the results.
 Each table shows mean probability judgments by each condition.
 In each condition, the second row indicates mean ratings on the first test, the third row indicates the mean ratings on the second test after the training instances, and the fourth row indicates the differences between the second and the first tests.
 For each test item, an A N O V A was conducted with the condition as a betweensubject variable and the two tests as a withinsubject variable.
 The focus of the current study is the interaction between the increase of the probability estimates and the three conditions; that is, does the increase or decrease of the causal strength changes as a function of existing causal knowledge? Only three out of the sue test items resulted in a reliable interaction effect at p < .
05; P(X|D, not B), P(Y|D, not B), and P(Y|C).
 The following figures illustrate the direction of the interaction effect on these three items.
 As can be inferred from the figures, the indirectcause and the directcause condition did not significantly increase or decrease their estimates for P(X|D, no B) and P(Y|D, no B), whereas the nocause condition significantly increased their estimates.
 Also, prior to training, the estimate for P(X|D, no B ) in the nocause condition is significantly less than the indirectcause condition, whereas after training it is significantly greater than the indirectcause condition.
 These results indicate that only the nocause condition established a new causal link between X and D and a somewhat weak, direct link between Y and D.
 Although the subjects in the indirectcause condition could have established a new causal link between X and D based on the same training instances, they presumably applied their existing knowledge to account for the association between X and D (i.
e.
, X causes B and therefore causes D).
 Because of this interpretation of the association between X and D, it mattered much more for the indirectcause condition not to have symptom B compared to the nocause condition, since B's absence blocks the known causal path between X and D.
 Another interesting but unexpected result came from the changes in the estimate of P(Y|C).
 The directcause condition's estimate significantly increased after the training instances compared to the other conditions.
 This is an mean% estimate 70 60 P(X|D, no B) 5040 30 20 First Second mean % estimate 70 mean % estimate 70 6050 40 30 20 P(Y|D, no B) • y ^ First Second P(Y|C) DirectCause 60 50 40 30 20 ' « ^ *_ _« IndirectCause % m NoCause First Second Figure 2.
 Results from the three conditions 440 unexpected finding because as far as the link between disease Y and symptom C is concerned, all three conditions were initially the same and they all received exactly the same training instances.
 Our interpretation is as follows: Note that in the training instances, the association between symptom D and disease Y is somewhat weakened whereas the association between symptom C and disease Y is somewhat strengthened.
 In the directcause condition, which is the only condition who started out with a direct link between Y and D, this causal link must have been weakened by the training instances.
 Then, this weakened link might have actually increased diagnostic values of other symptoms.
 In other words, as one symptom became less diagnostic of disease Y, the other symptom automatically became more diagnostic.
 This new phenomenon can be considered a converse of the "discounting effect" or "explaining away" for the revision of causal strengths.
 According to the discounting effect proposed by Kelley, people tend to discount a candidate cause if we fmd out that one cause is already responsible for the effect.
 For example, if Mary finds out that her brother took her radio away, she might wonder whether it was because his radio was broken or he was mad at her.
 Finding out that her brother's radio was actually broken, she is less likely to believe that her radio was taken because he was mad at her.
 In Artificial Intelligence, this phenomenon is called "explaining away" and is computationally implemented in Bayesian networks (Pearl, 1988), providing a normative account of this psychological principle.
 The current results on P(Y|C) in the directcause condition seem the converse of the discounting effect.
 That is, initially, one starts out with a belief that a cause has two effects.
 As one of the causes is weakened through later observations, people automatically boost up the strength of the other causal relationship.
 To give a more reallife example of this phenomenon, suppose one initially believed that having an extra Xchromosome caused a person to have a highpitched voice and to be agreeable.
 If the later observations indicated that there was no genetic ground for being agreeable, then having a highpitched voice would gain a more diagnostic value for the existence of an extra Xchromosome.
 Conclusion The current study had demonstrated two interesting biases in refinement of causal background knowledge as a function of its initial causal structure and training instances.
 First, the refinement occurred in a conservative manner.
 People would not construct a new causal link as long as their existing causal knowledge can explain the new training instances even when this causal explanation was less direct and parsimonious.
 This phenomenon is consistent with processes underlying stereotype formation; Even if there can be many alternative ways of accounting for one's behavior, people would rather apply their existing knowledge than take a new perspective on the observation and learn a new possible causal connection.
 Second, weakening an existing causal strength might actually strengthen the causal strength of an alternative effect.
 In the future, we hope to explore additional biases that people exhibit when revising probabilistic causal knowledge by examining the effect of different types of data on a larger variety of initial causal structures.
 In addition to inferring the revisions subjects made to their knowledge based on their subsequent judgements, we plan to more directly inquire into the exact changes they make to prior causal knowledge in order to account for conflicting data.
 W e also hope to develop and test a computational model of revising probabilistic causal knowledge based on revising both the parameters and structure of a Bayesian network to make it consistent with a set of training data.
 This model will attempt to integrate methods for revising existing causal strengths (Schwalb, 1993) with methods for inducing new causal structures (Cooper & Herskovits, 1992).
 References Ahn, W.
, Brewer, W.
 F.
, & Mooney, R.
 J.
 (1992).
 Schema acquisition fiom a single example, Journal of Experimental Psychology: Learning, Memory, & Cognition, 18, 391412.
 Ahn, W.
, Kalish, C.
 W.
, Medin, D.
 L.
, & Gelman, S.
A.
 1995).
 The role of covariation versus mechanism information in causal attribution.
 Cognition, 54, 299352.
 Cheng, P.
 W.
, & Novick, L.
 R.
 (1992).
 Covariation in natural causal induction.
 Psychological Review, 99, 365382.
 Copper, G, G.
, & Herskovits, E.
 (1992).
 A Bayesian Method for the Induction of Probabilistic Networks from Data.
 Machine Learning, 9, 309347 Ginsberg, A.
, Weiss, S.
 M.
, & Politakis.
 (1988).
 Automatic knowledge based refinement for c\d&s\i\cdXion sysiems.
 Artificial Intelligence, 35, 197226.
 Kelley, H.
 H.
 (1967).
 Attribution theory in social psychology.
 In D.
 Levine (Ed.
), Nebraska symposium on motivation (Vol.
 15, pp.
 192238).
 Lincohi: University of Nebraska Press.
 Kelley, H.
 H.
 (1971).
 Attribution in social interaction.
 Morristown, NJ: General Learning Press.
 Koppel, M.
, Feldman, R.
 R.
, & Segre, A.
 M.
 (1994).
 Biasdriven revision of logical domain theories.
 Journal of Artificial Intelligence Research, I, 150.
 Mooney, R.
 J.
 (1993).
 Integrating theory and data in category learning.
 In G.
 Nakamura, R.
 Taraban, & D.
 L.
 Medin (Eds.
) Categorization by humans and 441 machines: The Psychology of learning and motivation, 29, 189218.
 Orlando, FL: Academic Press.
 Murphy, G.
 L.
, & Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review.
, 92, 289316, Pazzani, M.
 J.
 (1991).
 A computational theory of learning causal relationships.
 Cognitive Science, 15, 401424.
 Pazzani, M.
 J.
, Kibbler, D.
 (1992).
 The utility of background knowledge in inductive learning.
 Machine Learning, 9, 5794.
 Pearl, J.
 (1988).
 Probabilistic reasoning in intelligent systems: Networks of plausible inference.
 San Mateo: Morgan Kaufmann.
 Schwalb, E.
 (1993).
 Compiling Bayesian networks into neural networks.
 In Proceedings of the Tenth International Conference on Machine Learning, 291297, Amherst, MA.
 Towell, G.
 G.
, Shavlik, J.
 W.
, & Noordewier, M.
 O.
 (1990).
 Refinement of approximate domain theories by knowledgebased artificial neural networks.
 In Proceedings of the Eighth National Conference on Artificial Intelligence, 861866.
 Boston, M A .
 Wisniewski, E.
 J.
 (1989).
 Learning from examples: The effect of different conceptual roles.
 Proceedings of the Eleventh Annual Conference of the Cognitive Science Society, 980986.
 Ann Arbor, MI.
 442 M o r e than Feature Comparison: Processes Underlying Similarity and Probability J u d g m e n t Valerie M .
 Chase Department of Psychology University of Chicago 5848 S.
 University Ave.
 Chicago, IL 60637 vinc5@ccp.
 uchicago.
 edu M i r i a m B a s s o k Department of Psychology University of Chicago 5848 S.
 University Ave.
 Chicago, IL 60637 mbmb@ccp.
spc.
uchicago.
edu Abstract Explanations of many cognitive processes, including probability judgment, rely on the construct of similarity.
 The present paper is concerned with the similaritybased explanation of reasoning in the conjunction task.
 Although high positive correlations have been found between similarity and probability judgments in this task, these alone cannot validate the assumption that similarity is judged by a process of feature comparison or that similarity judgment is an explanation of probability judgment.
 Preliminary results from a study in which we collected written justifications from subjects who made both types of judgment suggest that these assumptions are not tenable.
 Subjects cited considerations of causality and statistics ~ not just feature overlap  when judging both similarity and probability, indicating that (1) feature comparison is only one way in which people judge similarity and (2) similarity judgment can involve processes usually associated with probability judgment.
 These findings suggest that the role of similarity in explaining other cognitive processes needs to be revised.
 It is proposed that the power of similarity and probability to predict one another can be exploited for the purpose of making either type of judgment.
 Introduction Explanations of many cognitive processes, including categorization, probabilistic reasoning, and analogical transfer, rest on the construct of similarity at some level.
 Similaritybased explanations of cognition generally make two crucial assumptions about similarity judgment mechanisms and the role of similarity judgment in explaining other cognitive processes.
 The first assumption is that similarity is the outcome of a process of comparison, usually mediated by a mechanism that evaluates matches and mismatches between features representing the compared entities.
 The second assumption is that similarity judgment is a fundamental cognitive process that underlies many other cognitive processes and serves as an explanation of them.
 In the present paper, we present evidence from a protocol study in which we investigated both of these assumptions.
 W e collected similarity and probability estimates in a classic probabilistic reasoning task, the conjunction task.
 As in previous studies, we found that the two types of estimate are highly positively correlated.
 However, subjects' written justifications of their estimates revealed that, in addition to feature comparison, judgments in both tasks were also mediated by causal and statistical inferences.
 W e chose to study the conjunction task because the most prevalent explanation of reasoning in this and other probabilistic reasoning tasks — the "representativeness heuristic" ~ rests squarely on the similarityasexplanation and similarityascomparison assumptions.
 Similarity and probability judgments The representativeness heuristic has been defined as a rule of thumb by which subjects make a similarity judgment in lieu of the requested probability judgment (Kahneman & Tversky, 1972).
 For example, they might judge the similarity between a person and a particular category of people in order to derive the probability that the person is a member of the category.
 Because similarity is often positively correlated with probability, it is argued that judgment by representativeness is a plausible and useful way to make probability judgments.
 Thus researchers of probabilistic reasoning have made the similarityasexplanation assumption by proposing that similarity judgment underlies the judgments made by subjects performing a variety of probabilistic tasks (e.
g.
, Shafir, Smith, & Osherson, 1990).
 The same researchers have adopted the similarityascomparison assumption by operationalizing the representativeness hypothesis in terms of traditional featurematching models of similarity judgment (e.
g.
.
 Smith & Osherson, 1989).
 Featurematching models of similarity judgment make simplifying assumptions at the levels of both representation and processing.
 First, they assume that categories such as "spoon" can be represented as lists of feature slots (e.
g.
, color, size, purpose) that take on different feature values (e.
g.
, brown, large, used for mixing food).
 Next, they posit that the similarity between two entities is a weighted additive function of their common and distinctive features.
 Tversky's (1977) classic contrast model of similarity judgment assumes such a featurematching process and has served as the basis for many subsequent cognitive models involving similarity judgment.
 Featurematching models have fared reasonably well in predicting human judgments of similarity between schematic figures (Tversky, 1977; Tversky & Gati, 1978) and between simple adjectivenoun conceptual combinations such as "brown apple" and "green 443 mailto:mbmb@ccp.
spc.
uchicago.
eduapple" (Smith & Osherson, 1984; Smith.
 Osherson, Rips, & Keane, 1988).
 Despite their ubiquity, featurematching models of similarity judgment have drawn considerable criticism for their lack of constraints and untenable assumptions (e.
g.
, Goodman, 1972; Medin, Goldstone, and Centner, 1993).
 These assumptions become increasingly compromising as one moves from relatively simple, artificial categories to naturally occurring object categories such as "spoon," all the way up to the kinds of complex concepts most relevant to probabilistic reasoning, such as "friend" and "conservative.
" There is considerable evidence that modeling categories in terms of features and feature slots does not capture the structure of people's conceptual representations (Murphy & Medin, 1985), particularly when it is assumed that features are independent (Goldstone, Medin, & Centner, 1991).
 Moreover, it has been demonstrated that in similarity judgment, relations as well as features are aligned for the purposes of comparison (e.
g.
, Markman & Centner, 1993), However, even models that take account of the role of relations cast similarity judgment as a process of comparison.
 In this paper, we explore the processing that underlies similarity judgment in the conjunction task as well as in a typicality judgment task based on it.
 In a typical conjunction task, subjects receive a description of a person (e.
g.
, "Linda is 31, single, majored in philosophy and was concerned with issues of discrimination and social justice in college") and are asked to judge the probability that the person described is a member of three categories: two constituent categories (e.
g.
, bank teller, active in the feminist movement) and a conjoint category comprised of the two constituents (e.
g.
, bank teller who is active in the feminist movement).
 When the description is informative with respect to the categories and especially when the description differentially "points to" the constituent categories as in the Linda task, most subjects (typically about 80%) rank the probability of the conjoint category to be higher than the probability of one of the constituent categories (i.
e.
, they tend to think it is more probable that Linda is a bank teller who is active in the feminist movement than that she is a bank teller).
 This is considered to be a violation of the conjunction rule.
 The similaritybased explanation of conjunction rule violations states that subjects assess the given person's similarity to each category representation in order to judge the probability that the person is a member of each category.
 The claim that similarity judgment underlies probability judgment in the conjunction task has received support from studies in which typicality' ratings were found to be highly positively correlated with probability ratings on the same items (Shafir et al.
, 1990; Tversky & Kahneman, 1983).
 Shafir et al.
 (1990) explained the high positive correlation in qualitative terms as the result of a featurecomparison process responsible for both typicality and probability 'Ordinarily, the term "similarity" is used when the comparison is between instances, and "typicality" when the comparison is between an instance and a category.
 The terms will be used interchangeably here.
 judgment.
 Elsewhere, Smith and Osherson (1989) proposed a formal featurematching model of reasoning in the conjunction task based on Tversky's (1977) contrast model.
 The positive correlation between typicality and probability judgments used to support the similaritybased explanation of probabilistic reasoning leaves two questions unanswered: (1) Does typicality judgment underlie probability judgment, does probability judgment underlie typicality judgment, or are both supported by another process? (2) Assuming that typicality judgment underlies probability judgment, is feature comparison the only process by which typicality is computed? If not, what other processes are involved? The present study was designed to investigate these questions using items and measures adapted from Shafir et al.
 (1990).
 In order to assess the reasoning behind the estimates, we asked subjects to provide written justifications describing their thinking as they solved the task.
 This is the first study we know of in which justifications were collected in a correlational study of probability and typicality judgment.
 Although such justifications will not necessarily capture the underlying cognitive processing, they should reveal something about subjects' understanding of what information is relevant to the task and how this information should be used.
 Method Subjects.
 Subjects were 160 University of Chicago undergraduates who completed the experiment in small groups (28) immediately after various classroom lectures.
 Materials.
 The experiment was based on Experiment 1 in Shafir et al.
 (1990).
 Each subject received a questionnaire consisting of an instruction page and a response page.
 The instruction page informed the subject that the task was to make either probability or typicality estimates.
 (Estimate type was varied between subjects.
) A sample item was given so that subjects knew what to expect in the task.
 The response page showed one item consisting of a personality description and three categories to be judged.
 Procedure.
 Each subject received one of eight possible personality descriptions.
 Depending on the condition to which they were assigned, subjects were required to judge either the probability that the person described was a member of each of three categories or to judge the typicality of the person in each of the same categories.
 They were instructed to express their estimates on a 0tol scale, where 0 meant minimal probability (typicality) and I meant maximal probability (typicality).
 Each category triplet consisted of two single categories and a third category representing their conjunction.
 For example, a subject in the probability condition who read the description of Linda summarized earlier might have to judge the probability that Linda is (1) a bank teller, (2) active in the feminist movement, and (3) a bank teller who is active in the feminist movement, while a corresponding subject in the typicality condition judged Linda's typicality in the categories "People who are bank tellers," "People who are active in the feminist movement," and "People who are bank 444 tellers and who are active in the feminist movement.
" Order of constituent categories was randomized, with the conjoint category always appearing last.
 Half of the conjunctions, such as "bank teller who is active in the feminist movement," were "incompatible.
" The other half of the conjunctions, such as "teacher who is active in the feminist movement," were "compatible.
" Shafir et al.
 (1990) defined an incompatible conjunction in featurematching terms as one whose constituents share few properties and a compatible conjunction as one whose constituents share many properties.
 Although w e prefer not to define compatibility in this way, it should be intuitively clear that the two types of conjunction differ in how well they "fit together.
" (The compatibility factor did not affect the results reported in this paper and therefore will not be discussed further.
) Three of the eight personality descriptions and their associated conjunctions (which will be used for the purpose of illustration later) appear below.
 Compatible conjunctions are labeled "C" and incompatible conjunctions "I.
" Linda is 31, single, outspoken, and very bright.
 She majored in philosophy.
 In college, she was concerned with issues of discrimination and social justice and participated in antinuclear demonstrations.
 C: teacher who is active in the feminist movement I: bank teller who is active in the feminist movement Jack began his job immediately after completing high school.
 He frequently talks on his C B radio and goes to sporting events when he can.
 C: truck driver who plays softball for a hobby I: truck driver who watches birds for a hobby Richard is 50 years old.
 He loves his job, but is not very well liked by his colleagues.
 He is single, shy, and does not like to go out on social events.
 C: engineer who collects stamps for a hobby I: engineer who plays volleyball for a hobby Data Analysis and Results W e first report on subjects' quantitative estimates and then present our qualitative analysis of their written justifications.
 Quantitative estimates Consistent with previous studies, we found that the mean probability and typicality estimates for a given category in a given item were positively correlated.
 The Spearman correlations between the two types of estimates for matching items were .
71 for constituents and .
78 for conjunctions.
 W e computed the parallel correlations from the data reported by Shafir et al.
 (1990) and found them to be .
91 and .
73 for constituents and conjunctions, respectively.
 Thus, w e replicated the general finding that probability and typicality estimates in the conjunction task are positively correlated.
 In the next section w e report results that shed light on the nature of this correspondence at the level of processing.
 In the probability condition, 2 4 % of subjects (19 out of 80) estimated the probability of the conjunction to be greater than one or both of the constituents, i.
e.
, violated the conjunction rule.
 In the typicality condition, 4 6 % of subjects (37 out of 80) estimated the typicality of the instance in the conjoint category to exceed its typicality in one or both constituent categories.
 Although our finding of 2 4 % violations may seem to contradict the results of other studies, in which up to 8 7 % of subjects violated the conjunction rule in the Linda problem, Tversky and Kahneman (1983) themselves found that as few as 3 6 % of subjects violated the conjunction rule in the Linda problem under some conditions.
^ Because Shafir et al.
 (1990) did not report the percentages of violations by item, w e could not directly compare our results on this measure to theirs in either condition.
 W e believe that some probability and typicality subjects whose conjoint estimates did not exceed either constituent estimate allowed the conjunction rule to guide their judgments.
 From the binary measure of conjunction rule violations, it is impossible to tell whether the probability subjects w h o did not violate the rule followed it systematically or inadvertently.
 Similariy, one cannot tell if the typicality subjects intentionally applied the conjunction rule.
 However, w e can begin to answer this question indirectly by looking at the estimates to see what percentage of subjects gave conjoint estimates exactly equal to the lower of their two constituent estimates.
 A high percentage would suggest that these subjects allowed the lower of the two constituent estimates to constrain the conjoint estimate.
 In support of the notion that some subjects intentionally used the conjunction rule, 3 9 % of probability subjects who did not violate the rule (24 out 61) gave a conjoint estimate equal to the lower of the two constituent estimates.
 O f the typicality subjects whose conjoint estimates did not exceed the lower of the two constituent estimates, 4 7 % (20 out of 43) made the two estimates equal.
 It may not be surprising that some probability subjects seem to have applied the conjunction rule.
 It is surprising, however, that some typicality subjects seem to have done so.
 This quantitative result in the typicality condition is striking for two reasons: (1) One cannot reasonably argue that the conjunction rule applies to typicality judgment and it seems highly unlikely that people are ever instructed that it does; (2) Relative to the less typical constituent, the conjoint category was always more similar to the instance from a featurematching perspective.
 The idea that typicality subjects applied statistical strategies to their judgments will receive further support from the analysis of justifications presented below.
 ^This low percentage of violations was found in a statistically sophisticated population of graduate student subjects who used rating scales rather than rankings to make their responses.
 W e think that the University of Chicago undergraduate subjects in our study may be comparable to that population in statistical knowledge and that the 01 estimation response mode is more analogous to a rating scale than a ranking response mode, making this the most appropriate study to which to compare the present one.
 445 Justifications of estimates In general, the content of the justifications challenged featurematching assumptions about both representation and processing.
 As for representation, we found that subjects in both conditions often went beyond the information given in the personality description and reasoned using their enriched representations of the instances.
 In particular, subjects inferred features of the instance that they then used to make their judgments.
 These inferred features naturally affected the selection of category features that were brought to bear on the judgment.
 The fact that subjects inferred features in the conjunction task highlights a weakness of featurematching models first pointed out by Tversky (1977) himself: They fail to specify the features of instance and category that enter into the feature comparison.
 In addition, our finding that the "features" inferred were in some cases events rather than properties seems incompatible with the slotvalue representations of categories assumed by featurematching models.
 To study processing, w e had one judge categorize the justifications from both conditions using a scheme developed on justifications collected in a pilot study.
 The judge was trained on the pilot justifications and was blind both to condition (probability or typicality) and the purpose of the experiment.
 It was possible for a justification for a single estimate to fall in more than one category.
 The four coding categories are explicated below.
 Examples are shown after each category definition (except Other) and are labeled "T" or "P" to indicate the condition (typicality or probability) from which they were drawn.
 The justifications for 1 7 % of the constituent estimates and 4 0 % of the conjoint estimates were omitted from analysis because subjects did not write anything or wrote statements that could not be categorized.
 Feature comparison.
 Feature comparison involved mentioning a feature of the instance or category and either pointing out or implying the presence or absence of that feature in the other entity.
 Features of the instance could be directly quoted, paraphrased, or inferred from the given description.
 Examples of feature comparison justifications: P: It appears very likely that Linda is an active feminist, because she is outspoken and interested in debates over social issues.
 This could mean that she is an ultraconservative antifeminist, but it doesn't seem logical because her opp)Osition to nuclear power seems to connect her with leftwing rather than conservative ideas.
 P: [Jack is] too aggressive to watch birds.
 T: People who play volleyball play on a team, which implies that they are social.
 Richard is not like this.
 T: Truck drivers use CB radios while on the job and often are known (or stereotyped) to watch sports.
 Causal reasoning.
 W h e n a justification specified how a feature of the person or a hypothesized set of circumstances could cause the person to be or not to be a member of the category, then it was considered to show evidence of causal reasoning.
 The most c o m m o n type of causal reasoning involved construction of a hypothetical scenario about the instance that was then evaluated for its plausibility.
 Whether or not the causal scenario was accepted as plausible or rejected as implausible by the subject, the justification was put in this category if a causal mechanism was specified.
 Examples of causal reasoning justifications: P: If she was a teacher, she would appear to be a rebel and more than likely be fired for teaching in what the school would believe to be an inappropriate way of teaching.
 T: Volleyball is a team sport.
 A shy person is unlikely to play a sport that requires finding 9 other people in order to play.
 T: This could be a temporary job for Linda.
 Statistical and mathematical reasoning.
 W e identified four types of statistical and mathematical justifications: baserate, "general," conjunction rule, and averaging rule.
 Baserate and general statistical or mathematical justifications were used for both constituents and conjunctions.
 Baserate justifications took into account the subject's estimate of the percentage of instances in a reference class (e.
g.
, all people, men, 31yearolds) that fall in a particular category (e.
g.
, people who are teachers).
 General justifications mentioned statistics or mathematics as a consideration but failed to specify how statistics or mathematics was used to make the estimate.
 Examples of baserate and general justifications: P: I think because an engineer is independent of collecting stamps and I guess half of the people collect stamps.
 T: While it is not unreasonable for him to be one or the other, I imagine the percentage of birdwatching truck drivers is low, so Jack has a small category in which to fit.
 P: This would be the lowest probability because of the statistics involved.
 T: Two qualifications are less likely to be had than either alone.
 The remaining two types of statistical and mathematical justification cited rules for combining the constituent estimates and thus could only be used to justify conjoint estimates.
 Conjunction rule justifications were verbal expressions of the constraint that the lower of the two constituent estimates places an upper limit on the conjoint estimate or algebraic or arithmetic statements of the multiplication rule for independent events.
 Averaging rule justifications stated that the conjoint estimate was derived by 446 quantitative or qualitative averaging of the constituent estimates.
 For combining probabilities, the averaging rule was incorrect from a normative standpoint but was still considered to be a mathematical strategy.
 Examples of conjunction rule and averaging justifications: P: Mathematically, the odds of her being a bank teller and active in the feminist movement must be less than (or equal to) the odds of her just being a bank teller.
 P: I multiplied the probabilities #1 and #2 [the constituent estimates] together to come up with this estimate.
 I guess it can be said that very low X very low = even lower.
 T: I multiplied my first estimate by the second estimate because it seemed the most logical thing to do.
 T: [The conjoint estimate is] the average of the first two.
 Other.
 This catchall category included indifference and conceptual combination justifications.
 If a justification said that it was impossible to make an estimate or that the person was as likely as not to be in the category and the quantitative estimate was .
50, then it was categorized as indifference.
 Judgments of indifference were qualitatively different from all others in that they represented reactions to the task rather than responses to the question posed in the task (see also the Dick problem in Kahneman & Tversky, 1973).
 Conceptual combination justifications made assertions about the plausibility of the conjunction independent of the instance.
 The latter often had the flavor of baserate justifications (e.
g.
, "I don't think this category exists," "What graduate student goes to fashion shows?"), but were tallied separately for the sake of conservatism.
 The percentages of justifications that fell in each category are shown in Table 1.
 Because the possible justification types differed for constituents and conjunctions, the results are broken down by category type (constituent or conjunction) as well as by experimental condition (probability or typicality).
 For constituents (top panel), the statistical and mathematical justifications are all of the baserate subtype.
 Conjunction rule justifications accounted for 6 5 % and 5 9 % of statistical and mathematical justifications in the probability and typicality conditions, respectively.
 Conceptual combination justifications accounted for 7 7 % and 7 8 % of Other justifications in the two conditions, respectively.
 Examination of the Table 2 shows that for constituent categories, feature comparison is by far the most common type of justification given for both probability and typicality judgments.
 The distributions of the other types of justification are comparable in the two conditions, with baserate justifications and statements of indifference slightly more common in the probability than in the typicality condition.
 For conjunctions, however, feature comparison Justifications were not in the majority in either condition.
 In both conditions, the distribution for conjunctions is concentrated in the statistical and mathematical and Other categories.
 Table 1: Percentages of justification types.
 Constituents prob N=I47 typ N=139 Feature Causal StatMath Other 74 8 9 9 84 8 Conjunctions Feature Causal StatMath Other prob N=50 typ N=50 18 38 10 10 46 34 26 18 The shift from feature comparison to statistical and mathematical justifications as one moves from constituents to conjunctions suggests that the underlying processing depends on the complexity of the category being considered.
 While comparing the features of an instance to a constituent category may be straightforward because the category features can be retrieved from memory, comparing them to a conjoint category first requires representing the conjoint category.
 As has been pointed out by many theorists (e.
g.
, by Murphy and Medin, 1985), conjoint categories are not formed by merging feature lists, but by more complex cognitive processes such as causal reasoning.
 One way of approaching the conjunction task is to form a conjoint category representation by such processes and then to compare features of instance and category.
 Another way is to borrow combination rules from statistics and mathematics to derive a conjoint estimate.
 The justifications collected in our study suggest that some subjects took the latter approach to generating conjoint estimates.
 Discussion The results of our analysis of subjects' justifications speak to the similarityascomparison and similarityasexplanation assumptions in a way that quantitative estimates alone cannot.
 To the extent that the justifications reveal underlying processing, probability and similarity judgment involve more than feature comparison.
 Particularly when judging the probability or typicality of instances in conjoint categories, some subjects justified their estimates by citing causal or statistical and mathematical considerations that cannot be incorporated into traditional featurecomparison models of similarity judgment.
 One way to preserve the notion of similarity judgment strictly as a process of comparison might be to argue that processes other than feature comparison are distinct from similarity judgment but are sometimes used in addition to similarity to solve a particular task.
 But in that case, it is difficult to argue categorically that similarity judgment is 447 made in lieu of probability judgment, since even in the typicality condition feature comparison was only one of several types of justification.
 Indeed, one could argue from the finding that some subjects borrowed statistical and mathematical rules to make their typicality estimates that probability judgment can also underlie similarity judgment.
 Our results validate similaritybased explanations of probabilistic reasoning to the extent that the similarity and probability judgment tasks elicited similar inferential processes, including comparison of features.
 However, feature comparison was only one of the processes of which we found evidence.
 Not only do our results suggest the need to rethink the role of similarity as an explanation of other cognitive processes, but the need to change our conceptualization of similarity judgment itself.
 The justifications collected from typicality subjects in our study suggest that they reason about similarity in terms of plausibility and probability as well as in terms of feature comparison.
 In the case of causal scenarios, they evaluated the plausibility of an event sequence, beginning with the instance as described and ending with the instance as category member or nonmember (see also Bassok & Medin, this volume).
 In an even clearer departure from similarity judgment as feature comparison, some subjects borrowed statistical and mathematical strategies such as baserate estimation and the multiplication rule for independent events to estimate typicality.
 It should be noted that causal and statistical strategies for solving both judgment tasks were not used to the exclusion of feature comparison.
 Further analysis of the written justifications is expected to shed light on how individual subjects deployed the different strategy types.
 In principle, the ecologically valid positive cortelation between similarity and probability can be exploited for the purpose of making either type of judgment: Similarity can be used as a heuristic forjudging probability and probability can be used a heuristic for judging similarity.
 The ambiguity of both judgment tasks may lead subjects to look to other dimensions about which they are knowledgeable for guidance in defining the tasks and in making their judgments.
 Although the statistical and mathematical knowledge of subjects in the present study may be greater than that of subjects in most previous conjunction task studies, the fact that they relied on such knowledge to guide their typicality judgments nevertheless has broad implications because they also have knowledge of feature comparison.
 The point is that subjects drew on knowledge outside of feature comparison to make both similarity and probability judgments, using a variety of knowledge sources to guide the judgment they were required to make.
 W e conclude that, because it involves inferential processes other than feature comparison, similarity judgment as it has been defined cannot necessarily serve as a unidirectional explanation of other cognitive processes.
 R e f e r e n c e s Bassok, M.
 & Medin, D.
 L.
 (1995).
 Structural and thematic alignments in similarity judgments.
 In Proceedings of the Seventeenth Annual Cognitive Science Society (this volume).
 Hillsdale, NJ: Lawrence Eribaum.
 Goldstone, R.
 L.
, Medin, D.
 L.
, & Centner, D.
 (1991).
 Relational similarity and the nonindependence of features in similarity judgments.
 Cognitive Psychology, 23, 222262.
 Goodman, N.
 (1972).
 Seven strictures on similarity.
 In N.
 Goodman (Ed.
), Problems and projects (pp.
 437447).
 N e w York: BobbsMerrill.
 Kahneman, D.
, & Tversky, A.
 (1972).
 Subjective probability: A judgment of representativeness.
 Cognitive Psychology, 3, 430454.
 Kahneman, D.
, & Tversky, A.
 (1973).
 On the psychology of prediction.
 Psychological Review, 80,237251.
 Markman, A.
 B.
, & Centner, D.
 (1990).
 Similarity involving attributes and relations: Judgments of similarity and difference are not inverse.
 Psychological Science, 1, 6469.
 Medin, D.
 L.
, Goldstone, R.
 L.
, & Centner, D.
 (1993).
 Respects for similarity.
 Psychological Review, 100, 254278.
 Murphy.
 C.
 L.
, and Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Shafir, E.
 B.
, Smith, E.
 E.
, & Osherson, D.
 N.
 (199).
 Typicality and reasoning fallacies.
 Memory and Cognition, 18, 229239.
 Smith, E.
E.
, & Osherson, D.
 N.
 (1984).
 Conceptual combination with prototype concepts.
 Cognitive Science, 8, 337361.
 Smith, E.
E.
, & Osherson, D.
 N.
 (1989).
 Similarity and decision making.
 In S.
 Vosniadou & A.
 Ortony (Eds.
), Similarity and analogical reasoning (pp.
 6075).
 Cambridge: Cambridge University Press.
 Smith, E.
E.
, Osherson, D.
 N.
, Rips, L.
 J.
, & Keane, M.
 (1988).
 Combining prototypes: A selective modification model.
 Cognitive Science, 12,485527.
 Tversky, A.
 (1977).
 Features of similarity.
 Psychological Review, 84, 327352.
 Tversky, A.
, & Cati, I.
 (178).
 Studies of similarity.
 In E.
 Rosch & B.
 Lloyd (Eds.
), Cognition and Categorization (pp.
 7998).
 Hillsdale, NJ: Eribaum.
 Tversky, A.
, & Kahneman, D.
 (1983).
 Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment.
 Psychological Review, 90, 293315.
 Acknowledgments The present study was supported by a grant from the University of Chicago School Mathematics Project to Miriam Bassok.
 W e thank Boaz Keysar and Beth Hagen for their helpful comments on an earlier draft of this paper.
 448 O n Order Effects in Analogical Mapping: Predicting H u m a n Error Using l A M Mark T.
 Keane Department of Computer Science, University of Dublin, Trinity College, Dublin 2, I R E L A N D mark.
keane@tcd.
ie Abstract The Incremental Analogy Machine (lAM) predicts that the order in which parts of an analogy are processed can affect the ease of analogical mapping.
 In this paper, the predictions of this model are tested in two experiments.
 Previous work has shown that such order effects can be found in attributemapping problems.
 In the first expenment, it is shown that these effects generalise to relationalmapping problems, when subjects' error performance (incorrect mappings) is considered.
 It is also found that relationalmapping problems are significantly harder than attributemapping problems.
 In the second experiment, it is shown using relationalmapping problems, that order effects can be demonstrated for doubles (two sentences about two indiviudals) in these problems.
 Throughout the paper it is shown that these results are best approximated by lAM's measure of the complexity of global mappings (the remapscomplexity measure), and not as has been found previously, by a measure using frequency of remaps (the remaps measure).
 The empirical and theoretical significance of these results are discussed.
 Introduction The importance of analogy to problems solving, creativity and learning is welldocumented (see e.
g.
, Koestler, 1964).
 Now, the theoretical basis of analogy is better understood than it was 30 years ago, with the elaboration of the subprocesses underlying the phenomenon; that is, representation, retrieval, mapping, adaptation and induction.
 Many empirical studies now substantiate these theories (see e.
g.
, Clement & Centner, 1991; Centner & Toupin, 1985; Gick & Holyoak, 1980; Holyoak & Koh, 1987; Keane, 1985, 1987, 1988, 1994; Novick & Holyoak, 1991).
 The distinctive, core subprocess in analogy is analogical mapping; it establishes the correspondences between the concepts in a base domain of knowledge and a target domain, performing any analogical inferences that follow from these correspondences.
 For example, in drawing an analogy between the solar sytem and the atom, it is analogical mapping that determines the correspondences between, say, the revolution of the planets around the sun and the revolution of the electrons around the nucleus (see Centner, 1983).
 In performing analogical mapping subjects resolve many ambiguities in the mappings between the two domains, ambiguities that are highlighted in Holyoak & Thagard's (1989) attributemapping problem (see e.
g.
, singletonscrossed problem in Table 1).
 In attributemapping problems, subjects are asked to say which things in list A correspond to which things in list B (ignoring the meaning of the words); they have to discover a onetoone mapping between all the individuals and attributes in list A and list B.
 This mapping is difficult because many ambiguous matches have to be resolved.
 For example, smart may match hungry or friendly or frisky and the correct match can only be determined by eliminating the inconsistent matches that follow from all but one of these matches.
 The unique onetoone mapping which solves the problem is to match Steve and Fido, Bill and Rover, T o m and Blackie, smart and hungry, tall and friendly, and timid and frisky.
 This paper examines people's performance on this type of mapping problem.
 In particular, I test the predictions of one analogy model, the Incremental Analogy Machine, with a view to selecting its best predictor of the empirical data.
 Unlike much previous analogy research the emphasis here is on predicting subjects' specific, error performance rather than simply characterising their broad analogical competence.
 Theories and Models of Analogical Mapping There is some theoretical consensus as to the nature of analogical mapping, although the models used to instantiate this theory differ considerably.
 The basic view is that analogical mapping is a matching process that is sensitive to three main sets of informational constraints (see Keane, Ledgeway & Duff, 1994, for more details): • structural constraints which establish isomorphic matches between entities of the same type in both domains (e.
g.
, objects with objects, relations with relations), enforce structural consistency [if the relation hit(x, y) and hit(a, b) are matched then their arguments must be placed in correspondence (x with a, y with b)], and take the systematicity of the mapping into account (see Centner, 1983) • similarity constraints that in deciding between alternative matches, matches that are semantically similar to one another should be preferred over ones that are less similar, • pragmatic constraints that matches that are goalrelevant or pragmatically important in the task context (e.
g.
, because an experimenter has indicated them to be so) should be preferred over alternative matches Keane et al.
 (1994) pointed out that these constraints constitute a competencetype theory or computationallevel theory of analogy (see Marr, 1982; Palmer, 1989), that had to be extended to include algorithmiclevel or behavioural constraints to characterise performance aspects of analogy (e.
g.
, errors and solution times).
 They proposed two such behavioural constraints: working memory limitations and the effects of background knowledge.
 449 mailto:mark.
keane@tcd.
ieTable 1; Examples of mapping problems used in Experiment 1 AttributeMapping Problems SingletonsAligned B SingletonsCrossed A B Steve is smart.
* Bill is tall.
 Bill is smart.
 T o m is tall.
 Tom is timid.
 Fido is hungry.
* Blackie is friendly.
 Blackie is frisky.
 Rover is hungry.
 Rover is friendly.
 Bill is smart.
 Bill is tall.
 Tom is timid.
 Tom is tall.
 Steve is smart.
* Fido is hungry.
* Blackie is friendly.
 Blackie is frisky.
 Rover is hungry.
 Rover is friendly.
 SingletonsAligned Joe motivates Steven.
* Mark is beside Ronan.
 Mark motivates Ronan.
 Conor is beside Paul.
 Conor fears Paul.
 RelationalMapping Problems Singletons Crossed B A Lisa hugs Jenny.
* Mark is beside Ronan.
 Laura employs Ruth.
 Mark motivates Ronan.
 Laura hugs Ruth.
 Conor is beside Paul.
 Mary sees Ali.
 Conor fears Paul.
 Mary employs Ali.
 Joe motivates Steven.
* B Lisa hugs Jenny.
* Laura employs Ruth.
 Laura hugs Ruth.
 Mary sees Ali.
 Mary employs Ali.
 * indicates the singleton All of the computational models in the literature capture analogical competence by implementing the above informational constraints.
 Falkenhainer, Forbus & Centner (1989; Forbus & Oblinger, 1990) Structure Mapping Engine (SME) implements the three informational constraints in a serial fashion finding all possible legal matches between two domains and combining these into alternative mapping interpretations (or global mappings) of the analogy.
 Holyoak & Thagard's (1989) Analogical Constraint Mapping Engine ( A C M E ) uses parallel constraint satisfaction in an interactive network to find a single global mapping between two domains.
 Keane's (1990; K e a n e & Brayshaw, 1988; Keane, et al.
, 1994) Incremental Analogy Machine (lAM) uses serial constraintsatisfaction to form a single, optimal interpretation based on a subset of the possible matches between the two domains.
 l A M builds this global mapping incrementally by selecting a part of the base domain for mapping, mapping it and then moving on to map another part'.
 l A M was designed to include behavioural constraints, to capture people's performance on analogy tasks.
 The J A M model makes the novel prediction that the order in which parts of a domain are processed could affect the ease of the analogical mapping.
 Keane et al.
 demonstrated such order effects using the two versions of the attributemapping problem shown in Table 1.
 An important property of these attributemapping problems is that each ^ Different forms of incrementality have been proposed in analogy.
 Burstein (1986) proposed that multiple base domains could be combined incrementally over time when learning by analogy, but this model does not apply to complex analogies.
 Falkenhainer (1987) proposed a mechanism for the incremental revision of analogical inferences after they had been tested by a simulation method.
 Neither model performs incremental mapping of a single analogy.
 lAM is the first generalpurpose, incremental analogicalmapping engine.
 list has two individuals (e.
g.
, Bill and T o m ) with two attributes (termed doubles) and a remaining individual (i.
e.
, Steve) who has just one attribute (a singleton).
 Matching up the singletons ("Steve is smart" and "Fido is hungry") helps to achieve the isomorphic mapping because the singletons disambiguate the set of matches between the two lists (this argument also applies to the single attribute in both lists).
 Taking this property of the problem into account, lAM predicted that if the singletons were placed at the beginning of both lists (see singletonsaligned problem) then the problem should easier than when the singletons are ordered in a misaligned or crossed fashion (see singletonscrossed problem).
 Keane et al.
 (1994) found that people were almost twice as fast at mapping singletonsaligned problems than singletonscrossed problems.
 These order effects show that an incremental account of analogy is psychologically plausible.
 In part, as a response these findings Forbus, Ferguson & Centner (1994) produced an incremental version of S M E (ISME).
 ISME can also account for the order effects in attributemapping problems.
 Forbus et al.
 have also demonstrated that incremental analogising is important to model the successive learning by analogy over time.
 The Problem However, these order effects might not generalise to mapping problems involving relations.
 Most analogies do not hinge on mappings between oneplace predicates [e.
g.
, timid(x), hungry(x)], but rather involve multiplace predicates [e.
g.
, hit(x, y), hurt(y, z)].
 Keane et al.
 produced singletonsaligned and singletoncrossed versions of a new relationalmapping problem and noted that l A M predicted similar order effects for these problems (see Table 1).
 However, this prediction has never been substantiated empirically.
 This paper investigates order effects in relationalmapping problems.
 The paper also examines alternative measures of lAM's performance that can be used to simulate subjects' 450 performance, with a view to identifying the most predictive measure.
 In each experiment.
 I first report a computational experiment using l A M before testing these predictions with subjects.
 Experiment 1: Order and Problem Type l A M predicts that the order effects found for attributemapping problems should also hold for relationalmapping problems.
 So, singletonsaligned versions of both problems should be easier than singletonscrossed versions of both problems (see Table 1).
 l A M should also predict problemtype effects; that is, relationalmapping problems should be harder than the attributemapping problems because they involve more complex predicate structures (taking two arguments).
 However, the difficulty of an analogy can be measured in several different ways in lAM.
 In the simulation experiment, two such measures are examined in assessing the predictions of lAM.
 Experiment lA: Simulating Order & ProblemType Effects in l A M In the simulation experiment using LAM, the exact same problems were presented to the model that were later given to the human subjects (see Keane et al.
, 1994, for a full description of lAM).
 In previous studies, the measure used was the number of alternative globalmappings generated before the problem was solved; the remaps measure.
 This is a good measure of problem difficulty because it is common to lAM, S M E , A C M E and ISME (see Keane et al.
, 1994).
 It also makes accurate predictions for the order effects found in attributemapping problems.
 However, it is a very gross measure, because it does not take the contents of these global mappings into account.
 For instance, it should be clear that a global mapping involving three entities is less difficult than a global mapping involving 3(X) entities.
 Yet, the remaps measure would never reveal this difference.
 The remaps measure is unlikely to manifest problemtype differences because they hinge on the number of entities involved.
 A finergrained measure is possible using the number of mappings involved in each remap: the remapscomplexity measure.
 This measure tells us h o w m a n y m a p s (predicate and object) were constructed across all the global mappings generated before 4 3 .
 V) o.
 (0 E 01 cr '• 2 O 6 z 1 0 (a) ^ / /^ / ^ ^y j ^ ^ >> X a> a.
 E o o 10 Q.
 IB E a> IE the solution is reached.
 W e adopted these difficulty measures in our following tests rather than direct tests of error in the model because there are no strong guidelines for making the model produce errors.
 I could have stopped the model after a certain length of time, before the correct answer in reached; this would give us numbers of incorrect mappings but any proposals on h o w long the model should run seem arbitrary (see Keane, 1995, for details and other possible measures).
 Method Materials & Design.
 The materials presented to l A M in the computational experiment were predicate calculus representations of the problems shown in Table 1.
 The problems given to the program corresponded to the individual problems given to subjects in the subsequent psychological experiment (see Keane, 1995).
 The materials thus consisted of four sets problems, one for each condition; the attributealigned (11 problems), attributecrossed (13 problems), relationalaligned (12 problems), and relationalcrossed conditions (9 problems).
 Procedure & Measures.
 Each problem was run on L A M (see Keane et al.
, 1994, Appendix A for settings used).
 T w o measures were used: (i) remaps, the number of alternative global mappings generated; (ii) remapscomplexity, the number of maps (both relational and object) that were formed on successive remaps.
 Results & Discussion Figure 1 shows the mean number of remaps (Figure la) and the mean remapscomplexity scores (Figure lb) for the different conditions in the experiment.
 Both measures predict that singletonsaligned problems should be easier than the singletonscrossed problems, but only the complexity measure predicts a difference between attributeand relationalmapping problems.
 A 2 X 2 analysis of variance, with betweensubject factors for order (aligned or crossed) and problemtype (attribute or relational), of the computational results reveals the number of remaps measure only shows a reliable main effect of order [F(l, 41) = 72.
83, p < .
0001; M S g = 38.
99].
 However, the remapscomplexity measure shows reliable Attribute Relation (b) Aligned Crossed Aligned Crossed Figure 1: (a) the mean number of remaps and (b) mean remapscomplexity scores for the problems 451 main effects for both order 1F(1,41) = 55.
79, p < .
001; M S e = 54.
18] and problem type [F(l, 41) = 7.
36, p < .
01].
 There were no reliable interactions for either measure.
 The results of the computational experiment show that the previouslyused, remaps measure appears to be too blunt to be useful.
 It merely counts the number of different interpretations produced for the analogy and says nothing about the comple.
xity of these interpretations.
 The remapscomplexity measure was.
 therefore, used to predict subjects' performance.
 Ol c o a.
 o ^ Attribute •̂  Relation SingletonsAligned SingletonsCrossed Figure 2; The mean proportion of incorrectmappings produced in Experiment IB Experiment IB: Psychological Tests of Order and Problem T y p e W e have seen the sorts of predictions produced by the computational tests in Experiment lA.
 Here these predictions are tested in a parallel psychological experiment.
 Method Materials.
 W e used the four types of problem shown in Table 1: two sets of attributemapping problems and two sets of relationalmapping problems.
 For each problemtype there was a set of aligned problems (in which the singletons were first in both lists) and a set of crossed problems (in which the singleton in list A was last and the singleton in list B was still in the first position).
 The remaining sentences in each list were randomised with the constraint of keeping atuibutes (or relations) about the same individual (or pair of individuals) together.
 Procedure.
 Subjects were instructed in writing that their "task is to figure out what in the left set corresponds to what in the right set of sentences".
 A single column below list A listed the names of the individuals and attributes/relations in that list (in the order in which they appeared in the list of sentences).
 Next to each was a space for subjects to write the corresponding name or attribute/relation from list B.
 Subjects were first shown the instructions and problem and were asked to read them carefully.
 They were timed until they produced the correct answer to the problem (the clock was stopped after 15 minutes).
 Subjects & Design.
 Fortyfive undergraduates attending Trinity College Dublin took part voluntarily in the experiment.
 One subject was excluded prior to data analysis because he misunderstood the experimental instructions (failed to produce even one correct mapping).
 Data analysis was carried out on the remaining 44 subjects who were assigned randomly to the four conditions; the attributealigned ( n = l l ) , attributecrossed (n = 13), relationalaligned (n = 12), and relationalcrossed conditions (n=9).
 Measures.
 Keane et al.
 (1994) used solutiontime as the dependent measure in their experiments.
 However, solution time proved to be unsuitable here because many subjects found the relationalmapping problems very difficult; 7 5 % of subjects failed to solve them (or gave up) before the 15 minutes deadline.
 The dependent measure was, therefore, the proportion of incorrectmappings produced by subjects to a problem (the attribute mapping problem has six correct mappings and the relationalmapping problems has nine such mappings).
 Results & Discussion Figure 2 shows the mean number of incorrectmappings produced by subjects in the different conditions of Experiment 1.
 Order effects were demonstated in relationalmapping problems as well as in attributemapping problems.
 The effect of problem type was also marked; overall only 2 5 % of subjects solved relational mapping problems (i.
e.
, got no incorrect mappings) whereas 6 7 % of subjects solved the attributemapping problems.
 The results corroborate the predictions of the l A M model based on the remapscomplexity measure (compare Figures lb and 2).
 The 2 x 2 analysis of variance, with betweensubject factors for order (aligned or crossed) and problemtype (attribute or relational), revealed reliable main effects of order [F(l, 41) = 4.
17, p < .
05; M S g = .
055] and problemtype F(I,41) = 9.
25, p < .
01; M S g = .
055].
 There was no significant interaction.
 The results thus demonstrate that the remaps measure is, in itself, insufficient to distinguish problemtype differences in analogical mapping.
 Rather, we need a measure that takes into account the complexity of these remaps.
 Experiment 2: Order Effects in Doubles All of the order effects found in the literature make use of the singletons in the mapping problem.
 However, l A M is sensitive to the position of any sentence in lists A and B.
 So, if we take a double in list A (e.
g.
, the sentences "Mark is beside Ronan" and "Mark motivates Ronan") and align it with its corresponding double in list B (e.
g.
, "Laura employs Ruth" and "Laura hugs Ruth") then such a problem should be easier to solve than one in which these doubles are crossed (see Table 2).
 So, aligned problems involving doubles should be easier than crossed problems (see simulations below).
 The simple case where the sentences in the doubles are aligned perfectly and can be read off was excluded.
 Also, Table 2 shows that these problems include an implicit causal relation between the employspays double.
 The position of this double was also varied, but no reliable differences were found.
 In this presentation of the experiment, I collapse across this variable, treating the two conditions as being counterbalanced for this factor (see Keane, 1995, for details).
 452 Table 2: Examples of the mapping problems used in Experiment 2* DoublesAligned B Jim is beside FredJim employs Fred.
 Joe pays Sam.
 Mark employs Ronan.
 Mark pays Ronan.
 Ruth motivates Mi.
 Ruth sees Mi.
 Lisa hugs Jenny.
 Laura hugs Debra.
 Laura motivates Debra.
 DoublesCrossed Mark employs Ronan.
 Mark pays Ronan.
 Joe pays Sam.
 Jim is beside Fred.
 Jim employe Fred.
 B Ruth motivates Ali.
 Rvth sggs All, Lisa hugs Jenny.
 Laura hugs Debra, Laura motivates Debra.
 a E o u CO a a ff Aligned Crossed Figure 3a: The mean remap complexity scores produced by J A M in Expt.
 2B Experiment 2A: Computational Tests on Doubles The materials presented to l A M in the computational experiment were predicate calculus representations of the problems shown in Table 2.
 The materials corresponded to the two types of problem given to subjects in the subsequent experiment.
 Each of the problems were run on lAM.
 After running a problem the remapcomplexity measure was noted (as defined in Experiment 1 A).
 Results & Discussion Figure 3a shows the predicted differences for these problems.
 The groupcomplexity measure clearly shows an effect of order.
 A dependent ttest revealed a reliable difference between the doublesaligned (M = 18, 5 D = 3.
10) and doublescrossed conditions [A^ = 34, S D = 7.
23; /(15) =15.
49, p <.
0001].
 Experiment 2B: Psychological Tests of Doubles Materials & Procedure.
 W e used two versions of the relationmapping problem, examples of which are shown in Table 2.
 In these problems, the singleton sentence was always the third sentence in both lists, while the order of the doubles was varied around them.
 The procedures and instructions were as in Experiment IB except for two changes.
 First, we reduced the amount of lime given to subjects to solve the problem from 15 minutes to five minutes.
 In Experiment IB, we found that those people who solved the problem tended to do so in under 5 minutes.
 Finally, we also added the following sentence to the instructions: "There is a onetoone correspondence between the relations and objects in list A and list B".
 This was designed to provide a little more guidance as to the task demands.
 Subjects, Design & Measures Thirtyfour students in Department of Computer Science at Trinity College Dublin took part voluntarily in the experiment.
 T w o subjects were dropped from the experiment prior to data analysis because they misunderstood the experimental instructions (failed to produce even one correct mapping).
 The remaining 32 subjects were assigned randomly to the two conditions: the doublesaligned (n=16), and doublescrossed conditions (n=16).
 As before, The dependent measure was the proportion of incorrect mappings generated by subjects to a problem.
 Ol c '5.
 o Q.
 o O'O 0.
00 Aligned Crossed Figure 3b: The mean proportion of incorrect mappings produced by subjects in Expt.
 2B Results & Discussion Figure 3b shows the mean number of incorrect mappings produced by subjects in the different conditions of Experiment 2B.
 The results correspond well to the remapcomplexity measures found in l A M (compare Figures 3a and 3b).
 A dependent ttest carried out on the two conditions revealed that that difference between the doublesaligned (M=.
09, S D = .
17) and doublescrossed (M = .
43, SD = .
28) conditions was statistically relaible [f(15) = 3.
9, p < .
001].
 The results thus reveal that the positioning of doubles as well as the positioning of singletons can lead to order effects in these mapping problems.
 453 C o n c l u s i o n s Empirically, these experiments provide further support for order effects in analogical mapping.
 They show that the effect previously demonstrated in attributemapping problems can be replicated and extended to relationalmapping problems.
 They show that relationalmapping problems are considerably more difficult than attributemapping problems.
 Finally, they show that order effects are not just to be found for the positioning of singletons, but are also sensitive to the position of doubles.
 These experiments are among the first to predict specific error rates in analogical mapping and to show systematic differences in these rates over different types of analogy problems.
 Keane et al.
 (1994) argued that analogy models have to approximate subjects' performance, not just characterise the sort of analogies they can or cannot do (i.
e.
, their analogical competence).
 In this paper l A M has demonstrated a good approximation to subjects' performance.
 The previouslyused measure  the remaps measure — has been shown here to be insensitive to processing differences caused by the complexity of the predicates involved in a mapping (i.
e.
, whether there are attributes or relations).
 To approximate subjects' error performance in these experiments a new measure was required based on the complexity of the remaps being processed.
 This complexity measure provides a good account of both order and problemtype effects.
 However, these findings raise the issue of whether the other models in the literature can be shown to make similar predictions.
 It is known already that A C M E does not predict any order effects; these effects run counter to the parallel spirit of that model (see Keane et al.
, 1994).
 IS M E can model order effects using a remaps measure but its predictions for these experiments are not known (awaiting results).
 ISME constructs its remaps in a completely different way to lAM.
 The number of remaps it produces to different problems differs to the number generated by lAM.
 I would assume, however, that this remaps measure will not capture problemtype effects and therefore some complexity measure might be required.
 So, to the best of m y knowledge, at present, L A M is unique in its ability to approximate the human behaviour discovered here.
 Acknowledgements The author would like to thank Karen Looney running some of the subjects and the Al Group at Trinity College.
 Thanks go to Ruth Byrne for commenting on the paper.
 This reasearch has been aided by funding from the Hitachi Dublin Laboratory at Trinity College Dublin.
 References Burstein, M.
H.
 (1986).
 Concept formation by incremental analogical reasoning and debugging.
 In R.
S.
 Michalski, J.
G.
 Carbonell & J.
M.
 Mitchell (Eds.
), Machine Learning II:.
 Los Altos, Calif.
: Kaufmann.
 Clement, C.
A.
, & Centner, D.
 (1991).
 Systematicity as a selection constraint in analogical mapping.
 Cognitive Science, 15, 89132.
 Falkenhainer, B.
 (1987).
 An examination of the third stage in the analogy process: Verificationbased analogical learning.
 In Proceedings of the Tenth International Joint Conference on Artificial Intelligence.
 Los Altos: Morgan Kaufmann.
 Falkenhainer, B.
, Forbus, K.
D.
, & Centner, D.
 (1989).
 Structuremapping engine.
 Artificial Intelligence, 4], 163.
 Forbus, K.
D.
, & Oblinger, D.
 (1990).
 Making S M E greedy and pragmatic.
 In Twelfth Annual Conference of the Cognitive Science Society.
 Hillsdale: Erlbaum.
 Forbus, K.
D.
, Ferguson.
 R.
W.
.
 & Centner, D.
 (1994).
 Incremental structure mapping.
 In Sixteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Erlbaum.
 Centner, D.
 (1983).
 Structuremapping: A theoretical framework for anaiogy.
Cognitive Science, 7,155170.
 Centner, D.
 & Toupin, C.
 (1986).
 Systematicity and surface similarity in the development of analogy.
 Cognitive Science, 10, 227300.
 Cick, M.
L.
, & Holyoak, K.
J.
 (1980).
 Analogical problem solving.
 Cognitive Psychology, 12, 306355.
 Holyoak, K.
J.
 & Koh, K.
 (1987).
 Surface and structural similarity in analogical transfer.
 Memory & Cognition , 15, 332340.
 Holyoak, K.
J.
, & Thagard, P.
 (1989).
 Analogical mapping by constraint satisfaction.
Cogn/7/ve Science, 13, 295355.
 Keane, M.
T.
 (1985).
 On drawing analogies when solving problems.
 British Journal of Psychology, 76 , 449458.
 Keane, M.
T.
 (1987).
 On retrieving analogues when solving problems.
 Quarterly Journal of Experimental Psychology, 39A , 2941.
 Keane, M.
T.
 (1988).
 Analogical Problem Solving.
 Chichester: Ellis Horwood.
 Keane, M.
T.
 (1990).
 Incremental analogising: Theory and model.
 In K.
J.
 Cilhooly, et al.
 (Eds.
), Lines of Thinking.
 Vol.
 1.
 Chichester: John Wiley.
 Keane, M.
T.
 (1994).
 Adaptation as a selection constraint on analogical mapping.
 In Sixteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Erlbaum.
 Keane, M.
T.
 (1995).
 On order effects in analogy.
 TCDCSTR9504.
 May.
 Keane, M.
T.
, & Brayshaw, M.
 (1988).
 The Incremental Analogy Machine.
 In D.
 Sleeman (Ed.
), European Working Session on Learning.
 Calif.
: Morgan Kaufmann.
 Keane, M.
T.
, Ledgeway, T, & Duff, S.
 (1994).
 Constraints on analogical mapping: A comparison of three models.
 Cognitive Science, 18, 287 334.
 Koestler, A.
 (1964).
 The Act of Creation .
 London: Picador.
 Marr, D.
 (1982).
 Vision.
 San Francisco: Freeman.
 Novick, L.
R.
 & Holyoak, K.
J.
 (1991).
 Mathematical problem solving by analogy.
 Journal of Experimental Psychology: Learning, Memory and Cognition, 17, 398415.
 Palmer, S.
E.
 (1989).
 Levels of description in information processing theories of analogy.
 In S.
 Vosniadou & A.
 Ortony (Eds.
), Similarity and Analogical Reasoning.
 Cambridge: Cambridge University Press.
 454 A M e t r i c f o r S i t u a t e d Difficulty Citfl Edlund and Michael Lewis edlund@lis.
pitt.
edu sind ml@lis.
pitt.
edu Department of Information Science University of Pittsburgh Pittsburgh, P A 15260 Abstract Analogy, conceptual change and problem reformulation have been central components in the exploration of human problem solving.
 A Situation Theoretic approach is developed to model analogy and conceptual change.
 This model is then used to relate a problem's representation to the associated cognitive difficulty.
 In this Unified framework the cognitive difficulty of isomorphic problem situations is defined in terms of the task, objects and relations of the problem situation.
 These components are then decomposed based on an Ecological Information Processing user model.
 The decomposition turns a problem situation the structure and dynamics of the problem; the rules or constraints which are applicable; and the necessary instructions for user interaction.
 From this, the cognitive difficulty associated with a problem representation is shown to be largely determined by the "instructional" component.
 Introduction The use of analogy as a central mechanism in problem solving has been explored in numerous domains.
 Computational models of analogy commonly describe analogy as a typepreserving mapping between relation or predicates and objects, or terms, in dissimilar domains.
 However, it is the dynamic similarity between domains which is central to what humans consider to be good analogies [1].
 A differing perspective on analogy is typified by Lakoff and Johnson [13] <'ind Hofstadter and French [10] in which analogy is seen as a pervasive and integrative component of human thought and problem solving.
 By these accounts analogy is not a special instance, but rather a general form, of cognition which reveals an underlying associationist architecture.
 This perspective considers analogy to reflect an actual encoding of information rather tht'in a mapping imposed between separately encoded entities.
 W e .
issume the "commonplace dynamics" of specific types of situation to be automatically processed and therefore imagined without effort.
 The role of reformulation and conceptual change that results from an analogical encoding is both difficult to design for an difficult to predict.
 Despite a long history as an explanatory construct and a centr;il role in Gestalt theories of problem solving problem reformulation, or insight, remains explanatory rather than predictive of performance.
 Theories of human information processing which focus on problem structure to the exclusion of problem context, or situationness are to blame.
 The defects of this approach are most evident in studies of isomorphic problems ([9]; [12]; [21]) in which performance differences of up to an order of magnitude have been found between problems having identical structure.
 To capture the effects of representation on problem solving w e hypothesize a model of cognition in which mental models simulating commonplace physical events are additionally constrained by mental rules similar to production rules found in traditional models.
 W e assume some portions of the dynamics of the mental models can be automatically processed.
 The mental rules, by contrast, are assumed to be situation independent, effortful, and consciously used to guide, restrict and interpret the behavior of the model.
 W e operationalize the concept of a mental model, within situation theory ([2]; [6]) as a constrained parameteric situation type.
 The ecological realist epistemology of Situation Theory holds that through evolution, experience and learning our mental states come to reflect those of the world.
 The menuU reflection of environmental constraints is regarded as as attunement of the mental model to the environmental consistency.
 Because nomic (natural law) constraints exert such a pervasive influence over our experience and development, they are guaranteed to meet the conditions of extended practice and the consistent mapping needed to develop automaticity in cognitive processing.
 This distinction is psychologically significant because mental processes characterized as automatic: • are not subject to processing limitation or introspection • elicit attention automatically • and are extremely resistant to extinction.
 This means that a mental model constrained by nomic attunements should, without mental effort, exclude stJites or events which would violate those constraints.
 Thus, situated cognition, occurs within the context of expectations built from a history of experience and perception of the current environment.
 Cognition using this model involves simulating events which are jointly constrained by mental constraints JLssociated with the situationtype, referred to as attunements, and mental constraints not integral to the situationtype, referred to as instructions.
 The interplay between the expectations (attunements) and explicit constraints (instructions) is based on the context that the user is interacting with.
 This context contains a set of objects, relations, features and behaviors which impact cognition via the expectations they license and the constraints being applied.
 Defining the situation of an interaction as a relational composition of the objects and dyn.
unics provides an epistemology for hierarchically, and recursively typing the situation, objects, and associated constraints.
 455 mailto:edlund@lis.
pitt.
edumailto:ml@lis.
pitt.
eduThe assumptions of this cognitive modeling resuU in predictable differences in the processing of constrjiints in a situation.
 Constriiints to which the user has developed an attunement will be processed automatically.
 Whereas the constraints which require the application of explicit rules are processed by controlled cognitive and perceptuiil operations.
 The constraint to which an agent is attuned are determined by the type of situation which in turn is detennined by the types of objects ;uid relations involved.
 So for example, any mental model involving solid physical objects would be constrained by nomic attunements to exclude events in which two objects came to occupy the same location at the same time.
 Additional conscious constraints ciui be imposed, Jis instructions, on the nomically constrained mental model to further restrict its behavior.
 In the game of chess for example, a naive player's nomic attunements would preclude pieces changing locations or shape without being moved.
 However, the constraint preventing a Knight from moving three squares in a line would require application of a rule not available through nomic attunement, i.
e.
 explicit instructions.
 The power of this hybrid ̂ proach is in its ability to characterize the composition of imagined processes, visual inference, intuition, and controlled information processing within a single model.
 For example, an aeronautical engineer's mental model of wing behavior might compose a commonsense understanding of fluids and fluid flows with specialized engineering knowledge of airfoil design.
.
 The commonsense understanding which is unlikely to be verbalized, is described by attunements (constraints) associated with situations involving fluids.
 The other, more specialized, engineering knowledge, expressed as learned heuristics and equations, are the instruction which further constrain the commonsense model.
 With this epistemology, it then becomes possible to model differing situation types, and their associated constraints.
 The model is grounded in the perceptual and cognitive experience of the user and the task which they are attempting to perform within a context.
 Situational contexts which are consistent with the user's experience and which closely model the problem task will be less complex that those are not so consistent.
 Determination of this "closeness", or "intuitiveness", is accomplished through the unification of problem task, context and user model.
 The comparison of alternative problem contexts, for the same abstract problem task, becomes realisable due to the normalization of representation.
 The attunements and constraints licensed by each context determine the amount of cognitive and perceptual effort necessary for a user to interact.
 Maintaining constraints from the abstract problem as constraints in the alternative context results in greater difficulty than for contexts in which attunements are able to represent some of the same relations.
 The presence of this dichotomy, provides the framework to establish a mechanism for determining and evaluating the inherent complexity of a situation with respect to the interactions of a user and their particular problemsolving task.
 Difficulty in Situated Cognition Accepting the conventional characterization of cognitive tasks as search, the difficulty that a particular situation presents is determined by the degree to which contiolled processing is needed to consUJiin search, and by the size iind complexity of the problem space.
 Based on the Situation Theoretic approach outline above, it is convenient to think to the user's task ;ls involving two problem spaces: 1.
 A cognitive space which may be traversed with minimal effort but may also be very large.
 This is defined as a problem context, 5, which is consu^aind by attunements, A, iind written sis A • 5.
 2.
 A noncognitive, or formal, problem space which may require substJintial effort to traverse but contains only feasible U"Jinsitions.
 This is defined as a problem situation, 5, constiJiined by the task constraints, C , and written as C • S.
 The relation between the problem situation, U'lsk constraints, and attuned constraints can be expressed as: C.
S = /.
vl.
5 where / is the extrinsic consuaints necessary to provide a match between the two spaces.
 The complexity and character of these explicit constraints depend on the degree of correspondence between the problem situation, C • 5, and the user's cognitive situation, A * S.
 Thus the difficulty of a task can be thought of as reducible based on the difference between the two problem spaces.
 W h e n presented with the circumstance that several different, isomorphic, cognitive situations (S', S", S'",.
.
.
 ) may be used to instantiate the same abstiact problem space, this decomposition allows each one, and its associated attunements (A', A", A'",.
.
.
) to be contrasted to determine which is minimally complex, i.
e.
 C.
 S = / .
 A .
 S = /' .
 ^' .
 5' = /" .
 A" .
 5" It may be useful to approach this model, and its implications for the evaluation of alternative representations (f • A * S), from a slightly different angle.
 W e can define the extrinsic difficulty of a task, in a representation, as being detennined by the constraints, /, which must be supplied by using conu^oUed processing.
 The constiaints needed in / in turn depend on the task constraints, from C, which are not supplied to the analog representation through automatic processing by the attunements, A.
 The availability of automatically processed attunements are themselves determined by the type of the situation, S.
 From this chain of dependencies, the only way to reduce the difficulty, of the C • S problem is to introduce a new, but equivalent, situation S' whose attunements.
 A, correspond more closely to the problem constraints C.
 As a result, controlled processing constiaints are shifted to A iind thus processed automatically.
 Any constiaints which do not map to attunements are maintained as instructions, /, and thus also maintain their status as requiring controlled processing.
 This model predicts that analogy will be the only route to reducing problem difficulty, and even then only by shifting the contiolled processing constiaints of the problem situation onto the automatically processed attunements of the analogous situation.
 Introducing the analogous situation S \ however, requires defining an analogy as a tianslation M between S and S' written as: M:/.
A.
S — /'.
A'.
S' 456 Problem FSA Figure 1: Necessary Instructions As with the traditional problem reformulation systems [20], the complexity of M may also need to be considered.
 If the task is incompletely characterized (there may be additional goals or constraints associated with the object or relations of S) then resource consumption associated with M will increase the complexity of the representation.
 Assuming M to require controlled processing, a measure of cognitive difficulty, D, for a task can be defined as: D{f mA' • S') + D{M) If we presume constraint through attunement to be only nominally difficult, and certainly less difficult than enforcing constraints through instructions, we can rank representations for task difficulty by ordering them according to difficulty of their instructions, i.
e.
 D{f»A»S) > D{f' • A' • S') if D{f) > D{f') and generally that D{A) > D{f).
 This translates the measure of difficulty between isomorphic problem spaces into the determination of complexity of the necessary instructional component.
 Figure 1 shows the Necessary Instructions as the area of mismatch between the space of the analogical situation and the space of the problem situation.
 If w e were to treat these spaces as Finite State Automata, the Necessary Instructions are simply a prescriptive list of stiites and statetransitions which are illegal in the analogicjil context.
 This list is added to the analogical situation ;is explicit constraints (instructions) and becomes part of the specification of the mapping, M .
 Thus the difficulty of an ;in;dogic;d situation is increased by a mismatched mapping from the problem situation.
 The larger the mismatch, the more instructions <ire necessary and the greater the complexity which is as one would expect.
 It is convenient to think of nomic attunements as being those problem constraints which go without mentioning, such ;is object const;uicy.
 All other constraints are then those which require explicit instructions in order to be conveyed.
 The ability of a representation to convey constraints through instructions m;ikes the automatic identification of communicative iuiiilogies practical by providing what is essentially an "error term.
" This allows a relatively njurow range of nominally constniined situations to fit a much broader range of situations.
 1 S ^ g P ^ Figure 2: Tower of Hanoi Isomorphs A n operational approach is taken for establishing the difficulty associated with a set of instructions.
 Adopting the assumptions of Larkin and Simon [14], and Casncr [4|, that the difficulty of using a rule is proportional to the perceptuid/ memorial operations needed to determine its applicability w e are provided with a relatively simple measure of cognitive difficulty.
 This measure is experimentally verified in Cleveland and McGill [5], and operationalized in Mackinlay [17], for the automated design of graphs and by Casner [4] for the automated design of taskoriented graphics.
 The cognitive/ perceptual simplicity of instructionjd conditions is evaluated based on the results of tasklike decomposition.
 The actual reduction of instructions usually involves the presentation of conjunctive information at a single spatial location, this is the primary mechanism Larkin Jind Simon [14], use to explain cognitive efficiencies resulting form the use of diagrams and is central to many of the advantages demonstrated by Casner [4], in presenting airline reservation information.
 In other contexts it appears as a primjuy source of the effectiveness of task analytic approaches to display formatting such as Mitchell and Sasi [18], and a key mech^tnism involved in the presentation of spatially correlated diiUi in scientific visualization.
 Experimental Support For problem tasks in differing analogs of an isomorphic domain, marked differences in human performance have been seen for the situationalanalogues which possess ecological advantages ([12]; [16]; [3]; [21]).
 A large body of research into display design has also shown a similar trend, for example, Edlund and Lewis [7] showed that displays which present information and dynamics in a situationalanalogue that utilizes the attunements which the users possess toward physicjil objects and interactions, gain a performance advantJige over displays which rely more on instructions and controlled processing.
 This performance advantage existed both for control tasks iuid for error detection and diagnostic tasks.
 Moray [19], showed that a graphic rendering of the Rjuikin cycle, which makes physical constraints visible, allows steam pUuit operators to more accurately control and monitor for fmlures than did the more traditional collection of Piping iind Instrumentation displays.
 Lewis [16] showed that a simple attunement involving object constancy and extension sdlows a block stacking version of the Towers of Hanoi problem to be identified as simpler ;uid involving fewer necessary instructions thiin .
dternatives with isomorphic problem spaces.
 The blockstacking representation was shown to provide more efficient state discrimination 457 ;ind action identificalion thjin the isomorphs.
 For example see Figure 2 for two isomorphic problem contexts for the s;une abstract problem situation.
 The stitcked blocks, ;md the Globeholding Monsters present logically identical infonnation.
 However, the problemsolvingability of users is greatly improved by using the stacked blocks context.
 These siune attunements of object constsincy iind extension allow the derivation of the Gantt chart from the job shop scheduling problem ([15]; [8]), and the derivation of stacking keyed blocks (See Figure 3)as a display for the more constrained flow shop problem.
 H u m e [11] again experimentally show, that displays relying on attunement to reduce difficulty substantially improves performance.
 The ability of this model to order the difticulty of the problem isomorphs in agreement with experimental results; to derive proven display formats from their problem representation; and to generate novel formats in accordance with the same principles, lend empirical support to this approach.
 In an example from the airline reservation domain, the choice of a nonstop flight to a particular destination, with an interest in cost and departure time is shown by Casner [4], to be efficiently presented on a graph with time on the horizontal axis and cost on the vertical.
 A customer with the goal of choosing a flight for an approximate time and cost need only examine a single spatial region to identify flights matching her requirements.
 Experimental results show that the presentations which take advantage of spatial conjunction of information and which in turn reduce the complexity of the cognitive/perceptual operations necessary to administer an instruction, result in faster and more accurate task performance.
 Where a user's goal involves extracting conjunctive information from static data this form of conjunctive display is almost always superior to tabular presentations.
 Conclusion The determination of instructional complexity in isomorphic representation of a problem, is central to establishing an overall difficulty measure for the representation.
 The use of Situation Theory and an Ecological user model allow us to represent a person's problem solving goals, task environment and expectations in a unified framework.
 Within this framework, difficulty is modeled as a measure of resource allocation.
 Cognitive and perceptual tasks divide the problem constraints between the effortless, automatic operations (attunements) and the controlled operations (instructional constraints).
 The contents and the functional role of the problem instructions can now be determined for the various alternative representations for a problem situation.
 Comparison of the relative perceptual/cognitive difficulties of the instruction sets is used to rank the difficulty associated with each representation.
 Research into the methodology and accuracy of instructional task decomposition is currently being pursueid.
 The ecological cognitive model w e have presented, supplements information processing models of cognition by proposing a framework in which intuition, imagined events, mental models and production rulelike constraints interact and ;ire described within a unified model.
 Classic computational problems, as solved by human, such as the frame/ramification problems are explained by the proposed distinctions between attuned and instructed constraints.
 Where our expectations Blocks should be suclud in th< low and oiienution in which thry lie found Blocks foi th< sinru job should not be sucked out of oidci.
 OpeiitionO (mjchmf.
m, job.
j) single mjchine assumption single job issucnption time in piocesi \ Fi g u r e 3: F l o w  s h o p B l o c k Stacking Display 458 are governed by attunement, we track events in our environment without effort or error.
 This h^pens, not by performing complex sentential updates but by our unconscious adaptation to the regularities of our environment.
 This development suggests that analogy, as ;ui insiiuicc of conceptual change, plays a central role in humiin cognition and problem solving.
 Analogy is modeled here not as a mechanism of valid inference or as a heuristic guide to inductive hypotheses, but as a mechanism for reducing cognitive difficulty.
 This is accomplished by shifting the allocation of processing from controlled to automatic processes over the course of designing the representation for the cognitive space equivalent of the problem situation.
 In this manner we can evaluated the implications of representational, and thus conceptual, change on the cognitive complexity for a problem solving task.
 References [1] Falkenhainer B.
, K.
 Forbus, and D.
 Centner.
 The structuremapping engine: Algorithm and examples.
 Artificial Intelligence,4VA63, 1989.
 [2] J.
 Barwise and J Perry.
 Situations and Attitudes.
 M I T Press, Cambridge, 1983.
 [3] M.
 Bauer and P JohnsonLaird.
 H o w diagrams can improve reasoning: Mental models and the difficult cases of disjunction and negation.
 Psychological Science, 4(6):226230,1993.
 [4] S.
 Casner.
 A taskanalytic approach to the automated design of gr^hic representations.
 A C M Transactions on Graphics, 10(2): 111151, April 1991.
 [5] W.
 Cleveland and R.
 McGill.
 Graphical perception: Theory, experimentation and application to the development of graphical methods.
 Journal of the American Statistical Association, 79(387):531553, September 1984.
 [6] Keith Devlin.
 Logic and Information.
 Cambridge University Press, N e w York, 1991.
 [7] C.
 Edlund and M .
 Lewis.
 A comparison of display integration strategies for control of a simple steam plant.
 In IEEE International Conference on System, Man, and Cybernetics, volume 3, pages 26862691, San Antonio, Tx.
, Oct 1994.
 [8] C.
 Edlund and M.
 Lewis.
 A metric for situated difficulty.
 In Proceedings of Cognitive Science Society Annual Conference, pages 11, Pittsburgh, PA.
, Jul 1995.
 [9] J.
 Hayes and H.
 Simon.
 Psychological differences among problem isomorphs.
 In N.
 Castellan, D.
 Pisoni, and G.
 Potts, editors.
 Cognitive Theory, pages 21^0.
 Erlbaum, Hillsdale, NJ.
, 1977.
 [10] D.
 R.
 Hofstadter and R.
 M.
 French.
 Probing the emergent behavior of tabletop, and architecture uniting highlevel perception with analogymaking.
 In Proceedings of the 14th Annual Conference of the Cognitive Science Society, pages 528533.
 Cognitive Science Society, 1992.
 Bloomington, IN.
 [11] S.
Hume.
 Display comparisons for monitoring and routing in telecommunications networks.
 Master's thesis.
 University of Pittsburgh, Jan 1995.
 [12] K.
 Kotovsky, J.
 R.
 Hayes, and H.
 A.
 Simon.
 W h y are some problems hard? evidence from towers of hanoi.
 Cognitive Psychology, 17:248294,1985.
 [13] G.
 Lakoff and M.
 Johnson.
 Metaphors we Live By.
 University of Chicago Press, Chicago, II.
, 1980.
 [ 14] J.
 H.
 Larkin and H.
 A.
 Simon.
 W h y a diagram is (sometimes) worth ten thousand words.
 Cognitive Science, 11:65100,1987.
 [15] M .
 Lewis.
 Visualization and situations.
 In J.
 Barwise, M .
 Gawron, G.
 Plotkin, and S.
 Tutiya, editors.
 Situation Theory and its Applications.
 CLSI Publications, Stanford, C A.
, 1991.
 [16] M .
 Lewis and J Toth.
 Situated cognition in diagrammatic reasoning.
 AAAJ Technical Report on Reasoning with Diagrammatic Representations, pages 4752,1994.
 SS9202.
 [17] J.
 Mackinlay.
 Automating the design of graphical presentations of relational information.
 A C M Transactions on Graphics, 5(2): 110141, April 1986.
 [18] C.
 Mitchell and D.
 Sasi.
 Use of modelbased qualitative icons juid adaptive windows in workstations for supervisory control systems.
 IEEE Transactions on Systems.
 Man, and Cybernetics, 15:792798,1987.
 [19] N.
 Moray, J.
 Lee, K.
 Vicente, B.
 Jones, and J.
 Rasmussen.
 A direct perception interface for nuclear power plants.
 In Proceedings of the Human Factors and Ergonomics Society.
 38th Annual Meeting, pages 481^85, Nashville, TN.
, Oct 1994.
 [20] D.
 Subramanian.
 A theory of justified reformulations.
 In D.
 Benjamin, editor.
 Change of Representation of Inductive Bias, pages 147167.
 KJuwer Academic Publishers, Dordrecht, 1990.
 [21] J.
 Zhang and D.
 Norman.
 Representations in distributed cognitive tasks.
 Cognitive Science, 18:18122,1994.
 459 Structural and Thematic Alignments in Similarity Judgments Miriam Bassok Department of Psychology University of Chicago 5848 S.
 University Ave.
 Chicago, IL 60637 mbmb@ccp.
spc.
uchicago.
edu Douglas L.
 M e d i n Department of Psychology Northwestern University 2029 Sheridan Rd.
 Evanston, IL 60208 medin@nwu.
edu Abstract We examined similarity judgments between simple NounVerbNoun statements that were matched either in their verbs or nouns (separate matches) and made either analogous or nonanalogous assertions (combined matches).
 An analysis of written justifications that accompanied subjects' similarity judgments revealed that matching verbs and matching nouns lead to two qualitatively different types of alignments.
 Matching verbs (e.
g.
, "The carpenter fixed the chair" and "The plumber fixed the radio") led subjects to construct structural alignments and evaluate the quality of the resulting analogies (e.
g.
, "Not analogous because plumbers don't fix radios as part of their job").
 By contrast, and contrary to any traditional account of similarity as a process of comparison, matching nouns (e.
g.
, "The carpenter fixed the chair" and "The carpenter sat on the chair") led subjects to construct thematic ahgnments and evaluate similarity based on the plausibility of the resulting causal or temporal scenarios (e.
g.
, "He sat on the chair to see whether he fixed it well").
 I n t r o d u c t i o n H o w do people establish similarities between objects, situations, or events? The answer to this question is crucial given that similarity serves as a central explanatory construct in theoretical accounts of other cognitive processes (e.
g.
, categorization, inference, transfer of learning).
 Medin, Goldstone, and Gentner (1993) propose that similarity is an outcome of an active and constructive process of comparison in which people align the representations of the compared stimuli.
 In particular, they establish matches between two qualitatively distinct types of aspects: 1.
 Attributes, oneplace predicates that take objects as arguments (e.
g.
, BIG(house); RED(apple)), and 2.
 Relations, predicates that take two or more attributes, objects, or other relations as arguments (e.
g.
, B I G G E R  T H A N ( h o u s e , tent); S A M E COLOR(apple, book)).
 The motivation behind this distinction is that our representations of stimuli are structured such that objects and their attributes are interrelated (e.
g.
, books are made o/paper; carpenters/jjc chairs).
 Hence, people align the structured representations of the compared stimuli.
 Evidence in support of the structural alignment hypothesis comes from studies that contrast the relative impact of relational and attributional matches on similarity judgments (e.
g.
, Goldstone, Medin, & Gentner, 1991; Markman & Gentner, 1993; Medin, Goldstone, «fe Gentner, 1990).
 For example, Goldstone et al.
 (1991) found that people process relational and attributional matches in separate pools.
 They asked subjects to choose which of two targets was more similar to a given base.
 Presented with a base such as O X O , subjects were more likely to choose A * A (one relational match, i.
e.
, symmetry) than A * 0 (one attributional match, i.
e.
, circle).
 However, presented with a pair of targets with an additional attributional match (X), subjects were less likely to choose A X A (one relational and one attributional match, i.
e.
, symmetry and X ) than A X O (two attributional matches, i.
e.
, X O ) .
 That is, the existence of an additional attributional match in the second pair of targets changed the relative weight given to the relational (symmetry) and attributional (O) matches.
 Such differential weighting of relational and attributional matches has been captured by the M A X model, which posits that these two types of matches are processed in separate pools, and that people assign higher weights to matches in the bigger pool.
 Note that in order to contrast the impact of relational and attributional matches on similarity these studies used stimuli in which relations and attributes were separable and independent.
 For example, the symmetry of O X O and A*A (relation) is independent of whether the symmetric shapes in the two figures happen to be circles or triangles (attributes), or that a star is between two triangles (A*A) rather than vice versa (*A*).
 However, when people assess similarities between actual objects, situations, and events, relational predicates and the objects that serve as arguments in these predicates are not independent.
 For example, carpenters/u chairs as part of their profession whereas plumbers do not, cutting grass is a different type of cutting than cutting hair, and the difference in the costs of mozzarella cheese and cottage cheese is of a different magnitude than the difference between the costs of mozzarella cheese and a house.
 People are aware of such dependencies and spontaneously draw inferences based on their knowledge about the way in which various objects tend to be interrelated (e.
g.
, Anderson & Ortony, 1975; Gentner & France, 1988; Ortony, 1979).
 Given such inferences, it is unclear whether the conclusion that people process separately relational and attributional matches can be generalized to stimuli in which these two types of aspects are interdependent.
 The impact of inferences based on dependencies between relations and attributes has been recently documented in studies on analogical transfer (Bassok & Olseth, 1995; Bassok, W u , & Olseth, 1995).
 Existing models of analogical transfer are based on the assumption that 460 mailto:mbmb@ccp.
spc.
uchicago.
edumailto:medin@nwu.
eduattributional matches either support or compete with relational matches (Falkenhainer, Forbus, & Gentner, 1989; Hoiyoak, & Thagard, 1989).
 However, transfer performance was found to be affected by dependencies between these two types of aspects.
 For example, Bassok & Olseth (1995) found that after learning to solve physics problems involving constant change in speed, 7 1 % of subjects spontaneously applied the learned solution to analogous nonphysics problems involving continuous constant change (e.
g.
, constant change in the rate of population growth in people/year), but only 2 7 % of subjects applied the physics solution to analogous problems involving discrete constant change (e.
g.
, constant change in the rate at which people attend an annual conference in people/year).
 Such differential transfer occurred even though the manner of change was never mentioned during training.
 Thus, it appears that people spontaneously interpreted "constant change in speed" to mean "continuous constant change.
" Matches and mismatches between the interpreted meaning of constant change in the learned and novel problems (i.
e.
, continuous vs.
 discrete), rather than separate matches in relational terms ("constant change") or attributional terms ("people," "years") determined the scope of analogical transfer.
 The present study was designed to examine whether the conclusion that people process separately relational and attributional matches can be generalized to stimuli in which these two types of aspects are interdependent.
 W e asked subjects to rate similarities between simple NounVerbNoun statements, letting verbs stand for relations between objects and nouns stand for objects and their attributes.
 The statements were matched either in their verbs or in their nouns.
 For example, subjects were presented with a base statement "The carpenter fixed the chair" and were asked to assess the degree to which this statement was similar to a "relational target" with matching verb ("The electrician/iA:ed the radio") and to an "attributional target" with matching nouns ("The carpenter sat on the chair").
 Subjects were also asked to justify in writing their similarity ratings.
 Because nouns and verbs are semantically interdependent, we expected people to construct "combined representations" for the NounVerbNoun statements based on such semantic dependencies.
 For example, the above base statement could have been represented as "A professional doing his job.
" If people treat combined representations as conceptual entities, they might base their similarity judgments on combined matches between base and target statements and ignore the distinction between separate matches in relations (verbs) and attributes (nouns).
 However, even nonarbitrary conceptual combinations of relations and attributes have to be aligned for comparison.
 Hence, in order to constrain the comparison process people might exploit the distinction between relational and attributional matches even when these two types of aspects are interdependent.
 In order to examine the relative impact of combined and separate matches we created permutations of matching nouns and verbs that resulted in either analogous (i.
e.
, combined match) or nonanalogous (i.
e.
, combined mismatch) relational targets.
 Specifically, we examined similarity judgments for three types of relational targets: Good Analogies (e.
g.
, "The electrician fixed the radio").
 Poor Analogies (e.
g.
, "The plumber fixed the radio"), and Poor Analogies with matching subject (e.
g.
, "The c&vptnX&r fixed the radio").
 Each of these relational targets was paired with the same attributional target (e.
g.
, "The carpenter sat on the chair") which, having a different verb, was obviously nonanalogous to the base statement.
 To foreshadow our results, we found that combined matches dominated separate matches, and that the distinction between relational and attributional matches did not result in differential weighting of these two types of matches.
 Nonetheless, separate matches in nouns and verbs played a crucial role in similarity judgments — they determined the way in which subjects arrived at their similarity judgments.
 Matching verbs led subjects to construct structural alignments, i.
e.
, to compare the combined meaning of the paired statements and evaluate whether the statements were analogous (e.
g.
, "Not analogous because plumbers don't fix radios as part of their job").
 By contrast, and contrary to any traditional account of similarity as a process of comparison, matching nouns led subjects to construct thematic alignments, i.
e.
, to integrate the statements into causal or temporal scenarios and evaluate whether the resulting scenarios were plausible (e.
g.
, "Quite similar because he sat on the chair to see whether he fixed it well").
 Method Materials Eight action statements (e.
g.
, "The carpenter fixed the chair") and four comparison statements (e.
g.
, "Cottage cheese is cheaper than mozzarella cheese") served as base statements.
 For each of these 12 base statements we constructed four targets: one attributional (matching nouns) and three relational (matching verbs).
 Using these 12 sets of base and target statements we created three types of triplets, each consisting of a base, its attributional target, and one of its three relational targets.
 Below is one set of statements from which we constructed the three types of triplets (123, 124, and 125): Bass: 1.
 The engineer designed a car.
 Attributional target: (AA) 2.
 The engineer drove a car.
 Relational targets: (RC) 3.
 The choreographer designed a dance.
 (R) 4.
 The lawyer designed a dance.
 (RA) 5.
 The engineer designed a dance.
 The separate and combined matches between the base (1) and each of its targets (2 through 5) appear in parentheses: A denotes an attributional match (noun), R a relational match (verb), and C a combined match (good analogy).
 Note that the base and relational Target 3 (Good Analogy) made assertions that were compatible with people's default semantic expectations (e.
g.
, professionals doing their job).
 By contrast, relational Targets 4 and 5 (Poor Analogies) 461 made assertions that violated such default expectations (e.
g.
, neither lawyers nor engineers design dances as part of their job, although they could do it as individuals).
 Each triplet was typed on a separate page, with the base centered above the two targets.
 The left and right positions of the relational and attributional targets were randomized.
 A 7point rating scale appeared below each of the two targets.
 The scale assessed either similarity or difference'.
 Accordingly, the lowest rating (1) was labeled either "not at all similar" or "not at all different" and the highest rating (7) was labeled either "very similar" or "very different.
" W e constructed 12page booklets by randomly selecting a triplet type (123, 124, or 125) for each of the 12 base statements and collating the selected pages in randomized order.
 Procedure Subjects were 80 undergraduates from University of Chicago and from Northwestern University.
 They were tested individually or in small groups.
 Subjects were asked to rate either how similar (N=39) or how different (N= 41) each of the two bottom statements was to the top statement and to justify their ratings in the space provided below the rating scales.
 The task lasted between 1530 min.
Results and Discussion In what follows w e first describe the distribution of similarity ratings and then present an analysis of the justifications that accompanied these ratings.
 Similarity Ratings W e transformed the difference ratings into similarity ratings (8rd=rs), and in the present paper we do not distinguish between these two types of judgments (see again Note 1).
 Table 1 presents the average ratings for the three types of relational targets and their corresponding attributional targets.
 Standard deviations appear in parentheses.
 Because each of the three relational targets was paired with the same attributional target (12 ratings in the right column of Table 1), it is of little surprise that the average similarity ratings for the attributional targets did not differ across the three triplet types (F<1).
 The comparisons of interest are between the three relational targets in the left column of Table 1.
 The first comparison of interest is between the Good Analogy (Target 3) and Poor Analogy (Target 4) relational targets.
 These targets were equated in their separate matches to the base (i.
e.
, matching verb and mismatching nouns).
 However, Good Analogies (i.
e.
, combined match) were rated more highly than Poor Analogies (4.
63 vs.
, 3.
13, respectively, F(l,78)=79.
12, Mse=2.
29, p<.
001).
 The second comparison of interest is between the two Poor Analogy relational targets in the 124 and 125 triplets.
 Both targets mismatched the base in their combined meaning, but Target 5 had an additional attributional match (+ Subject) relative to Target 4.
 This additional match resulted in higher similarity ratings (3.
92 vs.
 3.
13 for Targets 5 and 4 respectively, F(l,78) = 33.
56, Mse=1.
53, p<.
001).
 This pattern of similarity ratings shows that when the compared stimuli consist of semantically interdependent relations and attributes, matches in the inferred combined meaning of the statements override separate matches.
 Thus, overall, Good analogies were rated more highly than Poor analogies even when Poor analogies had an additional attributional match (Target 3 > Target 5 > Target 4).
 However, when the compared stimuli differ in their combined meaning similarity increases with the number of separate matches.
 Table 1: Average similarity ratings for relational and attributional targets Good Analogy (123 triplets) Poor Analogy (124 triplets) Poor Analogy + Subject (125 triplets) Relational targets 4.
63 (1.
21) 3.
13 (1.
26) 3.
92 (1.
41) Attributional targets 3.
86 (1.
48) 4.
11 (1.
37) 4.
00 (1.
34) 1 Similarities and differences are not always inverses (Medin, et al.
, 1990).
 However, because this variable did not interact with the results reported in this paper, we combined the results obtained for these two types of judgments.
 The finding that Good Analogies were rated more highly than Poor Analogies is consistent with Gentenr's (1983) systematicity principle, because combined matches can be considered as matches in inferred higherorder relations (e.
g.
, the engineer designed a car because it is his job, and the choreographer designed a dance because it is her job).
 The systematicity principle predicts that higherorder relational matches would constrain separate matches, both relational and attributional.
 However, our findings do not support the claim that people process relational and attributional matches in separate pools and give higher weights to matches in the bigger pool (e.
g.
, Goldstone et ai, 1991).
 In the independent case, two attributional matches (OXOAXO) were found to be rated more highly than one relational match and one attributional match ( O X O  A X A ) .
 By contrast, in the dependent case, there was no difference in the ratings of the attributional and relational targets in the 125 triplet (bottom row of Table 1) even though Target 2 had two matching nouns whereas Target 5 had one matching noun and one matching verb.
 The present pattern of similarity ratings suggests that models of structural alignment (e.
g.
, Gentner & Markman, 1994; Goldstone, 1994; Markman & Gentner, 1993) might need to be modified to accommodate the difference between the dependent and the independent case.
 In particular, it appears that in the dependent case people disUnguish between combined (Target 3) and separate matches (Targets 462 2, 4, 5), but do not distinguish between separate relational and attributional matches (e.
g.
, the relational and attributional targets in triplet 125).
 However, analysis of the justifications that accompanied subjects' similarity ratings revealed that existing models of similarity cannot be adjusted to accommodate the present results.
 All traditional models of similarity are based on the assumption that similarity is a process of comparison that is mediated by matches and mismatches between various aspects of the compared stimuli.
 By contrast, we found that in some cases similarity judgments are not mediated by a process of comparison.
 Rather, as w e describe in the next section, similarity judgments can be mediated by a process of thematic alignment in which people integrate the base and target statements into causal or temporal scenarios.
 Similarity justifications Subjects generated between one to five justifications per target, resulting in a total of 1183 justifications for the relational targets (1.
23 per target) and 1223 justifications for the attributional targets (1.
27 per target).
 W e classified these justifications into three general types: Syntactic, Separate, and Combined.
 Syntactic.
 Justifications were coded as syntactic when they involved syntactic labels (e.
g.
, "different verbs"); reference to words (e.
g.
, "only the words are the same"); or reference to the structure of the sentence (e.
g.
, "both have the same structure").
 Syntactic justifications were infrequent ( 2 %  4 % per target type) and were distributed uniformly across the relational and attributional targets.
 Separate.
 Justifications were coded as separate when they referred to matches and mismatches between the specific nouns or verbs, either direct (e.
g.
, "both about a chair," "both fix") or indirect (e.
g.
, "both race and piano competition involve victory," "cutting is actively doing something as opposed to thinking about something").
 Subjects were very likely to mention separate matches and mismatches in their justifications ( 6 1 % 7 1 % per target type), but the distribution of these justifications simply mirrored the distribution of noun and verb matches in our stimuli (i.
e.
, more verb matches for relational targets and more noun matches for attributional targets).
 Thus, neither separate nor syntactic justifications can account for the significant differences in subjects' similarity ratings of analogous (13) and nonanalogous (14) targets.
 Combined.
 Differences in similarity ratings of the relational and attributional targets are adequately captured by the distribution of justifications that referred to the combined meaning of the compared statements ( 2 7 % 3 5 % per target type).
 In particular, we identified two qualitatively different types of combined justifications: (1) Analogies that aligned the structures of the compared statements, and (2) causal or temporal Scenarios that integrated the statements by forming thematic alignments.
 Below w e first define these two types of combined justifications and then present their distribution in the relational and attributional targets.
 Analogies: Combined justificauons were coded as analogies when they involved explicit references to analogy (e.
g.
, "the analogy is too farfetched," "barbenhair :: teen: lawn"), or described in what sense the statements were good or poor analogies (e.
g.
, "the child and the w o m a n both enjoyed something," "comparison of two sounds by two comparable sources").
 T w o prevalent types of combined justifications that were coded as analogies compared role appropriateness of the nounverbnoun combinations (e.
g.
, "a lawyer would never design a dance," "most children do not enjoy jobs") or the overall truth and validity of the compared statements (e.
g.
, "does not say anything w e don't already know like the other two," "the first sentence is a fact, whereas the second is an opinion").
 Scenarios: Combined justifications were coded as scenarios whenever they related the compared statements by causal or temporal relations.
 Examples of causal scenarios are: "A teacher may have listened to the lecture to prepare" (for the base "The teacher prepared a lecture" and the target "The teacher listened to the lecture"); "Something the child might do if he/she enjoyed the toy, out of selfishness" (for the base "The child enjoyed the toy" and the target "The child hid the toy"); or "A logical step: since equations are more accurate they are more difficult to use" (for the base "Equations are more accurate than words" and the target "Equations are more difficult than words").
 Examples of temporal scenarios are: "Very similar since he is now with the product he has just fixed," "A child might hide the toy while playing with it," "The barber would probably think about the hair before he cut it," or "Examining a case is something the lawyer would do when taking it.
" Table 2 presents the proportion of analogies and scenarios generated for the relational and attributional targets.
 Table 2 Proportion of Analogies and Scenarios in relational and attributional targets Relational targets 123 (N= 106) 124(N=132) 125 (N= 117) Attributional targets 123 (N= 116) 124 (N= 130) 125 (N= 107) Analogies 100 97 87 41 36 41 Scenarios 0 3 13 59 64 59 As can be seen by comparing the top and bottom panels of Table 2, analogies were virtually the only type of combined justifications generated for the relational targets (matching verbs), whereas more than half of the combined 463 justifications generated for the attributional targets (matching nouns) were scenarios.
 Thus, 9 4 % of the 355 combined justifications generated for the relational targets were analogies and only 6% were scenarios.
 By contrast, only 39% of the 353 combined justifications generated for the attributional targets were analogies and 6 1 % were scenarios.
 This overwhelming difference in the distribution of analogies and scenarios for the relational and attributional targets demonstrates that, when the base and target share a relational match, subjects construct structural alignments, but when the base and target share attributional matches, they construct thematic alignments .
 The high proportion of scenarios generated by our subjects is especially striking given that "thematic justifications" are believed to characterize similarity judgments of young children or people from nonwestern cultures who "fail to appreciate" the value of relational similarities (Markman, 1989).
 Yet, extremely bright undergraduates who participated in this study generated a total of 234 thematic justifications, and 214 of these justifications were written next to high quality analogical arguments justifying similarity of relational targets in the corresponding triplets.
 This surprising finding could be understood in terms of the pragmatic role of similarity.
 W e often use similarity to draw inferences (if y is like x in these ways, it may be like it in other ways).
 Scenario thinking can be seen as another way of drawing inferences where the two terms together suggest a context where understanding can be applied.
 Conclusion Medin et al.
 (1993) pointed out that relational and attributional matches constrain the "respects" that people select as relevant to their similarity judgments.
 In the present study we found that matches in these two types of aspects also affect the way in which people align the compared stimuli.
 Using semantically interdependent NounVerbNoun combinations we found that matching verbs lead to structural alignments and matching nouns to thematic alignments.
 Although our results support the psychological validity of the distinction between relational and attributional matches, we found that when subjects assess similarities between sentences with matching nouns they d^ not always compare these sentences or their interpretations.
 Rather, contrary to any traditional view of similarity, they integrate them into common scenarios and base their similarity judgments on the plausibility of such scenarios.
 Note that thematic alignments could not have been discovered with stimuli consisting of separable and independent relations and attributes (i.
e.
, it is unlikely that people would construct a scenario relating O X A and 0*A), and that it might be impossible to generalize processing assumptions across different types of stimuli.
 Clearly, comparison between various aspects of the paired stimuli is not the only process that underlies similarity judgments.
 In fact, our results suggest that thematic alignments will mediate transfer even without attributional matches.
 For example, it is likely that participation in a common scene or in a functional or causal relation will increase similarity between participants that do not share common attributes (e.
g.
, snow and shovel vs.
 snow and rake; flowers and pot vs.
 flowers and pan).
 An important challenge for future research is to identify the conditions that support structural and thematic alignments.
 To the extent that similarity alerts people to potential contexts in which they could apply their knowledge, such conditions are likely to be found in studies that use semantically rich stimuli and ecologically valid tasks.
 Acknowledgments The present study was supported by a grant from National Science Foundation BNS# 9211277 to Douglas Medin and by a grant from the University of Chicago School Mathematics Project to Miriam Bassok.
 W e want to thank Valerie Chase and Edward Wisniewski for their helpful comments.
 References Anderson, R.
 C, & Ortony A.
 (1975).
 On putting apples into bottles — a problem of polysemy.
 Cognitive Psychology, 7, 167180.
 Bassok, M.
 & Olseth, K.
 L.
 (1995).
 Objectbased representations: Transfer between cases of continuous and discrete models of change.
 Journal of Experimental Psychology: Learning, Memory, and Cognition (in press).
 Bassok, M.
, W u LingLing, & Olseth, K.
 L.
 (1995).
 Judging a book by its cover: Interpretative effects of content on problemsolving transfer.
 Memory & Cognition (in press).
 Falkenhainer, B.
, Forbus, L.
 K, & Centner, D.
 (1989) The structure mapping engine: Algorithm and examples.
 Artificial Intelligence, 41, 163.
 Centner, D.
 & France, I.
 M.
 (1988).
 The verb mutability effect: Studies of the combinatorial semantics of nouns and verbs.
 In S.
 L.
 Small, G.
 W.
 Cotrell, & M.
 Tanenhaus (Eds.
), Lexical ambiguity resolution in the comprehension of human language (pp.
 343382).
 Los Altos, CA: Morgan Kaufman Centner, D.
 (1983).
 Structuremapping: A theoretical framework for analogy.
 Cognitive Science, 7, 155170.
 Centner, D & Markman, A.
 B.
 (1994).
 Structural alignment in comparison.
 Psychological Science, 5, 152158.
 Coldstone, R.
 L.
 (1994).
 Similarity, interactiveactivation and mapping.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 328.
 Coldstone, R.
 L.
, Medin, D.
 L.
, & Centner, D.
 (1991).
 Relational similarity and the nonindependence of features in similarity judgments.
 Cognitive Psychology, 23, 222262.
 Holyoak, K.
 J.
, & Thagard, P.
 (1989).
 Analogical mapping by constraint satisfaction.
 Cognitive Science, 13, 295355.
 Markman, A.
 B.
, & Centner, D.
 (1993).
 Structural alignment during similarity comparisons.
 Cognitive Psychology, 25, 96102.
 Markman, E.
 M.
 (1989).
 Categorization and Naming in Children.
 Cambridge, Mass.
:MIT Press.
 Medin, D.
 L.
, Coldstone, R.
 L.
, & Centner, D.
 (1990).
 Similarity involving attributes and relations: Judgments 464 of similarity and difference are not inverse.
 Psychological Science, 1, 6469.
 Medin, D.
 L.
, Goldstone, R.
 L.
, & Centner, D.
 (1993).
 Respects for similarity.
 Psychological Review, 100, 254278.
 Ortony, A.
 (1979) Beyond literal similarity.
 Psychological Review , 86, 161180.
 465 Retrieval and Learning in Analogical Problem Solving Randolph M .
 Jones Artificial Intelligence Laboratory University of Michigan 1101 Beal Avenue Ann Arbor, M I 481092110 rj o n e s @ e e c s .
 u m i c h .
 e d u Pat Langley Robotics Laboratory Computer Science Department Stanford University Stanford, C A 94305 l a n g l e y @ c s .
 S t a n f o r d .
 e d u Abstract Eureka is a problemsolving system that operates through a form of analogical reasoning.
 The system was designed to study how relatively lowlevel memory, reasoning, and learning mechanisms can account for highlevel learning in human problem solvers.
 Thus, Eureka's design has focused on issues of memory representation and retrieval of analogies, at the expense of complex problemsolving ability or sophisticated analogical elaboration techniques.
 Two computational systems for analogical reasoning, ARCS/ACME and MAC/FAC, are relatively powerful and wellknown in the cognitive science literature.
 However, they have not addressed issues of learning, and they have not been implemented in the context of a performance task that can dictate what makes an analogy "good".
 Thus, it appears that these different research directions have much to offer each other We describe the Eureka system and compare its analogical retrieval mechanism with those in ARCS and MAC/FAC.
 We then discuss the issues involved in incorporating ARCS and MAC/FAC into a learning problem solver such as Eureka.
 We are interested in the lowlevel memory, learning, and reasoning processes that give rise to improvement in problemsolving behavior over time.
 E u r e k a is the problemsolving architecture we are using to study these processes.
 A n explicit assumption within EUREKA's design is that all processes are aspects of analogical reasoning.
 In addition, we designed the system so that the lowlevel retrieval and matching processes would dominate its behavior.
 The system does not possess or learn the types of highlevel control knowledge found in other problemsolving systems.
 Our intent is to investigate how much of human learning in problem solving can be modeled with such lowlevel mechanisms.
 This paper presents an overview of EUREKA's architecture and some of the learning results it accounts for.
 W e then turn our attention to two wellknown analogical retrieval mechanisms in the cognitive science literature.
 A R C S (Thagard, Holyoak, Nelson, & Gochfeld, 1990) and M A C / F A C (Centner & Forbus, 1991) model psychological findings on analogical retrieval and reasoning.
 However, neither has been examined in the context of a problemsolving system, or in a system that learns with experience.
 The remainder of the paper focuses on the issues of analogical retrieval and learning, and discusses the possibilities of incorporating these alternative analogical retrieval mechanisms into a problemsolving system.
 Terminology Before continuing, it is worth defining some terms to avoid future confusion.
 For analogical reasoning, a basic unit of knowledge is the analogical case, which is further decomposed into a set of concepts and relations between those concepts.
 For our purposes, every analogical case corresponds to a problem situation.
 A problem situation is a specific set of relations describing a state of the world, together with a set of goal relations that should be achievable by applying a sequence of operators to that state.
 Note that cases in Eureka are a bit different from those in casebased reasoning, where "case" typically denotes an entire problem solution.
 At any given time, Eureka will have a current problem situation, for which it must decide on an operator to apply.
 This is the target problem situation.
 The analogical reasoning process is generally divided into three stages.
 First, a retrieval mechanism identifies a number of candidate sources from the potential analogies stored in memory.
 Next, the set of candidate sources undergo further elaboration to fill out the potential mappings between each source and the target.
 Finally, evaluation of each candidate source determines how well each candidate will serve as an analogical source for the target.
 Let us now turn to a description of EUREKA in these terms.
 An overview of EuREKA Jones (1993) presents the computational details of Eureka, but here we provide a general overview of the system.
 Eureka adopts a reasoning formulation cai\ed flexible meansends analysis (Jones & VanLehn, 1994; Langley & Allen, 1991).
 As described above, each problem situation includes a current world state and a set of goal conditions to which the state should be transformed.
 Operator selection creates a goal to apply a particular operator to the current state of the problem situation.
 If the preconditions of the operator can all be matched to the current state, the operator executes, leading to a new problem situation with a different state but the same goals.
 Otherwise, the system sets up a new problem situation with the same current state, but with the operator's preconditions as the new goals.
 Eureka then treats this new problem situation in a recursive manner.
 The difference between flexible meansends analysis and standard meansends analysis (Ernst & Newell, 1969; Fikes &Nilsson, 1971) is that the flexible form does not require se466 mailto:ones@eecs.
umich.
edumailto:langley@cs.
Stanford.
edulected operators to apply directly to the current goal conditions (i.
e.
, it is not necessary that the selected operator obviously "reduce any differences") Rather than using this heuristic to limit search, E u r e k a relies on its retrieval and learning mechanisms to control which operators are suggested to apply to any particular problem situation.
 Because operator selection depends on the entire problem situation (and not just the goals), E u r e k a can blend goaldriven and opportunistic behavior when appropriate.
 Every time E u r e k a generates a new problem situation, it stores a representation of the situation (as well as the operator the led to this situation) into its longterm semantic network.
 Each object and relation in a problem situation becomes a node in the semantic network.
 In addition, the network stores nodes representing instances of architecturally defined concepts, such as problem situations and operators.
 Items are never deleted from longterm memory, and memories are never stored in an abstract form.
 Rather, the semantic m e m ory stores all the specific problem situations that it encounters.
 Situations become linked together in memory when they share objects, relations, or object types.
 If a particular concept from a problem situation already exists in memory.
 Eureka increases the trace strengths of the links from the concept, rather than adding a new copy of the concept.
 When E u r e k a is working on a particular problem situation, it must select an operator to apply to the problem.
 To this end.
 E u r e k a retrieves a subset of the stored problem situations from longterm memory.
 This small set of candidate sources is further elaborated and evaluated, to see which would provide the best candidate analogy for the current problem situation.
 E U R E K A chooses one candidate stochastically, based on the evaluation score, and identifies the operator associated with that source analogy.
 Finally, the system creates a goal to apply to the newly mapped operator to the current state.
 E u r e k a proceeds in this manner until it solves the problem or thecurrent solution path fails (by exceeding a time limit or detecting a cycle in the solution path).
 Upon failure, EUREKA does not have the luxury of backtracking, which would allow the system to search the problem space systematically and possibly exhaustively.
 Rather, E U R E K A begins the problem anew from the initial problem situation.
 The inability to backtrack systematically greatly hinders the system's ability to solve problems, but w e feel that this is a psychologically plausible limitation.
 The limitation also places further importance on effective learning.
 The combination of EUREKA's learning mechanisms and its stochastic selection process encourage the system to explore alternative solution paths on subseqent attempts to solve a problem.
 However, there is no guarantee that a previous search will not be duplicated.
 If the system fails to find a solution after a preset number of attempts (50 in our experiments), it abandons the problem completely.
 Analogical retrieval in EUREKA Eureka's analogical reasoner incorporates two stages.
 The Table 1: Eureka's algorithm for spreading activation.
 Let ACTIVATION_THRESHOLD be 0.
01; Let DAMPING_FACTOR be 0.
4; Let INITIAL_ACTIVATION be 1.
0; SPREAD_INIT(Source) SPREAD(Source,INITIAL_ACTIVATION,NIL) SPREAD(Source,Value,Path) If (Value < ACTIVATION_THRESHOLD) or Source is in Path Then EXIT Else Increase Source.
Activation by Value; For each link X from Source Let Target be the node connected to Source by X; Let Newvalue be SPREAD_VALUE(Source,X,Value) * DAMPING_FACTOR; PUSH Source onto Path; SPREAD(Target,Newvalue,Path) SPREAD_VALUE(Source,Link,Value) Let Total be 0; For each link X from Source If X has the same type as Link Then Increase Total by X.
trace_strength; Return Value * (Link.
trace_strength / Total) first retrieves a set of candidate source problem situations from memory.
 The second involves a relatively expensive computation to elaborate the mapping between each candidate source and the target problem situation.
 Because the elaboration process is so expensive, it is important that the cheaper retrieval process return a relatively small set of candidates.
 However, the system must also do what it can to make sure it does not miss good candidates in memory.
 In EUREKA, we have focused on the retrieval phase, to analyze how changes in retrieval patterns can lead to higherlevel changes in problem solving.
 As mentioned above, EUREKA stores in its semantic network an episodic memory of every problem situation it encounters.
 Retrieval is implemented as a spreadingactivation process similar to that found in ACT (e.
g.
, Anderson, 1976).
 Each node in the representation of the target problem situation becomes a source of activation, which then spreads to other nodes according to the strengths of the links to those nodes.
 The activation algorithm appears in Table 1.
 After the spread of activation terminates, EUREKA checks the "toplevel" node for each problem situation stored in 467 memory.
 This node contains a unique name for the problem situation and has links to all the nodes representing relations in the problem situation.
 The problem situation whose toplevel node has the highest level of activation becomes a candidate source.
 In addition, any other problem situation becomes a candidate source if its toplevel node has at least one percent of the level of activation of the strongest source.
 Learning in Eureka As Table 1 indicates, the activation that spreads from a source node, i, to another node, j, depends on the number of nodes to which i is linked (because activation is divided among links of the same type), as well as the strength of the link between ? and j.
 This highlights an important aspect of the retrieval process within Eureka.
 That is, the spread of activation (and, therefore, patterns of retrieval) can change for primarily two reasons: new nodes and links being added to memory, and changes in link strengths.
 It follows that these are the two ways that learning can change behavior in EUREKA.
 Thus, one way in which Eureka learns is simply by adding new experiences by rote into memory.
 Because spreading activation is a competitive process, introducing more competitors into memory can change what gets retrieved in the future.
 However, simply adding experiences to memory will not necessarily improve problemsolving behavior, which is what we really want.
 Therefore, Eureka also changes its behavior by updating link trace strengths.
 When the system solves a particular target problem situation, it checks which source analog was used to help solve the problem.
 The system then strengthens the links between the target problem situation and the successfully applied analogical situation.
 Note that a problem presented to EUREKA generally involves a set of problem situations, so EUREKA can learn about solved problem situations, even if the attempt to solve the global problem fails.
 In the long run, stored problem situations that help solve new problem situations become strongly connected to the problem situations that they help solve.
 Thus, they "soak up" more activation from future problem situations, and become more easily retrieved.
 It is also worthwhile to note that Eureka requires its learning mechanism to be noise tolerant.
 Because operator selection is based on the current structure of memory and the system cannot systematically backtrack, a search path that leads to failure now may turn into a successful path later.
 EUREKA might fail simply because it does not "remember" or retrieve the appropriate operator in a particular situation.
 As the system gathers experience, it may learn to retrieve such operators, turning bad search paths into good ones.
 Qualitative behaviors exhibited by Eureka Table 2 presents VanLehn's (1989) list of a number of robust qualitative results that have been observed in humans learning to solve problems.
 EUREKA addresses these issues to varying degrees.
 Jones and Langley (1994; Jones, 1989) present a number of detailed experiments with EUREKA that address these results.
 Due to a lack of space, we will not present the Table 2: Robust learning behaviors identified in human problem solvers (VanLehn, 1989).
 1.
 Subjects reduce their verbalizations of task rules as they become more experienced with practice.
 2.
 Improvement occurs quickly in knowledgelean domains.
 3.
 There is a powerlaw relationship between the speed of performance on perceptualmotor skills (and possibly problemsolving skills) and the number of practice trials.
 4.
 Problem isomorphs do not become more difficult simply by changing surface features of the problems.
 5.
 Other representation changes can make problem isomorphs substantially more difficult.
 6.
 There is asymmetric transfer between tasks when one task subsumes another.
 7.
 Negative transfer is rare.
 8.
 "Set" effects (or Einstellung) can lead to negative transfer.
 9.
 Spontaneous noticing of a potential analogy is rare.
 10.
 Spontaneous noticing is based on superficial features.
 details here so we can discuss other issues.
 EUREKA's retrieval and learning methods directly account for most of the behaviors identified by VanLehn.
 Behaviors 1 and 3 require a bit of extra interpretation, and are not modeled as well as the others.
 In general, the results indicate that these types of learning can indeed arise from rather lowlevel processes.
 There are other models of analogical problem solving (e.
g.
, Hammond, 1986; Veloso & Carbonell, 1993), which rely on indexing methods for analogical retrieval, and generally focus on learning and reasoning at a higher architectural level than Eureka.
 In contrast, there are other analogical mechanisms that share Eureka's spirit in modeling analogical reasoning as a relatively lowlevel memory process.
 The following section discusses two of the more wellknown models of this type.
 Learning to solve problems with ARCS and MAC/FAC A R C S (Thagard et al.
, 1990) and M A C / F A C (Centner & Forbus, 1991) are the analogical retrieval algorithms associated with two relatively wellknown and sophisticated systems for analogical elaboration and evaluation: A C M E (Holyoak & Thagard, 1989) and S M E (Falkenhainer, Forbus, & Centner, 1989).
 It is attractive to consider incorporating these sys468 tems into a learning, problemsolving architecture such as Eureka.
 W e feel such an attempt could benefit research on both sides.
 O n the one hand, Eureka's analogical mechanisms have been used to model human learning in problem solving, but it is questionable whether they can model some of the psychological findings on analogical retrieval and evaluation (e.
g.
, Gick & Holyoak, 1983).
 O n the other hand, A R C S / A C M E and M A C / F A C have both been demonstrated on the retrieval and evaluation results, but they have so far been used to model analogical retrieval in relative isolation from other tasks.
 Although both systems have builtin notions of what makes a good analogy, it is sometimes difficult to judge why other potential analogs or mappings might not be better in particular situations.
 A problem solver provides a context by which to judge the quality of analogies more objectively: A good analogy is one that helps solve a problem.
 In addition, our work with E U R E K A has focused on how analogical reasoning can adapt with experience, but the two other systems have so far not incorporated mechanisms for changing their behavior over time.
 The remainder of this paper discusses the issues we foresee in incorporating the A R C S and M A C / F A C retrieval mechanisms into a problemsolving system that learns.
 First, let us provide a quick overview of the A R C S and M A C / F A C retrieval methods.
 Retrieval with ARCS A R C S divides the retrieval process into two stages, beginning with a table lookup for each concept in the target.
 This table provides a list of all the concepts in memory that are immediately related to a concept (e.
g.
, by subordinate, superordinate, or partof relationships).
 A R C S then considers retrieving any source that includes at least one of the collection of concepts related to the target.
 This happens by creating a constraint network of possible concept matches, linked together by excitatory and inhibitory links.
 A R C S only sets up match hypotheses between semantically similar concepts (from the lookup table).
 More complete match hypotheses are saved for the more expensive A C M E matcher.
 In addition, special nodes are created to link concepts that have been marked as important in various ways.
 Finally, activation spreads throughout the network until the network settles.
 Each candidate source receives a retrieval score, computed from the activation of the concepts in the source.
 It is not clear, however, that the A R C S system makes a distinction between candidate sources that "are retrieved" vs.
 those that are not.
 Retrieval with MAC/FAC M A C / F A C ' takes quite a different approach to retrieval.
 M A C computes a content vector for each source stored in memory.
 The content vector ignores concepts that represent simple objects, and records the number of occurrences of each concept that can take other concepts as arguments (e.
g.
, relations and functions).
 This requires M A C to know the entire 'Note that M A C corresponds to the analogical retrieval mechanism, while FAC is the more expensive elaboration and evaluation algorithm.
 space of such concepts ahead of time.
 M A C then similarly computes a content vector for the target of the analogy.
 The retrieval score for each potential source is computed as the dot product of the source's content vector with the target's content vector.
 This gives an estimate of the degree to which relations are shared between the target and each source, and it is very quick to compute.
 The source with the largest dot product is marked as a retrieved candidate.
 In addition, any other source with a dotproduct value of at least 1 0 % of the highest value is retrieved.
 Changes in retrieval as knowledge increases Having a feel for how A R C S and M A C / F A C work, let us turn our attention to how their behavior might adapt with experience.
 W e have stressed that our primary focus in E U R E K A is on how learning can change retrieval patterns, leading to larger changes in problemsolving behavior.
 Thus, it is most important for us to examine the types of events that allow Eureka's retrieval mechanism to learn, and how they would apply to M A C / F A C or A R C S .
 Let us first consider how the mere storage of new experiences can influence retrieval.
 There are two aspects of performance to examine when the knowledge base increases in size.
 First, new knowledge may change the time it takes for the retrieval algorithm to execute.
 Second, the resulting set of candidate sources may change as new potential sources are added to memory.
 Taking the first issue, EUREKA's spreadingactivation mechanism performs a limited search through memory, and many portions of memory (those distant from the target concepts) will be completely ignored by the retrieval process.
 Jones (1989, 1993) has demonstrated empirically and analytically that Eureka's form of spreading activation takes a constant amount of time relative to the size of memory, even when implemented as a serial algorithm.
 O n the other hand, the specific representation or "shape" of memory can sometimes have a significant impact on retrieval time.
 This is an important issue, related to the utility problem (Minton, 1988) in machine learning.
 It would not be desirable for a system to slow down merely because its memory is growing.
 However, both A R C S and M A C / F A C are guaranteed to take longer as new analogical sources are added to memory, because they both examine every potential source as part of the retrieval process.
 This means that processing is at least linearly related to the number of potential source analogs in memory.
 A R C S includes an even more expensive construction of the constraint network, which depends on the number of sources that include concepts similar to those in the target.
 Thagard et al.
 (1990) propose, however, that much of their algorithm can execute in parallel, so time will be constant if we assume an arbitrary number of processors (one per potential source stored in memory).
 Presumably the same is true of M A C / F A C .
 Let us next consider how the mere addition of cases to the knowledge base can change retrieval patterns.
 N e w problem situations in Eureka's memory imply new competitors for activation.
 Thus, if a newly stored situation shares concepts with other problem situations, activation levels necessarily 469 change.
 In contrast, M A C / F A C independently associates a content vector and retrieval score with each stored situation.
 The retrieval score has absolutely nothing to do with other stored cases.
 Thus, adding new cases will have a limited impact on the set of retrieved candidate sources.
 Because the retrieval threshold is based on a percentage of the highestvalued retrieval item, a newly stored problem situation can only significantly change retrieval patterns in the cases where it receives the highest retrieval score.
 A R C S uses an activation process that is inherently competitive like Eureka's.
 Thus, the final retrieval values for each candidate source can certainly change as memory grows.
 Law, Forbus, and Gentner (1994) showed that increasing the number of cases can be quite detrimental to A R C S , but did not adversely affect MAC/FAC's behavior.
 Presumably, similar detrimental effects would be seen in Eureka's retrieval mechanism as cases begin to compete with each other.
 O n the other hand.
 E u r e k a (and most likely A R C S ) can also benefit from the addition of appropriate knowledge.
 M A C / F A C can only benefit in the sense that it may have a new case to retrieve, but it cannot benefit in any competitive sense.
 Thus, w e interpret Law, Forbus, and Centner's result not as a condemnation of competitive retrieval algorithms, but as further evidence of the importance of associating a learning method with retrieval.
 T\ining retrieval with experience The second aspect of learning has to do with tuning the retrieval process to improve and focus itself with experience.
 Again, E u r e k a achieves this by increasing link trace strengths associated with stored problem situations when they aid in the solution of new problem situations.
 With appropriate experiences, the system will eventually retrieve fewer items, but they will have higher estimated quality.
 None of the presentations of A R C S or M A C / F A C have addressed the issue of learning.
 Thus, rather than comparing learning mechanisms, we are free to hypothesize the types of learning mechanisms that might be amenable to A R C S and M A C / F A C .
 A R C S has a competitive activationbased retrieval mechanism, so it is tempting to assume that it would benefit from a learning mechanism similar to Eureka's.
 However, it is important to note that activation spreads through a very different type of network in each case.
 Eureka's semantic network is a longterm structure encoding the representation of problem situations and the relations and objects they share.
 In contrast, the constraint networks in A R C S are constructed anew each time a target is presented, and represent potential ways to match the concepts in each source to the concepts in the target.
 Despite these differences, there still seems to be some potential to altering link strengths in A R C S .
 Some link strengths are fixed measures of the degree of similarity between differently related concepts (e.
g.
, synonyms have a similarity value of 0.
6, superordinates a value of 0.
3, and subordinates a value of 0.
2).
 There does not seem to be any reason in principle that these similarity measures could not be learned for specific concept pairs, rather than fixed by these abstract types.
 This is an attractive option, because it would allow a more pragmatic view of similarity that adapts to problemsolving experience, rather than requiring a fixed table of similarities to be provided to the system.
 In addition, A R C S gives extra strength to concepts that are marked as "important" and mappings that are marked as "presumed".
 These marks are specified and fixed before retrieval begins.
 One of the benefits of a performance task, such as problem solving, is that it is possible to induce important concepts over time.
 Perhaps such an induction algorithm could use experience to adapt the measure of "importance" of concepts over time.
 M A C / F A C is another story entirely, because it does not share the notion of competition between candidate analogical sources.
 As we have mentioned above, retrieval computations are independent for each targetsource pair.
 However, the one thing that is c o m m o n across candidate sources is the algorithm for computing the content vector.
 When constructing the vector, M A C / F A C counts each occurrence of every feature.
 These counts could instead be weighted by parameters for each feature, which would be tuned with experience.
 There is a potentially more interesting alternative for learning.
 It almost seems that there is a builtin assumption to M A C / F A C : changes in analogical retrieval should only arise through a reformulation of the representation of the sources and targets.
 It is not clear whether the creators of M A C / F A C intend this to be a fixed, architectural constraint, but it is certainly interesting to view it that way.
 In this case, the only way for M A C / F A C to tune its retrieval patterns would be for it to change the representation of its stored cases.
 These changes would be based on knowledge of how the retrieval scoring mechanism works, and would be designed to award useful candidate sources higher scores in future similar situations.
 It is not clear to us what the details of such a mechanism would be.
 However, it would provide a pragmatic approach to changing representation within a cognitive agent.
 The agent would change its representations in response to problemsolving success (or failure), and would change them in such a way as to improve future behavior.
 Summary E u r e k a provides a model of analogical retrieval in problem solving.
 In addition, it incorporates a learning mechanism that focuses on tuning the retrieval of candidate analogical sources from memory.
 These relatively lowlevel mechanisms give rise to larger qualitative changes in problemsolving behavior.
 W e have used the E U R E K A model to explain the primary learning effects that have been identified in human problem solvers.
 Because the system includes a memorybased mechanism for the retrieval of analogies, it is natural to compare this mechanism to A R C S and M A C / F A C , two wellknown retrieval mechanisms in the cognitive science literature.
 W e have used the lessons learned from building EUREKA to guide our analysis of how A R C S and M A C / F A C would fit into the context of a performance task (problem solving) where learning can and should take place.
 E u r e k a demonstrates that lowlevel mechanisms can have a significant impact on high470 level behavior.
 It will be interesting to see what qualitative differences arise in learning problem solvers that incorporate the A R C S or M A C / F A C algorithms.
 References Anderson, J.
 R.
 (1976).
 Language, memory, and thought.
 Hillsdale, NJ: Lawrence Erlbaum.
 Ernst, G.
, & Newell, A.
 (1969).
 GPS: A case study in generality and problem solving.
 N e w York: Academic Press.
 Falkenhainer, B.
, Forbus, K.
, & Centner, D.
 (1989).
 The StructureMapping Engine: Algorithm and examples.
 Artificial Intelligence, 41, 163.
 Fikes, R.
 E.
, & Nilsson, N.
 J.
 (1971).
 STRIPS: A new approach to the application of theorem proving to problem %oW\ng.
 Artificial Intelligence, 2, 189208.
 Centner, D.
, & Forbus, K.
 (1991).
 MAC/FAC: A model of similaritybased retrieval.
 In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Erlbaum.
 Gick, M.
, & Holyoak, K.
 (1983).
 Schema induction and analogical transfer.
 Cognitive Psychology, 15, 138.
 Hammond, K.
 J.
 (1986).
 Casebased planning: An integrated theory of planning, learning, and memory.
 Doctoral dissertation.
 Yale University.
 Holyoak, K.
, & Thagard, P.
 (1989).
 Analogical mapping by constraint satisfaction.
 Cognitive Psychology, 15, 138.
 Jones, R.
 M.
 (1989).
 A model of retrieval in problem solving.
 Doctoral dissertation.
 Department of Information and Computer Science, University of California, Irvine.
 Jones, R.
 M.
 (1993).
 Problem solving via analogical retrieval and analogical search control.
 In S.
 Chipman & A.
 Meyrowitz (Eds.
), Machine learning: Induction, analogy, and discovery.
 Boston: Kluwer Academic.
 Jones, R.
 M.
, & Langley, P.
 (1994).
 Learning and problem solving with limited memory.
 Manuscript in preparation.
 Jones, R.
 M.
, & VanLehn, K.
 (1994).
 Acquisition of children's addition strategies: A model of impassefree, knowledgelevel learning.
 Machine Learning, 16, 1136.
 Langley, P, & Allen, J.
 A.
 (1991).
 The acquisition of human planning expertise.
 In L.
 A.
 Birnbaum & C.
 C.
 Collins (Eds.
), Machine Learning: Proceedings of the Eighth International Workshop.
 Los Altos, CA: Morgan Kaufmann.
 Law, K.
, Forbus, K.
 D.
, & Centner, D.
 (1994).
 Simulating similaritybased retrieval: A comparison of A R C S and MAC/FAC.
 In A.
 Ram & K.
 Eiselt (Eds.
), Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Erlbaum.
 Minton, S.
 (1988).
 Learning effective search control knowledge: An explanationbased approach.
 Boston: Kluwer Academic.
 Thagard.
 P, Holyoak, K.
, Nelson, C, & Cochfeld, D.
 (1990).
 Analogical retrieval by constraint satisfaction.
 Artificial Intelligence.
 46,259310.
 VanLehn, K.
 (1989).
 Problem solving and cognitive skill acquisition.
 In M.
 I.
 Posner (Ed.
), Foundations of cognitive science.
 Cambridge, M A : M I T Press.
 Veloso, M.
 M.
, & Carbonell, J.
 G.
 (1993).
 Derivational analogy in Prodigy: Automating case acquisition, storage, and utilization.
 Machine Learning, 10, 249278.
 471 Incorporating RealTime Random Time Effects in Neural Networks: A Temporal Summation Mechanism Cheongtag Kim and In Jae Myung Department of Psychology The Ohio State University Columbus, Ohio 432101222 k i m .
 3 1 5 @ o s u .
 e d u & m y u n g .
 l @ o s u .
 e d u Abstract Implementing random time effects in neural networks has been a challenge for neural network researchers.
 In this paper, we propose a neurophysiologically inspired temporal summation mechanism to reflect realtime random dynamic processing in neural networks.
 According to the physiology of neuronal firing, a presynaptic neuron sends out a burst of random spikes to a postsynaptic neuron.
 In the postsynaptic neuron, spikes arriving at different points in time are summed until the postsynaptic membrane potential exceeds a threshold, thus initiating postsynaptic firing.
 This temporal summation process can be used as a metric for deriving time predictions in neural networks.
 To demonstrate potential applications of temporal summation, we have employed a feedforward, twolayer network featuring a Hebbian learning rule to perform simulations using the semantic priming experimental paradigm.
 W e are able to successfully reproduce not only the basic patterns of observed response time data (e.
g.
, positively skewed response time distributions and speedaccuracy tradeoffs) but also the semantic priming effect and the timecourse of priming as a function of stimulusonsetasynchrony.
 These results suggest that the proposed temporal summation mechanism may be a promising candidate for incorporating realtime, random time effects into neural network modeling of human cognition.
 1.
 Introduction Neural network modeling of human cognition represents an attempt to combine two of the three levels of analysis proposed by Marr (1982), viz.
, the psychological (algorithmic) and the neurophysiological (implementation) levels.
 While considering the role of the realtime dimension in neural network modeling, two perspectives are relevant.
 From the neurophysiological perspective, the firing pattern of neurons, a basic building block of neural information processing, is usually described as a realtime random process (Bialek, Rieke, de Ruyter van Steveninck, & Warland, 1991; Gerstner, Ritz, & van H e m m e n , 1993).
 From a psychological perspective, the response time variable has been an important source of information for understanding human cognition (Luce, 1986).
 These perspectives have motivated us to consider the incorporation of the temporal dimension into neural network modeling.
 Moreover, it can be argued that incorporating realtime dynamics into neural networks represents an essential step in specifying the linking rules between psychological and neurophysiological levels, which is critical to understanding cognition.
 Although some doubt has been raised about the ability of extant feedforward neural networks to predict the time course of information processing (Massaro & Cowman, 1993), some noteworthy mechanisms have been proposed, including: (1) gradual propagation of activation in time (Cascade model, McClelland, 1979; G R A I N model, McClelland, 1993; Cohen, Dunbar, & McClelland, 1990; Seidenberg & McClelland, 1989* ; Kawamoto, 1993), (2) an independent decision module having linear integrator with threshold (see, e.
g.
, Lacouture & Marley, 1991, 1994), (3) number of iterations required to get from initial state to stabilized state (e.
g.
, Anderson, Silverstein, Ritz, & Jones, 1977; Masson, 1991, 1995), and (4) vector distance between initial and stable states (Sharkey, 1989).
 In particular, gradual propagation (McClelland, 1979, 1993) seems to come closest to implementing realtime dynamics.
 McClelland's models predict mean response times by assuming a nonlinear pattern of the time course of gradual activation through neural network layers.
 However, it is not clear how random time effects can be simulated using gradual activation, nor what aspect of neurophysiological mechanisms is responsible for the assumed nonlinear fiinction for the time pattern, particularly if one is to deem the neurophysiological plausibility as being important.
 This research seeks to provide a neurophysiologically motivated foundation for incorporating realtime random dynamic processing in neural networks.
 Many neural network models have utilized the mean firing rate (which contains information about the activation level of a neuron) as the basic metric of communication between neurons.
 The mean firing rate is, however, an unsatisfactory metric because it averages out the information related to the temporal pattern of firing (Gerstner et al.
, 1993; Pahn, Aertsen, & Gerstein, 1988).
 Accordingly, when Seidenberg & McClelland (1989) used mean square error as an indicator of mean response time based on the cascade model.
 472 mailto:kim.
315@osu.
edumailto:myung.
l@osu.
eduincorporating realtime dynamics into neural networks, it may be advisable to identify and utilize those firing mechanisms and metrics which are capable of reflecting temporal processing patterns.
 2.
 Temporal Summation of Neural Information Processing Neural firing results from the operation of two independent mechanisms: a spatial summation mechanism and a temporal summation mechanism (see Levitt, 1981; Arbib, 1989).
 A presynaptic neuron, once excited, sends out a train of random spikes to a postsynaptic neuron.
 The postsynaptic neuron accumulates spikes from different presynaptic neurons (i.
e.
, spatial summation) over time (i.
e.
, temporal summation) until activation from the presynaptic neurons exceeds a predetermined threshold, triggering a postsynaptic firing (see Figure 1).
 P 0 t e n t i a spike pcftential threshold Tenpa Surmati Time presynaptic spikes Figure 1.
 Pictorial depiction of temporal summation mechanism Spatial summation constitutes one of the basic building blocks in almost all neural network models, and has been widely utilized (Rumelhart & McClelland, 1986; Hopfield, 1982).
 Although the existence of the temporal summation mechanism is equally wellknown and established in neurophysiology, surprisingly little attention has been paid toward incorporating this mechanism in past neural network modeling.
 Accordingly, w e contend that the temporal summation mechanism may provide one way of implementing realtime dynamics into neural networks.
 W e will now review and summarize the formal description of temporal summation at the postsynaptic neuron as it relates to neural network modeling (for more details, see Ricciardi, 1977; Sato, 1978).
 A n input unit, once excited, sends out a timeseries of allornone spikes to the output units of a network.
 Let us assume that spikes, denoted by Si(t) = 0 or 1, are generated in input unit i via a Poisson process with parameter X (i.
e.
, the mean number of spikes during a given time interval is proportional to the time interval itself).
 A n output unit accumulates trains of spikes from different input units, weighted by the connection strength (Wy) between input unit i and output unit j.
 Specifically, leaky integration in temporal summation weakens the activation of an output unit when no spikes arrivesuch a leaky integration is commonly assumed in simulating a single neuron's activity (see, for instance, McKenna, Davis, & Zometzer, 1992).
 Formally, the change of activation in output unit j at time t (Anet/O) can be written as the following stochastic equation: rrt 1=1 t+ta Si{h)dh  \*mtj(t)*^ (1) Spatial Temporal Leakage Summation Summation Term where W,j ( > 0) is the connection weight between input unit i and output unit j, O/ represents the activity of input unit i, and ^ (> 0) is a leakage parameter.
 In principle, temporal summation can be applied to the modeling of any psychological phenomenon that involves the time course of processing.
 In the present study, with the view of exploring the psychological plausibility of the temporal summation mechanism, we have applied it to the semantic priming phenomenon.
 3.
 Simulating the Semantic Priming Effect 3.
1.
 The Neural Network To implement temporal summation, we constructed a feedforward, twolayer network with all input units (semantic feature units) being fully connected to output units (concept units).
 W e use a binary vector a = (a,, .
.
.
, a^), where â  = 1 (on) or 0 (off) to indicate the presence or absence of the ith semantic feature in an input stimulus (e.
g.
, "hasawing" for concept "BIRD").
 The output of the network is described by another binary vector b = (bj, .
.
.
, bn) where bj =1 (on) or 0 (off) indicates the concepttriggering response of the jth output unit (e.
g.
, "BIRD").
 The output bj, corresponding to concept j, is produced using the nonlinear threshold fiinction bj = f\netj{t)QY where netj(t) is the activation of unit j at time t, 9 is a threshold, and J{x) = 1 if x > 0 and 0 otherwise.
 As described in equation (1) above, net/t) is a random variable that changes over time according to the nonlinear stochastic process.
 The following form of Hebb's learning rule was 473 employed (cf.
 Hebb, 1949; Grossberg, 1987; Levy, 1982): MVi, =a»a»bjb»Wu (2) where a (>0) is the learning rate and 5 (>0) is a decay constant.
 The network was trained to learn concepts; each concept was defined by the corresponding prototype vector: / (y^, y j .
 y^herey>.
^P(ai = l\bi = l), (j = l n).
 For the purpose of the simulations, these prototype vectors were artificially generated.
 O n each training trial for a particular concept (say concept j), a binary vector is randomly generated from the prototype vector y' and presented to the network as an input while output unit bj remains turned on.
 Under these modeling assumptions, it can be readily shown that at equilibrium (i.
e.
, when E[AWjj] = 0), we have: E[W,j] = — P ( b j = l)P(a<= l\bj = 1) (see Clark & Ravishankar, 1990).
 In other words, a connection weight is determined by the product of the base rate of concept j (the prior probability of the output unit firing) and the conditional probability of existence of feature i given concept j.
 The network was trained for six randomly presented concepts over 12,000 training trials.
 The resulting weights were then used for subsequent simulations.
 3.
2.
 Response Time Response time in the network is defmed as the time lag between presentation of an input vector and the earliest firing of an output unit.
 From the characteristics of the temporal summation mechanism, four basic properties of the simulated response time patterns can be predicted for the network.
 First, response time will be probabilistic rather than deterministic owing to the random Poisson process assumption of temporal summation.
 Consequently, the network produces a response time distribution instead of simply the mean response time.
 In particular, the shape of the response time distribution will be positively skewed, a consequence of the accumulation of activation over time in the presence of a fixed threshold (Ratcliff, 1978).
 Second, note that leaky integration in the accumulation of activation in the network gives rise to nonlinearity in temporal summation.
 Although this nonlinearity is a common assumption of some random walk models (Ratcliff 1980; Smith, 1994), it may, in fact, be attributable to temporal summation of neural firing.
 This insight points to the benefit of giving due consideration to neurophysiological mechanisms in conjunction with mathematical modeling (e.
g.
.
 Link, 1992).
 Third, exploiting the properties of the Hebbian learning rule, it can be formally shown that the response time is determined by similarity between an input feature vector and a prototype concept vector.
 Defining similarity, s(a, y), as a dot product between an input feature vector a and a prototype concept vector y, we derived the mean drift rate of activation of the corresponding output unit given the input vector.
 The mean drift rate is proportional to the similarity between the two vectors.
 This implies that greater similarity of an input vector to a stored prototype vector will elicit a faster response in the corresponding output unit.
 This relation between similarity and response time will be demonstrated in the following section which reports our simulation results of semantic priming effects.
 Finally, as the threshold (9) of the network is varied, the response time changes.
 Manipulating this threshold will lead to speedaccuracy tradeoffs (i.
e.
, reciprocity between response time and error rate).
 Speedaccuracy tradeoffs have been a common empirical fmding in cognitive studies (see, Wickelgren, 1977, for a review).
 Simulations of our network have confirmed all four predictions regarding the characteristic patterns of response times.
 3.
3.
 Semantic Priming in the Network A typical study of semantic priming in experimental psychology consists of two conditions: a control condition and a priming condition.
 In the control condition, a target word (e.
g.
, "NURSE") follows a semanticallyunrelated word (such as "TREE"), presented for a fixed duration.
 In the priming condition, the same target word ("NURSE") follows a semanticallyrelated prime word (such as "DOCTOR").
 The subjects' task is to identify the target word as quickly as possible.
 As might be expected, an abundance of studies have documented that response times under the priming condition are shorter compared to the control condition (for reviews, see Meyer & Schvaneveldt, 1971; Neely, 1991).
 In particular, the greater the semantic similarity between the prime and target, the greater the priming effect.
 Another important fmding is that as the stimulusonsetasynchrony (denoted by Tsoa) between prime and target increases, the semantic priming effect increases and eventually reaches an asymptote level, which depends on semantic similarity between prime and target (Lorch, 1982; Ratcliff & McKoon, 1981).
 In the present network, simulation of the semantic priming effect was carried out by successively presenting two input vectors (one pertaining to the prime and another to the target) and recording the response time of the output unit corresponding to the target vector.
 All the data acquired from the following simulations are based on 1,000 simulation trials.
 Specifically, let the three input vectors ^CT^ a*""̂, and a °  denote the control, prime, and target vectors, respectively.
 As mentioned earlier, each element of the binary "target" vector a ™ is generated probabilistically from a prototype vector, say y*.
 By defining the control and 474 c o (0 > < Control Priming Period Threshold / ' L / ^ ^, , Con dition Targel Period RTcT ^ C ^ • P r i m i n g C o n d i t i o n I'ririuiig Period Threshold Targel Period RT PM Doctor Nurse Time Time Figure 2.
 The time course of activation for the control and priming conditions priming conditions as above, the similarity between a prime vector and the prototype vector corresponding to a target output, s(a , y') is greater for the priming condition than s(a , y') for the control condition.
 The following diagram summarizes presentation sequences under the two simulation conditions: Priming period (0<t<TsoA) Control condition: T R E E (a") Priming condition: DOCTOR(a'''^) Target period (t>TsoA) ^ N U R S E (a'̂ °) ^ N U R S E (a^^) Some typical patterns of activation in the output units are shown in Figure 2.
 A comparison of the activation patterns in the first part (priming period) of the two panels in the figure reveals different levels of preactivation of the target output unit ("NURSE") between control and priming conditions.
 During the priming period, owing to greater similarity, the preactivation of a target output unit in the priming condition increases faster than in the control condition.
 Next, in the target period, when the target word a is presented to the network at time t=TsoA.
 the activation starts to increase from the preactivated level.
 Because a target output unit has a higher preactivation level in the priming condition than in the control condition, the target output unit activation in the priming condition reaches the threshold faster, thus producing a shorter response time.
 Further, the size of the semantic priming effect is directly related to the semantic similarity between a prime and target.
 Formally, one can readily derive the following equation for RT^ describing the relation between response time and similarity for both simulation conditions [q = C T (control) or P M (priming) ]: RTa = iln TG p£[Mb(a'^,/) s{»\f) (lê '*'̂ ] _ p5 ?"»P £[/).
]5(a^° ,yOe+e (3) where P is equal to Xa/^8, 9 is the response threshold, and e is timedependent random noise with zero mean.
 Note that from the above equation, w e have mean RTct > mean RTp^, since s(a", y') < s(a'''̂ , y^).
 Figure 3 shows the influence of varying the S O A on the semantic priming effect.
 That is, as the S O A increases, the priming effect initially increases and then approaches an asymptote level.
 This pattern of our results closely approximates empirical findings (Lorch, 1982; Ratcliff & McKoon, 1981).
 It is noteworthy that this asymptotic c o .
 Control Priming 0 Figure 3.
 Priming effects as a fiinction of StimulusOnset Asynchrony (vertical error bars depict 9 9 % confidence intervals) 475 pattern of the priming effect is a direct consequence of the assumed leaky integration process.
 4.
 Summary and Conclusion The main goal of the present investigation was to design a neural network that reflects random time effects in human information processing.
 In particular, we have proposed a temporal summation mechanism inspired by the physiology of neural firing.
 As an application of this mechanism, we have demonstrated that a neural network implementing temporal summation can successfully simulate response time data, in particular, the "semantic priming effect" in human cognition.
 These results suggest that the temporal summation mechanism may be a promising candidate for implementing realtime dynamics into neural networks.
 By producing temporal activation patterns that are similar to those produced by gradual activation, the present study further develops and extends McClelland's cascade and G R A I N models (McClelland, 1979, 1993).
 However, this extension is accomplished, not by resorting to ftirther mathematical sophistication, but by making use of the neurophysiologically grounded temporal summation mechanism.
 W e believe that this implementation is an important advance because it represents a natural and logical extension to current modeling of realtime random dynamics in neural networks.
 In conclusion, by featuring the proposed temporal summation mechanism, the present study has opened up a new avenue for simulating random time effects in neural networks.
 Introducing this mechanism into neural network modeling is likely to enhance our understanding of human cognition by permitting both a psychological and neurophysiological treatment of the time dimension.
 Acknowledgments We would like to acknowledge the insightful comments and suggestions of Sridhar Ramamoorti and Krishna Tateneni on earlier versions of this manuscript.
 References Anderson, J.
 A.
, Silverstein, J.
 W.
, Ritz, S.
 A.
, & Jones, R.
 S.
 (1977).
 Distinctive features, categorical perception, and probability learning: Some applications of a neural model.
 Psychological Review, 54,413451.
 Arbib, M.
 A.
 (1989).
 The Metaphorical Brain 2.
 N e w York: John Wiley & Sons.
 Bialek, W.
, Rieke, F.
, de Ruyter van Steveninck, R.
 R.
, & Warland, D.
 (1991).
 Reading a neural code.
 Science, 252, 18541856.
 Cohen, J.
 D.
, Dunbar, K.
, & McClelland, J.
 L.
 (1990).
 O n the control of automatic processes: A parallel distributed processing account of the Stroop effect.
 Psychological Review.
 97,332361.
 Clark, D.
 M.
 & Ravishankar, K.
 (1990).
 A convergence theorem for Grossberg learning.
 Neural Networks, 3, 8792.
 Gerstner, W.
, Riz, R.
, & van Hemmen, J.
 L.
 (1993).
 A biologically motivated and analytically soluble model of collective oscillations in the cortex.
 Biological Cybernetics, 68, 363374.
 Grossberg, S.
 (1987).
 Competitive learning: From interactive activation to adaptive resonance.
 Cognitive Science, 11, 121134.
 Hebb, D.
 O.
 (1949).
 The Organization of Behavior.
 N.
Y.
 : Willey.
 Hopfield, J.
 J.
 (1982).
 Neural networks and physical systems with emergent collective computational abilities.
 Proceedings of the National Academy of Sciences, USA, 79, 25542558.
 Kawamoto, A.
 H.
 (1993).
 Timecourse of processing in feedforward connectionist networks: A n analysis of the exclusiveor problem.
 Journal of Mathematical Psychology, 37, 556574.
 Lacouture, Y.
 & Marley, A.
 A.
 J.
 (1991).
 A connectionist model of choice and reaction time in absolute identification.
 Connection Science, 3,401433.
 Lacouture, Y.
 & Marley, A.
 A.
 J.
 (1994).
 A mapping model of bow effects in absolute identification.
 Manuscript submitted for publication.
 Levitt.
, R.
 A.
 (1981).
 Physiological Psychology.
 N e w York: Holt, Rinehart and Winston.
 Levy, W .
 B.
 (1982).
 Associative encoding at synapses.
 In Proceedings of the Fourth Annual Conference of the Cognitive Science Society (pp.
 135136).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Link, S.
 W .
 (1975).
 The relative judgment theory of two choice response time.
 Journal of Mathematical Psychology, 12, 114135.
 Link, S.
 W .
 (1992).
 The Wave Theory of Difference and Similarity.
 Hillsdale, N.
J.
: Lawrence Erlbaum Associates.
 Lorch, R.
 F.
, Jr.
 (1982).
 Priming and search processes in semantic memory: A test of three models of spreading activation.
 Journal of Verbal Learning and Verbal Behavior, 21, 468492.
 Luce, R.
 D.
 (1986).
 Response Times.
 N e w York: Oxford University Press.
 Marr, D.
 (1982).
 Vision.
 San Francisco: W .
 H.
 Freeman & Company.
 Massaro, D.
 W .
 & Cowman, N.
 (1993).
 Information processing models: Microscopes of the mind.
 Annual Review of Psychology, 44, 383425.
 Masson, M.
 E.
 J.
 (1991).
 A distributed memory model of context effects in word identification.
 In D.
 Besner and G.
 W .
 Humphreys (Eds.
), Basic Processes in Reading: Visual Word Recognition.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Masson, M.
 E.
 J.
 (1995).
 A distributed memory model of semantic priming.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 21,323.
 476 McClelland, J.
 L.
 (1979).
 O n the time relations of mental processes: A n examination of systems of processes in cascade.
 Psychological Review, 86, 287330.
 McClelland, J.
 L.
 (1993).
 Toward a theory of information processing in graded, random, and interactive networks.
 In D.
 E.
 Meyer & S.
 Komblum (Eds.
).
 Attention and Performance XIV.
 Cambridge, M A : M I T press.
 McKenna, T.
, Davis, J.
, & Zometzer, S.
 F.
 (1992).
 Single Neuron Computation.
 Boston, NJ : Academic Press.
 Meyer, D.
 E.
, & Schvaneveldt, R.
 W .
 (1971).
 Facilitation in recognizing pairs of words: Evidence of a dependence between retrieval operations.
 Journal of Experimental Psychology.
 90, 227234.
 Neely, J.
 H.
 (1991).
 Semantic priming effect in visual word recognition: A selective review of current fmdings and theories.
 In D.
 Besner and G.
 W .
 Humphreys (Eds.
), Basic Processes in Reading: Visual Word Recognition.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Palm, G.
, Aertsen, A.
 M .
 H.
 J.
, & Gerstein, G.
 L.
 (1988).
 On the significance of correlations among neuronal spike trains, Biological Cybernetics, 59, 111.
 Ratcliff, R.
 (1978).
 A theory of memory retrieval.
 Psychological Review, 85, 59108.
 Ratcliff, R.
 (1980).
 A note on modeling accumulation of information when the rate of accumulation changes over time.
 Journal of Mathematical Psychology, 21, 178184.
 Ratcliff, R.
 & McKoon, G.
 (1981).
 Does activation really spread? Psychological Review, 88, 454462.
 Ricciardi, L.
 M.
 (1977).
 Diffiision Processes and Related Topics in Biology, Lecture Notes in Biomathematics, Vol.
 14.
 Berlin: SpringerVerlag.
 Rumelhart.
 D.
 E.
, & McClelland, J.
 L.
, (1986).
 Parallel Distributed Processing, Vol 1 & 2.
 Cambridge, M A : M I T Press.
 Sato, S.
 (1977).
 Evaluation of the firstpassage time probability to a square root boundary for the Wiener ^xocQss.
 Journal of Applied Probability, 14, 850856.
 Seidenberg, M.
 S.
, & McClelland, J.
 L.
 (1989).
 A distributed developmental model of word recognition and naming.
 Psychological Review, 96, 523568.
 Sharkey, A.
 J.
 C.
 (1989).
 The lexical distance model and word priming.
 In Proceedings of Eleventh Annual Cognitive Science Society Meeting (pp.
 860867).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Smith, P.
 L.
 (1994).
 Multiple detector models of visual simple reaction time.
 Unpublished manuscript.
 Wickelgren W .
 A.
 (1977).
 Speedaccuracy tradeoff and information processing dynamics.
 Acta Psychologica, 41, 6785.
 477 T w o Layer Digital R A A M Alan D.
 Blair Dept.
 of Computer Science Volen Center for Complex Systems Brandeis University Waltham, M A 022549110 b l a i r @ c s .
 b r a n d e i s .
 e d u Abstract We present modifications to Recursive AutoAssociative Memory which increase its robustness and storage capacity.
 This is done by introducing an extra layer to the compressor and reconstructor networks, employing integer rather than realvalued representations, preconditioning the weights and presetting the representations to be compatible with them, and using a quickprop modification.
 Initial studies have shown this method to be reliable for data sets with up to three hundred subtrees.
 Review of R A A M Recursive AutoAssociative Memory or RAAM (Pollack, 1990) is a method for storing tree structures in a feed forward network.
 It's architecture is very similar to that of encoder networks (Ackley, Hinton & Sejnowski, 1985, Cottrell, Munro & Zipser, 1987), consisting of a compressor unit and a reconstructor unit.
 The principal difference is that in a R A A M the compressor and reconstructor are used recursively to encode and decode, respectively.
 Introduction In the late 1980's a number of new connectionist models were developed in response to criticisms (e.
g.
 Fodor & Pylyshyn, 1988) that connectionism lacked the flexibility and representational adequacy needed for higher level cognitive tasks.
 Chief among these were coarse coding (Touretzky, 1986), tensor based representation (Smolensky, 1990), reduced representations (Hinton, McClelland & Rumelhart, 1986), and R A A M (Pollack, 1990).
 Compared to earlier systems, they had the advantage of compositionality built more explicitly into their design, and they have shown a great deal of promise in a number of areas (Chalmers, 1990, Plate, 1994).
 However, all of them typically run into difficulties when the structures involved are scaled up to a level of complexity commensurate with real world problems.
 In this paper, we describe a number of modifications to the R A A M architecture designed to address some of these inadequacies, and examine the feasibility of storing large, complex data structures within a connectionist system.
 2d O U T P U T UNITS RECONSTRU( LEFT [HOR CO M P R E S S O R \ RIGHT 1 / WHOLE / LEFT \ RIGHT d HIDDEN UNITS 2d INPUT UNITS Figure 1.
 R A A M architecture  a single network composed of a compressor and a reconstructor F G \ / a / \ F G E a \ / b / \ E a Figure 2.
 A simple tree and the autoassociations that encode it in a RAAM.
 Figure 2 shows how a RAAM encodes the tree (E (F G)).
 First we feed (F G ) into the compressor network, giving output a.
 Then we feed in (E a), giving b.
 To decode, we feed b into the reconstructor network, giving (E a).
 At that point we need some kind of 'terminal test' to tell us that E, F & G are terminals (requiring no further decoding), while a is a nonterminal that must be fed again into the reconstructor giving (F G).
 Several trees may be stored in the same R A A M at once.
 In what follows, we shall measure the complexity of a data set by the number n of subtrees or 'autoassociations' required to encode it.
 In the above example n = 2.
 Modifications to RAAM Hidden layers We enlarge the compressor and reconstructor networks to two layers each as shown in Figure 3, in order to increase the number of functions computable by the network.
 478 mailto:blair@cs.
brandeis.
eduw \ / R \ / <3 / \ B d UNITS (EACH) d + e UNITS (EACH) d UNITS 2d UNITS d UNITS (EACH) Figure 3.
 Architecture for Two Layer RAAM.
 Digital outputs One problem with R A A M is that, since the representations are allowed to take on noninteger values, greater accuracy is required as the depth of the trees increases, in order to prevent accumulation of roundoff errors.
 W e modify the network so that each output must take on a discrete value (11 or  1 ) , thus allowing larger structures to be stored in a noise tolerant fashion.
 This is done by using a threshold function 0 at the second layer of the compressor and reconstructor networks, while a hyperbolic tangent is used at the hidden layers: Xi = Wi = Zi = j=l fc=l Preconditioned weights It is well known that the success of neural network training using backpropagation is sensitive to the initial weight configuration (Kolen & Pollack, 1990).
 The complete randomness of the initial representations and weights becomes a significant problem as R A A M s are scaled up.
 To increase the likelihood of convergence, w e adopt the following strategy for choosing the initial weights: First, randomly choose two signed permutation matrices P q and Qo.
 For example, if d = 4, w e m a y have Po = 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 Qo = 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 Once Po and Qo are chosen, we assign the initial weights for the reconstructors as follows:   2 )=\ *=i d+e d 0 (Lio + Y .
 ̂ 'J tanh(P,o + Y .
 Pjk^k)) i=\ fc=i d+e d 0 (i?io + Y '̂i tanh(Q,o + Y QikXk)) Po 0 ^  \ Qo 0 L = R = d n 0 where 1(d) is the (d x d) identity matrix, and 0 denotes a zero matrix of the appropriate dimensions.
 In other words, the first d nodes of the hidden layer are connected in a 1tol fashion with those of the input and output layers by connections with synaptic strength d~', in such a way that the connections to the output layer are componentwise and excitatory, while those to the input layer are randomly assigned and may be excitatory or inhibitory.
 The remaining e nodes are connected componentwise to the first e nodes of the output layer by weaker excitatory links with strength n~' (where n is the number of subtrees to be stored).
 All other connections are initially set to zero.
 Each layer also has bias inputs, which are also initialized to zero.
 The initial compressor network is wired thus: A = P' 0 B = 0 Q'  ^ [ 1(d) 1(d) P' and Q' denote the transpose of P and Q.
 This setup has the following advantages: (a) the initial compressor is a left inverse for the initial reconstructor, (b) it produces compressors and reconstructors with much longer transients than would be the case with random initial weights, thus allowing the network to store trees of greater depth.
 Initial representations In single layer R A A M , nonterminal representations are determined by the network as an artifact of the training.
 This approach has the disadvantage that two or more representations may become fused in the course of the training (Angeline, 1992).
 The fusion problem gets more pronounced as the number of nodes increases, and is even more prevalent when the representations become digital.
 W e circumvent this difficulty by assigning the representations at the outset, in a way that is compatible with the initial weights.
 To see how this is done, consider our earlier example: F G N o w imagine a linearized version of the problem, in which the compressor and reconstructors are effected by (linear) matrix multiplications, rather than twolayer neural networks.
 In fact the initial weights as defined above do just that, using the matrices [ P g Q q ], P o & Qo respectively.
 N o w suppose w e assign a random representation to the root node b.
 For 479 instance, we could assign W e instead take x{b) = 1 1 1 1 Then it would be natural to use our initial (linearized) reconstructors Pq & Q o to determine representations for the other nodes, putting x(E) = Po.
x(6) = x(F) = Po.
x(a) = x(a) = Qo.
x(6) = x(G) = Qo.
x(a) = 1 1 1 1 1 1 1 1 This is the strategy we follow in general, with the following provisos: (a) In general there will be several trees in the data set, and we assign a random representation to each root node.
 (b) The above example is particularly simple because each terminal appears only once.
 In general a typical terminal or subtree will appear several times throughout the data set, and the above procedure will generate multiple representations for it.
 W e extract a single representation from this multitude by first computing their average, then rounding off each unit to + 1 or — 1, depending on its sign.
 (c) It may happen that two nodes end up having exacdy the same representation.
 In this case, we must select P q and Q o anew, and repeat the above procedure, choosing different representations for the root nodes.
 In order to estimate the probability of this problem arising, note that the total number of available representations is 2''.
 Suppose the number of terminals and subtrees to be represented is A'̂ , and choose d large enough that 2"* > A'̂ .
̂ If each representation were chosen at random (which is not strictly the case, but is probably a 'reasonable' assumption), the probability of them all being distinct would be n(i]^) > 1^"' >o.
6 t=0 So, by repeating this procedure a couple of times if necessary, we should soon satisfy the requirement that all representations be distinct.
 Backprop modification Since the representations are chosen in advance of training, the compressor and reconstructor networks may be trained separately.
 Training proceeds using backpropagation (Rumelhart, Hinton & Williams, 1986), with the following modification similar to Quickprop (Fahlman, 1989): In the usual backpropagation algorithm, the value of 'delta' propagated back through the network from the output layer is 6i = {l ZiU){UZi) Such a choice of S prevents individual outputs from getting trapped into a flat region on the wrong side of zero, by putting more emphasis on learning the correct sign for the outputs, and less on their exact numerical values.
 At the conclusion of training, the transfer function in the output layer is changed from a hyperbolic tangent to a threshold function.
 In view of this, the network may be said to have successfully learned the training set once the maximum error across all units of all outputs is less than 1.
0.
 However it is prudent to allow some safety margin, and in the trials described below we continued to train until the maximum error was less than 0.
6.
 The learning rate must be very small in order to ensure convergence.
 After some preliminary trials, we settled on a learning rate of (nd)~' for the reconstructors and (2nd)~' for the compressor.
 Parallel training Parallelization of the training set provides a significant speedup to backpropagation (Blelloch & Rosenberg, 1987).
 By removing dependencies from the original R A A M training regimen and parallelizing the algorithm on a 4096 processor Maspar M P 2 , we were able to run large scale experiments with full parallelization over the training sets.
 Data W e tested our methods on four different data sets, each consisting of parse trees for a collection of English sentences.
 Table 1 provides a summary, showing the number of trees in each data set, their average depth, and the total number of subtrees.
 Table 1.
 Summary of Data.
 Data Set 1 2 3 4 No.
 Trees 7 4 48 37 Avg.
 Depth 3.
1 8.
8 5.
7 8.
4 No.
 Subtrees 15 45 169 307 Data Set (1) is from (Pollack, 1990).
 Data Set (3) was taken from an introductory text on Syntactic Theory (Cowper, 1992).
 Data Sets (2) and (4) were extracted from a small fragment of the University of Pennsylvania Tree Bank '.
 The full data sets are available through the World Wide Web ̂ .
 Here is an example of a 'typical' tree from each data set: l.
((DN)(V(D(AN)))) 2.
 (S(NP(S(VP(P((NP(P NP))NP))))))(NP(VP(NP(P(NP NP))))) 3.
 ((NP(I(V(C(NP(I VP))))))(CONJ(NP(I VP)))) 4.
 (ADJP(( VP(NP NP))((NP(S( VP NP)))(S(NP(S( VP(NP(P NP))))))))) We took the liberty of slightly modifying the trees to make them binary  since our purpose was not to get syntactic details right, but simply to test how well our scheme could cope with the kinds of structures that typically arise in linguistic applications.
 Si = ^ .
 { t i  z i ) = (1  ZiZ,){ti  z,) Zi = tanh(rt) ti — target value for Zi 'ftp://ftp.
cis.
upenn.
 edu/pub/treebank/doc/* ĥttp://www.
cs.
brandeis.
edu/~blair/home.
html 480 ftp://ftp.
cis.
upennhttp://www.
cs.
brandeis.
edu/~blair/home.
htmlResults The results are shown in Table 2, where n is the number of subtrees, d is the dimension of the representations, r is the number of 'extra' units in the hidden layer of the rcconstructors, m = {5d + 2e + l)(2d + 1)  1 is the total number of connections in the network, and (enc.
 îcfi & 'nghi are the number of epochs to convergence for the compressor and the left and right reconstructors, respectively.
 Table 2.
 Summary of Results.
 n 15 45 169 307 d 9 12 16 17 e 0 0 8 17 m 873 1524 3200 4199 m/n 58.
2 33.
9 18.
9 13.
7 'enc 250 800 1,800 16,700 t\efl 100 1,100 11,000 42,800 bright 150 900 7,500 31,500 For large data sets, the compressor converged faster than the reconstructors  presumably due to the larger n u m b e r of connections in the compressor network  and the right reconstructor converged faster than the left one.
 This is probably due to the fact that parse trees tend to be leftbranching (in English), and the resulting "manytoone* nature of the left m a p m a k e s it harder to learn.
 Unfortunately, the system shows little or no capacity for generalization.
 Careful analysis of the compressor and reconstructors trained on the above data sets reveals that they were unable to store and retrieve any trees that were not explicitly in the data set.
 This tradeoff between storage capacity and ability to generalize presumably c o m e s about because of the way w e train the compressor and reconstructors separately, and assign the subtree representations in advance, instead of letting them be determined by the network in the course of its training.
 Conclusion These results show that twolayer digital R A A M can be used to reliably find representations for sets of binary trees of a size and complexity that would confound ordinary R A A M and most other connectionist representation systems.
 These advantages come from stronger constraints on the initial weights and the actual representations of the nonterminals, at the expense of generalization ability.
 Further work on how to preserve generalization while expanding capacity is certainly called for.
 Acknowledgments The author wishes to thank Jordan Pollack for many helpful comments and suggestions.
 This research was funded by a Krasnow Foundation Postdoctoral Fellowship, and by O N R grant NOOO14950173.
 References Ackley, D.
H.
, Hinton, G.
E.
 & Sejnowski, T.
J.
 1985.
 A learning algorithm for Boltzman Machines, Cognitive Science 9, 147169.
 Angeline, P.
J.
 1992.
 Avoiding fusion in floating symbol systems.
 Tech.
 Report 92PAFUSION, Computer Science Dept.
, Ohio State University.
 Blelloch, G.
, Rosenberg, C.
R.
 1987.
 Network learning on the Connection Machine, Proceedings Tenth International Joint Conference on Artificial Intelligence, Milan, Italy.
 Chalmers, D.
J.
 1990.
 Syntactic transformations on distributed representations.
 Connection Science 2(12), 5362.
 Cottrell, G.
, Munro, R, & Zipser, D.
 1987.
 Learning internal representations from grayscale images; An example of extensional programming, Proceedings Ninth Annual Conference of the Cognitive Science Society, Seattle, W A , 461^73.
 Cowper, E.
A.
 1992.
 A Concise Introduction to Syntactic Theory (University of Chicago Press, Chicago, IL).
 Fahlman, S.
E.
 1989.
 Fastlearning variations on backpropagation: an empirical study.
 In D.
 Touretzky, G.
 Hinton & T.
 Sejnowski, eds.
 Proceedings of the 1988 Connectionist Models Summer School, Pittsburgh, PA, 3851 (Morgan Kaufman, San Mateo).
 Fodor, J.
A.
, Pylyshyn, Z.
W.
 1988.
 Connectionism and cognitive architecture: a critical analysis.
 Cognition 28, 371.
 Hinton, G.
E.
, McClelland, J.
L.
, Rumelhart, D.
E.
 1986.
 Distributed Representations.
 In D.
E.
 Rumelhart, J.
L.
 McClelland and the P D P Research Group, eds.
 Parallel Distributed Processing: Experiments in the Micrestructure of Cognition 1: Foundations (MIT Press, Cambridge, M A ) .
 Kolen, J.
, Pollack, J.
B.
 1990.
 Back propagation is sensitive to initial conditions.
 Complex Systems 4, 269280.
 Plate, T.
A.
 1994.
 Distributed Representations and Nested Compositional Structure, Ph.
D.
 Thesis, University of Toronto.
 Pollack, J.
B.
 1990.
 Recursive Distributed Representations, Artificial Intelligence 46(1), 77105.
 Rumelhart, D.
E.
, Hinton, G.
E.
 & Williams, R.
J.
 1986.
 Learning representation by backpropagating errors.
 Nature 323, 533536.
 Smolensky, P.
 1990.
 Tensor product variable binding and the representation of symbolic structures in a connectionist system.
 Artificial Intelligence 46(12), 159216.
 Touretzky, D.
S.
 1986.
 BoltzCONS: Reconciling connectionism with the recursive nature of stacks and trees.
 Proceedings Eighth Annual conference of the Cognitive Science Society (Erlbaum, Hillsdale, NJ).
 481 L e a r n i n g to c o u n t w i t h o u t a counter: A case s t u dy of d y n a m i c s a n d activation landscapes in recurrent n e t w o r k s Janet Wiles Departments of Computer Science and Psychology University of Queensland Queensland 4072, Australia janetwics.
uq.
oz.
au JeffElman Department of Cognitive Science, 0515 University of California, San Diego La Jolla, California 920930515 elman@cogsci.
ucsd.
edu Abstract The broad context of this study is the investigation of the nature of computation in recurrent networks (RNs).
 The current study has two parts.
 The first is to show that a R N can solve a problem that we take to be of interest (a counting task), and the second is to use the solution as a platform for developing a more general understanding of RNs as computational mechanisms.
 W e begin by presenting the empirical results of training RNs on the counting task.
 The task {a b ) is the simplest possible grammar that requires a P D A or counter A R N was trained to predict the deterministic elements in sequences of the form a"b" * where n=l to 12.
 After training, it generalized to n=18.
 Contrary to our expectations, on analyzing the hidden unit dynamics, we find no evidence of units acting like counters.
 Instead, we find an oscillator W e then explore the possible range of behaviors of oscillators using iterated maps and in the second part of the paper we describe the use of iterated maps for understanding R N mechanisms in terms of "activation landscapes".
 This analysis leads to used an understanding of the behavior of network generated in the simulation study.
 Introduction It is common to view the brain as a computer.
 But the real question is.
 What sort of computer might the brain be? One reasonable assumption is that the functionally, brain computation can be understood within the framework of discrete finite automata (DFA).
 One can then use the Chomsky Hierarchy as a tool for inferentially classifying the computational power of the brain.
 If brains produce behaviors which fall entirely within the realm of contextfree grammars, for example, w e might suppose that the brain is the computational equivalent of a Linear Bounded Automata (since this class of machines is both necessary and sufficient for the generation and recognition of such languages).
 In reality, however, formal analysis of behavior does not suggest that such a neat typing will be possible.
 Furthermore, in the past decade, it has been suggested that the brain may not be best modeled as a type of D F A , but rather as a continuous analog automaton of the sort represented by neural networks.
 This possibility then raises the question.
 What sort of computers are neural networks? Attempts to answer this question generally attempt either to probe capacity through empirical experimentation (e.
g.
, of the sort reported in Cleeremans, ServanSchreiber, & McClelland, 1989; Elman, 1991; Giles, Miller, Chen, Chen, Sun, & Lee, 1992; Manolios & Fanelli, 1994; Watrous & Kuhn, 1992) or else to establish theoretical capacity through formal analysis (Kolen, 1994; Pollack, 1991; Seligmann & Sontag, 1992).
 Lacking in much of this work, however, has been a closegrained analysis of the precise mechanisms which can be employed by neural networks in the service of specific computational tasks.
 Elman (1991), for example, demonstrates the abiUty of a recurrent network to emulate certain aspects of a pushdown automaton (namely, to process recursively embedded structures to a limited depth); the analysis of this network suggests that the network partitions the hidden unit state space to represent grammatical categories and depth of embedding.
 The network weights then implement a dynamics which allow the network to move through this state space in a rulefollowing manner which is consistent with the contextfree grammar that produces the input strings.
 This analysis is suggestive at best, however, and leaves many important questions unanswered.
 H o w does the R N solution compare with that of a stack in terms of processing capacity? Are the solutions functionally exactly equivalent or are there differences? Are these differences relevant to understanding cognitive behaviors? If R N s are dynamical systems, then how can dynamics be employed to carry out specific computational tasks? Our goal in the project which this work initiates is to redress this failing.
 W e wish to investigate the nature of computation in recurrent networks by discovering the detailed mechanisms which are employed to carry out specific computational requirements.
 The strategy is first to tiain a recurrent network to produce a behavior which is of a priori interest, and which has known a computational solution within the realm of DFA.
 W e then analyze the recurrent network to discover whether the solution is 482 http://uq.
oz.
aumailto:elman@cogsci.
ucsd.
eduequivalent to that of the D F A or whether it is different.
 If the solution is different, the question then becomes whether the solution is more or less likely to provide insight into the computational mechanisms employed by the brain in the service of cognitive behaviors.
 Simulation The work of Giles and colleagues has demonstrated that recurrent networks (RNs) can provide reasonable approximations of the simplest class of DFAs: Finite State Automata (FSA).
 The network solution appears to involve an instantiation of the state space required by the FSA, although there are interesting and possibly useful differences.
 (For example, path information tends to be saved—gratuitously—in the R N , and the R N state space probably has an intrinsic semantics whereas the topology of the F S A is, aside from the state transitions, undefined.
) Our interest is therefore in exploring behaviors which require the next highest category of DFA, namely contextfree languages.
 These require a form of pushdown automaton known as a Linear Bounded Automaton.
 Task and stimuli One of the simplest CF languages one can devise is the language a"/?"; that is, the language consisting of strings of some number of as followed by the same number ofbs.
 This language requires a pushdown store in order to keep track of the as in order that each a may be matched by a later b.
 In reality, though, the full power of the store is not really essential.
 All that is required is a counter.
 W e generated a training set consisting of 356 strings, containing a total of 2,298 tokens of a and b.
 These strings conformed to the form a"b", with n ranging from 1 to 11 (meaning strength length varied from 2 to 22).
 Length was biased toward shorter strings (e.
g.
, there were 129 strings of depth 1 and 7of depth 11).
 A separate set of test stimuli were generated which consisted of all possible strings with n ranging from 1 to 30 so that we might test generalization to depths greater than that encountered during training.
 The network's task was to take a symbol as its input and to predict the next input.
 Successful performance would require that the network predict an initial a (since all strings begin with this token); the network should then predict aoT b with equiprobability until the first b is encountered.
 The network should then predict b for n timesteps, where n equals the number of as that were input.
 Following that, the network should then predict an a to indicate the end of the old string and beginning of the next string.
 Network and training 20 recurrent networks of the form show in Figure 1 was used.
 There were two input units (representing the two Output units Hidden units Input units Figure 1: Network architecture possible inputs, a and b) and two output units (representing the network's predictions for the next inputs).
 T w o hidden units were connected with full recurrence.
 Networks were initialized with different random weights.
 Networks was trained using back propagation through time (for 8 time steps).
 Training was carried out for a total of 3 miUion inputs.
 Results The networks' performance was evaluated using the test data in which all strings from depth 1 to 30 were present.
 Testing was carried out following 1, 2, and 3 million training cycles.
 After 1 million training cycles 9 of the networks learned the language a"b" for «  7 .
 One network generalized to «=11.
 The other networks learned the language a b .
 This is the language consisting of any number of as followed by any number of bs; in this case the network simply predicts its input.
 After 2 million training cycles, 4 of the 20 networks generalized the correct language to n=l2.
 One network generalized to n=18.
 Remaining networks had learned ab*.
 After 3 million training cycles, no networks were successful for n>ll.
 Those networks which had exhibited generalization at earlier stages of learning lost their solution and in many cases reverted to a b .
 Subsequent replications on additional groups of 20 networks yield essentially the same statistics, including at least one network which generalizes to approximately a depth of 18.
 W e therefore focus on this network for analysis.
 Analysis: Part I Our first conjecture was that the network might have solved this task by employing one or both of its hidden units as counters.
 This would be indicated by that hidden 483 unit's activation function changing (e.
g.
, increasing) as a monotonic function of the number of a inputs.
 The magnitude of the final activation state of the unit would therefore encode n.
 However, when we plotted the hidden unit activations as a function of input we saw nothing which resembled a counter.
 Instead, to our surprise, we found both units oscillating in activation value over time (but not in synchrony).
 W e took this as prima facie evidence that the counter hypothesis was falsified and then attempted to construct another hypothesis.
 This involved stepping back and considering in more general terms what sorts of dynamical behaviors might be generated in recurrent networks under very limiting conditions.
 Dynamics in recurrent networks Let us consider a simpler version of the network used in the simulation; this network will have two inputs, two outputs, a bias, and a single hidden unit with a selfrecurrent connection.
 This network is shown in Figure 2.
 fixed point Oa Ob \ ia ib Figure 2: Network used in analysis We are interested in the dynamics of the hidden unit, h, under various conditions.
 This unit has several sources of input: input tokens, bias, and selfrecurrence.
 W e begin by recognizing that when die input is held constant (as when the network is processing a string of as which it has to count), then the only thing which changes is die selfrecurrent excitation.
 W e can therefore subsume all other inputs under a bias term: netinput = bias + i^ŵ  + if̂ Wy + /i (f  1) w netinput = b + h(i^)w The activation function for this unit is then ''̂ '̂  " j_^^(wA(rl)+fc) If we let w= 10 and Z>=5 then we observe the unit has the properties shown in Figure 3.
 The unit has 3 fixed points.
 Thus, over time, if we begin with h(0) greater than 0.
5, we see the movement in activation space shown in Figure 4.
 fixed point fixed p o m h(t) Figure 3: Dynamical properties of network shown in Figure 2, with w=10 and b=5 ti(2) h(3) 0.
8 Q 0.
6 0.
2 Figure 4: Convergence properties of network in Figure 2 Suppose the sign of the selfrecurrent weight is negative.
 In effect, this flips the activation function and changes the convergence properties.
 W e now find that we have fixed points as before, but we oscillate back and forth above and below the middle fixed point.
 Depending on the steepness of the slope and our initial value, we either diverge out or converge inward.
 This is shown in Figure 5.
 Finally, we note that if we could change the slope of the hidden unit's activation function dynamically (i.
e.
, during processing), then we could produce two regimes, e.
g.
, first converging and then diverging.
 This is shown in Figure 6.
 W e now ask how such behavior might be useful to us? 484 h(t) Converging + Si h(t) Diverging Figure 5: Oscillating behavior found with negative selfrecurrent weight.
 In Figure 6 we see the activation function of the single hidden unit in the network in Figure 2, first when the slope is shifted to the left, and then when the activation function is shifted to the right.
 In both cases the hidden unit computes an iterated map on itself, given a constant input.
 Let us imagine that w e have two hidden units instead of one, so that these two slopes represent different units.
 Further, let us imagine that the graph shown on the left is the first hidden unit's response to a series of a inputs.
 The unit's activation will converge on successive iterations; how far it converges depends on how many iterations with the same input we carry out.
 N o w let us assume that the input changes to b.
 The graph on the right might represent the iterated m a p on the second hidden unit.
 The initial starting point depends on the final state value of the first hidden unit; it then diverges outward.
 To make use of this for a counting task, w e need two more Figure 6: Converging oscillations followed by diverging oscillations things to be true.
 First, w e need output units which can implement a hyperplane on the divergence phase so that the network can establish a criterial value which will signal the end of sequence.
 Second, during the initial phase, while the first hidden unit is converging, w e would like to have the second hidden unit (rightmost graph) "out of the way"; this could be accomplished if the input it receives from the first hidden unit shifts the slope to its asymptotic region.
 Then, during the second phase, while the second hidden unit is diverging, w e would like to have the first hidden unit suppressed in a similar way.
 Let us return to the actual simulation to see if this is what happens.
 Analysis: Part II Returning to the trained network shown in Figure 1, we can graph the activation function of each hidden unit under conditions when a sequence of as are received, and when a sequence of fes are received.
 Figure 7 shows the activation function of the first hidden u nit during presentation of as (rightmost plot) and fes (leftmost plot).
 Figure 8 shows the activation functions of the second hidden unit under similar conditions.
 What w e see is that each unit is "on" (i.
e.
, has an activation function which is capable of producing discriminably different outputs) only during one type of input, and each unit responds to a different input.
 While one unit is active, it shuts off the other unit.
 W h e n the input sequence switches from a to b, the other unit becomes active and shuts the first unit off.
 N o w let us look at the actual pattern of responses while this network processes a real sequence.
 This is shown in Figure 9.
 Here w e see exactly the desired behavior: One hidden unit in essence "winds up" like a spring as it counts successive a inputs; when the first b is encountered, the second unit "unwinds" for exactly the amount of time 485 hl(t) Figure 7: Activation function of hidden unit 1 during presentation of a sequence of as, and bs.
 a input / / ) k / / b input h(t) Figure 9: Hidden unit oscillations in trained network, processing 7 a's (spiral on lower left, representing hidden unit 1), followed by 7 bs (spiral on upper right, representing hidden unit 2).
 0.
8 0.
6 + ainpu 0.
2 0.
4 0.
6 0.
8 hl(t) Figure 8: Activation function of hidden unit 2 during presentation of a sequence of as, and bs which corresponds to the number of a inputs.
 Discussion We began by posing the question of how a recurrent network might solve a task (i.
e.
, the language a"fc")which, given a DFA, is known to require a pushdown store.
 W e hypothesized that the network might solve this task by developing a counter.
 What w e found was something quite different.
 The solution involved instead the construction of two dynamical regimes.
 During the first phase, one hidden unit goes into an oscillatory regime in which the activation values converged.
 W e might think of this as akin to the network's "winding up a spring.
" This phase continues until a b is presented.
 The effect of the b is to move the network into the second regime; in this phase the first hidden unit is now damped and the second hidden unit "unwinds" the spring for as long as corresponds to the number of as.
 This solution is effective well beyond the depth of strings (n=ll) presented during training.
 Our network was able to generalize easily to length n=21.
 W e found through making additional small adjustments of recurrent weights by hand that the generalization could be extended to /i=85.
 The solution is interesting because it demonstrates that a task which putatively requires a counter can in fact be solved by a mechanism which shares some but not all the properties of a counter.
 This particular dynamical solution, for example, solves the problem of indicating when to expect the beginning of a new string; but there is no way to read off from the internal state at any point in time exactly what the current count is (although once in the b phase, one can tell how many more bs are expected).
 In this regard, the network is very much like other dynamical systems: The instantaneous view of a child in motion on a swing will not reveal how many times the child has oscillated to get to that position.
 W e are currently involved in extending this work by looking at related languages such as parenthesis balancing (in which the count may be nonmonotonic, as opposed to 486 the a h ^ case).
 W e are also interested in cases such as the palindrome language, which more clearly motivate the need for a stacklike mechanisms.
 Finally, we are developing tools for studying dynamical solutions in networks which have a larger number of hidden units.
 This poses a major challenge, since the dynamics made possible through the interactions of many hidden units are much more complex than the case studied here.
 At this point we prefer not to evaluate this solution as better or worse than that provided by a conventional counter or by the pushdown store of a DFA.
 W e simply note that the solution is different.
 And we take this as an object lesson that prior notions of how recurrent networks might be expected to solve familiar computational problems are to be regarded as open hypotheses only.
 W e should be prepared for surprises.
 Acknowledgments We are grateful to members of the PDPNLP Research Group at UCSD, and in particular to Paul Mineiros, Gary Cottrell, and Paul Rodriguez for many helpful discussions.
 This work was supported in part by contract NOOO149310194 from the Office of Naval Research to the second author, and grant DBS 9209432 from the National Science Foundation, also to the second author.
 References Cleeremans, A.
, ServanSchreiber, D.
, & McClelland, J.
 (1989).
 Finite state automata and simple recurrent networks.
 Neural Computation, 1, 372.
 Elman, J.
L.
 (1991).
 Distributed representations, simple recurrent networks, and grammatical structure.
 Machine Learning, 1, 195225.
 Giles, C.
L.
, Miller, C.
B.
, Chen, D.
, Chen, H.
H.
, Sun, G.
Z.
, & Lee, Y.
C.
 (1992).
 Learning and extracting finite state automata with secondorder recurrent networks.
 Neural Computation, 2, 331349.
 Kolen, J.
F.
 (1994).
 Recurrent networks: state machines or iterated function systems? In M.
 Mozer, P.
 S.
 Smolensky, D.
 Touretzky, J.
 Elman, & A.
 Weigend (Eds.
), Proceedings of the 1993 Connectionist Models Summer School (pp 201210).
 Boulder, CO: Lawrence Erlbaum Assoc.
 Manolios, P.
 & Fanelli, R.
 (1994).
 First order recurrent neural networks and deterministic finite state automata.
 Neural Computation, 6,11541172.
 Pollack, J.
B.
 (1991).
 The induction of dynamical recognizers.
 Machine Learning, 7, 227.
 Seligmann, H.
T.
, & Sontag, E.
D.
 (1992).
 Neural networks with real weights: Analog computational complexity.
 Report SYCON9205.
 Rutgers Center for Systems and Control, Rutgers University.
 Watrous, R.
J.
, & Kuhn, G.
M.
 (1992).
 Induction of finitestate languages using secondorder recurrent networks.
 Neural Computation, 4, 406414.
 487 M e r e exposure effects  Merely total activation? Bruce F.
 Katz School of Cognitive and Computing Sciences University of Sussex Brighton BN19QH UK brucek@cogs.
susx.
ac.
uk Abstract The mere exposure effect, in which subjects prefer items they have previously been exposed to over unexposed items, is explained as the effect of competitive learning in a connectionist network.
 This type of unsupervised learning will cause the network to respond more strongly to patterns on which it has been trained.
 If it is assumed that positive affect is proportional to total activation, then the mere exposure effect is a direct consequence of this process.
 The addition of a habituation rule, with a dishabituating recovery element, can also explain factors which reduce or enhance the effect.
 These include the effect of exposure count, display presentation sequence, the complexity of the patterns, the effect of a delay after presentation, and finally, the effects of varying exposure duration.
 In the case of this last factor, in addition to showing that very short exposure durations can enhance the effect, the model reveals why it may be possible to respond positively to a stimulus that one cannot recall perceiving.
 Introduction The repeated presentation of an unreinforced and unclassified stimulus will cause subjects to prefer this stimulus over unexposed stimuli; this is known as the mere exposure effect (Zajonc, 1968).
 This effect is perhaps the most robust in the literature on aesthetic preference.
 It has been found with a number of stimulus types including nonsense words, meaningful words, Chinese chaiacters.
 photographs, music, and people (Harrison, 1977).
 Bornstein (1989) carried out a metaanalysis on 208 published studies on the mere exposure effect between the years 1968 and 1987.
 H e found a combined significance of p < .
0000(X)1, and a failsafe N of 33,047.
 That is, there would have to be this many unpublished studies with zero effect size to render the combined probability insignificant.
 In addition to demonstrating the consistency of the mere exposure effect, Bomstein's analysis revealed a number of factors which serve to enhance or reduce the size of the effect.
 This paper will treat five of these: 1) Number of exposures Bornstein found that the exposure effect was reduced in studies with large number of exposures.
 A number of studies have shown that preference is an inverted Ushaped curve as a function of exposure count.
 For example.
 Kail and Freeman (1973) found an increase followed by a decrease in rated attractiveness of ideographs as a function of number of exposures.
 Brentar, Neuendorf, and Armstrong (1994) have found a similar result in response to songs.
 This is consistent with the c o m m o n pattern whereby one initially plays a newly acquired piece of music at high frequency, but one finds one's attraction to it decline after many repeated listenings.
 These results indicate that in addition to whatever is causing the exposure effect, some sort of habituation eventually sets in causing the preference for tlie overexposed stimulus to decline.
 2) Homogeneous vs.
 heterogeneous display Berlyne (1970) stressed the importance of the presentation sequence in determining the size of the exposure effect.
 Homogeneous display consists of exposing a subject to a given stimulus a number of times, followed by the the presentation of the next stimulus a number of times, etc.
 Heterogeneous display is achieved by alternating the stimuli during each exposure.
 Berlyne found that heterogeneous display created a larger exposure effects with highfrequency stimuli.
 Bornstein's (1989) metaanalysis revealed that the combined homogeneous experiments yielded no exposure effect, but that the combined heterogeneous experiments showed a highly significant effect (p<.
0000001).
 3) Complexity Berlyne and his colleagues (1974) have stressed the importance of complexity on aesthetic preference.
 In particular, they showed that while ratings of interestingness increase with increasing complexity, affective ratings such as liking form an inverted U as a function of this variable.
 They also demonstrated that complex stimuli exhibit a less steep rise in affect as a function of exposure, and Beriyne (1970) has also demonstrated less steep declines with complex stimuli as a function of exposure.
 Bornstein (1989) claims that six of nine .
studies have shown greater exposure effects with complex stimuli than with simple ones, two found no difference, and one study favoured simple stimuli.
 In summary, there is some support for the claim that complex stimuli produce stronger exposure effects, although may take more presentations to exhibit such effects.
 4) Delay after exposure Studies directly studying the effect of delay after exposure have produced conflicting results (Harrison, 1977; Bornstein, 1989).
 However, Bornstein's (1989) metaanalysis revealed a significant "sleeper" effect.
 The exposure effect was greater if the ratings were completed after all the stimuli were presented, rather than immediately after each stimulus presentation.
 A forced delay after the the presentation of all stimuli also resulted in a more consistent effect than immediate ratings.
 5) Exposure time Bornstein's (1989) metaanalysis also showed that the exposure effect is more consistent when stimuli are briefly presented than when they are presented for long periods of 488 mailto:brucek@cogs.
susx.
ac.
uktime.
 Bornstein and D'Agostino (1992) have tested this hypothesis directly by using stimuli of 5ms and 500ms.
 As expected, the former produced greater exposure effects.
 In addition, recognition ratings for the brielly exposed stimuli did not differ from chance.
 Apparently, the nicic exposure effect can be achieved without recognition, and may even be enhanced by subliminal presentation (Bornstein, 1989).
 This is discussed further in the final discussion.
 An effect as important and robust as mere exposure has naturally attracted a number of theoretical treatments.
 Three of those are now briefly discussed: 1) Opponent process models These models propose two affective systems, positive and negative, acting in opposition (Solomon & Corbit, 1974).
 The initial response to a novel stimulus is assumed to be negative.
 With repeated exposure and greater familiarity, however, the negative affective response is weakened, permitting the antagonistic positive affective system to have greater input in determining the overall affective state.
 Despite some evidence for the sort of rebound effects such a model would predict, two problems remain.
 First, it requires that one's initial response to a novel stimulus invariably to be negative, which appears prima facie to be false.
 Second, it does little, in itself, to explain the five variables modulating the effect described above.
 2) Arousal models Most closely associated with D.
E.
 Berlyne, arousal models postulate that positive affect is an inverted Ushaped curve as a function of the arousal potential of the stimulus.
 Berlyne (1971) suggested that a complex stimulus, initially somewhere to right of the inflexion point on this curve, becomes subjectively less complex with repeated exposures.
 Hence, it becomes more liked as it comes closer to the apex of the inverted U.
 This would also explain why simple stimuli become less wellliked with repeated exposures.
 However, the model does less well in predicting inverse relation between exposure duration and the size of the exposure effect, and the role of delay on the effect, and it is not clear how one could operationalize the model to incorporate these auxiliary effects.
 3) Twoprocess models Twoprocess models suggest a familiarity effect is counterbalanced by a habituation effect (Bornstein, 1989).
 Initially, exposure to a stimulus causes it to become less threatening, and therefore preferred to a larger extent.
 However, eventually boredom will set in, causing the subject to lose interest in the now ovedy familiar item.
 Thus, one can explain the eventual downturn in affective response with repeated presentations.
 The tendency for homogeneous presentation, and long exposures to quash the effect can be explained along similar grounds.
 Delay should decrease boredom, and therefore will increase the exposure effect.
 Finally, presumably one becomes less bored with complex stimuli than with simple ones, explaining the effect of this variable.
 However, two problems remain.
 First, familiarity, which forms the basis for the first process in the twoprocess theory, does not seem to be a requisite of the mere exposure effect in that subliminal stimuli cause an exposure effect.
 and may be superior to supraliminal stimuli in doing so (Bornstein, 1989).
 Second, one would like to know how to operationalize the notions of familiarity and boredom in order to make predictions concerning the interactions between the various modulating factors.
.
 The purpose of this paper is propose a twoprocess connectionist model that meets these objections.
 A Connectionist Model The model rests on two unsupervised learning rules.
 Thus, it is consistent with the fact that mere exposure effect occurs in the absence of a teacher.
 In addition, the associative character of the proposed rules is consistent with the fact that the mere exposure effect is seen as far down on the phylogenetic scale as insects (Bornstein, 1989).
 Before, presenting the model in detail, however, a means of measuring the affective response of the model must be proposed.
 The fundamental assumption of this work is that positive affect is a monotonic function of cortical activity Thus, this measure contrasts with optimal arousal theories (Berlyne, 1970), which propose a downturn in affect with overaiousal.
 One justification for this measure is that it is consistent with the traditional aesthetic principle of unity in diversity (Martindale, 1984).
 The more competing representations the network is able to maintain, the higher the overall activity of the network.
 Conversely, low activity implies either low diversity in the input stimulus or the inability of the network to represent the diverse aspects of a complex stimulus at once.
 1 have shown how this measure is useful in understanding the unification of incongruities in humourous stimuli (Katz, 1993), and how it may be used to measure the worth of simple melodies (Katz, 1994).
 The mere exposure effect follows immediately from this premise acting in conjunction with an unsupervised learning regime such as competitive leaining (Rumelhart, & Zipser, 1986).
 Exposure to a stimulus causes the weights to realign such that future presentation of the stimulus will provide more activity to the classification layer.
 Eventually, this realignment results in superthreshold activity in this layer, and the organism prefers those stimuli that trigger such activity over those that do not.
 A habituation effect must be postulated in order to provide for the eventual downturn in activity with overexposure.
 Figure 1 shows how these two processes interact in the proposed model.
 The model consists of two layers, an input layer consisting of a grid of units, and a classification layer, consisting of a set of winnertakeall clu.
sters.
 Each such cluster consists of excitatory connections from units to themselves, and inhibitory connections to all other units in the cluster.
 Excitatory connections also form between active units in the input layer and active units in the competitive clusters as the classification process occurs.
 Inhibitory connections form between mutually active units in the input grid to form a novelty filter (Kohonen, 1987).
 i.
e.
, a subsystem which provides more activity to novel stimuli and less to frequently presented stimuli.
 This filter provides the habituation effect necessary to reduce activity provided to the classification layer.
 489 The novelty filler is governed by input grid cluster 1 cluster 2 classiflcation layer Figure 1.
 The model.
 Units in the input layer connect in an excitatory fashion to units in the classification layer (solid lines).
 They form inhibitory connections between themselves to form a novelty filter (shaded lines).
 Learning between the input and classification layers is governed by the competitive rule Awij = ^1 (aj / Z ak ) [ a i / Z a i  Wij ], (1) where Wij is the weight between unit i in the input layer and unit j in the classification layer, ai and aj are the activities of units i and j respectively, I a^ is the sum of the activity of all the units in the cluster of which j is a member.
 I ai is the sum of the activities of all units in the input layer, and l.
\ is the learning rate.
 Equation 1 reduces to the discrete competitive rule (Rumelhart & Zipser, 1986) Aw,j = X i [ 1 / S ai  w,.
 (2) when there is only a single winner] at full activation (1.
0) in the output layer (i.
e.
.
 (aj / 1 ak) = 1), and when all input units are also at unit activation.
 It is not possible to use Equation 2, however, for two reasons.
 First, a clear winner must emerge gradually in each cluster in order to simulate the gradual increase in activity and therefore affect as entailed by the exposure effect; selecting a single winner artificially would mean that the activity in the classification layer was constant.
 The term (aj / Z ak) in Equation 1 accommodates the "soft" winnertakeall, or contrast enhancement competitive network which permits multiple activity at relaxation.
 Second, because of the novelty filter, full activity cannot be guaranteed in the input layer.
 The term (ai / laj) in Equation 1 maintains constant learning despite lowered activity in the input layer (this will prove important for low exposure durations discussed in section 3.
5).
 Aw,j =  A.
2 aiaj_ Awjj = +Xi, when ai and aj > e, and (3) otherwise.
 The first part of Rule 3 ensures that mutually active units form an antiHebbian, inhibitory connection, causing the activity of such units to be reduced.
 The second part of the rule enables the .
system to dishabituate when the activity of these units arc decoupled.
 This part of the rule is for recovery from habituation only; weights between input units aic not allowed to creep above 0.
0.
 Relaxation in the network follows the typical network rule where ai = S (Iw,j aj).
 S(x)=l/(Ue(''6)^), (4) (5) is the sigmoid output function.
 Update is accomplished asynchronously to prevent oscillation in the input layer and the competitive clusters.
 In summary, unsupervised learning in the network follows two simple rules.
 The classification rule in Equation 1 is essentially a normalized Hebbian rule, and the filter in Rule 3 is essentially an antiHebbian rule with a restorative element.
 In the following simulations, it will be shown that these rules, in conjunction with the assumption that positive affect is proportional to the amount of activity registered by the classification layer, provide results in accord with the experimental data associated with the mere exposure effect.
 Simulation Results Five sets of simulations are now presented, corresponding to the five main exposure effects described in the inttoduction.
 Except where noted, the following parameters are in force.
 Learning rates in Rules 1 and 3, Xi, A,2, and ̂ 3 are all set to 0.
2; e in Rule 3 is set to 0.
001.
 The threshold for all units 9 is 0.
9, and the temperature T is 0.
1.
 These two paiameters help ensure that only a single winner emerges in each cluster once learning has occurred.
 Excitatory recuirent weights in the competitive network are 0.
5, and lateral inhibitory weights are 0.
5.
 Five clusters consisting of four units each are used.
 Initial weights between layers are set at random such that the sum of all weights to a given classification unit sum to 1.
0.
 Input stimuli consist of randomly generated stimuli on a 5 by 5 grid with each grid element having a 5 0 % probability of being on.
 Changing the parameters within reasonable limits does not alter the qualitative form of the results to be presented.
 Simulation 1: Number of Exposures In this simulation, a single input was repeatedly exposed to the network.
 The graph in Figure 2 show the mean activity in the cluster layer as a function of the number of exposures with full habituation (i.
e.
.
 A.
2,= A.
3 = 0.
2, as usual) and for reference, no habituation in the input layer (i.
e.
, A,2,= Xi = 0.
0).
 Both curves aie the averages of the curves obtained 490 over 10 trials.
 With no habituation, the exposure effect is monotonic, and the winning units in the classification layer asymptotically approach 1.
0 as the weights become aligned to the input vectors.
 A similar effect can be seen wl)cn habituation is in place, but at after 6 exposures the activity in the input layer causes a decline in activity achieved in ihe classification layer, asymptotically approaching 0.
0 as Ihe number of exposures increase.
 Thus, in common with all twofactor theories, the network model accounts for the inverted U relating affect to exposure number.
 The following four sections show how providing heterogeneous display, increasing stimulus complexity, inserting a delay after exposure, and decreasing exposure time can overcome some of the habituation to provide a stronger or longer lasting exposure effect.
 1.
0 n no habituation D — with habitaluation  A — heterogenous " D — homogeneous > 2 0.
6^ ^Dnnnnn 5 7 9 11 exposure number 15 Figure 2.
 Mean activation per cluster for a single stimulus as a function of exposure number, with and without habituation in place.
 Simulation 2: Homogeneous/Heterogeneous Display In this simulation, 5 input stimuli were presented to the network in a homogeneous display sequence or a heterogeneous display sequence.
 In the former case, a given stimulus was presented for the specified number of exposures, followed by the next stimulus presented in this manner.
 Activity in the classification layer was measured for all 5 stimuli at the end of this sequence.
 Heterogeneous display meant that stimuli 15 were presented sequentially, and this process was repeated for the specified number of exposures, after which network activity was measured.
 All stimuli were presented in the same order across presentations in both cases.
 Heterogeneous and homogeneous display involve equal numbers of presentations of a given stimulus for a given exposure number.
 Despite this, the graph in Figure 3 shows radically different results for the two presentation types (each data point represents the average of len trials).
 In accord with the human experimental results showing thai homogeneous presentation yields weak exposure effects.
 these data show a small exposure effect for low exposure frequency and then a decline as exposure number increases.
 T w o factors contribute to the lack of exposure effect for high frequency homogeneous presentations.
 First, successive presentation of a single stimulus results in habituation; this lowers the activity in the input layer for the 3 5 7 9 11 13 15 exposure number Figure 3.
 Mean activation per cluster for multiple stimuli as a function of presentation sequence and exposure number.
 last few stimuli presented.
 Earlier stimuli are able to recover from this habituation because other stimuli are interposed between their original exposure and the final test of their activity.
 However, because of this interval, they fall prey to the second factor.
 The interposed stimuli will share some of the same winners as the earlier stimuli, but will cause the weights to be realigned in accord with these later patterns.
 This lessens the response to the earlier stimuli.
 Heterogeneous presentation counteracts these factors by permitting the dishabituation to occur because successive stimuli will have nonoverlapping features.
 Furthermore, heterogeneous presentation ensures that all stimuli have been presented a relatively short time before testing, ameliorating the effect of the second factor.
 Simulation 3: Complexity Stimulus complexity in this simulation was operationalized in a manner similar to that of Berlyne (1974).
 Simple stimuli are assumed to differ from each other in relatively few ways, while complex stimuli differ along a number of differing features.
 Four levels of complexity over five features were tested here.
 The first, simplest level was created by allowing one feature to take two possible equiprobable values; all the other features took one value only.
 Thus, there were a total of 2 possible stimuli, with an uncertainty of U = log(2) = 1 bit.
 In the next level, 3 features took 2 possible values, the other 2 features took only one value, resulting in an uncertainty of U = log(8) = 3 bits.
 For the next level of complexity.
 4 features took 2 values resulting in an uncertainty of U = log(16) = 4 bits.
 The last, highest level of complexity consisted of 4 features taking 2 values, and 1 feature taking three, with an uncertainty of U = log (48) = 5.
58 bits.
 Five stimuli were chosen according to a given complexity level and presented to the network in a heterogeneous fashion.
 The graph in Figure 4 shows activity in the classification layer as a function of the number of times that these sets were presented.
 In accord with the experimental data, larger exposure effects were found with higher complexity (high uncertainty) stimulus sets after 15 presentations of the set.
 Less interstimulus similarity within a set, and therefore lower habituation explains this 491 e S ^ 2 '̂  e 0.
80.
60.
40.
20.
0 GU = 1 hit U = 3 bus U = 4 bits U = 5.
58 bits '^^^^Y'i^i^;^^^<^^ 1 5 9 13 exposure number Figure 4.
 Mean activation per cluster as a function of the uncertainty U of the stimulus set and exposure number.
 result.
 Also in accord with experimental data, high complexity initially exhibited a less steep rise in activity as a function of exposure number.
 This is the effect of low complexity stimuli sharing more winners because they are more similar, causing a faster rise in this curve before habituation sets in.
 In order to extend these results to experiments with natural stimuli such as simple and complex pieces of music, it must be assumed that the raw input is transformed into feature space before it is operated on (see Katz, 1994 for an example of how exposure effects can be demonstrated with melodies of varying complexity).
 Simulation 4: Delay after exposure In this simulation, a single stimulus was presented repeatedly to the network.
 A variable number of randomly generated stimuli were then presented, after which the networic's response to the original stimulus was measured, to simulate a delay between exposure and measurement of affect.
 Figure 5 shows these results as a function of the number of delay stimuli and the number of presentations of the original stimulus; each data point is the average of ten trials.
 For all three exposure frequencies, there is a rise in network response as a function of the delay.
 The reason for this is that repeated presentation of the original stimulus results in habituation, but the delay stimuli result in dishabituation, restoring the input layer to its original response.
 However, as the results also show, this restoration works best if the original stimulus was not highly overexposed.
 The reason for this is that high exposure results in a near complete dampening of input layer activity.
 This causes no clear winner to emerge, and therefore affects classification learning.
 These results do not explain the fact that the exposure effect is augmented by mere time delay (Bornstein 1989), although this could be possibly explained by a passive dishabituation effect.
 Simulation 5: Exposure duration In the final simulation, activity in the classification layer initia exposures ^ 1 3 5 7 9 11 number of delay stimuli Figure 5.
 Mean activation per cluster as a function of the number of initial exposures of a single stimulus and the number of subsequent delay stimuli.
 is studied as a function of exposure duration.
 Five input patterns were presented in homogeneous sequence for 10 or 20 exposures.
 Instead of allowing the system to relax, as in the previous simulations, these stimuli were permitted to activate the network for a specified amount of time.
 This time was measured in relaxation cycles and fractions thereof.
 In the case of fractional relaxation cycles, the activation value of a unit was proportional to the fractional value.
 For example, a unit's activation after 1.
4 cycles was the activation value after a single relaxation cycle plus 0.
4 of the difference between this value and what it would have been if 2 relaxation cycles had taken place.
 The graph in Figure 6 shows the results of measuring classification activity after the network was exposed to the patterns (the network was allowed to relax in this testing phase); each data point is the average of ten trials.
 In accord with the experimental data, both initial exposure frequencies show increased activity for shorter exposure times.
 Lack of habituation makes the lower exposure frequency presentation somewhat more effective.
 These results occur because short exposure durations result in less activity in the input units, and by Rule 3 less habituation.
 Learning in the normalized competitive Rule 1 is not affected by low activity in the input layer.
 Thus, low exposure duration is favoured.
 However, learning with very low exposure duration, though resulting in higher activity in the clusters.
 does not reliably produce a clear winner, when fully exposed to the original pattern.
 This occurs because the contrast enhancement mechanism provided by the winnerlakeall clusters does not have time to suppress the activity of the losing units, and therefore they are subject to the learning process in addition to the winner.
 This often results in all units becoming active in a cluster to a small extent when the network is exposed to the pattern in the test pha.
se; this is discussed further in the next section.
 Discussion In summary, two simple leaining rules, in conjunction with an activation measure of affect, yield simulation results 492 http://pha.
seexposure number 0.
08> ^ 0.
06 0.
040.
020.
6 1.
0 1.
4 1.
8 exposure duration (relaxation cycles} Figure 6.
 Mean activation per cluster as a function of the exposure duration for two exposure frequencies.
 in accord with the experimental data.
 The basic exposure effect occurs because competitive learning causes a network to be more responsive to stimuli to which it has been previously exposed.
 The other effects, including the fall off in the exposure effect with overexposure, the greater effectiveness in producing the effect of heterogeneous vs.
 homogeneous display, the greater effectiveness of complex stimuli vs.
 simple stimuli, and the increase in the effect with delay and low exposure duration can be explained by competitive learning acting in conjunction with a novelty filter.
 The network model is also capable of making predictions about the interactions between these variables, which is not necessarily possible in models which are less completely specified.
 In particular, the model may reveal why exposure to subliminal stimuli can produce an exposure effect in the absence of recognition.
 On the face of it, this is a strange result  subjects are responding positively to stimuli they have been exposed to, and at the same lime claiming they have never seen the stimuli.
 One explanation is that two systems are subserving perception, one affective, and one cognitive (Zajonc, 1980), and that the affective system is amenable to subliminal effects, while the cognitive one only works in conjunction with awareness.
 The model proposed here provides an alternative explanation.
 Recall that that low exposure duration resulted in an exposure effect, but (hat it did so by activating all units in a cluster to a small extent, rather than producing a clear winner.
 It is possible that subjects say they do not recognize the stimulus becau.
se it does not produce these winners, as a supraliminal stimulus would.
 However, the net activity in this layer is still greater than for an unencountered stimulus.
 In effect, the warm glow of affective response occurs without Tilchener's warm glow of recognition.
 Berlyne, D.
E.
 (1974).
 Studies in the new experimental aesthetics: Toward an objective psychology of aesthetic appreciation.
 Washington: Hemisphere.
 Bornslcin, R.
F.
 (1989).
 Exposure and affect: Overview and metaanalysis of research, 1968987.
 Psychological Bulletin.
 106.
 265289.
 Bornslein, R.
F.
 & D'Agostino, P.
R.
 (1992) Stimulus recognition and the mere exposure effect.
 Journal of Personality and Social Psychology.
 63, 545552.
 Brentar, J.
, Neuendord, K.
A.
, & Armstrong, G.
B.
 (1994).
 Exposure effects and affective responses to music.
 Communication Monographs, 61, 161181.
 Harrison, A.
A.
 (1977).
 Mere exposure.
 In L.
 Berkowitz (Ed.
), Advances in experimental social psychology.
 N e w York: Academic Press.
 Kail, R.
V.
, & Freeman, H.
R.
 (1973).
 Sequence redundancy, rating dimensions and the exposure effect.
 Memory and Cognition, 1,454458.
 Katz, B.
 F.
 (1993).
 A neural resolution of the incongruityresolution and incongruity theories of humour.
 Connection Science, 5, 5975.
 Katz, B.
 F.
 (1994).
 An ear for melody.
 Connection Science, 6.
 299324.
 Kohonen, T.
 (1987).
 Selforganization and associative memory.
 SpringerVerlag.
 Martindale, C.
 (1984).
 The pleasure of thought: A theory of cognitive hedonics.
 Journal of Mind and Behavior, 5, 4980.
 Rumelhart, D.
E.
, and Zipser, D.
 (1986).
 Feature discovery by competitive learning.
 In D.
E.
Rumelhart and James L McClelland (Eds.
), Parallel Distributed Processing, vol.
 1.
 Cambridge: M I T Press.
 Solomon, R.
L.
 & Corbit, J.
D.
 (1974).
 An opponent process theory of motivation: I.
 The temporal dynamics of affect.
 Psychological Review, 89, 119145.
 Zajonc.
 R.
B.
 (1968).
 The attitudinal effects of mere exposure.
 Journal of Personality and Social Psychology, 9, 127.
 Zajonc, R.
B.
 (1980).
 Feeling and thinking: Preferences need no inferences.
 American Psychologist, 35, 151175.
 References Berlyne, D.
E.
 (1970).
 Novelty, complexity and hedoiiic value.
 Perception and Psycliophysics.
 8, 279286.
 Berlyne, D.
E.
 (1971).
 Aesthetics and psychohiology.
 N e w York: Applcton.
 493 Alarms: Heuristics for the control of reasoning attention Timothy J.
 Norman Department of Computer Science, University College London, London, WC1E6BT, UK.
 T.
Norman@cs.
ucl.
ac.
uk Derek Long Department of Computer Science, University College London, London.
 WC1E6BT, UK.
 D.
LongQcs.
ucl.
ac.
uk Abstract Agents in the real world must be capable of autonomous goal creation.
 One effect of this ability is that the agent may generate a substantial number of goals, but only a small number of these will be relevant at any one time.
 Therefore, there is a need for some heuristic mechanism to control an agent's reasoning attention.
 Such a mechanism is presented in this paper; alarms.
 Alarms serve to focus the attention of the agent on the most salient goals, and thereby avoid unnecessary reasoning.
 In this way, a resourcebounded agent can employ modem planning methods to effectiveness.
 Introduction It is widely recognised that if an autonomous agent is required to interact with a realworld domain,^ a static set of goals is not a sufficiently flexible representation of the agent's purpose (Brooks, 1986; Carbonell, 1982; Long & Fox, 1995; Simon, 1967; Sloman, 1987; Wilensky, 1983).
 The domain may change at any time such that pursuing a goal may no longer be realistic, required, or even possible.
 A single goal may need to be satisfied more than once, or periodically, depending on how the domain evolves over time.
 So, an autonomous agent must have the ability to set itself goals (cf.
 Luck & d'Inverno (1995)).
 Such a capability has been investigated to varying degrees and for different purposes in a number of systems including P A N D O R A (Wilensky, 1983), Pengi (Agre & Chapman, 1987), P R S (Georgeff & Lansky, 1987), and N M L l (Beaudoin & Sloman, 1993; Beaudoin, 1994).
 In general, goals are set in response to changes in the domain that are relevant to the agent.
 The work presented here is motivated by two observations about the nature of goals that have important consequences in models of agency.
 1.
 The time at which changes in the domain that may lead to the generation of a goal are detected is not necessarily the time at which the agent should act on that goal.
 Action may be required some time in the future.
 2.
 Some goals tend to recur periodically, or at particular times of the day/weelc/etc.
 (Goals that recur in this way have been referred to as cyclical satisfaction goals (Schank & Abelson, 1977) and replenishment goals (Ortony, Clore & Collins, 1988).
) These goals persist; they are not abandoned once achieved, their influence is simply mitigated.
 Then, as time passes, the intensityof the influence increases until the goal recurs.
 However, the important role that time plays in the generation of these types of goal has not been fully appreciated.
 An agent that is capable of autonomous goal creation, potentially can have an unlimited number of goals.
 However, the number of goals for which action is required now will be a small number of these.
 Furthermore, all real agents are resourcebounded (Simon, 1957), so there is a limit on the number of goals that can be attended to at any one time.
^ A n additional complication is that the process of distinguishing between goals that warrant attention and those that do not, itself depletes resources.
 Therefore, in any resourcebounded agent an heuristic mechanism is required to focus resources on the most salient goals; i.
e.
 to avoid unnecessary reasoning (Norman & Long, 1995).
 Such a mechanism has been characterised as "fast but stupid" by Sloman (1987).
 A n heuristic mechanism for the control of reasoning attention is presented in this paper: alarms.
 This mechanism has been implemented and tested on a simulated warehouse agent, and intuitive examples from this domain are used throughout the paper.
 Goals In AJ planning systems, a goal is seen as a proposition, or a well formed formula in the world model, to be made true.
 The purpose of the planner is to search for a sequence of operators (a plan) that will transform the current state into one where a given goal or goals hold.
 Planning research is principally concerned with the creation of good plans to satisfy a conjunction of such goals in an efficient way.
 However, the planning problem quickly becomes intractable as the number of goals that must be planned for increases.
 Planning is also an important cognitive activity, and planning systems are useful in explaining certain types of human decision making.
 Explanations of human decision making 'The domain of an agent is its internal state and the state of the external environment that the agent perceives.
 A realworld domain is a domain that can neither be completely nor correctly modelled.
 ^In fact the load on the agent's reasoning resources is bounded, and this load is related to the number of goals that hold attention.
 However, some goals are more easy to attain than others, so this is not necessarily a simple relationship.
 494 mailto:T.
Norman@cs.
ucl.
ac.
uktypically concentrate on the creation and management of multiple goals in every day situations, and less on how these goals are represented or achieved (Beaudoin & Sloman (1993) and HayesRoth (1995) are exceptions).
 Typically, various types of goal are identified.
 For example, Ortony, Clore & Collins (1988) specify three broad goal types: replenishment goals, active pursuit goals and interest goals (cf.
 Schank & Abelson (1977) and Carbonell (1982)).
 In general, goals are the problems to be solved by an agent through some sort of planning capability.
 In the work presented in this paper, a goal is viewed as a proposition to be made true through purposeful action, but goals can be generated through different processes.
 It is different processes through which goals are generated that distinguish the two goal types discussed here.
 The term DGoal is used to refer to goals generated through decision, and the term RGoal is used to refer to goals generated through replenishment.
 It is important to note that goals from different sources are indistinguishable in content and function after they have been generated.
 These terms DGoal and RGoal refer to the goal and the process that generated the goal.
 DGoals Ortony, Clore & Collins (1988) describe active pursuit goals (analogous to DGoals) as states of affairs that the agent wishes to achieve under certain conditions.
 Necessarily, the agent must have some reason behind the generation of such a goal.
 In the system presented here, simple recognition mechanisms, similar to "Noticers" (Wilensky, 1983), are used to trigger the agent to consider generating DGoals.
 Demons (see figure 1) monitor the external environment and internal state of the agent, reporting to appropriate mechanisms when some set of conditions hold.
 Some of these demons are dedicated to recognising events that may warrant the generation of a goal.
 For example, if an agent is informed of a meeting, this event is reported, and a goal may be generated in response.
^ However, the time at which the agent recognises that something must be done is not necessarily the time at which its attention should be directed towards doing it.
 So, goals may be generated through such a mechanism that are not appropriate to the agent for some time.
 DGoals have a limited life: They are generated, planned for, and once they have either been satisfied or are no longer required, they are deleted.
 For example, the warehouse agent may receive a request for an order to be satisfied from a potential customer.
 If the order is accepted, a goal is generated; then if the order is satisfied or if the agent no longer wishes to satisfy the order, the goal is deleted.
'' ^A decision based on the agent's beliefs is a prerequisite to the generation of a goal in this way (Castelfranchi, 1995), hence the term DGoal.
 "•The deletion of a goal for whatever reason may influence other processes, or even cause the agent to consider generating other goals.
 RGoals The second type of process through which goals can be generated is replenishment.
 Replenishment is an autonomic process, and hence does not involve reasoning.
 Examples: (1) An agent that has the desire to interact with another agent with known behavioural patterns may synchronise its activity with the other agent for its own ends; (2) An agent that is concerned with maintaining the state of a domain variable may periodically affect the variable to keep it within acceptable bounds.
 Replenishment processes tend to cause the same goals to recur over certain periods of time or at certain characteristic times (e.
g.
 at 5pm every day, or every Thursday).
 There are two distinct reasons for RGoals to influence an agent's behaviour: 1.
 An agent in a realworld domain is not the sole actor in that domain.
 Influences that are independent from the agent may produce regularities in the domain; e.
g.
 a lecture timetable.
 For the agent to affect the domain in useful ways, it may be necessary for it to synchronise its activities with aspects of the environment that are not under its control.
 So, a student who has the desire to pass a course will be influenced by the recurring goal to have attended particular lectures.
 2.
 It is advantageous for agents to generate goals in this way, rather than through decision.
 (The process of generating a goal through decision is computationally expensive.
) For example, if a warehouse agent, through some autonomic process, causes goals to have restocked a commodity to recur every Thursday, in normal circumstances there is no need to even consider that commodity during the rest of the week.
 Replenishment processes allow reasoning resources to be redirected to more constructive tasks.
 Alarms Focusing attention is an important requirement for an agent capable of autonomous goal generation for two reasons: (1) The agent will be influenced by a large number of goals, but only a small number of these goals will warrant attention at any one time; and (2) Resource limitations bound the number of goals that can be considered, or planned for, at any one time.
 This section describes alarm management processes; these have the effect of focusing an agent's reasoning attention on appropriate goals at appropriate times.
 In the most simple terms, an alarm [qj) is a structure that associates a goal (gj) with a function of intensity over time: aj = {gj,fj{t)) This function is designed to reflect how appropriate the goal is to the present situation.
 Typically, as time passes the intensity of this function increases to a point where it exceeds some threshold.
 Then, the attention of the agent is focussed on that goal.
 This threshold changes when the situation changes; as the agent becomes more busy, the threshold increases and vice versa.
 Only when an alarm has triggered in this way will the goal be considered, and possibly activated.
 Alarms are essentially goal management processes that serve to avoid unnecessary reasoning.
 495 internal state Demons Alarms create alarm , ^ monitor events external state Replenish —commitments mitigate/delete  trigger Consider Set alarm goal Goal required? J activated goals Plannmg control action Figure 1: An architecture for goal creation and management.
 Intensity max alarm <" creation time tdi Ti me Figure 2: A general alarm function.
 A l a r m generation DGoals: W h e n the agent considers that an event (detected by a demon) warrants the creation of a goal, an appropriate alarm is set (see figure 1).
 For example, the warehouse agent contains a demon that will respond to any message received from a customer.
 If the customer has placed an order, and this order is acceptable to the agent, then a goal to have met the order is created.
 The agent predicts when this goal needs to achieved, how long it will take to achieve, the importance of the goal, etc.
 With this information, a function of intensity against time is defined, and an alarm created.
 This function of intensity (figure 2) is specified by defining the variables tdhAjJdt^ idt, and imax • The deadline {tdi) is the time at which the agent wishes the goal to have been satisfied.
 Aat is the period of time that the agent expects will be required to act to satisfy the goal.
 With this value and the deadline, an estimate can be made of the last point at which the agent should attend to the goal to have it satisfied in time, and hence the time at which the intensity of the alarm should be maximal: tmax The delay time {tdt) is a time, before which it is not appropriate for the agent to act on the goal.
 For example, there is no point in the warehouse agent preparing an order containing perishable commodities if the customer is expected to arrive after the commodities will have perished.
 The times tdt and tmai define a time window where the agent predicts that it is sensible to activate the goal.
 Different goals may have the potential to influence the agent to varying degrees; this potential is the maximum intensity of the alarm (imax) A modification of the Little Nell problem (McDermott, 1982) is useful in illustrating the effect of varying alarm potentials.
 The heroine (Nell) is tied to the tracks, a train is approaching, and the hero (Dudley) wishes to save her.
 The modification is that Dudley is not only influenced by the goal to have saved Nell.
 Dudley also has the goal to have sated his hunger.
 Furthermore, it is lunch time, so the intensity of the alarm encapsulating the goal to have sated his hunger is nearmaximum.
 Dudley has predicted that Nell will get mashed soon, so the alarm encapsulating the goal to have saved Nell is also nearmaximum.
 It is the fact that saving Nell is far more important to Dudley that distinguishes these two alarms; i.
e.
 the variable imax for the alarm encapsulating the goal to have saved Nell is greater than for the other alarm.
 In fact it is possible for a goal to be ignored, even if the alarm's intensity is maximum, if the threshold is sufficiently high (see the extended example).
 Finally, idt is the initial intensity of the alarm at the delay time.
 Between tdt and tmax, the intensity linearly increases from idt to imax • It is possible to define different criteria for an alarm function, but this depends heavily on the accuracy of the predictions, or the information they are based on.
 RGoals: The visible effect of an autonomic replenishment process is to generate a stream of alarms, and hence activated goals, at appropriate times.
 Each goal is treated in the same way as a goal generated through decision by the planning and control mechanisms.
 The goal will be activated, and acted on in the usual way.
 The function of the replenishment process is to continually monitor the existing alarms.
 If there is an RGoal that is missing (due to it having been deleted), a new alarm encapsulating that goal is automatically created (figure 1).
 The function of intensity of this replenished alarm will increase to maximum over some period of time.
 This period may be fixed and the intensity of the alarm increases as the time since it was last satisfied increases.
 (This type of mechanism is consistent with the observations of Ortony, Clore & Collins (1988) about the nature of replenishment 496 goals.
) For example, the intensity of the alarm encapsulating the goal to buy milk may increase as the time since the last visit to the shops for this purpose increases, based on some estimate of how long a pint (or quart) of milk lasts.
 However, the specification of a fixed period of replenishment does not sufficiently express certain types of Rgoal behaviour.
 If hunger is influenced primarily by social habit, the alarm could be replenished to increase in intensity over the periods of time between 08:00, 13:00, and 18:00, causing goals to be activated around these times in the day.
 This is an example of a timetabled RGoal.
 Note, this does not preclude the possibility of a DGoal to mitigate hunger being generated at any time.
 This RGoal to satiate hunger is an example of an autonomic replenishment process that is essentially permanent.
 However, an agent may have a number of RGoals that only exists under certain conditions; these are temporary RGoals.
 For example, the warehouse agent may accept regular orders from reliable customers under certain conditions.
 These regular orders become temporary RGoals, and will only exist if the agent continues to believe that the customer is reliable and that the customer still requires the order.
 Demon processes are again employed to notify the replenishment process that the conditions for the existence of a temporary RGoal no longer hold.
 In general, an agent will synchronise its activities with regularities in the environment, or with other agents, only if the agent considers it advantageous to do so.
 Alarm modification A realworld domain is intrinsically uncertain; predictions are fallible and the normal replenishment of certain goals can become inappropriate.
 At any time after an alarm has been set, the domain may change in an unexpected way.
 Such changes in the domain may directly cause changes in the intensity of an alarm.
 Opportunities: An opportunity is an action for which all the preconditions of that action hold in the present state, and that the achievement of a goal encapsulated in an existing alarm is a postcondition of that action.
 By taking an opportunity, it is possible for the agent (if all goes well) to satisfy the goal without the need for further planning.
 The agent is equipped with a set of opportunity demons, where the conditions for the triggering of that demon are the preconditions of the relevant action.
 The detection of an opportunity has the effect of giving the appropriate alarm an impulse of intensity.
̂  It is possible for such an impulse to increase the intensity of an alarm over the threshold, cause the alarm to trigger, and hence possibly activate the goal.
 If the goal is activated, the opportunity is communicated to the planning and control mechanisms of the agent.
 Dangers: A danger to a goal is one of three things: (a) A plan, constructed to satisfy the goal, which has failed; (b) A n essentially irreversible action^ that the agent intends to perform which will prevent it from satisfying the goal in time; or (c) All alarms are based on assumptions about h o w the domain will evolve over time.
 If the agent detects that the domain has changed such that a salient assumption is no longer valid, this constitutes a danger to the satisfaction of the goal.
 In the same way as opportunity demons, danger demons notify the agent of a dangerous situation by giving the alarm that encapsulates the goal that is in danger a temporary impulse of intensity.
 A n impulse may cause an alarm to trigger and force the agent to evaluate a possible danger to the goal encapsulated in that alarm.
 Commitments: In the construction of a plan, the agent commits itself to activity at certain times.
 Commitments reduce the time available for the agent to act to satisfy other goals.
 For example, if an agent plans to travel through a desert, whether the agent has recently sated its thirst or not, the goal to have mitigated thirst is appropriate to the situation.
 Commitments made by the agent have the effect of shifting a function of intensity left along the time axis, and hence the alarm is evaluated at the time {tnow + A c O .
 where tnow is the time now and Act is the effect of the commitments that the agent has made to future action.
 This alarm may therefore be triggered earlier.
 Alarm triggering A n alarm is triggered, and hence the goal is considered by the agent, if the alarm function evaluates at the time {tnow + Act) to a value greater than or equal to some threshold.
 This threshold is c o m m o n to all alarms and can have any value above zero.
 The threshold has the effect of controlling the sensitivity of the agent to alarms, and acts to limit the focus of the agent's attention.
 If the threshold is low, the agent will be more sensitive to new goals, and vice versa.
 However, to effectively control the focus of attention, this threshold must change in relation to the changing load on the agent's reasoning resources.
 A s the agent's activity increases, the threshold increases and hence the agent's sensitivity to new goals is reduced.
 So, if the agent has a large number of urgent tasks, it will tend to leave other alarms that have lower intensity potential to the last minute or ignore them.
 However, if the agent has fewer tasks demanding attention, alarms that have less intensity potential may trigger (the threshold having been lowered), and goals will generally be considered earlier.
 The effect of this system of alarms is to focus reasoning attention on a limited number of goals so that the planning and control processes are not swamped with things to do, or even things to think about doing.
 Once a goal is activated, it is important for an agent to then reconsider the goal at appropriate times (Bratman, Israel & Pollack, 1988).
 "Reconsidering a prior intention is an activity that uses up time and other limited resources" (Bratman, 1992), but determining when goals should be reconsidered ^This impulse exists only for as long as the opportunity exists.
 An essentially irreversible action is one that cannot be reversed in time for the goal to be satisfied in time.
 497 also depletes resources.
 Therefore, in the same way that an heuristic is required to determine when goals should be considered for achievement, a similar mechanism is required to determine what goals should be reconsidered.
 For example, as the deadline of the goal approaches, or if a danger to the satisfaction of that goal is detected after it has been activated, it should be reconsidered.
 When a goal is activated, the alarm management process is not deleted; the effect of activating the goal temporarily mitigates the intensity of the alarm.
 This mitigation effect decays over time, until the alarm will again be triggered and the goal reconsidered.
 When a goal is activated, the agent predicts when it should next consider the goal and this determines the rate of decay of the mitigation.
 In this way, the same alarm heuristic controls both goals to the considered for achievement and goals to be reconsidered.
 A goal that is activated by the agent will mitigate the relevant alarm (e.
g.
 the goal to satisfy an order placed by a customer in the warehouse domain).
 Typically, the goal is activated before the time tmax (figure 2), depending on the threshold.
 The mitigation effect on the alarm will decay at a rate such that the alarm will again trigger around tmax At this point the agent will reconsider the goal.
 If the alarm is not deleted, it is again mitigated until the deadline of the goal {tdi).
 If the goal to satisfy the customer's order is not satisfied and the deadline was correctly predicted, there may be no option other than to delete goal and alarm.
^ This is an example of a goal that is no longer relevant to the agent's alarms once the deadline has passed and it is not satisfied (a goal with a firm deadline).
 Other goals may still be relevant after the deadline has passed; they may be even more urgent.
 This type of deadline represents the time at which the agent would like the goal to be satisfied, not the time at which it must be satisfied: a soft rather than a firm deadline.
® A goal with a soft deadline will continue to be reconsidered periodically until it is satisfied, or the agent decides to delete the alarm for other reasons.
 Managing uncertainty A planning agent can never know for sure how long it will take to satisfy a goal.
 If the agent underestimates this time, it may wait too long before acting on the goal and the goal may never be satisfied in time.
 This is a potential source of error in the alarm heuristic.
 This period of time can only be known once the goal has been successfully achieved.
 Therefore, any mechanism for the scheduling of multiple goals may suffer from such errors.
 This variable (Aa< (figure 2)) is defined by the time period that the agent will allow for that goal to be satisfied.
 In fact, such rulesofthumb are common in decision making.
 For example, if I intend to travel from one part of London to another, I would simply allow an hour for the journey.
 However, if I do not know where I must travel to in the process of satisfying m y intention, the importance that I Intensity Alarm to satisfy customer Alarm to restock warehouse Threshold 0.
8 0.
6 50 Time Figure 3: Example.
 ^The deletion of a goal may have effects on other parts of the agent; this change in internal state may subsequently cause other alarms to be generated or modified.
 *The term hard deadline is avoided; this is only relevant for an agent interacting with a realtime process.
 give to satisfying that goal will govern how much time I shall allocate to the goal, and hence how far I could travel.
 For the same reason, the time commitments made by the agent in the process of planning cannot necessarily be determined.
 For example, the duration of the action to travel from point A to point B can only be determined when both these variables are bound.
 The agent may need to plan to seek further information before this can be done.
 Again time is allocated to these actions.
 Extended example Consider an agent that is designed to manage a warehouse.
 This agent will have various influences on its behaviour including satisfying orders placed by customers, maintaining the levels of stock in the warehouse, ensuring the agent has sufficient energy reserves to act on its intentions, etc.
 Figure 3 illustrates the behaviour of two alarms in a particular circumstance.
 These alarms encapsulate the goals to have satisfied an order placed by a customer, and to have restocked the warehouse with a certain commodity.
 (The time axis has been normalised for clarity.
) At time t=0, the intensity of the alarm encapsulating the goal to have satisfied the customer exists, but is at zero until t=5 denoting that it is not sensible for the agent to act before this time.
 This may be due to the order containing commodities that will perish if kept in the unfavourable conditions of the loading bay (e.
g.
 frozen food).
 After this time (the delay time), the intensity linearly increases until time t=20.
 At this point, the agent detects that the customer has arrived earlier that expected.
 This constitutes a danger to the satisfaction of the goal, and so the intensity immediately increases above the threshold.
 The agent's attention is directed towards this goal, it determines that it should act, and therefore activates 498 the goal to have satisfied the customer.
 The activation of this goal causes the respective alarm to be mitigated.
 This mitigation decays over time until (at about time t=40) the intensity of the alarm has again increased to the threshold, and the alien tion of the agent is directed towards reconsidering the goal.
 At this point the agent recognises that at some time between t=20 and t=40, the goal was satisfied, and so the alarm is deleted.
 At time t=20, the goal to have satisfied the customer's order is activated.
 It is important that the agent focuses a large amount of its attention towards satisfying this goal; the goal is very urgent and quite important.
 As the activity of the agent increases, so does the threshold.
 At time t=38, the agent has satisfied the goal, its activity decreases, and so does the threshold.
 The alarm to restock the warehouse encapsulates a goal that was generated through a replenishment process.
 The intensity of this alarm increases to maximum (in this case the potential of the alarm is 1) at around time t=35.
 However, because the agent is acting on the urgent goal to have satisfied the customer, the sensitivity of the agent to new goals is reduced.
 The alarm does not trigger the attention of the agent until some time later.
 At time t=50, the threshold has reduced sufficiently for the attention of the agent to be directed towards considering restocking the warehouse.
 The goal is activated, and the alarm mitigated in the usual way.
 Conclusion An heuristic goal management mechanism has been presented: alarms.
 Alarms serve to focus an agent's attention on the most salient goals at any one time.
 This concentrates planning and reasoning effort and avoids unnecessary distractions.
 Modern planning methods can then be employed to effectiveness in the search for solutions to the given problems (the active goals).
 The focus is continually updated as the situation changes, and limited through manipulation of the threshold.
 Additionally, goals generated through two distinctive and important types of process have been considered: DGoals and RGoals.
 Goals created through both these processes are effectively managed within the same alarms mechanism.
 Acknowledgements Maria Fox, Mike Luck and Vijaya Norman gave helpful comments, as did two anonymous reviewers.
 References Agre, P.
 & Chapman, D.
 (1987).
 Pengi: An implementation of a theory of activity.
 In Proceedings of the Sixth National Conference on Artificial Intelligence (pp.
 268272).
 Beaudoin, L.
P.
 (1994).
 Goal processing in autonomous agents.
 Doctoral thesis, School of Computer Science, University of Birmingham.
 Beaudoin, L.
P & Sloman, A.
 (1993).
 A study of motive processing and attention.
 In Prospects for Artificial Intelligence: Proceedings ofAISB93 (pp.
 229238).
 Bratman, M.
E.
, Israel, D.
J.
 & Pollack, M.
A.
 (1988).
 Plans and resourcebounded practical reasoning.
 Computational Intelligence, 4(4):349355.
 Bratman, M.
E.
 (1992).
 Planning and the stability of intention.
 Minds and Machines, 2(1): 116.
 Brooks, R.
A.
 (1986).
 A robust layered control system for a mobile robot.
 IEEE Journal of Robotics and Automation, 2:1423.
 Carbonell, J.
G.
 (1982).
 Where do goals come from? In Proceedings of the Fourth Annual Conference of the Cognitive Science Society (pp.
 191194).
 Castelfranchi, C.
 (1995).
 Guarantees for autonomy in cognitive agent architecture.
 In M.
J.
 Wooldridge & N.
R.
 Jennings (Eds.
), Intelligent agents (pp.
 5670).
 Volume 890 of Lecture Notes in Artificial Intelligence.
 SpringerVerlag.
 Georgeff, M.
P.
 & Lansky, A.
L.
 (1987).
 Reactive reasoning and planning.
 In Proceedings of the Sixth National Conference on Artificial Intelligence (pp.
 677681).
 HayesRoth, B.
 (1995).
 An architecture for adaptive intelligent systems.
 Artificial Intelligence, 72:329365.
 Long, D.
P.
 & Fox, M.
 (1995).
 A hybrid architecture for rational agents.
 In S.
 Torrance & C.
 Thornton (Eds.
), Hybrid models of cognition.
 AISB.
 Luck, M.
M.
 & d'Inverno, M.
 (1995).
 Agency and autonomy: A formal framework.
 Tech.
 Rep.
 CSRR276.
 University of Warwick, Department of Computer Science.
 McDermott, D.
 (1982).
 A temporal logic for reasoning about processes and plans.
 Cognitive Science, 6:101155.
 Norman, T.
J.
 & Long, D.
P.
 (1995).
 Goal creation in motivated agents.
 In M.
J.
 Wooldridge & N.
R.
 Jennings (Eds.
), Intelligent agents (pp.
 277290).
 Volume 890 of Lecture Notes in Artificial Intelligence.
 SpringerVerlag.
 Ortony, A.
, Clore, G.
L.
 & Collins, A.
 (1988).
 The cognitive structure of emotions.
 Cambridge University Press.
 Schank, R.
C.
 & Abelson, R.
P (1977).
 Scripts, Plans, Goals, and Understanding.
 Laurence Erlbaum Associates.
 Simon, H.
A.
 (1957).
 Models of man: social and rational.
 John Wiley.
 Simon, H.
A.
 (1967).
 Motivational and emotional controls of cognition.
 Psychological Review, 74:2939.
 Sloman, A.
 (1987).
 Motives, mechanisms, and emotions.
 Cognition and Emotion, l(3):217233.
 Wilensky, R.
 {\9%'i) Planning and understanding: A computational approach to human reasoning.
 AddisonWesley.
 499 Developing User ModelBased Intelligent Agents Alonso H.
 Vera and Julio K.
 Rosenblatt Hughes Research Labs 3011 Malibu Canyon Road MaUbu, CA 90265 vera@hkucc.
hku.
hk, jkr@cmu.
edu Abstract We describe a GOMS model of a shipboard Radar Operator's behavior while monitoring air and sea traffic.
 G O M S is a technique that has been successfully used in HumanComputer Interaction to generate engineering models of human performance.
 Based on the G O M S model developed, we identified those portions of the task where an intelligent agent would be most able to assist operators in the performance of their duties, and the nature of the knowledge that will be required for the task.
 W e present the results of a simulated execution of the model in a sample scenario, which predicted the operator's responses with a high degree of accuracy.
 I n t r o d u c t i o n Our goal is to determine the domain knowledge required to implement an intelligent agent which assists a human user in performing a computerbased task.
 A central characteristic of intelligent behavior is that it is purposeful, i.
e.
, the agent is executing a task in order to achieve a goal.
 Consequently, to help a user accompUsh a goal, an intelhgent agent must have knowledge about that goal.
 G O M S is a technique that has been used in the study of humancomputer interaction to model user knowledge and behavior at various levels of description.
 W e investigate here h o w G O M S models may be used by intelligent agents as a means of understanding the actions of other agents and users so that it may interact and cooperate with them in a consistent and helpful manner.
 A G O M S model consists of a set of Goals, Operators, Methods, and Selection rules necessary to accomplish a particular task.
 A hierarchy of goals is created, and within that hierarchy a set of methods provide a functional description of a task.
 Selection rules distinguish between various operational cases and account for the idiosyncrasies of individual users.
 Operators provide a low level description of the actions finally performed.
 Thus, G O M S provides a uniform strucmre for representing the intentional, functional, and implementational levels of behavior.
 A G O M S model of a particular task might be used by an intelligent agent to understand the task at hand and the current state within that task.
 Acting alone, the agent can use the model to decide the next action; acting as an assistant, the agent can use the model to understand what other the user is doing and tailor its actions and recommendations appropriately.
 In this paper w e describe a G O M S model of Radar Operators monitoring air and sea traffic on board a ship.
 The task is very interactive, between the operator and other members of the crew, as well as between the operator and the radar console itself.
 The work presented here uses a methodology that was originally developed to address routine expert behavior on noninteractive tasks; recent work has indicated that this methodology yields excellent results when applied to interactive tasks as well (John, Vera and Newell, 1994; Gray, John and Atwood, 1993; Endestad and Meyer, 1993).
 Our study of the Radar Operator's task shows that it has a large amount of routine content, even when things get busy.
 A Model of a Radar Operator We have created a model of the radar operation task by decomposing the Radar Operator's actions into goals, operators, methods, and selection rules (GOMS) as first proposed by Card, Moran and Newell (1982).
 A G O M S model begins with the concept of a toplevel goal which the user seeks to achieve, and a series of unit tasks that the user performs repeatedly until there are no tasks left.
 The classic example is that of a typist using a wordprocessor to make corrections that have been marked on a printed copy of a manuscript; the toplevel goal is to edit the onhne version of the manuscript, and the unit task is simply to make the next correction (Card et al, 1982).
 W e have written the G O M S model using N G O M S L , or Natural G O M S Language, (Kieras, 1988; 1994).
 It takes the basic precepts of G O M S and defines a programming language based on those ideas, allowing creation of a model where flow of control is clearly specified and which in principle could be run on a computer; indeed, a compiler is currently being written for that purpose.
 The process of fully specifying the Radar Operator's decisions and actions guided us to create a model that is complete ar.
d accurate to the level of detail in which it is specified, and aided us in the task of knowledge acquisition as well; it also pointed out those places where there were gaps or inconsistencies in our knowledge of the domain.
 500 mailto:vera@hkucc.
hku.
hkmailto:jkr@cmu.
eduStructure of the M o d e l One of the first and most basic decisions that liad to be made was how to define the unit task for the Radar Operator; the organization of the toplevel goal and the unit task would affect the entire structure of our G O M S model.
 In the case of text editing, the structure was easily defmed by making each marked correction a unit task.
 The analogous decomposition in our domain would be to define the unit task as tracking each object on the radar saeen.
 However, one obvious reason that such a scheme could neither model the Radar Operator's behavior accurately nor provide a reasonable framework for defming a system is that the task of tracking an object has no welldefined end; the task might never be completed and all other radar contacts would be ignored as a result.
 In addition, the Radar Operators must also receive and respond to orders which may arrive at any time, so they must be incorporated into the definition of a unit task as well.
 In search of a better definition of the unit task, we turned to the training manual used by the Radar Operators (Operations Specialist Training Manual), where we found this statement: "Information handhng comprises five major functions gathering, processing, displaying, evaluating, and disseminating information and orders.
" W e attempted to use these five functions for our unit task structure, but our efforts were complicated by another emergent task structure; as we examined a sample Radar Operator scenario, it became apparent that the Radar Operator went through various stages of identification for each new contact: establishing tentative track, air or surface, conmiercial or military, friendly or hostile, and so on.
 The challenge was to create a goal structure that persisted in the incremental acquisition of knowledge about a given tracked object while still providing reactiveness to new information and situations and as they developed.
 The manual continues, "All information handling must be considered a continuous and growing process that ultimately furnishes a composite picture of a situation, enabling the commanding officer to make a fmal evaluation and give orders for action.
" The solution we ultimately decided upon was to select a contact, determine which stage of identification should be performed next, and go through the steps of gathering, processing, displaying, evaluating, and disseminating information on this fine grained unit task.
 Once done with a particular stage of the identification process on a particular contact, the model returns to the toplevel, where new orders may be received and acted upon or a task that has become more urgent may be selected for execution.
 As in John and Vera (1992), a relatively shallow goal stack and carefully designed set of selection rules was used to make the model reactive to external changes.
 The resulting goal and method hierarchy for the intentional and functional levels of the task is shown in Figure 1.
 K n o w l e d g e C o n t e n t of the M o d e l As can be seen in Figure 1, there are three sets of selection rules in our G O M S model.
 These correspond to points in the execution of a unit task where a decision must be made as to how to proceed because there are multiple methods to accomplish a goal.
 The first selection rule, Select Next Task, simply chooses the Execute Order method if a new order has been received, otherwise the method for Monitor Radar Contacts is selected.
 If an order is to be executed, Execute Ordered Task selects the method that is ̂ propriate for carrying out that order.
 If no order has been received, then the Execute Unit Task selection rule must decide, for a given contact, which is the appropriate subtask; this depends on what information has already been gathered about that contact, which is reflected by the current label assigned to it.
 The corresponding selection rule, written in N G O M S L , is as follows: Selection rule set for goal: Execute Unit Task If <contactlabel> is N e w and contact is under local control, then accomplish goal: Establish Tentative Track.
 If <contactlabel> is Tentative Track and contact is under local control, then accomplish goal: Establish Air or Surface.
 If <contactlabel> is Unknown and contact is under local control, then accomplish goal: Establish Friend or Foe.
 If <contactlabel> is not Tentative Track or Unknown and contact is under local control, then accomplish goal: Update Contact Information.
 If contact is not under local control, then accompUsh goal: Update Contact Information.
 Return with goal accomplished.
 This selection rule uses perceptual information that is available to the Radar Operator, in order to choose the appropriate method.
 This is true of the other two sets of selection rules as well.
 Very little beyond the ability to understand symbols and orders is encapsulated in the selection rules.
 The Radar Operator's knowledge is contained in the methods of the model.
 Within the G O M S model of a Radar Operator, the goal hierarchy captures the structure of the decisionmaking process involved; its topology reflects knowledge of the nature of the task and the control knowledge needed to carry it out.
 The detailed knowledge which makes these decisions and the achievement of goals possible is embedded in the methods of the model.
 For example, the EstabUsh Air or Surface method describes the steps that are taken to achieve that goal, including the specific steps the Radar Operator must take to make the determination: Method for goal: Establish Air or Surface Step 1.
 Accomplish goal: Gather and Process Movement Information.
 501 OOP \ i .
 A Figure 1.
 Radar G O M S Goal Hierarchy 502 Step 2.
 Decide: If contact is not a track, then remove tentative track and return with goal accomplished Step 3.
 Decide: If contact type is determined to be Air.
 then Accomplish goal of: Display Contact Information Unknown Air.
 If contact type is determined to be Surface, then Accomplish goal of: Display Contact Information Unknown Surface.
 If contact type is not determined, then return with goal accomplished.
 Step 4.
 Accomplish goal: Evaluate and Disseminate Information.
 Step 5.
 Return with goal accomplished.
 The implementational (or keystroke) level is created by further decomposing the structure of the task into primitive operators, such as reading text, pointing and chcking the mouse, etc.
 For example, the first step in the Establish Air or Surface method is to invoke the subgoal Gather and Process Movement Information, implemented by the following method whose steps consist of operators that are not analyzed further: Method for goal: Gather and Process Movement Information Step 1.
 Decide: If contact is under local control, then perform position correction.
 Step 2.
 Read contact information.
 Step 3.
 Decide: If C P A needs to be evaluated, then compute contact CPA.
 Step 4.
 Process contact information.
 Step 5.
 Return with goal accomplished.
 Reactivity of the GOMS Model When developing a model of a dynamic, realworld task, it is of critical importance to capture and retain the qualities that allow humans to perform the task as well as they do.
 One of the key characteristics of human performance in this task is reactivity.
 The operators in the scenario are able to quickly react to new contacts and respond to new orders.
 They can stop whatever task they are doing, begin a new one, execute it, and r e m m to the original task.
 The G O M S model presented here must be able to reproduce this reactivity in a natural way that results in sequences of behaviors like those of the operators in the scenario.
 The G O M S model of the operator derives its reactivity from the organization of its methods and selection rules.
 At any given moment in the model's behavior, the goal stack is relatively shallow because there are very few chained methods that get called as a sequence.
 Reactivity is not achieved by forcing the model to check for changes in the world (e.
g.
, new orders or contacts) within each method, but instead by returning to the toplevel goal after completing a portion of prioritized subtasks.
 The toplevel method can then check for changes in the world.
 Avoiding long Unked sequence of methods allows the model to check for important changes in its environment in a way that does not overload workmg memory nor unnecessarily interrupt routine behaviors.
 The model was designed in such a way as to simulate the operator's sequence of contactidentifying behaviors while remaining sensitive to changes that affect its goal prioritization.
 It is thus able to combine the routine collection of information about contacts, detecting new targets, and executing orders in a cognitively plausible way.
 Using Predictive Models for AgentAssisted D e c i s i o n  M a k i n g The goal hierarchy of the GOMS model captures the structure of the decisionmaking process involved in performing the task; its topology reflects knowledge of the nature of the task and the control knowledge needed to carry it out.
 Additional knowledge which makes these decisions and the achievement of goals possible is embedded in the methods of the model.
 W e propose that an intelUgent agent must embody, at least in part, a model of the user, and that G O M S models provide a suitable structure for this purpose.
 The G O M S model described here indicates that there are at least three places where the user performs complex cognitive operations that might be assisted by an intelligent agent: evaluation of contact information, selection of most relevant contact, and checking of contact identity.
 These are parts of the operator's task that require decisionmaking based on both the current situation and experiencebased knowledge.
 These cases represent those aspects of the task where an intelligent agent, armed with a model of the operator's knowledge and behavior, can make significant contributions by knowing the current goal of the operator.
 A G O M S model provides a dynamic representation of users' goals, knowledge, and priorities, as well as their behavior.
 At any given point in the problemsolving process, there exists the current goal stack; associated with each goal is a method for achieving that goal, consisting of a series of primitive perceptual, cognitive, and motor operators that are to be executed.
 Using this knowledge, the intelligent agent can anticipate the information the operator will require to accomplish his goals, present that information in a useful form, and recommend actions based the information.
 Furthermore, the agent may use its model of the operator's knowledge to determine what task the operator is currently performing.
 If the operator diverges from the behavior predicted by the model, the agent will try to map the new behavior onto the model.
 The agent can then assess whether the operator's divergent behavior is warranted by the current situation.
 If it is not, the agent can recommend alternative courses of action that the operator should follow.
 If the operator's behavior is warranted by the situation, then the agent can update its location on the model to continue assisting the operator on the appropriate task.
 503 When selecting the next task to be performed, the agent can estimate the priority of processed information in order to focus the radar operator's attention on the most significant and urgent developments and to adapt to the operator's priorities when they diverge from those predicted by the model.
 As the operator evaluates new information, the agent must update its model of the operator's beliefs.
 The agent can anticipate the information the operator will require to accomplish her goals, present that information in a useful form, and recommend actions based the information.
 Monitoring Working Memory Load Due to their procedural nature, GOMS models also provide the means to predict a user's working memory load.
 At any given point in die problemsolving process, there exists the current goal stack; associated widi each goal is a method for achieving that goal, and each method expliciUy states what information it accesses and must therefore be stored in working memory for the duration of that method's execution.
 For example, referring to the model shown in Figure 1, the operator begins execution of the Operate Radar Station method, where she must retain whether or not a new order has been received, and if so what that order is.
 Within the selection rule Select Next Task, the operator must then choose which task she will perform next, and remember that information, and so on.
 Table 1 shows a trace of which variables are retained within each method, and the total working memory load at that point in the goal stack.
 Table 1: Working Memory Load during task execution.
 Method/Rule Variable; Retained _WM Operate Radar Station (order = nil) 0 Select Next Task none 0 Monitor Radar Contacts target_contact = Casper 1 Move to Target Contact contact_label = Unknown 2 Execute Unit Task none 2 Establish Friend or Foe none 2 Gather and Process M o v e m e n t Information Display Contact Information < n e w Iabel> bearing = 24.
5 range = 32 altitude = 30,000 speed = 500 heading = 69.
3 <new_label = Hostile> (contact_label = Hostile) Evaluate and Disseminate none 7 In the present scenario, the operator may often be in a situation where her working memory is overloaded.
 For example, if there are many new contacts as well as orders to be executed, the operator may not be able to retain the necessary sequence of behaviors.
 Using the model to evaluate situations where the operator's working memory capacity might be overwhelmed, it is possible to predict when behavior may deviate from what is expected, and to determine when an agent can be most effectively assisted.
 Comparison of Predicted versus Actual R a d a r O p e r a t o r Behavior A simulated execution of the GOMS model was conducted on a test scenario; this resulted in a sequence of behaviors that the model would perform if it were operating the radar station.
 W e then compared this sequence of behaviors with that of the operators in the scenario.
 Table 2 summarizes the results of this analysis.
 Table 2: Sunmiary of Comparison Between Model and Operator Behavior MODEL Match Miss X Match < Z u U Miss 54 107 4 N A T=58 T=161 There were 58 distinct operator behaviors described in the original scenario.
 The model generated a total of 161 behaviors in total and matched 54 of the 58 operator behaviors.
 In order to be considered matching, the model must generate not only the same behaviors as the operator, but it must also do so in the same order.
 Model behaviors that occurred out of order were counted as mismatches.
 Of the 4 operator behaviors that were not matched by the model, 2 of them were behaviors that the model performed implicitly.
 That is, the model, as we built it, did not explicitly perform these actions as independent methods, but instead had them built in to other methods.
 This was not an important design decision on out part but simply the consequence of the granularity level chosen for these methods.
 Of the other two actions that were not accounted for, one involved changing the type of radar used and simply was not included in our model, and the other involved a nonroutine reporting of information.
 Discounting the behaviors performed implicitly by the model, only 2 (3.
5%) of the operator's behaviors were not matched by the model.
 The model generated 107 behaviors in addition to the 54 that matched those of the operator.
 Although this is a large number of extra behaviors, a case by case analysis shows that 104 of Uiem are behaviors that are implicit in the scenario.
 That is, they are behaviors that were necessarily performed by the operator, but that were not exphcitly described in the scenario.
 For example, when the model selects a new contact to establish a Tentative 504 Track, it must necessarily execute an intermediate method of moving to the contact and then hooking it.
 The operator must also perform this sequence of behaviors, but the full set of steps is not explicitly described in tlic scenario.
 The remaining 3 behaviors produced by the model that were neither matches nor implicit in the scenario were behaviors that probably shoiild have been done by the operator but were left out because of time or memory constraints.
 As discussed, the G O M S model provides a measure of working memory usage that can be used to better predict the mental states of an agent by taking these constraints into account.
 Steps within methods that are not strictly necessary can be noted as optional, so that nondeterministic behavior may be accounted for.
 Overall, only 3 out of 161 (less than 2%) behaviors generated by the model were neither matches nor implicit when compared to the operator's behavior in the scenario.
 The model predicted 96.
5% of the operator's behaviors.
 Furthermore 9 8 % of the behaviors generated by the model were either expUcitly or implicitly present in the scenario.
 These results indicate that the model is successfully simulating the operator's behavior and therefore capturing the knowledge required to perform the task.
 Conclusion Using the GOMS methodology for analysis of humancomputer interaction, we have developed a model of a Radar Operator's goals, and the methods that used to accomplish them.
 A simulated execution of the model in a test scenario predicted the operator's responses with a high degree of accuracy, and furthermore provided details of those actions that were not explicitly stated in the scenario description.
 Based on this model, we were able to identify those portions of the task where an intelligent agent would be most able to assist the operator and to describe the nature of the knowledge required for the task.
 By creating a knowledgelevel description of a task (Newell, 1982), G O M S models provide the means to predict users' goals, beliefs, priorities, and, therefore, their actions.
 When the user's actual behavior departs from what the model has predicted, the agent may inform the user of the unexpected actions and reconunend an alternate course of action.
 If the operator's behavior is warranted by the situation, then the agent can update its model or its parameters so that the agent may continue assisting the operator on the appropriate task.
 Acknowledgements This work was conducted while both authors were at Hughes Research Labs, sponsored by the Information Sciences Laboratory at HRJL under the guidance of Mike Daily and David Payton.
 A.
 Vera is currently at The University of Hong Kong and J.
 Rosenblatt is at Carnegie Mellon University.
 The opinions expressed in this paper are those of the authors and not necessarily those of Hughes.
 References Card, S.
 K.
, Moran, T.
 P.
, and Newell, A.
 (1983).
 The psychology of humancomputer interaction.
 Lawrence Eribaum, Associates, Hillsdale, NJ.
 Endestad,T.
 & Meyer, P.
 (1993).
 G O M S analysis as an evaluation tool in process control: An evaluation of the ISACS1 prototype and the C O P M A system.
 Technical Report HWR349, OECD Halden Reactor Project, Instituut for Energiteknikk, Halden, Norway.
 Gray, W.
 D.
, John, B.
 E.
 & Atwood, M.
 E.
 (1993).
 Project Ernestine: A validation of G O M S for prediction and explanation of realworld task performance.
 Human Computer Interaction, 8, 3, pp.
 209237.
 John, B.
 E.
 & Vera, A.
 H.
 (1992).
 A G O M S analysis for a graphic, machinepaced, highly interactive task.
 In Proceedings of CHI (Monterey, May 37, 1992) ACM, NewYork,po.
 251258.
 John, B.
 E.
, Vera, A.
 H.
 and NeweU, A.
 (1994).
 Toward real time GOMS: A model of expert behavior in a highly interactive task.
 Behaviour and Information Technology, 13, 4, pp.
 255267.
 Kieras, D.
 E.
 (1988).
 Towards a practical G O M S model methodology for user interface design.
 In M.
 Helander (Ed.
), Handbook of HumanComputer Interaction (pp.
 135158).
 Amsterdam: NorthHolland Elsevier.
 Kieras, D.
 (1994).
 G O M S ModeUng of User Interfaces Using NGOMSL.
 Tutorial Notes, CHI Conference on Human Factors in Computing Systems, Boston, MA, April 2428.
 Newell, A.
 (1982).
 The knowledge level.
 Artificial Intelligence, 18, 87127.
 Operations Speciahst 3 & 2, Vol.
 1, Navy Training Manual.
 505 C o m p o n e n t s of D y n a m i c Skill Acquisition Frank J.
 Lee Deparlmeni of Psychology Carnegie Mellon University Pittsburgh, PA 15213 fjl@cmu.
edu John R.
 Anderson Deparlmeni of Psychology Carnegie Mellon University Pittsburgh, PA 15213 jaQcmu.
edu Michael P.
 Matessa Department of Psychology Carnegie Mellon University Pittsburgh, PA 15213 matessaScmu.
edu Abstract In this paper, we examine the components of dynamic skill acquisition using a data set collected by Ackerman (1988) with the KanferAckerman AirTraffic Controller Task©.
 Our analysis indicates that subjects arc improving in both the strategies they use to solve the task and the speed with which they execute the task.
 One strategy that subjects develop reduces the number of oven actions required lo land a plane.
 Another strategy that subjects develop enables them to land more planes simultaneously.
 A satisfactory model of this task must include both an improved strategic component and an improved speed component.
 The ACTR theory (Anderson, 1993) is well suited to model these components as it is able lo separately learn over trials which strategies are better and how to execute each more efficiently.
 Keywords: Dynamic skill acquisition.
 Cognitive models of problem solving, Strategy learning Introduction Thought and action in the real world are embedded in dynamic environments, but past research in problem solving and skill acquisition has focused primarily on tasks in static environments.
 In sialic tasks, changes in the problem slate can only occur through people's actions, while in dynamic tasks, changes can occur independent of people's actions.
 A n example of a static task is the Tower of Hanoi puzzle, where disks of different sizes must be moved from one peg to another according to simple rules.
 In this task, the disks move only if a person moves them.
 Driving, on the other hand, is a dynamic task: between any two consecutive actions in driving (e.
g.
 turning the steering wheel and stepping on the accelerator), changes in the problem slate, such as a decrease in fuel or a dog running in front of the car, occur independently of the driver's actions.
 W e have gained important insights from previous resciirch in static task domains.
 The legacy of past problem solving research in static task domains includes, the identification of search heuristics in problem solving (Newell & Simon, 1972), the discovery of the differences between novices and experts in problem solving in physics (Chi, Glascr, & Rces, 1982; Larkin, McDcrmotl, Simon, & Simon, 1980) and in programming (Anderson, Corbcti, & Conrad, 1984), and the isolation and the quantification of the elements of skill transfer (Singley & Anderson, 1989).
 However, to completely understand and appreciate the domain of problem solving and skill acquisition, w e must extend our investigations to dynamic tasks.
 The KanferAckerman Air Traffic Controller©^ (ATC) task is an ideal vehicle for studying dynamic skill acquisition.
 It simulates dynamic aspects of real air traffic control (e.
g.
, planes lose fuel and weather conditions change), yet is simple enough to be tractable for study.
 In addition, Ackerman (1994) has collected data from over 35(X) subjects on the A T C utsk and has made them available on a C D  R O M (Ackerman & Kanfer, 1994) to the Office of Naval Research (ONR).
 O N R intends lo use this task as a leslbed to compare a number of cognitive architectures including our own, A C T  R (Anderson, 1993).
 Ackerman has extensively analyzed the predictive measures of performance in the A T C task using a battery of psychological tests that measure cognitive, perceptualmotor, and psychomotor ability (Ackerman, 1988, 1990).
 Ackerman found that while cognitive ability best predicts performance in early trials, psychomotor ability best predicts performance in later uials.
̂  W e take a different approach to the study of dynamic skill acquisition.
 Instead of looking in from the ouLside  that is, instead of using taskexternal tests to predict individual performance in the A T C task we propose to go inside and see what subjects are actually doing in order to illuminate the components of dynamic skill acquisition in the A T C task.
 In this paper, we use a data set from Ackerman's study (study #6 in the KanferAckerman C D  R O M , as published in Ackerman, 1988) to examine the cognitive components of dynamic skill acquisition in the A T C task.
 W e will briefly review the A T C task.
 W e will then analyze the role of strategies and speed in the A T C task through correlational and regression analyses of different variables.
 W e argue that, even after taking subjects' increase in motor speed into consideration, their suaiegy use contributes significantly lo performance.
 The Air Traffic Controller Task The A T C task is composed of the following elements displayed on the screen (see Figure 1): (a) 12 hold pattern ^KanfcrAckcrman Air Traffic Controller Task© program is copyrighted software by Ruth Kanfer, Phillip L.
 Ackerman, and Kim A.
 Pearson, University of Minnesota.
 ^Ackerman has used multiple measures to gauge performance, including cumulative score, number of planes landed, number of errors made, and reaction time to wind change.
 506 mailto:fjl@cmu.
eduFLTI 342 14B 692 42B > 259 840 190 TYPE DCIO 727 747 prop 727 prop DCIO w II iiiiii IIII nil II w II n u l l II iiiiiiii FOEL 5 6 4 * 3 4 4 5 II II II 1 POS.
 3 n 3 a 3 • 3 w 2 n 2 • 2 • 2 w 1 n 1 a 1 • 1 w a n a «2 • «3 • H Scor« 380 Landing Pta: 350 Panalty Pta: 20 Runwaya : DRY Hind 020 Icnota from SOUTH rlta In Quaua: <F1> to accept Winda from South Figure 1.
 The Air Traffic Controller task.
 (Note: This figure is a reconstructed representation of the KanfcrAciccrman A T C task.
) positions, (b) 4 runways, numbered 1 through 4, (c) feedback information on subject's current score and penally, conditions of the runways, wind direction and speed, (d) a queue stack with planes wailing to enter the hold paliem, and (e) 2 message windows, one for notifying of weather changes (shown) and one for providing feedback on errors (not shown).
 The 12 hold pattern positions are divided into 3 levels corresponding to altitude, with hold level 3 being the highest and hold level 1 being the lowest.
 Six rules govern this task: (1) Planes must land into the wind, (2) Planes can only land from hold level 1, (3) Planes can only move one hold level at a time, but to any open position in that level, (4) Ground conditions and wind speed determine the runway length required by different plane types (747's always require long runways, DClO's can use short runways only when runways are dry or wet, and wind speed is less than 40 knots, 727's can use short runways only when the runways are dry or wind speed is 020 knots, and PROP'S can always use short runways), (5) Planes with less than 3 minutes of fuel left must be landed immediately, and (6) Only one plane at a time can occupy a runway.
 A weather change occurs approximately every 30 seconds; planes enter into the queue approximately every 7 seconds.
 Three principal actions are used in this task: (1) accept planes from the queue into a hold pattern, (2) move planes within the three hold levels, and (3) land planes on a runway.
 All three actions can be accomplished by using the four keys: T, i, Fl, and J.
 The T and i keys move the cursor up and down between the different hold positions and runways, and the Fl key accepts the planes from the queue into a holding pattern.
 The J key can select a plane in the hold, place a selected plane (cither from the queue or from another hold position) into an empty hold position, or land a plane on the runway.
 A subject's cumulative score is calculated as follows: a) 50 points for landing a plane, b) minus 100 points for crashing a plane, c) minus 10 points for violating one of the six rules that govern the task.
 M e t h o d a n d Analysis W e used data from 58 subjects in Ackerman's (1988) study.
 W e excluded data from 5 subjects who had not completed at least eighteen (10minute) trials and data from 2 subjects due to an error during their decompression from the KanferAckcrman C D  R O M (Ackerman & Kanfer, 1994).
 W e used cumulative score (Score) as dependent measure of performance.
 Figure 2 plots mean score and standard deviation of the 58 subjects across trials.
 4000 3000mean AT ^AAA^.
^.
^.
^.
^.
^.
.
^.
^.
^.
^ I I I I I I I I I I I I I I trials Figure 2: M e a n Score and standard deviation.
 As can be seen in Figure 2, subjects' cumulative scores grew from almost nothing in the first 10minute block to an average of over 3000 points in the last block, while the 507 standard deviation tended to decrease, indicating a reduction in intersubject variability.
 The increase in Score closely follows a power function: f(x) = 2024.
04 f 2791.
40 * x241, with r2=: .
954.
 T o help understand the basis for this improvement, w e looked at strategy change over trials.
 O n e strategy that many subjects developed, which w e call the hold 1 strategy, involved bringing planes directly into hold level 1, thereby skipping hold levels 2 and 3.
 O n average, 6 keystrokes (1 J key to select a plane, 4 4 keys to mo v e down to the next level, and 1 J key to place the plane) are needed to move a plane d o w n one hold level.
 If w e assume that the average number of keystrokes to land a plane from hold level 1 is equal to C, then the average number of keystrokes needed to land a plane from hold levels 1, 2, and 3 are C, C i 6, and C + 12, respectively.
 By bringing planes directly into the hold level 1 from the queue, subjects eliminate the need to use 6 to 12 additional keysuokes per plane.
 Using this strategy therefore increased subjects' keystroke efficiency by reducing the number of keystrokes needed to land a plane.
 W e measured hold 1 strategy as the percentage of planes brought directly from the queue into hold level 1.
 Figure 3 plots mean hold 1 strategy use and standard deviation for the 58 subjects across trials.
 A s can be seen, hold 1 strategy increases over the first half of the experiment and then asymptotes.
 However, variability in the hold 1 strategy remains high, indicating that hold 1 strategy is an important source of individual differences.
 0.
55 5 0.
45^ .
 ^ a a ^ a a ^ a "2 0.
35mean 0.
25I I I I I I I I I I I I II I I II trials Figure 3: Mean hold 1 strategy and standard deviation.
 Another strategy that many subjects used involved maximizing the number of planes landing simultaneously.
 A special opportunity for this occurs when the wind direction changes.
 This allows subjects to use the runways in a new direction, while planes are still taxiing on runways in the former direction.
 For instance, while landing planes on the northsouth runways, a subject can respond to a change in wind direction to cast or west by landing planes on the eastwest runways.
 These "crossover landings" occur when a subject lands a plane while at least one other plane is occupying an orthogonal runway.
 Crossover landings are possible only if subjects quickly respond to a wind direction change during a brief period after the change.
 W e defined runway efficiency as the percentage of crossover landings achieved by the subjects out of the maximum crossover landings possible within a trial.
 Figure 4 plots mean runway efficiency and standard deviation for the 58 subjects across trials.
 As can be seen, runway efficiency increases throughout the experiment and maintains a fair degree of iniersubject variability.
 0.
8 u c o G 0.
6£ 0.
4 H 0.
2D mean .
aA.
^.
AA^A^^A"^^^ I I I I I I I I I I I I I I I I I I trials Figure 4: Mean runway efficiency and standard deviation.
 We wanted to assess the contribution of these strategy variables to Score, controlling for psychomotor factors.
 W e defined two such psychomotor variables.
 O n e is total keystrokes, the total number of the relevant keys (T, i, Fl, and J ) used per trial.
 The other measure is mean reaction time to orthogonal wind direction change.
^ Figure 5 plots mean total keystrokes and standard deviation, and Figure 6 plots mean R T to wind change and standard deviation for the 58 subjects across trials.
 As can be seen, total keystrokes increased across trials, while maintaining a fair degree of intersubject variability.
 This is to be expected, given high intersubject variability in the use of hold 1 strategy.
 Subjects w h o use hold 1 suategy require fewer keysUokes to achieve performance comparable to that of subjects w h o do not use hold 1 strategy .
 Mean R T to wind change decreased steadily, with a corresponding reduction in intersubject variability.
 Nevertheless, the ratio between the standard deviation and the mean R T to wind change remains relatively constant.
 ^Ackcrman (1988) used mean reaction time to wind change, a.
s the dependent measure of performance.
 However, we chose to use cumulative score as the dependent measure of jjerformance, because that is what subjects are trying to optimize in this task.
 508 1500 1250I 10005002503 750mciin .
.
A .
.
.
.
^.
^.
^AA^AAA^^^'^'^A " L L l ^ i ' ' ' 'I ' I I I I I I I I  <N fl TT V, vo r00 O O  CM ro Tjvo vO r00 trials Figure 5: Mean keystrokes and standard deviation.
 25 E H c •s I 201510mcan 'Aa^ ̂ A A A A A a A a A 0 'l I I I I I I I I I I I I I I I I I — (Nm Tjui\Dr̂  ooo^o—'cs m^ uiso r~oo trials Figure 6; M e a n reaction time to wind change and stiindard deviation.
 Correlations b e t w e e n strategy variables, psychomotor variables, and Score W e examined the Pearson r correlations between the four predictor variables and Score.
 W e used the 18 trials for each of the 58 subjects as data, for a total of 1044 ob.
scrvations.
 Table 1 lists the correlations between the five variables: hold 1 strategy (HS), runway efficiency (RE), total keystrokes (KS), mean R T to wind change (MT), and Score.
 Runway efficiency correlated most strongly with Score, r = .
839, followed by mean R T to wind change, r = .
668.
 In addition, runway efficiency is fairly strongly but negatively correlated with mean R T to wind change, r = .
552, and hold 1 strategy is strongly but negatively correlated with total keystrokes, r = .
604.
 This supports our assertion that hold 1 strategy reduces the number of keys necessary to land a plane.
 By breaking down the eighteen trials into halves (19 and 1018), we see a striking decrease in the correlation between total keystrokes and Score: r dropped from .
575 in the first half of the trials to .
107 in the last half of the trials.
 Table 1: Correlations between Score, hold 1 strategy (HS), runway efficiency (RE), total keystrokes (KS), and mean reaction time to wind change (MT).
 HS RE KS MT Score .
291 .
839 .
492 .
668 HS .
349 .
604 .
178 RE .
316 .
552 KS .
347 These results indicate that while using more keys raised Score in the early trials, it had little impact on Score in the later U'ials.
 If increase in Score was due to an increase in motor speed, one would expect the correlation between total keystrokes and Score to increase with repeated trials.
 The opposite is true, however, which indicates that increase in motor speed, as reflected by total keystrokes and mean R T to wind change, was neither the sole nor the most important determinant of Score.
 Indeed, what best predicted Score was a combination of suatcgy and speed, as reflected by runway efficiency.
 W e explore this issue in more detail in the following regression analyses.
 Regressions with strategy and psychomotor variables as predictors of Score A multiple regression using all four variables to predict Score accounts for 87.
7% of the variance.
 The regression equation with the four variables is: Score = 307 + 1566 HS i 1524 RE i 1.
43 KS  22.
1 MT with the following tratios"^: HS = 25.
31, RE = 22.
57.
 KS = 30.
72, and M T = 10.
68.
 Mean R T to wind change conu^ibulcd the least to this fourvariable model.
 A model using only hold 1 strategy, total keystrokes, and runway efficiency still accounts for 86.
3% of the variance.
 The regression equation with the three variables is: Score =  843 + 1745 HS + 1676 RE i 1.
60 KS with tratios of 27.
80, 24.
11, and 34.
73, respectively.
 Deleting any of the other three predictor variables leads to much bigger reductions in the prediction of Score.
 This indicates that runway efficiency is a better predictor of Score than mean R T to wind change.
 Our analysis indicates that subjects' Score increased with adoption of cither the hold 1 strategy or the multiplelandings strategy, as measured by runway efficiency.
 However, overall speed also contributes to Score, especially All iraiios in ihc regression analyses we present have 1 d.
f.
 and are significant a\ p < .
001.
 509 in the early pari of the experiment.
 In the first half of the experiment, the regression equation is: Score =  1237 + 1862 HS + 1619 RE + 1.
95 KS with tratios of 20.
45, 12.
10, and 28.
09.
 respectively.
 In the second half of the experiment, however, it changes to: Score = 632 + 879 HS + 1873 RE + 0.
764 KS with tratios of 10.
54, 28.
07, and 12.
04, respectively.
 This change indicates the increasing importance of the runway efficiency across trials relative to other factors, such as total keystrokes.
 The multiple runway strategy, as measured by runway efficiency, allowed subjects to have more runways in service at the same time.
 As subjects become more skilled, the length of time required by planes to taxi down runways (15 seconds) became the performancelimiting factor.
 Taxiing time limits the utility of the hold 1 strategy.
 W h e n both runways are in use, the additional resources afforded by hold 1 strategy are wasted.
 Increasing one's key efficiency is irrelevant when both of the runways arc occupied and no additional planes can be landed.
 This is indicated both by the reduction in the importance of hold 1 strategy in the second half of the uials compare to the first in the regression analysis, and by the fact that subjects' use of hold 1 strategy reached an asymptote fairly quickly ai about the fifth trial (Figure 7 plots mean hold 1 suategy use by lowthird and highthird performers).
 A t i^ "^AA.
 A & A A high 3rd low 3rd I I I I I I I I I I I I I II I I trials Figure 7: Hold 1 strategy use of low third and high third subjects as measured by Score.
 Runway efficiency, which measures opportunistic use of the opposing runways during wind change, docs not suffer from this performancelimiting factor.
 This is indicated by the continuing increase in subjects' runway efficiency across trials (Figure 8 plots mean runway efficiency of lowthird and highthird performers).
 o g s 0.
750.
5oi 0.
25high 3rd low 3rd — fSroTjko^or^oooso^rJr^'^'ri^cr^oo trials Figure 8: Runway efficiency of low third and high third subjects as measured by Score.
 As previously noted, Ackerman found that taskexternal measures of individual differences in both cognitive ability and psychomotor speed predicted performance in the A T C ta.
sk.
 He also found that cognitive ability had a stronger effect early in the experiment, while psychomotor skills had larger impact later in the experiment.
 This might seem to contradict the results of our analysis of taskinternal variables (hold 1 strategy, runway efficiency, and total keystrokes), which indicates that keying speed becomes less significant in later trials.
 It is difficult to compare our results with Ackerman's, because Ackerman used mean R T to wind change as the dependent measure for subject performance, while w e use Score.
 One might argue that mean R T to wind change came to reflect psychomotor factors towards the end of the experiment, which explains Ackcrman's conclusion that psychomotor factors best predicted performance.
 However, psychomotor factors themselves cannot be such a significant contributor to Score given the relatively slow rate of planes taxiing on the runway and the invention of the hold 1 strategy, which relieves the need for keystrokes.
 Instead, runway efficiency emerges as an important factor, allowing subjects to turn psychomotor skill into useful actions for increasing Score.
 Discussion Our analysis of the A T C data indicates that skill improved in a complex way across trials in the experiment.
 Subjects improved both in the strategies used to solve the task and in the speed with which they executed the task.
 This indicates that any satisfactory model of this task will have to include both a strategic improvement component and a speed improvement component.
 There are currently many different theories of skill acquisition.
 It is useful to examine some of them in light of the findings presented here.
 W e examine two in particular: Logan's (1988) instance theory of 510 http://ta.
skautomatization and the Soar (Newell & Rosenbloom, 1981, Newell, 1990) chunking theory of learning.
 Logan (1988) proposed a theory of learning based on the idea of retrieving "instances" from memory.
 An instance is composed of the stimulus, subjects' goal during the encounter with the stimulus, their interpretation of the stimulus in relation to the goal, and their response to the stimulus.
 Logan argued that subjects automatically encode and store each encounter with a stimulus as an instance, and retrieve the instance when the stimulus is encountered again.
 In this theory, although skills are initially acquired through algorithmic processing, performance depends increasingly on retrieving past instances of solutions from memory.
 The Soar (Newell & Rosenbloom, 1981; Newell, 1990) theory of learning is based on chunking.
 In this theory, skills are acquired by chunking together productions that successfully solve a problem.
 For example, if subjects encounter an impasse during a problemsolving episode, they can set a subgoal to solve that impasse.
 If they arc successful at finding a solution to the impasse, the individual solution steps taken are then chunked together as a single production.
 When subjects encounters the same situation again, the newly chunked production can be used automatically, eliminating the need to repeat the laborious process of searching for a solution.
 Both theories are capable of explaining why keystroke rate was related to improvement in Score.
 Logan's instance retrieval and Soar's chunking result in less "cognitive time" between actions.
 However, it is unclear how either of these theories could predict the contribution of hold 1 strategy, which requires a reorganization of behaviors and a shift to a strategy that requires a different sequence of keystrokes.
 In addition, subjects do not switch hold strategies (i.
e.
 hold 3, hold 2, and hold 1) in a steplike transition, as Logan's theory and Soar's model would predict.
 Instead, the hold strategies overlap by a fair amount during transition, and in most cases subjects do not completely abandon the use of hold 2 and 3.
 Also, how these theories could explain the important contribution of runway efficiency (multiple runway use through crossover landings) to Score is unclear, since this would depend on the particulars of the initial algorithms used.
 While we have yet to undertake the simulation effort, we think that the ACTR theory is well suited to model these components, since it separately learns over trials which strategies are better and how to execute each strategy more successfully.
 For example, Lovett and Anderson (in press) have shown, in an artificial problem solving task, that subjects learn in both dimensions of strategy and speed.
 In particular, their subjects come to execute the less successful suategy less frequently and yet more rapidly with experience.
 They have modeled these phenomena successfully in ACTR.
 .
 Skill acquisition in the A T C ta.
sk involves a complex interaction between improvements in strategies and improvements in speed.
 W e are currently working on an ACTR model to explain these phenomena, as a first step toward extending the ACTR theory to dynamic skill acquisition.
 Acknowledgments The research reported in this paper was supported by the Office of Naval Research, Cognitive Science Program, under Conuact Number NOOO149510223 to John R.
 Anderson.
 All correspondences should be addressed to Frank J.
 Lee at the Deparunent of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213.
 We would like to thank Karen Adolph, Martha Alibali, Malcolm Bauer, Bonnie John, Lisa Haverty, Adisack Nhouyvanisvong, and Doug Thompson for comments on earlier drafts of this paper.
 In addition, we would especially like to express our gratitude to Marsha Lovett for extensive comments and suggestions on data analysis.
 References Ackerman, P.
L.
 (1988).
 Determinants of individual differences during skill acquisition: Cognitive abilities and information processing.
 Journal of Experimental Psychology: General, 117, 288318.
 Ackerman, P.
L.
 (1990).
 A correlational analysis of skill specificity: Learning, abilities, and individual differences.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 76,883901.
 Ackerman, P.
L.
 & Kanfer, R.
 (1994).
 KanferAckerman Air Traffic Controller Task© C D  R O M Database, Data Collection Program, and Playback Program.
 Office of Naval Research, Cognitive Science Program.
 Anderson, J.
R.
 (1993).
 Rules of the Mind.
 Hillsdale, NJ: Erlbaum.
 Anderson, J.
R.
, Corbett, A.
T.
, & Conrad, F.
 (1984).
 Learning to program in LISP.
 Cognitive Science, 8, 87129.
 Chi, M.
T.
H.
, Glaser, R.
, & Rees, E.
 (1982).
 Expertise in problem solving.
 In R.
J.
 Sternberg (Ed.
), Advances in the psychology of human intelligence.
 Hillsdale, NJ: Erlbaum.
 Larkin, J.
, McDcrmoii, J.
, Simon, D.
P.
, and Simon, H.
A.
 (1980).
 Expert and novice performance in solving physics problems.
 Science.
 208, 133542.
 Logan, C D .
 (1988).
 Towards an instance theory of automatization.
 Psychological Review, 95, 492527.
 Lovett M.
C.
 & Anderson, J.
R.
 (in press).
 History of success and current context in problem solving: Combined influences on operator selection.
 Cognitive Psychology.
 Newell, A.
 & Ro.
senbloom, P.
S.
 (1981).
 Mechanisms of skill acquisition and the law of practice.
 In J.
R.
 Anderson (Ed.
).
 Cognitive skills and their acquisition.
 Hillsdale, NJ: Erlbaum.
 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M.
A.
: Harvard University Press.
 Newell, A.
 & Simon H.
 (1972).
 Human Problem Solving.
 Englewood Cliffs, N.
J.
: Prentice Hall.
 Singlcy, M.
K.
 & Anderson, J.
R.
 (1989).
 The Transfer of Cognitive Skill.
 Cambridge, M.
A.
: Harvard University Press.
 511 http://ta.
skA Connectionist Formulation of Learning in Dynamic DecisionMaking Tasks Faison P.
 Gibson Graduate School of Industrial Administration Carnegie Mellon University Pittsburgh, PA 152133890 gibson+@cmu.
edu David C.
 Plaut Department of Psychology Carnegie Mellon University, and Center for the Neural Basis of Cognition Pittsburgh, PA 152133890 plautOcmu.
edu Abstract A formulation of learning in dynamic decisionmaking tasks is developed, building on the application of control theory to the study of human performance in dynamic decision making and a connectionist approach to motor control.
 The formulation is implemented as a connectionist model and compared with human subjects in learning a simulated dynamic decisionmaking task.
 When the model is pretrained with the prior knowledge that subjects are hypothesized to bring to the task, the model's performance is broadly similar to thatof subjects.
 Furthermore, individual runs of the model show variability in learning much like individual subjects.
 Finally, the effects of various manipulations of the task representation on model performance are used to generate predictions for future empincal work.
 In this way, the model provides a platform for developing hypotheses on how to facilitate learning in dynamic decisionmaking tasks.
 Introduction In businessrelated decisionmaking tasks, such as managing production output, decision makers make multiple recurring decisions to reach a target, and they receive feedback on the outcome of their efforts along the way.
 This type of dynamic decisionmaking task can be distinguished from onetime decisionmaking tasks, such as buying a house, by the presence of four elements (Brehmer, 1990a, 1992; Edwards, 1962): (1) The tasks require a series of decisions rather than one isolated decision; (2) The decisions are interdependent; (3) The environment changes both autonomously and as a result of decision makers' actions; (4) Decisions are goaldirected and made under time pressure, thereby reducing the decision maker's opportunities to consider and explore options.
 Given that dynamic decisionmaking tasks take place in changing environments, research to explain performance in these environments must account for the ability of the decision maker to adapt or learn while performing (Hogarth, 1981).
 With the emphasis on learning as a means for improving performance, the mechanism by which learning occurs becomes of central concern.
 Dynamic Decision Making and Control Theory Brehmer (1990a, 1992) uses control theory as a framework for analyzing decision makers' goaldirected behavior in dynamic decisionmaking environments.
 He hypothesizes that decision makers' ability to learn in dynamic decisionmaking tasks depends critically on the sophistication of their understanding or model of the environment.
 In particular, subjects who appear to be using less sophisticated environment models are able to learn to improve their performance only when ^Predicted Outcome (tilM Actual Outcome (t+1) Forward model / ^n^ } (̂ Action (t+l A Action model r Current State (t) ") ^ Goal (t) 2) Figure 1: A connectionist framework for control tasks, based on Jordan and Rumelhart (1992).
 Ovals represent groups of units and arrows represent sets of connections between groups.
 The unlabeled groups are hidden units that learn internal representations.
 The dashed arrow is not part of the network, but depicts the physical process whereby actions produce outcomes.
 feedback is timely and continuous (Brehmer, 1990a, in press).
 However, Brehmer fails to specify how decision makers form a model of the environment, how the model of the environment evolves with experience, and how decision makers use this model to learn to improve their performance when interacting with the environment.
 Casting dynamic decision making in terms of control theory allows for the transfer of insights from other related domains (Hogarth, 1986).
 In motor learning, Jordan and Rumelhart (1992; Jordan, 1992, in press) address issues very similar to those addressed by Brehmer.
 The key to applying their approach to dynamic decision making is to divide the learning problem into two interdependent subproblems: (1) learning how actions affect the environment, and (2) learning what actions to take to achieve specific goals, given an understanding of (1).
 These two subproblems are solved simultaneously by two connectionist networks joined in series (see Figure 1).
 The task of the action model is to take as input the current state of the environment and the specific goal to achieve, and to generate as output an action that achieves that goal.
 This action then leads to an outcome which can be compared with the goal to guide behavior.
 Unfortunately, when the outcome fails to match the goal—as it generally will until learning is complete—the environment does not provide direct feedback on how to adjust the action so as to improve the corresponding outcome's match to the goal.
 512 Such feedback can, however, be derived from an internal model of the environment, in the form of si forward model.
 This network takes as input the current state of the environment and an action, and generates as output a prcdicicd outcome.
 This predicted outcome can be comp;ued with the actual outcome to derive an error signal.
 A gradicntdescenl procedure, such as backpropagation (Rumelhan.
 Hinton, & Williams, 1986), can then be used to adjust the parameters (i.
e.
, connection weights) of the forward model to improve its ability to predict the effects of actions on the environment.
 Notice that learning in the forward model is dependent on the behavior of the action model because it can learn environmental outcomes only over the range of actions actually produced by the action model.
 To the extent that the behavior of the forward model approximates that of the environment, it can provide the action model with feedback for learning in the following way.
 The actual outcome produced by the action is compared with the goal to derive a second error signal.
 Backpropagation can again be applied to the forward model (without changing its own parameters) to determine how changing the action would change the error.
 This information corresponds to the error signal that the action model requires to determine how to adjust its parameters so as to reduce the discrepancy between the goal and the actual outcome produced by its action.
 Jordan and Rumelhart's (1992) framework provides an explicit formulation of the points left unclear in Brehmer's (1990a, 1992) original assertion that the environment model plays a central role in learning in dynamic decisionmaking tasks.
 In Jordan and Rumelhart's formulation, an internal or forward model of environment is formed and revised on the basis of goaldirected interaction with the environment.
 Furthermore, the importance of this forward model resides in its role of interpreting outcome feedback as the decision maker attempts to learn what actions to take in order to achieve given goals in an evolving context.
 A Test Case: The Sugar Production Factory In order to evaluate Jordan and Rumelhart's (1992) computational framework in the context of dynamic decision making, a version of the model depicted in Figure 1 was implemented to learn a computersimulated dynamic decisionmaking task that has received significant attention in the experimental literature, the Sugar Production Factory (Berry & Broadbent, 1984,1988; Brehmer, 1992; Stanley, Mathews, Russ, & KotlerCope, 1989).
 In one version of the task (the original learners condition from Experiment 1 of Stanley et al.
, 1989), subjects manipulate the workforce of a hypothetical sugar factory to attempt to achieve a particular goal production level.
 At every time step t, subjects are presented with a display screen depicting the curtent workforce (measured in hundreds of workers), the curtent production level (measured in thousands of pounds of sugar), and a graph of all past production levels.
 Subjects must indicate the workforce for time t + 1 and are limited to 12 discrete values ranging from 1 to 12 (representing hundreds of workers).
 Similarly, the output of the factory is bounded between 1 and 12 thousand tons in discrete steps, and is governed by the following equation (which is unknown to subjects): P(<+l) = 2M/(< + l )  P ( 0 + e (i; where P{t +1) represents the new production at time < I1 (in thousands), W{t + 1) is the specified workforce at < + 1 (in hundreds), and t is a random error term of 1,0, or 1.
 Over a series of such trials within a training set, subjects repeatedly specify a new workforce and observe the resulting production level, attempting to achieve a prespecified goal production.
 Stanley et al.
 (1989) report on the performance of eleven subjects trained on this task in three sessions taking place over three weeks.
 Each session was divided into twenty sets of 10 trials or time steps during which the subjects attempted to reach and maintain a goal level of 6 thousand tons of sugar production.
 At the start of each set of trials, initial workforce was always set at 9 hundred and initial production was allowed to vary randomly between 1 and 12 thousand.
 Subjects were told to try to reach the goal production exactly.
 However, due to the random element in the underlying system, Stanley et al.
 scored subject performance as cortect if it ranged within ±1 thousand tons of the goal.
 In addition, at the end of each set of 10 trials, subjects attempted to write down a set of instructions for yoked naive subjects to follow.
 The relative initial success of these yoked subjects compared with that of purely naive subjects was taken as a measure of the degree of explicit knowledge developed by the original subjects.
 The instruction writing also had a direct beneficial impact on the performance of the original subjects.
 The Sugar Production Factory task contains all of the elements of more general dynamic decisionmaking environments, with the exception of time pressure.
 In this regard, Brehmer (1992) has observed that, although removing time pressure may lead to improved performance, the relative effects of other factors on performance are the same.
 Furthermore, although the task appears fairly simple, it exhibits complex behaviors that are challenging to subjects (Berry & Broadbent, 1984, 1988; Stanley et al.
, 1989).
 In particular, due to the lag term P{t), two separate, interdependent inputs are required at times t and < t 1 to reach steadystate production.
 In addition, also due to the lag term, maintaining steadystate workforce at nonequilibrium values leads to oscillations in performance.
 Finally, the random element allows the system to change autonomously, forcing subjects to exercise adaptive control.
 The random element also bounds the expected percentage of trials at goal performance to between 11 % (for randomly selected workforce values; Berry & Broadbent, 1984) and 8 3 % (for a perfect model of the system; Stanley etal.
, 1989).
 Implementation of the Model Jordan and Rumelhart's (1992) framework, depicted in Figure 1, was instantiated in the following way to interactively learn to control the Sugar Production Factory.
 The goal production value was indicated as a real value on a single goal unit.
 The curtent production and the cmrent workforce were each represented as real values on separate input units.
 The graph of past production values was represented as a series of real values on separate input units, one for each value.
 All of these inputs were scaled linearly to between 0 and 1.
 Finally, the hidden layers in both the forward and action models each contained 30 hidden units with sigmoidal output ranging between ±1.
 The number of hidden units was established empirically based on series of simulation experiments intended 513 to determine the minimum hidden units required to lejirn a slightly more complex version of the task.
 As described eiirlicr, the network used two different error signals to train the forward and action models.
 The predicted outcome generated by the forward model was subtracted from the actual (scaled) production value generated by Equation 1 to produce the error signal for the forward model.
 The error signal for the action model was generated by subtracting the actual production generated by Equation 1 from the goal level and multiplying the difference by the scale factor.
 One training trial with the model occurred as follows.
 The initial input values, including the goal, were placed on the input units.
 These then fed forward through the action model hidden layer.
 A single action unit took a linear weighted sum of the action hidden unit activations, and this sum served as the model's indication of the workforce for the next time period.
 This workforce value was used in two ways.
 First, conforming to the bounds stipulated in Stanley et al.
's original experiment, the value was used to determine the next period's production using Equation 1.
 Second, the unmodified workforce value served as input into the forward model, along with all of the inputs to the action model except the goal.
 These inputs fed through the forward hidden layer.
 A single predicted outcome unit computed a linear weighted sum of the forward hidden unit activations, and this sum served as the model's prediction of production for the next period.
 It is important to note that the forward and action models were trained simultaneously.
 The model was trained under two conditions corresponding to different assumptions about the prior knowledge and expectations that subjects bring to the task.
 In the first condition, corresponding to no knowledge or expectations, the connection weights of both the forward and action models were set to random initial values sampled uniformly between ±0.
5.
 However, using the same task but a different training regimen.
 Berry and Broadbent (1984) observed that naive human subjects appear to adopt an initial "direct" strategy of moving workforce in the same direction that they want to move production.
 To approximate this strategy, in the second training condition, models were pretrained for two sets of ten trials on a system in which production was commensurate to size of workforce without lagged or random error terms.
 For both initial conditions, the regimen of training on the Sugar Production Factory task exactly mimicked that of Stanley et al.
 (1989) for human subjects, as described above, except that no attempt was made to model instruction writing for yoked subjects.
 In the course of training, backpropagation (Rumelhart et al.
, 1986) was applied and the weights of both the forward and action models were updated after each trial (with a learning rate of 0.
1 and no momentum).
 To get an accurate estimate of the abilities of the network, 2(X) instances (with different initial random weights prior to any pretraining) were trained in each experiment.
 Comparison of Model and Human Performance Aggregate Comparison with Stanley et al.
 (1989).
 Figure 2 shows a comparison of the average performance of the model under the two different initial conditions (with or without pretraining) and Stanley et al.
's (1989) eleven original learners.
 Performance is measured based on number of trials correct out of ten using the performance criterion of goal 7 :6 3 5 • • Pretrained Model (Base) O O Human Subjects A A Model w/o Pretraining Session 1 Session 2 Session 3 Figure 2: A comparison of the average learning performance across training sessions of Stanley et al.
's (1989) human subjects and models with and without pretraining.
 production ± 1 thousand.
 As is clear in the figure, the performance of the randomly initialized models is far below that of human subjects.
 This difference is unlikely to be due to explicit knowledge, unavailable to the network, that subjects were able to acquire early on in the task: Stanley et al.
 (1989) found that the instructions written by the original subjects were useful to yoked naive subjects only near the end of the third training session.
 By contrast, the pretrained models perform equivalently to human subjects in the first training session, and actually leam somewhat more quickly than do subjects over the subsequent two sessions.
 This advantage may be due to the fact that the model is not subject to forgetting during an intervening week between each training session.
 The findings of the current modeling work suggest that the prior knowledge and expectations that subjects bring to the task are critical in accounting for their ability to leam the task as effectively as they do.
 Accordingly, the remainder of the paper presents data only from models with pretraining.
 W h y should pretraining, particularly on a system that differs in important aspects from the Sugar Production Factory, improve performance in learning to perform in the task? Pretraining provides the model with a coherent set of initial parameter estimates describing system performance.
 Although the initial model parameters do not describe the true system well, the model is systematic in applying them in attempting to control the system.
 By contrast, models with no pretraining do not have the benefit of a coherent (albeit incorrect) set of parameter estimates describing system performance when starting the Sugar Production Factory task.
 Thus, their initial attempts to control the system do not show the same systematicity and their learning does not have the advantage of adjusting an already coherent set of parameters.
 SingleSubject Comparison across Training Sets.
 In addition to aggregate data, Stanley et al.
 (1989) provide two examples of individual subject performance for each set of trials, over the full 60 sets.
 Figure 3 shows a comparison between the learning performance of one such subject and that 514 Human Subject ^ Base Model Figure 3: The performance over 60 training sets of a single human subject (Stanley et al, 1989, Subject 10) and a single model.
 12 10 h § F ' c .
2 6 1 ' \ /• ' \ \J Training Set 1 Training Set 20 Training Set 60 Correct Range 5 6 Trial 10 Figure 4: The sugar production generated by the actions of a single model across the ten trials within training sets 1, 20, and 60.
 of an example (pretrained) model over the course of the 60 training sets.
 Although there is substantial variability over the course of training, the subject appears to show a breakpoint around training set 30, when the improvement in performance is much more dramatic than at any prior or subsequent time.
 There is no ^parent breakpoint for the model (and other models are broadly similar).
 One possibility is that the subject (but not the model) acquired an explicit insight into the behavior of the underlying system at the time of the breakpoint.
 To test this possibility, Stanley et al.
 (1989) analyzed the performance of the original subjects for bre^oints.
 They hypothesized that instructions that these subjects wrote for their naive yoked partners immediately after these breakpoints would have a significant positive impact on the naive yoked partners' performance, thereby indicating a link between explicit understanding of the system and performance.
 H o w ever, this hypothesis was not confirmed; instructions written just after breakpoints were no more effective than those written just prior to breakpoints in guiding yoked subjects.
 Thus, it appears that the breakpoints do not represent a measurable increase in subjects' verbalizeable knowledge about controlling the task.
 Furthermore, not all subjects exhibited clear breakpoints in learning.
 Nonetheless, the contrast between subject and model performance suggests that human learning may be more subject to rapid transitions than model learning (but see McClelland, 1994; McClelland & Jenkins, 1990, for examples of staged learning in connectionist networks).
 WithinSet Performance for the Model Learner.
 As mentioned earlier.
 Berry and Broadbent (1984) found that, at the beginning of training, subjects attempt to increase workforce to increase production and vice versa.
 Furthermore, they noted that subjects' performance initially shows large oscillations and that these oscillations decrease as the subjects gain experience with the system.
 Figure 4 shows three detailed sets of trials in which the example model whose overall performance is depicted in Figure 3 attempts to control the system.
 Like human subjects, the model starts with highly oscillatory performance and reduces those oscillations as it becomes more adept at controlling the system.
 The initial over and undercorrection is a hallmark of the model's systematic application of its pretrained conceptualization of the system.
 Attempting to bring about a change in production by a commensurate change in the workforce has the effect of increasing oscillation in production at nonequilibrium values.
 As training progresses, the model slowly revises its internal model of the system, as represented in its parameter estimates.
 B y training set 60, the model has overcome its tendency to over and undercorrect.
 Forward and Action Model Learning Over Time.
 The importance of the network's internal model of the system can be clarified by separately examining the time course of learning in the forward and action models.
 Figure 5 shows the total error across training sets for the forward and action models, averaged over 40 models.
 T w o observations are relevant.
 First, the difference in squared error between the forward and action models decreases over time.
 Second, in the early stages of learning, the error for the forward model drops more steeply than that of the action model.
 These two observations illustrate how the improvement in the model's understanding of the environment precedes and guides its increasing effectiveness in taking action.
 Summary of Comparisons with Human Performance.
 The performance of the model presented here is broadly similar to that of human subjects, given the available data.
 Although models without pretraining performed more poorly than human subjects, pretrained models outperformed subjects in performance measures aggregated over sets.
 Pretraining gives the model an edge because it has a coherent model of a system instantiated in its parameters that it applies and revises systematically.
 Consistent with this observation is the model's conformance to Berry and Broadbent's (1984) observation that human subjects tend to reduce oscillations in performance as they became more experienced.
 However, unlike the model, some human subjects show breakpoints in their learning performance across training sets, although these do 515 1.
2 S 1.
0 t •O 0.
8 on E 0.
4 3 00 0.
2 0.
0 1 I 1 I 1 k 1 • 1 > 1 * *• J 1 Forward model .
 ^ ^ ^ ^ 0 10 50 60 20 30 40 Training Set Figure 5: Reduction in error of the forward and action models over training sets.
 3 O r u 4 ID No Noise A No History Information •Base Model <> ODeviations Representation Session 1 Session 2 Session 3 Figure 6: Effects of various manipulations of the task environment on model perfomiance.
 not appear to be due to an increase in explicit knowledge about the underlying system.
 Finally, Figure 5 characterizes the evolution of model performance in terms of improvements in the forward model guiding improvements in the action model for this task.
 Effects of Manipulating Task Environment A n important benefit of developing an explicit computational formulation of dynamic decision making is that it provides a platform for evaluating factors that influence the effectiveness of learning in such tasks.
 In general, many of the relevant factors have not been studied extensively in the existing empirical literature.
 Nonetheless, w e can use the implemented model to generate predictions of how various manipulations will affect the performance of subjects.
 A s a first step, w e performed a number of simulation experiments to evaluate how model performance depends on certain aspects of the task representation.
 The results from these experiments are presented in Figure 6.
 Empirical studies to evaluate these predictions are currently being planned.
 Representing Values as Deviations.
 In the first experiment, the model is used to predict how two different representations of task quantities might affect human performance.
 In the deviations representation, the goal and new workforce which the model sets are represented as deviations (differences) from the current production and current workforce, respectively.
 In addition, the production history is also presented as deviations from the goal.
 As can be seen in Figure 6, model performance in the deviations condition starts out slightly better than base in the first session and slowly diverges over the next two sessions until it is almost a full point below in the third session.
 The reason for the divergence in performance appears to be as follows.
 The size of the error term relative to the action the model is trying to modify is larger in the deviations condition than in the base condition.
 At the beginning of learning, models in both conditions are trying to produce relatively large modifications in workforce (i.
e.
, size of error term is large for both conditions), so the difference in conditions is not apparent.
 However, later in learning, the modifications that both models are trying to produce in the workforce levels they are learning to set become finer.
 It is here that the difference in size of the error term relative to the action to be modified becomes significant and affects learning performance.
 Similar effects of feedback magnitude have been found in human learning.
 In a repeated prediction task, Hogarth, McKenzie, Gibbs, and Marquis (1991) found that subject performance was influenced by the absolute scale of the feedback they received.
 In particular, subjects receiving feedback with lowmagnitude variance tended to undercorrect, whereas those receiving feedback with highmagnitude variance tended to overcorrect.
 Reducing the Number of Presented Relations.
 The second experiment involved manipulating the number of variable relationships with which the model is presented.
 In particular, a model was trained without presenting the history graph of past production values.
 As mentioned earlier, this graph is represented in the base model as additional input values.
 As such, the representation has the effect of providing the model with a greater number of possible relationships between variables to sort through as it attempts to control the system.
 However, as learning progresses and the model learns which relationships are relevant to performance, the difference in performance between the base model and the one trained with no history graph lessens.
 Eliminating Random Variability.
 In the final experiment, performance on learning the original system was compared with learning an equivalent deterministic system (i.
e.
, without the random component e in Equation 1).
 In the original system, the model attempts to adapt to the random element.
 By definition, this random element cannot be learned, so, as would be expected in Figure 6, performance for the model in the original system is degraded relative to the deterministic system.
 Additionally, the model's attempts to adapt to the random element appear to be responsible for slowing the rate of learning in the original system.
 By showing a decrease in the long term rate of adaptation due to the learning mechanism itself, this result conforms with and extends Brehmer's (1990b) observation that random elements in system performance present a limit to human adaptation.
 516 C o n c l u s i o n This paper presents a connectionist model that builds on ihc previous application of control theory to psychological studios of dynamic decision making and a connectionist formulation of motor control.
 The model provides a broad approximation to existing data on human learning performance in the Sugar Production Factory, an example dynamic decisionmaking task.
 In addition, the model makes a number of untested predictions for future empirical work.
 This model's approach may be contrasted with alternatives that rely on explicit hypothesis testing or sequences of training trials to initiate learning.
 Explicit hypothesis testing would imply that improved verbal knowledge of the task would cooccur with improved performance.
 However, the results of Stanley et al.
 (1989) indicate that improved verbal knowledge occurs well after improved performance.
 Two sets of authors present theories that require sequences of attempts at controlling the system to initiate learning.
 First, Mitchell and Thrun (1993) present a learner implemented as a neural network that attempts to pick the best action based on its existing model of the environment.
 This model is updated based on its assessed accuracy in predicting the outcome of a sequence of trials once that sequence has occurred.
 Second, Stanley et al.
 (1989) conjecture that performance in the Sugar Production Factory depends on the learner's ability to make analogies between the current situation and prior (successful) sequences of examples.
 Thus, in this scheme, knowledge can be said to increase every time a successful sequence is encountered and retained.
 The model proposed here differs fundamentally from these two approaches in that it is able to use information from both successful and unsuccessful single control trials to alter its parameters (connection weights) to reduce the error in its performance.
 In particular, this property of the model is critical in producing a relatively rapid decrease in production oscillations as training progresses.
 If implemented to perform the Sugar Production Factory task, it seems unlikely that either Mitchell and Thrun's or Stanley et al.
's approach would produce similarly rapid decreases in oscillations.
 Clearly, the model presented here has several limitations.
 It does not account for metastrategies such as planning how to learn in the task.
 It also does not account for how verbalizeable knowledge is acquired during learning.
 Finally, it does not account for how relevant information presented across multiple time steps might be integrated while learning to perform in dynamic decisionmaking tasks.
 Empirical validation of the predictions made so far and this last limitation are the focus of ongoing research.
 Even with its limitation, the model constitutes one of the first explicit computational formulations of how subjects develop and use an internal model of the environment in learning to perform dynamic decisionmaking tasks.
 Acknowledgments The authors wish to acknowledge the helpful comments of Mark Fichman, Jim Peters, Javier Larch, and members of the C M U Parallel Distributed Processing research group.
 W e also thank the National Institute of Mental Health (Grants MH47566) and the McDonnellPew Program in Cognitive Neuroscience (Grant T8901245016) for providing financial support for this research.
 References Berry, D.
 C , & Broadbent, D.
 E.
 (1984).
 On the relationship between task performance and associated verbalizable knowledge.
 Quarterly Journal of Experimental Psychology, 36A, 209231.
 Benry, D.
 C .
 & Broadbent, D.
 E.
 (1988).
 Interactive tasks and the implicitexplicit distinction.
 British Journal of Psychology, 79, 251272.
 Brehmer, B.
 (1990a).
 Strategies in realtime, dynamic decision making.
 In R.
 Hogarth (Ed.
), Insights from decision making.
 Chicago: University of Chicago Press.
 Brehmer, B.
 (1990b).
 Variable errors set a limit to adaptation.
 Ergonomics, 33, 12311239.
 Brehmer, B.
 (1992).
 Dynamic decision making: Human control of complex systems.
 Acta Psychologica, 81, 211241.
 Brehmer, B.
 (in press).
 Feedback delays in complex dynamic decision tasks.
 In P.
 Frensch, & J.
 Funke (Eds.
), Complex problem solving: The European perspective.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Edwards, W.
 (1962).
 Dynamic decision theory and probabilistic information processing.
 Human Factors, 4, 5973.
 Hogarth, R.
 M.
 (1981).
 Beyond discrete biases: Functional and dysfunctional aspects of judgmental heuristics.
 Psychological Bulletin, 90, 197217.
 Hogarth, R.
 M.
 (1986).
 Generalization in decision research: The role of formal models.
 IEEE Transactions on Systems, Man, and Cybernetics, 16,439^149.
 Hogarth, R.
 M.
, McKenzie, R.
 M.
, Gibbs, B.
 J.
, & Marquis, M.
 A.
 (1991).
 Learning from feedback: Exactingness and incentives.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 17(A), 734752.
 Jordan, M.
 I.
 (1992).
 Constrained supervised learning.
 Journal of Mathematical Psychology, 36, 396425.
 Jordan, M.
 I.
 (in press).
 Computational aspects of motor control and motor learning.
 In H.
 Heuer, & S.
 Keele (Eds.
), Handbook of perception and action: Motor skills.
 New York: Academic Press.
 Jordan, M.
 I.
, & Rumelhart, D.
 E.
 (1992).
 Forward models: Supervised learning with a distal teacher.
 Cognitive Science, 16(3), 307354.
 McClelland, J.
 L.
 (1994).
 The interaction of nature and nurture in development: A parallel distributed processing perspective.
 In P Bertelson, P Eelen, & G.
 d'YdewaUe (Eds.
), International perspectivesonpsychologicalscience, Volume 1: Leading themes (pp.
 5788).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 McClelland, J.
 L.
, & Jenkins, E.
 (1990).
 Nature, nurture, and connections: Implications of connectionist models for cognitive development.
 In K.
 VanLehn (Ed.
), Architectures for intelligence (pp.
 4173).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Mitchell, T.
 M.
, & Thrun, S.
 B.
 (1993).
 Explanationbased neural network learning for robot control.
 In S.
 J.
 Hanson, J.
 D.
 Cowan, & C.
 L.
 Giles (Eds.
), Advances in neural information processing systems 5 (pp.
 287294).
 San Mateo, CA: Morgan Kaufmann.
 Rumelhart, D.
 E.
, Hinton, G.
 E.
, & Williams, R.
 J.
 (1986).
 Leammg representations by backpropagating errors.
 Nature, 323(9), 533536.
 Stanley, W.
 B.
, Mathews, R.
 C , Russ, R.
 R.
, & KotlerCope, S.
 (1989).
 Insight without awareness: On the interaction of verbalization, instruction, and practice in a simulated process control task.
 Quarterly Journal of Experimental Psychology, 41A(i), 553577.
 517 Poster Presentations Causal Structure in Categorization Wookyoung Ahn Department of Psychology University of Louisville Louisville, K Y 40292 w k a h n O O l O h o m e r .
 l o u i s v i l l e .
 e d u M a r y E .
 Lassaline Department of Psychology University of Illinois Champaign, IL 61820 m l a s s a l i ® p s y c h .
 u i u c .
 e d u Abstract What role does causal knowledge play in categorization? The current study tested the hypothesis that weight given to features is determined by the specific role they play within a causal structure.
 After learning typical symptoms of a disease, participants were asked to judge the likelihood that new patients had that disease.
 Half of the patients were missing one of the typical symptoms, and the other half had an extra symptom (a symptom typical of an alternative disease).
 For patients with a missing symptom, likelihood ratings were lower if the missing symptom was a cause of other symptoms than if it was an effect.
 However, for patients with an extra symptom, there was no difference between likelihood ratings when the extra symptom was a cause or an effect.
 These results suggest one mechanism underlying differences between experts and novices in categorization, and suggest an explanation for why different kinds of features (e.
 g.
, molecular or functional) are important for different kinds of categories (e.
g.
, natural kinds or artifacts).
 EBL and SBL Categorization research falls roughly into two camps: similaritybased learning (SBL) and explanationbased learning (EBL).
 S B L theories are based on the assumption that concepts are formed by extracting similarity across multiple examples.
 E B L theories emphasize the role of prior knowledge in learning new concepts.
 Categorization research within cognitive science had initially been dominated by SBL models.
 Recently, researchers have pointed out a number of difficulties faced by S B L theories, and proposed a knowledgeintensive E B L view.
 Importance of background knowledge Many psychological experiments supporting S B L models have involved categorization in controlled settings using artificially constructed stimuli.
 Therefore, S BL theories tend not to take into account the role played by learners' domain knowledge in categorization.
 In contrast, many studies have shown that categorization processes are strongly affected by the learners' background knowledge (see Murphy & Medin, 1985, for a discussion).
 For example, category learning occurred faster with background knowledge (Ahn, Brewer, & Mooney, 1992; Pazzani, 1991); different features were abstracted for rule induction depending on subjects' domain theories (Wisniewski & Medin, 1991); and typicality judgments varied with subjects' perspectives (Barsalou, 1983; Roth & Shoben, 1983).
 Importance of relational structure In most S B L theories, objects are represented as sets of independent features (Tversky, 1977).
 However, features in natural objects are structured in many complex ways.
 For example, in the category bird, "having wings" and "building nests in trees" are not independent features because having wings enables birds to fly, which in turn allows birds to build nests in trees.
 Recent approaches to similarity, induction and categorization have emphasized the importance of structural relations, which are predicates taking two or more arguments (e.
g.
, "is larger than" or "causes"), over simple attriburtes taking only one argument, such as "is red" (Centner, 1989; Goldstone, 1994; Lassaline, 1995; Markman & Centner, 1993; Medin, Coldstone, & Centner, 1993).
 For example, it has been shown that the soundness of an analogy is determined by matching on structural relations rather than on simple attributes.
 Importance of causal explanations The idea that features connected to a relational structure are more important in categorization than unrelated features is consistent with many E B L systems developed in Artificial Intelligence (DeJong & Mooney, 1986; Mitchell, Keller & KedarCabelli, 1986).
 In E B L systems, an instance is explained by using background knowledge, and then this explanatory structure is generalized to identify constraints and variables associated with a category.
 In making generalizations, causally connected features are incorporated into a schema as constraints that must be 521 satisfied in categorization, and unconnected features are allowed to take variable values.
 Feature Role within Relational Structure So far, w e have reviewed many studies showing that background knowledge is crucial in concept learning because it specifies which predicates are more important.
 The most prevalent theme in these studies is that features that belong to dependency structures (e.
g.
, relational features or explanatory structures) are more important.
 However, previous studies have not looked at how arguments within the same relational structure vary in importance.
 That is, given the relational structure "X causes Y," which feature is more crucial in categorization, XorY? To understand the importance of this question, consider a clinical graduate student w ho is forming the concept "borderline personality disorder" by learning its typical symptoms, which include frantic efforts to avoid abandonment, identity disturbance, and recurrent suicidal behavior.
 W h e n diagnosing a patient with borderline personality disorder, the student might simply set up a threshold for the number of typical symptoms that a patient must display in order to make a positive diagnosis (e.
g.
, if the patient has 5 out of 9 critical symptoms, classify as borderline personality, as described in the D S M IV, A P A , 1994).
 Note that if this is the manner in which the student makes the diagnosis, it does not matter which of the typical features a patient does not have (e.
g.
, suicidal behavior or fear of abandonment).
 Furthermore, suppose the patient has an extra feature.
 If the student is simply matching the patient against a set of typical symptoms, it would not matter whether the extra feature is "chronic substance use" or "has six toes".
 Alternatively, the student might learn the causal structure of the symptoms.
 For example, she might theorize that recurrent suicide attempts are caused by fear of abandonment.
 Consider the impact of both missing and extra features in this case.
 First, if a patient that fears abandonment does not currently display suicidal behavior, the student may be no less likely to make a positive diagnosis than if the patient did display suicidal behavior, because this symptom may show up later.
 In contrast, if the patient makes suicide attempts in the absence of fear of abandonment, the clinician might be more likely to make an alternative diagnose (e.
g.
, major depression rather than borderline personality).
 Second, it seems that having some extra features would have more of an effect on the diagnosis than others.
 For example, chronic substance use m a y matter more as an extra feature than having six toes, because chronic substance use is causally connected to an alternative diagnosis (e.
g.
, major depression) whereas having six toes is not.
 Existing knowledgebased systems cannot account for such differences in the important of features when the features both belong to the same relational structure (as is the case in the example of the clinical diagnosis).
 The presence or absence of relational predicates is important for existing systems.
 W e suggest that the differential position of arguments within the predicate also plays a role in categorization.
 The goal of the current experiment is to examine how the causal status of features affects their importance in categorization.
 In this experiment, w e manipulated the position of symptoms in a causal chain (e.
g.
, X causes Y, and Y causes Z), such that a symptom was either a cause or an effect of other symptoms in the causal chain.
 W e also manipulated whether the symptoms in the causal chain were associated with a target disease or an alternative disease.
 W e refer to absent symptoms associated with a target disease as missing features, and existing symptoms associated with an alternative disease as extra features.
 W e examined the effect of a missing and extra symptom on diagnosis of a target disease as a function of the causal status (i.
e.
, whether it was a cause or an effect of other symptoms) of that missing or extra symptom.
 W e predicted that a symptom that was a cause of other symptoms would have greater impact on categorization of new patients than a symptom that was an effect in a causal chain, both when the cause was a missing feature and when it was an extra feature.
 Method Participants Sixty undergraduate students at the University of Louisville participated in this study either in partial fulfillment of requirements of an Introductory Psychology course or for payment of $1.
00.
 Students were randomly assigned to each experimental condition.
 Participation involved approximately 10 minutes.
 Procedure Each participant was given six problems requiring them to judge the likelihood that a patient with some set of symptoms has a target disease.
 Each problem consisted of a description of the symptoms associated with the target disease and a list of a patient's symptoms.
 Specifically, for each of the six problems, subjects were first told that there were three symptoms associated with the target disease 7 5 % of the time.
 For some of the problems, subjects also received information about causal relationships between symptoms associated with the target disease or symptoms 522 Table 1.
 Likelihood judgment as a function of problem type.
 Problem Type Background Knowledge Likelihood Judgment Information about Missing Symptom Unavailable Explicit MissingEffect MissingCause MissingNone ExtraEffect ExtraCause ExtraNone A caused B, B caused C C caused B, B caused A none F caused E, E caused D D caused E, E caused F none P(X 1 A, B, (O) P(X 1 A, B, (O) P(X 1 A, B, (O) P(X 1 A, B, C, D) P(X 1 A, B, C, D) P(X 1 A, B, C, D) P(X 1 A, B, noC) P(X 1 A, B, noC) P(X 1 A, B, noC) P(X 1 A, B, C, D) P(X 1 A, B, C, D) P(X 1 A, B, C, D) associated with an alternative disease.
 Subjects were then presented with a description of a particular patient's symptoms and asked to judge the likelihood, using a 0100 scale, that the patient had the target disease.
 For example, one of the problems was the following: Scientists have found that symptoms A, B and C are associated with Disease Xeno 7 5 % of the time.
 In addition, scientists have found that symptom A causes symptom B, and symptom B causes symptom C.
 Suppose Susan has symptoms A and B, but we do not have any information about whether she has symptom C or not.
 H o w likely is it that Susan has Xeno? Design Three variables were manipulated in this experiment: Missing Information Condition, which refers to the manner in which information about missing symptoms was given (Unavailable or Explicit); Symptom Type, which refers to the manner in which a patient description differed fiom the abstract description of the disease (Missing or Extra); and Knowledge Type, which refers to the manner in which missing or extra symptoms were causally connected to other features (Cause, Effect, or None).
 Missing Information Condition varied between subjects.
 In the Unavailable condition, subjects were told that there was no available information about the missing symptom (as in the example above).
 In the Explicit condition, subjects were told that the patient definitely did not have a particular symptom known to be associated with the target disease.
 Both Symptom Type (Missing or Extra) and Knowledge Type (Cause, Effect or None) varied withinsubject to form a set of six problems.
 There were three problems in which the description of the patient was missing one of the symptoms associated with the target disease: (I) MissingCause, in which the missing symptom was the cause in a chain of symptoms associated with the target disease; (2) MissingEffect, in which the missing symptom was the effect in a chain of symptoms associated with the target disease; and (3) MissingNone, in which no background knowledge about causal relationships between symptoms associated with the target disease was provided.
 The example in the procedure section is a MissingEffect problem.
 There were three problems in which the description of the patient contained a symptom that was known to be associated with an alternative disease: (I) ExtraCause, in which the extra symptom was the cause in a chain of symptoms associated with the alternative disease; (2) ExtraEffect, in which the extra symptom was the effect in a chain of symptoms associated with the alternative disease; and (3) ExtraNone, in which no background knowledge about causal relations between symptoms associated with the alternative disease was provided.
 In addition, all participants were told that a person cannot have the target disease and the alternative disease at the same time.
 Materials Six problems were created for each of the Missing Information conditions (Unavailable and Explicit) by crossing the two levels of Symptom Type with the three levels of Knowledge Type.
 Likelihood judgments required for each of the six problem types are given in Table 1.
 In Table I, the three symptoms associated with the target disease are referred to as A, B and C, and the three symptoms associated with the alternative disease are referred to as D, E and F.
 The missing symptom, which is associated with the target disease but is not contained in the description of the patient, is C.
 The extra feature, which is associated with an alternative disease and is possessed by the patient, is D.
 The 523 Unavailable condition is denoted "(C)", to indicate that because no knowledge about C is available, the patient may or may not have symptom C.
 The Explicit condition is denoted "noC", to indicate that it is known that C is not present.
 The likelihood judgment required for each question type is indicated by a probability statement (e.
g.
, "P(X I A, B, C, D ) " should be read "What is the likelihood that the patient has Disease X, given that the patient has symptoms A, B, C and D?").
 The six problems given to subjects in the Unavailable and the Explicit conditions are listed under the heading "Information about Missing Symptom".
 O f the six problems given to each subject, three involved a missing feature and three involved an extra feature, one for each of the background knowledge conditions (Cause, Effect, and None).
 Although the letters AF were used in Table 1, in the actual stimulus materials, different sets of letters were used for each problem to label the symptoms and different fictitious names were used for the diseases.
 Subjects were told that the names of the symptoms were difficult to pronounce, so letters of the alphabet were used to label the symptoms.
 Consecutive letters of the alphabet were not used to label the three symptoms associated with each disease.
 80 ^ 70 c 0) E •1 •o 60 50 a> I 40 30 20 665 51.
8 ^ ^ 1 1 543 ^ ^ ^ 46.
6 ^ ^ 1 1 dMIssing BExtra 63 537 ^^HHH ^ ^ 1 1 None Cause Background Knowledge Effect Figure 1: Average likelihood judgment as a function of background knowledge and s y m p t o m type for Explicit condition.
 Results Average likelihood ratings for each of the six problem types in the Explicit condition are given in Figure 1, and average likelihood ratings for the six problems in the Unavailable condition are given in Figure 2.
 The impact of missing and extra features varied as a function of their status in the causal chains.
 W e will first discuss results from the missing features followed by results from the extra features.
 Analysis of categorization with missing features As shown in Figure 1, subjects in the Explicit condition were least likely to believe that a patient had a disease if the patient was missing a feature that was a cause in the chain of symptoms associated with the target disease.
 Subjects rated the likelihood that a patient had the target disease 16.
4% lower for the MissingCause problem than for the MissingEffect problem, t(29) = 3.
17, p < .
01; and 5.
2% lower for the MissingCause than for the MissingNone, p > .
10.
 The missing cause led to a lower likelihood of diagnosis as the target disease than the missing effect.
 In addition, subjects rated the likelihood that a patient had the target disease 11.
2% higher for the MissingEffect problem than for the MissingNone problem, t(29) = 3.
17, p < .
01.
 The missing effect was even less important for target disease categorization than the symptom that did not have any causal relationship with other symptoms.
 80  70 c Q> E •g 60 50 40 30 20 68 1 [•Missing • Extra 65.
4 65.
5 60.
7 56.
3 1 None Cause Background Knowledge Effect Figure 2.
 Average likelihood judgment as a function of background knowledge and s y m p t o m type for Unavailable condition.
 Interestingly, this significant decrease in belief that a patient had the target disease as a result of a missing causal feature did not occur in the Unavailable condition, in which subjects were told that no information w a s available about the presence of s y m p t o m C for the patient.
 A s shown in Figure 2, for the Unavailable condition, the m e a n likelihood judgment for the MissingCause problem w a s 1 4 .
 1 % greater than for the MissingNone problem, t(29) = 4.
54, p < .
01.
 524 Judgments for the MissingCause problem did not differ from judgments for the MissingEffect problem, p > .
10.
 Again, as in the Explicit condition, judgments for the MissingEffect problem were still 14.
2% greater than for the MissingNone, t(29) = 4.
76, p < .
01.
 To summarize results with a missing symptom, when the presence of the symptom was not explicitly denied (i.
e.
, in the Unavailable condition), and therefore subjects could make inferences about the presence or absence of the symptom, causal background knowledge led to an increase in target disease categorization.
 People could infer the presence of the missing symptom if it was causally connected with other symptoms, either as a cause or an effect.
 However, if the presence of the symptom was explicitly denied, causal background knowledge had differential impact depending on whether the symptom was a cause or an effect.
 Missing a cause led to a lower likelihood of being diagnosed as the target disease than missing an effect.
 Analysis of categorization with extra features As with missing features, the importance of extra features was affected by causal background knowledge about the extra feature.
 Unlike with missing features, however, the particular causal status of an extra feature in an alternative disease did not matter.
 That is, in both the Explicit and the Unavailable conditions, the cause of an alternative disease and the effect of an ahemative disease were equally likely to lower the subjects' ratings, p > 0.
10.
 However, both the cause and the effect of an alternative disease mattered more than an extra feature that had no causal relationship with features in the alternative disease, p<.
05.
 Discussion W e investigated the impact of the absence of characteristic features and the presence of extra features on categorization as a function of the causal status of the feature.
 W e found that weight given to extra and missing features is influenced by the specific role they play within the causal structure.
 Within a single causal structure, causes are believed to be more important in categorization than effects.
 People's categorizations reflect their belief in the existence of fundamental features shared exclusively by members of a category (Medin & Ortony, 1988).
 Indeed, many researchers in judgment and reasoning have found that inference proceeds from cause to effect rather than effect to cause (Einhom & Hogarth, 1986; Tversky & Kahneman, 1982).
 Our results suggest that this is not always the case: the presence of a cause is more crucial when confirming target category membership, but the causal status of a feature in an alternative category was not important when disconfirming target category membership.
 W h e n a cause known to be associated with a target category is missing, other associated features are given less weight as evidence that the example is a member than when that same feature is an effect of other features.
 In confrast, the presence of a cause associated with an alternative category is given just as much weight as counter evidence for target category membership as the presence of an effect.
 A followup study suggests an explanation for the interaction between types of categories and types of features observed in previous categorization research (Barton & Komatsu, 1989; Gehnan, 1988; Keil & Batterman, 1984).
 These studies have shown that changing a feature of an object has a different effect on belief about the identity of the object depending on both the kind of category to which the object belongs (i.
e.
, natural kinds or artifacts) and the type of feature which was changed (i.
e.
, "molecular", or having to do with what the object is made of, or "ftinctional", having to do with what the object is used for).
 In these studies, molecular features (e.
g.
, made of wood) are more important for identification as a member of a natural kind category than as a member of an artifact category.
 In confrast, functional features (e.
g.
, used for writing, gives milk) are more important for artifact category membership than natural kind category membership.
 These results can be explained within the current framework.
 Molecular features in natural kinds serve as causes for other features, including functional properties (e.
g.
, goats' D N A structure allows them to give milk).
 It is the causal status of molecular features of natural kinds, rather than the fact that they are molecular features per se, which is responsible for their importance to natural kind category membership.
 In artifacts, molecular features do not necessarily determine the function of categories, whereas functional properties typically do determine the molecular features of the artifact (e.
g.
, what it is made of).
 In our followup study, w e pitted causal status of features against type of category (natural kind v.
 artifact) and type of feature (molecular v.
 functional) and confirmed our hypothesis.
 That is, when a molecular structure was described as an effect of a functional property in natural kinds, the functional property was considered to be more important for categorization than the molecular structure, reversing the previous findings.
 Similarly, when a functional property was described as an effect of a molecular property in artifacts, the effect found in previous studies was again reversed.
 Finally, w e speculate that this mechanism may be responsible for differences between experts and novices in categorization.
 Experts and novices m a y know the same features, but these features m a y reside in different causal structures.
 By changing the causal status of features, their importance for categorization also changes.
 In conclusion.
 525 the results of the current study suggest a mechanism for determining the importance of features in categorization.
 References Ahn, W.
, Brewer, W.
 F.
, & Mooney, R.
 J.
 (1992).
 Schema acquisition from a single example.
 Journal of Experimental Psychology: Learning, Memory, & Cognition, 75,391412.
 American Psychiatric Association (1994).
 Diagnostic and statistical manual of mental disorders.
 Fourth edition,Washington, E.
 C : American Psychiatric Association.
 Barsalou, L.
 W .
 (1983).
 Ad hoc categories.
 Memory and Cognition, 77,211227.
 Barton, M.
 E.
, & Komatsu, L.
 K.
 (1989) Defining features of natural kinds and artifacts.
 Journal of Psycholinguistic Research, 18, 433 447.
 DeJong, G.
 F.
, & Mooney, R.
 J.
 (1986).
 Explanationbased learning: An alternative view.
 Machine Learning, 7, 145176.
 Einhom, H.
 J.
, & Hogarth, R.
 M.
 (1986).
 Judging probable cause.
 Psychological Bulletin, 99, 319.
 Gelman, S.
 A.
 (1988).
 The development of induction within natural kind and artifact categories.
 Cognitive Psychology.
 20, 6595.
 Gentner, D.
 (1989).
 The mechanisms of analogical learning.
 In S.
 Vosniadou & A.
 Ortony (Eds.
), Similarity and Analogical Reasoning.
 Cambridge: Cambridge University Press.
 Goldstone, R.
 L.
 (1994).
 Similarity, interactive activation, and mapping.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 328.
 Keil, F.
 C , & Batterman, N.
 (1984).
 A characteristictodefining shift in the development of word meaning.
 Journal of Verbal Learning and Verbal Behavior, 23, 221236.
 Lassaline, M.
 E.
 (1995).
 Structural alignment in induction and similarity.
 Manuscript submitted for publication.
 Markman, A.
, & Genmer, D.
 (1993a).
 Structural alignment during similarity comparisons.
 Cognitive Psychology, 25,431461.
 Medin, D.
 L.
, Goldstone, R.
 L.
, & Gentner, D.
 (1993).
 Respects for similarity.
 Psychological Review, 100, 254278.
 Medin, D.
 L.
, & Ortony, A.
 (1988).
 Psychological essentialism.
 In S.
 Vosniadou & A.
 Ortony (Eds.
), Similarity and analogical reasoning (pp.
 179196), N Y : Cambridge University Press.
 Mitchell, T.
 M.
, Keller, R.
 M.
, & KedarCabelli, S.
 T.
 (1986).
 Explanationbased generalization: A unifying view.
 Machine Learning, 1, 4780.
 Murphy, G.
 L.
, & Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Pazzani, M.
 J.
 (1991).
 Influence of prior knowledge on concept acquisition: Experimental and computational results.
 Journal of Experimental Psychology: Learning, Memory and Cognition, 17,416432.
 Roth, E.
 M.
, & Shoben, E.
 J.
 (1983).
 The effect of context on the structure of categories.
 Cognitive Psychology, 15, 346378.
 Tversky, A.
 (1977).
 Features of similarity.
 Psychological Review, 84, 327352.
 Tversky, A.
, & Kahneman, D.
 (1982).
 In D.
 Kahneman, P.
 Slovic, & A.
 Tversky (Eds.
), Judgment under uncertainty: Heuristics and biases.
 N e w York: Cambridge University Press.
 Wisniewski, E.
 J.
, & Medin, D.
 L.
 (1991).
 Harpoons and Long Sticks: The interaction of theory and similarity in rule induction.
 In D.
 Fisher & P.
 Langley (Eds.
) Concept formation: Knowledge and experience in unsupervised learning, p.
 237278, MorganKaufrnan.
 526 ModelBased Indexing and Index Learning in Analogical Design Sambasiva R.
 Bhatta and Ashok K.
 Goel College of Computing Georgia Institute of Technology Atlanta, G A 303320280 b h a t t a @ c c .
 g a t e c h .
 e d u , g o e l @ c c .
 g a t e c h .
 e d u Abstract Analogical reasoning is the process of retrieving knowledge of a familiar problem (source analog) similar to the current problem (target) and transferring that knowledge to solve the problem.
 The power of an analogical reasoner thus comes in part from the ability to retrieve the "right" analog when a taî et is specified.
 Indexing of analogs therefore is an important issue in analogical reasoning.
 This issue in fact has three different aspects: (i) indexing vocabulary, (ii) learning of the indices to a new analog, and (iii) use of indices for retrieving stored analogs.
 W e have been exploring the hypothesis that the reasoner's mental models of the analogs give rise to the answers to these issues.
 W e have tested this hypothesis in the context of analogical design of physical devices.
 In this paper, we describe how structurebehaviorfunction (SBF) models of devices help in addressing the indexing issues in analogical design.
 W e also describe how the IDEAL system implements and evaluates the modelbased scheme to indexing and index learning.
 Introduction Analogical reasoning is the process of retrieving knowledge of a familiar problem (called source analog) similar to the current problem (called target) and transferring that knowledge to solve the problem.
 The power of an analogical reasoner thus comes in part from the ability to retrieve the "right" analog when a new problem is specified.
 Indexing of analogs therefore is an important issue in analogical reasoning.
 Actually, the indexing issue has three different aspects: (i) what might be the indexing vocabulary, (ii) how might the indices be learned for a new analog when it is stored in memory, and (iii) how might the learned indices be used for analog retrieval.
 W e have been exploring the hypothesis that mental models of analogs give rise to the indexing vocabulary, enable and constrain the learning of indices for new analogs, and provide similarity measures for matching a target problem with the stored analogs and retrieving relevant ones.
 W e have tested this hypothesis in the context of designing physical devices.
 In earlier work, we showed how structurebehaviorfunction (SBF) models of devices provide the indexing vocabulary and enable the retrieval of analogs relevant to the target problem (Goel, 1992).
 W e also showed how S B F models enable and constrain the transfer of structural knowledge from the source analog to the target problem (Goel, 1991a), and how the concurrent transfer of structural and behavioral (i.
e.
, causal) knowledge leads to the acquisition of the S B F models of new analogs (Goel, 1991b).
 In this paper, we describe how S B F models enable and constrain the learning of indices to new analogs.
 W e also describe how the IDeAL system implements and evaluates the modelbased scheme for indexing and index learning in analogical design.
 Analogical Design IDEAL is an operational system that autonomously designs physical devices such as electrical circuits and heat exchangers.
 It takes as input a specification of the function of a desired design and the structural constraints on it.
 The structural constraints may specify, for example, what components cannot be (or must be) used in the design.
 The system gives as output a specification of a structure that realizes the desired function and satisfices the structural constraints.
 A design analog in IDEAL specifies (i) the functions delivered by the stored design, (ii) the structure of the design, and (iii) a pointer to the causal behaviors of the design (the S B F model).
 Since the input to the system is a specification of the functional and structural constraints on the desired design, the design analogs are indexed both by the functions that the stored design can deliver and by the structural constraints it satisfies, where the delivered functions act as the primary indices.
 Given the specification of a design problem, IDEAL retrieves the closest matching analog from the analog memory.
 The "closeness" of a match is determined by how many features and which features in the problem specification (function and/or structure) are the same as (or different from) the respective indices of a candidate analog.
 Then IDEAL uses the S B F model of the retrieved design to modify and transfer the design structure to the given problem.
 It also revises and transfers the causal behaviors of the old design, and thus it generates not only a new design but also a S B F model for it.
 Then it evaluates the new design by a qualitative simulation of the new S B F model.
 Finally, IDEAL learns indices for the new design analog as described in this paper and stores the design for potential reuse.
 Device Models IDEAL represents the knowledge of how devices work in the form of structurebehaviorfunction (SBF) models.
 S B F models are based on a componentsubstance ontology.
 In this ontology, the structure of a device is viewed as constituted of components and substances.
 Components form the structural topology of the device.
 Substances flow between components with a corresponding rate.
 Substances have locations in reference to the components in the device.
 They also have 527 mailto:bhatta@cc.
gatech.
edumailto:goel@cc.
gatech.
edu'\ SO^pipe1 V H.
,0 p HjSO^pi rP5 pe2 ipe Heatexchange ^̂  H^SO.
pipe3 H ̂ opipe Waterpump (a) HiOhAcidity Sulphuric Acid Cooler emperature:T flow:R OIVEN: state:1iquid sub:H^SO 2 d loc:pi acidity:high magnitude:Q sub:heat MAKES: state.
 / loc:p4 at h Sub:H SO 2 4 •;/J „ v temperature:T2 (< T.
 ) flow:R state:liquid acidity:high sub:heat magnitude:Q.
 BYBEHAVIOR: pointer to the behavior "cool acid" (b) Function "Cool Acid" of Hi^hAcidity SAC Same as state but with 1 loc:p2 USINGFUNCTION AliliOW H 2SO4 Of H2S04pipe2 I UNDERCONDITIONSUBSTANCE > state:iiquid ; ub:H so 1< : ^^JV, ,: ^ acidity:high ; UNDERCONDITIONSTRUCTURE INCLUDES Heat  ExChamber H2S04pipe2 (p2,p3) UNDERCONDITIONSTRUCTURE CONTAINS " 2SO4pipe2 (p2,p3) H2SO4 UNDERCONDITIONCOMPONENT HeatExChamber volume:vlI temperature ;T Same as state^ but with loc;p3 magnitude;Q_ (c) Behavior "Cool Acid" of HighAcidity SAC Note; All locations are with reference to components in this design.
 All labels for states and transitions are local to this design.
 Figure 1: Design of HighAcidity Sulfuric Acid Cooler behavioral properties, such as acidity of sulfuric acid, and corresponding values, such as low, high, etc.
 The constituents of the S B F model are described below.
 Structure: The structure of a design is expressed in terms of its constituent components and substances and the interactions between them.
 Figure 1(a) shows a h i g h  a c i d i t y s u l f u r i c a c i d c o o l e r (SAC).
 Components and substances can interact both structurally and behaviorally.
 For example, water can flow from HiOpipt to heatexchange chamber only if they are connected, and sulfuric acid flows from pi to p2 due to behavior allow of i/2'504pipel.
 The typology of such structural and behavioral interactions is borrowed from (Bylander, 1991).
 Function: A function of a device is a desired output behavior of the device such as cooling of some substance or producing light of certain color and intensity.
 A function is represented as a schema that specifies the behavioral state the device takes as input, the behavioral state it gives as output, and a pointer to the internal causal behavior of the design that achieves the function.
 Figure 1(b) shows the function "cool acid" of the h i g h  a c i d i t y S A C .
 Both the input state and the output state are represented as substance schemas.
 The input state specifies that sulfuric acid at location pi in the topography of the device (Figure 1(a)) has the properties t e m p e r a t u r e , flow, s t a t e , and acidity, and the corresponding values T l , R, liquid, and high.
 It also specifies that the sulfuric acid contains another substance h e a t whose m a g n i t u d e is Q l .
 Similarly, the output state specifies the properties and the corresponding values of the substance at l o c a t i o n p4.
 Note that the values Tl and T2 of temperature of sulfuric acid are used to denote some corresponding quantitative/qualitative values (e.
g.
, 100 degrees, high, low, etc.
) and that T2 < Tl.
 In addition, the slot bybehavior acts as an index into the causal behavior that achieves the function of cooling sulfuric acid.
 The resulting organization of behaviors around the functions they deliver is based on Sembugamoorthy and Chandrasekaran's (1986) functional representation scheme.
 Behavior: The internal causal behaviors of a device are viewed as sequences of state transitions between behavioral 528 states.
 The annotations on the state transitions express different kinds of context (e.
g.
, causal, functional, and structural contexts) in which the transformation of state variables, such as substance, location, properties, and values, can occur.
 The causal context, for instance, provides causal relations between the variables in preceding and succeeding states.
 I'igure 1(c) shows a fragment of the causal behavior that explains how sulfuric acid is cooled from t e m p e r a t u r e Tl to T2 .
 S t ate2 is the preceding state of t r a n s i t i o n 2 3 and state3 is its succeeding state.
 S t a t e 2 describes the state of sulfuric acid at location p2 and so does stateB at location p3.
 The annotation U S I N G  F U N C T I O N in t r a n s i t i o n 2 3 indicates that the transition occurs due to the behavior allow of/f2'504pipe2 (i.
e.
, functional context).
 Similarly, the U N D E R  C O N D I T I O N  S U B S T A N C E annotation specifies that the behavior allow of i/25'04pipe2 can allow the flow of only some substances—the substances that are in liquid state and that have high acidity.
 One of the annotations U N D E R  C O N D I T I O N  S T R U C T U R E specifies that the heatexchange chamber I N C L U D E S /f25'04pipe2 (i.
e.
, structural context).
 Furthermore, the causal behaviors can be specified at different levels of detail.
 A single transition between two states can be described as a sequence of several states at a different level of detail using the primitive bybehavior (not shown in the example).
 ModelBased Indexing Since the SBF models explicitly specify the device functions, the device structure, and the causal principles that underlie the functioning of the device, a design analog can be indexed by any and all of these.
 But IDeAL's analog memory is organized functionally, i.
e.
, its indexing scheme reflects the reasoning tasks it addresses.
 Since the design task it addresses is specified by the functional and structural constraints on a desired design, the design analogs are indexed by the functions they deliver and the structural constraints they satisfy.
 The SBF models provide the vocabulary for this indexing of the design analogs.
 Functional Indexing of Design Analogs For now, we focus on IDeAL's use of device functions for indexing the design analogs—we will return to the use of structural constraints for indexing in the evaluation section.
 The design analogs are organized in generalizationspecialization hierarchies.
 As described earlier, a function is expressed in terms of substance schemas.
 Since the substance schema specifies properties of substances, IDeAL uses them as dimensions along which design analogs are generalized/specialized.
 For example, it organizes designs of acid coolers along the dimension of property acidity, and discriminates on the corresponding values l o w vs h i g h as shown in Figure 2.
' The H N O i c o o l e r c a s e in Figure 2(a) is a design of lowacidity nitric acid cooler and hence stored under the category that refers to lowacidity coolers.
 pMign ClH M«mory JDMlgn C<M Memory I 'The figure 2(a) illustrates the analog m e m o r y only along the dimension of acidity for clarity.
 T h e property acidity in our example is important because the choice of pipe in the design depends o n whether it has to allow a lowacidity substance or a highacidity substance.
 DImentlon ol girwfillullon: AcldMyy : Dimension of : generelluilon: Acidity LowAcldltyCoolen Acldliy:low Dimension of genenllzailon: Sute AcldltySpecBootNode? Acidity: quallteilvevelue StiteSpecRoolNode9 Suieillquld (^jCooler C W ) III Before the ne» doljn Is stora) LowAcidityCoolers Acldlty:low AcldltyHlghNode« Acldltyihlgh j (fiilOjCoolerCese) iSO^Cooler C*s«) (1)1 Arier the new design is stored onder the learned indices Figure 2: Snapshots of IDeAL's functionally organized analog m e m o r y Learning of Functional Indices Now consider the task of identifying indices for the design of highacidity S A C (Figure 1) when storing it in memory.
 Although the analog memory presently has designs of acid coolers organized only along the dimension of property acidity, perhaps the new analog should be indexed along other dimensions also so that it is more useful in future design episodes.
 There are two different issues concerning the selection of indices for the new design analog.
 First, if a new design is stored only along the substance properties specified in its function, the retriever would not be able to make use of knowledge of other substance properties relevant to the design.
 Second, if the new design is indexed by all the properties of the substance in its function, then the retriever may retrieve a design based on a match with an unimportant property, which can make analog transfer hard or even impossible.
 So, the issue becomes how to determine the substance properties that are relevant to the functioning of highacidity SAC.
 In general, the issue is how to learn "new" indexing vocabulary.
^ IDEAL capitalizes on the knowledge of the causal behaviors in the S B F model of the new analog.
 In particular, it uses the behavioral requirements on the substance expressed under U N D E R  C O N D I T I O N  S U B S T A N C E to identify the substance properties relevant to the functioning of the design.
 These behavioral requirements of a substance specify that in order for the transition to take place, the properties of the specified substance should satisfy certain conditions.
 IDeAL's algorithm for selecting useful indices to a new analog is shown in Figure 3.
 Given a new design analog and the type of indexing (i.
e.
, functions) this method traverses through the causal behaviors in the S B F model of the new analog to identify substance properties on which the working of the design is predicated.
 Since the S B F model can specify multiple behaviors, the outer loop (in step 1) in the algorithm analyzes each causal behavior in the model.
 The second loop is for analyzing the transitions within a causal behavior.
 If a ^By "new" indexing vocabulary, we do not mean that the vocabulary is new to IDeAL but rather it is new for the purpose of indexing.
 529 Input: • Design analog, C, its Functional or Structural specification, F/S, l^pe of indexing, T, (i.
e.
, fijnctional or structural), and all Causal behaviors (model), M , including one for the function.
 Output: • Exact vocabulary for indexing C, i.
e.
, the set of useful features from F/S.
 Procedure: specifiedprops P = getallcomp/subpropertiesrelations(F/S); indices = alternativeindices = plausiblesourcesofindices M ' = {}; while true do 1.
 foreach causal behavior B € M do foreach transition t € B do condilionsonfeatures C F = getunderconditions(T, t); indices = indices U {f | feature f € C F A f € P}; alternativeindices = alternativeindices U {f I feature f € C F A f € P A f € parameterrelations(t)}; if indices = P then exit(indices); if C F = {} then M ' = M ' u getdetailedbehavior(t); 2.
 ifM' = {}then if indices 7̂  {} then exit(indices); if alternativeindices 9̂  {} then exit(altemativeindices); exit(P); 3.
 M = M'; 4.
 M'={}; end.
 Figure 3: The algorithm for obtaining functional indices to design analogs substance property is part of the causal context of a transition,^ then the algorithm adds it to the set of indices if it is a property in the functional specification; and, it adds the property to the set of alternative indices if it is also in the parameterrelations on the transition.
 Since the causal behaviors in IDeAL's S B F model are specified at different levels of detail, the algorithm searches the space of behaviors in a breadthfirst manner If a higher level behavior does not lead to the identification of any useful substance properties, then the more detailed behavior, indicated by bybehavior* is added to the list of plausible sources of indices.
 For example, given the function of h i g h  a c i d i t y SAC and its causal behavior (Figures 1(b) & (c)), the above method results in a c i d i t y and s t a t e as the indexing features for storing this analog in memory.
 This is because the annotation on t r a n s i t i o n 2 3 specifies that the transition can occur only under certain conditions on properties s t a t e and a c i d i t y of the substance flowing through /r2'S'04pipe2.
 The initial analog memory (Figure 2(a)) did not have the property s t a t e as part of its indexing vocabulary.
 The S B F model however suggests that s t a t e is a useful index to the new design analog, and hence IDEAL indexes the new analog by s t a t e also.
 A snapshot of the analog memory after storing this design is shown in Figure 2(b).
 Once the indices are selected, IDEAL uses similaritybased learning to generalize them.
 Under each property, IDEAL organizes the analogs in a binary tree discriminated on values of the property in the analogs.
 It uses the differences in the values of a given property that constitute a type of functional difference between two designs to determine whether the two designs belong to the same category or to different categories.
 For example, the design of highacidity S A C is stored under the category of A c i d i t y  H i g h  N o d e 8 that is different from that of L o w  A c i d i t y  C o o l e r s (Figure 2(b)) because their values of acidity differ The level to which the indices are generalized depends on how similar are the corresponding values in the new and old analogs in memory.
 For instance, a more general category A c i d i t y  S p e c  R o o t  N o d e 7 is created that covers both low and h i g h values of acidity.
̂  Note that H 2 S O 4 Cooler Case is stored in multiple levels corresponding to the nodes A c i d i t y  S p e c  R o o t  N o d e 7 & A c i d i t y  H i g h  N o d e 8 under the property acidity and at one level corresponding to the node S t a t e  S p e c  R o o t  N o d e 9 under the property state.
 Evaluation W e have evaluated IDeAL's modelbased indexing and index learning along a number of different dimensions—we will discuss only one of these dimensions in detail, and briefly mention the others.
 Learning multiple types of indices: In IDEAL, the same representations of S B F models that provide functional indices also provide structural indices.
 W e have tested and found that the same index learning method described in this paper also works for learning structural indices to design analogs.
 (See (Bhatta&Goel, 1993).
) Learning in multiple domains: In addition to the domains of electric circuits and heat exchangers, we have tested and found that the same method of modelbased index learning applies to learning indices to analogs from other domains such as reaction wheel assemblies, controllers, electronic circuits, and electromagnetic devices.
 Effect on the Performance Task of Analog Retrieval: W e used 20 different designs from two different domains (electric circuits and heat exchangers) to test the effect of modelbased index learning on retrieval.
 The independent variable is the number of analogs added to memory and the dependent variable is the normalized average time for retrieving any of the analogs in memory.
 The retrieval time is measured in terms of the number of comparisons needed between a specified problem and the stored analogs along each dimension (i.
e.
, property of substance in functional specification) common to the problem and stored analogs.
 The retrieval time is normalized with respect to the time it takes to retrieve an analog when only that analog is in memory.
 As analogs are added to any memory, the subsequent retrieval time increases.
 In the first set of experiments, the question is whether modelbased index learning has any useful effect on the growth of the retrieval time.
 Within each domain, w e compared the retrieval times on 10 problems as 'getunderconditions in the algorithm gets the annotations such as UNDERCONDITIONSUBSTANCE and UNDERC O N D m O N  C O M P O N E N T from the given transition corresponding to the type of indexing used.
 ''obtained by the function getdetailedbehavior in the algorithm.
 ^The general value of acidity at this higherlevel node comes from IDeAL's knowledge of qualitative values and quantitative values.
 If the values are quaUtative, it is determined by climbing up a known value hierarchy.
 And, if the values are quantitative, a new value range is created that spans from the lowest of the two child nodes in the discrimination tree to the highest of the two.
 530 /C<0'h>\>\T\Cs' 3 Condnion 1 Condnton 2 Condnion 3 :oK.
T>»T«1vJZ cc;^.
^'^T\Ol^ 1 (a) Effect o n retrieval u n d e r 3 conditions of indexing 35 3 25 2 1 5 Condition 1 2 4 6 8 10 U 12 14 16 18 2 r*3 of Designs Added lo Memory (110 ElectricCircurt Domain, 1120 HoalExchanger Domain) (b) Effect of the addition of analogs in o n e d o m a i n o n the retrieval in another Figure 4: Performance measures on analog retrieval task the 10 analogs are added to memory under three different conditions: (1) analogs are stored using modelbased index learning, (2) analogs are stored along all possible features in the respective problems (i.
e.
, models are not used to select the relevant indices), and (3) analogs are stored without any organization in memory (i.
e.
, the bottomline condition in which the retrieval requires an exhaustive search through a list).
 The results are shown in Figure 4(a).
 It is evident from the graph in Figure 4(a) that the rate of growth of retrieval time in modelbased index learning condition is the slowest.
 The next best is the condition (2), with the condition (3) being the worst.
 The reason condition (1) is better than condition (2) is precisely because the S B F models help store the analogs in a relevant, smaller number of features in the problems.
 In this first experiment, new indices are added to memory when the first analog is stored.
 The difference in the number of features selected under conditions (1) and (2) is just 1.
 The difference in the retrieval times in these two conditions when only one analog is stored hence indicates the advantage due to pruning out merely one feature.
 In condition (2), the retrieval time grows faster as analogs are added because of the addition of analogs along the irrelevant feature(s) which in turn increases the retrieval cost due to matching on those features also.
 This experiment is controlled such that there is no confounding effect due to retrieval on partial match (because a partial match requires less number of comparisons in a hierarchy, as the search would stop at a higher level, than a perfect match requires).
 That is, for each of the problems used to measure the retrieval time, there is a perfect match in the stored analogs, and the retrieval under all 3 conditions results in the retrieval of the same analogs.
 W e have also tested another effect of modelbased indexing on analog retrieval.
 The question here is how the addition of analogs to memory under this indexing scheme in one domain affects the retrieval of analogs in another domain.
^ W e first stored the 10 analogs in the domain of electric circuits.
 There are two features under which IDEAL stored these analogs hierarchically based on the feature values.
 Then, we measured the normalized average retrieval time on the retrieval of these 10 analogs as 10 more analogs from the domain of heat exchangers are stored.
 IDeAL stores the second set of 10 analogs under different features than those for the first 10 (as the different sets of features in the problems characterize the domains to be different).
 The results are shown in Figure 4(b).
 A s evident from the graph in Figure 4(b), the retrieval of analogs in the domain of electric circuits is unaffected with the addition of analogs in the domain of heat exchangers except for the spike in the retrieval time once when a new feature is added to memory as an index.
 The spike in the retrieval time is due to the comparisons required at the root node in analog memory to discriminate between the features (that is, for instance, to select the hierarchy under voltage and weed out the hierarchies under acidity and state).
 Thus modelbased indexing is effective in grouping analogs based on their content, and this in turn enables retrieval of only semantically relevant analogs for given problems.
 Although this suggests a useful effect of modelbased indexing on the quality of retrieval in restricting the retrieval to a relevant domain, it is yet to be empirically determined how exactly it affects the quality of retrieval within a given domain.
 Related Research The IDEAL system evolves from our earlier work on the Kritik project(Goel, 1991a; 1991b; 1992).
 IDeAL's S B F models, for example, are directly borrowed from Kritik.
 Falkenhainer, Forbus & Centner (1989) describe the use of mental models for enabling analogical transfer.
 But they do not address the issue of analog retrieval.
 Our work on IDeAL suggests that mental models are also useful for addressing the indexing issues in analog retrieval.
 Like Kritik and Kritik2, the analog memory in IDEAL is organized functionally, i.
e.
, the indexing depends on the functional requirements of the reasoning task(s).
 This is a very general organizational principle.
 Bhatta and R a m (1991), for example, use the same principle to organize scripts and schemas for the task of story understanding.
 Since the S B F models provide an explanation of the functioning of a device, our work is also related to explanationbased approaches to learning such as explanationbased generalization (EBG) (Mitchell, Keller & KedarCabelli, 1986), *Two domains are considered distinct if the structural elements (e.
g.
, batteries, pipes) in the domains are different.
 531 explanationbased learning (EBL) (DeJong & Mooney, 1986), and especially explanationbased indexing (EBI) (Barletta& Mark, 1988).
 This relationship can be analyzed along the dimensions of the learning task, the learning strategy, and the knowledge used by the learning method.
 Learning task: The learning tasks in both (Mitchell, Keller & KedarCabelli, 1986) and (DeJong & Mooney, 1986) pertain to concept learning, not index learning.
 The index learning task addressed by Barletta and Mark (1988) is closely related to and yet different from the one we address.
 EBI assumes that a preenumerated set of indexing features is available, and its learning task is to select some subset of the set of features.
 In contrast, IDEAL knows only about the types of features that are to be used as indices (e.
g.
, the function) but identifies the exact vocabulary for indices from its SBF model of the new analog.
 Of course, IDEAL too knows the vocabulary as part of its representations of the SBF model, but does not know a priori the specific vocabulary for indexing.
 Further, IDEAL learns multiple types of indices (e.
g.
, device function and structural constraints).
 Learning strategy: In addition, our modelbased scheme differs from EBI in the learning strategy itself, although both integrate explanations and experience for index learning.
 Firstly, EBI necessarily determines both irrelevant and relevant indexing features.
 IDEAL in contrast needs to determine only the relevant features.
 This is because the SBF model generated by its problem solver automatically rules out all irrelevant features.
 Secondly, IDeAL integrates modelbased learning with similaritybased learning (SBL).
 Specifically, it uses the modelbased method to determine the relevant indexing features, and SBL to generalize over the selected features.
 Types of knowledge: The explanations in a SBF model are quite different from the explanations in EBG, EBL, and EBI.
 Firstly, the explanations in EBG, EBL, and EBI are general in that they specify only the form of an explanation as being a resolution proof in F O L (i.
e.
, the explanation can be of any type depending on which context it is used for), whereas IDeAL's explanations are of a specific type (i.
e.
, functional) and the content theory of the explanations is critical to its success.
 Secondly, the explanations in E B G and E B L specify how an example is an instance of a target concept, and those in EBI refer to the malfunctions of devices, while SBF models are explanations of the normal functioning of devices.
 Thirdly, the explanations in EBG, EBL, and EBI are constructed at runtime from domain specific rules whereas IDeAL's SBF models are formed by revising old models as part of the problem solving.
 Fourthly, IDeAL's SBF models are grounded in a welldefined componentsubstance ontology.
 Conclusions Our experiments with IDeAL lead us to conclude that mental models of analogs provide a useful method for addressing the indexing issues in analogical reasoning.
 In reference to analogical design in particular, they lead to three specific conclusions.
 ModelBased Indexing: First, structurebehaviorfunction models, together with a specification of the task for which the design analog may be reused, give rise to the vocabulary for indexing design analogs.
 This vocabulary arises from a deeper domain ontology.
 ModelBased Index Learning: Second, the SBF models enable the learning of the vocabulary for indexing new design analogs.
 The modelbased method for index learning can be integrated with the similaritybased method for learning the levels of generalization of the indices.
 Use of ModelBased Indices for Analog Retrieval: Third, the indexing vocabulary suggested by SBF models enables an efficient and effective retrieval of stored analogs.
 Acknowledgements This work has been supported by research grants from NSF (grant C36688), O N R (contract N0001492J1234), Northern Telecom, Georgia Tech Research Corporation, and a C E R grant from NSF (grant CCR8619886), and equipment grants and donations from IBM, Symbolics, and NCR.
 This research has benefited from numerous discussions with other members of our research group, in particular Eleni Stroulia.
 References Barletta, R.
 & Mark.
 W.
 (1988).
 Explanationbased indexing of cases.
 In Kolodner, J.
 (Ed.
), Proc.
 of the DARPA Workshop on CaseBased Reasoning, pages 5060, San Mateo, CA.
 Morgan Kaufmann.
 Bhatta, S.
 & Goel, A.
 (1993).
 Modelbased learning of structural indices to design cases.
 In Proc.
 of the IJCAI workshop on "Reuse of Designs: An Interdisciplinary Cognitive Approach", pages A1A13, Chambery, Savoie, France.
 Bhatta, S.
 & Ram, A.
 (1991).
 Learning indices for schema selection.
 In Proc.
 of the Florida Artificial Intelligence Research Symposium, pages 226231, Cocoa Beach, FL.
 Bylander, T.
 (1991).
 A theory of consolidation for reasoning about devices.
 International Journal of ManMachine Studies, 55(4), 467^89.
 DeJong, G.
 & Mooney, R.
 (1986).
 Explanationbased learning: An alternative view.
 Machine Learning, 1{2), 145176.
 Falkenhainer, B.
, Forbus, K.
, & Gentner, D.
 (1989).
 The structuremapping engine: Algorithm and examples.
 Artificial Intelligence,4I, 163.
 Goel, A.
 (1991a).
 A modelbased approach to case adaptation.
 In Proc.
 of the Thirteenth Annual Conference of the Cognitive Science Society, pages 143148, Chicago.
 Goel, A.
 (1991b).
 Model revision: A theory of incremental model learning.
 In Proc.
 of the Eighth International Conference on Machine Learning, pages 605609, Chicago.
 Goel, A.
 (1992).
 Representation of design functions in experiencebased design.
 In Brown, D.
, Waldron, M.
, & Yoshikawa, H.
 (Eds.
), Intelligent Computer Aided Design, pages 283308.
 Amsterdam, Netherlands: NorthHolland.
 Mitchell, T M.
, Keller, R.
, & KedarCabelli, S.
 (1986).
 Explanationbased generalization: A unifying view.
 Machine Learning, I{ 1), 4780.
 Sembugamoorthy, V.
 & Chandrasekaran, B.
 (1986).
 Functional representation of devices and compilation of diagnostic problemsolving systems.
 In J.
Kolodner & C.
Riesbeck (Eds.
), Experience, Memory and Reasoning, pages 4773.
 Hillsdale, NJ: Lawrence Erlbaum.
 532 T h e Relative Importance of Spaces and Meaning in Reading James R.
 Booth jbl640umail.
umd.
edu Julie Epelboim yulya0brissun.
umd.
edu Robert M .
 Steinman 3teinman@bris3un.
umd.
edu Department of Psychology University of Maryland College Park, Maryland 20742^ 11 Abstract The relative importance of meaiung (semantic context) and spaces between words during reading was investigated.
 Subjects read paragraphs of coherent or incoherent text aloud; some paragraphs were presented normally, others with spaces between words removed.
 Coherent paragrafrfis were taken from a short story.
 Incoherent paragraj^ had the same words and punctuation as the coherent paragrajrfis, but the order of these words was randomized, resulting in text devoid of meaning normally provided by context and syntactical structure.
 As expected, spaced text was read faster and with fewer pronunciation errors than unspaced text, and coherent text was read faster and with fewer pronunciation errors than incoherent text, regardless of the presence or absence of spaces between words.
 Removing spaces slowed reading down less and caused fewer pronunciation errors when the text was meaningful (coherent), than when the text was meaningless (incoherent), so spaces helped more when the text was meaningless than when the text was meaningful.
 The fact that spaces between words were more important for reading meaningless text than for reading meaningful text suggests that semantics, rather than spaces, are the more important determinants of reading speed and errors.
 Introduction Current theories of reading stress the importance of gross visual features of the text, namely, spaces between words (interword spaces), for guiding saccades as the text is read (e.
g.
 Pollatsek & Rayner, 1982; Morris, Rayner, & Pollatsek, 1990, Rayner, 1993; O'Regan, 1990; Rayner & Pollatsek, in press).
 This claim has been questioned recently.
 Epelboim, Booth & Steinman (1994; in press) found that subjects could read texts from which interword spaces were removed with only modest decrements in reading speed.
 Two subjects even read unspaced texts as quickly as they read spaced texts, despite the fact that they had had no prior experience reading unspaced texts.
 Epelboim et al.
 (1994) also found no differences in where, within words, subjects fixated, or in the percentage of their regressions, a widelyused measure of reading difficulty.
 These and other results allowed Epelboim et al.
 (1994) to conclude that the same oculomotor strategy was used for reading spaced and unspaced texts, and that cognitive factors, such as word recognition, rather than gross physical features of the texts, such as spaces, were the primary determinants of saccadic programming and reading rates.
 These findings should not come as a surprise because many ancient, as well as m o d e m languages, such as Thai and Japanese (see Fig.
 1), do not place spaces between words 0 lu iriQnnn^'jmiuvi^uifluQ'inn fi'jnn^4^UYiR«>iRutRi7iJ'airu'l\iuu v)ufininirhwwul7lunifidni/iou»4<u Figure 1: A passage of Thai text Thai is an alphabetic language containing 44 letters.
 Small symbols that appear above some of the letters are part of the letters, and cannot, by themselves, indicate word boundaries.
 Spaces in Thai text (there are 3 in this passage) are used to separate phrases, not single words.
 The English paraphrase of this passage is: "Doi Tung is the name of a high mountain north of Chiang Rai, Thailand's northern most province.
 Covering an area of some 90,000 rai in M a e Chan and Mai Sei districts, the mountain has cold climate and picturesque scenery.
" in text Some m o d e m languages, such as Dutch and German, are sparselyspaced — they contain many very long, compound nouns.
 Consider the following Dutch sentence and its literal English translation: Op het treinmachinistencongres waren vertegenwoordigers van de arbeidsinspectiedienst van spoorwegpersoneel maar ook perronkaartjesverkopers en fietsenstallingbewakers.
 At the train drivers congress were representatives of the labor inspection service of railway employees but also platform ticket sellers and bicycle shack custodians.
 A reader, relying on spaces for saccadic programming, would have difficulty reading this Dutch sentence.
 Although it is possible that readers of generouslyspaced languages, such as EngUsh, depend on spaces for saccadic programming, and that some other oculomotor stfaiegy is used for unspaced 533 http://umd.
edumailto:3teinman@bris3un.
umd.
eduor sparselyspaced languages, a more parsimonious theory of reading is possible.
 It only requires emphasizing words, recognized or anticipated on the basis of meaning derived from context (syntax and semantics), rather than placing emphasis on spaces between unprocessed groups of letters, to guide the line of sight through the texL Semantics is a defining feature of all languages and its importance in reading has been known for a long time.
 Huey (1900) showed that meaning increases the rale with which progressive saccades can be made.
 This finding was confirmed recently by Kowler, Pizlo, Zhu, Erkelens, Steinman & Collewijn (1992).
 Both studies showed that making readinglike saccades through a "text", where all but the first letter of each word was blocked out, was slower than reading the same text with the words intact and meaning preserved.
 Removing spaces between words influences semantics, as well as changes the physical appearance of the text.
 Letters around word boundaries in unspaced texts can be grouped incorrecdy, alt^ng the meaning of a phrase being read (see Jusczyk, 1986, p.
 272).
 It has been shown that many kinds of transformed texts can be read fairly easily as long as familiar letter patterns (words or morphemes) are not disturbed.
 When letter patterns are disturbed, however, reading becomes very difficult (Kowler & Anton, 1987; Kolers, 1968).
 These considerations suggest that word recognition, not saccadic programming, limits reading speed.
 Unspaced texts are read more slowly than spaced texts because when spaces are removed, word recognition becomes more difficult.
 Epelboim et al.
 (1994) supported this idea by showing that keeping words intact was more important than having spaces in a text.
 Removing interword spaces from a meaningful text did not reduce reading rates nearly as much as keeping spaces, but putting them at inappropriate places in the text The latter made reading nearly impossible.
 The goal of the present study was to determine the relative importance of spaces and meaning for reading.
 It had been shown previously that reading lists of unrelated words takes longer than reading the same words presented as meaningful text (Biemiller, 197778), suggesting that a meaningful context facilitates word recognition.
 If difficulty in word recognition slows reading of unspaced text more than spaced text, meaningless unspaced text should be harder to read than meaningful, unspaced texL If, however, removing spaces disturbs saccadic programming, differences between spaced and unspaced reading rates should be the same regardless of whether the text is meaningful or meaningless.
 This proved no< to be the case.
 Method Subjects Four undergraduate students in the University Honors Program and three graduate sttidents at the University of Maryland served as subjects.
 All were native English speakers with normal or corrected to normal vision, and were naive as to the purpose of the experiment Materials Text, presented white on a blue background, was taken from "The Blue Cross" in The Innocence of Father Brown by G.
K.
 Spaced Coherent Between the silver ribbon of morning and the green glittering ribbon of sea, the boat touched Harwich and let loose a swarm of folk like flies, among whom the man we must follow was by no means conspicuous — nor wished to be.
 Spaced Incoherent Papered for strong Castor to element had and stand ridiculous really up and, but they instant robbery sea his brown I still he face turn brain, early then and was he show wisdom one of do judge peppermints — had splash he it.
 Unspaced Coherent Probablyhewouldtravelassomeminor clerkorsecretaryconnectedwithit; but,ofcourse,Valentincouldnotbe certain;nobodycouldbecertainabout Flambeau.
 Unspaced Incoherent Valentinorfirstsecondheweretalks whileheeagernesstangerinetheyat ; and,hesprang,colossusnamedtheit snail' s;motorsotherhefeelingspell suddenly.
 Figure 2: Different kinds of text used in the experiments.
 Chesterton.
 The paragraph structure of the story was altered so that each paragraph contained between 9 and 11 lines of text that were presented, doublespaced, on a computer monitor (IBM 486DX).
 These paragraphs served as "coherent", meaningful text The text chosen for this experiment was fairly difficult.
 Difficult text was used deliberately in order to avoid ceiling effects, which would be a problem with easy text in which reading speed would be determined by the speed with which subjects could pronounce the words as they read normal text aloud, rather than by inho'ent differences in the experimental variables of interest, i.
e.
 spaces and meaning.
 "Incoherent", meaningless, text was created by replacing each word in the "coherent" text with a word of equal length taken randomly, without replacement, from within the entire story (65 paragraphs).
 This procedure equated word frequencies and the placement of spaces.
 Punctuation marks and capitals were also preserved.
 As a result, coherent and incoherent paragraphs had similar gross visual characteristics, word lengths and word frequencies.
 Coherent and incoherent paragraphs were presented both with spaces between words and with spaces removed (see Fig.
 2).
 Displays of spaced texts were about 60 characters wide.
 Spaces were taken out without readjusting linewidth, leaving the mean number of words per line the same in both spaced and unspaced texts, but a line of spaced text was about 15% wider than a line of unspaced text.
 Coherent and incoherent conditions were run in separate blocks, with a 10 minute break 534 • Spaced H Unspaced 150 (/) 250 Q^ COH INC Figure 3: Mean reading times (seconds/word — left ordinate) and speeds (words/minute — right ordinate) for 7 individual subjects (labeled S1S7 on top) reading coherent (COH ) and incoherent (INC) paragraphs.
 Open bars show means for spaced text, filled bars show means for unspaced text Error bars show 1 SD.
 Each bar is based on 10 paragraphs.
 in between.
 Within each text condition, each subject read 10 paragraphs in alternating pairs of 2 spaced and 2 unspaced paragraphs.
 Procedure Before the start of each session, the subject positioned the chair and the display screen such that the text was clearly visible.
 Subjects were told not to start a trial unless they could clearly see a sentence indicating the nature of the upcoming paragraph ('The next paragraph will be spaced" or "Thenextparagraphwillbeunspaced").
 Subjects fixated on the capital'T", the first letter of this introductory sentence, which appeared at the upper left comer of the screen.
 This position corresponded to the location of the first letter of the upcoming paragraph.
 The spacebar was pressed when ready to read, and pressed again as soon as the paragraph had been read, at which time the paragraph disappeared.
 Reading time of each paragraph (bar press to bar press) was recorded to the nearest 10 ms.
 Blocks started with 2 spaced and 2 unspaced practice paragraphs followed by 20 test paragraphs.
 Subjects read aloud and their speech was recorded.
 They were told to read with meaning, to articulate each word, and that they would have to summarize the story later.
 All paragraphs were read aloud and the subjects' speech was recorded.
 Reading aloud provides an unambiquous and continuous measure of reading competence, tfiat is, the speech can be scored for errors in pronunciation and intonation.
 This measure was particularly important for reading incoherent text, where comprehension could not be measured in any other way.
 In our view, reading aloud is the best way to study reading, especially when processing meaning is an important feature, as it is in our experiment, because asking subjects to read aloud provides the only way to monitor comprehension as text is actually being read.
 Posthoc questioning, the only way to lest silent reading, continues to be controversial (e.
g.
 Katz, Blackburn & Lautenschlager, 1991; Freedle & Kostin, 1994; Katz & Lautenschlager, 1995).
 Inasmuch as there is no evidence that reading silently and reading aloud are fundamentally different (see Epelboim el al.
, 1994, for a recent comparison of silent reading and reading aloud), w e believe that reading aloud should be the preferred paradigm in reading research.
 Although most reading in everyday life is silent, it is difficult to understand the role of variables in the text being read, such as spaces and meaning, if comprehension cannot be indexed as the reader proceeds through the text.
 This is not possible when text is x&aA silently.
 Pronunciation of each word was scored for accuracy into 4 categories: 1) "Errors" — words pronounced incorrectly; 2) "Hangups" — words repeated inappropriately, but eventually pronounced correctly; 3) "Deletions" — words not aiticulated; and 4) "Additions" — words articulated, but not in 535 the text.
 Results Individual performance Reading times.
 Figure 3 shows mean reading times and speeds of each of the 7 subjects who served in this experiment.
 Subjects varied considerably in their ability to read unspaced text The best subject, S2, slowed down by only 1 4 % when spaces were removed from coherent text.
 The worst subject, S4, slowed down by about 5 3 % .
 This range of individual differences was similar to the range (0 to 4 8 % ) observed previously when paragraphs of unspaced text were read aloud (Epelboim et al.
, 1994).
 Despite such within subject variability, all subjects showed the same pattern of results.
 Specifically, they read spaced text faster than unspaced text (p < 0.
001) and coherent text faster than incoherent text (p < 0.
001).
 In addition, the absence of spaces affected the reading of meaningful text less than it affected the reading of meaningless text, that is, spaces helped more when no meaning was provided by context.
 This interaction between spaces and meaning was statistically significant for 6 of the 7 subjects (p < 0.
01) and approached significance for the other subject (S4,p < 0.
1).
 Errors.
 Only pronunciation errors, type 1 (see Method above), will be considered here because the number of deletions and additions were too small to allow meaningful statistical analyses.
 The number of hangups, although larger, showed only the main effect for spaced vs.
 unlaced reading.
 The percentage of type 1 errors ranged from 0 to 9%.
 The pattern of errors was the same as the pattern of reading rates, that is, the subjects made more errors with unspaced than with spaced text, and more errors with meaningless than with meaningful text.
 The effect of spaces was statistically significant for all six subjects, whose errors were scored (p < 0.
001; pronunciation data for S7 could not be reported because of a recorder problem).
 The effect of meaning was statistically significant for 4 of these subjects (p < 0.
001) and approached significance for the other 2 (p < 0.
1).
 As with reading times, the absence of spaces increased the number of errors more when the text had no meaning.
 This interaction between spaces and meaning was statistically significant for SI and S2(p < 0.
05), approached significance for S3 and S6 (p < 0.
1), and was not significant for S4 and S5.
 The pattern of reading times and errors for individual subjects reported just above supports our hypothesis that meaning and word recognition are more important for reading than spaces and saccadic programming.
 Group performance A c o m m o n approach in reading research is to report data averaged over all subjects with no discussion of the data of individual subjects or indication of the withinsubject variability.
 This approach is unfortunate because reading characteristics are long known to vary greatly among individuals (e.
g.
 Buswell, in Kolers, 1976), which means that the pattern of results observed with averaged data need not be indicative of what individual subjects actually did.
 The next section is included to present a summary of the data averaged over all subjects for those readers accustomed to considering reading D Spaced Unspaced 120 _ <2 0 6 a 04 Figure 4: Mean reading times (seconds/word) and speeds (words/minute) averaged over all seven subjects.
 Error bars show 1 SE based on the individual subject means.
 data iM^sented in this form.
 In our experiment, grouping the data, fortunately, did not distort the pattern of results obs^^ed with each individual subject in any way.
 Reading times.
 The mean reading times and speeds averaged over all seven subjects are shown in Fig.
 4.
 The pattern of group performance was similar to the performance of the individual subjects.
 As a group, subjects read spaced text faster than unspaced text (F(l,256)=379.
74,p < 0.
001), and read meaningful text faster than meaningless text (F(l,256)=158.
39,p < 0.
001).
 As was the case with individual subjects, spaces and meaning interacted (F(l,256)=27.
25, p < 0.
001).
 Errors.
 The group pattern of errors was also the same as the pattern for reading times.
 Subjects made fewer errors when they read spaced text than when they read unspaced text (F( 1,256)= 108.
04, p < 0.
001) and fewer errors when they read meaningful text than when they read meaningless text (F(l,256)=43.
67,p < 0.
001).
 The interaction between ^aces and meaning was also significant (F(l,256)=17.
71,p < 0.
001).
 Discussion Reading times and error rates were influenced by the absence of ̂ aces more when the text being read had no meaning.
 Furthermore, meaningless text benefitted more from interword ̂ aces than meaningful text.
 These findings support the hypothesis that reading slows down when spaces are removed because removing spaces impairs word recognition when letter groupings become ambiguous, and not because removing 536 spaces impairs saccadic programming.
 This conclusion shifts emphasis from the physical features of the text to its meaning.
 This shift of emphasis can be used to: (1) explain large individual diH'erences observed in prior experiments in which unspaced texts were read, and (2) speculate about why spaces were introduced into many m o d e m languages, written and then printed, unspaced for millennia prior to the 16"' century (Boorstein, 1983).
 Relevance to prior research There have been many studies of the role of spaces in reading.
 In most, spaces were filled with a variety of characters, including random letters, random numbers and gratings (e.
g.
 Pollatsek & Rayner, 1982; Morris et ai, 1990).
 Most prior studies also used isolated sentences rather than coherent text — a practice that deemphasizes meaning conveyed by context in ordinary text The only experiments, to our knowledge, in which interword spaces were simply removed with nothing else added, and in which coherent paragraphs were read, were performed by Fisher and his collaborators (reviewed in Fisher, 1976).
 Spragins, Lefton & Fisher (1976) measured reading rates of thirdgraders, fifthgraders and adults as they read normal and unspaced paragr^hs.
 Thirdgraders read unspaced texts only 2 6 % slower than they read spaced texts, whereas adults and fifihgraders read unspaced text about 4 9 % slower.
 Reading unspaced text became poorer as reading skills improved! Spragins et al.
 explained this result by suggesting that the younger children suffered less from the removal of spaces because they did not use peripheral visual information about the gross shapes of the words to the right of fixation.
 According to this hypothesis the children read letterbyletter or, at best, one word at a time.
 An alternative explanation, based on our results and other recent developmental research is possible.
 Once emphasis is placed on the meaning of the text rather than on its physical appearance, the results of Spragins et al.
 can be explained differently.
 Namely, it is wellknown that younger children use context information about meaning more during reading than adults and older children (Schwantes, 1991; Stanovich, 1980).
 Thus, when thirdgraders read unspaced texts, they benefited more from the context of the paragraph than older children or adults.
 Older children and adults rely more on recognizing individual words than on context when they read.
 They discriminate words more easily and guess less about what is coming up in the text W h e n interword spaces are removed, however, some letters may be grouped inappropriately to form words that do not fit within the context of the paragraph.
 Having to resolve conflicts between the meaning of the text and the words being recognized visually takes time, which results in slower reading.
 W h e n lettergrouping errors occur in meaningless, incoherent text, they are more difficult to resolve because there is no context to help the reader decide which grouping forms the Expropriate word.
 For this reason reading without spaces is more difficult when the text has no meaning.
 Individual Differences The tendency to use context less as reading becomes more skilled, welldocumented in the Developmental literature.
 suggests a plausible explanation for the large range of individual differences observed in the adult subject's ability to read unspaced text W h e n children are taught to read, they are often taught by the "phonics" method, in which individual letters are sounded out to form words.
 Early on, when they are slow at sounding letters, children must rely heavily on context 10 recognize words.
 As reading skill increases, words are recognized more easily and context is relied on less.
 This allows reading of meaningless text and even allows reading of text not understood by the reader (Allington & Reming, 1978; Doehring, 1976).
 N B .
 The widelyused phonics method for teaching reading is not without controversy, going in and out of vogue cyclicly.
 Huey, back in 1900, criticized the phonics method, suggesting that children should be taught to read whole words or even phrases, rather than to sound words one letter at a time.
 Thai children, whose language is unspaced, are taught in the manner suggested by Huey.
 They are first taught to read individual words, but when sentences are introduced, words within them are unspaced from their very first appearance.
 It is possible that some people, like our subjects 52 and S7 (our "best" unspaced readers), retain into adulthood their ability to benefit from context when they read.
 52 and 57 slowed down by only 1 4 % and 2 3 % , respectively, when spaces were removed from coherent text 52 and S7, however, were our "worst" subjects when meaning was removed from spaced text, slowing down by 3 8 % and 3 5 % , respectively.
 This observation also supports the suggestion that these subjects relied on context more than the other five subjects.
 Epelboim et al.
 (1994) also found that some readers were better than others in reading unspaced texts.
 Their best unspacedreader was a Dutchman.
 H e read spaced and unspaced Dutch text equally quickly, and unspaced English text only 1 8 % slower than ̂ aced English text.
 His exceptional ability to read without spaces in both his native and a second language, may have been the result of a lifetime of reading a native language, Dutch, which is sparselyspaced as compared to English or the Romance languages.
 W e beUeve that a cognitive explanation of the individual differences in the observed ability to read unspaced text is both more plausible and more satisfying than an explanation that relies on differences in eye movement strategies.
 It seems likely that the large range of abilities observed when unspaced text is read arises from the more efficient use of context, or, from better word recognition skills, or, from a larger available vocabulary, or, from a higher level of reading comprehension, or, from better visual acuity (the hypothesis proposed in Epelboim et al.
, 1994).
 All of these cognitive and sensory, rather than oculomotor, characteristics are known to vary widely among individuals.
 O n the other hand, the eye movements of normal readers of different languages show little variability except in global parameters, such as saccade length or direction.
 What are spaces for? Epelboim et al.
 (1994) suggested that one reason spaces between words may have been introduced was to allow reading under poor lighting conditions or with less than perfect vision.
 Blurry strings of letters separated by spaces can be read more easily than blurry strings of letters not separated by spaces.
 Another reason, suggested by the present study, 537 may have been to allow people to "read" text they do not understand.
 Illiterate copiers of manuscripts often put spaces into texts inappropriately for aesthetic reasons, rather than to separate actual words (Boorstin, 1983).
 These inappropriate spaces, which may have been aesthetically pleasing to illiterate scribes, surely made reading more difficult for those who could understand what they read.
 Spaces between words, in this view, were introduced into text first to reduce errors in handcopying by illiterate scribes and then to help illiterate typesetters set and proof text after printing was invented.
 Conclusion Much emphasis in recent years has been placed on the importance of visual features as guides for eye movements during reading.
 This emphasis derives from the ease with which eye movements can be recorded with modem instruments, and with which texts can be displayed and perturbed contingent on the approximate locus of the line of sight within the text.
 The role of meaning has not been emphasized despite Buswell's sage pronouncement that "reading is the process of comprehending meanings" (in Kolers, 1976).
 Our study shows that it may finally be time to accq>t long known, and rather obvious, facts, and face squarely the message clear in our data, as well as in the histiMy of written languages: meaning matters.
 Acknowledgments This research was supported by the grants from the Life Sciences Directorate of the Air Force Office for Scientific Research; R%2092J02060, and FA 4%209410333 and by a grant from the Office of Educational Research and Improvement, U.
S.
 DqjartmOTt of Education: 01432735.
 W e thank Mrs.
 Preyawan Dara from the Office of Information at the Royal Thai Embassy for an explanation of the nature of the Thai language and for information regarding Thai schooling practices, and Suzan Markestijn for providing the Dutch sentence used.
 References Allington, R i .
 & Fleming, J.
T.
 (1978).
 The misreading of high frequency words.
 The Journal of Special Education, 12,417421.
 Biemiller, A.
 (197778).
 Relationships between oral reading rates for letters, words, and simple text in the development of reading achievement Reading Research Quarterly, 2, 223253.
 Boorstin, DJ.
 (1983).
 The Discoverers.
 N e w York: Random House.
 Doehring, D.
G.
 (1976).
 Acquisition of rapid reading req)onses.
 Monographs of the SRCD, 41 (2, Serial No.
 165).
 Epelboim, J.
, Booth.
 J.
B.
 & Steinman, R.
M.
 (1994).
 Reading unspaced text Implications for theories of eye movements.
 Vision Research, 34.
17351766.
 Epelboim, J.
, Booth, J.
B.
 & Steinman.
 R.
M.
 (in press).
 Much ado about nothing: the place of space in text.
 Vision Research.
 Fisher.
 D.
 (1976).
 Spatial factors in reading and search: The case for space.
 In Monty, A.
 & Senders, W.
 (Eds), Eye movements and psychological processes (pp.
 417427).
 Hillsdale, NJ.
: Erlbaum.
 Freedle, R.
 & Kostin.
 I.
 (1994).
 Can multiplechoice reading tests be constructvalid? A reply to Katz, Lautenschlager, Blackburn & Harris.
 Psychological Science, 5,107110, Huey, E.
B.
 (1900).
 On the psychology and physiology of reading.
 The American Journal of Psychology, 11, 283302.
 Jusczyk.
 P.
 (1986).
 Speech perception.
 In Boff, K.
, Kaufman, L.
 & Thomas, J.
 (Eds), Handbook of perception and performance, (Vol.
 2, Chap.
 27).
 New York: Wiley.
 Katz, S.
, Blackburn, A.
B.
 & Lautenschlager, G.
 (1991).
 Answering reading comprehension items without passages on the SAT when items are quasirandomized.
 Educational and Psychological Measurement, 51.
 747754.
 Katz.
 S.
 & Lautenschlager, G J.
 (1995).
 The SAT reading task in question: Reply to Freedle and Kostin.
 Psychological Science, 6,126127.
 Kolers, P.
A.
 (1968).
 The recognition of geometrically transformed text Perception andPsychophysics, 3,5764.
 Kolers, P.
A.
 (1976).
 Buswell's discoveries.
 In R.
A.
 Monty & J.
W.
 Senders (Eds.
), Eye movements in reading: Perceptual and language processes.
 Hillsdale, NJ: Erlbaum.
 Kowler, E.
 & Anton, S.
 (1987).
 Reading twisted text Implications for the role of saccades.
 Vision Research, 27, 4560.
 Kowler, E.
.
 Pizlo.
 Z.
, Zhu.
 G.
.
 Erkelens.
 C.
J.
.
 Steinman, R.
M.
 & Collewijn, H.
 (1992).
 Coordination of head and eyes during the performance of natural (and unnatural) visual tasks.
 In A.
 Berthoz, P.
R Vidal, & W.
 Graf (Eds.
) The head neck sensory motor system (pp.
 419426).
 Oxford: Oxford University Press.
 Mwris, R.
K.
, Rayner, K.
 & Pollatsek, A.
 (1990).
 Eye movement guidance in reading: The role of parafoveal letter and space information.
 Journal of Experimental Psychology: ///'P, 16,268281.
 O'Regan, J.
K.
 (1990).
 Eye movements in reading.
 In E.
 Kowler (ed.
).
 Eye movements and their role in visual and cognitive processes (pp.
 395453).
 Amsterdam: Elsevier.
 Pollatsek, A.
 & Rayner, K.
 (1982).
 Eye movement control in reading: The role of word boundaries.
 Journal of Experimental Psychology: HPP, 8,817833.
 Rayner, K.
 (1993).
 Eye movements in reading: Recent developments.
 Current Directions in Psychological Science, 2, 8185.
 Rayner, K.
 & Pollatsek, S.
 (in press).
 Reading unspaced text is not easy: Comments on the implications of Epelboim et a/.
's study (1994) for models of eye movement control in reading.
 Vision Research.
 Schwanies, F.
M.
 (1991).
 Children's use of semantic and syntactic information for word recognition and determination of sentence meaningfulness.
 Journal of Reading Behavior, 23,335350.
 Spragins, A.
B.
, Lefton.
 L.
A.
 & Fisher.
 D.
F.
 (1976).
 Eye movements while reading and searching spatially transformed text A developmental examination.
 Memory and Cognition, 4.
 3642.
 Stanovich, K.
E.
 (1980).
 Toward an interactivecompensatory model of individual differences in the development of reading fluency.
 Reading Research Quarterly, 16.
3271.
 538 The Convergence of Explanatory Coherence and the Story Model: A Case Study in Juror Decision Michael D.
 Byrne School of Psychology Georgia Institute of Technology Atlanta, Georgia 303320170 b y r n e @ c c .
 g a t e c h .
 e d u Abstract This paper presents an integration of two approaches to complex decisionmaking from very different traditions: from the psychology of jury decision, the Story Model, and from the philosophy of science, the Theory of Explanatory Coherence and its con^utational instantiation, E C H O .
 The subjects in Pennington & Hastie (1993) generated causal "stories" to represent the events related to a particular trial.
 These stories were modeled with E C H O , and E C H O reached the same verdicts as did the human subjects.
 The E C H O simulations were also linked to the trial testimony, which, despite the inconsistent nature of the testimony, actually increased the coherence of stories for two jurors with very different verdicts.
 Implications for both the Story Model and E C H O are discussed.
 Introduction One of the questions confronting both psychology and philosophy is understanding how it is that people make decisions in complex situations.
 Such situations often contain contradictory evidence, gaps in what is known, and the like.
 While no complete account has yet been offered, similar frameworks for understanding complex decisions have arisen, and from very different traditions.
 One tradition is that of the historical philosophy of science, which attempts to understand how it is that scientists come to accept new paradigms.
 While there have been many approaches to understanding what Kuhn (1962) termed a "paradigm shift," the one considered here is Thagard's (1989, 1992a) Theory of Explanatory Coherence (TEC) and the associated computational model, E C H O .
 The second tradition is the psychology of jury decisions, which attempts to understand how it is that jurors arrive at a particular verdict.
 This, too, is not a field with a unitary way of understanding its phenomena, but one model that has been particularly promising in this area is the Story Model (Pennington & Hastie, 1986; 1993).
 Interestingly, work beginning in these seemingly disparate domains has converged to the point that it should be possible to integrate the two frameworks into a unitary theory of complex decisionmaking.
 While presenting such an integrated theory is beyond the scope of this presentation, it is fx)ssible to demonstrate that these two approaches are both consistent and complementary.
 This will be made clear by presenting T E C  E C H O simulations of some of the data which has been used to support the Story Model.
 To understand these examples, the two frameworks will first be described and then the simulations presented.
 A discussion of the implications for both approaches and possible integration will follow the presentation of the simulation models.
 Explanatory Coherence and ECHO In attempting to understand how it is that scientists make decisions to accept new theoretical positions, Thagard has constructed the Theory of Explanatory Coherence (TEC) and a computational modeling system which embodies the principles of T E C , E C H O .
 T E C and E C H O have been used to provide "a mechanism that can lead people to abandon an old conceptual system and accept a new one" (Thagard, 1992a, p.
 62).
 In T E C , "explain" is taken to be a primitive relation between propositions (P, Q, and PiP^) in an explanatory scheme (S).
 Coherence, then, is the extent to which the propositions in the system follow the "principles" of explanatory coherence: Principle 1.
 Svmmetrv (a) If P and Q cohere, then Q and P cohere.
 (b) If P and Q incohere, then Q and P incohere.
 Principle 2.
 Explanation IfPl.
.
.
P„ explain Q, then (a) For each Pj in Pj .
Pn,, P̂  and Q cohere.
 (b) For each P̂  and Pj in P,.
.
.
P̂ , P; and Pj cohere.
 (c) In (a) and (b) the degree of coherence is inversely proper tional to the number of propositions Pj .
.
.
P^.
 Principle 3.
 Analogy If Pj explains Q j, Pj explains Qj, Pj is analogous to Pj, and Qj is analogous to Qj, then Pj and Pj cohere, and Q, and Q2 cohere.
 Principle 4.
 Data Priority Propositions that describe the results of observations have a degree of acceptability on their own.
 Principle 5.
 Contradiction If P contradicts Q, then P and Q incohere.
 Principle 6.
 Competition If P and Q both explain a proposition Pj, and if Pand Q are not explanatorily connected, then Pand Q incohere.
 Here P and Q are explanatorily connected if any of the following conditions holds: (a) P is part of the explanation of Q.
 (b) Q is part of the explanation of P.
 (c) P and Q are together part of the explanation of some proposition, Pj.
 Principle 7.
 Acceptability (a) The acceptability of a proposition P in a system S depends 539 mailto:byrne@cc.
gatech.
eduon Its coherence with the propositions in S.
 (b) If many results of relevant experimental observations are unexplained, then the acceptability of a proposition P that ex plains only a few of them is reduced.
 which were taken directly from Thagard (1992a), The coherence of a large system of explaining and contradicting propositions cannot be computed simply by informally applying the principles of T E C (despite criticisms to the contrary, which have not demonstrated themselves to be successful).
 In light of this, a connectionist (though not PDF) system called E C H O has been developed which makes this computation straightforward.
 T E C and E C H O have been used to explain numerous scientific revolutions such as the Copernican revolution (Nowak & Thagard, 1992; Thagard, 1992a) as well as various complex decisions, such as Hitler's belief the Allies would invade Calais rather than Normandy and the decision of the captain of the USS Vincennes which led to the destruction of a passenger aircraft (Thagard, 1992b).
 Most closely related to the present issue, E C H O has been used to model prominent jury verdicts (Thagard, 1989), though this work did not model the decisions of individual jurors, nor were the E C H O models based on explanations actually provided by human subjects.
 One of the criticisms that has been raised (e.
g.
 Giere, 1993) about the E C H O simulations is that the "explanations" have been provided to the system by the programmer—that is, the propositions used and the explanatory and contradictory links between them have all been decided upon by the same person, and since it is impossible to know what explanations that, say, Darwin actually considered, the simulations are in some way invalid.
' The simulations presented here later address this issue by using the explanations provided by the jurors themselves rather than explanations provided by the programmer.
^ The Story Model The Story Model was developed to explain how individual jurors reach particular verdicts.
 Decisionmaking by jurors represents an interesting and complex psychological domain, because jurors typically receive large amounts of often contradictory evidence in essentially random order.
 One of the reasons for the success of the Story Model is that other, more "traditional" decision models have difficulty modeling human decisions under such conditions (Pennington & Hastie, 1992).
 The Story Model maintains that jurors arrive at decisions as the result of a threestage process: (1) Story Construction, "an active, constructive compre'This is not a particularly imaginative criticism, as the algorithms and input data used by almost all computational models are supplied by the researchers—for example, the "feature vectors" supplied to connectionist models (e.
g.
 Churchland, 1989).
 The burden is upon the critics to demonstrate why the explanations supplied E C H O are wrong.
 So fai; Thagard's critics have failed to do this for all but the simplest of the E C H O simulations, the Darwin example (Thagard, 1989; 1992a.
 Chapter 6).
 ^ It should also be noted that Thagard (1992a, Chapter 4) directly addresses this criticism in several different ways.
 hension process in which they make sense of trial information by attempting to organize it into a coherent mental representation" (Pennington & Hastie, 1992, p.
 190).
 These representations typically take the form of stories with causal links between episodes in the story.
 It is possible for jurors to construct more than one story, and in that case stories are judged on the basis of their acceptability.
 According to the Story Model, acceptability is a function of coherence, completeness, and uniqueness.
 These principles, when explained in greater detail, parallel those of TEC, as has been observed both by Thagard (1989) and Pennington and Hastie (1993).
 (2) Verdict Representation, in which the juror constructs a representation of the possible verdicts.
 In most criminal cases, verdicts consist of more than simply "guilty" or "not guilty.
" For example, in the murder case used in Pennington and Hastie (1986), the jurors have four options: firstdegree murder, seconddegree murder, manslaughter, and not guilty.
 Verdicts are represented along four axes: identity (i.
e.
 was the defendant the one?), mental state of the defendant at the time, circumstances during the event, and the actions taken by the defendant.
 While jurors differ from one another in terms of their representations of the verdicts, this does not play a central role, as differences in verdict representations are not associated with differences in decision outcomes (Pennington & Hastie, 1986).
 (3) Story Classification, in which the story constructed in step 1 is matched to the verdicts represented in step 2.
 The central element here is the goodness of fit between the story and the various verdicts.
 The verdict with the best fit to the story is hypothesized to be the one chosen by the juror The relationship between the Story Model and E C H O is clear: E C H O provides a computational account of the acceptability of the stories constructed and the story classification processes, and, to the extent that juror's decisions are in accord with E C H O predictions, supports the psychological plausibility of E C H O .
 To demonstrate this more conclusively, I constructed E C H O simulation models based on the causal stories of two of Pennington and Hastie's (1993) subjects.
 These E C H O models do indeed reach the verdicts that the subjects reached, and have other interesting properties.
 Simulation M o d e l s T h e Jurors The jurors simulated are Jurors 109 and 128, taken from Pennington and Hastie (1993).
 The jurors were presented with videotaped testimony, and then presented with four alternatives: firstdegree murder, seconddegree murder, manslaughter, and not guilty.
 The fictional case involves Frank Johnson killing Alan Caldwell.
 Since Johnson admitted that he killed Caldwell, there is no doubt about the identity or basic actions of the defendant.
 However, the exact verdict is not wellconstrained by the testimony.
 For example, it is not clear if Caldwell attacked Johnson with a razor immediately before Johnson stabbed Caldwell.
 Beliefs about events such as that can play a key role in juror decisions.
 540 Figures 1 and 2 are reproductions of the Pennington and Hastie's (1993) Figures 3 and 4 (pp.
 144, 145), which represent the stories generated by Juror 109 and 128, respectively.
 In these figures, [e]vents and episodes are represented by solid circles and the diameters of the circles indicate the degree of elaboration provided of events by the jurors; broken circles represent the defendant's goals, inferred by the juror The arrows connect events that were explicitly linked by causal relations in the juror's verbal report.
 The letters J and C refer to the defendant Johnson and the victim Caldwell respectively.
 It is important to note that Juror 109 delivered a "not guilty" verdict and Juror 128 delivered a "firstdegree mur der" verdict, after both of them had seen exactly the same evidence presented in exactly the same manner.
 The clear difference between the two jurors was in the stories they generated to explain the events which led to the trial.
 <iea>.
 AlBai.
 C Threaiani J Avord Troubte : Avoid C •.
.
 ,.
.
.
.
.
• L«»v«t Bar SUyHonw • Frwnd Comes to J s House Al Horn* Friend Suggests Going to Bar (OfsDrmfc Go to Bar ; SoveC : BlunC Takes C Leaves J Alone • Fhendand Go Back ^^^J^ou.
.
.
 Q J a n d F n e n d Enla<Bv C end J Go Outs<le Q Show Knile .
 P'olecl Sell ' C Ktis J and Pulls Razof f j JSUlwC Q C Wounded Figure 1.
 Causal even chain given by Juror 109 Simulation Elements The ECHO simulation models constructed for both jurors contained many of the same elements, in particular those related to the verdict categories and the trial testimony.
 The verdict categories of action, mental states, and circumstances (taken from Pennington and Hastie, 1986) yielded 18 propositions and 7 explanations or contradictions.
 Linking the verdict categories and the final verdicts required four explanations and one contradiction.
 /^Friend Comae SUbC Fiiend and J Go Back 10 Ba/ JandC GoOulside C Hits J J Slabs c FnenO Suggests GokiQtDBar loiaDmk Olticef Fight O Police see.
 Figure 2.
 Causal event chain given by Juror 128 The four possible final verdicts generated four propositions.
 Since those verdicts are generally exclusive, five contradictory links were generated between pairs of final verdicts.
 The final verdict delivered by the juror was assumed to be the final verdict proposition with the highest activation at the end of the E C H O run, since E C H O activation level is intended to correspond to belief strength.
 Nineteen propositions were generated by the testimony itself; while there were certainly more than 19 propositions in the testimony, those that seemed the most directly relevant were used.
 There were several pieces of directly contradictory testimony and these were included to see how E C H O would handle the contradictions.
 Since one of the aims of this paper was to remove the supposed "programmer bias," and the stories of the two jurors included few references to the actual evidence, there were two models made for each juror: one including the testimony propositions and one without the testimony, as it is not guaranteed that the links made from the evidence to the story are exactly the ones made by the jurors.
 While this does have some impact on the E C H O network as a whole, the impact on the final decisions was negligible.
 Juror 109's story consisted of 26 propositions and 18 explanations, all of which were again derived from the causal graph (Figure 1).
 Nodes from Figure 1 were represented in E C H O by propositions and links in the graph by E C H O explanations.
 Seven explanations/contradictions connected Juror 109's story to the verdict categories, and 19 more were necessary to connect the story to the testimony.
 The story for Juror 128 consisted of 19 propositions and 541 14 explanations, all of which were derived directly from the graph presented in Figure 2 just as they were derived from Figure 1 for Juror 109.
 Eight explanations/contradictions connected Juror 128's story to the verdict category propositions.
 It should be noted that one of the propositions in Juror 128's story actually was a piece of the testimony, so only 18 additional explanations or contradictions had to be added to link the story to the 19 testimony propositions.
 Summary of Results A general summary of the results of the four simulations can be found in Table 1.
 This table presents the final (asymptotic) activation values for the total network and the four propositions representing the possible final verdicts.
 (Activation values range from Hi to 1 for a given proposition, with +1 indicating complete acceptance and 1 complete rejection.
) There are a several things to note about the simulation results.
 First and foremost, the simulations are in agreement with the verdicts reached by the jurors that were modeled.
 Second, according to E C H O , both of the stories constructed by the jurors are coherent explanations.
 This is important in that the explanations used were those constructed by the jurors themselves and not the E C H O programmer.
 Third, both explanations become even more coherent when related to the testimony.
 This is particularly interesting since the two stories yield opposing verdicts, and the testimony presented is not itself consistent.
 Both stories formed by the jurors integrate this contradictory testimony in a coherent way, even though the stories themselves differ dramatically.
 Another interesting facet of the E C H O models relates to the testimony.
 Since the jurors did not observe any of the events as they happened, they must rely on the testimony and their o w n inferences to guide them.
 In many legal cases, though, testimony is somewhat less than guaranteed to be an accurate description of the events that took place.
 In the case examined by these jurors, the defendant and one of his best friends are also witnesses.
 Are they to be believed? As it turns out, whether or not the wimesses are believed depends on the content of their testimony.
 According to the E C H O simulations, testimony will be believed to the extent that it is coherent with the story that the juror constructs.
 In these simulations, for example, almost all of the defendant's testimony ends up with negative activation valTable 1.
 ECHO simulation results Total coherence Not guilty by selfdafenss Manslaughter SecoTKJdegree murder Firstdegree murder Juror 109 story with only testimony .
37 .
59 .
34 .
40 .
47 .
40 .
10 .
09 .
12 .
03 Juror 128 story only .
49 .
54 .
26 A9 .
56 with testimony .
78 .
54 .
28 .
49 .
57 ues (is not believed) for Juror 128, and all of it ends up with positive activation values for Juror 109.
 This is consistent with many of the E C H O simulations of scientist's beliefs, wherein certain experiments are considered "anomalies" and not believed by the scientists.
 Discussion Despite their different origins, ECHO and the Story Model can work together to provide a compelling account of how people make complex decisions.
 While this account would certainly be more compelling with more jurors, in particular those delivering manslaughter and seconddegree murder verdicts, the results presented here are promising.
 This has implications for further work on both the Story Model and E C H O .
 Implications for the Story Model One of the primary advantages for the Story Model of the E C H O approach is that it is less posthoc than the present Story Model.
 As it stands, the Story Model is more an account than a predictive model (but see Pennington & Hastie, 1992).
 Jurors' stories are noted to be consistent with the verdict categories after the final verdict from each juror is known.
 Because "coherence, completeness, and uniqueness" are not formally defined in the Story Model, multiple interpretations of any given story are possible.
 With E C H O , the coherence is computed for a single verdict, making the prediction clear.
 Second, the Story Model has been applied primarily to the domain of juror decisions.
 While, in principle, the Story Model is part of a more general framework of explanationbased decision making, most of the work on explanationbased decision making has been conducted as work on the Story Model.
 While this is certainly reasonable given the complexity of the task confronting jurors, the success of E C H O in domains outside of juror decision bodes well for the extension of the Story Model to other domains.
 Implications for TECECHO One of TECECHO's more caustic critics is Glymour (1992), with two major points: E C H O lacks psychological plausibility and the complex algorithm used by E C H O is unnecessary.
' This fusion with the Story Model addresses both of these criticisms.
 Glymour (1992, p.
 470) claims that "there is no psychological case at all" for the way E C H O computes coherence.
 While this claim ignores other successful applications of E C H O to psychological data (Ranney & Thagard, 1988; Schank & Ranney , 1991), this criticism is rendered even weaker by the present work.
 Jurors do indeed appear to make decisions that are consistent with the E C H O simulations, giving further support for ECHO'S psychological plausibility.
 The support for E C H O would be stronger if the stories that individual jurors rejected were also included and shown to ' Thagard (1992c) addresses this latter criticism quite effectively, this work merely serves to provide further evidence in favor of ECHO'S algorithm.
 542 have lower coherence than the story each juror decided upon.
 Another point in suppon would be if two jurors with contradictory stories were brought together and the juror with the story having greater total coherence "won" out (Juror 128 in this case).
 In fact, such an enterprise would be quite useful, extending both the Story Model and E C H O to the domain of con:q)lex decisionmaking by groups and not just individuals.
 Glymour's second criticism is addressed by this work as well.
 Glymour's "pocket calculator" algorithm (1992, p.
 474) for E C H O has a critically linear aspect to it which is not found in E C H O .
 While it may indeed agree with E C H O that the jurors' stories are coherent and yield the decisions they do, it is unclear that Glymour's algorithm will yield increases in coherence for both stories given the inconsistent nature of the testimony.
 Again, until Glymour can demonstrate a simpler algorithm that yields the consistency of results that E C H O does, there is no reason to believe that Glymour's aiticism is a valid one.
 What Is an Explanation? One of the criticism that has been leveled at T E C  E C H O by both the previouslymentioned critics (Giere, 1993; Glymour, 1992) is that E C H O begs the question of what an explanation is.
 When "P explains Q" is provided in the context of TEC, what does "explain" actually mean? Are all explanations the same? Thagard (1992a) attempts to address this question with the answer that explanations take a variety of forms.
 Explanation, Thagard maintains, is a complex process that can include suprocesses based on deductive, statistical, schematic, analogical, causal, or linguistic/pragmatic subprocesses.
 There is no single way to construct an explanation, and the "goodness" of an explanation is a function of the explanatory system in which it is embedded.
 This is entirely consistent with the data provided in Pennington and Hastie (1993).
 The inferences which connect one part of their story with the next take a variety of forms, all of which are equally valid for that juror.
 In fact, several of the explanatory links shown in Figures 1 and 2 are broken down by Pennington and Hastie (1993) to more primi tive inferences, each of which could also be analyzed with E C H O (e.
g.
 Pennington & Hastie's (1993) Figures 5 and 6).
 Thus, there is no single answer to what an explanation is across all individuals, but once the (local) explanations have been formed, a given system of explanations seems to match the predictions made by TECECHO.
 While this may be something of a difficulty for E C H O as a normative model, it provides healthy support for E C H O as a predic tive one, Conclusions Understanding how people make complex decisions is a critical question for both psychology and philosophy, and an approach which integrates detailed analyses of the complex explanations formed and the coherence of those explanations could potentially shed a great deal of light on the problem.
 There is still plenty of work to be done here, of course, particularly in the area of understanding exactly how people construct these causal stories, but the integrated Story Model/ECHO approach offers much promise in answering the question of how people make decisions in complex situations.
 Acknowledgments I would Hke to thank Paul Thagard for providing me with the Macintosh implementation of E C H O , Dave Rettinger for providing me with reprints of most of the Story Model work, and Nancy Nersessian for getting m e started on this project.
 I would also like to gratefully acknowledge the financial support of the National Science foundation through its Graduate Fellowship program.
 References Churchland, P M .
 (1989).
 A neurocomputationalperspective: The nature of mind and the structure of science.
 Cambridge, M A : M I T Press.
 Giere, R.
 N.
 (1993).
 Explaining conceptual revolutions.
 Unpublished manuscript, presented at the Eastern Division meeting of the American Philosophical Association, Dec.
 2830, 1993.
 Glymour, C.
 (1992).
 Invasion of the mind snatchers.
 In R.
 N.
 Giere (Ed.
) Cognitive models of science (pp.
 465474).
 Minneapolis, M N : University of Minnesota Press.
 Kuhn, T, (1962).
 Structure of scientific revolutions.
 Chicago: University of Chicago Press.
 Nowak, G.
, & Thagard, P.
 (1992).
 Copernicus, Plolemy, and explanatory coherence.
 In R.
 N.
 Giere (Ed.
) Cognitive models of science (pp.
 274309).
 Minneapolis, M N : University of Minnesota Press.
 Pennington, N.
, & Hastie, R.
 (1986).
 Evidence evaluation in complex decision making.
 Journal of Personality and Social Psychology.
 51, 242258.
 Pennington, N.
, & Hastie, R.
 (1992).
 Explaining the evi dence: Tests of the story model for juror decision making.
 Journal of Personality and Social Psychology, 62, 189206.
 Pennington, N.
, & Hastie, R.
 (1993).
 Reasoning in explanationbased decision making.
 Cognition, 49, 123163.
 Ranney, M.
, & Thagard, P.
 (1988).
 Explanatory coherence and belief revision in naive physics.
 In Proceedings of the Tenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Erlbaum.
 Schank, P, & Ranney, M .
 (1991).
 Modeling an experimental study of explanatory coherence.
 In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Eribaum.
 Thagard, P.
 (1989).
 Explanatory coherence.
 Behavioral and Brain Sciences, 12, 435502.
 Thagard, P.
 (1992a).
 Conceptual revolutions.
 Princeton, NJ: Princeton University Press.
 Thagard, P.
 (1992b).
 Adversarial problem solving: Modeling an opponent using explanatory coherence.
 Cognitive Science.
 16, 123149.
 Thagard, P.
 (1992c).
 Computing coherence.
 In R.
 N.
 Giere (Ed.
) Cognitive models of science (pp.
 485488).
 Minneapolis, M N : University of Minnesota Press.
 543 Representing Dialectical A r g u m e n t s Clark A.
 Chinn Center for the Study of Reading 51 Gerty Drive Champaign.
 IL 61820 c a c g 6 9 0 7 @ u x a .
 c s o .
 u i u c .
 e d u Abstract The purpose of this paper is to present and contrast two approaches to representing the structure of complex, dialectical arguments.
 Previous research has focused mainly on representing single arguments presented by a single arguer; this analysis examines the naturalistic give and take of dialectical argumentation among fourth graders.
 One approach to representing dialectical arguments is the argument network approach, which views the arguments as webs of interlocking premises and conclusions.
 The second approach is the causal network approach, which treats many of the ideas presented in the discussions as events linked in causal, narrative sequences.
 The two approaches capture different but complementary aspects of the structure of the arguments.
 In a formal debate or in a spirited disagreement among friends, how can the structure of the interwoven arguments and counterarguments be represented? The study of argument structure has an ancient history among philosophers and rhetoricians, but these scholars have usually focused upon arguments made by a single arguer.
 This paper, by contrast, investigates the structure of complex dialectical arguments, in which two or more participants present arguments for different positions and responsively attempt to counter each others' arguments.
 The purjKjse of this paper is to present and contrast two approaches to mapping the structure of complex, dialectical arguments.
 O n e approach is the argument network approach; the other is the causal network approach.
 The two approaches provide complementary views of dialectical arguments.
 Each is potentially a useful tool for evaluating the quality of argumentation and for tracing the development of dialectical argumentation among students.
 Data and analyses The argument network and causal network approaches to representing dialectical discussions were developed through analyses of 20 discussions held in four fourthgrade classrooms.
 In each discussion, the children informally debated an issue raised by a story they had just read.
 For instance, in one of the stories, "Stone Fox," set in frontier Wyoming, a boy named Willie and his grandfather are about to lose their farm because the grandfather has been too sick to work and so has fallen behind on mortgage payments.
 In a desperate attempt to save the farm, Willie enters a local dogsled race.
 His most formidable competitor is Stone Fox, a Native American who regularly wins on the dogsled race circuit and uses the money to buy back tribal lands taken by white settlers.
 Despite having just one dog, WilUe is about to win the race when his dog dies.
 Stone Fox is close behind and soon catches up.
 The other racers are far behind.
 At this point, the students stop reading and discuss the question, "Should Stone Fox let WilUe win the race?" The 20 discussions took place in 10 reading groups in four classrooms.
 The groups ranged in size from 5 to 10 students, and the discussions ranged in length from 17 to 28 minutes.
 Five different stories were used; most discussions centered around ethical issues raised by these stories.
 Each discussion was led by the students' usual classroom teacher.
 To illustrate the two ai^roacbes to representing dialectical arguments, I will present detailed analyses of the following transcript, which is taken from the very beginning of one group's discussion after reading the stwy "Stone Fox.
" 1 Carl I think Stone Fox should go ahead and win because, well 1 mean, Wilhe's dog is dead.
 And I mean, well, he can't bring the dog back to Ufe and have the dog go ahead.
 2 Maria Carl, Carl, justthis story made m e think of m y dog and we had to get rid of m y dog.
 .
.
.
 Wouldn't you, pretend you are little Willie, and you are almost ready to win a race and save your grandfather's land and you are 10 feet away, just 10 feet away, and then your dog dies.
 Wouldn't you be very upset? I would, I mean, I would have just sat there.
 I wouldn't have done anything.
 I think they should just make it a tie and they can split it and Willie's grandfather can try and pay the rest of it since he got better all of a sudden.
 3 Carl But, Maria, what if you were Stone Fox and the opponent that you knew you had to beat, their dog died and you knew they died, it's not like you can bring them back to life and let them win.
 4 Maria Yeah, but still, if I were Stone Fox, I would feel sorry for a kid who had a dog practically killed, I mean, I mean the kid practically won and he only had one dog.
 5 Alan Yeah, but he could j ust win the race and maybe give one of his dogs uh to uh Willie.
 And uh if uh you were Willie and you just had a dog die, what would you rather have, the dog or the money? 544 mailto:cacg6907@uxa.
cso.
uiuc.
edu6 Maria I wouldbut Carl, you see if Stone Fox could win and he could get urn butjust think if your dog died and the tax collector was right there and if he saw how close you were for paying off your taxes, 1 think the Lix collector would give you a little bit more time to c:irn the money.
 And he could split it with (Willie).
 7 Carl But Stone Fox also had land.
 He also needed the money for his land, too// 8 several Yeah 9 Carl And it said in the story, that u m somewhere in here, that when they were going past the .
.
.
 when they were going past the .
 .
 .
 u m .
 .
 .
 their grandfather's place, the farm u m .
 .
 .
 it said that the grandfather was fine.
 He was// 10 Maria It did not say he was fine, it said he was better.
 11 Carl Yeah.
 12 Maria No, it doesn't mean like he's perfectly fine.
 That morning he was very sick, that last night, he had to get his medicine.
 I mean, if you had the chicken pox, you could get better and everything, but you couldn't get better overnight 13 Carl He was sick for a long time.
 14 Maria Yeah, he was also, they said that the night before the race that Willie had to go out and get his grandfather's medicine, he ran out of medicine.
 15 Carl Yeah, he ran out of medicine.
 16 Maria Yeah, but, doesn't that hint that he is not that well yet? 17 Carl Even though I'm not sick any more, I still take medicine.
 18 Maria Yeah, that's so to prevent// Argument Networks In recent decades, researchers in a variety of fields have used simple schemas or frames to represent the structure of single arguments.
 These researchers often stress that arguments are not deductively valid but are instead plausible yet defeasible.
 The most widely used approach to representing plausible arguments is typified by the argument frame advanced by Toulmin (1958), illustrated in Figure 1.
 Touhnin's argument frame has six elements.
 The claim (C) is the conclusion of the argument.
 The claim is supported by a premise, called a datum (D).
 The datum is linked to the claim by the warrant (W), which essentially allows one to infer the claim from the datum by m o d u s ponens.
 The warrant is usually left unstated in real arguments (see Toulmin, 1958; van Eemeren & Grootendorst, 1992), but even when it is left unstated, it is frequently supported by an explicitly stated backing (B).
 The argument may be qualified by an adverb such as presumably or probably (Q).
 Conditions under which the argument do not apply are indicated by a rebuttal (R).
 Argument frames similar to Touhnin's have been adc^ted by scholars in numerous fields, including rhetoric (e.
g.
, Fisher, 1988), philosophy (e.
g.
.
 Scriven, 1976), artificial intelligence (e.
g.
, CavalliSforza, Lesgold, & Weiner, 1992; Cohen, 1985), law (Wigmore, 1937), linguistics (e.
g.
, van Eemeren & Grootendorst, 1992), education (e.
g.
, Russell, 1988), and psychology (e.
g.
, Voss et al.
, 1986).
 Most of these researchers have focused on relatively simple arguments made by single individuals.
 By contrast, there is little work on how to represent the ideas presented in the give and take of complex, dialectical arguments (although see CavalUSforza et al.
, 1992; Wigmore, 1937).
 The argument network ̂ proach to representing dialectical arguments is based on Toulmin's argument frame.
 The argument frame is modified in several ways to represent dialectical arguments rather than simple arguments presented by a single arguer.
 Argument frames must be allowed to hnk with each other, so that there is a gradually expanding web of interlocking arguments.
 In order for the argument frames to be interlinked, the basic argument frame is simplified.
 First, backings are not treated as a separate element within each argument frame.
 Instead, a backing is simply a datum whose claim is the warrant from a different argument frame; backings and warrants therefore have the same relationship as any other datum and claim.
 Second, rebuttals are treated not as separate argument elements but as data that contradict claims, warrants, or other data.
 Third, data are sometimes conjunctive, so that several propositions taken together can serve as the datum supporting a claim.
 These modifications permit one to combine argument frames in a straightforward manner to produce webs of interlinked arguments and counterarguments.
 Figure 2 presents an argument network for the beginning of the Stone Fox discussion.
 (Each statement is numbered with its turn number.
) Three ultimate claims are argued for.
 Carl argues that Stone Fox should go ahead and win the race, and he supports Willie took a short cut.
  • Q So, presumably.
 Since W A person who takes shortcuts is disqualified from winning.
 On account of B The following rules of the race .
.
.
.
 C Willie should not win the race.
 Unless R The rules were not nnade clear to the participants.
 Figure 1.
 Example of Touhnin's argument frame.
 545 Maria would if she were Stone Fox.
 (4) Willie's dog died.
 (4) & Willie practically won.
 (4) & Willie had only one dog.
 (4) Stone Fox needed the money for his land.
 (7) Willie's dog is dead.
 (1) & Stone Fox can't bring the dog back to life and have the dog go ahead.
 (1, 3) | Story says that when they were going past grandfather's place, the grandfather was fine.
 (9) \ Maria would have just sat there.
 (2) Stone Fox would feel sorry for Willie.
 (4) You or Maria would be upset.
 (2) Maria was sad when they had to get rid of her dog.
 (2) ; x Stone Fox should just go ahead and win the race.
 (1) 7 Grandfather is fine.
 (9) X Stone Fox and Willie should tie and split the money.
 (2) Stone Fox could win the race and give one of his dogs to Willie.
 (5) Willie was ^ upset.
 (2) Tax collector would give them more time to earn the money.
 Willie's grandfather can try and pay the rest of it.
 (2) * ^ Willie was about to win a race and save his grandfather's land.
 (2) & Just 10 feet from the finish, his dog dies.
 (2) Tax collector sees how close you are to paying taxes.
 (6) He's better, not fine.
 (10) Ahhough Alan is not sick, he still takes medicine.
 (17) I That morning he was very sick.
 (12) ^ & (Last night I he was very sick.
) (12) If you had chicken pox, you couldn't get better overnight.
 (12) rest of It.
 (2) w \ X & Willie's dog died.
 (6) Willie would rather have a dog than rrwney.
 (5) Willie's grandfather got better all of a sudden.
 (2) You would.
 (5) That's to prevent//(18) They said the night before the race that Willie had to go out and get his grandfather's medicine.
 (14) He was sick for a long time.
 (13) He had to get his nnedicine.
 ^'^^fa (14) ^=*^ He ran out of medicine.
 (14,15) eo • ^ Supporting evidence link between datum and claim with implicit warrant Supporting evidence link between datum and claim with explicit warrant Rebutting link between a datum and the denial of a claim Figure 2.
 A n argument network representation of a segment of a dialectical argument.
 his claim with three separate lines of argument in Turns 1, 3, 7, and 9.
 Maria argues in Turns 2, 4, and 6 that Stone Fox should tie with Willie and split the money with him.
 Alan claims in turn 5 that Stone Fox should give WilUe one of his dogs.
 In Turns 9 through 18, Maria and Carl construct an argument around the claim that Willie's grandfather is now better, with Carl arguing that grandfather is better and Maria that he is still sick.
 Even though the argument network in Figure 2 represents only a small portion of one discussion, it illustrates several features that are typical of all the discussions in the corpus.
 First, the students broach many lines of argument, yet most of these lines of argument are not taken up by other students and so are left undeveloped.
 For instance, in Turn 7 Carl points out that one reason why Stone Fox should win is that Stone Fox needs money for his land, but other students do not pick up on this point, so the idea goes unelaborated 546 and unchallenged.
 Only a small proportion of arguments are extensively elaborated.
 Second, most lines of argument are constructed by a single individual; this is especially true of the lessdeveloped arguments.
 A smaller pcrccniagc of arguments are developed by multiple participants, aiuJ ihcsc arguments are usually the most highly developed ones.
 Third, students explicitly state very few warrants ( 3 % of all warrants in the fully analyzed discussions), but there is a much larger proportion of implicit warrants that are supported or rebutted with additional, explicitly stated data.
 For instance, in Figure 2 there is just one explicit warrant, but there are four implicit warrants that are explicitly backed or rebutted.
 Thus, the argument network representation provides a powerful tool for analyzing the development of dialectical argumentation in children.
 The representation makes it easy to count such features as the number of lines of argument and the relative degree of development of different lines of argument Causal Networks An alternative approach to mapping dialectical arguments is the causal network.
 The causal network approach is inspired by work by Trabasso, van den Broek, and their colleagues (e.
g.
, Trabasso & van den Brock, 1985) on the causal structure of stories.
 The causal network approach is also related to work by Pennington and Hastie (e.
g.
, 1992), w h o have demonstrated that people who observe a criminal trial organize what they learn in the trial as narratives.
 Figure 3 presents a causal network for the dialectical argumentation in Turns 1 through 4 of the transcript.
 (Each node is numbered with turn numbers.
 Rectangles indicate events that actually occurred in the story.
 Ovals mark hypothetical events that could happen to story characters in the future.
 Trapezoids mark ideas derived frcxn background knowledge.
) Causal network representations of dialectical arguments appear necessary because argument networks fail to capture two key characteristics of the argumentation.
 First, argument networks fail to capture causal and temporal connections.
 For instance, Maria's first contribution to the discussion in Turn 2 includes the following propositions: (a) Willie was about to win the race, (b) Willie's dog died, (c) Stone Fox would feel sorry for Willie, and (d) Stone Fox could tie and split the money with Willie.
 In the argument network representation, these four propositions are separate claims and data in separate arguments.
 They possess no temporal relationships, because the argument frames allow only the relationship of premise and conclusion.
 But in fact, the four assertions make up a temporal sequence of events, with each event enabling or causing the subsequent event.
 Maria's argument, therefore, is not just a set of premises and conclusions but a series of events that are connected causally and temporally.
 The ordering of these propositions in the argument network in Figure 2 does not reflect this temporal order or causal connection.
 It is possible, of course, to augment argument networks with formalisms that encode causal and temporal relations.
 This has not, however, been done by most of the scholars who have used argument frames.
 More important, the core organizing principle of argument networks is the premiseconclusion relationship rather than the causal or temporal relationship.
 In the argument network, the most closely related ideas are seen to be ideas that fall into premiseconclusion patterns rather than ideas that are temporally or causally related.
 In the causal network, precedence is given to the causal and temporal relationships.
 The second shortcoming of argument networks is that they sometimes dissociate ideas that appear to be closely connected.
 To illustrate, in the argument network in Figure 2, Carl's first argument (Stone Fox should win because Willie's dog is dead and can't be brought back to life) is not linked to Maria's argument that Stone Fox would feel sorry for Willie, so Stone Fox should let Willie tie); instead.
 Figure 2 implies that Carl makes one argument, and Maria makes a separate argument for a contrary position.
 However, Carl and Maria's arguments actually seem to be more closely connected: Both are concerned with the ramifications of the death of Willie's dog.
 Carl insists that the dog's death means that Willie can't win, so Stone Fox might as well go ahead and win.
 Maria, by contrast, focuses on a different set of consequences of the dog's death.
 Willie's misfortunes would lead Stone Fox to feel sorry for him, so Stone Fox might decide to tie with Willie.
 The argument network representation fails to highlight this focus on alternative consequences of the dog's death.
 In causal network representations of dialectical argumentation, events are placed in causal, temporal sequences.
 The events form causal sequences in which one event may strongly cause or weakly enable the next event in the sequence (Trabasso & van den Broek, 1985).
 In causal network representations of dialectical arguments, envisionments (de Kleer & Brown, 1984) play a key role.
 Envisionments are mutually exclusive alternative causal paths.
 De Kleer and Brown applied the idea to the domain of physical causality, but envisionments can also be applied to ethical argumentation.
 The dialectical arguments in our corpus often consist of students proposing different hypothetical envisionments that could follow from particular events.
 For instance, Stone Fox could decide to let Willie tie him, which would have one set of likely consequences, or he could go ahead and win, which would have a mutually exclusive set of likely consequences.
 Students' arguments often center around just what these likely consequences are.
 Figure 3 is a causal network of the first four turns.
 Carl begins in Turn 1 by laying out two envisionments that could ensue from the dog's death: Stone Fox could go ahead and win the race, or the dog could come back to life and go ahead.
 Because the latter envisionment is physically impossible, Stone Fox is left with no alternative but to go ahead and win the race.
 The nodes labeled 2a in Figure 3 make up the first part of Maria's response to Carl in Turn 2.
 The causal network representation, unlike the argument network representation, shows that Maria is building upon the ideas that Carl has introduced.
 She begins by adding three events that precede the state of Willie's dog being dead These antecedents are that Willie is 10 feet from the finish line, Willie is about to win, and then the dog dies.
 Then Maria adds further consequences to what would have happened if Willie had won: 547 Maria would feel sorry for Willie.
 Maria would have just sat there.
 Willie was almosi ready to win the race.
 Willie had only one dog \ Willie was just 10 feet away.
 You or Maria would be upset z I Stone Fox feels sorry for Willie Willie s dog died.
 Maria was sad when they had to get rid of her dog.
 Stone Fox and Willie tie.
 Willie is upset.
 Willie's dog is dead.
 / V You cant bring the dog back to life Stone Fox an Willie split the nrioney Stone Fox brings the dog back to life.
 Grandfather pay for the rest of the land.
 WIlie can't win.
 The dog goes ahead Stone Fox wins.
 Willie wins the race.
 Willie's land is saved.
 Grandfather got better all of a sudden.
 " ^ Causal or enabling connection •^ Innpossible causal connection A Relation of evidence for a link or node Indicates that an event or state is desirable (+) or undesirable () Figure 3.
 A causal network representation of a segment of a dialectical argument Willie would have w o n the race and saved his grandfather's land.
 Maria has thus built upon the beginning and end of one of Carl's causal chains.
 Maria also notes a new consequence that follows from the dog's death: The dog's death upsets Willie.
 Maria's clearly implies that this state is highly undesirable, which is symbolized in the network by a triangle with a minus sign inside it.
 In the last half of Turn 2 (the nodes labeled 2b in Figure 3), Maria constructs a new envisionment that achieves the desirable state of WilUe's land being saved.
 Maria presses that Stone Fox and Willie tie and split the money.
 Then, since Willie's grandfather is getting better, he will be able to pay for the rest of the land and save the farm.
 Each of Maria's envisionments culminates in one or more state or event that is taken to be desirable or undesirable.
 This is typical of the children's ethical argumentation in our 548 corpus of discussions.
 The majority of the argumentation consists of students proposing alternative envisionments tliat end in desirable or undesirable states or events.
 In response to Maria, Carl reaffirms in Turn 3 iJiat Willie cannot win the race (and therefore, presumably, that Willie cannot tie, either).
 He attempts to recast Maria's envisionment as an impossible envisionment, one that cannot happen.
 Maria's response is a clever maneuver to strengthen her causal sequence by linking two causal sequences that are as yet unconnected; she links the sequence in 2a with the sequence in 2b.
 She asserts that Willie's misfortune would lead Stone Fox to feel sorry for Willie, which would in turn make him decide to let Willie tie him.
 Thus, Maria creates a series of links between a node that Carl agrees to be valid, the dog's dying, and Stone Fox's possible decision to let Willie tie him.
 Figure 3 suggests that the argument between Maria and Carl in Turns 1 through 4 consists of constructing envisionments that terminate in states or events that the discussants take to be desirable or undesirable.
 This is the predominant pattern in all of the discussions that have been examined.
 For instance, students who want Willie to win construct envisionments in which Willie's victory has positive consequences (Willie can save the farm and he and his grandfather can continue to live there) and envisionments in which Stone Fox's victory has negative consequences (Willie and his grandfather have nowhere to go).
 By contrast, students who favor Stone Fox's victory construct envisionments in which Stone Fox's victory has positive consequences and Willie's victory has negative consequences.
 Causal networks alone cannot account for all aspects of the argumentation.
 Figure 3, for instance, shows that some of the causal links are supported by evidence.
 Maria supports the idea that the dog's death would upset Willie by appealing to her peers' empathetic emotional reactions.
 She supports the idea that she herself would be upset with additional evidence that she was sad when her family had to get rid of their dog.
 This evidentiary support takes the form of Toulminlike argument frames embedded within the causal network.
 Like argument networks, causal networks provide a powerful tool for investigating the character of dialectical discussions in classrooms.
 In the two discussions that have been exhaustively analyzed, a large majority of all statements fall into envisionments.
 However, although fourth graders frequently imply or state that the terminal events in these envisionments are desirable or undesirable, they seldom justify these value judgments; less than 5% of value judgments are defended or justified.
 Similarly, the students almost never weigh the relative desirability of different events or states (e.
g.
, which is more highly desirable: recovering tribal lands or saving Willie's farm?).
 Very few causal connections (less than 5%) are supported or challenged with evidence, even though it appears that many of the proposed causal connections could reasonably be called into question.
 Such indicators are very useful for evaluating the progress of students as they learn to argue during discussions.
 It would also be interesting to compare discussions of adults with discussions by children on these dimensions, as well as to examine how different types of argumentation (ethical, scientific, etc.
) differ.
 A weakness of causal networics is that they fail to capture the sense in which students selfconsciously advance reasons and evidence.
 During the discussions, students use such terms as reasons, evidence, positions, and challenges to refer to their own discourse.
 They sometimes summarize the discussion by listing lines of argument that they have considered so far.
 In short, the discussants often seem to conceptualize their discourse as sets of arguments and counterarguments.
 Causal networiu are not organized in this way.
 It appears, then, that the discussions can be viewed as being organized both as patterns of premises and conclusions in argument networks and as rival envisionments in causal networks.
 A complete understanding of the discussions appears to require representations that capture both patterns.
 Acknowledgments This research was supported in part by Department of Education grant Rl 17E20218 to Richard Anderson.
 I thank Richard Anderson, Martha Waggoner, William Brewer, and two anonymous reviewers for their helpful cranments.
 References CavalliSforza.
 V.
, Lesgold, A.
 M.
, & Weiner, A.
 W.
 (1992).
 Strategies for contributing to collaborative arguments.
 In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society (pp.
 755760).
 HUlsdale, NJ: Erlbaum.
 Cohen, P.
 R.
 (1985).
 Heuristic reasoning about uncertainty: An artificial intelligence approach.
 Boston: Piunan Advanced Publishing Program.
 de Kleer, J.
, & Brown, J.
 S.
 (1985).
 A qualitative physics based on confluences.
 Artificial Intelligence, 24, 783.
 Eemeren, F.
 H.
 van, & Grootendorst, R.
 (1992).
 Argumentation, communication, and fallacies: A pragmadialectical perspective.
 Hillsdale, NJ: Exlbaum.
 Fisher, A.
 (1988).
 The logic of real arguments.
 Cambridge: Cambridge University Press.
 Pennington, N.
, & Hastie, R.
 (1992).
 Explaining the evidence: Tests of the story model for juror decision making.
 Journal of Personality and Social Psychology, 62, 189206.
 Russell, T.
 L.
 (1988).
 Questions and arguments.
 In J.
 T.
 Dillon (Ed.
), Questioning and discussion: A multidisciplinary study (pp.
 240258).
 Norwood, NJ: Ablex.
 Scriven, M.
 (1976).
 Reasoning.
 New York: McGrawHiU.
 Toulmin, S.
 E.
 (1958).
 The uses of argument.
 Cambridge: Cambridge University Press.
 Trabasso, T.
, & van den Broek, P.
 (1985).
 Causal thinking and the representation of narrative events.
 Journal of Memory and Language, 24, 612630.
 Voss.
 J.
 F.
, Blais, J.
, Means, M.
 L.
, Greene, T.
 R.
, & Ahwesh, E.
 (1986).
 Informal reasoning and subject matter knowledge in the solving of economics problems by naive and novice individuals.
 Cognition and Instruction, 3, 269302.
 Wigmore, J.
 H.
 (1937).
 The science of judicial proof Boston: Little, Brown.
 549 A Scowl is W o r t h a Thousand W o r d s : Positive and Negative Facial Expressions Automatically Prime Affectively Congruent Information in M e m o r y Joseph V.
 Ciarrochi Cognitive Psychology University of Pittsburgh Pittsburgh, P A 15260 J o s e p h c S v m s .
 c i s .
 p i t t .
 e d u Abstract Does affective context automatically activate congruent information in memory (e.
g.
 positive context/ positive information) and/or inhibit incongruent information (e.
g.
 negative context/positive information)? Context was elicited by presenting either a positive, negative, or neutral facial expression briefly on a computer screen.
 Immediately after setting the context, subjects saw a positive, negative or neutral word and had to pronounce it as quickly as possible.
 The experiment was designed to eliminate subject strategies.
 The results indicated that subjects pronounce words faster in a congruent context, relative to a neutral baseline.
 There was no evidence of a slowing down in the incongruent context.
 These findings suggest that affect automatically activates congruent information in memory.
 Results are discussed in relation to previous mood findings which suggest that affective priming is not found in semantic tasks.
 The central question in this paper is, does affective context automatically activate congruent information in memory (e.
g.
 positive context/ positive word) and/or inhibit incongruent information (e.
g.
 negative context/positive word)? In this paper "affect" will be used synonymously with "valence" and can be either positive or negative.
 Affect is not equivalent to mood or emotion but is assumed to be a basic dimension or component of these states (Watson & Tellegen, 1985; Davidson, 1992).
 A n automatic process is one that is involuntary, effortless and operates outside of awareness (Shiffrin, 1988; Bargh, 1989; Mathews & MacLeod, 1994; but see Bargh, 1989, for some qualifications regarding this definition).
 Bower's (1982, 1991) associative network model suggests that affective context will automatically activate all affectively congruent information in memory.
 More specifically, activation of an emotional memory leads to the activation of a valence node associated with the memory.
 Activation of the valence node then leads to activation of all other memories associated with that valence.
 Memories, once activated, are more quickly and easily retrieved.
 Bower's model (1982) also suggests that opposite affective states (e.
g.
 fear and joy) may inhibit each other.
 Though only weakly implied by the model, it is possible that if a valence node is inhibited, then a memory associated with that node may take longer to be activated.
 This is because when the memory is activated, it will receive less feedback activation then normal from the inhibited affect node.
 Consistent with Bower's (1991) position, a number of studies have provided evidence suggesting that the efficiency of recall is biased by the congruence between an existing mood and the affective tone of the material involved, a phenomenon termed mood congruent recall (Blaney, 1986; Bower, 1981; Clark & Teasdale, 1985; Laird, Wagener, Halal, & Szegda, 1982).
 There is evidence that mood congruent recall may be the result of either an increase in the ease of retrieving congruent memories ("facilitation," Clark & Waddell, 1983) and/or a decrease in the ease of recalling incongruent memories ("inhibition," Natale & Hantas, 1982).
 There are, however, ways of explaining mood congruency aside from Bower's associative network model (Blaney, 1986).
 One alternative explanation is that mood congruency is the result of strategic processes associated with the mood (Blaney, 1986; Mathews & MacLeod, 1994; Perrig & Perrig, 1988; Wyer & Frey, 1983).
 For example, subjects may engage in a motivated search for data in order to provide an attribution for their mood (Schwarz, Bless, & Bohner, 1991).
 This search leads subjects to selectively recall information that is congruent with the tobeexplained mood.
 Using a lexical decision paradigm that is quite different from the mood induction paradigm discussed above, Hill and KempWheeler (1989) and KempWheeler & Hill (1992) found some evidence that appeared to support Bower's model.
 They asked subjects to determine as quickly as possible whether or not a letter string was a word and found that subjects evaluated an emotionally aversive target faster when it was preceded by an emotionally aversive prime than when it was preceded by a neutral prime (e.
g.
 "snake—wars" trials were faster than "pilotrats" trials).
 This finding is consistent with the possibility that the affect elicited by the prime activated all congruent words in memory.
 There are problems with the KempWheeler and Hill studies, however, that make it difficult to use them as evidence in support of Bower's (1991) model.
 First, there is some question as to whether the neutral prime trials used in those studies allow one to establish a "true" baseline from which to derive facilitation (facilitation is the decrease in reaction time in the congruent context).
 Facilitation in both studies was derived by comparing the 550 negative primenegative target condition to the neutral primenegative target condition.
 For example, "snakewars" trials were compared to "papernightmare" trials.
 Researchers have argued that primes used in different conditions should be identical to each other in terms of their physical appearance, ease of encoding, memory demands, and potential to alert subjects (Groot, Thomassen, & Hudson, 1982; Jonides & Mack, 1984).
 In the KempWheeler and Hill studies, the neutral primes and valenced primes probably differed not only in terms of valence, but also in terms of alerting or arousal characteristics.
 If it is assumed that aversive primes may induce some arousal, and there is evidence for this (KempWheeler & Hill, 1987),then it may be that anything that follows an aversive prime will be responded to more quickly.
 So the facilitation findings in these studies may be attributable, at least in part, to arousal.
 The second problem with the KempWheeler and Hill studies is intrinsic to the type of task used.
 The researchers used a lexical decision task that presented the stimuli in primetarget pairs (e.
g.
 in one trial, a subject may be asked to read the prime and then make a lexical decision to a target 200 m s later).
 W h e n prime and target are presented in pairs, subjects tend to notice relationships between these pairs, which allows them to use various strategies to speed up their lexical decision time (McNamara & Altarriba, 1988; Neely, 1977, 1991; Shelton & Martin, 1992).
 One such strategy is called semantic matching (Neely, 1991).
 After lexical access for the target has occurred, but before subjects have time to make their word/nonword decision, they may use information indicating whether the target semantically matches (is related to or semantically similar to) the word prime that preceded it.
 If there is a semantic match between prime and target, subjects are able to quickly respond that the target is a word since there is never a semantic match when the target is a nonword.
 The review of the literature thus far suggests that two basic issues must be addressed when testing for automatic affective facilitation and inhibition.
 1) H o w do you know the results are due to automatic rather than control processes? 2) H o w do you establish a "true" neutral baseline from which to derive inhibition and facilitation scores? Ciarrochi (1995) attempted to address both of these issues in the context of a lexical decision task.
 To deal with the issue of strategies, he used the single presentation lexical decision task, which has been specifically designed to eliminate strategies (McNamara & Altarriba, 1988; Shelton & Martin, 1992).
 In this task, stimuli are presented singly with no obvious pairings between stimuli.
 A lexical decision is made to each word, whether it is a prime, target, or filler.
 A subject might see the following list of stimuli flash up on a computer screen, one at a time: paper, smorf, laughter, valentine, book, telephone, glom, sickness.
 accident (critical primetarget pairs are underiined).
 In this task, subjects do not notice relationships between prime and targets (because the pairings are not obvious) and thus are not able to use strategies based on this knowledge to speed up there decision times (McNamara & Altarriba, 1988; Shelton & Martin, 1992).
 With respect to the problem of establishing a neutral baseline and controlling for the arousal effects of primes, each prime and target acted as its o w n control and each prime type and each target type was crossed with one another (Ciarrochi, 1995).
 For example, the target "vacation" occurred at different times after the primes, "birthday", "cruelty", "seat" and "torsin," and the prime "birthday" occurred before the targets "vacation", "panic", "opinion" and "predent".
 This design allowed Ciarrochi (1995) to establish a estimate of facilitation and inhibition, while controlling for any unintended differences between words.
 For example, because the same positive prime occurred before both a positive and neutral target, any differences in processing between those targets could not be attributable to any constant effect (e.
g.
 arousal) of the prime.
 Ciarrochi (1995) found that lexical decisions were faster in the congruent context while there was no slowing in the incongruent context.
 These results were interpreted as supportive of Bower's (1991) model.
 There was, however, a potential confound in the study.
 Unintended associations between the prime—target pairs may have influenced the results, despite Ciarrochi's (1995) attempts to eliminate such a possibility.
 For example, positive words like "birthday" and "valentine" might be linked by some semantic relationship that is independent of valence.
 Such a link might explain the priming effects.
 Experiment The present experiment attempted to replicate Ciarrochi (1995) while reducing the possibility that any observed priming effect was due to unintended relationships between primes and targets.
 To accomplish this, novel facial expressions were used as primes.
 In an attempt to increase generalizability, the naming task was used instead of the lexical decision task.
 Subjects were required to pronounce positive, negative or neutral words as quickly as possible after having been briefly exposed (51 ms) to a picture of a face expressing a positive, negative, or neutral emofion.
 Murphy and Zajonc (1993) have shown that briefly presented pictures of positive and negative facial expressions can be used to elicit affect automatically.
 As in the Ciarrochi (1995) study, each prime and each target acted as its own control, which allowed the elimination of any constant effects of the prime type (e.
g.
, arousal).
 Potential error due to intrinsic differences between targets (e.
g.
 target length) was also eliminated.
 Concerning the issue of strategies, the naming paradigm used in the present study has been shown to greatly reduce the possibility that subjects will use strategies (Neely ,1991; Seidenberg, et al, 1984).
 For example, information about whether the prime and target semantically match may help an individual in the lexical decision task (this is the semantic matching strategy discussed above) but does not help an individual retrieve a phoneme.
 As a result, subjects do not appear to use the semantic matching strategy in the naming task (Neely, 1991).
 551 Another aspect of the experiment that makes strategy use unlikely is the short S O A (time from onset of the prime to the onset of the target).
 Neely (1977) has shown that the 85 millisecond S O A used in the present experiment is short enough to eliminate subjects' ability to use certain time consuming strategies.
 The following predictions were made: 1) subjects would be able to retrieve a word's phoneme and pronounce a word more quickly in a congruent context (positive prime/positive target and negative prime/ negative target) than in an incongruent context (positive prime/negative target and negative prime/positive target).
2) The speed to pronounce targets in a congruent context would be faster than a neutral baseline (affective facilitation).
 Facilitation effects are calculated by taking the difference in means between a valenced target in a congruent context and a neutral context minus the difference in means between a neutral target in the same two contexts.
 For example, positive facilitation is equal to [ (positive prime/positive target minus neutral prime/positive target) minus (positive prime/neutral target minus neutral prime/neutral target)].
 3) Targets in an incongruent context would be slower than a neutral baseline (affective inhibition).
 Inhibition was calculated by taking the difference in means between a valenced target in a incongruent context and a neutral context minus the difference in means between a neutral target in the same two contexts.
 4) W o m e n would show stronger effects of affective context then men The fourth prediction requires some explanation.
 Clark and Teasdale (1985) found that women, and not men, showed mood congruent retrieval of verbal materials.
 Clark and Teasdale argued and provided evidence for the possibility that, for women, affect may have been more strongly associated with the verbal materials used in the experiment.
 Ciarrochi (1995) also found that only w o m e n showed affective priming effects in a lexical decision task and that affect was more strongly associated with the verbal materials.
 These findings provided the imputes to test for gender differences in the present experiment.
 Although less critical to the main purpose of the experiment, differences between gender may be important.
 Subjects NinetySix University of Pittsburgh undergraduates participated in the study for class credit.
 All subjects were native English speakers Materials The materials consisted of 3 types of primes (positive, negative, and neutral) and 3 types of targets (positive, negative, neufraJ).
 Each prime and each target acted as its own control.
 The target stimuli consisted of 42 positive, 42 negative and 42 neutral words used in previous studies (e.
g.
 Bellezza, Greenwald, & Banaji, 1986).
 The priming stimuli were 21 colored photos, 7 positive (happy), 7 negative (4 angry, 3 disgusted) and 7 neutral.
 The photos were of 7 individuals, each of w h o m posed for a positive, negative, and neutral photo.
 Practice stimuli consisted of nine additional photos (three positive, negative and neutral expressions) and eighteen words (six positive, negative, and neutral).
 Procedure The stimuli were presented on the computer screen of a 486 IBMcompatible computer with a V G A noninterlaced color monitor and a 16.
72 refresh rate.
 Reaction time (RT) was recorded by computer.
 Subjects were seated in front of a computer and told to rest their chin on a chin rest whenever working through a trial.
 A microphone was attached to the chin rest, about two inches from the subject's mouth.
 Subjects were given instructions and 18 practice trials.
 Subjects started each trial by pressing a space bar.
 W h e n the bar was pressed, they saw a cross hatch and then a face presented for 50 ms.
 The screen then went blank and 34 ms later, a word appeared in the middle of the area where the face had been.
 Subjects pronounced the word as quickly as possible.
 After the word disappeared, subjects were given feedback on how long it took to pronounce the word.
 Below this feedback, either the letters "NQ" or "Q" appeared.
 If "Q" appeared, subjects were asked, "Was that face expressing emotion?" and were instructed to answer either "yes" or "no" "NQ" appeared on two thirds of the trials and stood for "no question.
" This manipulation was designed to ensure that subjects attended to the pictures.
 The main phase of the experiment consisted of 126 primetarget trials.
 The order of the trials was randomized by the computer.
 Results The first set of analyses involved mean correct response latencies and mean error rates, collapsed across items.
 To calculate the error term for the set of planned comparisons, two 3 (prime) x 3 (target) x 2 (gender) x 48 (subjects within gender) A N O V A s were conducted.
 Dependent measures in these analyses were reaction time and error.
 The mean square errors were 750.
71 for the reaction time analysis and 20.
95 for the error analysis (error scores were converted to percentages).
 The overall effect of context was significant, t(752)=3.
888, p <.
0001.
 (All comparisons were planned and one tailed unless otherwise stated.
) Congruent trials were 10.
87 m s faster on average than incongruent trials.
 Figure 1 shows the overall effect split into facilitation and inhibition for men and w o m e n separately and combined.
 W h e n collapsed across gender, the facilitation effect was significant, t(752)=1.
82, p=.
034, whereas the inhibition effect was not significant, t(752)=.
634, p>.
l.
 (The positive prime/positive target condition and negative/negative conditions were combined to determine the facilitation score.
 The positivenegative and negative—positive conditions were combined to determine the inhibidon score.
) The congruent trials were 8.
06 ms faster than baseline (facilitation) while incongruent trials were 2.
8 ms slower than baseline (inhibition).
 The overall effect was qualified by a significant interaction with gender, t(752)=1.
66,p=.
049.
 Affective context had more impact on women's naming time than on 552 Facilitation and inhibition: Reaction T i m e o c 1 « m o c •a 31 10 5 0 5 10 15 20 ^ mPosPos • PosNeg nNegPos • NegNeg Overall Female Male Figure 1: NegPos refers to the negative prime—positive target condition.
 A negative score indicates that the mean R T was faster than baseline; a positive score indicates that the mean R T was slower than baseline.
 The PosPos score was derived as follows;[(Positive primepositive target condition minus neutralpositive) minus (positive—neutral minus neutral—neutral)] men's.
 Women's naming latencies for congruent trials were 15.
51 m s faster than incongruent trials, t(752)=3.
921,p<.
0001.
 Men's naming latencies for congruent trials were 6.
24 m s faster than incongruent trials, t(752)=1.
578,p=.
057.
 For women, the facilitation effect was significant, t(752)=2.
06,e=.
02, but the inhibition effect was not significant, t(752)=.
424, p>.
3 (Figure 1).
 Performance on congruent trials was 12.
86 m s faster than baseline and performance on the incongruent trials was 2.
65 m s slower than baseline.
 For men, neither facilitation nor inhibition was significant (e>.
3) (although the overall effect was significant).
 With respect to the error data, the overall effect of context was significant, t(752)=2.
395, c=.
008.
 Pronunciation of words in a congruent context was 1.
12% more accurate than in an incongruent context.
 W h e n the overall effect was split into facilitation and inhibition , neither facilitation nor inhibition was significant (t<l).
 Subjects were not significantly more accurate in a congruent context than a neutral context and not significantly less accurate in a incongruent context than a neutral context.
 There was a nonsignificant trend for affective context to impact men's error data to a greater extent than women's error data, t(752)=1.
57,p=.
116 (two tailed).
 M e n were 1.
86 % more accurate in congruent than incongruent trials while women were .
38% more accurate.
 Because the overall genderbyerror interaction was not significant, tests were not performed on men and w o m e n separately.
 T w o posthoc comparisons were conducted to determine if there was a difference in the speed/accuracy criteria used by men and women while performing the task.
 There was a nonsignificant trend for men to respond 14.
8 m s faster than women, t(752)=.
82, g=.
41 and a marginally significant trend for men to make .
85 % more errors than women, t(752)=1.
84, p=.
066.
 Discussion The reaction time and error results suggest that affect does automatically influences the accessibility of information in memory.
 Pronunciation of words was faster and more accurate in the congruent context than in the incongruent context.
 W h e n the overall R T effect was split into facilitation and inhibition effects, only facilitation was significant.
 The overall R T effect was qualified by a significant interaction with gender.
 Affective context exerted a stronger influence on w o m e n than on men, although the effect was significant for both genders.
 W h e n the overall effect was split into facilitation and inhibition within gender, facilitation was significant for w o m e n only and inhibition was not significant for either gender.
 Gender differences on this task may have been due to a stronger association between affect and verbal materials (as discussed above).
 Gender differences might also reflect, at least in part, differences in the speed/accuracy criteria used while performing the task.
 There were nonsignificant trends for men to make more errors, pronounce words faster, and to show more impact of affect in their error data than women.
 Future research will be needed to assess these possibilities.
 The conclusion that the priming effect resulted from an automatic process might be challenged on the following grounds.
 Subjects were asked to report whether or not the face prime was expressing emotion.
 This manipulation was designed to ensure that subjects attended to the pictures.
 It might be argued that explicitly drawing the subjects' attention to the emotional content of the faces may have led them to engage in some strategy that involved relating the affect of the face with the affect of the target word.
 This might account for the priming results.
 There are, however, a number arguments against this position: 1) The time from onset of the prime to the onset of the target (SOA) was only 85 milliseconds.
 This short interval has been shown to eliminate subjects ability to use certain strategies (Neely, 1977).
 2) The naming paradigm, used in the present study, has been shown to eliminate certain strategies like semantic matching (see above) (Neely ,1991; Seidenberg, et al.
 1984) 3) Because there was no predictive relationships between primes and targets, subjects could not have used strategies to successfully 553 improve their times.
 Even if they were tempted to try using some strategy, they would have received no reinforcement for using it (i.
e.
 it would never help improve their times).
 The findings in the present study may relate to a discrepancy in the mood congruency literature.
 There has generally been a lack of semantic mood congruence effects analogous to those found in recall tasks.
 Such null results have been observed in paradigms involving wordrecognition thresholds (Gerrig & Bower, 1982), valence decision times (e.
g.
 is this word/sentence positive or negative in valence?.
 Bower & Mayer, 1989; Weaver & Mcneill, 1991), and lexical decision times (Clark, Teasdale, Broadbent, & Martin, 1983).
 Such findings may be interpreted as contradicting Bower's (1981) claim that affect automatically activates all information associated with it in memory.
 If such a claim were true, then a particular mood should activate all concepts and words associated with it, leading to lower wordrecognition thresholds, faster valence judgments, and faster lexical decision times for the activated words.
 The present results provide evidence that affective priming effects can be observed in a semantic memory task.
 H o w are these results to be reconciled with the null effects observed in mood congruency paradigms? It might be that the affect (or valence) elicited by the facial expressions is completely different from the affect that Watson and Tellegen (1985) found to be one of the basic components of a mood.
 Thus, the present results might have no bearing on the mood results.
 A n alternative explanation might start by assuming that the state that is elicited in a mood induction and the brief state that is elicited by the presentation of a facial expression share a common component: valence.
 (This is not to imply that there are not important differences between a mood and a simple affective reaction.
 One such differences is probably level of arousal.
) The null results in mood studies might be explained as follows: Semantic tasks require subjects to respond as quickly and accurately as possible and thus force subjects to engage in very concentrated, shortlived focusing that might disrupt an induced mood (Bower, 1991).
 That is, because the subject is focusing on the task, the mood may not be activated at the u m e of retrieval and thus would have no effect.
 In the present study, a facial expression was presented less then 100 m s before the person was required to retrieve a phoneme.
 This procedure probably ensured that affect was activated when the subject made the phoneme retrieval.
 Perhaps if a procedure is used that ensures a mood is activated when a subject retrieves information in a semantic task, then mood congruency would be observed for such tasks.
 Future research will be needed to assess this possibility.
 References Bargh, J.
 A.
 (1989).
 Condifional automaticity: Varieties of automatic influence in social perception and cognition.
 In J.
 S.
 Uleman & J.
 Bargh (Eds.
), Unintended thought (pp.
 351).
 N e w York: The Guilford Press.
 Bellezza, F.
.
 Greenwald, A.
, & Banaji, M.
 R.
 (1986).
 Words high and low in pleasantness as rated by male and female college students.
 Behavior Research Methods, Instruments, & Computers.
 18(3), 299303.
 Blaney, P.
 (1986).
 Affect and Memory: a review.
 Psychological Bulletin, 99(2), 229246.
 Bower, G.
 H.
 (1981).
 Mood and memory.
 American Psychologist, 36(2), 129148.
 Bower, G.
 H.
, & Cohen, P R.
 (1982).
 Emotional influences in memory and thinking: Data and theory.
 In S.
 Fiske & M.
 Clark (Eds.
), Affect and Cognition (pp.
 291331).
 Hillsdale: Lawrence Erlbaum.
 Bower.
 G.
, & Mayer, J.
 (1989).
 In search of mooddependent retrieval.
 Journal of Social Behavior and Personality, 4(2), 121156.
 Bower, G.
 H.
 (1991).
 Mood congruity of social judgments.
 In J.
 P.
 Forgas (Eds.
), Emotion and Social Judgments (pp.
 3153).
 N e w York: Pergamon Press.
 Ciarrochi, J.
 V.
 (1995).
 Automatic influences of affect on memory retrieval.
 Paper presented at the meeting of the Midwestern Psychological Association, Chicago.
 Clark, D.
, & Teasdale, J.
 (1985).
 Constraints on the Effects of Mood on Memory.
 Journal of Personality and Social Psychology, 4S(6), 15951608.
 Clark, D.
 M.
, Teasdale, J.
 D.
, Broadbent, D.
 E.
, & Martin, M .
 (1983).
 Effect of mood on lexical decisions.
 Bulletin of Psychonomic Society, 21(3), 175178.
 Clark, M.
 S.
, & Waddell, B.
 A.
 (1983).
 Effects of Moods on Thoughts About Helping, Attraction and Information Acquisition.
 Social Psychology Quarterly, 46(1), 3135.
 Davidson, R.
 (1992).
 Prolegomenon to the structure of Emotion: Gleanings from Neuropsychology.
 Cognition and Emotion, 6, 245268.
 Gerrig, R.
, & Bower, G.
 (1982).
 Emotional influences on word recognition.
 Bulletin of the Psychonomic Society, 19(4), 197200.
 Groot, A.
 D.
.
, Thomassen, A.
, & Hudson, P.
 (1982).
 Associative facilitation of word recognition as measured from a neutral prime.
 Memory and Cognition, 10(4), 358370.
 Hill, A.
 B.
, & KempWheeler, S.
 M.
 (1989).
 The influence of context on lexical decision times for emotionally aversive words.
 Current Psychology: Research and Reviews, 8(3), 219227.
 Jonides, J.
, & Mack, R.
 (1984).
 On the cost and benefit of cost and benefit.
 Psychological Bulletin, 96(1), 2944.
 KempWheeler, S.
 M.
, & Hill, A.
 B.
 (1987).
 Anxiety responses to subliminal experience of mild stress.
 British Journal of Psychology, 78, 365374.
 KempWheeler, S.
 M.
, & Hill, A.
 B.
 (1992).
 Semantic and Emotional Priming below Objective Detection threshold.
 Cognition and Emotion, 6(2), 113128.
 Laird, J.
 D.
, Wagener, J.
, Halal.
 M.
, & Szegda, M .
 (1982).
 Remembering what you feel: Effects of emotion on memory.
 Journal of Personality and Social Psychology^ 42, 646657.
 McNamara, T.
, & Altarriba, J.
 (1988).
 Depth of spreading activation revisited: Semantic mediated priming occurs 554 in lexical decisions.
 Journal of Memory and Language, 27, 545559.
 Mathews, A.
, & MacLeod, C.
 (1994).
 Cognitive Approaches to Emotion and Emotional Disorders.
 Annual Review of Psychology, 45, 2550.
 Murphy, S.
 T.
, & Zajonc, R.
 B.
 (1993).
 Affect, Cognition, and Awareness: Affective Priming with Optimal and Suboptimal Stimulus Exposures.
 Journal of Personality and Social Psychology.
 64(5), 723739.
 Natale, M.
, & Hantas, M.
 (1982).
 Effect of Temporary Mood States on Selective Memory About the self.
 Journal of Personality and Social Psychology, 42(5), 927934.
 Neely, J.
 (1977).
 Semantic Priming and Retrieval from Lexical Memory: Roles of Inhibitionless Spreading Activation and LimitedCapacity Attention.
 Journal of Experimental Psychology: General, 106(3), 226254.
 Neely, J.
 H.
 (1991).
 Semantic priming effects in visual word recognition: A selective review of current findings and theories.
 In H.
 Besner & G.
 W .
 Humphreys (Eds.
), Basic processes in reading: visual word recognition (pp.
 264336).
 Hillsdale, NJ: Earlbaum.
 Perrig, W .
 J.
, & Perrig, P.
 (1988).
 Mood and memory: Moodcongruity effects in absence of mood.
 Memory & Cognition, 16(2), 102109.
 Shelton, J.
 R.
, & Martin, R.
 (1992).
 H o w semantic is automatic semantic priming.
 Journal of Experimental Psychology: Learning, Memory and Cognition, 18(6), 11911210.
 Seidenberg, M.
, Waters, G.
, Sanders, M.
, & Langer, P.
 (1984).
 Pre and postlexical loci of contextual effects on word recognition.
 Memory and cognition, 12(4), 315328.
 Shiffrin, R.
 (1988).
 Attention.
 In R.
 H.
 R Atkinson G Lindzey & R Luce (Eds.
), Steven's Handbook of Experimental Psychology, Volume 2: Learning and Cognition, (pp.
 739811).
 New York: John Wiley & Sons.
 Watson, D.
, & Tellegen, A.
 (1985).
 Toward a consensual structure of mood.
 Psychological Bulletin, 98(2), 219235.
 Weaver, K.
, & Mcneill, A.
 (1991).
 Null Effect of Mood as a Semantic Prime.
 Journal of General Psychology, 7/9(3), 295301.
 Wyer, R.
 S.
, & Prey, D.
 (1983).
 The effects of feedback about self and other on the recall and judgments of feedbackrelevant information.
 Journal of Experimental Social Psychology, 19, 540559.
 555 T o w a r d s an ObjectOriented Language for Cognitive Modeling Richard Cooper Department of Psychology University College London Gower Street London W C 1 E 6 B T r.
cooperipsychol.
ucl.
ac.
uk Abstract This paper describes work towards an objectoriented language for cognitive modeling.
 Existing modeling languages (such as C, LISP and Prolog) tend to be far removed from the techniques employed by psychologists in developing their theories.
 In addition, they encourage the confusion of implementation detail necessary for computational completeness with theoretically motivated aspects.
 The language described here (OOS) has been designed so as to facilitate this theory/implementation separation, while at the same time simplifying the modeling process for computationally nonsophisticated users by providing a set of classes of basic "cognitive" objects.
 The object classes are tailored to the implementation of functionally modular cognitive models in the box/arrow style.
 The language is described (in terms of its execution model and its basic classes) before a sketch is given of a simple production system which has been implemented within the language.
 W e conclude with a discussion of ongoing work aimed at extending the coverage of the language and further simplifying the modeling process.
 Introduction: Rationale The principle of "functional modularity", whereby the behavior of a complete system is determined by the interaction of a number of semiautonomous subsystems, is a commonplace within cognitive science.
 Many cognitive models, including those from both the connectionist paradigm and the symbolic paradigm, are based on the principle.
 The former is exemplified by models such as Miikkulainen's model of script processing (Miikkulainen, 1993) and Burgess & Hitch's model of the articulatory loop (Burgess & Hitch, 1992).
 The latter is exemplified by models such as Barnard's Interacting Cognitive Subsystems model (Barnard, 1985) and production systems such as Soar (Newell, 1990, which is modular in the sense of having separable working memory and production memory components).
 Hybrid symbolic/connectionist models also employ functional modularity (e.
g.
, Wermter & Lehnert, 1989), and further models, such as Morton's model of the processing of words and pictures (Morton, 1981), adopt functional modularity without making any commitment to the underlying implementation.
 Within cognitive psychology, functional modularity is often expressed in terms of box/arrow diagrams.
 These diagrams, which generally consist of a number of labeled interconnected boxes, have a long and checkered history stretching back to Lichtheim (1885).
 Early criticisms failed to differentiate between functional and structural modularity (see Shallice (1988) for a review).
 More recently, critics have argued that such diagrams are virtually contentless, but this accusation can be rebutted by observing that the diagrams do make theo retical claims about functional modularity and the flow of dat£ between the modules.
 Such theoretical claims may be justified by, and tested against, empirically observed dissociations between functioning (cf.
 Morton, 1981; Shallice, 1988).
 Box arrow diagrams share a superficial resemblance to flow charts, and this too has led to criticism.
 However, the two diagrammatic notations differ on several substantive grounds.
 Crucially, flow charts encode algorithms and express the flow of control.
 They are rooted in the traditional model of computation as sequential processing, and (if taken to be more than purely descriptive of behavior) seem to imply that flow charts are somehow represented in the head and executed by some conventional computational device.
 Box/arrow diagrams, in contrast, express functional modularity and flow of data between functional modules.
 They make no claims about sequential processing, and do not suggest the existence of any program which the system deliberately follows.
 Independently of their use in cognitive psychology, ideas similar to those behind functional modularity have recently achieved prominence within computer science.
 In particular, the objectoriented paradigm (see, e.
g.
, Rumbaugh et al.
, 1991) advocates the use of informationally encapsulated objects to which subcomputations can be allocated via specified communication channels.
 As a result, ObjectOriented Programming (OOP) offers the possibility of directly addressing, within a sound computational framework, the functional modularity implicit in box/arrow diagrams.
 Specifically, within an objectoriented paradigm, boxes might be directly modeled as objects (of various classes), with arrows being directly modeled as communication channels between those objects.
 O O P has considerable potential utility within the domain of cognitive modeling in virtue of the approach that it offers to functional modularity.
 There are further arguments, however, for O O P within the discipline.
 Firstly, an objectoriented class hierarchy may be used to facilitate modeling by providing a variety of object classes tailored to the requirements of cognitive modeling.
 The class hierarchy described in the following section, for example, includes various different forms of buffer common in psychological theorizing.
 By providing the psychologist with a library of such classes, he/she may implement a model without having to consider the detailed implementation of the boxes within the model.
 That is, the psychologist can work at the level of interacting buffers and processes, etc.
, rather than at the level of C, Lisp, or Prolog code.
 In this way, O O P can lessen the "distance" between the language of the cognitive psychologist and the language of 556 http://ucl.
ac.
ukthe implementation.
 Secondly, O O P offers the possibility of providing a truly declarative specification of a psychological model.
 There are two advantages to such a specification: 1) it frees the theorist entirely from the implementation level, so the question of whether individual boxes are implLnicnled in symbolic or connectionist terms is sidestepped, and the important issue of specifying the properties of the individual boxes comes into focus;^ and 2) the box/arrow specifications with which cognitive psychologists work are equally declarative.
 The declarative statement offered by O O P of box/arrow diagram comes about by directly mapping the diagram to a specification of object instances and communication channels.
 Extending that statement to a complete declarative (and executable) specification requires declarative specifications of the processes internal to each box, but such specifications may be given in, for example, the purely logical fragment of Prolog.
 While this does not entirely free the psychologist from traditional programming, it does dramatically reduce the extent of that programming.
 OOS: ObjectOriented Sceptic Is objectorientedness (including the provision of an appropriate class hierarchy) the only requirement for a cognitive modeling language? Certain functionality is implicated in a great many cognitive theories (such as pattern directed processing, content addressable memory retrieval and update, and the possibility of both sequential and parallel processing modes), and a case can be made for providing these c o m m o n features as primitive operations in a modeling language.
 One language which provides these primitives (but is not objectoriented) is Sceptic (Hajnal et ai, 1989; Cooper & Farringdon, 1993).
 This modeling language (which is based on Prolog) has been successfully applied in the implementation of a number of cognitive theories, including theories of reasoning, memory, motivation, automatic control of action, and two versions of the Soar architecture (see Cooper et ai, 1993).
 For present purposes, the details of Sceptic are not important.
 This section describes O O S (ObjectOriented Sceptic), a language developed in order to extend Sceptic's capabilities by incorporating support for objectoriented programming.
 The Execution Model A cognitive model specified in OOS consists of a set of box declarations.
 These declarations specify the class of boxes (e.
g.
, limitedcapacity buffer: see below), their classspecific properties (e.
g.
, the capacity of a buffer), and how they interact (i.
e.
, the arrangement of arrows between those boxes, in terms of paired input and output ports).
 The underlying execution model of O O S , the mechanism by which a cognitive model specified in the language is animated, is cyclic.
 O n each cycle each object (i.
e.
, each box) operates on any data waiting at its input ports.
 The result of this processing depends on the class of object in question.
 A typical process will transform the data and send the transformed data as input to some other 'This is not to say that the properties of certain classes of boxes might not be more easily implemented in one technology or another, but that box properties, rather than implementation technology, should be the issue under discussion.
 object, whereas a typical buffer will incorporate the data into its state.
 All objects effectively operate in parallel.
 Central to the execution model is a data bus, which contains all data (or messages) in transit between boxes, i.
e.
, all messages that have been sent along an arrow from one box but not yet received.
 In addition, each box has an internal state.
 The state of the entire model at time t is fully determined by the state of each box at time t together with the contents of the data bus at timei.
 The behavior of a box over time is determined by two functions, a state transition function and an output function.
 Each box is completely specified by its initial state (i.
e.
, its state at time < = 0) and these two functions.
 If the state of box x at time < is denoted by s$.
, its input denoted by zj.
, and its state transition function by stx, then: The output of a box is similarly a function of its input and its internal state, and consists of a multiset of (message, box identifier) pairs, with the interpretation that (m, x) represents a message m bound for box x (and to be processed as input to box X during the next cycle).
 Elements of the bus are also (message, box identifier) pairs.
 If w e denote by 5* the state of the bus at time t, then the multiset of messages in the bus at timet bound for box x, r{B^ ,x), is given by: r{B',x) = {m\{m,x)eB') The content of the bus at time < |1 is the union of the outputs of all boxes, given their state at time <, and the messages bound for them at that time.
 In symbols: 5'+i= \^{b\h = ouUsi,r{B\x))) where X is the set of all boxes which comprise the model, and i±) denotes multiset union.
 The Class Hierarchy The class hierarchy developed to date is somewhat limited.
 The root class in the class hierarchy is box.
 It has four subclasses: buffer, process, data, and compound.
 More subclasses (such as network objects) are easily added, and it is anticipated that the class hierarchy will be extended as the need arises.
 Buffers: These are boxes that store information but have a null output function: messages sent to a buffer may change its state, but they will not produce output.
 The utility of a buffer lies in the fact that its state may be read by process or compound boxes (see below).
 Buffers are sensitive to three sorts of messages.
 A c l e a r message will effectively remove all elements from the buffer to which it is sent by replacing the existing state with an empty state.
 A message of the form +X (where X is a Prolog term) will add X to the buffer.
 A message of the form X will delete X from the buffer (provided X is currently in the buffer).
 A buffer may receive any number of messages on one and the same cycle.
 In this case, clear messages are processed before delete messages which are in turn processed before add messages.
 N o ordering is specified on the processing of messages within a particular category (e.
g.
, within the category 557 of delete messages), as such ordering does not affect the final result of processing within a cycle.
 This is consistent with the treatment of the bus as a multiset, with no ordering on its elements.
 Buffers have various properties which alter the way they behave when they receive messages and when they are read.
 A binary property indicates whether a buffer can store duplicate copies of the same information, or whether duplicates should be ignored.
 A second property specifies the order of access (newest first; oldest first; or random) when the buffer is read.
 A third property specifies whether the contents of the buffer are subject to decay (and if so what form of decay).
 Current options include: none; decay after a specified number of cycles; and decay randomly with probability specified in terms of a halflife.
 These properties must be specified for all buffers.
 The class buffer has two subclasses: unlimited capacity and limited capacity.
 Limited capacity buffers have two additional properties.
 The first specifies the capacity, and the second specifies the action to take when this capacity is exceeded (delete the most recent element to make room for the new element; delete the least recent element; delete a random element; or ignore the new element).
 Specifying a buffer in O O S only requires that its subclass and the value of the appropriate parameters be specified.
 The use of classes and properties standardizes the notion of a buffer (thus potentially increasing communicability of theories), and also allows theorists to experiment with variations on a model by varying the properties (e.
g.
, the decay characteristics) of individual subcomponents.
 The intention is that the above properties and subclasses should cover the majority of forms of buffer employed in current psychological theorizing, though further application of the language m a y well reveal further properties or subclasses.
 The motivation for the current properties and subclasses comes partly from existing psychological theorizing and partly from logical possibilities that are consistent with this theorizing.
 For example, in Fodor and Frazier's model of sentence processing (Frazier & Fodor, 1978; Fodor & Frazier, 1980), during processing the Preliminary Phrase Packager (PPP) works on a fragment of the sentence under consideration.
 In psychological parlance, the PPP makes use of a limited capacity push through store.
 A s each new word enters the store, it pushes the least recent entry out.
 Within O O S , the relevant box is a limited capacity buffer with duplicates but without decay, with access via the most recent element first and with the least recent element being deleted when the capacity is exceeded.
 Fodor and Frazier do not specify the capacity of the PPP's buffer,^ but O O S allows one to experiment with different capacities (by simply varying the value of the corresponding property and conducting the appropriate simulations), thereby allowing an optimal capacity (and the effects of varying this capacity) to be determined.
 ^Frazier & Fodor (1978: 293) comment that the capacity of the PPP might not be defined in words, but in terms of syllables, morphemes, or even time slices.
 If capacity is to be measured in syllables, morphemes or time slices, then the input messages should be packaged as syllables, morphemes, or time slices, respectively.
 Capacity is defined strictly in terms of the elements which constitute the messages that a buffer receives.
 Processes: Processes are defined to be objects which transform data according to fixed, well specified, rules.
 They may be viewed as boxes which map from one representation to another.
 The output function is defined to be independent of the internal state, which cannot be queried.
 (As such, the internal state is effectively redundant, and might as well be defined to be null, with the identity mapping as the state transition function.
) Processes thus have no memory capabilities, and in this sense they are the complement of buffers, which have an internal state, but a null output function.
 T w o subclasses of process are available (triggered and autonomous: see below), but because of the variability of possible output functions, it is not currently possible to specify processes completely in terms of properties and further subclasses.
 The output function of a process must at present be defined via rewrite rules similar to standard Sceptic (see Cooper & Farringdon, 1993, for details).
 This is an undesirable aspect of the current system, as it requires some knowledge of a conventional textbased programming language.
 Triggered processes are those which are activated by input messages.
 If they receive no input, they generate no output, but when triggered by input, they map that input according to their output function.
 In a sense, triggered processes are passive processes.
 Autonomous processes, on the other hand, are active processes: they actively find data (by, for example, reading the contents of a specified buffer) and produce output on the basis of that data.
 Triggered processes may also read a buffer's contents when calculating their output, but they will not attempt to produce output unless specifically triggered by an input message.
 Returning to Fodor and Frazier's model of sentence processing, the PPP can be seen to also include an autonomous process which monitors the input buffer looking for phrasal constituents, packaging such constituents when they are found and sending them to the Sentence Structure Supervisor (SSS), a collection of boxes which combine the PPP's results into a complete phrase marker for a sentence.
 Data: Data boxes may be used to supply input data to a model or to record output data from a model.
 The two subclasses of data box which serve these two functions are source and sink.
 Data sources are initialized with a list of Prolog terms (read from a file).
 O n each cycle, if the source is not empty, the first element of this list is removed from the source and a copy of it is sent via any arrows to all boxes connected to the source.
 Data sinks accumulate output, functioning in the reverse way to data sources: on each cycle, any messages sent to a data sink are appended to the sink.
 Data boxes generally do not belong to a model in the same way as other boxes do in that no psychological validity is typically ascribed to them.
 Data sources might be used, for example, to supply the posited results of perceptual processes to boxes performing more central cognitive functions (thus circumventing the problem of modeling perception), and data sinks might be used to record the sequential output of the cognitive process under investigation.
 Thus an appropriate data source for the Fodor and Frazier model may comprise a list of words, syllables, or morphemes which constitute the input to the PPP.
 A data sink may then be used to collect the phrase markers generated by the SSS.
 558 Data boxes are very flexible and individual boxes or subsets of boxes may be tested in isolation by lifting those boxes out of the complete model and attaching data sources (with appropriate inputs) at all disconnected input ports and data sinks at ail disconnected output ports.
 Thus, Fodor and I'la/.
icr's SSS may be tested/developed in isolation from the PPF (and vice versa) by replacing the boxes comprising the PPP with an appropriate data source that feeds directly into the SSS.
 Compounds: Compound boxes are used where it is desirable to group other boxes together into a single functional module.
 They might be thought of as a box within which other boxes can be put, thus allowing a model to be hierarchically structured.
 There are no restrictions on the outputs or states of compound boxes, and they serve no computational function within the execution model.
 They are, however, vital to the structured topdown development of models (see below).
 With regard to the sentence processing model, it would seem appropriate to treat the PPP and the SSS each as compound boxes, both consisting of a network of processes and buffers.
 Communication Within O O S communication between boxes is generally specified by defining arrows from the source box to the target box.
 Thus, to specify that data should be feed from a data source to a process, an arrow must be defined from the data source to the process.
 Defining a second arrow from the data source to, for example, a buffer, will result in the data from the source being simultaneously sent from the source to both the process and the buffer.
 The exception to this simple means of establishing communication channels arises with messages sent from processes, which must be explicitly addressed to a named target box (or to several named target boxes).
 This is to allow a single process to generate multiple messages for a variety of target boxes.
 Explicit addressing is performed in modified Sceptic within the specification of a process' output function.
 Methodology: Building Models with OOS There are three stages to developing an O O S model.
 Firstly, the model should be drawn in diagranmiatic (box/arrow) form.
 Where modules with both processing and buffering capabilities are required, compound boxes should be used.
 These can "opened up" at stage 3.
 Compound boxes thus facilitate a top down, structured, approach to the development of an D O S model: global characteristics of the model can be specified before lowerlevel details of individual compounds are considered.
 This is consistent with psychological theorizing, where many boxes typically have complex processing characteristics (though those processing characteristics are often only specified informally).
 Secondly, the class (or subclass) of each box must be determined, and the relevant properties specified.
 At this stage, the capacity or decay characteristics of buffers should be specified, and questions of whether processes are triggered or autonomous must be addressed.
 Thirdly, the internals of those boxes which have internals must be specified.
 At this stage data must be specified for the various data sources, code must be given to specify the output functions of the various processes, and compound boxes must be decomposed into their constituent subboxes (which may, in themselves, be compound boxes).
 The contents of a data source will be the data which is to be used to test the model.
 Specifying this data may involve making assumptions about perceptual processes and the representation of data which is delivered to the model.
 With regard to processes, these may, in the first instance, operate as lookup tables.
 Given that the test data is specified, processes may initially be specialized so as only to respond appropriately to this data.
 Once the complete model has been debugged and is operational, the output functions of processes can be generalized (keeping in mind that their input/output characteristics in the original domain must be preserved).
 Compound boxes must be specified recursively.
 That is, for each compound box the three stages outlined here must be repeated, until all compound boxes at all levels have been decomposed into networks of primitive boxes.
 Compound boxes are effectively a way of bracketing a part of the model as a complete submodel.
 Given this, a second appropriate development methodology involves developing detailed specifications of compound boxes in isolation.
 As noted above, the interaction of a particular compound box with the remainder of the model can be simulated with data sources and data sinks, and in this way a detailed model of one component can be formulated (and executed) before the complete model has been specified.
 O O S lessens the problems of confusing theoretically motivated aspects of a program with implementation detail by lessening the distance between the theoretical statement of the theory and its implementation.
 In doing so, O O S forces the theorist to consider questions which might otherwise have been ignored (such as the access properties of a buffer, or indeed the specification of any properties specific to a particular box).
 It might be argued that such questions are truly implementation details, and should not concern the psychological theory.
 This position is justified only if the behavior of the complete model is independent of the precise value of the property in question.
 Within O O S it is possible to experimentally test such claims.
 In particular, the theorist can examine the effect of various objects' parameters on the model's behavior.
 Hence, by systematically varying the relevant parameters and conducting the appropriate simulations the truth of such claims concerning implementation detail can be ascertained.
 O O S is thus more than simply an implementation tool.
 By bring implementation claims to the forefront, and by allowing those claims to be tested, O O S can actually inform psychological theorizing.
 An Example: A Simple Production System In order to illustrate the power and simplicity of OOS this section sketches the implementation of a simple production system within the language.
 Figure 1 depicts a box/arrow diagram corresponding to such a production system.
 In this figure, hexagons represent processes, rounded rectangles represent buffers, and diamonds represent data boxes.
 Arrows with standard arrow heads indicate message sending.
 Arrows with black triangular tails indicate buffer reading.
 Thus, the process "Resolve Conflicts" reads "Match Memory" and "Refractory Memory" and sends messages to "Refractory M e m ory" and "Fire Productions".
 559 Refractory Memory V y Match Memory latch Productions> < Proiluction Memory < Resolve Contlic Working Memory Fire Productions Figure 1: Box/arrow representation of a simple production system.
 The diagram is considerably more complex than some production system diagrams, which typically only show working memory and production memory.
 This is because Figure 1 is complete.
 It shows all processes and buffers, and all communication channels, necessary for a simple production system.
 It can be seen then that a production system involves four buffers (i.
e.
, memory components).
 As well as working memory and production memory, a match memory (in which current instantiations of productions are held) and a refractory memory (in which previously fired instantiations of productions are held) are required.
 These are all modeled as unlimited capacity decayfree buffers, although O O S allows for the possibility of exploring capacity restrictions or decay characteristics (see Cooper et ai, 1993, for details of experiments with working memory and match memory decay in the Soar production system).
 Each buffer is specified completely in terms of its properties and the subclass of buffer of which it is an instance.
 There are three distinct processes.
 "Resolve Conflicts" is an autonomous process which monitors match memory and refractory memory.
 W h e n it discovers new production instantiations in match memory which are not in refractory memory, it sends the elements on the right hand side of those instantiations to "Fire Production" and adds the instantiation to refractory memory.
 "Fire Productions is a triggered process.
 W h e n it receives a message it adds an element to working memory or sends a message to the output (depending on the message received).
 These processes are distinct from the "Match Productions" process which monitors working memory and production memory, looking for production instantiations which should be added to match memory.
 Note that each process is specified locally — as an encapsulated object that responds in a specified way to specified inputs.
 The figure embodies a theory of the functional structure of a production system, and there is a direct mapping from the boxes shown to an O O S specification of the system.
 To transform this specification into a complete implementation it is necessary to specify the properties and subclasses of the various boxes, together with the output functions associated with the various processes.
 These output functions have each been specified in about a dozen lines of code.
 Of course, to model a particular task within the production system it is still necessary to provide taskspecific productions.
 In order to validate ihc production system described here, it has been tested with the productions necessary for multicoluinn addition as described by Anderson (1993, p.
 10).
 Discussion OOS currently exists as a Sceptic program implementing the execution model and a set of Sceptic libraries implementing the class hierarchy.
 The libraries have been sufficient for our modeling to date, but elaborations to increase coverage are likely as the language is applied to further domains.
 For example, at present buffers cannot send messages, but it may be appropriate to include, as a subclass of limited capacity buffers, a class of buffer which sends messages consisting of those elements shunted out when the buffer's capacity is exceeded.
 Work is also continuing on attempting to further subclassify processes (into classes such as delay, filter, monitor, and agglomerate).
 This is particularly important as the specification of a process' output function is currently the only substantive programming required in using the language.
 Lastly, network objects (e.
g.
, feedforward networks, associative networks, recurrent networks, and interactive activation networks) may also be included, thus allowing the language to be used for modular connectionist and hybrid symbolic/connectionist modeling.
 Attempts have previously been made to develop computational tools and modeling environments to assist cognitive modeling (e.
g.
, OPS: Forgy, 1981).
 Such environments have had little penetration into mainstream cognitive science.
 The language described here attempts to address the perceived failings of such earlier tools in a number of ways, based on recent advances in computer science.
 Firstly, by taking functional modularity as the major design requirement, O O S is closer to the formalisms used by traditional cognitive psychologists than, for example, languages based on production system.
 Secondly, O O S aims to minimize the programming (and hence computational sophistication) required of its uses.
 Early modeling environments were generally most successful with those skilled in computer languages.
 O O S still requires a certain level of computational expertise (in specifying the output functions of processes), but this is strictly limited, and as noted above it is anticipated that the inclusion of more object classes will further reduce the programming skills required.
 Furthermore, the language is well suited to a graphical interface, and a preliminary version of a Graphical O O S Editor ( G O O S E ) which allows box/arrow diagrams to be drawn and automatically converted from the diagrammatic form into O O S syntax has been developed.
 This further simplifies the modeling process, taking much of the burden of writing textual code off the psychologist.
 Work is continuing on a more sophisticated version of this interface.
 The use of an objectoriented language for cognitive modeling raises a number of issues.
 Firstly, it should be noted that the contribution of objectorientedness is more than implementational.
 Although objectorientedness was motivated on the grounds of providing an appropriate implementation base, the use of a class hierarchy could (if sufficiently extensive) provide a standard specification of box types.
 Such a specifi560 cation would lessen the problem of ambiguity and underspecification faced by current uses of box/arrow diagrams, and thereby increase communicability of theories.
 Furthermore, by associating properties with box classes, issues concerning the relation between theory and implementation (and specilically if certain properties are theoretically relevant) can be addressed.
 There is also a question of whether more standard objectoriented languages (such as C + + or Smalltalk) would be more appropriate than O O S for cognitive modeling.
 In one sense, the language in which the class hierarchy is implemented is irrelevant, but implementing it in Sceptic does bring the benefits of certain primitives common in cognitive theories.
 The execution model could similarly be implemented in any language — it is, after all, effectively just a shell.
 It is the properties of that shell that are important, and it is this, which identifies O O S as an objectoriented language specialized for cognitive modeling.
 Programmers often abuse languages by using them in ways which conflict with their design aims, and the use of an objectoriented language cannot enforce the development of objectoriented programs.
 It is, however, difficult to misuse O O S .
 The underlying execution model is built around the notion of communicating objects.
 To avoid the use of such objects requires substantial knowledge about the underlying implementation of the execution model.
 This issue is further addressed by G O O S E , which places tight restrictions on text based programming.
 The complete model (apart from the output functions of processes) must be expressed in box/arrow notation.
 The only possible abuse within G O O S E is to overload processes (i.
e.
, to have one process performing functionally distinct operations).
 The converse of this is that the language may be too restrictive, not allowing sufficient freedom to implement certain classes of models.
 In general, this difficulty can be addressed by extending the class hierarchy as necessary.
 Such extensions do, of course, require substantial computational sophistication, and could not be achieved unaided by O O S ' target audience.
 Lastly, it might be objected that use of O O S implies a commitment to boxes in the brain with messages (and an attendant language of thought) being sent between them.
 This is not the case.
 Implicit in the concept of functional modularity is the differentiation of structure and function.
 Functional modularity does not imply structural modularity: a functional subsystem is a system at the cognitive level and it need not correspond to any identifiable structural subsystem (either neurally localized or neurally distinct) at the neurophysiological level.
 Conclusion OOS, an objectoriented language for computational modeling, has been described.
 The language facilitates the modeling process by providing a set of object classes appropriate for (symbolic) cognitive modeling within the box/arrow tradition.
 The language is primarily intended to simplify the development of computational models and thereby empower computationally less sophisticated researchers.
 The language is also appropriate for the fast prototyping of models and theory driven experimentation (by varying properties or classes of boxes within a model).
 Acknowledgements I am grateful to John Fox, Sofka Barreau, John Morton, NickBraisby, Tim Shallice, David Glasspool, Bradley Franks, Jonathan Farringdon and two anonymous referees for discussion of, and/or comments on, this work.
 This work was supported by the Joint Council Initiative in Cognitive Science and HumanComputer Interaction, project grant #G9212530.
 Further details of this project may be obtained from our Web page at http: //www.
psychol .
ucl .
ac.
uk/ research/adrem/adrem.
html.
 References Anderson, J.
 R.
 (1993).
 Rules of the Mind.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Barnard, P.
 J.
 (1985).
 Interacting cognitive subsystems: A psycholinguistic approach to shortterm memory.
 In Ellis, A.
 (Ed.
), Progress in the Psychology of Language, (ch.
 6, pp.
 197258).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Burgess, N.
 & Hitch, G.
 J.
 (1992).
 Toward a network model of the articulatory loop.
 Journal of Memory and Language, 31, 429^60.
 Cooper, R.
 & Farringdon, J.
 (1993).
 Sceptic Version 4 User Manual Tech.
 Rep.
 UCLPSYADREMTR6, Department of Psychology, University College London, UK.
 Cooper, R.
, Fox, J.
, Farringdon, J.
 & Shallice, T.
 (1993).
 Towards a systematic methodology for cognitive modeling.
 Tech.
 Rep.
 UCLPSYADREM8, Department of Psychology, University College London, UK.
 To appear (subject to revision) in Artificial Intelligence.
 Fodor, J.
 D.
 & Frazier, L.
 (1980).
 Is the human sentence parsing mechanism an A T N ? Cognition, S(4), 417459.
 Forgy, C.
 L.
 (1981).
 OPS5 User's Manual.
 Tech.
 Rep.
 C M U CS81135, Department of Computer Science, CarnegieMellon University, Pittsburgh, Pennsylvania.
 Frazier, L.
 & Fodor, J.
 D.
 (1978).
 The sausage machine: A new twostage parsing model.
 Cognition, 6(4), 291325.
 Hajnal, S.
, Fox, J.
 & Krause, R (1989).
 Sceptic User Manual: Version 3.
0.
 Tech.
 Rep.
, Advanced Computation Laboratory, Imperial Cancer Research Fund, London, U K .
 Lichtheim, L.
 (1885).
 O n aphasia.
 Brain, 7, 433^84.
 Miikkulainen, R.
 (1993).
 Subsymbolic Natural Language Processing.
 Cambridge, M A : M I T Press.
 Morton, J.
 (1981).
 The status of information processing models of language.
 Philosophical Transactions of the Royal Society of London B, 295, 387396.
 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M A : Harvard University Press.
 Rumbaugh, J.
, Blaha, M.
, Premerlani, W.
, Eddy, F.
 & Lorensen, W.
 (1991).
 ObjectOriented Modeling and Design.
 Englewood Cliffs, NJ: PrenticeHall.
 Shallice, T.
 (1988).
 From Neuropsychology to Mental Structure.
 Cambridge, U K : Cambridge University Press.
 Wermter, S.
 & Lehnert, W.
 G.
 (1989).
 A hybrid symbolic/connectionist model for noun phrase understanding.
 Connection Science, 7(3), 225272.
 561 http://www.
psycholhttp://ac.
uk/Learning N e w SpatiallyOriented GamePlaying Agents through Experience Susan L.
 Epstein Department of Computer Science Hunter College and The Graduate School of The City University of New York New York, NY 10021 epstein@roz.
hunter.
cuny.
edu Jack Gelfand Department of Psychology Princeton University Princeton, NJ 08544 J J g@princeton.
edu Abstract As they gain expertise in problem solving, people increasingly rely on patterns and spatiallyoriented reasoning.
 This paper describes the integration of an associative visual pattern classifier and the automated acquisition of new, spatiallyoriented reasoning agents that simulate such behavior.
 They are incorporated into a gamelearning program whose architecture robustly combines agents with conflicting perspectives.
 When tested on three games, the visual pattern classifier leams meaningful patterns, and the patternbased, spatiallyoriented agents generalized fiom these patterns are generally correct.
 The trustworthiness and relevance of these agents are confirmed with an algorithm that measures the accuracy of the contribution of each agent to the decisionmaking process.
 Much of the knowledge encapsulated by the correct new agents was previously inexpressible in the program's representation and in some cases is not readily deducible from the rules.
 Pattern Learning in Game Playing In this paj)er we describe the use of an associative visual memory and spatiallyoriented reasoning agents in twoperson, perfect information, finiteboard games.
 This approach uses two kinds of patternoriented learning for game playing: the association of particular pattems with successftil or unsuccessftil play, and the construction of spatiallyoriented heuristics from those pattems.
 Figure 1(a), where the empty locations are blanks and # denotes "don't care," is an example of the first kind of pattern learning; it Unks a particular pattern from tictactoe with success for X.
 In any symmetric orientation and whatever the # squares contain, a human expert associates such a configuration with a win for X.
 Along with particular pattems, gameplaying experts use more general but equally salient heuristics as spatiallyoriented "rules of thumb.
" Figure 1(b) is an example of the second kind of pattem learning.
 It is the spatiallyoriented heuristic "reflect O's move through the center," proved to be optimal play for X in the game of lose tictactoe (Cohen, 1972).
 Advice from experts on how to analyze and play games is repeatedly couched in the language of such spatiallyoriented pattems.
 Chess and checkers are discussed in terms of controlling the center of the board, while control of the edges is cmcial in Othello (Fine, 1989; Gelfer, 1991; Lee & Mahajan, 1990; Samuel, 1963).
 Concepts such as shape and thickness are fiindamental to the game of G o (Hideo, 1992; Iwamoto, 1976; Yoshio, 1991).
 As people improve their expertise in game playing, they increasingly employ spatiallyoriented heuristics, and treat them as compiled knowledge, integrated but no longer reasoned about.
 To learn pattem associations, programs use a feature language and inductive learning algorithms that operate on game states described in that language.
 De Groot proposed a recognitionassociation model to explain human chess skill in terms of spatial pattems (de Groot, 1965).
 Chase and Simon refined this model to include recall from long term memory in terms of spatial chunks (Chase & Simon, 1973; Simon & Gilmartin, 1973).
 There are several chess playing programs that capitalize upon pattems (George & Schaeffer, 1991; Levinson & Snyder, 1991).
 Applying learned pattems to game playing, however, has proved somewhat problematic.
 There are usually a great many of them and matching is nontrivial.
 T2 and Zenith, for example, leamed predicate calculus expressions for tictactoe and Othello, respectively (Fawcett & Utgoff, 1991; Yee, Saxena, Utgoff, & Barto, 1990).
 O n one run T2 leamed 45 tictactoe concepts with 52 exception clauses after 800 contests, a great many for so simple a game.
 In the woik described here, leamed pattem knowledge is used to constmct higherorder, spatiallybased reasoning agents.
 Programs that leam concepts from gameplaying experience have in the past been hampered by a predicate calculus representation that lacks incisiveness, and by exhaustive explanation of inconsistencies for positions that may have no consequence in the strategic play of the game X X # # X X to move or (a) X to move or X to move 0 # # # X # # # ^ # o # #~"x # # t # # t # # X # # 0 # Go here (b) Figure 1: (a) A tictactoe pattem that X associates with winning.
 # denotes "don't care.
" (b) "Reflect through the center," a spatiallyoriented heuristic for lose tictactoe.
 562 mailto:epstein@roz.
hunter.
cuny.
edumailto:g@princeton.
edu(Fawcett, et al.
, 1991; Yee, et al.
, 1990).
 The process we describe, in contrast, is able to deal with inconsistencies robustly while it focxises attention on those situations containing important visual patterns.
 Most importantly, a dynamic filtering process continually refines the contents of the pattern memory to assure that, as the gameleanung program becomes more expert, concept formation becomes increasiî ly accurate.
 The longrange objective of this work is to create a heuristicallybased decision maker that learns rapidly enough to participate in inteUigent behavior while it is still acquiring knowledge.
 With a hierarchical multiagent system, the presence of other more general problem solving advisors prevents incorrect actions, especially during early experience while learning.
 This paper reports that patternoriented learning functions as anticipated within this environment.
 W e foimd that the validation process for newly created agents performed properly, and that the system worked smoothly as knowledge was being refined during the learning process.
 W e believe that this process of creating new agents and testing their correctness in a multipleagent program is unique.
 A GameLearning Program There is evidence that humans integrate a variety of strategies to accomplish problem solving (Biswas, Goldman, Fisher, Bhuva, & Glewwe, 1995).
 There is also evidence that multiple, concurrent processing streams exist in the brain, each performing a component of a complex task.
 Automatic behaviors produce a locus of activity in the brain different fiom that of similar tasks requiring more cognitive processing (Grafton, Hazeltine, & Ivry, In press; Raichle, et al.
, 1994; Wallace, Silberstein, Bluff, & Pipingas, In press).
 In addition, during skill acquisition the locus of activity in the brain shifts from cognitive to associative areas with practice (Grafton, et al, In press, Raichle, et al.
, 1994; Wallace, et al.
.
 In press).
 The primate visual system has pathways for form, place, motion, and color (DeYoe & Van Essen, 1988; Ungerleider & Mishkin, 1982).
 Information from these streams is combined to form a perception of the visible world (Kandel, 1991).
 In addition, it has been found that different parts of the brain are activated when decisions are being made about different strategic aspects of chess (Nichelli, et al.
, 1994).
 The mechanisms we describe below simulate these features.
 Hoyle is a program that leams to play twoperson, perfect information, finiteboard games.
 It is based on a learning and problemsolving architecture for skills called FORR, predicated upon multiple rationales for decision making (Epstein, 1994a).
 F O R R employs multiple concurrent processing streams.
 Hoyle, as modified here, includes a separate stream for pattern learning.
 The transitions in the way Hoyle treats patterns model the automaticity shifts detected in humans during skill learning.
 Hoyle leams to play in competition against a handcrafted, external expert program for each specific new game.
 Whenever it is Hoyle's m m to move, a hierarchy of resourcelimited procedures called Advisors is provided with the current game state, the legal moves, and any useful knowledge (descnbed below) already acquired about the game.
 Hoyle has 23 heuristic Advisors m two tiers.
 The first tier sequentially attempts to compute a decision based upon correct knowledge, shallow search, and simple inference, such as Victory's "make a move that wins the contest immediately.
" If no single decision is forthcoming, then the second tier collectively makes many less reliable recommendations based upon narrow viewpoints, such as Material's "maximize the number of your markers and minimize the number of your opponent's.
" A n Advisor outputs its recommendations in the form of comments.
 A comment is of the form <Advisor, action, strength> where strength is an mteger from 0 to 10 that measures the intensity and direction of opinion.
 Given the Advisors' recommendations, a simple arithmetic vote selects a move that is forwarded to the gameplaying algorithm for execution.
 Although 23 may appear to be quite a few Advisors, they do a large job with remarkable efficiency.
 Hoyle leams to play five men's morris with about 9 million states expertly, for example, during exposure to about .
012% of the search space, and explicitly retains data on only about .
006% of the states in the game graph.
 Hoyle plays without ever searching more than two ply (one move for each contestant) ahead in the game tree.
 Hoyle leams from its experience to make better decisions based on acquired useful knowledge.
 Usejul knowledge is expected to be relevant to future play and is probably correct in the full context of the game tree.
 Examples of usefiil knowledge include recommended openings and states from which a win is always achievable with perfect play on both sides.
 Each item of usefiil knowledge is associated with at least one learning algorithm.
 The learning methods for useful knowledge vary.
 The learning algorithms are highly selective about what they retain; they may generalize and they may choose to discard previously acquired knowledge.
 Further details on Hoyle are available in (Epstein, 1992).
 Learning to Use and Apply Patterns The cmx of this paper is the addition to Hoyle of pattern learning and its application in new, gamedependent thirdtier Advisors.
 The implementation of pattem leaming and its application were inspired by repeated laboratory experiences with people, in the context of many different games.
 College students spoke about, reacted to, and relied upon familiar, sometimes symmetrically transposed, patterns while leaming (Ratterman & Epstein, 1995).
 Later, they relied heavily upon these patterns as a kind of compiled expertise.
 In this work, visuallyperceived regularities are represented as pa^^'m^, small geometric arrangements of marker types (e.
g.
, black, X) and unoccupied positions (blanks) in a particular geographical location.
 A n associative pattem store provides a heuristicallyorganized database that links patterns with contest outcome (win, loss, or draw).
 The associative pattem store includes a set of templates, a waiting list, a pattem cache and generated spatial concepts.
 Figure 2 provides an overview of the pattem matcher and the development of patternbased Advisors from the game563 R e c o m m e n d e d Action N e w Spatial Advisors Proceduralize ® Validate Test Correctness ' ® Spatial Concepts R e m o v e ® Generalize Pattern Caciie © Associate patterns with outcomes Pattern Waiting List G a m e State Figure 2: A schematic diagram of the associative pattern learning and spatial concept formation system.
 specific associative pattern store.
 There are four stages detailed here: associate, generahze, proceduralize, and validate.
 Once patterns are identified, they are associated on the waiting list with winning, losing, or drawing.
 Patterns that persist over time and are identified with a single consistent outcome move fi^om the waiting list to the pattern cache.
 Patterns in the cache are proceduralized via an associative pattern classifier, a new, gameindependent Advisor called Patsy.
 Periodic sweeps through the pattern cache also attempt to generalize sets of patterns into concepts.
 Concepts are proceduralized as individual, gamespecific Advisors that are then vahdated during subsequent learning.
 Finally, the pattern matcher improves as Hoyle learns to constrain pattern generation by excluding uninformative patterns.
 Formulating Concepts from the Pattern Cache Cached patterns are a rich source of information about the marker clusters to be seen during a particular game.
 Some of them ought to be forgotten; others are worthy of elevation to concepts that drive gamedependent Advisors.
 The identification of both kinds of patterns is done during a periodic sweep of the pattern cache.
 Currently, the first sweep of the pattern cache to form concepts is after 15 contests, and then the frequency is recomputed as a fionction of a confidence parameter after each sweep.
 Generalization summarizes a set of detailed experiences into a more useful and efficient representation.
 Hoyle has two generalization rules to form concepts.
 Patterns in a cache are said to agree when they originate from the same template and pertain to the same stage of the game.
 • Given distinct agreeing patterns PI, P2, and P3 with q ?'s that have the same mover and single, nonzero response, and are identical, except that in the /th position PI has a black, P2 a white, and P3 a nil value, construct a new pattern P on the ql ?'s other than the /th.
 A n example appears in Figure 3(a).
 • Given distinct agreeing patterns PI and P2 such that interchanging the contestants' markers and changing the mover in PI results in P2 with the opposite single nonzero response, construct a new pattern P with variable place holders a for black and P for white.
 A n example appears in Figure 3(b).
 The cache is organized to support fast detection of agreeing patterns.
 Proceduralization Proceduralization is the transformation of expert knowledge into expert behavior.
 This is a nontrivial task in AI (Mostow, 1983).
 W h e n there is much data or it conflicts in its potential application, as with pattern knowledge, interesting challenges arise.
 Each segment of the associative pattem store therefore relates differently to decision making.
 Patterns on the waiting list have no impact on decision making at all.
 Patterns in the cache serve as input to the associative pattem classifier.
 Patsy.
 Patternbased concepts become gamespecific Advisors.
 The new, gameindependent, secondtier Advisor Patsy ranks legal next moves based on the way the states they engender match patterns in the cache.
 Patsy considers the set of possible next states resuhing from the current legal moves.
 Each next state is compared with the patterns in the appropriate, gamespecific cache.
 N o new patterns are cached during this process.
 Each pattem is assigned a value computed from the total number of won, lost and draw contests since the pattem was first seen.
 The strength of Patsy's comment on each legal next move is a function of the values of the pattems in the state to which it leads.
 Thus Patsy encourages moves that lead to states introducing pattems associated with a win or a draw, while it discourages moves that lead to states introducing pattems associated with a loss.
 Each concept is proceduralized as a new, thirdtier, gamespecific Advisor.
 If the perfectlycorrect, gameindependent firsttier Advisors can select a move with their gamespecific usefiil knowledge, they do so and the second tier is never consulted.
 If the heuristic but generally correct, gameFor the template (a) ifPlls P2IS NIL and P3 Is 6 b 6—6 thenP ' • n (b) IfPlls P2IS _o For black f <" *""• then P Is P Figure 3: T w o generalization mles that are applied to pattems to formulate concepts.
 564 independent secondtier Advisors can agree upon a move with their gamespecific useful knowledge, they do so.
 Otherwise the moves judged equally good by the second tier are forwarded to the newlycreated third tier of gamedependent, patternbased Advisors.
 Validation of New Advisors As new, patternbased Advisors are introduced and Hoyle's skill develops further, some of them may prove irrelevant, selfcontradictory, or untrustworthy, despite prior empirical evidence of their vahdity.
 Credit^lame assignment in a domain such as this is extremely difficuh.
 At the end of a contest, it is difficult, even for human experts, to pinpoint the move that won or lost.
 The significant decision may have been early in play, or ma y have been a set of moves rather than an individual one.
 Rather than credit or blame a particular move, we have chosen to credit or blame the Advisors that support experthke behavior.
 Consider, for example, a hypothetical game state in which Hoyle has only secondtier comments <Advisorl, move1, strength1> and <Advisor2, move2, strength2>.
 Until now, if strength1 and strength2 were equal, the vote would be a tie, and one of the moves would have been chosen at random.
 But if Advisor2 were more trustworthy in this particular game, its comment should have more influence.
 This approach holds the rationale behind actions accountable, rather than the actions themselves.
 Irrelevant and selfcontradictory Advisors in a particular game should have weight 0, and more trustworthy Advisors should have higher weights than less trustworthy ones.
 Empirical experience with Hoyle indicates that these weights are problemclass specific, i.
e.
, a new item of useful knowledge to be learned.
 With an external model of expertise as its performance criterion, we use A W L , a perceptronlike model, to learn problemclassspecific weights for the [ procedure (Epstein, 1994b).
 A W L runs at the end of every contest Hoyle plays against an external (human or computer) expert.
 The algorithm considers, one at a time, only those states in which it was the expert's turn to move and Hoyle's first tier would not have made a decision.
 For each such state, A W L distinguishes among support and opposition for the expert's recorded move and for other moves.
 Essentially, Hoyle learns to what extent each of its Advisors simulates expertise, as exemplified by the expert's moves.
 A W L cumulatively adjusts the weights of secondtier and thirdtier Advisors at the end of each contest (whether or not the third tier would actually have voted during play), and uses those weights to make decisions throughout the subsequent contest.
 These weights are determined by a modification of Littlestone's learning algorithm (Littlestone, 1988).
 Results In all the experiments described here, Hoyle alternately moved first in one contest and second in the next.
 Such a trial continued until Hoyle was said to have learned to play a game because it could draw n consecutive contests in this environment.
 Once it met this behavioral standard, learning was turned off and the program was tested against four challengers that simulated perfect, expert ( 1 0 % random move selection, 9 0 % perfect), novice (70% random move selection, 3 0 % perfect), and random contestants.
 During testing, reliability measures the consistency with which the program can continue to win or draw against contestants of varying strengths, and power measures the ability of the program to defeat contestants of various strengths (Epstein, 1994c).
 W e have used patternbased learning with Hoyle in tictactoe, lose tictactoe (played exactly like tictactoe except that the first contestant to achieve three of the same playing piece along a row, column, or diagonal loses), and five men's morris.
 This game has two contestants, black and white, each with five markers.
 A contest at this game is played on a board like that in Figure 5 and has two stages: a placing stage, where initially the board is empty, and the contestants alternate placing one of their markers on any empty position, and a sliding stage, where a turn consists of sliding one's marker along any line drawn on the game board to an immediately adjacent empty position.
 A marker may not jump over another marker or be lifted fiom the board during a slide.
 Three markers of the same color on immec'iately adjacent positions on a line form a mill.
 Each time a contestant constructs a mill, she captures (removes) one of the other contestant's markers that is not in a mill.
 Only if the other contestant's markers are all in mills, does she capture one from a mill.
 The first contestant reduced to two markers, or unable to move, loses.
 Since Hoyle had aheady learned to play all the games studied here expertly after relatively few contests, these experiments were intended to demonstrate that gamedependent visual patterns exist and persist, despite the nondeterminism of the learning experience.
 They also showed that such patterns can be gathered without a combinatoric explosion, and that the transition from waiting hst to pattern cache to concept and Advisor is warranted.
 Furthermore it was shown that new, gamespecific Advisors can be learned and managed appropriately, all without reducing the program's ability to play.
 The potential computational overhead for concept formation is avoided.
 Very few of the possible patterns ever appear on the waiting list or in the cache.
 Even fewer are emphasized as the conceptual grounds for a heuristic Advisor, and some are learned to be uninformative.
 In tictactoe, despite the potentially large niunber of patterns, after learning there were 58 patterns in the waiting list, 22.
2 patterns in the cache, 4.
2 uninformative patterns, and 6.
4 concepts, all for draws.
 In lose tictactoe, with just as many potential patterns, after learning there were 58.
8 patterns in the waiting list, 57.
2 patterns in the cache, 1.
4 uninformative patterns, and 19 concepts, some for draws and others for losses.
 Furthermore, the Advisor Patsy is highly weighted by the A W L validation algorithm.
 After learning tictactoe.
 Patsy's average rank by weight among the Advisors in the second tier was 3 out of 17; after learning lose tictactoe Patsy's average rank was 6.
5 out of 17.
 A W L assesses Patsy to be a valuable Advisor.
 The growth in the weight of Patsy and in the weights of the patternbased Advisors simulates the transition from highlevel reasoning to skill learning.
 With sufficient experience, Hoyle learns only correct as565 n # n ForX X # # # # a # # For P # # a # # a # # For p # # # # # P # # # For p a # P # # # Figure 4: Some learned concepts for tictactoe and lose tictactoe.
 Note that the mover for a concept is in the current state, but the pattern is matched for the subsequent state.
 sociations, ones considered relevant and significant by hum a n experts.
 The first concept in Figure 4, for example, describes control of the center.
 Although it appears to be a simple pattern, it is actually a generalization over a set of persistent patterns.
 The second concept in Figure 4 blocks a potential row of three in its center.
 In addition, concepts are learned which were previously inexpressible in Hoyle's representation.
 A n example of this jqjpears in lose tictactoe where, to play the role of X perfectly, one must move in the location that is the reflection, through the center, of O's last move.
 Such reflection was not previously expressible in Hoyle's useftil knowledge, but is n o w learned as the last pair of draw concepts in Figure 4.
 (Note that, wath symmetry, vertical reflection through the center encompasses horizontal reflection and one diagonal reflection encompasses the other.
) The program experiences the rules of a game only as a set of "black boxes" that return the current state, the legal moves from it, and whether or not a state resuhs in a win, a loss, or a draw.
 Consider, for example, what w e term here confinement, the concept of restricting a five men's morris marker to a comer so that it can no longer slide.
 (Recall that a morris contestant unable to slide loses.
) Confinement, the rightmost concept in Figure 5, is learned by Hoyle on every run.
 The concept of a mill (three markers of the same color on immediately adjacent positions on a hne) was also previously outside the program's knowledge.
 (Hoyle only knows that certain moves permit it to capture, but not why.
) N o w on every run of five men's morris, Hoyle learns the first two concepts in Figure 5 as a pair of Advisors that subgoal on mills.
 W e found that value of patternbased heuristics is confirmed in continued play.
 The reflection Advisors for lose tictactoe and the mill Advisors for five men's morris have weights that remain among the top few in the third tier during learning with A W L .
 Although the reflection Advisors tend to emerge only after 80 or so contests, they typically achieve weights higher than 10 of the 17 secondFor a For a Forp (3>^ )  ^ ##4 )i S'' : c o n f i n e m e n t Figure 5: Some learned concepts for five men's morris.
 Note that the mover for a concept is in the current state, but the pattern is matched for the subsequent state.
 tier Advisors, i.
e.
, learned, gamespecific knowledge proves more powerflil than much of the more general gameindependent knowledge supplied by the other advisors.
 W e note that there is a refuiement of the contents of both the waiting list and pattern memory due to the threshold for a pattern to get into the waiting list, aging in both the waiting list and pattern memory, and the management of both consistent and inconsistent entries.
 Although we did not perform a quantitative study of this memory refuiement process, w e did find that without it performance was degraded.
 This process is ongoing and constantly refines the storage of important patterns with experience.
 Discussion Our work not only integrates pattern learning with highlevel reasoning, it also suggests how the former gradually comes to support and enhance the latter.
 W e do not advocate reliance on patternlearning alone.
 That would ignore the other higherlevel processes quite evident in humans.
 Indeed, Hoyle learns many other kinds of usefiil knowledge detailed elsewhere (Epstein 1992).
 Pattern learning is, however, an important component in skill development, one that those interested in the simulation of human intelligence or the design of adaptive gameplaying programs cannot afford to ignore.
 Each of the patterns Hoyle now learns is a generalization over a class of states that occurs with some flequency and contains a simple configuration of spatiallyrelated markers.
 These patterns occur in the context of a particular stage of the game and are consistently associated with a single outcome.
 A n associative pattern classifier provides learning whose possibly premature guidance is tempered by the higherlevel reasoning of the other Advisors.
 W h e n we force patterns to prove their reliabihty and importance before they can enter the cache, w e reduce the combinatorics that would otherwise confront the generalizer.
 More experienced, conceptbased Advisors gradually emerge to emphasize broader generalities, and are expected to advocate expert play to retain their status.
 Finally, the identification and exclusion of uninformative patterns constrains the pattern generator and thereby focuses the entire process more intelhgently.
 For this initial test w e used simple games and made a number of simplifications in the individual components of the program.
 The Advisor, Patsy, based on individual patterns was placed in the second tier of Hoyle.
 The correct tier assignment for the new Advisors created from patternbased concepts is another subject of current research.
 They were all placed in a third tier for the experiments described here, to avoid interference with a preexisting second tier that already worked quite well.
 To improve computational efficiency, however, and to model the transition to automaticity, the patternbased Advisors should reside in the second tier.
 If they competed in parallel with the other secondtier Advisors, the patternbased Advisors should comment faster and with greater weight in situations where they are applicable, and thereby supplant the others.
 Future work includes more difficult games and other kinds of visual biases for spatial relations (such as center, edge, perimeter, bounded regions, length, and area), and 566 causallybased pattern generation where one or more patterns that give rise to concepts are combined to create new, larger, somewhat less regular patterns.
 W e intend to experiment with other learning algorithms to determine which is best for our application, and to develop and test a suite of generalization rules and metarules to construct concepts from patterns.
 Acknowledgments We acknowledge helpful discussions with Ron Kinchla, PhiUp JohnsonLaird, and Nick Littlestone.
 This work was supported in part by a grant from the James.
 S.
 McDonnell Foundation to the Human Information Processing Group at Princeton University, grant #9423085 from the National Science Foundation, and O N R grant #000149310510.
 References Biswas, G.
, Goldman, S.
, Fisher, D.
, Bhuva, B.
, & Glewwe, G.
 (1995).
 Assessing Design Activity in Complex C M O S Circuit Design.
 In P.
 Nichols, S.
 Chipman, & R.
 Brennan (Ed.
), Cognitively Diagnostic Assessment.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Chase, W.
 G.
, & Simon, H.
 A.
 (1973).
 The Mind's Eye in Chess.
 In W .
 G.
 Chase (Ed), Visual Information Processing.
 New York: Academic Press.
 Cohen, D.
 I.
 A.
 (1972).
 The Solution of a Simple Game.
 Mathematics Magazine, 45{A), 213216.
 de Groot, A.
 (1965).
 Thought and Choice in Chess.
 The Hague: Mouton.
 DeYoe, E.
, & Van Essen, D.
 (1988).
 Concurrent Processing Streams in the Monkey Visual Cortex.
 Trends in Neuroscience, 11, 219226.
 Epstein, S.
 L.
 (1992).
 Prior Knowledge Strengthens Learning to Control Search in Weak Theory Domains.
 IntemationalJoumal of Intelligent Systems, 7, 547586.
 Epstein, S.
 L.
 (1994a).
 For the Right Reasons: The F O R R Architecture for Learning in a Skill Domain.
 Cognitive Science, 18(3), 4195U.
 Epstein, S.
 L.
 (1994b).
 Identifying the Right Reasons: Learning to Filter Decision Makers.
 Proceedings of the AAAI 1994 Fall Symposium on Relevance, (pp.
 6871).
 Palo Alto, CA: AAAI.
 Epstein, S.
 L.
 (1994c).
 Toward an Ideal Trainer.
 Machine Learning, 150), 25\m.
 Fawcett, T.
 E.
, & Utgoff, P.
 E.
 (1991).
 A Hybrid Method for Feature Generation.
 Proceedings of the Eighth International Workshop on Machine Learning (pp.
 137141).
 San Mateo, CA: Morgan Kaufimann.
 Fine, R.
 (1989).
 The Ideas behind the Chess Openings.
 N e w York: Random House.
 Gelfer, I.
 (1991).
 Positional Chess Handbook.
 New York: Macmillan.
 George, & Schaeffer.
 (1991).
 Chunking for Experience.
 In D.
 F.
 Beal (Ed.
), Advances in Computer Chess VI.
 London: Ellis Horwood.
 Grafton, S.
, Hazeltine, E.
, & Ivry, R.
 (In press).
 Locahzation of Independent Cortical Systems in Human Motor Learning.
 Science.
 Hideo, O.
 (1992).
 Good Shape.
 In Opening Theory Made Easy.
 San Jose, CA: Ishi Press.
 Iwamoto, K.
 (1976).
 Go for Beginners.
 N e w York: Random House.
 Kandel, E.
 (1991).
 Chapter 30: Perception of Motion, Depth, and Form.
 In E.
 Kandel, J.
 Schwartz, & T.
 Jessel (EA.
), Principles of Neural Science.
 Amsterdam: Elsevier.
 Lee, K.
 F.
, & Mahajan, S.
 (1990).
 The Development of a World Class Othello Program.
 Artificial Intelligence, '/i(l), 2136.
 Levinson, R.
, & Snyder, R.
 (1991).
 Adaptive PatternOriented Chess.
 Proceedings of the Eighth International Machine Learning Workshop (pp.
 8589).
 San Mateo, CA: Morgan Kaufmann.
 Littlestone, N.
 (1988).
 Learning Quickly when Irrelevant Attributes Abound: A New Linearthreshold Algorithm.
 Machine Learning, 2, 285318.
 Mostow, D.
 J.
 (1983).
 Machine Transformation of Advice into a Heuristic Search Procedure.
 In R.
 S.
 Michalski, J.
 G.
 Carbonell, & T.
 M.
 Mitchell (Ed.
), Machine Learning: An Artificial Intelligence Approach.
 Palo Alto: Tioga Pubhshing.
 Nichelli, P.
, Grafman, J.
, Pietrini, P.
, Alway, D.
, Carton, J.
, & Miletich, R.
 (1994).
 Brain Activity in Chess Playing.
 Nature, 369, \9\.
 Raichle, M.
, Fiez, J.
, Videen, T.
, MacLeod, A.
, Pardo, J.
, Fox, P.
, & Petersen, S.
 (1994).
 PracticeRelated Changes in Human Brain Functional Anatomy during Nonmotor Learning.
 Cerebral Cortex 4, 826.
 Ratterman, M.
 J.
, & Epstein, S.
 L.
 (1995).
 Skilled like a Person: A Comparison of Human and Computer Game Playing.
 Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society, in press.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Samuel, A.
 L.
 (1963).
 Some Studies in Machine Learning Using the Game of Checkers.
 In E.
 A.
 Feigenbaum, & J.
 Feldman (Ed), Computers and Thought.
 N e w York: McGrawHill.
 Simon, H.
 A.
, & Gihnartin, K.
 (1973).
 A Simulation of Memory for Chess Positions.
 Cognitive Psychology, 5, 2946.
 Ungerieider, L.
, & Mishkin, M.
 (1982).
 Two Cortical Visual Systems.
 In D.
 Ingle, M.
 Goodale, & R.
 Mansfield (Ed.
), Analysis of Visual Behavior.
 Cambridge: MIT Press.
 Utgoff, P.
 E.
 (1986).
 Shift of Bias for Inductive Concept Learning.
 In R.
 S.
 Michalski, J.
 G.
 CarboneU, & T.
 M.
 Mitchell (Ed.
), Machine Learning: An Artificial Intelligence Approach Volume II.
 Palo Alto: Tioga Publishing.
 Wallace, J.
, Silberstein, R.
, Bluff, K.
, & Pipingas, A.
 (In press).
 Semantic Transparency, Brain Monitoring and Evaluation of Hybrid Cognitive Architectures.
 Connection Science.
 Yee, R.
 C , Saxena, S.
, Utgoff, P.
 E.
, & Barto, A.
 G.
 (1990).
 Explaining Temporal Differences to Create Usefiil Concepts for Evaluating States.
 Proceedings of the Eighth National Conference on Artificial Intelligence (pp.
 882888).
 Palo Alto, CA: A A A I Press.
 Yoshio.
 (1991).
 All about Thickness.
 Mountain View, CA: Ishi Press.
 567 O n the Roles of Search and Learning in TimeLimited Decision Making Susan L.
 Epstein Department of Computer Science Hunter College and The Graduate School of The City University of New York New York, N Y 10021 epsteinSroz.
hunter.
cuny.
edu Abstract Reported properties of human decisionmaking under time pressure are used to refme a hybrid, hierarchical re;isoner.
 The resultant system is used to explore the relationships among reactivity, heuristic reasoning, situationbased behavior, seiirch, and learning.
 The program first has the opportunity to react correctly.
 If no ready reaction is computed, the reasoner activates a set of timelimited search procedures.
 If any one of them succeeds, it produces a sequence of actions to be executed.
 If they fail to produce a response, the reasoner resorts to collaboration among a set of heuristic rationales.
 A timelimited mazeexploration task is posed where traditional AI techniques fail, but this hybrid reasoner succeeds.
 In a series of experiments, the hybrid is shown to be both effective and efficient.
 The data also show how correct reaction, timelimited search with reactive trigger, heuristic reasoning, and learning each play an important role in problem solving.
 Reactivity is demonstrably enhanced by brief, situationbased, intelligent searches to generate solution fragments.
 1.
 Introduction When confronted with a difficult problem and a limited amount of time to decide upon an action, people employ a variety of devices to make what they hope will be expert decisions.
 S o m e of this behavior is automatic; perceptions about the current state of the world m a y trigger a response without conscious reasoning.
 AI researchers model such automaticity with reactive systems.
 Other portions of this behavior are heuristic; an approximately correct decision rule is selected and applied.
 AI researchers model such "rules of thumb" with rulebased systems.
 There is, however, another important mechanism people use.
 Situationbased behavior is tile serial testing through search of known, triggered techniques for problem solving in a domain.
 This paper describes a cognitive model that integrates situationbased behavior with reactivity, heuristic reasoning, and learning.
 The contribilions of this work are the model and empirical evidence from it tiiat situationbased behavior is an effective method for decisionmaking imder time pressure.
 Situationbased behavior is based upon psychologists' reports about human experts in resourcelimited situations (Klein & Calderwood, 1991).
 For example, an emergency rescue team is called to the scene of an attempted suicide, where a person dangles from a sign after jumping from a highway overpass.
 Time is hmited and the person is semiconscious.
 During debriefing after a successful rescue, the commander of the team describes h o w they immediately secured the semiconscious woman's arms and legs, but then needed to Uft her to safety.
 H e retrieved, instantiated, and mentally tested four devices that could hold her while the team lifted, one device at a time.
 W h e n a device failed in his mental simulation, he ran the next.
 W h e n die fourth scenario ran several times in simulation without an apparent flaw, he began to execute it in the real worid.
 Klein and Calderwood describe the predominance of this situationbased behavior in 32 such incidents, and cite additional evidence from studies of other decisionmakers under time pressure.
 Its key features, for the piu"poses of this discussion, are that a situation triggers a set of procedural responses, not solutions, and that those responses are not tested in parallel.
 The purpose of this paper is not to argue that situationbased behavior is the only way to reason and search, but to explore its role with respect to learning and reactivity and heuristic reasoning under time limitations.
 The next section describes die integration of situationbased behavior into a problem solving and learning model called F O R R .
 Subsequent sections detail the problem domain, describe an implementation for path finding, discuss the experimental results, and relate situationbased behavior to otiier work.
 2.
 FORR: the Model The problem solvers Klein and Calderwood studied did not have the leisure to research similar situations or to explore many ahematives.
 They had to decide quickly.
 Reactive systems are intended to sense the world around them and respond with a quick computation (Brooks, 1991; Maes & Brooks, 1990).
 They iterate a "sensecomputeexecute" loop where the sensing is predetermined and the heuristic computation is either hardwired or extremely rapid.
 In most complex dynamic problems, however, a simulation of intelligence is strengthened by learning.
 In the spirit of reactivity, such learning should be quick to do and easy to apply in subsequent loop iterations.
 The model described in this section supports the development of such a reactive reasoner.
 F O R R (FOr tiie Right Reasons) models the transition from general expertise to specific expertise (Epstein, 1994).
 A FORRbased system begins with a domain of related problem classes, such as board games or mazes, and some domainspecific but problemclassindependent knowledge, such as "do not set the other contestant up for a win" or "avoid deadends.
" With problem solving experience, such as contests played or trips from one maze location to another, a FORRbased program acquires usejul knowledge.
 problemclassspecific data that is potentially usefiil and probably correct.
 Useftil knowledge, such as good game openings or shortcuts in a particular maze from one vicinity to the next, should enhance the performance of a FORRbased system.
 F O R R integrates reactivity, situationbased behavior, and heuristic reasoning in the threetiered hierarchical model 568 shown in Figure 1.
 Tier 1 is reactive and correct, tier 1.
5 is situationbased search, and tier 2 is reactive and heuristic.
 A n i^rfvwor epitomizes a domainspecific but problemclassindependent, decisionmaking rationale, such as "muiimize the other contestant's material" or "get closer to your destination.
" Each Advisor is a "right reason" for decisionmaking in the domain, implemented as a timelimited procedure.
 Input to each Advisor is the current state of the world, the current permissible actions from that state, and any learned useful knowledge about the problem class under consideration.
 Each Advisor outputs any number of comments that support or discourage permissible actions.
 A comment lists the Advisor's name, the action commented upon, and a strength, an integer from 0 to 10 that measures die intensity and direction of the Advisor's opinion.
 F O R R addresses a problem as a sequence of decisions to be made.
 At decisionmaking time, a FORRbased system senses the current state of the world and reacts with a rapidlycomputed decision.
 The calculation for that decision begins in the first tier, where Advisors are consulted in a predetermined, fixed order.
 They may have the authority to make a decision unilaterally or to eliminate a legal action from any ftulher consideration.
 Firsttier Advisors are reactive, consulted in sequence, and reference only correct useftjl knowledge.
 They "sense" the current state of the world and what they know about the problem class; if they make a decision, it is fast and correct.
 The commander had a firsttier Advisor which insisted that the victim's hmbs be secured.
 A good firsttier Advisor for game playing is "if you see a winning move, take it;" a good one for mazetraversing is "if you see the goal, go to it.
" Only when the first tier of a FORRbased system fails to make a decision does control default to the next tier.
 Secondtier Advisors, in contrast, are not necessarily independent, or even correct in the full context of the state space.
 Each of them epitomizes a heuristic, specialized view of reahty that is a reasonable argument for or against one or more actions.
 Secondtier Advisors are reactive too, but far less trustworthy, because neither theu reasoning process nor the useful knowledge on which they rely is guaranteed correct.
 All the secondtier Advisors have an opportunity to comment before any decision is made.
 The decision they compute is the action with the highest total strength; this represents a consensus of their opinions.
 A good secondtier Advisor for game playing is "maximize the number of your pieces on the board and minimize those of the other contestant;" a good one for mazetraversing is "move in the direction of the goal.
" There is evidence in the literature that people approach complex tasks as if they had such Advisors (Biswas, Goldman, Fisher, Bhuva, & Glewwe, 1995; Ratterman & Epstein, 1995), but for the rescue situation, secondtier Advisors may be too slow and too risky.
 Situationbased behavior has recently been incorporated into F O R R with tier 1.
5.
 A tier1.
5 Advisor temporarily digresses from the "sensecomputeexecute" loop when it recognizes a situation in which its knowledge may have substantial impact.
 Each tier1.
5 Advisor has a reactive trigger to recognize that the current situation may benefit from its solution method, just as the need to hoist was a trigger for each of the rescue team's holding devices.
 Each also has a acquired useful knowledge current state 1 Tier 1: Reaction from perfect krtowledge legal actions Tier 1.
5: Search and Inference triggered by situation recognition Tier 2: Heuristic reactions execute Decision? decision Ak+1 Decision? Am+ 1 Am+2 Voting Figure 1: H o w F O R R makes decisions.
 knowledgeintensive, highlyconstrained search procedure to construct a solution fragment, a sequence of decisions rather than a single reactive one.
 If the first tier has failed to make a decision, each of the prioritized Advisors of tier 1.
5 has the opportunity in turn to trigger, and each triggered Advisor is ceded control until one of them produces a solution fragment.
 Tier1.
5 Advisors execute decisions in the actual problem space as they attempt to construct a solution fragment.
 Regardless of its outcome, the fnst retiuned solution fragment is incorporated into the sdution under construction, and control is returned to tier 1.
 If no tier1.
5 Advisor produces a sequence of recommended steps, the second tier will make the decision.
 The effectiveness of situationbased Advisors and their role in reasoning is best demonstrated with an example.
 3.
 Ariadne: an Implementation Ariadne is a FORRbased system for simulated robot pathfinding.
 (Ariadne, daughter of King Minos, helped Theseus find his way through the labyrinth.
) Ariadne models learning the way around a complex geographic area through a series of trips there.
 A problem class for Ariadne is a particular maze, and learning occurs as a result of repeated path fmding in the same maze.
 Ariadne's task is to move a robot from some initial location to the stationary goal in a sequence of legal moves.
 The robot, however, is severely restricted.
 It has no explicit map and it is not permitted to construct one.
 It senses where it is and where it can go in one step, decides which step to take, and "leaps" there without collecting data on the way.
 A state in Ariadne is a maze containing the robot and the 569 goal.
 Figure 2 represents a sample state in a 20 x 20 rectangular grid with discrete internal obstructions.
 A location (r, c) in a maze is the position in the rth row and cth column, addressed as if it were an array.
 The robot is at (18, 6) and the goal at (5, 14) in Figure 2.
 At any instant in time, the state of the world is described to Ariadne as the dimensions of the maze, the coordinates of the goal, the robot's coordinates, the path it has thus far traversed, and how far the robot can "see" in four directions to the nearest obstruction or to the goal.
 At each step the robot is permitted to move through any number of unobstructed locations in one (north, south, east, or west) direction.
 The robot in Figure 2 has 8 legal moves: north to (17, 6), east to (18, 7), (18, 8), (18,9), and (18, 10), south to (19, 6) and (20,6), and west to (18, 5).
 A problem in Ariadne is an initial location R for the robot and a location G for the goal.
 A problem is solvable if and only if there exists some path, consisting only of legal moves, fix)m R to G, i.
e.
, through only unobstructed locations.
 The level of difficulty of a solvable problem is one more than the minimum number of (left or right) turns the robot must make to reach the goal.
 Note that this is different from the Manhattan distance (as measured in grid units) from the robot to the goal.
 Figure 2 is a level 11 problem; one solution for it has Manhattan distance 29.
 It is important to note that the robot is not given, and does not construct, an explicit, detailed m a p of the maze.
 Ariadne does, however, learn descriptive abstractions about the maze as useful knowledge: gates, deadends, and chambers.
 A gate is a location that offers a transition from one quadrant of the maze to another, for example, (11, 3) is a gate between quadrants 3 and 2 in Figure 2.
 O f course, a gate may not always be helpful; (11, 3) offers access to little of quadrant 2.
 After each decision, Ariadne tests whether its last move has changed its quadrant, that is, if it has moved through a gate.
 If so, the robot's current location is learned as a gate between the current quadrant and the previous one.
 A corridor is a passageway of width one that either leads nowhere (a deadend) or is a hallway.
 In Figure 2 {(14, 1), (15, 1), (16, 1)} is a deadend and {(5, 15), (5, 16), (6, 16), (6, 17)} is a hallway that zigzags.
 A corridor is learned as a pair of endpoints when, from the current state, the robot has only one or two moves.
 Corridors are enlarged and merged together as necessary.
 A chamber is an irregularly shaped space with an access point and an approximate extent, the furthest in each direction one can go in the chamber.
 This is a compact, heuristic description that at worst overstates the chamber by a bounding rectangle.
 Figure 2's robot is in a chamber with access point (16, 5) and extent 16 north, 10 east, 20 south, and 4 west.
 The access point of a chamber is a location within the chamber that affords a view outside it.
 For example, from (16, 5) the robot can see east beyond its extent to (16, 3).
 All locations reachable from the robot really constitute one large chamber, but the chambers that Ariadne learns are more limited and roomlike.
 When Ariadne is not making good progress and the decision cycle reaches tier 1.
5, an Advisor may call a search procedure that scans vertically and horizontally from the robot's current position to estimate the extent of the current chamber.
 A chamber is represented as an extentaccesspoint pair and stored on a Ust.
 A new chamber may subsume an old one, in Quadrant 2 Quadrant 1 I 2 3 4 5 6 7 S 0 10 II 12 13 MIS 16 17 18 1920 2 3 4 S b / a 9 10 II 12 13 MIS 16 17 18 1920 Quadrant 3 Quadrant 4 Figure 2: An Ariadne problem.
 The robot must move to the goal in unidirectional steps through unobstructed locations.
 which case it replaces it on the list.
 Otherwise, chambers are not merged, and they may overlap or have more than one access point.
 Ariadne has 17 Advisors, listed in Table 1, with tiers 1 and 1.
5 in order of their relative priority.
 Descriptions of the triggers for the tier1.
5 Advisors are italicized.
 For example, Roundabout triggers when the robot is in the same row or column as the goal but it cannot see it because of an obstruction.
 Roundabout attempts to shift over and then go around the wall between it and the goal.
 If, for example, the robot of Figure 2 were at (5, 18), Roundabout would take it to (6, 18), (6, 17), and (6, 16) before stopping at (5, 16) where the goal is in sight.
 Note that Roundabout, like any tier1.
5 Advisor, is timelimited and heuristic.
 It may fail, or it may only get closer to the goal than it had been, without actually bringing the goal in sight.
 Ariadne's tier2 Advisors embody pathfinding commonsense and do no forward search at all in the problem space.
 Chamberlain, for example, encourages moves to the entry point of a deadend or a chamber whose extent indicates that the goal might lie within, and discourages moves to any other entry points.
 (Although Chamberlain's comments are based upon heuristic extents, it never permanently prevents a solution, because the other Advisors may eventually override it with their own comments.
) Note that Chamberlain, unlike Outta Here, is not permitted to search.
 The simple ideas behind the tier2 Advisors support rapid computation.
 F O R R signals (but continues to calculate) if any Advisor runs out of time, and that has yet to happen with Ariadne.
 Ariadne is implemented as a set of C o m m o n Lisp routines that run with F O R R .
 To create a problem class, the user specifies the dimensions of the maze, the level of problem difficulty, and the percentage of internal obstruction.
 Further technical details are available in (Epstein, 1995).
 570 Table 1: Ariadne's Advisors for path finding.
 Starred Advisors reference useful knowledge.
 N a m e Description Tierl N o Way* D o not enter a goalfree deadend.
 Victory Move to the goal if it is in sight.
 Tier 1.
5 Roundabout M o v e around the wall if already in the right row or column.
 Outta Here* Exit a goalfree deadend or chamber or a small geographical area.
 Probe* Exit a chamber if recently locally constrained.
 SuperQuadro* Exit a quadrant if recently locally constrained.
 Wander Take very large steps Lshaped steps if recently locally constrained.
 Tier 2 Been There Avoid return to a previous location.
 Chamberlain* Avoid or encourage entrances to deadends and chambers based upon their extent.
 Done That Avoid repetition of a move in the same direction as one aheady taken from a previous location.
 Giant Step Make the longest possible move in some direction.
 Goal R o w Move to the same row as the goal.
 Goal Column Move to the same column as the goal.
 Mr.
 Rogers Move as close to the goal as possible.
 Opening* Begin the way a previous successful path did.
 Plod Move one location in some direction.
 Quadro* Move from one quadrant to another through known gates.
 4.
 Experimental Results The performance of six reasoning agents was tested: the full version of Ariadne and five ablated versions that measure the contribution of Ariadne's various components.
 The Random agent selects random legal moves; this is equivalent to bhnd search.
 The Reactive agent leams, but uses only the Advisors in tier 1; it simulates correct reactive response.
 The Reactive+ agent leams, but uses only the Advisors in tiers 1 and 1.
5; it simulates reactive decision making with situationbased behavior but without heuristic reasoning.
 The ReactiveHeuristic agent leams, but uses only the Advisors in tiers 1 and 2; it simulates reactive decision making without situationbased behavior.
 NoLearning includes only the Advisors in any tier that do not consult learned useful knowledge (those starred in Table 1).
 The F O R R agent uses all the Advisors in Table 1; this simulates reactive decision making and learning with situationbased behavior.
 Agents were eliminated from testing after poor performance.
 During early trials the Random agent, solved only 1 2 % of 100 level 6 problems; it therefore served merely as a benchmark, A run for a fixed, randomlygenerated maze is 10 learning problems given to the ftill version of Ariadne, followed by 5 newlygenerated testing problems in the same maze given to the agents with learning turned off.
 A problem of either kind was terminated when the agent reached the goal or when it had made 100 passes through Figure 1.
 Learning problems were provided only to establish a useful knowledge base for those Advisors that depend upon it.
 (Those Advisors are starred in Table 1.
) Because F O R R is nondeterministic and the mazes and problems are generated at random within the specified constraints, results from 10 runs were averaged to produce an experiment.
 A n experiment was performed for problems with levels of difficulty 6, 8, 10, and 12 in a 20 X 20 maze with 3 0 % intemal obstruction.
 These parameters were selected to provide at least 1000 possible problems at the specified level of difficulty.
 Any agent that performed badly was omitted fiom more difficult exp)eriments.
 Table 2 reports the results.
 "Solved" is the percentage of the test problems the agent could solve with at most 100 moves in the same maze.
 "Path length" is the Manhattan distance along the solution to the goal.
 Since a step may move through more than one location, path length varies among problems of the same difficulty.
 "Moves" is the number of moves in the solution.
 The number of distinct locations actually visited during those moves is reported as "locations.
" "Triggers" measures the reliance of the system on tier 1.
5; it is the number of passes through Figure 1 during which any situationbased Advisor executed.
 Path length, moves, and locations are computed only over solved problems.
 (This makes the ablated agents look somewhat better than they actually are.
) " B F S % " is the percentage of the space reachable from the robot's initial position that breadthfirst search would have visited on the same test problems.
 Time pressure can be apphed to a solution two ways: either as the path length (since computation time would be much faster than travel time), or as the number of passes through Figure 1 (based pwely on confutation time).
 As the problems become more difficuh, the ability of the ablated agents to solve the problems becomes markedly inferior, and the situationbased Advisors trigger more often.
 The ReactiveHeuristic agent, FORR's original formulation, draws the robot to fewer locations and constructs shorter paths than Reactive+ on the simpler problems, but solves fewer difficult ones.
 Although situationbased Advisors make some contribution when combined with tier 1, Reactive+ is clearly inadequate on the more difficult problems.
 The situationbased Advisors trigger more often with Reactive+ than with the full F O R R agent because most of them recognize repetitive action, and Reactive+ frequently behaves repetitively.
 TTie full F O R R agent is clearly more powerful than the ablated ones.
 F O R R with tier1.
5 offers a measure of reliability and achievement the other versions lack.
 The number of successes by the full F O R R agent represents a statistically significant improvement over the others.
 Although this work was predicated on the acceptability of suboptimal solutions, the successfiil paths of the ablated agents are extremely long.
 With all of FORR's tiers in place, Ariadne gets the robot to the goal more often, more quickly, and considers fewer alternatives along the way.
 571 Table 2: Average testing performance of agents after learning in 10 randomly generated 20 x 20 mazes.
 Search terminated upon solution or after 100 decisions.
 Level Agent Solved Path Length Moves Locations Triggers B F S % Reactive Reactive+ ReactiveHeuristic FORK 24% 96% 90% 98% 156.
2 61.
2 48.
2 29.
7 52.
0 28.
0 23.
5 19.
2 29.
8 22.
0 16.
1 15.
8 — 13.
3 — 5.
5 66.
1% 8 10 12 Reactive+ ReactiveHeuristic FORR Reactive+ ReactiveHeuristic FORR Reactive+ FORR 86% 88% 96% 80% 66% 86% 64% 80% 79.
7 93.
3 45.
5 105.
3 122.
0 60,6 118.
0 69.
4 37.
4 37.
5 28.
5 50.
4 54.
3 38.
3 53.
0 41.
8 29.
1 23.
7 24.
3 37.
8 33.
0 28.
5 41.
2 31.
7 17.
7 9.
9 19.
7 14.
8 29.
9 25.
7 87.
4% 95.
2% 96.
2% 5.
 Search a n d L e a r n i n g This domain is not amenable to traditional AI search techniques.
 Depthfirst search requires elaborate backtracking and loop prevention to calculate any solution; very few, if any, of the test problems would be solvable in 100 steps this way.
 Breadthfirst search, while it will always solve the proWem, does so at the cost of visiting a high proportion of the nodes ever accessible to the robot fiom its starting location in the search space.
 AI searches are often steered by an evaluation function toward the "most promising" locations to avoid such difficulties.
 The robot's knowledge is so limited, however, that an evaluation function would have all the shortcomings of the ReactiveHeuristic agent.
 For example, closer to the goal is not necessarily better; there may be a very long wall there.
 Meansends analysis, another standard AI technique, is not possible because the robot knows little, if anything at all, about the immediate vicinity of the goal.
 For a very large maze, then, exphcit search would be extremely inefficient, perhaps intractable.
 There is a complex relationship among the tiers.
 Tier 1.
5 requires both tier I's commonsense and tier 2's heuristic knowledge to be effective.
 Tier 2 tries to avoid search and effectively sets up the situationbased Advisors in tier 1.
5 so that they can trigger.
 For example.
 Goal R o w and Goal Colu m n push the robot into a situation where Roundabout can trigger.
 In turn, the situationbased Advisors of tier 1.
5 set up the heuristic reasoners in tier 2.
 For example, Wander puts the robot where all the tier2 Advisors are more likely to make new, constructive comments.
 W h e n Ariadne bogs down, the triggers of the tier 1.
5 Advisors behave like a search party; they expend resources to improve the program's ability to make progress.
 The usefiil knowledge acquired this way is not overwhelming.
 Ariadne averaged only 30.
5 corridors and 10.
8 chambers in its level 12 problems.
 The initial impulse behind reactive programming was to avoid search.
 W h e n one augments the reactive Advisors of tier 1 and tier 2 with tier 1.
5, the system is kept within the search minimization philosophy two ways.
 First, F O R R only allocates each Advisor, in any tier, a limited amount of computing time.
 Therefore solution fiagments that take too long to construct are not considered.
 Second, tier1.
5 Advisors have handcoded routines intended to address their particular subgoals.
 These routines generate and test solution fiagments, just the way the conunander did, but the proposed partial solutions must be highly constrained, just as the commander's are.
 This constraint saves the tier1.
5 Advisor from a combinatoric explosion.
 Although their search can be quite deep, they are effective because they are severely curtailed by knowledge.
 A n important difference between F O R R with tier 1.
5 and the commander is the fact that he ran his successftil simulation four times before he implemented it.
 Comparing moves and locations in Table 2, it is clear that Ariadne could shorten its path lengths by as much as 2 5 % if it removed the loops.
 With respect to timing, however, the robot visited those locations, so the entire path is still the cost.
 The role of learning in this domain becomes apparent only in the most difficult problems.
 In another series of experiments w e tested the fiill F O R R agent against NoLearning.
 By level 10, NoLearning solved 2 0 % fewer problems and triggered tier 1.
5 three times as often.
 There were mazes (runs) where NoLearning could solve all five level10 problems (albeit in slightly longer paths) without learned useful knowledge, but in two mazes it could solve only two.
 The paths NoLearning finds in hard problems look like a fhght of steps.
 NoLearning fails on problems where the goal is hidden behind or the robot begins behind a variety of deceptive barriers.
 Even when NoLeaniing could solve a hard problem, the solutions with learning were shorter, less repetitive, and required fewer decision cycles.
 Ariadne has already performed well on preliminary tests in 30 X 30 mazes and continues to improve as we refine its Advisors and its learning algorithms.
 There is every reason to believe that Ariadne will continue to scale up, i.
e.
, perform well in much larger and more tortuous mazes than these.
 Hoyle, a FORRbased gamelearning program, progressed to much larger spaces after the addition of only a few tier2 Advisors (Epstein, 1994).
 572 6.
 Related W o r k Situationbased behavior is not casebased reasoning (CBR), although they have much in common.
 In CBR, experiences are indexed and stored.
 Later, when a problem arises, one or more potentially relevant cases that "remind" the system of the current one are retrieved, and an attempt is made to modify their solutions to solve the current problem (Kolodner, 1993).
 Although situationbased behavior is triggered by an abstraction of the current state that could have been used as an index for CBR, situationbased behavior does not retrieve specific solutions to be modified, only procedures intended to generate solution firagments.
 Situationbased behavior and C B R both constrain solution generation, but C B R does it by searching from old solutions, while situationbased behavior does it by the knowledge inherent in its procedures.
 Klein and Calderwood emphasize that the human experts they study do not perceive their problem solving as reminding.
 This is not a claim that C B R has no parallel in people, only that it is less likely to be used under time pressure.
 Situationbased behavior is not planning either.
 A plan is a set of actions intended to reach a specific goal.
 The commander tested holding devices by incorporating them into plans and mentally executing those plans until one promised success.
 The situationbased Advisors of tier 1.
5 are not planners because they actually execute their behavior, even if they do not eventually recommend it.
 For example, Wander can investigate as many as eight L's (by moving one longest step in each direction and then testing for possible second steps) before it chooses one to execute.
 Rather than planners, situationbased Advisors are procedures that reactively seize control of a FORRbased program's resources for a fixed period of time.
 When that time elapses the situationbased Advisor either returns control to tier 2 or returns a sequence of actions whose execution it requires.
 Tier 2 constitutes a reactive decision maker, much like Pengi (Agre & Chapman, 1990).
 The principal difference is that Pengi's problem is hving in its world; it is not held to an explicit decision standard Uke Ariadne's "solve in 100 decision steps.
" Nor is situationbased behavior a macrooperator.
 A macrooperator is a generalization across the variables entailed in a successful procedure, whereas a situationbased Advisor is a procedural generahzation over several kinds of behavior appropriate to a situation.
 Situationbased behavior is a resourcegrabbing heuristic digression intended to produce a solution fiagment.
 Situationbased behavior does shed some light on the debate about representation and reactivity (Hayes, Ford, & Agnew, 1994).
 For Ariadne conceptual knowledge includes situationbased triggers like "the last 3 0 % of the moves have been in no more than 5 % of the locations in the maze" and "a wall lies between the aligned robot and the goal.
" This work demonstrates that, at least in this domain, the representation of conceptual knowledge is an essential component in a reactive learner.
 7.
 Conclusions Ariadne succeeds on timelimited decision problems where traditional AI techniques fail.
 Ablation indicates that no single component of the hybrid reasoner is responsible for its success; there is a synergy among them.
 The program is robust; it can learn in any maze without "tuning.
" The thesis of this work is that severely constrained search, particulariy when enhanced by learning, can play an important role in the performance of an otherwise reactive and heuristic system.
 Situationbased behavior is modeled on people who produce suboptimal solutions under time constraints.
 A reactive system goes directly firom perception to an associated action, without any opportunity to reason about the state.
 With tier 1.
5, FORK, like Klein and Calderwood's subjects, perceives and then reasons about the current state of the world before it elicits an associated action, but still maintains some of the advantages of reactivity.
 Ariadne's success at maze search is a clear indication that resource allocation to highlyrestricted, intelligent search is an important facet in the simulation of efficient, effective learning and decision making under resource limitations.
 Ackno wledgm ents Jack Gelfand originally formulated a somewhat different Ariadne problem, and continued to ask constructive questions as this research evolved.
 David Sullivan's preliminary work on Tonka convinced us that a FORRbased version of Ariadne could be a success.
 Rich Korf, Jim Hendler, and Rich Sutton offered helpful comments.
 References Agre, P.
E.
, & Chapman, D.
 (1990).
 What are Plans for? Robotics and Autonomous Systems, 6, 1734.
 Biswas, G.
, Goldman, S.
, Fisher, D.
, Bhuva, B.
, & Glewwe, G.
 (1995).
 Assessing Design Activity in Complex C M O S Circuit Design.
 In P.
 Nichols, S.
 Chipman, & R.
 Brennan (Ed.
), Cognitively Diagnostic Assessment.
 Hillsdale, NJ: Lawrence Erlbaum.
 Brooks, R.
A.
 (1991).
 Intelligence without Representation.
 Artificial Intelligence, ̂ 7(13), 139160.
 Epstein, S.
L.
 (1994), For the Right Reasons: The F O R K Architecture for Learning in a Skill Domain.
 Cognitive Science,! 80), A195n.
 Epstein, S.
L.
 (1995).
 O n Heuristic Reasoning, Reactivity, and Search.
 Proceedings of IJCAI95 (in press).
 San Mateo: Morgan Kauftnann.
 Hayes, P.
J.
, Ford, K M .
 , & Agnew, N.
 (1994).
 O n Babies and Bathwater: A Cautionary Tale.
 AI Magazine, 75(4), 1526.
 Klein, G.
A.
, & Calderwood, R.
 (1991).
 Decision Models: Some Lessons from the Field.
 IEEE Transactions on Systems, Man, and Cybernetics, 21(5), 10181026.
 Kolodner, J.
L.
 (1993).
 Introduction to the Special Issue on CaseBased Reasoning.
 Machine Learning, 10(2), 15.
 Maes, P.
, & Brooks, R.
A.
 (1990).
 Learning to Coordinate Behaviors.
 Proceedings of the Eighth National Conference on Artificial Intelligence (pp.
 796802).
 Palo Aho, CA: A A A I Press.
 Ratterman, M.
J.
, & Epstein, S.
L.
 (1995).
 Skilled like a Person: A Comparison of Himian and Computer Game Playing.
 Proceedings of the Seventeenth Annual Conference of the Cognitive Science Society (in press).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 573 Discourse Processing in Situated Cognition: Learning through Tutorial Dialogue in Complex Domains Carl H.
 Frederiksen, Marguerite Roy, and Denis Bedard' Laboratory of Applied Cognitive Science McGill University Montreal, Quebec.
 Canada H 3 A 1Y2 e d 7 6 @ m u s i c a .
 m c g i l l .
 c a Abstract This study set out to apply a model of situated discourse to analyze tutorial dialogue in a complex welldefined domain of problem solving in engineering.
 One tutor met individually with three students to teach them to solve shear force and bending moments problems.
 The participants' discourse and actions were analyzed according to a situated discourse model.
 Quantitative analyses of the tutorial dialogue affirmed that the constraints on situated discourse processing identified in the model predicted the propositional content and conversational functions of utterances produced by both the tutor and the students.
 Qualitative analysis of the conceptual content of the tutor's dialogue for Problem 1 revealed several distinct types of situation models that constituted the meaning associated with the situated discourse and action.
 The students initially (Problem 1) received this information, their participation consisting mostly of observing, and participating in lowlevel algebraic procedures with tutorial guidance.
 Students' problem solving and dialogue on subsequent problems (2 and 3) displayed their ability to solve problems with some tutorial assistance.
 These results demonstrate that analysis of tutorial dialogue from the standpoint of cognitive models of discourse processing can provide detailed information about the conceptual situation models involved, and the cognitive processes used by the participants.
 Introduction There has been growing acceptance of a constructivist view of learning (i.
e.
, learning as situated cognition) in which contextual and social processes support shared cognition and learning in natural situations or domains of knowledge and activity (Resnick, Levine, & Teasley, 1991).
 This view has been used to advocate particular models of instruction such as cognitive apprenticeship (Brown, Collins & Duguid, 1989), and has prompted theoretical debate over the relationship of conceptual knowledge, symbolic information processing, and learning, to the social and situational contexts in which they occur (Vera & Simon, 1993).
 However, despite the recognition that situations play an important role in shaping cognition, w e lack studies that explicitly link characteristics of situations to the cognitive processes and learning outcomes of participants within these situations.
 Sociolinguistic studies of language use within natural social contexts of learning and instruction have established that conversational discourse plays a central role in facilitating cooperative activity and learning within natural learning situations.
 In addition to its social functions as a medium for interaction, communication, and cooperation, conversational discourse is also a principal medium through which students' acquire new knowledge and learn to apply their knowledge in practical situations of cognitive activity (Lemke, 1990).
 In addition, recent studies have investigated how discourse interaction in instructional situations supports students' knowledge construction and development of competence in particular, welldefined subjectmatter domains in mathematics and science (Fox, 1993; Greeno, 1991; Leinhardt, 1993; Schoenfeld, Smith, & Arcavi, 1993).
 However, despite the recognition that situations and language play key roles in shaping knowledge, cognition, and learning, few studies have attempted to systematically examine the cognitive processes and representations that underlie discourse interaction and learning from naturallanguage discourse in authentic instructional situations.
 Studies of the cognitive processes involved in learning through conversational discourse, therefore, ought to lead to more precise models of the processes involved in situated learning and cognition.
 In the present study, existing models of the cognitive representation and processing of text and discourse were applied to study the cognitive processes and representations involved in discourse interaction within a complex instructional situation and domain (Frederiksen, 1986; Frederiksen & Breuleux, 1990; Frederiksen & Donin, 1991; van Dijk & Kintsch, 1983).
 A "situated discourse model" was developed to extend current discourse processing theory to model discourse interaction (i.
e.
, tutorial dialogue) within a specific tutorial situation in a welldefined, knowledgerich domain of problem solving in engineering.
 This model identified specific classes of constraints on tutorial dialogue which were tested in the present study.
 The model also provided a theoretical framework for analyzing the conceptual and semantic (propositional) content and conversational structure of the tutor's and the students' discourse interaction and their relationship to concurrent problemsolving behavior.
 Using cognitive models of discourse analysis, w e studied the conceptual "situation models" (i.
e.
, proposifional structures, conceptual networks, and procedure frame representations) that the tutor and students displayed through their conversational discourse over the course of a tutoring session.
 B y analyzing the characteris'Now at Universite de Sherbrooke, Departement d'education specialisee, Sherbrooke, Q C , Canada, JIK 2R1.
 574 mailto:ed76@musica.
mcgill.
caINTEGRATED DECLARATIVE AND PROCEDURAL KNOWLEDGE I SCRIPTS, PLANS & EXPECTATIONS Macrostructure Constraints SCRIPTS, PLANS & EXPECTATIONS i SButllon Mod.
l X X IMTC5RATEP DECL̂ R̂ATIVE AND PROCEDURAL KNOWLEDGE tics of these representations, w e were able to investigate h o w situation models define and make public the knowledge that students need to become proficient in the domain, how situation models displayed through tutorial dialogue within a problemsolving context support students' comprehension and learning, and h o w the tutor used the conversational interaction to support students' problemsolving and reasoning.
 The Situated Discourse Model Our analysis of discourse processing within tutorial situations was guided by the situated discourse model (Figure 1).
 Consistent with sociolinguistic research on tutorial dialogue, participants are seen as interacting through discourse which they coconstruct through their conversational interaction.
 This interaction occurs in a "transaction space" that includes the participants' concurrent actions (e.
g.
, in solving the problem) and any external knowledge representations (e.
g.
, diagrams, equations, or graphs written on a "blackboard" workspace).
 At any time, the tutorial dialogue reflects these actions and external representations, as well as the tutor's and the student's knowledge, their cognitive processes in applying their knowledge to understand and solve problems, and their pedagogical or learning strategies.
 This entire process is embedded within a social context which structures the tutorial interaction.
 This includes a participation structure (that reflects each participant's perception of his or her role or identity as a student or tutor and how these perceptions govern participants' relationships to oneanother and the nature of their participation in the learning situation); and the social organization of the tutoring situation itself, that is, the norms or expectations participants have about their patterns of social interaction and participation within a tutoring situation.
 Although we recognize that the social context is an important aspect of any learning situation, the primary focus of the present study was on the question of how situated discourse supports students' learning in a particular subjectmatter domain within a tutorial learning situation that is relatively typical of those that occur in science and engineering at the University level.
 Our model views the structure of a tutorial dialogue (including its sequential and topical organization and the form, propositional content, and conversational functions of individual utterances) as a reflection of processes of shuated_conversational inference that enable the participants to construct and update conversational frames (Gumperz, 1992; Tannen, 1993), that is, conceptual situation models (van Dijk & Kintsch, 1983), on a momenttomoment basis.
 Participants' situation models at any point Tutor PROBLEM SOLVING ACTIVITY PEDAGOGICAL STRATEGIES V X Slliî lon UoiM I I ^ ^ ^ X /Discourse ) BlacKboard Representations ^ ^ Transactions in Learning Environment 1.
.
.
.
I ± = t PROBLEM SOLVING ACTIVITY ^ ^ T ^ LEARNING STRATEGIES Student Figure 1: The situated discourse model.
 in the tutorial interaction reflect cognitive, situational, and macrostructure constraints.
 Cognitive constraints include the participants' current domain knowledge, their cognitive activities in using their knowledge to perform tasks within the learning situation (e.
g.
, reason or solve problems), and their preferred strategies for learning or tutoring.
 Situational constraints include the local discourse context, and any external representations or overt actions that occur within the learning situation.
 The situation models that a tutor constructs for a student and displays through his or her discourse and actions define a meaningful context within which the student can construct his or her o w n situation models, and these provide the basis for learning and transfer to new problemsolving situations.
 Finally, the conversational discourse reflects macrostructure constraints governing the participants' communication and activity within the situation, including scripts or expectations concerning the social organization of the tutoring session, and plans for organizing problemsolving activity and use of subjectmatter knowledge topically or sequentially within the interactive learning situation.
 This model predicts that the structure of interactive situated discourse will reflect the following constraints: (a) the declarative and procedural knowledge of the tutor and student; (b) concurrent cognitive activity of the tutor and student; (c) pedagogical strategies used by the tutor, and learning strategies used by the student; (d) external representations produced or manipulated in the workspace; macrostructure constraints such as (e) the tutor's script for the session and (f) the tutor's instructional plan ; the discourse microstructure including (g) local patterns of conversational speech acts and (h) local propositional inferences that are based on the content of speakers' prior utterances; and (i) highlevel tutoring strategies (e.
g.
, "modeling and explanation", or "coaching and evaluation") that are reflected in particular patterns of local pedagogical strategies.
 These predictions were tested in the present study.
 575 M e t h o d Subjects One experienced tutor and three students participated in this study.
 The tutor was a postdoctoral fellow from a department of civil engineering where she tutors undergraduate students in how to solve shear force and bending moments problems.
 Student 1 (novice) was about to enter an undergraduate engineering program.
 She had no prior experience with this class of problems, although, she did posses the prerequisite physics background.
 Student 2 (experienced) had just completed his first year in an engineering undergraduate program that included a course inwhich shear force and bending moments problems were taught.
 Student 3 (intermediate) was also an undergraduate student who had completed his first year in a related field, but had no prior experience with these problems.
 Procedure The experimental session consisted of an apprenticeship learning situation in which each student met individually with the tutor for the purpose of learning to solve and reason about shear force and bending moments problems.
 Each student was taught using an identical sequence of three problems which increased in complexity.
 These problems were selected by the tutor.
 While the traditional approach to teaching shear force and bending moments problems focuses on a purely algebraic solution method, the tutor's objective for this study was to teach students a more qualitative approach.
 Solving these problems required constructing a series of external representations (on the blackboard): (1) drawing a beam with all of its supports and loads, (2) drawing a more abstract "free body diagram" depicting all forces acting on the beam, (3) determining the values of reactions to loads on the beam, and (4) determining and graphing the shear forces and bending moments that maintain equilibrium at each point on the beam.
 These areconstructed by applying a general procedure (which is to be learned) and by reasoning from knowledge of relevant principles of physics (statics).
 All sessions were videotaped and a record of all notations generated on the "blackboard" (actually a large pad on an easel) was kept.
 In addition, a copy of the tutor's lesson plan was obtained before the tutoring session.
 Development of a Procedure F r a m e A procedure frame describing the various steps used to solve shear force and bending moments problems was developed and evaluated in a previous study.
 This frame represents a declarative model of the procedure (called the "procedure frame") in which nodes represent procedures and links relate procedures in terms of decomposition into and disjunctive choice of subprocedures, and conditional and temporal order constraints on their execution (Figure 2).
 Transcription and Coding of Data All discourse that occurred in the tutorial sessions was transcribed and divided into conversational turns and main clause segments.
 Successive representations generated on the blackboard were transcribed into graphics on cards in a HyperCard stack, and each card was crossreferenced to discourse segments that accompanied its blackboard representation.
 Segments were coded in terms of response categories that correspond to the main constraints on the production of discourse identified in the situated discourse model (Figure 1).
 First, to analyze the conversational structure, a modified version of Dore's (1980) coding system was used to classify each discourse segment into a type of conversational act (Cact) {assertions, requests, performatives, and organizational devices).
 Percents of segments initiated by the tutor were obtained.
 Second, to study the participants' use of procedural knowledge to control the content of their discourse, the tutor's and the student's discourse segments (together with concurrent actions on the blackboard) were matched to nodes (i.
e.
, subprocedures) in the procedure frame.
 These were also classified by: (a) the level of the subprocedure in the decomposition hierarchy, (b) the semantic fields that were used to describe each subprocedure {act, goal, initial state, situation, conditions, instrument, result, or evaluation of results), and (c) concurrent problemsolving activities that accompanied the discourse segm e n t (planning, testing, evaluating, interpreting, executing, or explaining).
 Third, the tutors discourse segments were coded according to type of pedagogical strategy e m ployed {instruction, demonstration, explanation, comprehension check, hint, evaluation, question).
 Finally, the tutor's instructional plan w a s studied by analyzing the sequence of subprocdures identified in her plan and used in the session.
 Discourse "fields" consisting of sequences of thematicallyrelated discourse segments were identified.
 ProposiProc 1.
0 Diamine forces c* eoch point within astdicloaded becm Proc2 0 Drew becm wit h supports & bods Proc2.
1 Construct free body dicgrcm (FBD) Proc2.
2 Dd amine reactions •JMZProc2.
3 Determine forces wlttiin t tie becm d Gocti point X Proc3,8 Represent shea force c* eocti point x ^ ^ ^ o n b e o T ^ ^ ^ Proc3 9 (Represent baidmg moment cJ eocti point on bean Figure 2: T o p level structure of the procedure frame model.
 576 tional analysis and conceptual graph modeling techniques were applied to these fields to study the types of situation models, that is, the types of conceptual and procedural knowledge that were displayed by the tutor.
 Tutorial discourse for Problem 1 was also analyzed by matching segments and actions to nodes and semantic fields in the procedure frame to examine how the tutor described the procedure.
 The tutorial dialogue for Problems 2 and 3 was analyzed in the same manner to evaluate: (a) the procedures applied by individual students to solve Problems 2 and 3 (procedures learned from Problem 1 and applied to the new problems), and (b) the types of tutorial assistance provided by the tutor to the student.
 Results Quantitative Analysis of Tutorial Interaction Log linear models were used to quantitatively investigate the predictions of the model.
 In Ionlinear analysis, the individual utterance (discourse segment) is taken as the sampling unit (response) and the model predicts the categories of individual discourse segments (responses).
 This statistical method allowed the estimation and testing of interactions of Students (13) and Problems (13) with each response coding (i.
e.
, set of Response Categories) in predicting crosstabulated frequencies of discourse segments in each category of response.
 A significant interaction of Problems with a particular Response Category would indicate that frequencies of each response category depended on the particular problem being studied; a significant interaction of Students with a particular Response Category would indicate that frequences of the response categories were different for (i.
e.
, adapted to) particular students; and a significant triple interaction would indicate that student differences depended on which problem was being studied in the sequence.
 Significant main effects of Response Categories would indicate consistent effects of the response category on response frequencies across problems and students.
 A n alpha level of .
01 was adopted to determine statistical significance.
 The stucture of conversational interaction.
 Analysis of frequencies of tutorinitiated vs.
 studentinitiated discourse revealed a dramatic shift from tutor initiated dialogue (for Problem 1), to studentinitiated dialogue (for Problems 2 and 3).
 Analysis of types of Cacts used by the tutor also revealed a significant shift from Problem 1 to Problems 2 and 3: the tutor's Cacts for Problem 1 were consistent across students and emphasized assertions; in contrast, her use of Cacts for Problems 2 and 3 involved fewer assertions and patterns of conversational interaction that varied across students and problems.
 Use of pedagogical strategies to control conversational interaction.
 One explanation of this shift in the conversational control from teacher to studentinitiated is that these patterns reflect different highlevel tutoring strategies for Problem I as compared to Problems 2 and 3.
 Such a shift should be reflected in different patterns of local pedagogical strategies.
 Analysis of problem differences in pedagogical strategies for the three problems did indeed reveal a significant interaction.
 For Problem 1 the tutor consistently emphasized strategies of instruction, demonstrations, explanations, and comprehension checking, across students; however, for Problems 2 and 3 there was a shift to evaluation and hints, with different patterns across students and problems.
 These dramatic shifts in pedagogical strategies were consistent with the use of a global tutorial strategy of tutorinitiated "modeling and explanation" for all students on Problem 1, followed by a strategy of "coaching and evaluation" in a context of studentinitiated problemsolving on Problems 2 and 3.
 Further analyses demonstrated that the various pedagogical strategies were related to specific patterns of use of different types of Cacts.
 Planbased control of tutoring.
 Given evidence that the teacher adopted a modeling and explanation strategy for Problem 1, we investigated planbased control of the tutor's discourse by matching her discourse segments for Problem 1 to subprocedures in the procedure frame.
 If a subprocedure node was included explicitly in the tutor's plan, it was coded as planned; if a matched subprocedure was not in the plan, it was coded as unplanned.
 A loglinear analysis revealed that the tutor favored planned procedures in her discourse and did so consistently across subjects.
 Furthermore, she tended to introduce and teach procedures in the sequence that was established by her plan.
 A qualitative analysis showed that departures from the planned sequence consisted principally of backtracking and reference to procedures not included in the original plan.
 Explaining and modeling problemsolving procedures and reasoning.
 One of the most important predictions of the situated discourse model is that the content of tutorial dialogue will reflect the structure of the tutor's knowledge of the procedure, her declarative (physics) knowledge, and the integration (linking) of physics knowledge through explanations of the physical principles that define the situation in which a particular subprocedure is applied.
 Several quantitative analyses investigated the extent to which the tutor's procedural knowledge predicted the content of her dialogue for Problem 1.
 First, the tutor focused differentially on the three main subprocedures for the experienced, intermediate, and novice students.
 Second, the tutor emphasized descriptions of high level subprocedures for Problem 1, and procedures near the "bottom" of the frame hierarchy (i.
e.
, more specific subprocedures) in her dialogue across students.
 Third, for Problem 1, the tutor emphasized particular semantic fields, including: results, goals, evaluations, and situation information (in that order) in her descriptions and explanations of procedures to Students 1 and 2; for Student 3, she shifted her emphasis to goals, with less attention to results, situation, and evaluation.
 There was evidence from the students' dialogue for Problem 1 that this difference reflected an adaptation to a consistent preference on the part of Students 1 and 2 for result descriptions, and a preference for goal information by Student 3 in learning the procedures (i.
e.
, different stu577 dent learning strategies).
 Finally, we analyzed the problem solving activities of the tutor in her actual problemsolving behavior (which accompanied her dialogue).
 The tutor consistently emphasized execution of procedures, and then interpretation of problem features and results; she demonstrated less explanation, evaluation, planning, and testing of results.
 Furthermore, the semantic fields she used in describing the procedures were strongly related to the particular cognitive activity being carried out in solving the problem and to the level of the procedure in the goal decomposition hierarchy.
 Tutorial support for students' problemsolving.
 The tutorial dialogues for Problems 2 and 3 consisted principally of dialogue accompanying students' problemsolving episodes.
 Their problemsolving actions and accompanying dicilogue were matched to nodes in the procedure frame and counts were made of percent of nodes referred to by students with no help from the tutor, and those with help from the tutor.
 All students were able to solve these problems (which required transfer of learned procedures and knowledge to new problems in the domain that increased in complexity) with help, and the novice required more help than the other two students.
 The extent of help from the tutor varied with student and from the simpler (Problem 2) to the more complex problem (Problem 3).
 Analyses of thecontent of the tutor's dialogue were carried out to examine the types of coaching and assistance she provided to the students.
 These analyses revealed that: (a) she focused on different subprocedures with different students, (b) her emphasis on describing lowlevel and highlevel procedures was different for different students and different problems; and (c) she shifted from resultsbased to evaluationbased descriptions of the procedures.
 Qualitative Analysis of Discourse Content One example will be given to illustrate the types of conceptual situation models that the tutor represented in her situated discourse and action.
 In this example (Figure 3), the tutor explained the meaning of a particular representation that had just been written on the blackboard.
 The diagram is a "free body diagram" of a beam with two supports, two loads (one concentrated and one uniformly distributed), and two reactions (the arrows pointing upwards).
 The beam has been cut at point x, and the tutor is explaining the forces (shear force and bending moment) acting at the cut.
 The conceptual graph represents the content of the tutor's explanation, and the unlabelled arrows from nodes in the graph point to components of the free body diagram that were referred to in the tutor's description.
 The tutor's situation model, thus, makes the external representation meaningful by linking it to conceptual information in the situation model for the physical system being represented (forces acting on the beam at the cut).
 Other types of situation models were also characteristic of the tutor's discourse, particularly; (a) explanations of the physics of static systems in equilibrium and the principles governing them; (b) modeling of reasoning used to derive equations, plots of shear forces and bending moments, or explain results; and (c) descriptions and explanations of procedures.
 Situation models describing static physical systems (a) typically consisted of propositions representing such information as classifications of types of forces, the structure of beams, principles of equilibrium, definitions of complex concepts, and mathematical properties of static systems in equilibrium.
 Causal, conditional, and logical implications were a salient characteristic of these models, as were algebraic descriptions of their quantitative properties.
 Models of reasoning (b) typically consisted of chained conditional relations proceeding from abstract physical principles to statements about the properties of the specific system being described.
 Explanations of procedures (c) consisted of, first, a sequence in which specific procedures were applied and explained, and second, conceptual information related to the various semantic fields for procedures previously described.
 There was smooth integration of declarative and procedural knowledge in these dialogues, and some of the procedures acted merely as a guide to a reasoning process.
 Thus, the complex nature of cognitive activity and integrated knowledge in this domain was strongly reflected in the content of the tutorial dialogues.
 Conclusions This study set out to apply a model of situated discourse to analyze tutorial dialogue in a complex though welldefined domain of problem solving in engineering.
 Quantitative analyses of the tutorial dialogue affirmed that the constraints on situated discourse processing identified in the model were strong predictors of the propositional content and conversational functions of utterances produced by both the tutor and the students.
 Qualitative analysis of the conceptual content of the tutor's dialogue for Problem 1 revealed several recurring and distinct types of situation models that constituted the meaning associated with the situated discourse and action.
 Trace analysis of the dialogue accompanying problem solving actions enabled us to anabending V(K) V(x) Shear terteodpolnl or beam ROftJ (ore© R.
06J RfTURNS FUNCTION dWance Figure 3: Example of the tutor's explanation of a representation 578 lyze how the tutor described the procedure, in what sequence, and how procedures were explained by linking them with declarative domain knowledge and semantic descriptions of external representations.
 Thus, the situation models "presented" to the student integrated declarative and procedural knowledge, and tied it to actions of applying procedures and reasoning.
 The students initially (Problem 1) "received" this information, their participation consisting mostly of observing, asking questions and participating in carrying out lowlevel algebraic procedures with tutorial guidance.
 Students' problem solving and dialogue on subsequent problems (2 and 3) displayed that they had acquired sufficient declarative and procedural domain knowledge and practice in its use to enable them, with varying degrees of assistance, to solve new problems.
 These results demonstrate that cognitive models of discourse processing can be extended to the analysis of tutorial dialogue to provide detailed information about the conceptual situation models involved, and the processes used by the tutor and students.
 Tutorial dialogue is similar to protocol data in studies of problem solving: it is a rich natural source of information about the processes and knowledge involved in situated learning.
 Such study of situated tutorial dialogue can uncover the characteristics of situations and how they constrain the cognitive processes involved in situated learning.
 Acknowledgements W e would like to thank the Department of Mechanical Engineering, McGill University for their cooperation in this research.
 This study was supported by research grants from the National Research Council (Canada), the Fonds F C A R (Quebec), and B N H Expert Engineering Software, Inc.
, St.
 Laurent, Quebec.
 References Brown, J.
S.
, Collins, A.
, & Duguid, P (1989).
 Situated cognition and the culture of learning.
 Educational Researcher, 18(1), 3242.
 Dore, J.
 (1980).
 Conversation and preschool language development.
 In P.
 Fletcher and M .
 Carman (Eds.
), Language acquisition: Studies in first language development.
 N e w York: Cambridge University Press.
 Fox, B.
A.
 (1993).
 The human tutorial dialogue project: issues in the design of instructional systems.
 Hillsdale, NJ: Eribaum.
 Frederiksen, C.
 H.
 (1986).
 Cognitive models and discourse analysis.
 In C.
 R.
 Cooper & S.
 Greenbaum (Eds.
), Studying writing: Linguistic approaches.
 Beverly Hills: Sage.
 Frederiksen, C.
 H.
 & Breuleux, A.
 (1990).
 Monitoring cognitive processing in semantically complex domains.
 In N.
 Frederiksen, R.
 Glaser, A.
 Lesgold, & M.
 Shafto (Eds), Diagnostic monitoring of skill and knowledge acquisition.
 Hillsdale, NJ: Eribaum, 351392 Frederiksen, C.
 H.
, DoninFrederiksen, J.
 (1991).
 constructing and manipulating representations in understanding and producing text.
 In G.
 Denhiere and J.
 Rossi (Eds.
), Text and text processing: Psychological and linguistic aspects.
 North Holland: Elsevier Science Publishers.
 Greeno, J.
 G.
 (1991).
 Environments for situated conceptual learning.
 In L.
 Birnbaum (Ed.
), Proceedings of the International Conference on the Learning Sciences.
 Evanston, Illinois, August, 1991.
 Gumperz, J.
 (1992).
 Contextualization in understanding.
 In A.
 Duranti & C.
 Goodwin (Eds.
), Rethinking context: language as an interactive phenomenon.
 Cambridge: Cambridge University Press, 229252.
 Leinhardt, G.
 (1993).
 O n teaching.
 In R.
 Glaser (Ed.
), Advances in instructional psychology, volume 4.
 Hillsdale, NJ: Eribaum, 154.
 Lemke, J.
L.
 (1990).
 Talking science: language, learning, and values.
 Norwood, NJ: Ablex.
 Resnick, L.
 B.
, Levine, J.
 M.
, & Teasley, S.
 D.
 (1991).
 Perspectives on socially shared cognition.
 Washington, D C : American Psychological Association.
 Schoenfeld, A.
 H.
, Smith III, J.
P.
, Arcavi, A.
 (1993).
 Learning: the microgenetic analysis of one student's evolving understanding of a complex subject matter domain.
 In R.
 Glaser (Ed.
), Advances in instructional psychology, volume 4.
 Hillsdale, NJ: Eribaum, 55176.
 Tannen, D.
 (1993).
 Framing in discourse.
 Oxford: Oxford University Press.
 van Dijk, T.
 A.
 M.
, & Kintsch, W .
 (1983).
 Strategies of discourse comprehension.
 N e w York: Academic.
 Vera, A.
H.
 & Simon, H.
A.
 (1993).
 Situated action: a symbolic interpretation.
 Cognitive Science, 17(1), 748.
 579 T h e H U M E ModelDriven Discovery System Adrian Gordon' Laboratoire de Recherche en Informatique Universite de ParisSud Orsay France SMTP%"adrian.
gordonOunn.
ac.
uk" Abstract Structural models provide an important source of hypothetical knowledge in scientific discovery.
 Informal Qualitative Models (IQMs) are structural models which can be applied to weak theory scientific domains.
 Example models are presented for the domain of solution chemistry.
 These models can be systematically generated, but, due to the weak theory nature of the domains to which they are applied, they cannot be verified directly.
 Instead, the application of IQMs to a problem can be used to drive other scientific discovery processes; in particular, the discovery of numeric laws.
 The H U M E system is a discovery system based around the application of IQMs.
 HUME's discovery goal is to construct explanations for phenomena, such as the depression of the freezing point of salt solutions, using a variety of reasoning strategies.
 H U M E first attempts to explain such phenomena using a preexisting theory.
 If this theory is not able to provide an explanation, the system uses a combination of theory construction and numeric law discovery.
 The application of IQMs provides hypotheses for use by the other two processes.
 Used in this way, IQM application can be seen to provide a degree of explanatory support for numeric laws which would otherwise be simply descriptive generalisations of data.
 An example of the application of H U M E to a problem in solution chemistry is presented.
 Informal Qualitative Models in Scientific Discovery Structural models can provide an important source of hypothetical knowledge for use in scientific discovery.
 Informal Qualitative Models (IQMs) are one sort of structural models that are used by scientists.
 IQMs are abstract structural descriptions of physical systems, either actual or hypothetical.
 They were first introduced in Sleeman et al.
 (1989), and further elaborated in Gordon (1992, 1993) and Gordon ̂ f a/.
 (1994, 1995).
 Figure 1 gives an example of two models which can be used in the domain of solution chemistry.
 Model A shows the case where molecules of solvent and solute are uniformly physically distributed throughout a solution, with neither sets of molecules being chemically changed in any way.
 This is the Physical Mixing model.
 Model B shows the Association model, in which molecules of solute form an association with molecules of solvent.
 The associations thus formed are dissolved in the remainder of the solvent.
 An example might be a salt which existed in a hydrated form in solution.
 •O > Current Address: Department of Computing, University of Northumbria at Newcasde, NewcastleUponTyne, NEl 8ST, UK.
 A B Figure 1.
 The (A) Physical Mixing and (B) Association IQMs A historical study of eighteenth and nineteenth century solution chemistry has lead to the elaboration of a set of increasingly complex IQMs.
 As we show in (Gordon et al.
 1994) each of these models can be generated form the simplest model in the domain, the Physical Mixing model, by the application of a set of model generation operators.
 The repeated application of these operators results in the synthesis of a search space of IQMs.
 Clearly, this formulation of a search space of structural models is closely related to previous work in computational discovery.
 Systems such as S T A H L / D A L T O N (Langley et al.
 1987), R E V O L V E R (Rose and Langley, 1986) and BR3 (Kocabas, 1991) all formulate discovery as a heuristic search through a space of models.
 However, previous approaches have used strong heuristics to constrain the generation of models, and to confirm their validity.
 BR3, for example, uses a set of quantum conservation laws to constrain the generation of quark models in particle physics.
 Many previous systems are also able to confirm the observational consequences of generated models.
 This is frequently done by looking for observed reactions (such as particle decay reactions or chemical reactions) which confirm the generated models.
 In weak theory domains, these constraints do not operate.
 None of the models used historically in solution chemistry had directly observable consequences, for example.
 In early solution chemistry history, IQMs were confirmed by looking for numeric laws.
 If a "good" numeric law could be found based on the applied model, then this was accepted as evidence for the validity of the model.
 The HUME Discovery System H U M E is a discovery system which is based around the application of IQMs.
 The view of scientific understanding 580 http://ac.
ukOBSERVATION I l̂  1 " DEDUCTIVE THEOREM PROVEk IQM APPLICATION (Abducuon) THEORY CONSTRUCTION (Induclion) NUMERIC LAW DISCOVERY (Induction) 1 1 1 1 1 1 X 1' I.
 A N A T I O N Figure 2.
 General Architecture of H U M E that is adopted by H U M E is that it depends on the construction of deductive nomological explanations (Hempel and Oppenheim, 1948).
 H U M E attempts to understand a phenomenon by explaining it in terms of an existing domain theory.
 However, since H U M E will be in most cases dealing with incomplete domain theories, a significant subtask for the system is the construction or extension of domain theories.
 Figure 2 illustrates the general architecture of HUME.
 The system is based around a deductive theorem prover.
 This theorem prover takes an observation as input, and produces an explanation for this observation on successful exit.
 The explanation is based on the application of a domain theory, and background domain knowledge.
 However, if this domain theory cannot initially provide an explanation, the other modules of H U M E are called to extend that domain theory.
 These modules are an IQM application module, which is employs basically abductive reasoning techniques; a theory construction module, based around that of the DISCIPLE system (Tecuci and Kodratoff, 1990); and a numeric law discovery module, which is at present provided by the ARC system (Moulet, 1991).
 The discovery element of the system lies not merely in the construction of explanations, but in the confirmation of existing IQMs, the construction of new domain theories, and the discovery of new laws.
 Table 1.
 Freezing point data.
 Asterisks indicate anomalous datapoints (See later explanation).
 Substance Barium Chlorate Barium Nitrate Strontium Nitrate Copper Nitrate Copper Acetate* Lead Acetate* Barium Chloride Mercuric Chloride* Formula Ba(CIO,), Ba(NO,), Sr(NO,), Cu(NO,), Cu(C,H,0,), Pb(C,H,0,), BaCl, HgCK Molecula r Mass (M) 304 261 211 187.
2 181 325 208 271 Freezing point °c (Fp) 0.
145 0.
155 0.
195 0.
244 0.
171 0.
068 0.
233 0.
076 M X Fp 44.
1 40.
5 41.
2 45.
7 31.
1 22.
2 48.
6 20.
5 'ARC is an extension of the ABACUS system HUME'S inputs are a set of experimental observations, a set of theorems which constitutes a background domain theory, and a library of IQMs.
 All of this knowledge is represented in Horn clause form.
 A discovery problem must then be specified to the system.
 This discovery problem takes the form of a particular experimental problem, and the result of that experimental problem.
 Typically, this will be one of the experimental observations that the system has already seen.
 The direct output from H U M E on the successful completion of a discovery task is an explanation for a specified discovery problem, in the form of a proof tree.
 However, though a proof tree is the direct result of successful discovery, there may be many indirect results.
 Some of the theorems used in the proof tree might themselves have been constructed by HUME, and some of the "facts" used in the proof tree might be hypotheses introduced by the system.
 An Example: HUME and Solution Chemistry This section will describe how H U M E can be used to undertake a discovery task in the domain of solution chemistry.
 The data used in this example discovery session are taken from (Raoult, 1885, pp.
 407408).
 This data deals with the freezing points of a set of thirty aqueous solutions of the salts of various bivalent metals.
 Table 1 shows some of this data.
 Table 1 shows the name and empirical formula for some of the salts used by Raoult, together with their molecular masses ( M ) and the observed freezing point (Fp) for a solution of each salt.
 In each case the solution involves Ig of solute dissolved in lOOg of solvent.
 The calculated term M x Fp is also shown.
 H U M E ' s initial discovery goal is to explain the observed freezing point of the first example from Table 1, a solution of Barium Chlorate, with a freezing point of 0.
145 ""c.
 Initially, H U M E is provided with knowledge about the solvents and solutes used in each example from Table 1, such as their composition, mass, and the molecular mass of the substances involved.
 However, the only knowledge provided for each resulting solution is its observed freezing point.
 H U M E ' S initial domain theory is therefore incomplete, and the system is initially unable to explain the observed freezing point of the selected example.
 The system's discovery modules are called to extend the initial theory.
 The system first attempts to use its theory construction strategy, adapted from that of the DISCIPLE system.
 The basis of this strategy is a search for possible causal relationships amongst the objects implicated in a problem.
 This process is described in detail in (Tecuci and Kodratoff, 1990) and (Gordon, in preparation).
 However, since the system initially has knowledge only about the composition of the solvent and solute used in the first example, and not the resulting solution, it is unable to discover (Falkenhainer and Michalski, 1987).
 581 any possible causal relationships.
 At this stage, the system can proceed no further without making some hypotheses about the structure of the solution.
 This is done by applying an IQM.
 Each I Q M in H U M E is represented in the form of a Horn clause theorem.
 Theorem 1 represents the Physical Mixing IQM, for example.
 Theorem 1: (<— (model physicalmixing ?eg) (and(makesolution ?eg ?solvent ?solute ?solution) (composedof ?solvent [?substancel]) (composedof ?solute [?substance2]) (composedof ?solution [?cl ?c2]) (composedof ?cl [?substancel]) (composedof ?c2 [?substance2]))) where the symbol "^" represents logical implication, square brackets represent lists (Prolog syntax) and "?" preceding a symbol represents a variable.
 This theorem states that the Physical Mixing I Q M applies to an example of the creation of a solution ("makesolution"), where the solvent is composed of some substance, ?substancel, the solute is composed of some substance, ?substance2, and the resulting solution is composed of two sub components (?cl and ?c2) which are themselves composed of ?substancel and ?substance2 respectively.
 In order to apply this I Q M to a solution, the theorem is first matched against H U M E ' s knowledge base.
 Typically, this will result in a partial match, where some of the assertions required to fully instantiate the antecedents of the theorem are missing from H U M E ' s knowledge base.
 H U M E ' s abductive reasoning strategy in these circumstances simply asserts any missing antecedents directly into the knowledge base as hypotheses.
 In the current case, since no knowledge is initially available concerning the components of the resulting Barium Chlorate solution, the final three antecedents of the theorem will fail to match assertions in H U M E ' s knowledge base.
 These three antecedents will then be directly asserted into H U M E ' s knowledge base, with system generated symbols to replace any still uninstantiated variables.
 This ammounts to hypothesising the unknown components of the solution.
 Once an IQM has been applied in this way, HUME's theory construction strategy can be applied again.
 This time, however, the system can make use of the hypothetical knowledge about the solution that has been introduced by the application of the Physical Mixing IQM.
 Theorem 2 results: Theorem 2: (<—( freezingpoint ?solution ?x ) (and (composedof ?solution [?cl ?c2]) (composedof ?cl [?sl]) (composedof ?solvent [?sl]) (composedof ?c2 [?s2]) (composedof ?solute [?s2]) (makesolution ?gl ?solvent ?solute ?solution))) This theorem has been constructed based on the relationships which now exist between the solvent, the solute, and the hypothesised components of the resulting solution.
 That is, it is based on the fact that the solvent and solute are composed of the same substances as are the hypothesised components of the solution.
 However, this theorem is not complete.
 The value of the freezing point property, ?x, is nowhere instantiated in the antecedents of the theorem.
 In circumstances such as this, in order to instantiate the missing property, H U M E applies its third discovery strategy: the search for numeric laws.
 In order to search for numeric laws, H U M E uses partial theorems such as Theorem 2 as contexts for numeric law discovery.
 All of the numeric properties of objects which are implicated in the partial theorem are gathered together and passed to H U M E ' s law discovery module.
 However, this is not done only for the example currently under investigation, but for all examples known to the system.
 All of the examples from Table 1 would be used in this case, for example.
 Using this data, H U M E ' s numeric law ^2.
986 discovery module discovers the law Fp = where M Fp is the freezing point of the solution, and M is the molecular mass of the solute .
 Figure 3 shows the graph of freezing point against molecular mass for Raoult's data.
 Figure 3 also shows the newly discovered law superimposed over this data.
 Once discovered, this law is then incorporated into the previously seen partial theorem, to produce Theorem 3: Theorem 3 (<( freezingpoint ?solution (/ 42.
986 ?m ) (and antecedents as in Theorem 2 (molecularmass ?sl ?m))) Once this theorem is constructed, HUME is able to construct an explanation for the observed freezing point of the first solution from Table 1.
 The resulting proof tree is shown in Figure 4.
 The basis of this proof tree lies in the application of Theorem 3, but some of the grounded assertions in this proof tree are only available because of the abductive application of the Physical Mixing IQM.
 These are the assertions shown underlined in Figure 4.
 These assertions concern the hypothetical composition of the solution (named solutioni in this case).
 Conclusions The previous section showed how H U M E was able to undertake a discovery task in the domain of Solution Chemistry.
 The system was able to explain the observed This law can also be expressed as Fp x M = 42.
986.
 Values for Fp X M are shown in Table 3.
 582 MMolecular Mass 0.
1 • 0.
2 •5! 0.
3 0.
4 0.
5 • 0.
6 L 100 200 300 400 Anomalous Data Points FP = 42.
986 / M Figure 3.
 Graph of Freezing point against molecular m a s s for Raoult's data.
 freezing point of a particular example solution.
 H o w e v e r , the theorem that the system constructed, and the numeric law embodied in that theorem, are also able to explain the observed freezing points of a significant n u m b e r of other solutions from Table 1.
 Thus, by starting from the careful analysis of a single example the system is able to construct a generally useful domain theory for a particular aspect of solution chemistry.
 Although the system uses a n u m b e r of different m o d e s of reasoning, the general discovery strategy is guided by the application of I Q M s .
 I Q M application provides hypotheses for use in theory construction, and frequently allows the derivation of numeric data for use in law discovery (Gordon, 1992, 1993).
 Furthermore, I Q M s also lend a degree of explanatory support for discovered numeric laws.
 In the case of Theorem 3 above, the two parts of the theorem are mutually supporting.
 The explanatory component represented by the antecedents of the theorem (which have been constructed after I Q M application) supports the discovered numeric law.
 Similarly, the > • V o (freezingpoint solution 1 0.
145) (freezingpoint ?solution (/ 42 986 ?M)) _co(?solution [?c1 ?c2] |—(co ?solute [?s2]) II co(solution1 [c1 c2]l — (CO''solvent [?s1]) II (CO solventi H20]) (co?c1 [?s1]) 11 (mm '52 ''m) (CO solutel [BaCI032]) 11 (CO ?c2 [?s2]) (mm BaCICX32 304) fcoc2[BaCI0321) I—(makesolution ?G1 ?solvent ?solute ?solutlon) C0(C1 [H201) (makesolution exi solventi solutel solutioni) Figure 5.
 The Solute Dimerism I Q M Figure 4.
 Proof tree for "(freezingpoint solutioni 0.
145)".
 m m = "molecular mass", co = "composedof, BaCI032 = Barium Chlorate, H 2 0 = water.
 discovered numeric law also serves to confirm the validity of the applied I Q M .
 I Q M s can also explain away anomalies in a domain theory.
 A s Figure 3 shows, there are three examples in the data of Table 1 which appear to be anomalous with regard to the numeric law discovered by H U M E .
 That is, the observed value of the freezing point of each of these examples differs significantly from that predicted by the law (these examples are labelled with asterisks in Table 1).
 A s can be seen in Table 1 the three anomalous examples have a value for the term Fp x M which is roughly half of that observed for the other examples.
 However, if w e assume that the molecules of each of the substances in the anomalous cases exist in solution associated two by two, then the value of their molecular masses, M , would be doubled in each case, and the substances would then fit the general law fairly closely.
 Hypothesising that these salts associate two by two in solution in fact corresponds exactly to the application of a n e w I Q M to each of these examples.
 This is the Solute Dimerism model shown in Figure 5.
 Raoult himself explained away these apparent anomalies in precisely this way.
 A careful study of the history of solution chemistry offers numerous other examples in which n e w I Q M s , or variations on existing I Q M s were used to derive and justify numeric laws, and explain away seemingly anomalous observations (Gordon, in preparation).
 References Falkenhainer, B.
C.
 and Michalski, R.
 S.
 (1986).
 Integrating Quantitative and Qualitative Discovery: The A B A C U S System.
 Machine Learning, 1, pp.
 367401.
 Gordon, A.
 (1992).
 Informal Qualitative Models and Scientific Discovery.
 In Proceedings of the M L 9 2 583 Workshop on Machine Discoverv, J.
 M.
 Zytkow (Ed), pp.
 98102.
 Aberdeen.
 Gordon, A.
 (1993).
 Informal Qualitative Models and the Depression of the Freezing Point of Solutions.
 In Working Notes for the MLnet Workshop on Machine Discovery, P.
 Edwards (Ed), pp.
 5660, Blanes, Spain.
 Gordon, A.
 Edwards, P.
, Sleeman, D.
 and Kodratoff, Y.
 (1994).
 Scientific Discovery in a Space of Structural Models: An Example from the History of Solution Chemistry.
 Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, pp.
 381386.
 Gordon, A.
, Sleeman, D.
 and Edwards, P.
 (1995).
 Informal Qualitative Models: A Systematic Approach to their Generation.
 Working Notes for the AAAI Spring Symposium on Systematic Methods of Scientific Discovery, pp.
 1922.
 Gordon, A.
 Informal Qualitative Models in Scientific Discovery.
 These de Docteur en Sciences, Universite de ParisSud, Centre D'Orsay, in preparation.
 Hempel, C, and Oppenheim, P.
 (1948).
 Studies in the Logic of Explanation.
 Philosophy of Science, vol 15.
 pp.
 135175.
 Kocabas, S.
 (1991).
 Conflict Resolution as Discovery in Particle Physics.
 Machine Learning, 6, pp.
 277309.
 Langley, P.
, Simon, H.
A.
, Bradshaw, G.
L.
, and Zytkow, J.
M.
 (1987) Scientific Discovery: Computational Explorations of the Creative Processes.
 Cambridge, MA: MIT Press.
 Moulet, M.
 (1991).
 Using accuracy in law discovery.
 In Proceedings of the Fifth European Working Session on Learning.
 Y.
 Kodratoff (Ed), Lecture Notes in Artificial Intelligence, Springer Verlag, pp.
 118136.
 Raoult, P.
M.
 (1885).
 Sur le point de congelation des dissolutions salines.
 Annales de Chimie et de Physique, (6) IV, pp.
 401430.
 Rose, D.
, and Langley, P.
 (1986).
 Chemical Discovery as Belief Revision.
 Machine Learning, 1, pp.
 423452.
 Sleeman, D.
H.
, Stacey, M.
K.
, Edwards, P.
 and Gray, N.
A.
B.
 (1989).
 An Architecture for TheoryDriven Scientific Discovery.
 In Proceedings of the Fourth European Working Session on Learning (pp.
 1124).
 Montpeilier, France: Pitman/MorganKaufmann.
 Tecuci, G.
 and Kodratoff, Y.
 (1990).
 Apprenticeship Learning in Imperfect Domain Theories, in Machine Learning: An Artificial Intelligence Approach, Vol.
 3, Y.
 Kodratoff, and R.
S Michalski (Eds.
), pp.
 514552, Morgan Kauffman, San Mateo CA.
 584 Informal Reasoning and Literary Expertise Barbara Graves Laboratory of Applied Cognitive Science 3700 McTavish Street McGill University Montreal, Quebec, H3A 1Y2 cxch@musica.
mcgill.
ca Abstract This paper presents a psychological investigation of the informal reasoning of literary experts and students as they describe a fictional narrative.
 The literary situation is viewed as a communicative relation between readers and writers mediated by written text.
 This investigation used a task of text description and applied an explicit twostage cognitive model of literary communication to analyze the readers' verbal protocols in terms of discursive patterns and reasoning strategies.
 Findings suggest that the model of the communicative context which literary experts construct for their reading is instrumental in their reasoning about the text.
 Students it seems are ambivalent about the authortext relationship Informal Reasoning and Literary Expertise This paper presents a psychological investigation of informal reasoning of literary experts and students and the role that authorial intentions play in their interpretive strategies.
 It draws on several areas of cognitive research: the study of expertise (Ericsson & Smith, 1991), the study of informal reasoning (Voss, Blais, Means, Greene, & Ahwesh, 1989), and the study of discourse representation and processing (Denhiere & Rossi, 1991).
 There has been an ongoing debate in literary studies regarding the role of an author's intentions in constraining a reader's interpretation.
 The argument has evolved from the position held at the beginning of the twentieth century, that understanding an author's intentions was strategically necessary for understanding the literary text and was the only means by which an interpretation could be validated.
 This was then replaced by the view that textual interpretation was to be denved solely from an examination of text properties and had no need of biographical inl'ormation about the author or additional study of the historical period or cultural mores.
 The literary text was regarded as a freestanding aesthetic object which could be successfully interpreted in terms of its own structure and coherence and in this way marginalized the influence of the author in the interpretive process.
 In the 196()'s the European structuralist movement set out to replace the intcrprctne paradigm altogether.
 Seeking to make the study of literature an exact science w hich w ould be explanatory rather than interpretive they achieved the demise of mtentionalism and announced the "death of the author" (Barlhes, 1966/77).
 Their interest was not on the meaning or value of a work but rather on the devices which enabled it to be realized within a social context.
 Thus, within literary studies the emphasis shifted to the social construction of meaning in the production and reception of literary text.
 A s a result, the author was marginalized in the establishment of meaning and the role of the reader greatly expanded.
 Then the questions pertaining to the limits of interpretation surfaced with theorists allowing readers unlimited possible readings.
 The instability of the text and the role of the reader in literary communication became important topics within critical theories about literature (Cullers, 1981; Eco, 1992; Fish, 1980).
 At this point the debate within literary theories at to what constrains interpretation is wide ranging and often unsettling from a psychological perspective.
 Recently, psychologists interested in text processing have begun to consider the relationship between current cognitive discourse theories and literary reading, (Kintsch, 1993) and have undertaken research to investigate this activity (e.
g.
, Britton & Eisenhart, 1993; Graves & Frcderiksen, in press; Magliano & Graesser, 1991; Z w a a n , 1992).
 While extending the existing experimental paradigm to investigate the processes associated with literary understanding, these psychologists relate their theoretical assumptions and empirical findings to very well grounded theories which have been established in the study of text comprehension.
 The following psychological investigation is based on the assumption that the literary situation is a communicative relation between readers and writers mediated by written text and that successful communication hinges on shared understanding.
 T o read successfully one must establish the appropriate context for the reading, and there is no hard and fast rule for accomplishing that since each text presents novel problems.
 In addition readers \ ary widely with respect to their general world knowledge and their literary knowledge.
 The context m ay be derived from multiple sources which include understanding the words, the events of the narrative, the plans and goals of the characters, as well as thematic information.
 At the same time the context also includes the communicative context which includes a model of the author, the reader and the text.
 Pre\ ious research has already identified the construction of an author mcxlel while reading as influencing the strategic behaviors of readers (Gibbs, Kushner, & Mills, 1991; Haas & Flower, 1988; Vipond & Hunt, 1984).
 It appears that literary experts construct multilayered representations not only of the discourse structure, but also of the communicative decisions 585 mailto:cxch@musica.
mcgill.
caof the writer, as well as the comprehension processes required by a reader to understand the text, and that e\ en when the author's identity is unavailable, expert readers construct a hypothetical model of the author (Graves & Frederiksen, 1991).
 These psychological data suggest a more interactive view of the relationship between the literary reader, the author and the text than is commonly found within literary studies which privilege one aspect over another a priori.
 What do we mean by literary expertise? The expertise in question is viewed as an acquired set of skills and knowledge resulting from specialized training over an extended period (Encsson & Charness, 1994).
 Literary expertise includes both specific subjectmatter expertise and a more general discourse expertise.
 Much of the cognitive research on expert performance has focused on specific subjectmatter domains, (Chase & Simon, 1973; Chi, Feltovich, & Glaser, 1981) and has characterized expertise in problemsolving in terms of domainspecific knowledge representations and cogniti\e strategies.
 At the same time, another part of the discussion associated with reading, text comprehension, and writing has led to a consideration of discourse expertise as a more general expertise (Perfetti, 1989; Scardamalia & Bereiter, 1991).
 Unlike domainspecific expertise, discourse expertise is not associated with specific subjectmatter knowledge and tasks, but rather is applicable across domains.
 This research investigates literary expertise more as a discourse expertise (albeit quite specialized), than as a domainspecific expertise.
 T w o expenmental conditions support this: first, none of the experts involved is a subjectmatter expert of the author or the period, and second, the verbal protocols are recorded during a first reading of the texts.
 A cognitive model of literary expertise As cognitive science research in expertise suggests, two aspects of symbolic processing that need to be characterized are representations and the processes which act on those representations.
 This investigation used a task of text descnption and applied an explicit twostage cognitive model of literary communication to analyze the readers' verbal protocols.
 Discursive patterns.
 In the first stage of analysis a multilevel cognitive model of discursive patterns (Graves & Fredenksen, 1991) is applied to analyze the semantic units, in this case the propositions, in readers' description protocols.
 Each discursive pattern includes a text unit being described, and a point of reference for the description, that is, a reader, author, or text perspective.
 This model assumes that readers construct representations of the linguistic structures (style, lexicon, syntax, cohesion, topicalization, punctuation) the propositional structures (literal and figurative meaning, coherence, macrostructures, logical relations), and the conceptual frames of a text (descriptive, narrative, dialogue, and problem frames).
 A n examination of the discursive patterns provides a picture of what aspects of the text readers are descnbing and from which discourse perspective.
 It is also possible to infer some aspects of process if one examines the discursive patterns over the course of the reading.
 This level of analysis, however, does not provide information about how readers use those descriptions as they reason about the text.
 Informal reasoning.
 In order to investigate how literary readers reason about the text, a mcxlel of informal reasoning is applied to the text descriptions with the discursive patterns constituting the input (Graves, 1993).
 The analysis of informal reasoning specifies a semantic net, built over time, where unit nodes are based on reasoning operations (claim, hypothesis, analogy, expectation, question, evaluation, and metastatement), which are linked by relalioits (condition, elaboration, reiteration), and are situated at one of three reasoning levels (fact, local, global).
 This model draws on studies of reasoning carried out in the social sciences, (Voss, Blais, Means, Greene, & Ahwesh, 1989), in medical diagnosis (Patel & Groen, 1991), and in scientific discovery (Dunbar, 1993).
 Method This study employed a textdescription task in which six literary experts and six Honors' English students at the end of their undergraduate training were individually asked to produce a verbal description of a literary passage.
 The chosen excerpt was the opening of The English Patient (1992) by Michael Ondaatje.
 Three of the literary experts were faculty members of McGill University's English Department and three were published writers of English fiction.
 While all twelve participants were familiar with both the author and his writing, not one had read The English Patient at the time of the interview.
 Readers' verbal text descriptions were recorded and were analyzed in terms of the discursive patterns and reasoning strategies.
 Selected results and discussion In analyzing the discursive patterns, the within subjectsmeasures were the specific levels of the discursive patterns and the three discourse perspectives.
 To analyze the reader's reasoning strategies the withinsubjects measures were the reasoning categories, operations and levels.
 For both sets of analyses an additional withinsubjects measure, the time course of the reading was operationalized as sections of the text.
 Expertise and text descriptions.
 An examination of the developing models of text description revealed that for both student and expert readers the conceptual frame level descriptions of the text (mean = 164.
0) predominates over linguistic (mean = 20.
8) and propositional (mean = 22.
4) descriptions across all three sections.
 In addition there is a significant interaction for frame level descriptions by sections read with amount of frame description increasing over the course of the reading F(2,20) = 4.
68, p = 0.
021.
 This IS a very robust pattern for literary reading and refiects the reader's focus on the construction of a situation model of the text which include descnptive information pertaining to 586 setting, character identification etc.
, the sequence of events of the narrative, the plans and goals of the characters, as well as thematic information.
 The Honor's English students in this study resemble the literary' experts with respect to the specific levels of text representation identified by the discursive patterns.
 The question that follows is gi\ en that they are talking about the same things, will they operate on these text descnptions and reason about text in the same way as the experts? Expertise and the communicative context.
 It was stated earlier that all successful reading is a matter of identifying the relevant context and while this context can be descnbed at multiple levels of the text, it also includes the communicative context pertaining to the writer's strategies and the reader's responses.
 While all readers generate significantly more descriptions from the text pjerspective (mean = 142.
1) than either the author (mean= 39.
82) or reader perpsectives (mean = 20.
41), it is only the expert readers who early in their reading generate almost as much description from the author perspective (mean = 25.
67) as from the text perspective (mean = 34.
16) (see Figure 1).
 Expert readers also begin to construct a model of the reader very early in their reading.
 This suggests that the pragmatic context helps define the overall problem space for expert text descriptions.
 It would appear that the communicative context gets established before the situation model which requires much more additional information from the text.
 This is not to suggest that these readers are embarking on a quest for the author's meaning.
 Rather it is taken as recognition of the fact that the construction of the author and reader models reflects the explicit acknowledgment of the intentionality underlying the text.
 Following IS an extract from the protocol of a literary academic after reading the first sentence of the text which gives a sense of how important the communicative context is for expert readers and how it provides an immediate framework for the ensuing interpretation: She stands up in the garden where she has been working and looks into the dLstance.
(stnlence #1 from the novel.
 The English patient.
) "Well again you know the beginning is obviously sort of designed to grab your attention by a kind of disonentation.
 Y o u don't know w h o the hell this 'she' is, where the garden is, what she's doing.
 And one of the jobs that you're going to have to do is figure it all out as the text unfolds: the relationships between these different elements and the background.
 You're given very much a focus on the foreground, but beyond that all of the context and the literal landscape is not there.
" Having read only the first sentence of the novel, this literary academic begins immediately with a global claim which is made up of three discursive patterns from both the author and reader perspectives.
 This extract is particularly interesting since much psychological text research has privileged text features over all other variables and in this instance this expert reader is identifying what is not present in the text.
 This is a c o m m o n strategy of expert literary reasoning and suggests that a text gets descnbed not only on its own ments but by comparisons, explicit or not, to other texts and writers.
 Reasoning levels and links.
 The identification of reasoning levels is meant to provide some measure of the scope of readers' reasoning strategies.
 At the fact level are paraphrased or verbatim text expressions which are usually cited as evidence for reasoning operations other the other two levels.
 At the local level the reasoning operations refer to what has just been read but include some inferential processing.
 Reasoning operations at the global level include integrative inferences which are broad in scope.
 Experts lJ Students 2 30 • « 20 • lext Author Reader Section 1 lext Author Reader Section 2 Text Author Reader Section 3 Figure 1.
 Discourse perspectives by expeitise over sections.
 587 Reasoning Path for Literary Readers Literary academic Global Local Facts 8 9 10 U 12 13 Writer (.
lobal r Local D w Facts U IL.
 J • " 1 3 9 10 11 12 13 Student Global Local Facts D o a [ 5 m D o a D m m D m D ^ .
 II II IL DDfrnDDDDq 6 6 0 6 7 8 1011 12 13 Figure 2.
 Reasoning path of three readers for the first thirteen sentences The identification of reasoning links is meant to give a sense of the coherence of the reader's reasoning.
 Overall the most common links are conditions which occur when readers provide evidence for their statements.
 The links between reasoning operations at the local level often consist of elaborations and sometimes conditions.
 The links among operations at the global level are most often elaborations and reiterations.
 The quantitative results of the reasoning analyses reveal a difference between students cmd experts with regard to the scope of their reasoning.
 The withinsubjects contrast between statements occurring at the fact and local levels is statistically significanL SI,10) = 56.
70, p < O.
OOI, as is the contrast between information occurnng at the kxal and global levels, ££1,10) = 67.
43, p < 0.
001.
 All readers carried out more reasoning operations at the local level (mean = 95.
92), followed by the fact (mean = 48.
83), and global levels (mean = 10.
5).
 There was, however, a statistically significant betweengroups effect for the global level only, F(.
l,10) = 6.
34, p = 0.
031, with the literary experts generating more global reasoning operations (mean = 17.
0) than the students (mean = 4.
0).
 Figure 2 pro\ ides a schematic representation of the reasoning paths for one literary academic, one writer, and one student reader.
 An analysis of the reasoning links reveals that the withinsubjects contrast between statements linked by conditions and elaborations is statistically significant, F(.
1.
10) = 23.
84, 2 < 0.
001 as is the contrast between elaboration and reiteration links F(.
1,I0) = 62.
66, p < 0.
000.
 Looking at the means reveals it is clear that readers generate more than twice as m a n y conditional links (mean = 86.
75), as elaborations (mean = 41.
00).
 Reiterations cKcur least often 588 (mean = 8.
00).
 With respect to le\el of expertise, however, there is a statistically significant betweengroups effect for reiterations, F(.
1.
10) = 5.
25, 2 = 0.
045.
 An examination of the means shows that the expert readers generated more reiteration links (mean = 10.
67) than student readers (mean = 5.
33).
 While all readers provided coherent descnptions of the text, the structure of the coherence is very different for the two groups.
 This reasoning network generated by the student in Figure 2 is coherent since the reasoning operations do not stand in isolation but are linked by elaborations, reiterations or conditions.
 The scope of the reasoning, however, is much more local and neither the claims at the local level nor the textbased facts are used as evidence for a more encompassing framework.
 Directionality of reasoning.
 Literary experts rely on both forward and backward reasoning as they work their way through a text.
 The directionality of the representation in this type of a task follows the semantics of the links and nodes and should not be understood to represent the directionality of the reasoning.
 While directionality has been an important issue in some studies of reasoning such as medical diagnosis where there is an agreed upon endstate, namely correct diagnosis, it is not possible to pin it down in the context of the textdescription task of this research.
 When a reader provides evidence to support a reasoning operation this does not necessarily specify the directionality of the underlying reasoning as from text instance to claim since the reader may have elaborated a specific schema and then be simply looking for instances to confirm it.
 The unique problem space of literary experts.
 It is at the global level that the expert readers appear to set up individual tasks for themselves which are in the nature of puzzles requiring solutions.
 The reading that each gives at this level is specific to each reader; it's as if each sets up a unique problem space.
 It is at this level that the multiple interpretations are developed which correspond to the idea that "the creative text is always an Open Work" (Eco, 1992).
 For example, the literary academic cited above focuses on the postmodern theme of relationships the relation between art and nature, between the natural and the artificial, sexual relations between men and women including the role of a modem day Adam and Eve.
 In her own words: "What's the relationship and where's the snake?" The literary writer, by comparison, develops an in depth stylistic analysis of the musical structure of the text, comparing it to a sonata and drawing on all levels of text description to elaborate his view.
 His description explains just how the text was built up and examines in considerable detail the effect of certain linguistic choices made by the author at the same time evaluating those techniques.
 In each case, these readers make claims and hypotheses based on specific textual evidence in conjunction with their literary knowledge, their more general world knowledge, and their goals for reading.
 They then continue to look for evidence to confirm or disconfirm.
 This accounts for the multiple reiteration and elaboration links evident in their reasoning at the global level.
 At the local level and the fact level there is a great deal of overlap among readers because it is here that they are using textual evidence to support their remarks.
 At this level there is no doubt that all readers are understanding the same text.
 In discussing the limits and range of interpretation, the expert p>erformance strongly suggests establishment of the author model comprises an important component of the interpretive process.
 Expert readers appear to be clear on this issue.
 As one expert puts it, "You can't use language at all if you don't identify what the source of this information is and start guessing about the mind that's behind it.
" Another expert explains, "I go from the premise that the text is something that a person has put together and one of the things that interests me is why have they done it this way.
" This premise has important consequences for how experts reason about incoming text information.
 For example, consider the role of anomalies in most reasoning tasks.
 Coming upon anomalous information when building theories about the world, often leads to a reinterpretation or restructuring of information.
 In literary reading, however, anomalies are v iewed as deliberate and are incorporated into the developing model of the text.
 Students, in contrast, seem ambivalent when expressing their views about the authortext relationship.
 While able to acknowledge the agency underlying the text, "Common sense tells me of course that the text and the jjcrson who is writing the text are linked," one student goes on to say, " For me it's a mistake to read a text knowing everything about the author.
" Students seem to be caught between a commonsense acceptance of the intentional aspects of human communication and fear of committing the intentional fallacy.
 References Barthes, R.
 (1977).
 Introduction to the structural analysis of narrative.
 In S.
 Heath (Ed.
 and Trans.
), Image, Music, Text.
 N e w York: Hill and Wang.
 (Original work published 1966).
 Britton, B.
 K.
, & Eisenhart, J.
 F.
, (1993).
 Expertise, text coherence, and constraint satisfaction: Effects on harmony and settling rate.
 In Proceedings of The Fifteenth Annual Conference of the Cognitive Science Society.
 Hillsdale NJ: Eribaum.
 Chase, W.
, & Simon, H.
 (1973).
 The mind's eye in chess.
 In W .
 G.
 Chase (Ed.
), Visual information processing (pp.
 215281).
 New York: Academic Press.
 Chi, M.
 T.
, Feltovich, P.
, & Glaser, R.
 (1981).
 Categorization and representation of physics problems by experts and novices.
 Cognitive Science, 5, 121152.
 Cullers, J.
 (1981).
 The pursuit of signs: Semiotics, literature, deconstruction.
 Ithaca, N.
Y.
: Cornell University Press.
 Denhiere, G.
, & Rossi, J.
P.
 (Eds.
).
 (1991).
 Text and text processing.
 Amsterdam: North Holland.
 589 Dunbar, K.
 (993).
 How scientists really reason: Scientific reasoning in realworld laboratones.
 In R.
 J.
 Sternberg & J.
 Davidson (Eds.
), Mechanisms of insight.
 Cambridge MA: MIT Press.
 Eco, U.
 (1992).
 Interpretation and overinterpretalion.
 Cambndge University Press.
 Ericsson, K.
 A.
, & Chames, N.
 (1994).
 Expert performance: Its structure and acquisition.
 American Psychologist, 49 (8), 125141.
 Flower, L.
 (1988).
 The construction of purpose in writing and reading.
 College English, 50, 528550.
 Gibbs, R.
 W.
 Jr.
.
 Kushner, J.
 M.
, & Mills, W.
R.
 (1991).
 Authorial intentions and metaphor comprehension.
 Journal of Psycholinguistic Research, 20, 1130.
 New York: Plenum Press.
 Graves, B.
 (June, 1993).
 The communicative context of literary experts.
 F*aper presented at the Society for Text and Discourse.
 Boulder, CO.
 Graves, B.
, & Fredenksen, C.
 H.
 (1991).
 Literary expertise in the descnption of a fictional narrative.
 Poetics, 20, 126.
 Haas, C, & Flower, L.
 (1988).
 Rhetorical reading strategies and the construction of meaning.
 College Composition & Communication, 39, 167183.
 Ondaatje, M.
 (1992).
 The English Patient.
 Toronto: McClelland & Stewart.
 Patel, v.
, & Groen, G.
 J.
 (1991).
 The general and specific nature of medical expertise: A critical look.
 In K.
 A.
 Ericsson & J.
 Smith (Eds.
), Toward a general theory of expertise (pp.
 93125).
 New York: Cambridge University Press.
 Perfeni, C.
 A.
 (1989).
 There are generalized abilities and reading is one of them.
 In L.
 B.
 Resnick (Ed.
), Knowing, learning, and instruction: Essays in honor of Robert Closer (pp.
 307336).
 Hillsdale, NJ: Erlbaum, Scardamalia, M.
, & Bereiter, C.
 (1991).
 Literate expertise.
 In K.
 A.
 Encsson and J.
 Smith (Eds.
), Toward a general theory of expertise (pp.
 172194).
 New York: Cambridge University Press.
 Vipond, D.
, & Hunt, R.
 A.
 (1984).
 Pointdriven understanding: Pragmatic and cognitive dimensions of literary reading.
 Poetics , 13, 261277.
 Voss, J.
 F.
, Blais, J.
, Means, M.
 L.
, Greene, T.
 R.
, & Ahwesh, E.
 (1989).
 Informal reasoning and subject matter knowledge in the solving of economics problems by naive and novice individuals.
 In L.
 B.
 Resnick (Ed), Knowing, learning, and instruction: Essays in honor of Robert Closer (pp.
 217249).
 Hillsdale, NJ: Erlbaum.
 Wimsaat, W.
 & Beardsley, M.
 (1954).
 The intentional fallacy.
 In W.
 Wimsaat & M.
 Beardsley (Eds.
) The verbal icon: Studies in the meaning of poetry.
 Lexington: University of Kentucky Press.
 590 Combining Analyses of Cognitive Processes, Meanings, and Social Participation: Understanding Symbolic Representations James G.
 Greeno and Randi A.
 Engle School of Education, Stanford University, Stanford, CA 943053096 greenoScsli.
stanford.
edu, randi@csli.
Stanford.
edu Abstract We propose three analytic representations of collaborative problem solving.
 Activity nests, a generalization of goalsubgoal trees, represent functional decompositions of task activity into components, using nesting to indicate operations that satisfy task functions.
 Semiotic networks, an extension of semantic networks, represent meanings as refersto relations between symbolic expressions and other signifiers, and relations in situations and situation types, along with general relations between these meanings.
 Contribution Vagrants, an adaptation of contribution trees (Clark & Schaefer, 1989), represent how turn sequences collectively achieve task components.
 W e developed these representations to analyze how pairs of middleschool students constructed tables to represent quantitative properties of a simple physical device that models linear functions.
 Variations between activity nests of dififerent pairs support an explanation of activity in terms of attimement to constraints and to affordances and abilities, rather than following procedures.
 The semiotic networks support a hypothesis that task components are completed through accomplishing alignments of refersto relations.
which is a generalization of goal satisfaction.
 Similarities between the contribution diagrams support a general pattern that we call the turn structure of collaborative operations, in which task information is recognized and task operations are initiated, performed, and accepted.
 Interaction is organized into this structure in order to support mutually aligned intentions, understandings, actions, and agreements.
 Introduction W e hope that this paper contributes to two growing bodies of research and conceptualization.
 One of these is the effort to combine analyses of cognitive processes and social participation to understand reasoning and conceptual understanding.
 The other is the study of how people construct and interpret symbolic representations like diagrams, graphs, equations and (in the case of this paper) tables.
 Along with current investigators such as Hutchins (in press) and Lave (1988), and following theorists such as Bartlett, Dewey, Gibson, and Mead, we consider cognitive processes such as reasoning, understanding, and representing to be accomplished by systems that include humans interacting with each other and with available material resources, rather than as processes that only occur inside individual human minds.
 Although w e do not consider symbolic representations as a ubiquitous substrate for cognition, we consider constructing and interpreting symbolic representations as a distinctive aspect of human social/cognitive activity that is important to study and analyze, as do other investigators such as Hutchins (1995) and Ochs,Jacoby, and Gonzales (1994).
 T a s k a n d Participants W e studied pairs of seventh and eighthgrade students who were asked to construct tables to represent the quantitative properties of a simple physical apparatus, the winch (shown in Figure 1).
 Each of its two tracks held a block that was pulled along when the handle turned, winding a string around its spool.
 Spool sizes varied, determining distances per turn of 3,4 or 6 inches.
 A conventional yard stick was fastened next to each track allowing the students to determine the position of each block after various numbers of turns.
 A 123436761 to lll?m4m6inBI9a)21 22 23 f< 2̂ 26 2? 2g2<303m 33 »< / O I 2 3 4 5 » 7 t « 10 tM2 1314 IS 16 1711102021 22 23 24 2̂ 26 27 20 29 30 3132 33 34 Figure 1.
 Winch apparatus.
 We analyze students' work on the following item presented in a workbook: "Imagine that you had a 3spool on one track and a 4spool on the other track with both of the blocks starting at 0.
 Make a table that shows where the blocks would be after 0,1,2,3,4,5, and 6 turns.
 Use the device if you want to.
" This was the third item that the students worked on in the experiment In the two previous items they had been asked to write what they thought would happen when they turned the handle with the winch set up in different ways, then to turn the handle, and then to write what did happen and whether it was what they predicted.
 W e have used this schoollike task in these analyses because it is simple and well defined.
 Like cryptarithmetic, geometry proof exercises, and other tasks commonly used for cognitive analyses, the task of constructing a rowsbycolumns table has a simple structure that was followed by most of our participants^.
 Because the task mainly involves constructing symbolic representations, it affords analysis of their semantics.
 The participants' active conversations as they worked on solving the workbook items provide useful information about patterns of social participation in cognitive activity.
 Analyses and Findings For this task, the system we analyze includes the winch whose regularities are being represented, the workbook instructions which ask students to construct a table, space 'Two of the six pairs constructed unconventional representations for this item, but presentation of these important exceptions requires a longer p^ser.
 591 http://stanford.
edumailto:randi@csli.
Stanford.
eduleft in the workbook to do just that, and the students w h o are participating.
 Also in the system are key attunements to social practices like h o w to draw tables and represent quantities in them, h o w to use arithmetic operations to make inferences about numerical values, and ways of demarcating academic tasks to facilitate skilled performance.
 Our theoretical goal is to arrive at hypotheses about what the participants knew in order to act the way they did in accompUshing the task.
 W e consider knowing as being auuned to constraints (Barwise & Perry, 1983) and to affordances and abilities (Gibson, 1979) involved in activity.
 W e use the concept of schemata, in Bartlett's (1932) sense, as a theoretical construct that describes ways in which activity is organized.
 A schema, in this view, is attunement to a collection of interrelated constraints and affordance/abilities.
 W e have constructed three analytical representationsactivity nests, semiotic networks, and contribution treesthat allow us to analyze students' activity to include both traditionally "cognitive" and "social" aspects.
 W e discuss each representation in turn, focussing on the performance of two pairs of participants.
 These two pairs, whose aliases are Julie and Paula, and Brad and Geoff, constructed the tables in standard form shown in Figure 2.
 0 o j£ 0 & o c ^ O 106> if̂ d'̂ î  \Qr 5o T ^^ 1 1 IS 1̂  3z^.
l C o '' Figure 2.
 Tables by Julie and Paula (above) and by Brad and Geoff (below) Activity Nests and Hypotheses about Attunements to TaskContent Schemata Based on the videotaped records of the participants' performance and their transcriptions, we constructed representations of our hypotheses about how each pair structured this task, resulting in the activity nests shown in Figure 3.
 J3.
1.
 Und«r«tan(ing d««tgn«t*d winch condnont J 3 ^ Undarstanding and commrang to goal of miking tlw tcU* J2.
1.
 nudingand undtnunding innnjclioni and comrnnng to talk goal [j3.
3.
 Sattng up mnch oonditiom m tha ntuition | J34.
 R«fx«Mnling tricks with cdunn latMli J3.
& Oawr^g lin«« lor c d u m m J16.
 Rip(«Mnbng tî n* vaiabJi with cdumn liM JX7.
 Dtiwng bmi fa rowi JXt.
 Ripftimbng numturt al luini witi row libili M 3 .
 Sinng uptabli J2.
3.
 Rlpraaanling itarting block powtioni J3 t.
 For Iti* 4ipool bkick.
 datarmning thit diManoa par bim and poiition iflar 1 turn il 4 J3.
10.
 Raprasanting poalion of 4lpool block atlar 1 turn J3.
11 For Iha3ipoolbk>ck.
 datarmning tl)aldillanc» par tim and poirtiofi iftar 1 turn ii 3 J3.
12.
 RaprMaming ponDon of 3ipool bkxk attar 1 turn J2A.
 Datarmning diitancaa par turn and rapraaanting bkxk poaitona aftarl turn J3.
13.
 Inl and rap poi of 4ipool block aftar 2 turns J3.
14.
 Inf and rap poa of 3apool bkx> aftar 2 U m i J2.
6, Infarnnoand rapriaanting block ponDons aftar 2 tumt J.
I.
MAinga tabia of block poartion 3ipool spool and 4spool.
 both start at 0; 0, 1.
 6 turns.
 J3.
1S.
 Inf and rap poa of 4apool bk>ck aftar 3 turns J3.
16.
 Inf and rap poa of 3apool bkick attar 3 turns ingand raprasanting bkx* postons aftar 3 tunns J3.
17.
 Inf and rap poa of 4apoot block attar 4 turns J3.
1S.
 Inf and rap poa of 3spool block aftar 4 tjms J2.
7.
 Infarnnoand rapraaanting Dlodt pontons aftar 4 hims J3.
1©.
 Inl artd r»p po«.
 ol 3«pool block atttr 5 tjm« J3.
20.
 Inl and rep pos ot 3spool block after 6 Lima J3.
21.
 Inf and rap poa of 4spool bkxrk aflar S turns J3.
22.
 Inf and rap poa of 4apool bkxk attar 6 turns J2.
6.
 Infarring and rapraaantingbkKk powBona attar 5 luma and attar 6 turns J2.
«.
 Confirming accuracy of tha rapraaantation [B3.
1 • Undarstanding dasignatad winch condition>| ̂ ^ ̂  Reading and B3.
2.
 Racogmzing that spoolsize conditions are true in tna situation B3.
3.
 Undafftanding and commning to goal of n'ukjng the tabia understancing ins^ucttona and committing to task gosi |B3.
4.
 Setting tjp winch conditiorw in the tituationj B2J.
SettnguptaUes B2.
3.
 Raprasen«ng itartng bock poaidons 83.
11.
 Moving Uocks by turning handle once 83.
12.
 Representing position of 3spool Hock after 1 turn 83.
13.
 Representing posJUon ot 4spool block after 1 turn 82.
4.
 Determning and representng Uock postttons after 1 turn 83.
14.
 Moving blocks by turning handle or>ce 83.
16.
 Representing position ofSspool block after 2 tirna B3.
16.
 Representing position of 4spool btock ̂ mr 2 ttjrns 83.
17.
 Recognizing tnai distance* per turn are 3 and 4 83.
11.
 Interpreting n>«aning of lymboli on spools ai distance per turn 82 J.
 Determning and representng block posjtions after 2 lums B.
I.
 Making a table of Uodt posjtions 3spool and 4spool.
 both start al 0.
 0,1.
 6 turns B3.
1».
 Moving blocks by turnino handle once 83.
20.
 Representing position 0(3spool block after 3 turns 83.
21.
 Representing position ol4spoot Wock after 3 turrw 83.
22.
 Confirminq consistency of positions with pattern 82.
6.
 Determning and representng blodi positons aflar 3 turns B3.
23.
 Moving blocks by turning handle once B3.
24.
 Confirmr^g cDr̂ sisterv:̂  ̂* powOorw with pattern B3.
26.
 Representing ponton ol 3spool bock after 4 turns B3.
26.
 Representing position of 4spool block after 4 turns B2.
7.
 Deterrrining and representng block posjttons attar 4 tjrns 83.
27, Moving blocks by tinning handle or>ce B3.
2B.
 Infeaing block positions after 5 turns 83.
29.
 Repr»«sniing position of 3spool Hock aher 5 ttjrne B3.
30.
 R»pras»niing positton of 4spool Hock atlw 5 turns 82.
t.
 Determning and representng block Dositons ah»r 5 turns 83.
31.
 Infemng Hock positions after 6iL#na 83.
32.
 Representing po&ibon of 4spool Hock after 6 turns B3.
33.
 Moving H o c M by tLrning handle once B3.
34.
 Representing positon of 3spool Hock after 6 turns 82.
9.
 Determning and representng bloci(j30Sitons after 6 turns Figure 3.
 Activity nests for Julie and Paula (above) and Brad and Geoff (below) 592 http://J3.
11In these diagrams, functional relations are shown using containment.
 Each rectangle labels a function which can be achieved by performing the operations contained in the rectangle within it.
 For example, if the four operations labeled J3.
9  J3.
12 are performed, the function labeled J2.
4 is achieved.
 In terms of constraints, in a situation where the contained operations are performed, the containing function is satisfied.
 W e hypothesize that participants were attuned to those constraints of functionsatisfaction that correspond to the containment relations of their activity nests.
 However, unlike standard goalsubgoal decompositions w e do not assume that participants necessarily set explicit goals unless there is evidence of this in the data.
 Based on the structure of the activity nests, w e hypothesize that the students* task activity was organized partly by their attunement to a practice of completing school assignments, which includes reading instructions, understanding the kind of information that is to be represented, obtaining that information, and constructing a representation of it in a conventional form.
 In addition, to understand the instructions, they had become attuned to constraints and affordance/abilities of operating the winches so they could interpret references to spool sizes, starting positions, and numbers of turns.
 They also were attuned to constraints and affordance/abilities of the representational form of tables.
 Our account of activity in terms of attunements to constraints and affordance/abilities, rather than procedures, is supported by the activity nests, which show differences between pairs of students.
 O n e kind of difference was in the ordering of components; most pairs worked row by row, as did Julie and Paula and Brad and Geoff; another pair completed the table column by column.
 In this example, the pairs differed in the ways they obtained the information they needed about positions of the blocks.
 Julie and Paula began by determining the distances per turn of the two spools by measuring their circumferences, and then inferred the positions of the blocks throughout, apparently using arithmetic addition.
 Brad and Geoff, on the other hand, began by turning the handles to determine the block positions empirically, then included arithmetic inference along with empirical observation when they recognized the pattern of constant numerical additions.
 Although procedural descriptions of these performances could be constructed, the variety of specific procedures needed would be very large.
 Therefore, it is more plausible to hypothesize that all the students were attuned to the general requirement of determining the block positions of a type of event in which the handles were turned with the specified spool sizes and starting positions, and were differentially attuned to the consuaint of equal additions of the positions, and to the affordances of determining distances per turn by measurement and of performing handle turns to determine block positions.
 Semiotic Networks and Hypotheses About Attunements to Representational Schemata Semiotic networks are an extension of semantic networks.
 They represent how participants consUuct and use symbolic, indexical, and iconic signifiers (following Peirce) to refer to states of affairs of situations and to properties and relations of situation types.
 Like semantic networks, our semiotic networks also include relations between meanings.
 A simple example of a semiotic network is shown in Figure 4.
 The notation is adapted from sittiation theory (Devlin, 1991).
 Each expression between double angle Ixackets is an infon, a basic unit of information.
 A n infon includes the name of a property or a relation, followed by symbols that indicate arguments.
 Nonitalicized arguments indicate specific entities in the situation; italicized arguments are parameters.
 States of affairs involving signifiers are in ellipses.
 Infons those signifiers refer to are in rectangles.
 The lines between ellipses and rectangles indicate refersto relations.
 •csymbol.
 "both Blarttng at h bIcKka ****v ', inatructton taxt»»^ C<caymbol.
 "O' lablo/^^S.
 column=ned Bk>ck, j row=0> ^ ^ ^ <«»ymbol, "O' column=Blua row=:0>> r T i I b i ? ^ BlocK.
 ^ rl «1urnin(^ar»dlB, rf *•» <<Btartl(mo, rf, T O » )<<poBitlon, bluoblock.
 0, 70 »4— «poa(tlon.
 redblock, 0, /O » |— Zo —1| «posilion.
 bluoblock.
 O, 1 »•=1 <.
cpo»llion.
 red block.
 O, '/ »>»— «pOBition.
 redbiock.
 O, ta»>hidoK, zoro«nd7*'**v r.
 tracK=red } .
K»  " " ^ C « i n d e x , reroondT^Sv rulor.
 lr«ck=bluo ) btock» y Figure 4.
 Refersto relations consttiicted or used by Julie and Paula in Turns 3538.
 Figure 4 represents meanings of signifiers concerned with the starting positions of the blocks.
 The referent infons in Figure 4 include states of affairs that held in the specific situation, ao, as well as properties of situation types, 1 0 and II.
 The instruction text included the phrase, "both blocks starting at zero.
" Julie and Paula adjusted the positions of the blocks to agree with that description, so that the positions that "zero" referred to were indicated by the ends of the rulers beside the U^cks.
 Figure 4 shows that this printed phrase and the ends of the rulers were interpreted as referring to states of affairs in ao, the positions of the blocks at the time of Julie and Paula's interaction, the time called "ta.
" The tokens of " 0 " that Julie and Paula wrote in the top row of their table also referred to these same states of affairs.
 The students interpreted their tables as referring to properties of the general type of situation in which the handle was turned with the specified conditions.
 The situation type II has an event of turning the handle, with starting positions of zero, and the symbols were interpreted as referring to the type infons of those starting positions.
 W e include 1 0 for completeness.
 Affordances are relations between situation types, so the actual situation, ao, was related to the situation type, II, by an affordance between 10, the type of ao, and II.
 From creating these semiotic networks, and seeing the correspondence of referents of the various signifiers, w e hypothesize that semiotic alignment plays a crucial role in reasoning, especially in the consuiiction of symbolic representations.
 In this example the alignment, which included a phrase in the instructions, indices in the situation, and symbols that the 593 students constructed, provided the basis for their symbols being correct in the interpretation that we and they adopted.
 The other numerical symbols provided more complex examples.
 For some participants, including Julie and Paula, the situation when they wrote numerical symbols did not include turning the handle.
 W e hypothesize that the situation type II was represented by the students with mental simulations that provided some of the needed information, such as the direction and continuity of motion.
 The symbols referred both to the quantitative positions of blocks and to numbers within the arithmetic system that includes the operations of addition and multiplication.
 Aspects of the situation type, II, were also represented iconically.
 For example, the temporal ordering of turns in the situation is represented in the table by the spatial ordering of rows from the top to the bottom.
 Further analysis would include relations between the meanings of these symbols, such as that the several turns are parts of the event of turning the handle six times, and that each position is a displacement from the previous position of the same block.
 Contribution Diagrams and Hypotheses About Attunements to Interactional Schemata Figure 5 shows an example of a contribution diagram, along with the transcription of Julie and Paula's activity during the same four interactional turns.
 Mis.
 Patija J2J 35.
 Starting at zcto 37.
 Yeah, so this would be zero [wrote " 0 " in fir St row of both columrvi] 36.
 Ok, started, they're both at zero, is that what they're saying? 38.
 Ok, zero J2J JulK PMik Mil 35 inlialtopantion 36 »gm»wthrtmntiorvp»rformop»niion(inl) 37agr9«wihink>malk>npaiiannoperaiion(mat) X tgnewthofMmlionmiuk J2.
3 Mil Figure 5.
 Julie and Paula, Turns 3538, dialogue and contributions.
 The transcription and contribution diagram are crossreferenced with that pair's activity nest.
 In the transcription, bold symbols indicate the beginnings and ends of activities that accomplished the designated task components.
 A symbol on the left marks the beginning, and a symbol on the right marks the end.
 In this case, the activity accomplished the component of representing starting block positions, labelled J2.
3 in Figure 3.
 The contribution diagram presents our analysis of the way that these turns were interrelated in order to accomplish task components.
 W e have adapted a method developed by Clark and Schaefer (1989) for this.
 In our use of the method, turns are grouped according to the activity components they achieved.
 Julie and Paula's Turns 3538 accomplished the operation of determining that the starting positions were zero and entering symbols representing that in the table, Operation J2.
3.
 Julie's Turn 35 initiated this operation.
 Paula's Turn 36 registered the information that was to be represented.
 Julie's Turn 37 completed the action of representing the starting positions by writing the symbols.
 Paula's Turn 38 expressed agreement and completed the contribution.
 The students' statements provide evidence lat some of the refersto relations in Figure 4.
 Paula's 'They're both at zero" apparently referred to the positions of the blocks in the situation, and Julie's "So this would be zero" apparently referred to the values to be wriuen in the table, which referred to the situation type involving turning the handle.
 A more extensive and complicated example, by Brad and Geoff, is the transcription shown in Figure 6 and the conuibution diagram of Figure 7.
 As the diagram indicates.
 Brad and Geoff were working on the component we labelled B2.
4, determining and representing block positions after one turn.
 They had moved the blocks by turning the handle once and recorded the symbol" 3" in the table for the position of the 3spool block.
 In Turns 4348, Brad and Geoff identified the position of the 4spool block after one turn as 4 1/8, and Brad recorded that, corresponding to Operation B3.
13.
 They began Operation B2.
5, determining and representing the positions after two turns, with Brad's initiating Turn 49.
 Geoff turned the handles and Brad adjusted one of the handles so it had made one complete revolution, finishing Operation B3.
14.
 In Turn 52, Brad recognized the positions as 6 and 8 and recorded them.
 Geoff's Turn 53 was apparently interpreted by Brad as agreeing with his statement and representation of the position of the 3spool block.
 In the light of Turn 60, we interpret this as the beginning of a presentation of the inference that the positions increased by constant increments of three and four inches, Operation B3.
17.
 However, that operation was not established in their common ground, so we indicate it in parentheses.
 Brad's Turn 55 was a signal to jffoceed to the third handleturn.
 B2.
6, but Geoff hesitated, saying,"So.
" W e believe this was a continuation by Geoff of considering the pattern of constant additions.
 It seems likely that it also involved a question or disagreement with the symbol" 4 1/8"," which had been written in Brad's Turn 48.
 Geoff apparently interpreted it as a question of the more recent operation of writing " 6" " and " 8"," and reiterated those states of affairs.
 Geoff's Turn 58 agreed with that, completing their activity on Operations B3.
15 and B3.
16.
 Brad's response in Turn 59 was to emphasize that they had finished the second handletum, and he repeated his initiation of the third handletum activity in his Turn 60.
 Then in his Turn 61, Geoff stated the pattern of increases of the symbols in the table,which we consider as performance of an operation of stating an infon—the patternas well as presenting disagreement with the symbol" 4 1/8"," thus reopening Operation B3.
13.
 Brad agreed with the pattern in his Turn 62,which established the pattern in their common ground, completing Operation B3.
17.
 Brad then stated the change of the 1tum position to "a regular four," and erased the "1/8" symbol from the table, in Turn 63.
 Geoff agreed 594 Biad QsaH B3.
13 43.
 And this one [leaned over to see block positions] is at 45.
 Four and, wait, no.
 47.
 [pointing, counting division marks on yard stick] One, two, three, four  that's right.
 That's <> about <> 48.
 [wrote"4 1/8"" in the 4spool table) mS.
 B3.
14 44.
Four and an eighth.
 46.
 Yeah, four and an eighth.
 49.
 Ok, do it again.
 51.
 This one [adjustedposition of one handle] good enough 50.
 Another turn, [sat down; turned handles] B3.
14 B3.
15.
 B3.
16 52.
 Six and eight, [wrote "6"," and"8".
"] (B3.
17) 53.
 Six [pointed to red block] 54.
 Yeah.
 (B2.
6) 55.
 Ok, do it again.
 (B3.
17) 56.
 So 57.
 [pointing to blocks) That one's at six, this one's at eight.
 59.
[ I] abeady didjt; 58.
 Ok, you did it [already] 83.
15, 83.
16 (8161.
 60.
 Do it again.
 83.
17 62.
 [I know, nnh] 63.
 This one should just be a regular four.
 Or else it doesn't make any sense, [erased "J/8" in previous entry ] 61.
 [boking at tables] Three, six.
 The fourspool would make this one [poirUed to 4spool column] [go up by four inches.
] 83.
17 64.
 Right 83.
13, 82 J 83.
18 65.
 We read it wrong.
 Ok, so the spool is the amount of inches it goes up.
 83.
18,82.
5 Figure 6.
 Transcription of Brad and Geoff's Turns 4365.
 Br*d OMlt 43 tnitat»Cf>»r»ton 0*f1ormootrttiar{mfi awfiWfiwritgfiYtM fiimffnnifitanfia/f 47 • 4«.
 qum1lonftQrmv*9>optr»tionT99Ult gff»mwritflnr'"iii 4« inteutoDtruon SO tarm/t»ncrm<Kitrilontmu) SI S2qumHonMarm^lhofiwattonftult p«r1ormaf>«rtllcn(inl*<n»ti (p*f1Ofm<3i>«raoon{inrn/aQr0*wrtfice«ralianr»3ult 5455adtno^»aga»Qr»0Tnnt (mitutctMttant OnWtt ODtratanUaMttanooerationtnUI fSMn<x>»'atonr»»ilt agr90mt)Of)»rat)onT»9u/l 59 .
 60.
 racogninaara^ment (inltiat0'CparatiOf)) disagraamthoparatonrasuH/fMrlormoparatiarOnf) 62 .
 63 agr»amt)op»rabonr93uit par1ofTnop«abcn(inl*mati agra€mt\op«rabonra9uH — B3 17) [>ariormoparabcn(inr) B3 14| B3 1S B31« B317) B3.
17| 82.
5 82 6) B2 6) |B11 Figure 7.
 Contributions by Brad and Geoff in Turns 4365.
 with Brad's action in Turn 64, completing their activity Operations B3.
13 and B2.
3.
 In Turn 65, Brad recognized that the numerals stamped on the spools referred to their distances per turn.
 Based on the contribution diagrams for all the pairs, a general interactional pattern, shown in Figure 8, emerged.
 As its title indicates, w e view this pattern as a sequential structure that organizes interactional turns whenever a collaborative group is performing a joint operation.
 To interpret this schematic structure, consider rightbranching links as obligatory and leftbranching hnks as optional.
 A contribution that fit this pattern always included performance of an operation, which could be material or merely informational.
 W h e n an operation was performed, the participants needed to agree on its performance and result for it to be included in their task solution.
 If one of the participants questioned or disagreed with the performance or result, there was a negotiation about it.
 A s a result of the negotiation, the initial performance and result of the operation could be agreed to, there could be agreement to some modification of the operation or its result, or there could be agreement to not perform that operation, at least at that time.
 Before an op)eration was performed, it could be initiated by one of the participants, which could be done by proposing the operation or by indicating in some less direct way that the operation would be appropriate.
 If the initiation of an operation was agreed to, the participants established a shared intention for that operation to be performed.
 If a participant questioned or disagreed with an initiation, they negotiated before the operation was performed, which could lead to agreement 595 Perform Initiate / Agree Negotiate Agree Negotiate Figure 8.
 Turn structure of collaborative operations.
 to perform the operation, agreement to perform some modified form of the operation, or agreement to not perform or postpone that operation.
 This pattern provides an effective way of satisfying the constraint that the participants should be aligned in their intentions and actions and that they should mutually agree to the products of their activity.
 Our participants presented questions or disagreements frequently, with little mitigation (cf.
 Linde, 1988).
 The data are consistent with the hypothesis that participants constructed shared perspectives on the task and expected each other to indicate that they were not aligned whenever the other's behavior did not fit with constraints they were attuned to.
 The participants also respected a constraint of relevance, in quite a strong form.
 Nearly all of the contributions were organized around performance of taskrelevant operations.
 Sperber and Wilson (1986) pointed out that contributions to conversation are relevant in a general sense of applying to a context that the participants share.
 In this activity, apparently, the participants' shared context included a commitment to limit their conversations mainly to the assigned tasks.
 W e expect that this constraint resulted from—or at least was reinforced b y — the presence of an adult researcher and a videocamera, which created a situation of closely observed and supervised school activity.
 Whatever its cause, the participants' close adherence to a constraint of task relevance produced patterns of interaction in which nearly all the activity was functionally related to operations for making progress on the task.
We do not believe that this relation between cognitive tasks and social interaction is general.
 Indeed, in other studies (Engle & Greeno, 1994) interpersonal relations also crucially shaped how the task was carried out, and we expect to find that as well when we apply these analyses to performance by these participants on less welldefined problems where they wrote equations for the first time.
 Conclusions The representations of activity nests, semiotic networks, and contribution trees provide evidence about the details of both the cognitive processes of accomplishing the tableconstruction task and the social participation through which the task was carried out Because of explicit Unkages between these analytic representations, we can begin to examine how cognitive and social aspects of collaboration are related.
 Our analysis resulted in three main findings.
 First, students' activity can best be explained in terms of auunements to constraints and to affordances and abilities that form schemata of school assignments, forms and meanings of symbolic representations, causal and quantitative properties of the physical device, and patterns of collaborative activity.
 Second, sttidents completed components of the table construction task through accomplishing alignments of refersto relations involving signifiers in the instructions, on the winch, and in their table, which referred to properties and relations of the material system of the winches and the conceptual system of numbers and arithmetic.
 Third, the participants' structure of turn taking was organized to support mutually aligned intentions intentions, understandings, actions, and agreements relevant to task components.
 W e believe that the methods of analysis and representation that we have developed here will be applicable in more complex situations, but significant extensions may well be needed.
 Acknowledgements This research was supported by a grant and a graduate fellowship from the National Science Foundation and a grant from the J.
 McKeen Cattell Fund.
 Others who conttibuted to this research include Joyce L.
 Moore, Barbara Katzenberg, Laura Kerr, Richard Mander, and Rory Mather.
 References Bartlett, F.
 C.
 (1932).
 Remembering.
 Cambridge, U K : Cambridge University Press.
 Barwise, J.
, & Perry, J.
(1983).
 Situations and attitudes.
 Cambridge, M A : M I T Press.
 Clark, H.
 H.
, & Schaefer, E.
 F (1989).
 Contributing to discourse.
Cô /i/7/vg Science, 13, 259294.
 Engle, R.
 A.
 & Greeno, J.
 G.
 (1994).
 Managing disagreement in intellectual conversations.
 Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp.
 266271) Hillsdale, NJ: Eribaum.
.
 Gibson, J.
 J.
 (1979).
 The ecological approach to visual perception.
 Boston: Houghton Mifflin.
 Hutchins, E.
 (1995).
 Cognition in the wild.
 Cambridge, M A : MIT Press.
 Hutchins, E.
 (in press).
 H o w cockpits remember their speeds.
 Cognitive Science.
 Lave, J.
 (1988).
 Cognition in practice.
 Cambridge, UK: Cambridge University Press.
 Linde, C.
 (1988).
 The quantitative study of communicative success: Politeness and accidents in aviation discourse.
 Language and Society, 17, 375399.
 Ochs, E.
, Jacoby, S.
, & Gonzales, R (1994).
 Interpretive journeys: H o w physicists talk and û avel through graphic ŝ diCt.
 Configurations, 2, 151171.
 Sperber, D.
, & Wilson, D.
 (1986).
 Relevance: Communication and cognition.
 Oxford, UK: Basil Blackwell.
 596 Complexity of Structure Mapping in H u m a n Analogical Reasoning: A P D P Model Graeme S.
 Halford Department of Psychology University of Queensland Brisbane 4072 Australia gshOpsych.
psy.
uq.
oz.
au William H.
 Wilson School of Computer Science & Engineering University of New South Wales Sydney 2052 Australia billw@cse.
unsw.
edu.
au Matthew M c D o n a l d Department of Psychology Murdoch University Perth 6150 Australia mafm@cs.
uwa.
oz.
au Abstract A PDP model of human analogical reasoning is presented which is designed to incorporate psychologically realistic processing capacity limitations.
 Capacity is defined in terms of the complexity of relations that can be processed in parallel.
 Relations are represented in the model by computing the tensor product of vectors representing predicates and arguments.
 Relations in base and target are superimposed.
 Based on empirical evidence of capacity limitations, the model is limited to processing one quaternary relation in parallel (rank 5 tensor product).
 More complex relations are processed by conceptual chunking (receding to fewer arguments, but with loss of access to some relations) or segmentation (processing components of the structure serially).
 The model processes complex analogies, such as heat flowwater flow, and atomsolar system, while remaining within capacity limitations.
 Introduction The growth of parallel processing models of human analogical reasoning raises the question of the complexity of structures which humans can map in parallel.
 A good case can be made for parallel processing in analogies (Holyoak & Thagard, 1989) but it is implausible that the most complex analogies can be processed entirely in parallel.
 The Rutherford analogy between the hydrogen atom and the solar system (Centner, 1983; Holyoak & Thagard, 1995) entails a very complex set of relationships, and it is far from clear that humans process the entire structure in parallel.
 If computational models are to be psychologically realistic, a means must be found for quantifying the complexity of structures that can be processed in parallel.
 It is also necessary to explain how problems that exceed this capacity are processed.
 The Structured Tensor Analogical Reasoning (STAR) model was designed to incorporate realistic human information processing capacities into a P D P model of analogy.
 An earlier version of the model (Halford, Maybery, O'Hare, & Crant, 1994) did not handle problems that exceeded human capacity to process structures in parallel.
 In this paper we present extensions of the model which introduce a number of new processes, and handle more complex tasks.
 An analogy is a structurepreserving map from a base or source to a target (Centner, 1983).
 The structure of base and target are coded in the form of one or more relations.
 In the simple proportional analogy cat:kitten::horse:foal the base would be coded as MOTHEROF(catJdtten) and the target as MOTHEROF(horse,foal).
 More complex analogies might comprise ternary and higher rank relations, or they might be coded as a higherorder relation which provides an overarching structure, and which has firstorder relations as arguments.
 In general, a firstorder relation has objects as arguments, and a secondorder relation has firstorder relations as arguments, and so on.
 Capacity and complexity The complexity of structures in base or target can be quantified by the complexity of relations, which may be defined by the number of arguments.
 A binary relation (e.
g.
 B I G C E R  T H A N ) has two arguments, and a ternary relation has three arguments (e.
g.
 L O V E  T R I A N G L E is a ternary relation, and has arguments comprising three people, two of w h o m love a third).
 Each argument can be instantiated in more than one way.
 For example, each argument of B I G G E R  T H A N can be instantiated in an arbitrarily large number of ways (e.
g.
 BIGGERTHAN(horse,mouse), BIGGERTHAN(whaIe,dolphin) etc.
).
 Consequently, each argument provides a source of variation, or dimension, and thereby makes a contribution to the complexity of the relation.
 In general, an Nary relation Rn(ai,a2,.
.
.
.
,an) is a subset of the cartesian product SixS2x.
.
.
xSn).
 It is the set of ordered ntuples {(ai,a2,.
.
.
.
,an) I R(ai,a2 ,an) is true}.
 A n Nary relation can be thought of as a set of points in Ndimensional space.
 Relations of higher dimensionality (more arguments) impose higher processing loads.
 W e have proposed (Halford et al.
, 1994; Halford & Wilson, submitted) that processing capacity of higher cognitive processes can be quantified in terms of this dimensionality concept.
 Assessment of the working memory literature, plus some specific experimentation, has led to the conclusion that adult humans can process a maximum of four dimensions in parallel, equivalent to one quaternary relation (Halford, 1993; Halford, et al.
, 1994; Halford & Wilson, submitted).
 Structures more complex than this must be processed by either conceptual chunking or segmentation.
 Conceptual chunking is recoding a concept into fewer dimensions.
 For example the ternary relation R(a,b,c) can be chunked to a binary relation R'(a,b/c) by combining b,c into a single argument.
 The relation between a and b/c can be computed, but the relation between b and c cannot, because they are processed as a single argument.
 R(a,b,c) can also be chunked to a unary relation, R"(a/b/c) in which a,b,c constitute a single dimension, and relations between them cannot be computed.
 A relation can also be chunked 597 http://uq.
oz.
aumailto:billw@cse.
unsw.
edu.
aumailto:mafm@cs.
uwa.
oz.
auto a single entity, in which predicate and argument(s) are not distinguished.
 In our tensor product representations, this is represented by a single vector.
 Chunked representations can also be unpacked so as to return to the original relation.
 The chunking principles are: (1) a chunk functions as a single entity, predicate or argument, in a relation.
 (2) no relations can be accessed between items within a chunk.
 (3) relations between the chunk and other items, or other chunks, can be represented.
 Segmentation is decomposing tasks into steps small enough not to exceed processing capacity, as in serial processing strategies.
 The Model An Nary relation, R(ai,a2 an) is a binding between a relation symbol or predicate, R, and the arguments ai,a2 ,an In the S T A R model, relations are represented as the tensor product of vectors representing the predicate and each argument.
 Thus, given a set of unary relations Rl on a set A, the relations are represented in a vector space V r i and the members of A in a vector space V ^ , a relational instance rl(a) (i.
e.
 "rl is true of a") where rl e RI and a e A is represented by a tensor Vri)®Va in the tensor product space V r i ® V a .
 Similarly, if R 2 is a set of binary relations on A x B , then the representation space for these binary relations would be denoted V r 2 ® V a ® V b , and a particular relational instance r2(a,b) by the tensor Vr2®Va®vb.
 This notation extends naturally to any number of arguments  for example, the quaternary relational instance r4(a,b,c,d) would be represented by Vr4®Va®vb®Vc®vd.
 Conceptual chunking is implemented by convolution of the vectors in the tensor product, in the limiting case to a single vector.
 Segmentation is implemented by processing one tensor product representation at a time.
 The relations in base and target are superimposed on the same tensor product, as shown in Figure lA, and the mathematical treamient is given in Halford et al.
 (1994).
 Simple proportional analogy The representation of base and target in the analogy cat:kitten::horse:foal is shown in Figure lA.
 There is a vector representing the predicate M O T H E R  O F , and other predicates such as L O V E S , F E E D S , P R O T E C T S , L A R G E R  T H A N .
 The first arguments of both base and target are superimposed on one vector, and the second arguments on another, as shown.
 Predicateargument bindings other than those essential to the problem are represented (e.
g.
 LARGERTHAN(mare,rabbit)) to demonstrate that the model can select the appropriate solution and avoid irrelevancies.
 The solution of the problem cat:kitten::mare:? is presented schematically in Figure IB.
 In the first step, the input is cat:kitten and the output is all the predicates that have "cat" and "kitten" as arguments (a "predicate bundle").
 That is, the output represents the set { M O T H E R  O F , LOVES, FEEDS, PROTECTS, LARGERTHAN}.
 Tensor Memory r ^ kitten predicate bundle MOTHER_OF,etc.
} horse—• Tensor Memory argument bundle {foal} predicate bundle {MOTHER_OF,etc.
} feeds, protects, motherof, loves, largerthan foal,kitten cat, horse Figure lA: Tensor product repressentation Figure IB: Processing of a simple analogy.
 In the second step, this predicate bundle is used as input, together with "mare".
 The output is an "argument bundle" representing all possible solutions.
 The possible solutions can be recognized by computing the inner product of vectors representing each possible solution with the output vector.
 Alternatively, it can be done by an autoassociation technique (Chappell & Humphreys, 1994) which selects the most appropriate solution.
 Notice that "foal" is not the only valid solution.
 For example, "rabbit" is a syntactically correct solution because cat:kitten::mare:rabbit is a valid analogy.
 The base can be represented as LARGERTHAN(cat4dtten) and the target as LARGERTHAN(mare jabbit).
 The preferred solution "foal" can be justified on a number of grounds however.
 One is the salience of predicates.
 M O T H E R  O F is a more salient predicate relating "cat" and "kitten" than is L A R G E R T H A N , because of the stronger associations between terms such as "kitten" and the motherinfant relation.
 Second, the 598 solution "foal" fits more predicates than does "rabbit".
 The solution "foal" is consistent with all the predicates MOTHEROF(mare, foal), LOVES(mare, foal), FEEDS(mare, foal), PROTECTS(mare.
 foal).
 L A R G E R THAN(mare, foal).
 However "rabbit" fits only one predicate: LARGERTHAN(marejabbit).
 The model can use both salience and the number of predicates consistent with a solution to produce an analogy corresponding to the one which we would find most satisfying.
 Therefore the model acknowledges that more than one solution is syntactically consistent, but can distinguish between solutions according to their plausibility.
 Analogies with higher rank relations More complex analogies can be processed.
 Analogies based on ternary relations can be processed using Rank 4 tensor products, V r ® V a ® V b ® V c .
 A n example would be when premises representing two asymmetric binary relations are mapped into a conventional ordering schema, such as top to bottom.
 The premises T o m is happier than John, John is happier than Mark might be mapped into a topdown schema in which T o m is in the top position, John in the middle, and Mark in the bottom.
 The base is MONOTONICALLYHIGHER(top,middle,bottom) and the target is M O N O T O N I C A L L Y  H A P P I E R ( T o m John,Mark).
 This can be represented by a Rank 4 tensor product, as shown in Figure 2.
 Concepts based on quaternary relations (e.
g.
 proportion a/b = c/d) can be represented in Rank 5 tensor products in analogous fashion.
 The representation and processing of other complex concepts in the architecture of this model are discussed elsewhere (Halford, 1993; Halford & Wilson, submitted).
 These representations have two important properties, which we call flexibility and derivation.
 Flexibility means that there must be no fixed input or output.
 To represent the relation Rn(a|,a2,.
.
.
,ajj), it must be possible to use the predicate and any n1 arguments as inputs, and compute the remaining argument as output.
 Similarly, it must be possible to retrieve the predicate, given the arguments as input.
 Both these functions were illustrated with the simple proportional analogy discussed above, and they are important to analogical reasoning generally.
 Derivation means that it must be possible to derive lower dimensional relations.
 Given a representation of the nary relation Rn(aj,a2,.
.
.
,a_), it must be possible to derive all the (n1)ary induced relations R ^'^\'f^^^y\+i •••.
2„), all the (n2)ary induced relations R •• (aj,.
.
.
,'aj i,aĵ j .
.
.
.
aj,â j .
.
.
,a^), and so on.
 This property is also used in ansiloglcal reasoning.
 Complex Analogies  Serial and Parallel Processing The main focus of this paper is analogies which are too complex to be completely represented in parallel.
 W e will consider two examples, the analogy between waterflow and heatflow, and the Rutherford analogy between the structure of the solar system and the structure of the hydrogen atom (Falkenhainer, Forbus, & Gentner, 1989).
 A Premises: T o m is happier than John.
 John is happier than Mark.
 base schema top above ̂  middle abovq^ bottom 1 J ^^,, ^ happier (problemTom — — — | representation) '*̂ "̂ John happier than t Mark B monotonicallyhigher monotonicallyli middle John bottom Mark Figure 2.
Mapping of ternary relation into ordering schema (A) with tensor product representation (B).
 The water flowheat flow analogy is shown in Figure 3.
 The figure shows that waterflow is caused by pressuredifference.
 The component relations are GREATER(PRESSURE(vesselA)J>RESSURE(vesselB)) and FLOW(vesselA,vesselB,water,pipe).
 There is a higherorder relation C A U S E which has pressuredifference and waterflow as arguments.
 The way this complex structure can be represented in the model without exceeding processing capacity limitations is shown in Figure 3.
 Pressuredifference and waterflow are each chunked to a single vector, by convolution.
 Cause is then represented as a binary relation, with the chunked representations of pressuredifference and waterflow as arguments.
 The model can actively represent the causal relation between pressuredifference and waterflow, but cannot simultaneously represent the structure of the pressuredifference and waterflow concepts, because these are chunked into single entities.
 These must be unpacked in order for their constituent structure to be represented.
 However while the constituent structure of pressuredifference and waterflow are being actively represented, the overarching causal relation between them cannot be.
 599 CAUSE GREATER FLOW (vessel A.
 vessel B, water, pipe) PRESSURE (vessel A) PRESSURE (vessel B) LIQUID (water) FLATTOP (water) GREATER DIAMETER (vessel A) DIAMETER (vessel B) CAUSE (pressuredifference, waterflow) GREATER (pressurevesselA, pressurevesselB) FLOW (water, vessel A, vessel B, pipe) Figure 3.
 Representation of waterflow.
 The Rutherford analogy is represented, as in the model of Falkenhainer et al.
 (1989) in Figure 4.
 The orbital motion of a planet around the sun is caused by the difference in mass between planet and sun, and by the gravitational attraction between planet and sun.
 In analogous fashion, the orbital motion of an electron around the nucleus of an atom is caused by the difference in mass and the electrostatic attraction of the bodies.
 As with waterflow and heatflow, the structures are represented in a hierarchy in which higherorder predicates have chunked lowerorder relations as arguments.
 The hierarchy has more levels however than in the case of waterflow and heatflow.
 Distracting irrelevant relations, such as the temperature difference between sun and planet, are also represented.
 The model works by matching relations in base to relations in target one at a time, staying within the limitation of not representing more than one quaternary relation in parallel.
 The model can move either up or down the tree looking for matches, which are accumulated in a match matrix, and checked to ensure that the uniqueness and correspondence properties of structure mappings are maintained.
 The uniqueness property means that mappings are onetoone.
 The correspondence property means that if a predicate P in structure 1 is mapped to a predicate P' in structure 2, the arguments of P are mapped to the arguments of P', and vice versa.
 Matches which violate these properties are rejected.
 Each match that is made adds an increment to a structural evaluation score, which is designed to assess the consistency of the matches made.
 The operation of the model was also assessed by presenting it with the following base, and testing to see whether a mapping to target 1 or target 2 was preferred.
 Cause Cause And RevolvesAround(planet,sun) Gravity Attracts(sun,planet) GreaterThan Mass(sun) Mass(planet) Temperature(sun) Temperature(planet) Cause OppositeSign Attracts(nucleus,electron) Charge(nucleus) Charge(electron) RevolvesAround(electron,nucleus) GreaterThan Mass(nucleus) Mass(electron) Figure 4: Representation of atomsolar system analogy.
 Base: John is anxious John's anxiety is caused by a thesis John's anxiety affects his thesis Target 1: Joan is anxious Joan's anxiety is caused by an exam Joan's anxiety affects her sleep Target 2: Martin is anxious Martin's anxiety is caused by his obesity Martin's anxiety affects his obesity Target 2 is more structurally similar to the base than is target 1.
 This is reflected in the output of the model, which was able to perform both mappings, but gave a higher structural evaluation score to the mapping between base and target 2.
 The representation of each relation in the hierarchy is based on tensor products, and is distributed.
 However in the present version of the model the movement up and down the tree, from one relation to another, and the compilation of the structural evaluation score, is implemented by a conventional Cprogram.
 Means of implementing this aspect in a P D P architecture are being investigated now.
 However the logic of the model will remain essentially as at present.
 600 The model implies that complex analogies must entail a combination of parallel and serial processing because parallel processing of the entire structure would exceed capacity limitations.
 The task is segmented into relations.
 with parallel processing within each relation, but serial processing between relations.
 This is implemented by coding each relation as a tensor product which binds predicate and argument vectors, and permits predicates and arguments to be recovered.
 These vectors can be convolved into a single vector, which can be an argument to a higherorder predicate, enabling a hierarchy of relations to be represented.
 The computational cost of highrank tensor products provides a natural explanation for the processing load imposed by complex relations.
 The model can handle complex analogies, such as water flowheat flow and atomsolar system, while remaining within psychologically realistic capacity limitations.
 References Chappell, M.
, & Humphreys, M.
S.
 (1994).
 An autoassociative neural network for sparse representations: Analysis and application to models of recognition and cued recall Psychological Review, 101(1) 103128.
 Falkenhainer, B.
, Forbus, K.
 D.
, & Centner, D.
 (1989).
 The structuremapping engine: Algorithm and examples.
 Artificial Intelligence, 41 163.
 Centner, D.
 (1983).
 Structuremapping: A theoretical framework for analogy.
 Cognitive Science, 7 155170.
 Halford, C.
S.
 (1993).
 Children's understanding: the development of mental models.
 Hillsdale, N.
 J.
: Erlbaum.
 Halford, C.
S.
, Maybery, M.
T.
, O'Hare, A.
W.
, & Grant, P.
 (1994).
 The development of memory and processing capacity.
 Child Develpoment .
 Halford, C.
S.
, & Wilson, W.
H.
 (submitted).
 Processing capacity defined by relational complexity: Implications for comparative, developmental, and cognitive psychology.
 Holyoak, K.
J.
, & Thagard, P.
 (1989).
 Analogical mapping by constraint satisfaction.
 Cognitive Science, 13(3) 295355.
 Holyoak, K.
J.
, & Thagard, P.
 (1995).
 Mental leaps.
 Cambridge, M A : M I T Press.
 601 Frequency, Competition and Lexical Representation Mary Hare Cemcr for Research in Language  0526 UC San Diego 9500 Gilman Drive, La Jolla, CA 92093 USA phone: 619  534 2695 hare@crl.
ucsd.
edu Abstract Lianne Older, Michael Ford William MarslenWilson Centre for Speech and Language Psychology Department, Birkbeck College Malet Street, London, WCIE 7HX phone: 441716316372 w.
marslenwilson@psyc.
bbk.
ac.
uk An important issue in recent work on lexical representation is whether inflected past tense forms are represented as single units or in morphologically decomposed form, and whether this varies according to the regulartity of the fonns involved.
 W e investigated this by looking at competitor effects between homophonic past tense forms (paced/paste, made/maid) where we varied the relative frequencies of the past tense form and its homophonic competitor.
 In particular, if regular forms are represented in morphologicaly decomposed form, as is widely argued, and irregular forms are listed as single units, this should lead to contrasting effects.
 To investigate this we used two tasks  writing to dictation and cross modal priming to compare frequency effects for regular and irregular forms.
 The results for both type of experiment were highly consistent, showing parallel effects of frequency for both regular and irregular forms.
 W e discuss the implications of this for claims about the lexical representation of morphologically complex forms.
 Introduction An important issue in recent work on lexical representation is whether inflected past tense forms are represented as single units or in morphologically decomposed form, and whether this varies according to the regularity and irregularity of the forms involved.
 Although the subject remains controversial, at least one influential account does assume that lexical storage varies as a function of regularity, with regular verbs represented in a morphologically decomposed form and irregular past tense forms lexically represented as single units, either in an unstructured list, or, more recently, in a networkbased associative memory (e.
g.
, Prasada & Pinker, 1993).
 On the decomposition account, frequency effects should also vary with regularity.
 Such effects m ay be found in irregular past tense verbs, since these exist as separate lexical items.
 It would be incoherent, however, to assume that the frequency of a regular past tense form should have any influence on its lexical representation or access, since no such item is stored.
 A n d indeed, there are experimental results that suggest that frequency effects are found in irregular past tenses, but not in the regulars.
 In separate experiments, Prasada, Pinker, and Snyder (1990) and Seidenberg and Bruck (1990) presented subjects with verb stems and asked them to name the corresponding past tense form as rapidly as possible.
 Both experiments showed that frequency of the verb stem influenced naming latencies for both regular and irregular verbs.
 Importantly, however, there was a reliable effect of past tense frequency only for irregular verbs, with longer naming latencies for low frequency than for high frequency items.
 These results are consistent with the claim that lexical representation is influenced by regularity: O n this account the irregular forms are produced after a search through the lexicon for the appropriate past tense, and, on the assumption that frequency affects access time, the more frequent past tense items are more rapidly accessed.
 For the regular verbs, on the other hand, only the stem is stored and consequently only stem frequency influences search time.
 Once the verb stem has been accessed, the addition of the past tense suffix takes a constant amount of time across verbs, so no differences due to past tense frequency are expected.
 But while these data are consistent with the decomposition account, they are also open to a very different interpretation.
 In a recent paper Daugherty and Seidenberg (in press) have shown that the same pattern of effects occurs in a connectionist model, for reasons having to do with h o w such networks learn.
 Briefly put, their account is this: In connectionist networks using the backpropagation learning algorithm, the goal of learning is to find the set of connection weights that will produce the most accurate output to each input.
 Both token frequency and pattern consistency (or type frequency) have strong effects on the sorts of weight changes that occur.
 For frequent patterns, this is due to the fact that they are presented to the network many times during training, and a weight change that reduces error (the difference between expected and obtained output) on one presentation of the pattern entails error reduction on all other presentations  therefore, a weight change that improves performance on a frequent pattern leads to a large reduction in error.
 For consistent patterns the effect is due to the fact that a weight change that leads to lower error on one mapping will reduce error on all patterns are consistent with it.
 Thus, for example, a weight change that reduces the error on the mapping jump > jumped will also reduce error on mappings like look > looked or like > liked, since these items share a consistent form of inflection.
 602 mailto:hare@crl.
ucsd.
edumailto:w.
marslenwilson@psyc.
bbk.
ac.
ukWhat this means for the current problem is that the learning of regular past tense forms does not rely entirely on the presentation frequency of that word, since each regular verb benefits from the learning of the other regular items.
 But learning the past tense of an exception word like take or give relies heavily on presentations of the word itself, so correct performance is highly dependent on word frequency.
 As a result, item frequency matters suongly for irregular items, but has much weaker consequences for regulars.
 This was the pattern found in the experimental data.
 Since they are consistent with both the decomposition and the connectionist accounts, the naming data do not decide between the two possibilities.
 In the current paper we will present the results of two new experiments, using two different types of task, which show that under appropriate testing conditions frequency effects can be found in both regular and irregular verbs.
 W e will then show that general principles of learning embodied in connectionist models can adequately account for these new data.
 Experiments In this work we use two tasks  writing to dictation and crossmodal repetition priming  to look at competitor effects between homophonic past tense forms such as paced/paste or made/maid.
 In both experiments we varied the relative frequencies of the past tense form and its homophonic competitor, to determine whether this led to contrasting effects for the regular and irregular verbs.
 O n the decomposition account, relative frequency should have an effect in the irregular past tense verbs, but not in the regulars.
 If all past tense forms are represented in a similar fashion, on the other hand, there should be parallel effects of frequency for both regular and irregular forms.
 Experiment 1: Dictation In this experiment subjects heard a list of words presented on tape, and were instructed to write a phrase or a sentence containing each word as they heard it.
 There was a short pause after the presentation of each word to allow the subjects to write.
 Test items in the experiment were 40 regular and 39 irregular past tense verbs, each with a second (monomorphemic) reading.
 Both regulars and irregulars were divided into three groups according lo the frequency of the past tense (PT) reading relative to its homophone (HP).
 Frequencies were calculated throughout using the L O B norms (Johansson & Hofland, 1989) 1.
 PT greater.
 Items where the frequency of the past tense form was higher than the frequency of the homophonic reading, (e.
g.
 allowed/aloud, made/maid) 2.
 Approximately equal.
 Items where the frequency of the past tense did not differ from the frequency of the homophone, (ducked/duct, heard/herd) 3.
 HP greater.
 Items where the frequency of the homophone was higher than the frequency of the past tense reading, (fined/find, ate/eight) A further 40 nonhomophonous monomorphemic nouns and verbs were included as fillers.
 Twentyone subjects, all universityage native speakers of British English, completed the test.
 In presenting the results we will focus on the proportion of past tense responses to the test items.
 The mean proportion of past tense responses for each verb type is given in Table 1.
 TABLE 1.
 Mean proportion of past tense responses.
 Experiment One P T greater Approx.
 Equal H P greater Regular 0.
78 (n=9) 0.
42 (n=14) 0.
20 (n=17) Irregular 0.
73 (n= 15) 0.
78 (n=9) 0.
44 (n=15) A n overall analysis of variance gave a main effect of frequency group (F2(2,73) = 16.
3, p < 0.
001).
 Post hoc tests showed significant differences among all frequency groups: There were significantly more past tense responses in the P T Greater group than in either the H P Greater group (p < 0.
01) or the Approximately Equal group (p < 0.
05).
 There were also significantly more past tense responses in the Approximately Equal group than in the H P Greater group (p < 0.
01).
 ANOVAs carried out separately on the two verb types, regular and irregular, showed the same pattern of results.
 In both cases there was a main effect of frequency group (for the regular verbs, F2(2,37) = 17, p < 0.
001; for the irregulars, F2(2,36) = 5.
1, p < 0.
05), with significantly more past tense responses to the P T Greater and Approximately Equal groups than to the H P Greater group.
 Summary The experiment shows a strong effect of past tense frequency that is highly consistent across regular and irregular verbs.
 These results are most simply explained by an account that says that the subjects, operating under time pressure, wrote the first item to be accessed when the homophone was heard.
 The most frequent of the homophone readings would be accessed first, and indeed the subjects reliably did choose the more frequent of the two.
 What is surprising about these results, though, is that this was the case not only for the irregular past tense verbs, which are noncontroversially assumed to be represented in the lexicon, but for the regular past tenses as well.
 These 603 results are expected in the network account, which assumes that regular and irregular verbs are subject to the same treatment, but more difficult to explain under the assumptions of the decomposition account.
 To demonstrate that the frequency effect is a robust one, we then ran a second experiment using a very different task.
 Experiment 2: Lexical Decision In the second experiment we used crossmodal repetition priming to compare the effects of frequency on the regular and irregular verbs.
 In this task the subject hears a spoken prime  for example, spoke  and immediately at the offset of this word sees a visual target  here, speak which is morphologically related to the prime.
 The subject makes a lexical decision response to this target, and the response lime relative to that in a control condition (with the same target following an unrelated prime) is used to measure any priming effect (MarslenWilson, Tyler, Waksler, & Older, 1994).
 In this experiment, as in experiment one, there were two classes of verbs.
 Regular and Irregular.
 In each verb class two thirds of the items consisted of past tense forms with unrelated homophones, as in Experiment 1.
 For comparison, a further third of the items had unambiguous past tense forms, as in pairs hke jumped/jump.
 Triplets were created for each verb, in which visual target was always the uninflected verb stem, while the prime was either the inflected present tense, the inflected past tense, or an unrelated control prime.
 Table 2 gives an example stimulus set.
 TABLE 2.
 Example stimulus set.
 Experiment Two Regular Irregular hphone nonHP hphone nonHP Primes Present paces jumps speaks sleeps Past paced jumped spoke slept Target PACE JUMP SPEAK SLEEP As in Experiment One, verbs in the Homophone conditions were divided according to the relative frequency of the past lense and homophone readings into P T Greater, H P Greater, or Approximately Equal groups.
 The controls were matched to the primes for frequency and syllable length, and the Homophone and NonHP conditions were matched to each other for frequency.
 Three experimental versions were constructed so that each target word occurred only once for each subject.
 The experiment included a further 324 filler pairs, to reduce the relatedness proportion of prime/target pairs and to guarantee that the target was a nonword on 5 0 % of the trials.
 The results given below are for 45 subjects (15 in each version), all native speakers of British English.
 In presenting these results we will consider the testcontrol difference scores for the past tense primes, to determine whether the existence of a homophone, and the frequency relation of the two readings (as a past tense form or as an unrelated monomorphemic form) affected an inflected verb's ability to prime its stem.
 These scores are given in Table 3.
 TABLE 3.
 Difference scores (test minus control) for Experiment T w o NoHomophone Verb type Regular Irregular PT prime 51* 1 Homophone Verb type Regular Irregular Frequency group P T Greater Approx.
 Equal H P greater P T greater Approx.
 equal H P greater PT prime 17 6 46(*) 5 2 26* Note that there is significant priming in the NoHP regular condition, but not in the H P condition'.
 Note also that verbs in the H P Greater groups showed interference relative to control.
 This was marginally significant in the regular verbs (p < 0.
1) and significant in the irregulars (p < 0.
5).
 Tests were then run comparing test/control differences following past tense primes for all frequency groups.
 These showed a significant difference between the P T greater and H P greater groups for the Regular verbs (p < 0.
05), but not for the Irregular verbs We next looked at the correlation between the relative frequency of a homophonic past tense form and its ability to prime its stem.
 This was done by correlating the testcontrol difference following the past tense prime with the difference in frequency between the past tense form and the competing homophone.
 This correlation was significant for all items (R = 0.
35, p < 0.
01) though not for the Irregular past tense verbs alone (R = 0.
22, p > 0.
1).
 Importantly, however, the correlation was significant for the Regular past tense verbs (R= 0.
52, p < 0.
01).
 We also looked at the relationship between the size and the direction of priming effects and the frequency of the verb ' The absence of priming for the NoHP Irregular past tense forms replicates findings we have reported previously, showing that irregular past tense forms do not prime their stems (MarslenWilson, Hare, & Older, 1993) 604 stems.
 Although a decompositional account might not predict an effect of past tense frequency per se for regular verbs, it would predict effects on speed of access of the frequency of the verb stem itself.
 Since stem frequency (defined as the cumulative frequency of occurrence of a stem across all its inflectional variants) is highly correlated with past tense frequency, we used multiple regression analyses to determine the proper attribution of effects.
 These analyses showed that the dominant factor was indeed the frequency of the past tense form, and that stem frequency made only a marginal additional contribution, increasing R for regular verbs from .
52 to .
55.
 This means that the results cannot be attributed to variations in stem frequency across the three frequency groups.
 Summary As in the first experiment, the lexical decision experiment shows an effect of past tense frequency that is not limited to the Irregular verbs.
 For both Regular and Irregular verbs, the existence of a more frequent homophone leads to interference in the priming task.
 Furthermore, the degree to which a homophonic past tense form facilitates recognition of its stem correlates with the frequency of that form relative to its homophone.
 It is notable that this correlation is stronger in the Regular verbs than in the Irregulars.
 A second point of interest is that while there is significant priming for Regular verbs in the nonHomophone condition, the facilitation effect is greatly reduced in the Homophone condition, even for those items in the P T Greater group.
 This suggests that frequency alone cannot account for our pattern of results, for the existence of a competing homophone appears to have an effect that is not eliminated by differences in frequency.
 Discussion The pattern of results found in these two experiments is clearly inconsistent with any account which assumes that frequency effects in the past tense must vary with the regularity of the verb.
 The pattern is consistent with current connectionist assumptions that both regular and irregular verbs are learned and processed in a similar fashion, however.
 Therefore, in the remainder of this paper we will call upon principles of connectionist learning to account for the details of our experimental results.
 As discussed in the Introduction, both token frequency and pattern consistency have strong effects on learning in a network.
 Patterns that are consistent, in the sense they are subject to similar inputoutput mappings, benefit from the existence of their consistent neighbors.
 Thus, to take the example of a mapping from the form of a verb stem to the form of its inflected past, the fact that a network has learned to produce sing > sang will aid it in producing ring > rang, since these are phonologically similar inputs that inflect in the same way.
 This is so because the same set of connection weights mediate between input and output for both forms.
 A n important consequence, then, is that the opposite must also be true: connection weights that correctly produce the consistent patterns will lead to larger error on patterns that are inconsistent.
 Seidenberg (1992) shows that this aspect of the consistency effect can account for the fact that in naming experiments, regular verbs with irregular neighbors (such as bake, with the inconsistent neighbors take or nuike) have longer response latencies than regular verbs whose neighbors are all consistent.
 The basis of the explanation is that weight changes beneficial to take will increase the error on bake, and vice versa.
 Since the two items compete for how the weights will be set they take longer to learn than will a regular consistent item such as jump, and once learning is complete the error on regular inconsistent words like bake will be slightly higher than on other regular words.
 In summary, in this type of network high frequency patterns are easier to learn than low frequency ones, and items with consistent neighbors are easier to learn than those with inconsistent neighbors (or no neighbors at all).
 In other work this difference in leamability has been correlated with speed of lexical processing (e.
g.
 Seidenberg and McClelland, 1989).
 O n the assumption that the correlation is correct, the network account makes certain predictions for our data.
 Consider, first, that the recognition of a spoken word is a mapping task: the listener must match the perceived sound pattern to the correct lexical item.
 In a network, this task will be learned more efficiently for more frequent words, thus offering an explanation for the standard assumption that more frequent items are accessed more rapidly.
 In addition, the homophones are subject to the consistency effect in much the same way as the regular inconsistent verbs discussed above: Homophones have inconsistent neighbors, since in each case the form of the word can m a p to two dissimilar responses.
 In a network these items compete for how the weights are set, and their relative frequencies will play a role in which form would be most successful.
 Furthermore, even when learning is complete the total error on these items will be higher than on items that are not subject to such competition.
 Thus the network learning account predicts that error (and therefore speed of access) will be higher for items with homophones than for those without, and that for the homophonous pairs, error will be lower on the form with the more frequent reading.
 This is the pattern of results obtained in our experiments, and argues in favor of the network account of these data.
 605 Acknowledgments This research was supported by grants from the UK ESRC, M R C , and SERC/BBSRC to William MarslenWilson and Lorraine Tyler References Daugherty, K.
G.
 & Seidenber, M.
S.
 (in press).
 Beyond rules and exceptions: A connectionist approach to inflectional morphology, in S.
 Lima (Ed.
), The Reality of Linguistic Rules.
 John Benjamins.
 Johansson, S, & Hofland, K.
 (1989) Frequency analysis of English vocabulary and grammar.
 Oxford: Oxford University Press.
 MarslenWilson, W.
D.
, Hare, M.
, & Older, L.
 (1993) Inflectional morphology and phonological regularity in the English mental lexicon.
 Proceedings of the 15th Annual Meeting of the Cognitive Science Society, Princeton, NJ: Erlbaum.
 MarslenWilson, W.
D.
, Tyler, L.
K.
, Waksler, R.
, & Older, L.
 (1994) Morphology and meaning in the English mental lexicon.
 Psychological Review, 101, 333.
 Prasada, S.
, & Pinker, S.
 (1993).
 Generalization of Regular and Irregular Morphological Patterns, Language and Cognitive Processes, 8,156.
 Prasada, S.
, Pinker, S.
 & Snyder, W.
 (1990).
 Some evidence that irregular forms are retrieved from memory but regular forms are rule generated.
 Presented at the Psychonomic Society meeting, Nov 1990.
 Seidenberg, M.
 S.
 (1992).
 Connectionism without tears.
 In S.
 Davis (Ed.
) Connectionism: Theory and Practice.
 Oxford Universtiy Press.
 Seidenberg, M.
S.
 & Brack, M (1990).
 Frequency and consistency effect in the past tense.
 Presented at the Psychonomic Society meeting, Nov 1990.
 Seidenberg, M.
 S.
 & McClelland (1989).
 A distributed, developmental model of word recognition and naming.
 Psychological Review, Vol.
 96:4, (pp.
52356).
 Simpson, G.
B.
 (1990).
 Lexical ambiguity and its' role in models of word recognition.
 Psychological Bulletin, Vol 9, no.
 2, 36340.
 606 Exploring the Continuum of Unit Size in W o r d Identification Catherine L.
 Harris 64 Cummington St.
, Department of Psychology Boston University, Boston, M A 02215 charris@bu.
edu (617) 3532956 Abstract Conneciionist approaches to word recognition suggest thai the units of word identification are not part of a fixed architecture, but emerge through extracting cooccurrence regularities.
 One implication of this idea is that unitstatus, and the size of units, may be a matter of degree.
 This paper investigates the possible unit status of common word collocations, such as adjectivenoun pairs {nexi step, large pari) and verbpreposition combinations (look out, appear in).
 On analogy to the pseudowords used in word superiority experiments, I contrasted letter detection in nearcollocations {next stem, barge part) and random pairs (next role, power part) with performance on collocations (which had been defined as frequent combinations in a printed corpus).
 Although letter detection for collocations was not better than single words, detection was impaired for random pairs relative to single words and collocations.
 Nearcollocations had a paradoxical effect that was only partially anticipated: an enhancing effect when letter targets were in the first word, and an inhibiting effect when targets were in the second word.
 Because reaction times were 400msec slower in the latter case, it was inferred that the nearcollocations have a timedependent effect, one of initial activation of neighbors, followed by inhibition.
 Introduction The word superiority effect (WSE) refers to the finding that laboratory subjects are more accurate at detecting a letter in a word than in a nonword or a letter alone (Reicher, 1969).
 Letter detection is also enhanced in pseudowords (strings which embody the orthographic regularities of English), even for pseudowords which aren't pronounceable (McClelland & Johnston, 1977).
 For example, A^ can be detected more easily in S L N T than in S D N R .
 These and other effects were explained in McClelland & Rumelhart's (1981) interactiveactivation model of word recognition, a model which illustrated how elements in an interacting system can mutually constrain each other, and how rulegoverned behavior can emerge in the absence of explicit rules.
 McClelland & Rumelhart's lA model explained the enhancing effect of pseudowords by proposing that the familiar letter clusters (such as SL and N T in SLNT) activate the many words of which they are a member, and these words feedback activation to their component letters, allowing, for example, S and A' to receive more activation when viewed as part of S L N T than when viewed in the context of SDNR.
 lA achieves these results by representing words as units which receive and send inhibitory and excitatory signals.
 Nonwords do not have these characteristics.
 For humans, an open question is which mental entities have unit status, and why.
 Presumably the letter strings w e call words come to have unit status via readers' frequent (and usually early) exposure to these letter combinations.
 Elman (1991) has shown that words as perceptual units can emerge from a backpropagation network trained to predict the next letter in a letter sequence composed of words strung together without separations.
 In a discussion of "subsymbolic psycholinguistics" Van Order, Pennington & Stone (1990) describe how the units of word identification emerge through extracting cooccurrence regularities, which they call "covariant learning".
 A s they point out, ".
.
.
any relatively invariant correspondence, at any grain size equal to or larger than the grain size of our subsymbols, may emerge as a rulelike force.
.
.
" (Van Order et al, p.
 504).
 If unit status is a matter of degree, then units smaller than words, and units larger than words, could come to have a degree of unit status.
 The hypothesis that units smaller than words may have a type of unit status has been well researched, although usually in the context of determining the representational status of morphemes (e.
g.
, are morphemes stored separately from the words of which they are a part; can readers search for morphemes in text; do morphologically related words prime each other).
 In the current paper, I investigate the possible unit status of c o m m o n word combinations.
 For simplicity, I look at two types of combinations: noun combinations (noun+adjective, adjectivetnoun and noimnoun: next step, night club) and verbpreposition combinations (look out, appear in).
 Since w e recognize the cohesive quality of these pairs, it may seem obvious that they must have a type of unit status.
 But the nature of this cohesive quality has important implications for theories of lexical representation and language processing.
 Current theories propose that words are stored in a separate data structure (the lexicon) and are individually accessed and assembled into larger units (Forster, 1979; for a review, E m m o r e y & Fromkin, 1988).
 Although proponents of a unitary lexicon acknowledge that semantically cohesive word combinations (such as word compounds, cliches and idioms) may have their o w n "entries" in the lexicon, these com607 mailto:charris@bu.
edupound items are considered the exception to the intrinsic nature of the mental lexicon, which is a compendium of individual words and their meanings.
 If c o m m o n word combinations have unit status, then w e may want to view the mental lexicon as being composed of items of varying size.
 The modal unit size may correspond to the word, but this would result from the statistical attributes of words, which itself may be a result of "functional unitization" (Van Orden et al.
, 1990) and the usefulness of this size for human language processing (Harris, 1994).
 One method of investigating whether collocations like the noun compound "night club" have unit status is to see if these two words prime each other.
 Experiments have shown priming for noun compounds in lexical decision tasks (Hodgson, 1991; Harris, unpublished data).
 But enhanced lexical decision at most shows an associative link between two words.
 Hodgson (1991) has argued that semantic priming reflects an attempt at semantic integration initiated by the language comprehension system after lexical representations are accessed.
 A more stfingent test of the unitstatus of a word combination would be if the hypothesized unit was able to feed activation down to the level of letters.
 I thus chose a forcedchoice letter detection task as m y method of exploring activation between units at one granularity level and units at another level.
 W S E experiments typically contrast detection of a letter alone, a letter in a word, and letters in various types of nonwords.
 One type of nonword is pronounceable and differs from a word by a single letter.
 A typical finding is that letter detection is facilitated in a pseudoword relative to a random letter string.
 One set of items was constructed to be analogous to a W S E experiment (see Table 1).
 These were the nouns materials.
 In these materials, subjects detected letters under 5 conditions: letter alone, target word alone, collocation, nearcollocation (adjacent word is one letter removed from a collocation) and random wordpair (adjacent word is frequencymatched to the adjacent word in the collocation but is not associatively related to it).
 These materials allowed m e to answer the following questions: • Does a collocation enhance detection, compared to a single word? A positive finding would be strong support for the unitstatus of collocations.
 A negative finding could simply mean that letter detection is too fast for the enhancing effect of the collocation to be observed.
 • Does a nearcollocation enhance or inhibit detection, relative to a noncollocation? One might expect a nearcollocation to enhance letter detection relative to a noncollocation, on analogy to how a pseudoword enhances detection relative to a nonword.
 This possibility is diagrammed in Figure la.
 On the other hand, a nearcollocation could inhibit detection, if the nearcollocation competes with the collocation (Figure lb).
 Support for this view comes from the "Word Inferiority Effect" (Chastain, 1986).
 Decreased letter detection occurs for letter collocation fxax bill^ tap dance level word level letter level Cbiin Cfill (ti p ) / VSeTT) tax bell Figure la.
 nearcollocation enhances letter detection relative to a noncollocation: T h e unit for bill is activated by letters in the input.
 This spreads activation to the collocation tax bill, which then feedback activation d o w n to tax and the target letter x.
 collocation (taxbilM f tap dance level word level t a g / \5etT) letter F ^ t ^ D e g l p n tax bell Figure lb.
 nearcollocation inhibits letter detection: Units for bill and bell are both activated by the input and compete, inhibiting each other.
 This prevents bill from activating tax bill, or m a y even lead to inhibition of tax bill (dotted line).
 608 file:///5etTTable 1: Table 1: Example of Stimulus Materials Sample Noun Materials Collocation NearCol loc (Letter target in first word) tax bill tax bell night club night clue (Letter target in second word) focal point vocal point free world tree world NonCollocation Forced Choice Letters tax deep night wall cargo point open world X g n e oa ru Sample Verb Materials High Freq.
 find out keep in give up show up L o w Freq.
 find off keep over give on show under Anomalous find for keep if give oy show ip Forced Choice Letters de kd u a hi strings in which an additional letter was interposed partway through string exposure, if both strings made a word; e.
g.
, cat, with interposed s to make cast).
 Chastain interprets this to mean that competition between words is inhibiting both words' activation levels, thereby decreasing letterlevel activations.
 • Does the effect of context differ depend on whether the target is the first or second word in a collocation? One reason not to expect enhanced letter detection in collocations compared to single words is that excitatory feedback from collocations to words, and from words to letters, may take too much time; by the time the feedback reaches the letter level, the word (and its letters) may already have been recognized.
 I hoped to be able to distinguish this possibility by comparing the patterns of letter detection when the target is in the second word, rather than the first, on the assumption that more time is required to read the second item in a twoword pair than the first.
 The verb materials were used to explore the effects of frequency of a collocation, by contrasting high and lowfrequency verbprepositions pairs.
 M e t h o d Materials The experimental stimuli were 55 noun pairs and 27 verbpreposition pairs, constructed using the criteria described below.
 Subjects also saw 55 single words and 75 single letters.
 Verbs and nouns used in the study were selected by filtering the Brown Corpus (Francis & Kucera, 1982) frequency listings for words that were less than 8 characters long and appeared more than 100 times in the millionword corpus.
 The frequency of each words' left and right neighbors (in the Brown Corpus) was then tabulated.
 Noun materials Nouns were selected for inclusion in the study if they followed or proceeded another content word such that the pair had a frequency of at least 2 (mean for the final set was 6) and the resulting string was 11 characters or less (counting the blank space as a character).
 55 nouns met this criteria.
 28 were the first member of the pair, and 27 were the second member of the pair.
 Two types of control items were also selected (see Table 1).
 The nearcollocations are items in which one letter has been changed (preserving wordstatus) in the word which is tiot targeted for letter detection.
 The randompair control items keep constant the word targeted for letter detection, and pair it with a word which is length and frequencymatched to the analogous item in the collocation.
 Verb materials Verbs were most frequently followed by prepositions (e.
g.
.
 find out and live in had counts of 34 and 30, respectively).
 Because there were theoretical reasons to believe that verb+preposition may have unit status (Harris, 1990; 1994) (and to increase stimulus homogeneity), verb items were restricted to verb+preposition (or particle) pairs.
 Ten prepositions with clear semantic content were selected.
 Frequencies were obtained for all verb+preposition combi609 nations.
 27 verbs were found which met the following criteria: Each verb occurred in a highfrequency verbpreposition pair (mean frequency of 10 counts per million), a lowfrequency pair (occurred only 1 time per million), and an illegal pair (never occurred in the Brown corpus, and was judged anomalous by two independent raters).
 In order to keep repetition of the prepositions to a minimum (to avoid repetition priming), in the "illegal" condition, 18 of the 27 verbs were paired with either a nonpreposition or a nonword (which was one letter removed from the preposition used in the highfrequency condition).
 Subjects Subjects were 28 Boston University undergraduates who participated for course credit.
 All subjects were native speakers of English.
 Procedure Subjects focused on a fixation window and pressed a button to initiate each trial.
 The target letter, word or word pair appeared for 30 msec and was followed by a pattern mask for 250 msec.
 The letters for the forced choice task then appeared above the masked stimulus and remained visible until the subject pressed a top or bottom button to signal which letter had been in the corresponding position.
 The 212 experimental trials followed 27 practice trials.
 o a top tan c 0) o 0) Q .
 Results Noun Combinations The dotted line in figure 2 allows comparison of the mean 9 0 8 0 o 0) a.
 O o c o o o *^ 7 0 O O 4irf * « » 0) 6 0 5 0 Target Letter in First W o r d Target Letter in Second Word Collocation Pseudo NonColloc Colloc Letter Single Word S t r i n g T y p e Figure2: Percent of correct letter detection for noun pairs.
 610 detection rate for single words compared to other conditions.
 Letter detection was worse when letter targets were in the second word, for all string conditions; F(l,53)=22; p < .
001.
 The condition X target word interaction shown in Figure 2 is significant; F(3,159)=2.
8; p < .
05, as are the 2 X 2 anovas on target word and pseudoword vs.
 noncoUoc; F(l,53)=5.
7, p < .
02 and colloc and noncolloc; F(l,53)=7.
8; p < 0.
005.
 (The only means in Figure 2 which aren't significantly different firom each other are colloc and NearColioc, and NearColloc and ndncolloc, when the target letter is in the first word.
 Because all stimuli were leftadjusted on the screen, collocations in which the secondword contained the letterdetection target didn't have a matching "single word" condition.
" Figure 3 shows response time for each of the string types Buttonpressing times were an average 426 msec slower when the target occurred in the second word; F(l,287)=94; p <.
0001.
 Verb Combinations Table 2 shows that percent correct was better for all conditions containing a word than the single letter condition; F(4,104)=10.
 However, there was no advantage the high frequency verb combinations over the low frequency or anomalous word pairs.
 The difference between response time means for the high frequency and the anomalous conditions /.
 All analyses are withinitem anovas, averaging over subjects.
 Results are comparable for anovas with subjects as the random factor, although some F values are smaller.
 was statistically reliable; F(l,26)=6; p< .
03.
 implying that the anomalous word pairs incur a reaction time cost.
 Data Summary The current study showed the following: • The basic word superiority effect (better detection of letters in words than in single letters) holds when words are part of word pairs, with a total string length of up to 11 characters.
 The target letter may appear in any of the 11 positions.
 • Detection of letters in collocations is equivalent to detection in single words.
 Relative to single words and collocations, detection in random pairs is impaired.
 • Letter detection in a nearcollocations (tax bell) is inhibited relative to a collocation {lax bill) or an unassociated word pair (tax deep), but only if the target letter is in the second word of the word pair.
 • Frequency and legality of verb+preposition pairs did not modulate letter detection.
 Conclusions My method of establishing the reality of units larger than words was to show that letter detection in collocations is better than detection in single words.
 A positive finding would have supported the proposal that activation can accrue to word combinations and enhance letter detection via topdown activation.
 However, detection in collocations and single words was found to be equivalent.
 u 0) (A 0) E 0) (A r o a (0 1900 1800^ 17001600 1500 1400 1300 Target Letter in Second Word Target Letter in First Word Collocation Pseudo Non Single Colloc Colloc Word String T y p e Figure 3: Response latencies for noun pairs Table 2: Verb Combinations Condition % correct RT letter alone .
68 1174 single word .
83 1230 high freq word pair .
81 1282 low freq word pair .
85 1330 anomalous pair .
84 1368 611 Some support for the unitstatus of common word combinations was provided by the finding that detection was impaired in random pairs compared to collocations, at least for the noun materials.
 But how could a noncollocation impair letter detection, if random pairs aren't units, and don't send inhibition and excitation? One possibility is that this is an effect of automatic semantic integrative processes.
 To make sense of the noncollocation, the processor initiates a search, which activates many candidate wordunits.
 These interfere with units which are legitimately activated by the perceptual display, thus impairing letter detection.
 Support for this scenario is that response times for the random pairs were greater than for the collocations, for both noun and verb materials.
 The current experiment contained materials analogous to those in W S E experiments, by comparing collocations and nearcollocations.
 In W S E experiments, pseudowords are sometimes as good at enhancing letter detection as real words.
 This study found results comparable to that of W S E studies, but with a twist.
 When the target letter was in the first word, nearcollocs showed letter detection performance similar to that of collocations, and better than that of random pairs, suggesting they enhanced the activation of word units (as depicted in Figure la).
 W h e n the target letter was in the second word, detection of letters in nearcollocs was worse than in noncollocs, suggesting the nearcollocs inhibited word units, as depicted in Figure lb.
 A plausible reason for the difference in these conditions is time: detection was over 400 msec slower when the target letter was in the second word.
 Thus, nearcollocs play an initially enhancing role, followed by an inhibiting role.
 Future Work One reason the collocations did not lead to higher detection rates than the single words may have been because the collocations are much less frequent as units than single words: they had an average frequency of 6 per million (range: 2 to 43), while the single words had an average frequency per million of 316 (range: 13 to 807).
 An experiment which includes a singleword, low frequency control condition is currently underway.
^ A second method of demonstrating the beneficial effects of context is to investigate whether being oneletter away from a collocation facilitates letter detection in unpronounceable (orthographically illegal) nonwords.
 Subjects could be asked to detect the letters in bold: let down, let dowx, act dowx (choose d or g) come from, come frxm, fact frxm (choose m or g) According to standard WSE findings, d in down should show superior detection rates to dowx, but there is no prediction regarding how detection of d in dowx varies if preceded by either let or act.
 If units larger than words can facilitate letter detection, then we predict superior facilitation in let dowx, since it is a neighbor of let down.
 Acknowledgments This work was supported by a grant to the author from the McDonnelPew Program in Cognitive Neuroscience.
 I thank Brendan Kitts and two anonymous reviewers for helpful comments on an earlier version of the paper.
 References Chastain, G.
 (1986).
 Wordtoletter inhibition: Wordinferiority and other interference effects.
 Memory & Cognition.
 14, 36\36S.
 Elman, J.
L.
 (1990) Finding structure in time.
 Cognitive Science.
 14.
 179211.
 Emmorey, K.
D.
, & Fromkin, V.
A.
 (1988).
 The mental lexicon.
 In F.
J.
 Newmeyer (Ed.
), La«^tta^^.
 Psychological and biological aspects.
 New York: Cambridge University Press.
 Forster, K.
 (1979) Accessing the mental lexicon.
 In R.
J.
 Wales & E.
 Walker (eds.
) New approaches to language meclianisms.
 Amsterdam: NorthHolland.
 Harris, C.
L.
 (1994) Coarse coding and the lexicon.
 In C.
 Fuchs and B.
 Victorri, (Eds.
), Continuity in linguistic semantics.
 Amsterdam: John Benjamins.
 Harris, C.
L.
 (1990) Connectionism and cognitive linguistics.
 Connection Science 2, 734.
 McClelland, J.
L.
 & Johnston, J.
C.
 (1977) The role of familiar units in perception of words and nonwords.
 Perception & Psychophysics, 22, 249261.
 McClelland, J.
L.
 & Rumelhart, D.
E.
 (1981) An interactive activation model of context effects in letter perception: Part 1.
 An account of basic findings.
 Psychological Review, 88, 375407.
 Reicher, G.
M.
 (1969) Perceptual recognition as a function of meaningfulness of stimulus material.
 Journal of Experimental Psychology.
 81, 274280.
 Van Orden, G.
C.
, Pennington, B.
F & Stone, G.
O.
 (1990) Word identification in reading and the promise of subsymbolic psycholinguistics.
 Psychological Review, 97, 488522.
 2.
 I think one of the anonymous reviewers for .
suggesting this compari.
son.
 612 L e a r n i n g Sets of Related Concepts: A S h a r e d T a s k M o d e l Tim H u m e ICS Dept.
 University of California, Irvine Irvine, C A 92717 huine@ interplay .
com M i c h a e l J.
 P a z z a n i ICS Dept.
 University of California, Irvine Irvine, C A 92717 pazzani@ics.
uci.
edu (714)8245888 http://www.
ics.
uci.
edu/dir/faculty/AI/pazzani Abstract W e investigate learning a set of causally related concepts from examples.
 W e show that human subjects make fewer errors and learn more rapidly when the set of concepts is logically consistent.
 W e compare the results of these subjects to subjects learning equivalent concepts that share sets of relevant features, but are not logically consistent.
 W e present a sharedtask neural network model simulation of the psychological experimentation.
 Introduction Researchers have investigated how the relevant background knowledge of the learner influences the speed or accuracy of concept learning (e.
g.
.
 Murphy & Medin 1985, Nakamura 1985, Pazzani 1991, Wattenmaker et al 1986).
 However, the psychological investigation to date has only explored problems where subjects learn a single concept and the relevant background knowledge is either brought to the experiment by the subject or given in written instructions.
 In contrast, research in machine learning has addressed issues that occur when learning a set of related concepts.
 For example, relevant background concepts might be learned inductively from examples before learning concepts that depend upon this knowledge (Pazzani 1990).
 Here, w e report on two experiments in which subjects induce the relevant background knowledge from examples and use this background knowledge to facilitate later learning.
 The experiments illustrate the importance of learning the relevance of combinations of features, rather than individual features.
 W e model this experiment with sharedtask neural networks (Caruana, 1993).
 In the first experiment, subjects first induce the relevant background knowledge and then have the opportunity to use this knowledge in later learning.
 To more closely simulate the real world, w e ran a second experiment wherein the subjects induce the relevant background knowledge at the same time as learning the concept that depends on this knowledge.
 In both experiments, subjects were divided into two groups.
 One group, the "feature consistency" group, learned a complex concept that shared relevant features with previously learned related concepts, but was not logically consistent with those concepts.
 Another group, the "logical consistency" group, learned a complex concept that was logically consistent with previously learned related concepts.
 Initial Psychological E x p e r i m e n t a t i o n In the first experiment, subjects were asked to imagine that they work for the U S Forest Service and were assigned the task of learning to predict years in which there is a severe risk of forest fire danger in the fall.
 Four concepts had to be learned in the experiment ~ one concept in each of four phases.
 All subjects learned the same 3 background concepts in phases 13.
 Then, for phase 4, they were divided into two groups (the logical consistency group and the feature consistency group) to learn one of two separate concepts which depended on the background concepts.
 The first phase of the experiment was designed to minimize the effects of the subjects' domainspecific preexisting theories by having every subject learn the same concept.
 In this first phase, subjects had to learn when there is a severe risk of forest fires in the fall given data on rain in the spring and summer.
 A n example of these data is shown in Figure 1.
 Subjects were given data that indicated that there is a severe risk of forest fires in the fall only when there is both a wet spring and a dry summer.
 This rule is consistent with the knowledge of most people w h o live in Southern California.
 In the remaining phases, when w e measure the learning rate and number of errors made by subjects, novel stimuli are used as features to insure that the knowledge was acquired during the experiment.
 Next, the subjects were told that the U S Forest Service needs to do advance planning, so it cannot wait until the end of summer to predict when there will be a severe risk of fire in the fall.
 The subjects again examined data from several years.
 This time, however, the data was from five simulated scientific instruments that are used each January to detect the presence of factors that may be useful in predicting the amount of rain.
 W h e n one of the instruments detects the presence of a particular factor, it displays a distinctive graph, as shown in Figure 2.
 Otherwise, a bar is shown to mark the absence of the instrument's graph (see Instrument 3 of Figure 2) Each instrument displays a graph whose shape differs from that of the other instruments.
 In this second concept learning problem, subjects had to learn to predict from the instrument readings when there would be a rainy spring.
 All subjects were given data that indicated there would be a wet spring when one particular instrument showed a distinctive graph.
 All subjects learned a rule of the form "There will be a wet spring when InstrumentA displays a graph," with the instrument corresponding to 613 mailto:pazzani@ics.
uci.
eduhttp://www.
ics.
uci.
edu/dir/faculty/AI/pazzaniInstrumentA selected randomly.
 This concept will serve as background knowledge for learning the fourtli concept.
 In the third concept learning problem, subjects learned another piece of background knowledge.
 Here, subjects had to learn to predict from the instrument readings when there would be a dry summer.
 All subjects were shown datii derived from the rule "There will be a dry summer when InstrumentB or InstrumentC displays a graph.
" In the fourth, and final, concept learning problem, subjects had to learn to predict from the instrument readings when there would be a severe risk of fire in the fall.
 Concepts 13 served as background knowledge for this concept.
 Subjects in the logical consistency group were given data that indicated there would be a severe risk of fire when InstrumentA displayed a graph and when either InstrumentB or InstrumentC (or both) displayed a graph, i.
e.
, A A (B V C).
 This concept is logically consistent with the first three concepts that were learned.
 Subjects in the feature consistency group were given data that indicated there would be a severe risk of fire when InstrumentC displayed a graph and when either InstrumentB or InstnimentA (or both) displayed a graph, i.
e.
 C a (B v A ) .
 Although not consistent with the concepts that were learned, this concept shares relevant features with the logical consistency concept.
 Subjects.
 The subjects were 18 male and female undergraduates attending the University of California, Irvine who participated in this experiment to receive extra credit in an introductory psychology course.
 Stimuli.
 The stimuli consisted of data that were displayed on a computer monitor.
 In the first concept, since there are two twovalued features, 4 distinct stimuli were constmcted.
 In the remaining three concepts, there were 32 distinct stimuli since there are five twovalued features.
 The stimuli were presented in a random order for each subject.
 Procedures.
 Each subject was shown data on the computer from a single year and asked to make a prediction (e.
g.
, whether there would be a severe risk of fire in the fall) by clicking on a circle next to the word Yes or a circle next to the word N o (i.
e.
, using a mouse to move a pointer to the circle and pressing a button on the mouse).
 Next, the subject clicked on a box labeled Check Answer.
 While still displaying the data, the computer indicated to the subject whether his answer was the correct answer.
 If the subject's answer was correct, the subject could click on a box labeled Continue and data from another year was shown.
 Otherwise, he selected a different answer and clicked on Check Answer again.
 This process was repeated unul the subjects performed at a level that ensured they had learned an accurate approximation to the concept (making no more than one error in any sequence of 24 consecutive trials).
 The subjects were allowed as much time as they wanted to make their prediction and to view the data after the correct answer was shown.
 This process of learning a concept to criteria was repeated for each of the four concepts learned.
 W e recorded the number of the last trial on which the subject made an error, the total number of errors made by the subject for each concept, and the number of made on each block of 16 trials.
 If the subject did not obtain the correct answer after 96 trials, w e recorded that the last error was made on trial 96.
 Results.
 Subjects in the logical consistency group required an average of 27.
6 trials to learn the fourth concept, while subjects in the feature consistency group required an average of 50.
4 trials t(16) = 1.
91, p < .
05.
 Subjects in the logical consistency group made an average of 6.
8 errors, while subjects in the feature consistency group made an average of 14.
0 errors t(16) = 2.
135, p < .
05.
 Multiple Concept Learning In Experiment 1, subjects accurately induced three relevant background concepts, prior to learning a single concept which depended upon those concepts.
 The order of the concepts is the ideal order for subjects to first acquire knowledge inductively and then use that knowledge in future learning.
 However, the natural world does not have a benevolent teacher w h o orders experiences for the learner.
 To more closely simulate the natural world, in the second experiment, those concepts that had the same stimuli from the first experiment (the last three concepts) are learned at the same time.
 For each presentation of stimuli, subjects predicted whether there would be a rainy spring, a dry summer, and a severe risk of fire in the fall (see Figure 3).
 With this exception.
 Experiment 2 was identical to Experiment 1.
 For the second learning phase, subjects had to click on all three boxes correctly before proceeding to the next stimuli.
 W e recorded the number of the last trial on which the subject made an error and the total number of errors made by the subject only for the concept that involved predicting whether there would be a severe risk of fire in the fall from the instrument data.
 In addition, for this concept, we also recorded the number of errors made by the subject on blocks of 16 trials.
 If the subject did not obtain the conect answer after 128 trials, we recorded that the last error was made on trial 128.
 Results.
 The subjects in the logical consistency group required an average of 77.
8 trials to predict whether there would be a severe risk of fire in the fall from the instrument data, while subjects in the feature consistency group required an average of 109.
9 trials t(16) = 1.
81, p < .
05.
 In addition, subjects in the logical consistency group made an average of 29.
3 errors, while subjects in the feature consistency group made an average of 41.
4.
 errors.
 This last figure is marginally significant t(16) = 1.
41, p < .
1.
 The results demonstrate that simultaneously learning a set of related concepts is easier when the concepts are logically consistent than when the concepts merely share a set of relevant features.
 Figure 4a graphs the percentage of errors made by the two groups at predicting a severe risk of fire in the fall from the instrument data as a function of the number of trials.
 It shows that subjects in logical consistency and feature consistency groups perform similarly until trial 64.
 After this point, subjects in the logical consistency group make fewer errors than those in the feature consistency group.
 614 Wet Spring Dry S u m m e r ( Continue ) (̂  Effi]@@fe fflmsrasir) Uijil there be a seuere risk of fire in ttie fall? $ ) V e s Q î o Ves, is righ Figure 1.
 An example of the abstract feature stimub used for the first concept.
 \ M D Will there be a rainy spring? m j (̂  Check Hnsiuer ) (DVes O"*^** Ves, is incorrect Figure 2.
 An example of the stimuli used for the second, third and fourth concepts.
 W f t w ? m f (Check nn$mcr} Ulill there be a rainu spring? (s) ffe$ O No Will there be a dry summer? O *es ® No UJili there be a seuere risk of fire in the fall? O *es ® No Figure 3.
 An example of the stimuli used in the second phase of Experiment 2.
 Discussion There are three findings of note in these experiments.
 First, subjects in the logical consistency condition make fewer errors and require fewer trials to learn.
 While this finding agrees with our intuition on how people should learn, previous experiments involving background knowledge have not had subjects learn this background knowledge.
 Furthermore, current cognitive models do not perform in this manner and there is no quantitative data on how background knowledge that is learned inductively influences the learning rate and number of errors made by learners.
 Second, learning the relevance of individual features cannot account for these findings.
 Wisniewski and Medin (1994) use the term selection models to refer to learning models that use prior knowledge to determine which features are relevant.
 Lien and Cheng (1989) present one such model.
 Selection models would not be able to explain the results since both the logical consistency and feature consistency groups leam concepts with the same relevant features.
 Third, although the subjects in the logical consistency group leam faster and make fewer errors than subjects in the feature consistency group, they learner slower and make more errors than would be predicted by existing computational models of the influence of prior knowledge such as Explanationbased learning (EBL) (Mitchell et al.
 1986).
 E B L is a machine learning method that derives concepts from background knowledge.
 At first, it might seem that E B L would serve as an ideal model of the use of prior knowledge in learning.
 Its inputs correspond exactly to those items learned in Phases 13 of the first experiment, and its output correspond exactly to the concept to be learned in Phase 4.
 However, there are several problems with E B L as a model of human learning.
 First, E B L algorithms would leam more quickly than the logical consistency subjects.
 Since the fourth concept can be deductively derived from the preceding three, E BL would make no errors on this data.
 Second, E B L cannot function unless the background 615 knowledge is complete.
 For example, E B L could not acquire the concepts in Phases 2 and 3 since these are just associations between stimuli and weather predictions.
 Modeling with SharedTask Networks Here, we propose a model of the psychological experiments using multilayer neural networks trained with error backpropagation (Rumelhart et al.
 1986) to leani multiple concepts.
 First, we would like to make a distinction between subtask learning and sharedtask learning.
 In subtask learning, some of the concepts to be learned serve as background concepts for the other concepts to be learned.
 For instance, in poker, learning the hands two pair and one pair is a subtask problem because one pair is a background concept for learning two pair.
 Sharedtask learning, on the other hand, involves learning concepts that share subordinate concepts.
 As an example, learning both the hands two pair and full house require knowing what one pair is, but two pair and full house do not require knowledge of each other.
 The network diagrammed on the left side of Figure 5 shows a typical way of using networks to learn subtask concepts with the network applied to Experiment 1.
 (Please note that in order to make the diagrams more comprehensible, only some of the connections between nodes are drawn.
 In an actual network, all the nodes of a hidden layer would be connected to all of its input and output nodes.
) The network first learns the section enclosed in the solid line.
 The two inputs are analogous to the abstract features shown our subjects in the first phase of the experiment.
 The ouQJut is the network's guess at whether or not there will be a severe risk of fire in the fall.
 Second, the network is trained on the section enclosed in the dashed line.
 This represents learning the Wet Spring concept.
 The five inputs (AE) on the left represent the five instrument displays shown to the human subjects.
 The output is the network's prediction at whether there will be a wet spring.
 Third, the Dry Summer concept is trained on the network section enclosed in the dotted line.
 The same five inputs are used as were used to learn the previous concept.
 The output is the network's guess at whether there will be a dry summer.
 The wet spring and dry summer concepts are the subtasks the network learns.
 The final Fire in the Fall concept is represented by training and testing on the entire network.
 The network uses the five inputs to decide if there will be a severe risk of fire in the fall.
 A system such as K B A N N (Towell et al.
 1990) could set up a network like the one on left side of Figure 5, given symbolic inferences rules that represent the knowledge acquired in the first three phases of the experiment.
 A problem with this method in modeling the experiment is that since the network would already be trained on the three background concepts, it would not require any training to learn the final concept in the logical consistency group of our experiment.
 This is the same problem that E B L suffers from.
 Caruana (1993) has done work on sharedtask learning using networks with one hidden layer.
 The network on the right of Figure 5 is a representation of such a network.
 A major advantage of this model is that the hidden layer can create new features which can be shared by all of the output units.
 To model the first experiment, the network first uses the five inputs and only the Wet Spring output unit is trained, i.
e.
, receives feedback on its performance.
 Second, the same five inputs are used, but only the Dry Summer output unit is trained.
 Third, the Fire in the Fall output unit is trained and tested using the five inputs.
 W e performed experiments with sharedtask neural nets to see if they could model the results from our psychological experiments since it appeared that this method could leam tlie combinations of features in addition to feature relevancy.
 These networks might also be able to combine features and store the combination in the network just as it stores learned knowledge.
 In both experiments, the first phase used 2 abstract features as stimuli while the later phases used 5 instrument displays.
 Since the network cannot leam concepts with different forms of inputs, it cannot be trained on the first phase.
 However, the network can be used to leam the other phases of the experiments.
 To model the sequential experiment (Experiment 1), the network first uses the 5 inputs and only the Wet Spring output unit is trained, i.
e.
, receives feedback on its performance.
 Second, the same 5 inputs are used, but only the Dry Summer output unit is trained.
 Third, the Fire in the Fall output unit is trained and tested using the 5 inputs.
 Modeling the simultaneous experiment (Experiment 2)is done by training all 3 of the output nodes at the same time, but only using the Fire in the Fall unit for testing.
 The logical form of the data was the same as used in the psychological experiments.
 The first output unit had a value of one when one random feature, say A, had a value of 1.
 The second output unit had a value of 1 when either (or both) of two other randomly selected features, say B and C, had values of 1.
 To model the logical consistency group, the third output unit had a value of 1 when feature A had a value of 1 and either feature B or feature C (or both) had a value of 1, i.
e.
 A a (B v C).
 The network used was a feedforward system with one layer of 20 hidden units.
 The generalized delta rule was used for training and the logistic function was used for activation.
 At testing, a network output value greater than 0.
5 was treated as a 1 and a value below 0.
5 was treated as a 0 to model the forced guessing that was applied to the human subjects.
 Momentum was set at 0.
90 and the learning rate was set at 0.
25.
 To model Experiment 1, we trained the network to sequentially leam each of the 3 concepts: wet spring, dry summer, and fire in the fall.
 W e first trained the network to leam when an example was a positive example of the wet spring concept, i.
e.
 when the first output unit would have a value of 1 as a function of the 5 features.
 After each epoch through the training data, the network was tested to see if it could correctly predict the value of the first output unit on at least 31 of the 32 examples.
 If it could, the network was then trained on learning when the second output unit (dry summer) was true as a function of the 5 features.
 If it could not reliably predict the first feature, it was trained on another epoch through the data.
 After it had learned to reliably predict the second output unit, it was trained to predict the third output unit the fire in the fall concept.
 Data was recorded on how many epochs the network took to leam the 616 final concept.
 The process of learning each concept sequentially was repeated 50 times.
 The network required an average of 5.
96 epochs, or 190.
72 trials, to learn the logical consistency set, while it took significantly longer, 8.
50 epochs or 272.
00 trials, to learn the feature consistency set, t(98) = 6.
06, p < .
05.
 Similar to the human subjects, this network sequentially learned the set of concepts more easily when it was logically consistent than when the concepts merely share features.
 To model Experiment 2, w e trained the network to simultaneously learn all three concepts.
 The network was trained on all 3 of the concepts, but was tested only on the third concept.
 After each epoch through the training data, the network was tested to see if it could correctly predict the value of the third feature on at least 31 of the 32 examples.
 If it could, then training stopped; otherwise, it was trained for another epoch.
 Data was kept on how many errors the network made on each epoch and on which epoch the network learned the final concept.
 The process of learning the concepts was repeated 50 times.
 The neural net required an average of 7.
12 epochs, or 227.
84 trials, to learn the logical consistency set, while it took significantly longer, 9.
66 epochs or 309.
12 trials, to learn the feature consistency set, t(98) = 5.
039, p < .
05.
 Similar to the human subjects, this network simultaneously learned the set of concepts more easily when it was logically consistent than when the concepts merely share features.
 Figure 4b graphs the percentage of errors made on the two sets as a function of the number of epochs.
 It shows that after the second epoch, the graph is similar to Figure 4a.
 On the logically consistent condition, the network becomes accurate with fewer training epochs.
 Shared task networks are able to model these results because they can create new abstract features and use these features to influence learning other concepts.
 The network requires some training to determine how to use these abstract features, but less training than would be required if new concepts were not consistent with the concepts learned earlier.
 The shared task network is an example of what Wisniewski and Medin (1994) call a tightly coupled model.
 Prior knowledge, in this case created by prior learning, selects the relevance of features (by having higher weights on some connections), and creates new features (as represented in the hidden units).
 Furthermore, feedback during learning one concept can change the features or strengths of the hidden units used by other concepts.
 Conclusions Although the general topic of learning a series of concepts has been discussed, previous research has focused on attentional phenomena such as the intradimensional and extradimensional shift in which subsequent concepts share related features with prior concepts.
 However, these approaches consider sets of arbitrary groups of concepts rather than concepts that are causally related.
 Waldmann and Holyoak (1990) argue that the causal induction process differs from the learning process used to acquire arbitrary concepts.
 In particular, we show that concepts acquired by induction in one phase of an experiment influence later learning in much the same manner as concepts acquired by reading written instructions or prior background concepts.
 W e have focused on how prior knowledge facilitates learning.
 W e should also point out that incorrect prior knowledge may also hinder learning by providing misconceptions (Chi, Slotta & de Leeuw, 1994).
 It is only when prior knowledge is compatible with the new knowledge to be acquired that we anticipate a positive effect.
 Classical concepts that consistent of sets of necessary and sufficient features have several flaws.
 Few concepts people encounter have such rigorous logical definitions (Rosch, 1978).
 More recently, it has become apparent that concepts do not exist and are not learned in isolation.
 Here, w e have presented quantitative results on how induced background knowledge influence the rate of learning and the number of errors made during learning.
 While we have found that having relevant, correct background knowledge facilitates learning, it does not eliminate the need for learning.
 That is, unlike previous learning models, when subjects have learned rules corresponding to "A ^ WetSpring," "B v C > D r y S u m m m e r " and "WetSpring a D r y S u m m m e r > FirelnFall" they do not automatically know that "A a (B v C) > FirelnFall.
" W e believe that one flaw in previous learning models that use prior knowledge is that the equate an explanation with a logical proof, and use rules that have necessary and sufficient preconditions.
 Such rules may be as rare in the real world and as cognitively implausible as concepts that consistent of necessary and sufficient definitions.
 Acknowledgments The research reported here was supported in part by NSF grant IRI9310413.
 W e thank Kamal Ali, Donit Billman, Chff Brunk, Piew Datta, Dennis Kibler, Chris Merz, Brian Ross, and David Schulenburg for comments on various phases of this work.
 617 «30H 5 20H Lxjgical Consistency Feature Consistency 00 1̂  o 00 U1 ON 00 Trial Logical Consistency Feature Consistency Epoch Figure 4a.
 The mean percentage of errors made by subjects in the logical consistency and feature consistency groups as a function of the trial in Experiment 2.
 Figure 4b.
 The mean percentage of errors made by the neural network in the logical consistency and feature consistency groups as a function of the epoch.
 ( ^ i: B i: c i: D ,  ^ s 3 Wet » Spring Dry • Summer I n Fire in Fall Wet Spring Dry Summer Fire in Fall Figure 5.
 Neural network diagrams.
 The network on the left is a subtask learning model.
 The network on the right is a sharedtask learning model.
 R e f e r e n c e s Caniana, R.
 (1992).
 Multitask learning: A knowledgebased source of inductive bias.
 Proceedings of the Tenth International Machine Learning Conference (pp.
 4148).
 San Mateo, CA: Morgan Kaufman.
 Chi, M.
, Slotta, J.
 & de Leeuw, N.
 (1994).
 From theories to processes: A theory of conceptual changes for learning science concepts.
 Learning arid Instruction, 4, 2743.
 Lien, Y.
.
 & Cheng, P.
 (1989).
 A framework for psychological induction: Integrating the power law and covariation views.
 The Eleventh Annual Conference of the Cognitive Science Society (pp.
 729733).
 A n n Arbor, M I : Lawrence Erlbaum Associates, Inc.
 Mitchell, T.
, KeUer, R.
, & KedarCabelli, S.
 (1986).
 Explanationbased learning: A unifying view.
 Machine Learning, Vol.
 1(1).
 Murphy, G.
, & Medin, D.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 3.
 Nakamura, G.
 (1985).
 Knowledgebased classification of illdefmed categories.
 Memory & Cognition.
 13, 37784.
 Pazzani, M .
 (1990) Creating a memory of causal relationships: A n integration of empirical and explanationbased learning methods.
 Hillsdale, NJ: L a w r e n c e E r l b a u m A s s o c i a t e s .
 Pazzani, M .
 (1991).
 The influence of prior knowledge on concept acquisition: Experimental and computational results.
 Journal of Experimental Psychology: Learning, Memory & Cognition, 17, 3, 41632.
 Rosch E.
 (1978).
 Principles of categorization.
 In Cognition and categorization (Ed.
), Rosch E.
 & Lloyd B.
.
 Hillsdale, NJ.
: Lawrence Erlbaum Associates.
 Rumelhart, D.
, Hinton, G.
, & Williams, R.
 (1986).
 Learning internal representations by backpropagating errors.
 In: Rumelhart, D.
, McClelland, J.
 (eds.
).
 Parallel Distributed Processing, Cambridge, M A : MIT Press.
 Towell, G.
 Shavlik, J.
 & Noordewier, M .
 (1990).
 Refinement of approximate domain theories by knowledgebased neural networks.
 Proceedings of the Eighth National Conference on Artificial Intelligence (pp.
 86166).
 Cambridge, M A : M I T Press.
 Waldmann, M .
 & Holyoak, K.
 (1990).
 Can causal induction be reduced to associative learning? Proceedings of the Twelfth Annual Conference of the Cognitive Science Society Cambridge, M A : Lawrence Erlbaum.
 Wattenmaker, W.
, Dewey, G.
, Murphy, T.
, & Medin, D.
 (1986).
 Linear separability and concept learning: Context, relational properties and concept naturalness.
 Cognitive Psychology, 18, 158194.
 Wisniewski, E.
 & Medin, D.
 (1994).
 O n the interaction of data and theory in concept learning.
 Cognitive Science, 18, 221282.
 618 Exploring the Variety and Use of Punctuation Bernard Jones Centre lor Cognitive Science University of Edinburgh 2 Buccleuch Place Edinburgh, EH8 9LW United Kingdom bernie@cogsci.
ed.
ac.
uk Abstract Several studies have indicated that NLP could benefit from the inclusion of a treatment of punctuation.
 The main impediment to the construction of any such implementation is that there no theory of punctuation upon which to base it.
 More basically, little is currently known about just what punctuation marks exist, how much they are used, and how they interact with each other This study aims to answer these basic questions through the analysis of a very large corpus, and some suggestions are made for the formulation of a theory of punctuation.
 Introduction In the field of natural language processing, punctuation has been almost universally ignored, with perhaps the single exception of the period^ marking the end of sentences.
 The reason for this apparent shunning is quite simple: there are no good, solid theories of the form and function of punctuation upon which to base any treatment in any computational system or linguistic theory.
 Therefore most current systems will simply strip out any punctuation occurring in text to be analysed or generate text that contains no punctuation marks.
 Intuitively this seems very wrong.
 Punctuation is undeniably an integral part of written language — it would be almost unthinkable to have a newspaper article or scientific paper devoid of all punctuation other than sentence breaks, for example.
 Therefore it is likely that any system ignoring these extra cues within the text will suffer from reduced performance, especially if the text to be processed is real, i.
e.
 the more complex sentences found in corpora from realworld sources.
 Several studies have already shown the potential benefits of utilising punctuation.
 The study by Dale (1991) has shown the potential for punctuation in the fields of discourse structure and semantics.
 H e suggests that punctuation marks can not only indicate degrees of rhetorical balance and aggregation between juxtaposed textual elements, but also that some punctuation marks can actually suggest the rhetorical relations that hold between such elements.
 Additionally Dale has shown by using punctuation in real sentences that discourse structure below sentence level is a reality, which prior emphasis on spoken material had deceptively missed.
 'Throughout this paper 1 shall refer to sentencefinal dots as periods rather than fullstops, to avoid confusion.
 Our study similarly shows the potential for the use of punctuation in syntax and parsing (Jones, 1994b).
 A comparison was made between the performance of two grammars, identical except that one made use of punctuation and the other ignored it.
 For sentences that were simple in syntactic structure and punctuation use, results were similar between the two grammars.
 However, for the more complex sentences the punctuated grammar yielded numbers of parses that were typically two orders of magnitude smaller than those from the unpunctuated grammar.
 In addition to this improved performance, the study showed that use of punctuation in the grammar gave parsing results that better reflected the linguistic structure of the sentence.
 In a further analysis of the results of this study, (Jones, 1994a), w e showed that while there was no good relationship between the number of punctuated parses and overall sentence length or number of punctuation marks in the sentence, there was a relationship between the average length of unpunctuated lexical segments in a sentence (how many words occur between the punctuation marks in a given sentence, on average) and the number of punctuated parses of a sentence.
 This would seem to reinforce the arguments for making the maxim u m amount of use of punctuation in syntactic text analysis.
 If the conclusions of these various studies are believed, then it must be a priority to generate some theory on which implementations of punctuation can be based.
 However, before any investigations are carried out into the syntactic and semantic functions of punctuation, i.
e.
 the interaction of punctuation and the surrounding lexical items, it is first necessary to investigate the punctuation marks themselves.
 Whilst most of us could quickly produce a list of 'obvious' punctuation marks, lists from different people will not necessarily correlate.
 Furthermore, it is not clear which punctuation symbols are used in the texts w e are likely to be analysing.
 A n important conclusion from our earlier studies was that the adhoc punctuation grammar used had extremely poor coverage of punctuation phenomena.
 Hence it seems necessary to determine just which punctuation symbols out of the whole set are likely to be used by different categories of text producers.
 A University academic, for example, is likely to have a very different usage to a highschool student.
 This paper describes an investigation of what constitutes punctuation in real text, which symbols are used, h ow they interact and ho w frequently they occur.
 619 mailto:bernie@cogsci.
ed.
ac.
ukPunctuation Punctuation, as it is considered by most people, can be defined as the range of nonlexical orthography.
 This definition includes a \cry wide range of phenomena, from the sublexical (hyphens, apostrophes) through the interlexical punctuation marks to stylistic devices such as underlining and italicising, and structural devices such as paragraphing and bulletpoint itemisation.
 Since the superlexical devices are still hard to represent in a computational system (since they are chiefly visual in orientation) they are not considered here.
 The sublexical marks are not terribly interesting, since their function and application is well understood and straightforward.
 Therefore they are also be ignored here, except where they interact with the interlexical punctuation marks, e.
g.
 when they occur in wordfinal positions.
 This investigation therefore focuses on the central portion of the range of nonlexical textphenomena which includes the familiar punctuation symbols shown in (I).
 Specifically, all symbols occurring between adjacent lexical items are of interest, and therefore it is quite possible that the interword space could be considered as a punctuation mark.
 Whilst such an observation is of limited use in a language such as English, for languages like German, where compound words are often concatenated, it is quite possible that careful consideration of the space symbol could be useful.
 Table 1: The Corpora used for punctuation extraction.
 (1) I 9 The literature on punctuation is not plentiful, but can be divided into two categories: the stylistic and the academic.
 The former category is the larger but is of limited relevance to this study.
 G o o d examples of socalled 'style guides' are those by Jarvie (1992) and Partridge (1953), but whilst their coverage of conventional punctuation is impressive, they do not mention many of the less c o m m o n marks that can be found in real corpus examples.
 In addition, these guides tend to be rather prescriptive, ruling out many constructs that can be observed in real text.
 Academic books, specifically those by Meyer (1987) and Nunberg (1990), set out to be analytical and descriptive rather than prescriptive.
 However, the punctuation coverage in these books is fairly limited.
 Meyer only considers the marks in (1) and parentheticals whilst Nunberg augments these with various quotation marks and considerations of structural devices.
 Therefore it seems necessary to determine the true extent and variety of punctuation marks in realistic text, and to discover h o w these marks interact with each other This information could then be used to help determine the linguistic form and function of punctuation marks within text — a prerequisite for the formulation of any theory and implementation of punctuation for NLP.
 Procedure A varied set of machinereadable corpora were processed to extract the punctuation patterns from sentences.
 For each senCorpus The Guardian'90 The Guardian '91 Leverhulme The Bible Philosophy (IPPE) Project Gutenberg Usenet Total Corpus size (words) 23,963,515 21,638,956 355,594 820,731 518,138 13,747,367 22,779,757 83,824,058 Corpus size (sentences) 961,604 879,438 15,547 30,021 28,945 649,069 1.
658.
707 4.
223.
331 Words per sentence 24.
9 24.
6 22.
8 27.
3 17.
9 21.
2 13.
7 19.
8 tence in a corpus, adjacent lexical items that were not separated by punctuation were replaced by a marker The punctuation patterns, consisting of all the marks of punctuation (all nonalphanumeric interlexical characters) in a sentence.
 with lexical markers inserted appropriately, are then collected.
 Thus the punctuation pattern for the previous sentence would have been as in (2).
 (2) (3) e , e ( e ) e , e , e .
 e ; e , e,e.
 Sentence closure is detected by the presence of a period (or other sentencefinal marker, such as the question mark or ellipsis (.
.
.
)) unless it occurs within a set of bracketing characters or quotation marks.
 In such a case, the end of the delimiting structure must be reached before a sentence closure can be triggered.
 To satisfy the principles of quote and bracket transposition (Nunberg, 1990), a closure marker immediately followed by a final delimiting mark is treated as valid, despite the apparent nesting violation (3).
 If the closure marker is followed by any punctuation mark other than a delimiting one or another closure marker, then it is not treated as valid.
 Blank lines, or endoffiles are treated as valid sentence closures and any nesting information for bracketing or quotation is reset in these circumstances.
 The punctuation patterns so obtained are processed to produce the frequency of occurrence for each pattern in a given corpus, and then the patterns are broken down into their constituent symbols to produce the total frequency of each punctuation character.
 Note that a punctuation character is not necessarily the same as a punctuation mark, since some punctuation marks may be composed of two or more punctuation characters.
 Both these sets of frequency information are reported and discussed in the results, especially contrasts and similarities between results for different corpora.
 In addition, the original punctuation patterns themselves are discussed with reference to conventional expectations for punctuation use.
 Corpora The corpora used, with their sizes and average sentence length, are shown in Table 1.
 The corpora together total almost 84 million words — over four million sentences — and 620 Table 2: Mean distance (wds) between similar punctuation characters.
 (• represents numbers above 10,000) 7 ( ) [ ] < > { } ' " # * * 1 / \ & % $ + = @ f*tab Ttl Guardian 1990 22 919 5556 19 369 518 1724 364 363 • • • • • • 74 69 • • • • • • 6015 • 3547 • • 7 1991 22 790 3311 19 329 535 341 380 377 • • 4444 199 40 • • • • • 7037 • 3711 • • • 7 Lever hulme 22 859 1357 31 893 835 256 267 257 • • • • • • 210 148 • 9118 • 3521 • 4445 7730 2044 • 1539 5229 • • 55 8 Bible 31 249 2622 12 65 81 • 3714 3714 3616 7 IPPE 16 494 2617 16 131 359 47 72 70 978 1110 9090 1400 • 8933 784 305 491 6923 415 8933 2927 2186 3454 168 1134 7971 • • 594 • • 875 4 Proj.
 Gul.
 22 244 318 13 97 86 133 183 177 1640 1613 • 5328 2575 2680 848 349 61 831 622 • • 5956 • 325 • 165 1264 1729 510 • • 5 Use ncl IS 146 185 20 81 320 38 75 66 479 459 460 233 2797 2848 803 280 74 433 115 319 523 421 907 166 1101 923 437 334 202 1026 1014 4 come from a wide range of sources.
 The two full years of The Guardian (a British daily newspaper), the King James Version of the Bible and texts from Project Gutenberg (an online electronic text initiative)̂  constitute the more 'formal' portions of the data.
 These have been produced with the help of editorial style guides/policies (so a more formal, constrained use of punctuation is expected), whilst the other three corpora have been produced more freely, without the help, or hindrance, of such guides.
 Of these three freer corpora, the Philosophy corpus (a collection of philosophical papers from the IPPE initiative) is likely to be the most formal, and the Usenet corpus^ is likely to be the least formal.
 The Leverhulme corpus consists of essays by secondaryschool children (1118 years old), and hence is ^But it should be stressed that such datarich Project Gutenberg files as TT to a million decimal places have not been included! ^This corpus was collected from Usenet spool files from all newsgroups except those in the comp hierarchy.
 Thanks are due to Steve Finch for permission to use and modify his grab program to perform this extraction.
 a corpus of text that has been produced in a formal setting, but by learners.
 Hence these corpora should yield information regarding the use of punctuation by learners, and use of punctuation in formal and informal settings by writers w h o (should) know how to punctuate.
 Quantitative Results The most useful way of presenting frequency results for punctuation characters is their frequency of occurrence with respect to the lexical items surrounding them''.
 Table 2 shows the average number of lexical items occurring between each instance of a particular punctuation character.
 The analysis has shown 33 different printing punctuation marks.
 It could be argued that some of the punctuation characters in the table should be lexicalised since they (usually) have very specific meanings when used in text.
 This is particularly true for those shown in (4).
 (4) # & % $ + = @ Punctuation frequency Punctuation frequency information is one of the most important sets of results that can be obtained from this study.
 It will obviously be more important to develop an interpretation for a very frequent punctuation mark than for one that is only likely to occur once in every 1000 sentences.
 The c o m m a seems to be the most popular symbol overall.
 In most corpora it occurs at least once per sentence, excepting the Leverhulme corpus where the probability of a c o m m a is 0.
75 per sentence and Usenet, where the probability is 0.
67.
 Stress markers (? !) are relatively infrequent compared with normal dots.
 The probability of a questionmark varies from 0.
11 to 0.
03 per sentence across corpora, and the variation for the exclamation mark is from 0.
09 to 0.
01.
 Although they are least frequent in the styleguided material and are most frequent in informal material such as Usenet, the frequency of these symbols seems to reflect the genre of the material more than its formality — Project Gutenberg, for example, is very rich in them.
 Interestingly, the Bible has the highest frequency of question marks and one of the lowest for exclamation marks, which is a reflection of its particular content rather than anything else.
 The question mark is more frequent than the exclamation mark in all the corpora, but the difference in frequency between the two narrows in the freer corpora.
 The bracketing and quotation characters seem mostly to be equal in frequency between opening and closing characters, confirming their matching role.
 Minor discrepancies can be explained by missed openings or closings (either by author or analysis), but the larger discrepancies are due to use of symbols other than in their matching roles.
 For example, the higher percentage of closing single quotes than opening ones in many corpora is due either to the use of closing quotes to "The raw numerical results are uninteresting since the corpora are of wildly different sizes, and frequency per sentence is affected by varying sentence length.
 621 mark both beginning and end of a quotation, or to an abundance of wordfinal apostrophes.
 Frequencies again tend to be rather more dependent on genre than fonnaUty of corpora.
 The journalistic corpora, for example, have a set of quotation marks every three sentences, on average, reflecting a high instance of reported utterances.
 The characters that correspond to the remaining items of point punctuation — the colon, semicolon and dash — occur with greater frequency in most of the corpora than the unusual symbols in the lower portion of Table 2.
 They also tend to be more frequent than the stressmarkers.
 In most of the corpora the colon occurs more frequently than the semicolon; the dash occurs with unpredictable frequency though, from only two occurrences in the entire Bible to a high of almost 10% of the punctuation in Usenet.
 Once more, the frequency of the symbols seems dependant on the genre of the corpora.
 The only non point symbols that occur with any regularity are the various matched bracket and quotation symbols (the type used varies between corpora); the asterisk, equals sign and underscore in the Usenet, Philosophy and Gutenberg corpora; and oneoffs such as the percent sign in the Gutenberg and the caret in the Usenet corpus.
 Spread The spread of symbols varies considerably between the corpora.
 Almost all the corpora contain all the punctuation marks shown in the top three sections of Table 2, albeit in varying frequencies.
 The Bible is the single exception — it contains only a few instances of the matching punctuation symbols in the third section of the table.
 This is presumably because of its highly standardised and edited nature.
 The more unusual punctuation symbols in the lower portion of the table do not occur as standardly in all corpora.
 The Bible and Guardian corpora contain fewer types of these symbols than the other corpora, and the symbols the Guardian corpora do contain are far less frequent than in other corpora.
 The corpus that contains most of these unusual symbols is the Usenet corpus, which perhaps reflects the danger of letting largely untrained people loose on keyboards that contain too many pretty characters! Stylistic Quirks Some stylistic differences between corpora also emerge from the results.
 It is clear from the figures that, for example, the Guardian uses single quotation marks (which happen to be concatenated, forming double quotes) rather than the doublequote symbol, and that this situation is reversed in the other corpora, except the Bible, which does not contain quotation marks at all.
 From Table 2 it appears that at least one type of quotation character is used in the Bible, but this is an anomaly that has been caused by the presence of wordfinal apostrophes.
 General Observations Some corpora appear to have more than one sentencefinal character per sentence.
 There are several explanations for Table 3: Frequencies of increasingly complex sentences.
 Commas per sentence 0(e.
) 1 (e,e.
) 2 (e,e,e.
) 3 (e,e,e,e.
) 4 5 6 7 8 Total The Guardian 1990 64,599 4 4 % 38,882 2 6 % 27,282 1 8 % 10,759 7% 4,048 3% 1,541 1% 569 234 98 148,012 1991 80,606 43% 48,273 26% 35,123 19% 13,747 7% 5,274 3% 2,012 1% 750 306 127 186,218 Leverhulme 3,940 63% 1,440 23% 628 10% 188 3% 53 1% 22 6 4 6,281 this: the characters could be compounded (.
.
.
 !!!) or sentences could contain several subsentences inside delimiting structures.
 Stress markers can also legitimately occur within sentences, stressing particular words or phrases.
 While the comma and dot are the two most popular characters, their relative importance varies greatly.
 In the styleguided corpora the comma is more important than the dot, occurring from 14.
4% more frequently (The Guardian, 1992) to 170% more frequently (the Bible has almost three times more commas than dots).
 The freer corpora produce more varied results: the Philosophy corpus is almost at parity; the Usenet corpus has 33% more dots; and Leverhulme corpus has 43% more dots than commas.
 Note that we are referring to dots here rather than periods, since these are punctuation symbols we are reporting, not marks.
 Some of these dots may be combined into other marks (e.
g.
 ellipsis), so not all will act as periods.
 Sentential Punctuation The average number of punctuation symbols per sentence varies between corpora from 2.
89 in the Bible to 4.
41 in Project Gutenberg.
 Similarly the average number of words between (any) punctuation symbols changes across the corpora.
 It decreases from the formal corpora to the less formal ones, the exception being the Leverhulme corpus, which has the longest distances between punctuation.
 Table 3 shows the relative frequencies of increasingly complex commaseparated multiclausal sentences in sections of the Guardian and Leverhulme corpora, proving that increasing punctuational complexity corresponds to decreasing occurrence in the corpus.
 Similar results are observed with sentences containing colons and semicolons in addition to commas.
 Table 4 shows the twenty most popular sentence patterns in all the corpora.
 It is interesting to note the unconventional, unstopped patterns that appear, and also the isolated dots, which are probably caused both by spacing out ellipsis marks and separating the sentenceclosing punctuation mark from the end of the sentence.
 622 Table 4: The 20 most frequent sentence punctuation patterns.
 Rank 1 2 3 4 5 6 7 Pattern e.
 e,e.
 e,e,e.
 e,e,e,e.
 e? e e,e,e,e,e.
 Rank 8 9 10 11 12 13 14 Pattern e:e.
 e! "e,"e.
 e"e"e.
 e: e(e)e: Rank 15 16 17 18 19 20 Pattern e,e,c,e,c.
c.
 c(e)c.
 e.
e? e.
.
.
 e;e.
 "e.
" Table 6: Sample 'valid' corpus punctuation patterns.
 1 ", ( )) .
) / ?•) Ill # 0 ).
' ,_ +7; !"$) (' )}• @ !"? %.
 )'? * : :[?] !) & !"' + .
") •' [" ' !"? ," « < ].
 "): '}; \ .
(1 •} >v _,_ Table 5: S o m e anomalous corpus punctuation patterns.
 !!;( 91 ••{" •* ?:) /= 1 ! : ) " ,.
 '' .
(: !:) • !;> !"> :: :" !, !.
" !.
 r —• »t *' 1 • .
& : !:"' !:( 1 ") !•&) 1.
!:( :) !;) Qualitative Results Table 5 shows some of the anomalous punctuation concatenations that have been extracted from the corpora.
 Whilst some of these patterns can instantly be recognised as mistakes [,.
 „] that are mainly typographical (as in (5)), most of the other patterns in the table constitute idiosyncratic or quirky usage.
 Patterns that would be judged 'incorrect' by the majority of readers [.
?! .
" ,&] due to conflict of meaning or omission of whitespace can still have some meaning extracted from them.
 There is also the whole class of quirky, nonstandard uses of punctuation, where particular marks used in a particular context will have some novel meaning [/= ::] that, if recognised, can be extracted.
 Perhaps the most typical such phenomenon observed in these results is the prevalence of the so called 'smileys', used particularly on Usenet [!;> ?:).
(:].
 Such marks may be interesting from a sociological perspective, but it also seems that they should be considered as punctuation, since their use is increasing in certain genres of text! Hence in analysis, we have to be careful about considering particular symbols or patterns 'incorrect', since very few of them are actually mistakes.
 Most symbols or patterns used will simply be idiosyncratic or unusual, so it is worth trying to extract as much information from them as is possible in the circumstances.
 (5) I will begin at the most obvious,, though not necessarily the most simple level [.
.
.
 ] Some of the more valid, uncontroversial punctuation combinations are shown in Table 6.
 Here it is worth noting that whilst all the patterns are 'valid' in some sense of the word, not all are the types of patterns one would expect to find in a normal text.
 [@ %.
 # + < « ] are examples of these unusual punctuation patterns that one might expect to find in certain genres of text (e.
g.
 financial reports), but would be surprised to find in, say, a novel.
 Furthermore, even of the more conventionally linguistic patterns there are some unusual ones, that would only appear normal within specific contexts, e.
g.
 [!" ? [?] ,(|].
 Thus there is an argument for considering all the various marks of punctuation, including those that are deemed to be genrespecific, since these will very often carry a great deal of meaning.
 Sentential Punctuation It is clear that some of the more prescriptive parts of punctuation theories are violated by examples occurring in real text.
 One of the few prescriptive parts of Nunberg's work, for example, states that a colonexpansion (text following a colon) cannot contain another colon but examples (6) and (7) violate this.
 Also the principle of quote transposition does not appear mandatory (8) (11), parentheses can be nested (9), stressmarkers are concatenated (10) and nested quotation marks do not have to alternate between single and double quotes (11).
 (6) Therefore the eye counters this [.
.
.
 ] so that no single group becomes depleted: in fact experiments which fix an immobile image on the eye show that subjects quickly become 'blind' to the stimulus: this is of course a significant difference [.
.
.
].
 (7) Here are some of the main arguments that have been put forward by each camp: The case for war: The argument in favour of going to war to remove Iraq from Kuwait is quite simple: Saddam Hussein has used naked aggression against a small and defenceless country.
 (8) "Sir, she fancies you".
 (9) The Alchemist, by Mark Illis (Bloomsbury, 13.
95 Pounds (pds)).
 (10) The question now was, which other blue dress??!! (11) Says Guthrie: "Iceblink Luck'sjust a good single.
 [.
.
.
] I'm amazed people think this record's a conscious attempt to be more "coherent.
" It's not a conscious attempt to 'do' anything.
" Conclusions There are several main points that can be brought out of this study.
 The first is the general unsuitability of prescriptive theories of punctuation for text analysis.
 Such a wide range of punctuation occurs in real text that almost any prescriptive theory will clash.
 Whilst such theories are of definite use in 623 the area of text generation, for text analysis a far looser system is needed.
 When a punctuation symbol is encountered, whether it is in an unusual position or not, it should be associated with a set of possible functions or meanings that can be used to assist the linguistic analysis.
 Similarly unusual punctuation mark combinations should be processed to extract the maximum amount of information possible, rather than ignoring those patterns not licensed by a prescriptive theory.
 What is more surprising is that the more linguistic, analytical theories, such as Nunberg's (1990), have also made the error of veering into being overprescriptive.
 Hence while they are of undoubted use for guiding the development of a true punctuation theory, any prescriptive parts of these theories should be ignored as much as possible in the construction of such a theory.
 The second point concerns the variety of punctuation marks we are likely to encounter.
 It now seems logical to divide the set of possible punctuation marks into two.
 This study has confirmed that there is a core subset of punctuation characters that account for the majority of instances.
 This subset of punctuation (the marks in (12), a parenthetical device and a quotational device^) could be implemented across N LP systems in a standardised manner, and cover the majority of punctuation encountered.
 Such a conclusion is not as obvious as it might seem, as the different sets of punctuation considered by the studies of Meyer (1987) and Nunberg (1990) show.
 (12) I 9 The study has also shown that there exists a second subset, formed of more unusual punctuation symbols which often have a high semantic content, e.
g.
 [% + = $].
 Since the variety and particular use of these symbols is likely to be corpus specific, it is unlikely that a standardised interpretation is possible.
 The existance of this second set is not at all obvious, since it varies between sources and often occurs far less frequently than the main set.
 However, recognition of the existance of this set, and correct analysis/use will be crucial in any proper theory of punctuation.
 Hence punctuation treatment for any system should consist of the standard and the corpusspecific parts, which together should account for all the punctuation encountered.
 Since every sentence of the English language is likely to contain 3 or 4 punctuation symbols, the argument for studying punctuation and including it in N L P is strengthened.
 The results further suggest that formal, edited writing produces more highlystructured material than less formal writing, in that punctuation is more frequent and more varied.
 The learners (Leverhulme) appear to produce text with the least complex punctuational structure.
 Free and learner writing also seem to include more stress markers than the formal style, suggesting either higher emotive content or symbol overuse.
 Hence inclusion of punctuation into analysis systems is likely to have a smaller impact if the analysed material is of a less ^ Since there are several different orthographic methods of implementing these, which vary between texts.
 formal nature, and least impact if learners material is to be examined.
 However, the punctuation that is present can still be crucial to the interpretation of the text, and so should still be considered.
 Since the majority of corpora consist of formal, edited material, however, we can see that use of punctuation has the capacity to be highly beneficial to analyses.
 The foundation has now been laid for the development of a full theory of punctuation.
 Initially, instances of punctuation symbols in grammatical sentences must be studied to determine the ways in which the punctuation interacts with the lexical items surrounding it and the syntactic stucture of the sentences containing it.
 In this field the first set of conventional punctuation symbols is likely to produce the most useful results.
 In addition to syntactic investigations, similar work should be carried out to determine the semantic form and function of punctuation, and it is in this area that the second, less c o m m o n set of punctuation symbols will prove very useful.
 From this information it should be possible to synthesise a theory of the linguistic function of punctuation marks, that can then be integrated into other linguistic systems to greatly enhance their performance, especially when dealing with real, complex sentences of natural language.
 Acknowledgements This work was carried out under a (UK) Economic and Social Research Council studentship.
 Thanks for instructive and helpful comments to Henry Thompson, Alexander Holt, Andrew Fordham and anonymous reviewers.
 References Dale, R.
 (1991).
 Exploring the Role of Punctuation in the Signalling of Discourse Structure.
 In Proceedings of the Workshop on Text Representation and Domain Modelling (pp.
 110120).
 Technical University Beriin.
 Jones, B.
 (1994a).
 Can Punctuation Help Parsing? Esprit AcquilexII Working Paper No.
 29.
 Cambridge, U K : Cambridge University Computer Laboratory.
 Jones, B.
 (1994b).
 Exploring the Role of Punctuation in Parsing Real Text.
 In Proceedings of the 15th International Conference on Computational Linguistics (COLING94) (pp.
 421425).
 Kyoto, Japan.
 Jarvie, G.
 (1992).
 Chambers Punctuation guide.
 Edinburgh, UK: W & R Chambers Ltd.
 Meyer, C.
F.
 (1987).
 A Linguistic Study of American Punctuation.
 American University Studies, Series XIII.
 N e w York: Peter Lang.
 Nunberg, G.
 (1990).
 The Linguistics of Punctuation.
 CSLI Lecture Notes 18.
 Stanford, C A : CSLI.
 Partridge, E.
 (1953).
 You Have a Point There (A Guide to Punctuation and Its Allies).
 London, U K : Hamish Hamilton Ltd.
 624 The Roles of Motion and Moving Parts in Noun and Verb Meanings Alan W.
 Kersten School of Psychology Georgia histitute of Technology AUanta.
 G A 303320170 phone: (404)8530192 psg90ck8gitvinl.
gatech.
edu Abstract This study contrasts the learning of two different kinds of motion.
 The first of these we call extrinsic motion, or the motion of one object with respect to another, reference object.
 The second we call intrinsic motion, or the motion of an object or its parts expressed with respect to the object itself.
 An experiment tests for people's abilities to associate these two types of motion with nouns and verbs.
 Subjects were presented with animated events on a computer screen accompanied by sentences involving nouns and verbs.
 In the learning phase, each noun and verb was related to both an extrinsic motion attribute and an intrinsic motion attribute.
 Subjects were then tested by presenting them with pairs of events varying on only one of these attributes and asking them which event better exemplified the meaning of a particular noun or verb.
 The results of this experiment demonstrate a bias to associate verbs with extrinsic motion and to associate nouns with intrinsic motion.
 These results suggest a division of labor between noun and verb meanings, with verb meanings specialized to encode relational information, while noun meanings are specialized to encode information about objects in isolation.
 Introduction All of the world's languages seem committed to expressing meaning through combinations of lexical items, either morphemes or independent words.
 Of course, there are many words such as "baseball" that are associated with a myriad of notions about the culture in which they are used and the functions their referents fulfill (e.
g.
, national pastime, can be hit by a bat or thrown, etc.
).
 There seem to be no languages, however, that employ individual words to describe entire events even at relatively low levels of specificity, such as "the motion of a small mammal into an enclosure in a stealthy maimer.
" Yet we can effortlessly express the same idea in greater detail using combinations of words, such as nouns, verbs, and prepositions, as in "The fox skulked into the henhouse.
" Expressing meaning through combinations of words would seem most efficient if different words contributed different aspects of meaning to the expression, eliminating redundancy through division of labor.
 This paper will explore a seeming division of labor between nouns and verbs in the expression of one particular type of meaning, namely the description of motion.
 W e will begin by trying to convince you that the division of labor proposed by your Dorrit B i l l m a n School of Psychology Georgia Institute of Technology AUanta, G A 303320170 phone: (404)8942349 b i l l m a n @ p r a v d a .
 c c .
 g a t e c h .
 e d u elementary English teacher  noims label people, places, or things, leaving to verbs the description of motion was in fact wrong, or at least overly simplistic.
 After arguing that nouns do indeed play a role in the description of motion, w e will go on to describe the role of the verb, noting how this role may be different from that of the noim.
 W e will then describe an experiment designed to test for the division of labor proposed in the introduction.
 One tends not to think of motion when one thinks about noun meanings.
 Noims are generally thought of as labels for objects, with each common noim seemingly labeling a different category of objects.
 Tversky and Hemenway (1984) have provided evidence that different basiclevel object categories are primarily distinguished based on their parts, and thus, determining which noim or noims are applicable to a particular object requires an examination of the parts of that object.
 As argued by Tversky and Hemenway (1984), however, good parts are those that have functional as well as perceptual significance.
 One function that would seem particularly important to animate objects is motion.
 For example, the legs and arms of human beings function to provide locomotion for the human body.
 Thus, the noun "human" may be associated not only with arms and legs but also the motion they provide.
 Some evidence for this claim comes from work by Johansson (1973).
 He presented observers with points of light representing various points on the bodies of walking humans.
 W h e n presented with a static image of these points, no observer identified the points as being representative of human bodies.
 W h e n these points were displayed in motion, however, every observer was almost instantly able to recognize human locomotion.
 Thus, these observers were apparendy able to categorize and label human beings based only on the relative motions of their body parts.
 The work of Barr and Caplan (1987) suggests a further role of motion in noun meanings.
 They propose two different types of features in object category representations.
 One type they call intrinsic features, which are characteristics that are true of an object when considered in isolation, such as object parts.
 Adopting Barr and Caplan's (1987) terminology, we can define intrinsic motion as the motion of an object that can be described in terms of the object itself, such as the relative motions of parts of the object.
 Barr and Caplan (1987) call the second type extrinsic features, or features that involve relations between objects.
 For example, "used to work with" is offered as an extrinsic feature of a hammer, describing a relation between a hammer 625 http://psg90ck8gitvinl.
gatech.
edumailto:billman@pravda.
cc.
gatech.
eduand a human.
 W e can similarly characterize extrinsic motion as the motion of an object relative to another object.
 Extrapolating from Barrand Caplan's (1987) distinction, w e would predict that both intrinsic and extrinsic motion play a role in object categories and the meanings of nouns that label them.
 Thus, the meaning of "cat" may include information not only about how a cat's legs move relative to its body to produce motion, but also that cats tend to chase mice and run away from dogs.
 Nelson (1983) has proposed, however, that noun meanings are first formed around objects that play the same role within an event, only later noticing perceptual similarities of fillers of this role.
 For example, a child may first use "cat" to label those things that have played the role of "chaser" in events involving mice.
 This theory thus predicts that people should first associate nouns with extrinsic motion, as roles within an event seem to involve relations between objects.
 Unlike nouns, verbs are generally regarded as conveying motion.
 Different verbs convey different types of motion, however.
 These differences are especially evident when one compares across languages.
 According to Talmy (1985), the most c o m m o n type of verb across languages is the pathspecifying verb.
 Examples of this verb in English are "enter", "exit", "ascend", and "descend".
 Such verbs seem to convey extrinsic motion, with the first two describing motion into and out of some reference object, and the second two describing motion away from and toward the earth, respectively.
 In contrast, the most c o m m o n verb type in English, and second most c o m m o n type across languages is the mannerspecifying verb (Talmy, 1985).
 Examples of this type of verb are "run", "walk", "stroll", and "saunter".
 Jackendoff (1987) has proposed that such verbs convey objectinternal motion, similar to our notion of intrinsic motion, describing different ways of moving body parts to achieve locomotion, but providing no information about path.
 Although the majority of Enghsh verbs seem to convey intrinsic motion, young children learning Enghsh seem to prefer using relational terms that convey extrinsic motion.
 Namely, children of around 14 months of age start to use pathspecifying prepositions such as "in", "out", "up", and "down", often well before they first start using verbs.
 Interestingly, children learning Korean start to use verbs at about the same point in development that children learning English start to use these prepositions, and use them in the same situations that Englishspeaking children use prepositions (Choi & Bowerman, 1991).
 Like English prepositions and unlike English verbs, these Korean verbs are pathspecifying, describing extrinsic motion.
 These findings provide evidence for a bias to associate relational terms with extrinsic motion.
 Such a bias would facilitate the learning of verbs in many languages and prepositions in English, but would have to be overcome to learn many verbs in English, accounting for the delayed acquisition of these verbs relative to prepositions and verbs in other languages.
 Given such a bias, a sensible division of labor between nouns and verbs in the description of motion would seem to require a bias to associate nouns with intrinsic motion.
 Such a bias would facilitate the association of nouns with the relative motions of body parts, as was found by Johansson (1973).
 It would, however, be inconsistent with Nelson's (1983) theory.
 The following experiment tested the prediction that nouns tend to be more strongly associated with intrinsic motion than with extrinsic motion, and that verbs tend to be more strongly associated with extrinsic motion than intrinsic motion.
 To this end, we used computers to create animated events involving two characters, one of which moved throughout the course of the event.
 Each event was accompanied by a sentence involving a novel noun and verb.
 During learning, each noun and verb was associated with one value of each of several attributes, as depicted in Figure 1.
 Most crucially, each noun and each verb was associated with one value of an intrinsic motion attribute, the leg motion of the moving character, and one value of an extrinsic motion attribute, the path of the moving character relative to the other character.
 Figure 1.
 Schema for learning events seen by subjects for w h o m legs differentiated the four nouns.
 Orientation differentiates the four verbs here, while each leg motion and path is associated with two nouns and two verbs.
 626 After a number of learning events, knowledge of these relations was tested by presenting subjects with pairs of events that differed on the value of only one of the relevant attributes, asking the subject to indicate which of the two events better exempUfied the meaning of a particular noun or verb.
 Subjects were predicted to more strongly associate nouns with leg motion than with path, and to more strongly associate verbs widi path than with leg motion.
 Learning to associate nouns with leg motion, however, may require those nouns to also be associated with the appearances of the legs carrying out that motion.
 To test this conjecture, nouns were associated with legs for half of the subjects, as depictedin Figure 1, while they were associated with heads for the other half.
 W e predicted that subjects would show more learning of the relation between nouns and leg motions when those nouns were related to legs than when they were related only to heads.
 Method Subjects Sixty undergraduates at the Georgia Institute of Technology received course credit for participation in this experiment.
 Stimuli All Events.
 The events were displayed on Macintosh II computers using MacroMind Director 2.
0.
 Two characters appeared in each event.
 Each character was composed of three attributes: head, body, and legs.
 Each of these attributes had four possible values.
 In addition, one of the characters, the agent, moved throughout the course of the event, while the other, the patient, remained stationary.
 An agent's motion could be described by three attributes.
 One was the path of the agent, or the direction(s) taken by the agent relative to the patient.
 A second motionrelated attribute was the leg motion of the agent.
 Schematic descriptions of the values of these two attributes are shown in Figure 2.
 A third motionrelated attribute was the orientation of the agent as it moved.
 Some agents moved in the directions they faced, some moved backwards, some moved to the left, and some moved to the right.
 A static background was also present in each event.
 The four backgrounds were a swamp, a desert, a mountain scene, and a rocky plain.
 Learning Events.
 There were 80 learning events.
 Each learning event was accompanied by a spoken sentence presented by the computer.
 Each sentence involved a novel noun, preceded by "the", and a novel verb, preceded by "is" and followed by "'ing".
 There were four different nouns and four different verbs.
 Throughout learning, each noun always accompanied a particular value of one of the body parts of the agent.
 For half of the subjects, this was the head, while for half, it was the legs.
 Each verb was always accompanied by a particular orientation by the agent.
 Thus, one verb corresponded to moving forwards, one to moving backwards.
 and so on.
 Two attributes, leg motion and path, were related to both nouns and verbs.
 This was accomplished by presenting each subject with only two of the four possible values of each of these attributes, with the choice of which two values to be presented and how these values related to the noun and verb determined randomly for each subject.
 Each value of each of these attributes was associated with two of the nouns and two of the verbs.
 Values for other attributes were assigned randomly in each event.
 t < A J\ A.
 .
 A I < P ^ P P Figure 2.
 Values of leg motion (top) and path (bottom) in this experiment.
 The A and P on the bottom represent the agent and patient, respectively.
 Word Meaning Test Events.
 There were 24 trials testing the meanings of individual words.
 Each trial involved a forced choice between two events, so that there were 48 events during this part of the experiment.
 During each test trial, one event was presented, accompanied by a spoken question about the meaning of an individual noim or verb, asking "Is this" and followed either by "a" and a noim or by a verb followed by "ing".
 During the second event, a subject was asked the same question as in the first event, after which (s)he had to choose which event better exemplified the meaning of the word accompanying the event.
 In each trial, one event was entirely correct while the other event had one attribute whose value mismatched the meaning of the noun or verb accompanying the event.
 Each trial thus tested the association of one attribute with a noun or a verb.
 Twelve trials tested for knowledge of nouns, 4 testing associations with either heads or legs, 4 testing associations with leg motions, and 4 testing associations with paths.
 Twelve other trials tested for knowledge of verbs, 4 testing associations with orientations, 4 testing associations with leg motions, and 4 testing associations with paths.
 Novel Combinations Test Events.
 After the word meaning test trials, there were 16 trials testing for interpretations of sentences involving nouns and verbs not found together during learning.
 For example.
 Noun 1 and Verb 3 in Figure 1 would have been paired together only in a novel combinations trial.
 The reason why such nouns and verbs had not been paired together during learning was that they had been associated with different values of leg motion and path.
 Thus, when used together in a sentence, they 627 made conflicting predictions for the values of those attributes.
 Each novel combinations trial involved two events.
 In one event, the values of leg motion and path were consistent with the meaning of the verb in the sentence accompanying the event.
 In the other event, one of these two attributes took a value consistent with the noim, while the other took a value consistent with the verb.
 At the end of each trial, subjects were asked to choose which of the two events better exemplified the meaning of the sentence.
 A subject thus had to decide whether the noun or verb was more important in predicting the value of the attribute varying across events.
 Eight trials varied leg motion, while 8 varied path.
 In every event, the value of either agent legs or agent head was consistent with the meaning of the noun, while the value of orientation was consistent with the meaning of the verb.
 Procedure Subjects were instructed that they were to view a number of events depicting life on another planet, and that they were to leam the meanings of words accompanying those events.
 Subjects were then presented with 80 learning events.
 After each learning event, the subject clicked on a button labeled "Next Event" to continue.
 At the end of learning, subjects were instructed that they were to be tested on their knowledge of the nouns and verbs heard during learning.
 Subjects were then presented with 24 word meaning test trials, each involving 2 events.
 At the end of the first event in each trial, the subject clicked on the "Next Event" button to see the second event in the trial.
 At the end of the second event, subjects pressed one of three buttons.
 One button, labeled "Repeat" allowed subjects to view the two events in the trial again.
 The other two buttons were labeled "First Event" and "Second Event", allowing the subject to indicate which event was the better example of the word accompanying the events.
 Subjects were then presented with the 16 novel combinations trials, following the same procedure.
 Design The primary dependent measure in this experiment was accuracy at choosing the correct events in the word meaning test trials.
 The two withinsubjects independent variables were the part of speech of the word accompanying each test trial (noun vs.
 verb) and the attribute being tested (leg motion vs.
 path).
 Manipulated betweensubjects was the choice of body part to fully differentiate nouns (head vs.
 legs).
 Results During the word meaning test trials, subjects were tested 4 times with each combination of part of speech and the attribute being tested, so that chance performance would produce a score of 2.
 As predicted, subjects more strongly associated nouns with leg motion (M = 2.
60, S D  1.
11) than with path (M  2.
27, S D = 1.
18).
 This difference was significant, t(59) = 1.
80, p < .
05 (onetailed).
 Also as predicted, subjects more strongly associated verbs with path (M = 3.
40, S D = 1.
01) than with leg motion (M = 3.
03, S D = 0.
97).
 This difference was also significant, t(59) = 2.
18, p < .
05 (onetailed).
 A n A N O V A on these data revealed a significant interaction of part of speech and the attribute being tested, F(l,58) = 7.
70, p < .
01, M S E = 0.
95, as well as a main effect of part of speech, F(l,58) = 33.
75, p < .
001, M S E = 1.
09.
 Contrary to prediction, the body part associated with nouns had no significant main effect, F(l,58) = 1.
75, p > .
10, M S E = 1.
61, nor any significant interactions, all Fs < 1.
00.
 As can be seen in Figure 3, however, subjects showed a tendency to more strongly associate nouns with leg motion when the values of legs were also related to noun meaning (M = 2.
83, S D = 1.
09) than when only the values of head could be used to differentiate the four nouns (M = 2.
37, S D = 1.
10).
 N ouns Differentiated by Heads 100 Leg Motion Path Noun Verb Part of Speech Nouns Differentiated by Legs 100 90 t o o 4—' <r> o a: 80 70 60 50 • Leg Motion Ba Path ».
 \ \ —f k \ \ y y y y Noun Verb Part of Speech Figure 3.
 Results of the word meaning test tnals.
 628 CO CD c > o <4—• O 4—' <r\ O) {̂  q) CX •fi a> >• C; 4 • ^ c u> 4—' oo C/1 c <> o l O O 8060 4020 o• Leg Motion ra Path H e a d Legs N o u n s Differentiated b y Figure 4.
 Results of the novel combinations test trials.
 Subjects were also tested on relations between nouns and either heads or legs and between verbs and orientations.
 When heads differentiated nouns, subjects averaged 3.
03 (SD = 1.
07) on relations between nouns and heads, and 3.
23 (SD  1.
01) on relations between verbs and orientations.
 W h e n legs differentiated nouns, subjects averaged 3.
00 (SD = 1.
08) on relations between nouns and legs, and 3.
03 (SD = 1.
13) on relations between verbs and orientations.
 In the novel combinations trials, leg motion varied on 8 trials, while path varied on the other 8.
 These trials were scored for the number of choices consistent with the verb.
 Thus, if a subject showed no preference for associating an attribute with one part of speech over the other, a score of 4 would be obtained.
 Choices perfectly consistent with the verb would produce a score of 8, while choices perfectly consistent with the noun would result in a score of 0.
 Overall, subjects more strongly associated path with verbs than with nouns, with an average score of 6.
57 (SD = 1.
75).
 In contrast, subjects showed no preference for associating leg motion with one part of speech over the other, with an average of 4.
37 (SD = 2.
49).
 This pattern of results produced a main effect of attribute, F(l,58)  33.
16, p < .
001, M S E = 4.
38.
 The body part associated with nouns had relatively little impact on path scores, with an average of 6.
70 (SD = 1.
73) when nouns were differentiated by heads and 6.
43 (SD = 1.
79) when nouns were differentiated by legs.
 Body part had important consequences for leg motion scores, however (see Figure 4).
 Subjects averaged 5.
33 (SD = 2.
31) when heads differentiated the four nouns, compared to an average of only 3.
40 (SD = 2.
31) when legs played this role.
 This pattern of results produced significant main effects of body part, F( 1,58)= 8.
94, p < .
01, M S E = 4.
06, and test attribute, F(l,58) = 33.
16, p < .
001, M S E = 4.
38, as well as a significant interaction of body part with attribute, F(l,58) = 4.
76, p < .
05, M S E = 4.
38.
 Discussion The results of this experiment provide evidence for a set d" biases that function to create a division of labor between nouns and verbs in the description of motion.
 The finding that nouns were more strongly associated with leg motion than with path may be indicative of a general bias to associate nouns with intrinsic motion.
 In contrast, the opposite pattern of results with verbs may exemplify a bias to associate verbs with extrinsic motion.
 It should be noted that progressive forms of the verbs used in these experiments (e.
g.
, "morping") are in some sense more "nounhke" than finite verbs (e.
g.
, "morp").
 Progressive forms were used because these seemed most natural in describing actions occurring simultaneously with the accompanying speech.
 This decision may have reduced the differences between nouns and verbs, however, and thus diere is reason to believe that the contrasts between nouns and veibs discovered in this experiment are fairly robust.
 In contrast to the intuitive definition that verbs label motion while nouns label only objects, leg motion was foimd in both the word meaning and novel combinations trials to be roughly equally associated with nouns and verbs, at least when the appearance of the legs was also related to noun meaning.
 Moreover, in novel combinations trials where subjects chose the leg motion consistent with the noun, path was always consistent with the verb, and thus they chose a novel combination of leg motion and path over a familiar combination seen during learning.
 Without the influence of path, subjects may have been even more willing to choose the leg motion consistent with noun over that consistent with the verb.
 This issue is also being explored in other work.
 In addition, the finding that subjects chose leg motions consistent with the noun more often when legs differentiated the four nouns provides evidence that associations between nouns and motions may be mediated by the parts carrying out those motions.
 This is reasonable given that realworld nouns are associated with maimers of motion only because the objects labeled by those nouns have evolved particular configurations of body parts that are conducive to motion.
 The finding that intrinsic motion is associated with both nouns and verbs is consistent with Langacker's (1990) notion of a nominal predication.
 According to Langacker, nominal predications (e.
g.
, nouns) differ from relational predications (e.
g.
, verbs) not in their content, but rather in how this content is construed.
 Langacker offers as an 629 example the terms "group" and "together," the first a nominal predication and the second a relational predication.
 These predications reflect the same content, namely a close configuration among a number of entities.
 In the present experiment, body parts may have played a similar role to the entities in this example, with nouns and verbs mapped onto the configuration of body parts of a creature.
 Langacker's theory can also explain why nouns were not associated with extrinsic motion, as nominal predications are thought of as bounded entities.
 These boundaries fall most naturally around the extent of the object itself, ruling out any influence of an external, reference object.
 The finding that nouns and verbs were equally associated with intrinsic motion, however, seems to conflict with Langacker's theory.
 In this theory, relational predications place primary emphasis on the interconnections between entities, while nominal predictions emphasize the entities themselves.
 This would seem to predict that information about the relation between the legs and body of a creature would always be more strongly associated with verbs than with nouns.
 This pattern of results was found only when the appearance of the legs was random.
 In summary, this work provides a new experimental method for studying differences between nouns and verbs.
 This method could be very useful in understanding how these two differoit types of concept are represented and how these representations interact in the production and interpretation of sentences.
 This study provides evidence that motion is not exclusively represented in verb meanings, but rather that nouns and verbs must work together to this end Tversky, B.
, & Hemenway, K.
 (1984).
 Objects, parts, and categories.
 Journal of Experimental Psychology: General.
 113, 169197.
 References Barr, R.
A.
, & Caplan, L.
J.
 (1987).
 Category representations and their implications for category structure.
 Memory and Cognition, 75(5), 397418.
 Choi, S.
, & Bowerman, M.
 (1991).
 Learning to express motion events in English and Korean: The influence of languagespecific lexicalization patterns.
 Cognition, 41, 83121.
 Jackendoff, R.
 (1987).
 On beyond zebra; The relation of hnguistic and visual information.
 Cognition, 26, 115122.
 Johansson, G.
 (1973).
 Visual perception of biological motion and a model for its analysis.
 Perception and Psychophysics, 14, 201211.
 Langacker, R.
W.
 (1990).
 Concept, image, and symbol.
 Berlin; Mouton de Gruyter.
 Nelson, K.
 (1983).
 The derivation of concepts and categories from event representations.
 In E.
 Scholnick (Ed.
), N e w trends in conceptual representation: Challenges to Piaget's theory (pp.
 129150).
 Hillsdale, NJ; Lawrence Erlbaimi Associates.
 Talmy, L.
 (1985).
 Lexicalization patterns; Semantic structure in lexical forms.
 In T.
 Shopen (Ed.
), Language typology and linguistic description.
 Vol.
 3: Grammatical categories and the lexicon.
 Cambridge University Press; Cambridge.
 630 S O U L : A Cognitive Parser Lars Konieczny Center for Cognitive Science Institute of Computer Science and Social Research University of Freiburg, Germany lars@cognition.
iig.
unifreiburg.
de Gerhard Stnibe Center for Cognitive Science Institute of Computer Science and Social Research University of Freiburg, Germany strubeQcognition.
iig.
unifreiburg.
de Abstract In this paper, we introduce a new model of human sentence processing.
 The psychological issues addressed include the use of lexical information, specifically subcategorization information, during the initial stage of syntactic structure assembly, the issue of linear parsing, i.
e.
 immediate attachment of words to the sentence structure, within a headdriven grammar framewoik, and the resolution of attachment ambiguities.
 W e will demonsu^te that the variety of psycholinguistic phenomena can be accounted for by the assumption of principled behavior of linguistic signs, which are implemented in an objectoriented fashion.
 The model provides a serial implementation of Parametrized Head Attachment.
 Parsers as a d e q u a t e cognitive m o d e l s Cognitive parsers are computational models of human cognitive processes with respect to the syntactic analysis of natural language.
 To qualify for that, those models first have to be computationally sufficient, which means that they must be able to parse sentences of some natural language (or at least a nontrivial subset of those).
 The second criterion is that cognitive parsers must be shown to proceed in a way that leads to the same behavior that has been found in studies of human parsing, i.
e.
, the same kind of errors, and the same preferences in analysis.
 A third, ambitious criterion, labeled 'type transparency', has been specified by Berwick and Weinberg (1985), w h o suggest that 'granunatical representations are embedded directly into parsers, without intervening derived predicates or multipliedout rule systems'.
 The S O U L (SemanticsOriented Unificationbased Language) system has been built with this requirement in mind.
 If transparency holds, then cognitive parsers should not only model linguistic performance, but the linguistic competence of the idealized 'native speaker' as well (Konieczny & Hemforth, 1994).
 Our approach is therefore based on a principled theory of grammar (namely, the Headdriven Phrase Structure Grammar, H P S G , Pollard & Sag, 1994).
 The status of lexical information in parsing In a 'headdriven' grammar framework, such as HPSG, transparently assembling syntactic structure depends directly upon the availability of lexical information.
 Although there is a broad consensus among psycholinguists that lexical information influences the parsing process very shortly after a word is processed, it is still an open question as to whether this information is used to guide the initial structurebuilding process (lexical guidance, lexically directed assembly), or whether it is only used to monitor or evaluate the independently built structures (lexical filter, structure checking models), and to rule out inconsistent ones.
 In our approach, w e take the former view.
 The most prominent proponent of the latter view is the gardenpath model by Frazier and her colleagues, which still constitutes a substantial part of its successor, the construal theory (Frazier & Clifton, in press).
 The gardenpath model focuses on structural economy in parsing (minimal attachment, late closure).
 In addition to the 'constituent structure subsystem', Frazier (1987, p.
 582) distinguishes another subsystem, the thematic processor, which serves the purpose of checking or monitoring the initially built structure based on lexical and higher level information.
 In terms of processing, this amounts to the structure being built from syntactic category information alone, and a later 'filtering' stage, where structures proposed by the constituent structure subsystem can be rejected by means of additional lexical information, for example, semantic features.
 Structure checking models, such as the gardenpath model, therefore presume that: 1.
 there is an independent grammar, such as CFGrules, outside the lexicon.
 This grammar is constructive in the sense that syntactic structure can be built from it without further lexical information.
 2.
 only the category information of lexical items is used initially, while subcategorization information is ignored at the first stage.
 The model presented in this paper depends on neither of these assumptions.
 It will nevertheless be shown that the data can be accounted for with a transparent onestage parser built on a stateoftheart lexicalized grammar.
 Psycholinguistic evidence.
 Although the issue of lexical guidance vs.
 filter is one of the most extensively investigated in psycholinguistics, a final decision is yet to come.
 A m o n g the many researchers reporting evidence in favor of the guidance assumption are Boland and Tanenhaus (1991) and others.
 In a series of selfpaced reading and eyemovement experiments, reported in (Hemforth et al.
, 1991; Strube et al.
, 1990; Konieczny et al.
, 1994ab), w e investigated PPattachment preferences in German sen631 mailto:lars@cognition.
iig.
unifreiburg.
detences, such as (1) and (2).
 (1) Marion beobachtete das Pferd {a.
 mit dem neuen Femglas, b.
 mit d e m weiBen Fleck}.
 Marion watched the horse {a.
 with the new binoculars, b.
 with the white fleck}.
 (2) Marion erblickte das Pferd {a.
 mit dem neuen Femglas, b.
 mit d e m weiBen Fleck}.
 Marion caught sight of the horse {a.
 with the new binoculars, b.
 with the white fleck}.
 The verb was either biased to "expect" an instrument, as in the case of beobachten (to watch), or not to do so, as in the case of erblicken {to catch sight of).
 Subjects spent longer reading the PP, if the verb's bias contradicted the plausibility of the attachment, as in (lb) and (2a), compared to (la) and (2b), where the verbbias is confirmed by plausibility.
 These data are thus in line with findings in support of the assumption that the verbbias influences initial parsing decisions.
 O n the contrary, Mitchell (1987, 1989), and recently Adams, Clifton, and Mitchell (1991, in press) have reported studies that seem to provide evidence against the lexical guidance hypothesis.
 Subjects read sentences like (3ab).
 (3) Although the audience {a.
 yawned, b.
 booed} (,) the comedian continued telling very bad jokes.
 Readers spent longer reading the disambiguating second verb (continued) in a sentence with a transitive first verb (booed, 3b), than in any other condition, including control conditions with a conmia.
 However, they spent reliably longer reading the N P (the comedian) following an intransitive verb, such as yawned (3a), than in any of the other conditions.
 Their results indicate that in the absence of a c o m m a readers preferred to interpret the N P as a direct object of the first verb.
 In case of a transitive first verb, the initial choice was only corrected at the disambiguating second verb.
 However, the longer reading times on the N P in sentences with an intransitive verb (3a) indicate that the N P has initially been interpreted as a direct object despite the verb's intransitivity.
 The results thus seem to support Mitchell's interpretation that only information at the major category level is used during the initial stage of structure assembly, thus allowing the "minimal" attachment of the N P to the current VP.
 Only during the second stage can the verb's subcategory rule out the initial attachment and initiate a reanalysis, resulting in increased processing load at the NP.
 Hence, onestage approaches hke ours appear to be challenged.
 If lexical information were essential for the assembly of structure, and hence for interpretation, headfinal structures, which are very c o m m o n structures in some languages, such as German or Dutch, must obviously be processed differently from headinitial structures.
 This aspect is often pointed out by proponents of twostage structure checking models, such as Frazier (1989) and Mitchell (1989).
 Even if lexical information can only help the parser to build the "best" structure more often, headfinal structures, such as German subclauses, will hence be disadvantageous, since lexical information enters the process too late to prevent the parser from building the wrong structure.
 Frazier (1989) claims that headfinal structures had disappeared over time if the initial assembly of structure were dependent upon lexical information.
 W e will argue against this position later.
 Immediate vs.
 delayed attachment There is common agreement that human parsing proceeds incrementally, essentially in a wordbyword fashion.
 From a technical point of view, parsing with lexicalized headdriven grammars bears the problem that the assembly of a certain piece of structure without its head does not seem to be possible at all.
 Lexicalized headdriven grammars seem to imply headdriven parsing accounts, which have been proposed in psycholinguistics (Abney, 1989; Pritchett, 1992), as well as in computational linguistics (e.
g.
 Kay, 1989).
 Contrary to "linear'' parsing approaches (Konieczny, in prep.
), in which 'perceivers incorporate each word of an input into a constituent structure representation of the sentence, roughly as each item is encountered' (Frazier, 1987, p.
 561), headdriven parsing accounts assume that structure is not built before its head is processed and, as a consequence of this, the attachment of complements to the structure is delayed until it is licensed by the head.
 However, there is an increasing amount of evidence against delayed attachment (e.
g.
 Inoue & Fodor, 1994; Bader and Lasser, in press).
 Hemforth, Konieczny and Strube (1993) found evidence for attachment to a phrase marker even before the head of the phrase was read.
 Overall, there is good reason to believe that structure is built even before the head is processed, and that complements can be attached into the structure before the attachment is licensed by the head.
 However, there is no need to reject headdriven grammars as a competence base for strictly linear parsers because of these findings, as will be demonstrated later on in this paper.
 The SOUL system A short note on the competence base HPSG is a system of linguistic signs (in roughly the Saussurean sense).
 Signs can be either phrases or words, and consist of a set of attributes, such as the phonological form, syntactic and semantic features, etc.
 Constituent structure is accounted for by an attribute as well, which is only permitted for phrasal signs, however.
 Whenever signs are combined, parts of their feature structures are unified.
 After successful unification, the feature structure consists of all the information that constituted the formerly separated feature structures.
 A n important extension is that feature structures are 632 labeled.
 A label represents a specific sort of feature structure, and only certain attributes are permitted by a particular sort.
 Sorted feature structures, then, represent a partial description of a linguistically relevant generalized piece of information, and can be organized in hierarchical systems of linguistic sorts.
 Thus, sorts can have subsorts, which are subsumed by their supersorts, i.
e.
 they inherit all the information of their supersorts but are more specific to a certain extent.
 Sorts are a powerful device that distinguish H P S G from many other grammar frameworks.
 Valenceclasses, for example, can be accounted for by a hierarchical system of sorts, which represent the respective feature structure of subcategorization requirements of intransitive, transitive, strictlytransitive, ditransitive verbs, etc.
 These general sorts can later be referenced in the concrete lexical entries.
 In our model, sorts play an important role in solving the problem of linear incremental parsing with a headdriven grammar, as described later in this p^>er.
 Apart from this, there are only a few very general constraints on the wellformedness of signs left outside the lexicon, namely general ruleschemas (about five in number) without any category information, which serve as the basic buildingblocks of constituent structure, and a few principles of wellformedness, which further constrain the way in which signs can be put together (see Pollard & Sag, 1994, for a detailed introduction to H P S G ) .
 The processing mechanism The parser is implemented in an objectoriented manner.
 Linguistic signtokens, such as words or phrases, are implemented as objects and come equipped with methods for combining themselves with other signobjects^.
 Feature structures, i.
e.
 the internal representations of signs, are implemented as objects with methods suited for unification, consistencychecks, copying, etc.
 The objectclass sign inherits these methods from the feature structure class, and adds a certain amount of parsing "behavior".
 Parsing starts out from the lexicon: as soon as a word is encountered, a lexical sign is "activated", i.
 e.
 after it is retrieved from the lexicon, an "act"message is sent to it (active sign).
 W h e n activated, a lexical sign behaves in a very principled way.
 The active sign and the waiting sign.
 Besides the active sign, there is a waiting sign, which represents the entire sentencestiiicture that was parsed before a new word was processed.
 During processing, the active sign passes through several stages of development, which correspond to a level in the constituent stiiicture.
 At each stage, the active sign attempts to successfully invoke one of the following three methods in the order of appearance: 1.
 attach self to the waiting sign (if there is one).
 If it is 'a signoriented mechanism is thus inserted before the undirected typededuction mechanism of unificationbased grammars.
 impossible to do so at the current state, 2.
 project self up to the next phrasal level, as a "daughter" in one of the basic HPSGruleschemas, but never higher than sentence level.
 As a part of projection, unify Uie new phrasal unit with the principles of wellformedness in order to rule out illegal projections.
 Then start again with 1.
 3.
 If either the attachment (1.
) worked, or the projection (2.
) reached the sentence level, predict the subsequent constituents at each level topdown, in order to provide attachment sites for subsequent items.
 This is done by collecting the yet unfilled daughters, which stem from the subcategorization frame of the preferred lexical forms of each item read so far.
 The daughters are put onto a stack, with die predicted adjacent sisters {predicted signs) on top.
 T w o types of attachments have to be distinguished: 1.
 predicted attachment, i.
e.
 the unification with one of the predicted signs, and 2.
 the active attachment search, which starts at the left adjacent item and proceeds upwards to each inunediate dominator of the current constituent, if the attachment is prohibited at the current level.
 The active attachment search incorporates the search for alternative lexical forms of the items read so far, which might provide a matching complement, and the attempt to attach the sign to the current node as an adjunct.
 The basic attachprojectpredict behavior of signs results in an "eager leftcomer"like process.
 The first item in a sentence is projected upwards until the sentence level is reached.
 Each following item is integrated immediately, either as a complement, or as an adjunct.
 In headfinal structures, however, complements precede their heads.
 Thus, complements have to predict their heads in some way.
 Strictly linear parsing of headfinal constructions.
 As demonstiated in Konieczny and Hemforth (1994), H P S G has some specific devices that can either be used direcUy, or easily extended to avoid the procedural shortcomings of a headdriven account.
 Firstiy, some nonheads, such as determiners, modifiers and complementizers, are equipped with information about their heads, which allows the bottomup projection of the stiiicture beyond the level of the 'maximal projection' of the particular item itself, and hence the (topdown) prediction of the head it specifies, or modifies, respectively.
 As a modest deviation from transparency, Konieczny and Hemforth (1994), secondly, propose the use of general sentence schemes for those cases, where this kind of information is not available from the lexicon.
 These schemas can be tiiggered by anything Uiat can start a new sentence, including nonheads.
 Importantly, sentence schemas are initially underspecified at the level of verbal complements, i.
e.
 they are simply restricted to the most general sort in the lexical sorthierarchy for subcategorization frames, namely verbalcomplements.
 The restriction 633 to verbalcomplements, thirdly, serves two purposes during the parsing of headfinal structures: 1.
 it allows only those complements to be attached that are consistent with other complements within a legal subsort of the verbal subcategory, and hence 2.
 it successively constrains the subcategory of the subsequent verb.
 Thus, with each attached complement of a verb, the predicted verbsign is restricted to a more specific subcategory.
 The sortal hierarchy is intended to express linguistic generalizations, such as the valenceclasses of verbs, which would otherwise have to be encoded within each lexical entry.
 Sorts can further be used in parsing, as described above.
 This kind of "typeinference" thus serves a purpose comparable to CFGrules in a standard parsing paradigm.
 Equipped with these devices, parsing with H P S G avoids most of the "shortcomings" of other principled accounts.
 However, the processing of verbfinal and verbinitial structures is carried out differently: whereas heads in the initial position project their subcategorization requirements directly into the structure, the successive attachment of complements in headfinal structures results in a sortal inference on the head's subcategory.
 However, since constraining lexical information is available in headfinal constructions to permit the attachment of the complements of subsequent heads, processing these structures is not significantly disadvantageous compared to headinitial structures.
 Thus, Frazier's and Mitchell's argument does not apply to the approach presented here.
 Contrary to our approach, in an account based on an extralexical grammar, such as CFGrules, the parsing of headfinal and headinitial structures results in the same kind of process, namely the selection and application of a particular rule.
 It is important to point this out in the light of the data presented in the next sections.
 Results PPattachment revisited We have presented data on PPattachment sentences such as (1) and (2), which strongly support the lexical guidance hypothesis.
 In Konieczny et al.
 (1994ab) w e also investigated the processing of similar German subclauses, such as (4), in which the verb was placed at the end of the subclause.
 (4) Ich habe gehdrt, da£ Marion das Pferd {a.
 mit d e m neuen Femglas, b.
 mit d e m weiBen Fleck} beobachtete.
 I have heard, that Marion the horse {a.
 with the new binoculars, b.
 with the white fleck} watched.
 "/ have heard, that Marion watched the horse (a.
 with the new binoculars, b.
 with the white fleck}.
" The material was used in two experiments, in one of which w e measured wordbyword selfpaced reading times, whereas in the other one eyemovements were recorded.
 Subjects spent longer processing the PP, if it represented an object which could not plausibly be attributed to the preceding noun (horse with binoculars), as in (4a).
 As w e have demonstrated in Konieczny et al.
 (1994ab), these findings strongly contradict the predictions of the garden path theory and its current successor construal theory (Frazier and Clifton, forthcoming), since the subjects did not seem to choose the structurally more parsimonious attachment to the V P initially, but preferred to attach the PP to the preceding direct object in the initial stage, before world knowledge rendered this analysis implausible.
 In an eyemovement study based on very similar materials, Konieczny (in prep.
) found an interaction of verbplacement and the referential ambiguity of the direct object N P in sentences like (4).
 Findings like these were fiirther supported by results from a selfpaced reading study and an eyemovement experiment reported in (Scheepers, Hemforth, & Konieczny, 1994) on sentences with NPattachment ambiguities.
 Taken together, the data provide overwhelming evidence in support of the head attachment principle (Konieczny, Hemforth, & Strube, 1991) as expressed in (5).
 (5) head attachment Prefer to attach an item to a phrasal unit whose lexical head has already been read.
 The head attachment principle applies to all those cases, where an attachment ambiguity can be resolved by either attaching to a preceding head, or to a head yet to come.
 In many other cases, such as the verbsecond sentences in (1), there are two or more heads that are potential attachment sites for an ambiguous item.
 As w e have seen above, the decision now depends on the lexical preferences of either of the heads, as expressed in (6).
 (6) preferredrole attachment Prefer to attach an item to a phrasal unit whose head preferentially subategorizes for it.
 This is to an extent the reincarnation of Ford et al.
's (1982) principle oi lexical preference, which was built into their LFGbased parsing model.
 In the current version of our model, the preference to expect either the occurrence, or the nonoccurrence of an optional complement is implemented by the assignment of a 5/ren̂ //ivalue to distinct subcategorization frames.
 After the lexicon was accessed, only one frame, and most probably the strongest one, will be used throughout the initial analysis^.
 O f course, there are cases where two (or more) preceding heads do not differ in their preference to bind a constituent.
 In these cases, a decision is supposed to be based ^Tie use of a strength value does not necessarily imply the assumption of an "exposurebased" aspect in our model.
 On the contrary, we are currently approaching a theory of lexical preference that uies to relate subcategorization preferences to the argument suncture of verbs (Scheepers, in prep.
), to the issue of ontological necessity of thematic roles, and to properties of the situation model (Konieczny, in prep).
 634 upon recency (7).
 (7) mostrecent head attachment Prefer to attach an item to the head that was read most recently.
 The predictions of mostrecent head attachment compare to those oilate closure in the gardenpath model.
 However, it is only applied if the other principles fail to provide a decision.
 This has been expressed in the unified parametrizedhead attachment principle, P H A (8), which furthermore serves the purpose of emphasizing the fact that attachment ambiguities are resolved on the basis of certain parameters of lexical heads, such as relative position and lexical preferences.
 (8) parametrizedhead attachment, P H A (Konieczny, Hemforth, Scheepers, & Strube, 1994) (Attempt to) apply head attachment (5) before preferredrole attachment (6) before mostrecent head attachment (7).
 According to P H A , and in particular due to head attachment, the parser initially builds a syntactic structure, which can be evaluated semantically as soon as possible {"semanticsoriented" processing).
 Note, however, that semantics is not supposed to guide the parser, as in a strongly interactive "semanticsdriven" account.
 The implementation of PHA.
 Fortunately, PHA can be accounted for without major extensions to the current model.
 This is most obvious in the case of head attachment, which can be derived directly from the fact that an active sign first attempts to attach itself to the waiting structure before it continues to do something else.
 The observed attachment phenomena in verbfinal constructions, such as (4), can easily be explained: firstly, let us assume that the waiting sign is the structure built before the PP was processed.
 The list of predicted signs now contains the predicted verbfragment, but also a pointer to the list of the complements of the verb.
 Since the direct object N P has been processed before, the list is restricted to the sort transitive.
 However, due to the lack of the verb in this position, no PP has been predicted yet.
 Thus, no predicted attachment of the PP in (4) can take place.
 However, the active attachment search starting at the leftadjacent N P succeeds in attaching the PP as an adjunct.
 Only then can the attachment be evaluated with respect to plausibility.
 If the "plausibility check" fails, the active attachment search is continued at the next level, namely the VP.
 Since no verb was read so far, the search for an alternative lexical form does not make much sense.
 Instead, the sorthierarchy is accessed in order to search for a subsort of the proposed verb's subcatsort transitive that permits the attachment of a PPobject.
 It will finally attach itself as a PPcomplement into the list of complements, which is now restricted to a subsort of ditransitive.
 Hence, the process of active attachment is refined to 1.
 the search of an alternative lexical form, in the case that a lexical item is already available, and 2.
 permitted attachment, which requires a sortal inference in the hierarchy of valencesorts, otherwise, followed by adjunct attachment.
 The situation in verbsecond structures is different.
 B y the time the P P is about to be processed, the verb has aheady predicted its preferred complements.
 If the verb is biased towards the expectation of an instrument, a P P is among the predicted signs and thus succeeds in attaching itself to the VP.
 If not, the P P has to initiate the active attachment search, starting at the most recent head, the direct object NP, to which it can easily be adjoined.
 Preferred role attachment therefore directly results from the distinction between predicted and active attachment^.
 If the active attachment to the N P fails for reasons of plausibility, the attachment to the V P is pursued.
 Finally, mostrecent head attachment is a direct result of 1.
 the prediction stack with the most recent predictions always on the top, and 2.
 the active attachment search starting from the leftadjacent item upwards.
 The recency effect is thus accounted for within a serial search model, as opposed to some current accounts, which provide an "activation" based explanation.
 E.
g.
 Gibson et al.
 (in prep.
) implement recency as a costfutiction, which assumes that all potential attachment sites have to be computed in parallel before the cost for the attachment to each of them can be calculated in the second run.
 W e regard the serialsearch account as more elegant and parsimonious.
 The immediate use of lexical information revisited.
 We still have to provide an explanation for Mitchell's (1987, 1989) and Adams et al.
's (in prep.
) challenging results on sentences like (3).
 A closer look to their material uncovers that many of their verbs, such as to talk and to yawn, have rare but permissible transitive forms^.
 Although this does not weaken their argument against lexical guidance models that only pursue the lexically preferred path, e.
g.
 the model of Ford et al.
 (1982), the studies provide no evidence against the immediate use of lexical information in a model, that gives highest priority to head attachment (5): If no complement is preferentially predicted at the point when the N P is to be processed, the active attachment search provides another lexical form that permits its attachment as a complement, at least in case of verbs like pray, talk, yawn, cough, doze, smile, etc.
.
 However, the unification with the now predicted complement fails very early, e.
g.
 due to a thematic role restriction mismatch.
 Only then can the active sign continue to project itself further bottomup and finally produce the correct structure.
 The increased reading times at the N P following an "intransitive" verb, compared to the transitive verb condiNote that there are no grades of preference during parsing, since lexical strength only affects the initial choice of a subcategorization frame.
 ^according to Webster's Ninth New Collegiate Dictionary.
 635 tion, are thus firstly due to the search for another verbform that permits the attachment and secondly, and more importantly, due to the additional processing load of several steps of bottomupprojection after the attempted attachment / unification failed.
 Compared to the c o m m a conditions, however, the processing load is increased because with a comma, the search for another verbform and the unification with the predicted complement is not even attempted.
 Although attachment and unifying in lexical information takes place at one and the same stage, because it is actually one and the same process, Mitchell's results are easily accounted for.
 Conclusions We introduced the SOUL system as a computationally sufficient, implemented' model of human language competence and performance.
 H P S G sign tokens are implemented as objects, whose basic attachprojectpredict behavior results in attachment preferences predicted by the Parametrized Head Attachment (PHA) principle.
 Since the principles of the grammar are put to use directly, parsing is supposed to be 'transparent'.
 It could be demonstrated that this behavior fits the available psycholinguistic data well, i.
e.
, it is psychologically adequate.
 Acknowledgments This research was supported by the German National Research Foundation (Deutsche Forschungsgemeinschaft, DFG, Str 301/43).
 We want to thank Barbara Hemforth and Don Mitchell for many fruitful discussions and comments, and Kim O'Brien and an anonymous reviewer for their helpful comments on an earlier draft of this paper.
 References Abney, S.
 (1989).
 A computational model of human parsing.
 Journal of Psycholinguistic Research, 18.
1, 129144.
 Adams, B.
 C , Clifton, C , Jr.
, & Mitchell, D.
 C.
 (in prep).
 Lexical guidance in sentence processing: further support for a filtering account.
 Manuscript submitted.
 Berwick, R.
 C.
 & Weinberg, A.
 S.
 (1985).
 Deterministic parsing and linguistic explanation.
 Language and Cognitive Processes, 1, 109134.
 Boland, J.
 E.
, & Tanenhaus, M.
 K.
 (1991).
 The role of lexical representation in sentence processing.
 In G.
 B.
 Simpson (Ed.
), Understanding word and sentence (pp.
 331366).
 NorthHolland: Elsevier.
 Ford, M.
, Bresnan, J.
 & Kaplan, R.
M.
 (1982).
 A comptencebased theory of syntactic closure.
 In J.
 Bresnan (Ed.
) The mental representation of grammatical relations.
 Cambridge, Mass.
: MIT Press Frazier, L.
 (1987).
 Sentence processing: A tutorial review.
 In M.
 Coltheart (Ed.
), The psychology of reading (pp.
 559586).
 Hove/ London/Hillsdale: Lawrence Eribaum.
 'The S O U L system is implemented in the ObjectiveC programming language and runs on computers with NEXTSTEP 3.
2 or higher.
 Frazier, L.
 (1989).
 Against lexical generation of syntax.
 In W.
 MarslenWilson (Ed.
), Lexical representation and process (pp.
 506528).
 Cambridge, M A : MIT Press (Bradford).
 Frazier, L.
, & Clifton, C.
 (in press).
 Construal theory.
 Gibson, E.
, Pearlmutter, N.
, CansecoGonzalez, E.
, & Hickock, G.
 (in prep.
).
 Recency Preference in the Human Sentence Processing Mechanism.
 Submitted manuscript.
 Hemforth, B.
, Konieczny, L.
.
 Sunibe, G.
, & Wrobel, H.
 (1990).
 Kognitive Modellierung und cmpirische Analyse von IVozessen der Satzverarbeitung.
 Technical report.
 Hemforth, B.
, Konieczny, L.
.
 & Strube, G.
 (1993).
 Incremental syntax processing and parsing suategies.
 Proceedings of the 15th Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Eribaum (pp.
 539545).
 Inoue, A.
, & Fodor, J.
 D.
 (1994).
 Informationpaced parsing of Japanese.
 In R.
 Mazuka & N.
 Nagai (Eds.
), Japanese syntactic processing.
 Hillsdale, NJ: Eribaum.
 Kay, M.
 (1989).
 Headdriven parsing.
 Proceedings of the international workshop on parsing technology.
 CamegieMellon University, Pittsburgh, PA.
 Konieczny, L.
 (in prep.
).
 Sentence processing.
 Doctoral dissertation at the University of Freiburg, Germany Konieczny, L.
 & Hemforth, B.
 (1994).
 Incremental parsing with lexicalized grammars.
 Submitted to Linguistics.
 Konieczny, L.
, Hemforth, B.
, Scheepers, C , & Smibe, G.
 (1995).
 PPattachment in German: results from eye movement studies.
 In J.
 M.
 Findlay, R.
 Walker, & R.
 W.
 Kentridge (Eds.
) Eye movement research.
 Mechanisms, processes and applications.
 Amsterdam: North Holland, pp.
 405420.
 Konieczny, L.
, Hemforth, B.
, & SUTibe, G.
 (1991).
 Psychologisch fundierte Prinzipien der Satzverarbeitung jenseits von Minimal Attachment.
 Kognitionswissenschaft, 2.
 Konieczny, L.
.
 Scheepers, C , Hemforth, B.
 & Suube, G.
 (1994).
 Semantikorientierte Syntaxverarbeitung.
 In S.
 Felix, C.
 Habel, & G.
 Rickheit (Eds.
), Kognitive Linguistik: Reprdsentationen und Prozesse.
 Opladen: Westdeutscher Verlag.
 Mitchell, D.
 C.
 (1987).
 Lexical guidance in human parsing: Locus and processing characteristics.
 In M.
 Coltheart (Ed.
), Attention and Performance XII: The psychology of reading.
 London: Lawrence Eribaum Associates Ltd.
 Mitchell, D.
 C.
 (1989).
 Verbguidance and other lexical effects in parsing.
 Language and Cognitive Processes, 4, SI 123155.
 Pollard, C , & Sag, I.
 A.
 (1994).
 HeadDriven Phrase Structure Grammar.
 Chicago, London: University of Chicago Press and CSLI Publications.
 Pritchett, B.
 (1992).
 Grammatical competence and parsing performance.
 Chicago: University of Chicago Press.
 Scheepers, C.
 (in prep.
) Zur Verarbeitung von Argumentrelationen.
 Doctoral dissertation at the University of Freiburg.
 Scheepers, C , Hemforth, B.
 & Konieczny, L.
 (1994).
 Resolving NPattachment ambiguities in German verbfinal consunjctions.
 In B.
 Hemforth, L.
 Konieczny, C.
 Scheepers & G.
 Strube (Eds.
), First Analysis, reanalysis, and repair (IIGBerichte 8/ 94, pp.
 5176).
 Freiburg: IIG.
 Sunbe, G.
, Hemforth, B.
, & Wrobel, H.
 (1990).
 Resoluuon of Suvctural Ambiguities in Sentence Comprehension: Online Analysis of Syntactic, Lexical, and Semantic Effects.
 The 12th Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Eribaum, pp.
 558565.
 636 Evidence for Explanatory Patterns in Evolutionary Biology Jorge F.
 LarreamendyJoerns Learning Research and Development Center University of Pittsburgh Pittsburgh, P A 15260 l a r r e a m @ p i t t .
 e d u Stellan O h i s s o n Learning Research and Development Center University of Pittsburgh Pittsburgh, P A 15260 stellan@vins .
 c i s .
 p i t t .
 e d u Abstract Students' naive conceptions of natural phenomena have been analogized to scientific theories.
 This theory view does not account for the instability and inconsistency of students' explanations.
 An alternative is the schema view according to which students construct explanations by instantiating explanatory patterns acquired in previous learning.
 In two previous studies eight explanatory schemas for evolutionary change were identified through content analysis of students' explanations.
 It was hypothesized that if the schemas have cognitive reality, data from explanation tasks ought be consistent with data from recognition tasks.
 In this study students were asked to sort 24 explanations that exemplified the eight different schemas in three different ways.
 A hierarchical cluster analysis shows that half of the students recognized five schemas and merged the remaining ones into one broader explanatory pattem, giving partial support for the schema view.
 ImpHcations of the schema view for the learning of scientific ideas are discussed.
 Students' Explanatory Schemas Students' beliefs about complex phenomena in domains such as physics, astronomy and biology have been analogized to scientific theories.
 Albeit some novice representations do resemble theories in the history of science (McCloskey & Kargon, 1988), the adequacy of the scientific theory/naive belief analogy remains a subject of debate in developmental and cognitive psychology (Kuhn, 1989).
 A problem for the theory view, which underlies most studies of misconceptions, is that students' explanations, unlike their scientific counterparts, are not stable over time and lack internal consistency (diSessa, 1988).
 A n alternative to the theory view is the schema view (Brewer & Nakamura, 1984; Leake, 1992; Ohisson, 1993; Schank, 1986; Schank, Kass & Riesbeck, 1994).
 The latter implies that students' prior knowledge should be conceptualized as a repertoire of explanatory patterns or schemas constructed in the course of everyday learning and prior educational experience.
 Explanations are generated by instantiating a schema visavis a target event and replacing slots with referential expressions.
 Unlike propositional beliefs, which carry truth values, a schema that does not fit a given situation is not rejected, simply not activated.
 A n existing schema can also be modified ("tweaked", Schank, 1986) to fit a novel situation, and indexed in memory as a new knowledge structure.
 However, the schema initially retrieved is not deleted from memory.
 Explanatory schemas emphasize the instrumental role of knowledge structures rather than their veridical status.
 Furthermore, a schema repertoire is not a belief system, naive or otherwise.
 T w o or more alternative schemas can coexist in memory without contradicting each other in the logical sense.
 Hence, no coherence demands are imposed upon the mental representation, and the question about the consistency of students' mental models is consequently deemphasized.
 In previous studies w e asked students to explain instances of evolutionary change (Ohisson, 1991; Ohisson & Bee, 1992, 1993).
 Although the students produced explanations that include ideas similar to some theories in the history of biology, the instability and inconsistency, across and within tasks, of their accounts suggest that the content of their explanations are not expressions of stable beliefs about evolutionary change.
 Eight explanatory patterns were identified in students' explanations through content analysis: intentional creation, mutation, crossbreeding, static selection, dissemination, cognition, training, and needs and advantages.
 The intentional creation schema rejects the very occurrence of evolutionary change and therefore bypasses any explanation of its underlying mechanisms.
 This schema relies on the purposive action of some agent w h o created the different species.
 The static selection schema explains adaptations via natural selection, but without gradualism; the selection happens within a single generation (hence its static nature).
 This schema does not account for the source of intraspecies variation, nor does it specify the relation between selective processes and changes in reproduction rates.
 According to the crossbreeding schema, new species arise from a crossing between organisms with different traits.
 This schema does not rule out the possibility of interspecies breeding, nor does it constrain the kind of changes likely to occur through intraspecies crossbreeding.
 The mutation schema postulates a sudden genetic change that brings to existence complex anatomical features, while the dissemination schema postulates an unexplained appearance of an adaptation in one or more members of the species, followed by the spread of that adaptation throughout the entire population.
 The needs and advantages schema explains adaptations as the direct result of an organism's needs to meet the demands of the environment, without explicating the mechanisms underlying the emergence of new traits.
 According to the cognition schema, adaptations are the outcome of cognitive processes such as 637 mailto:larream@pitt.
edudecision, discovery and learning.
 Finally, the training schema embodies the idea that an adaptation appears as a consequence of an animal's repetitive behavior.
 As this repertoire demonstrates, students do not have one major misconception (e.
g.
, Lamarkianism) about evolution but a variety of schemas for explaining biological change.
 Variability exists within as well as between students.
 This repertoire of schemas is not a classification of students because individual students typically use more than one schema.
 Within the students' conception of evolution, these schemas satisfy different explanatory goals; they account for the source of change (e.
g.
, genetic mutations, creation), the mechanism of change (e.
g.
, selection, breeding, purposive actions, needs), or the type of change (e.
g.
, gradual, sudden).
 One of the central assumptions of schema theory is that schemas are used both generatively and interpretatively, i.
e.
, both to produce discourse and to comprehend discourse (Brewer & Nakamura, 1984).
 If explanatory schemas do have psychological reality, and subjects have learned them well, then data from production tasks should be consistent with data from recognition tasks.
 This is the rationale behind the use of sorting tasks to assess cognitive representations (Benysh, Koubek, & Calvez, 1993; Chi, Feltovich, & Glaser, 1981).
 The purpose of this study was to gather evidence to support the psychological reality of the eight explanatory patterns mentioned above, as a step toward understanding how explanations of complex phenomena are generated.
 W e asked students to sort evolutionary explanations into categories on the basis of similarities.
 Each of the eight explanatory patterns mentioned above was instantiated for three different species.
 Thus, the 24 explanations were classifiable in two ways: First, according to explanatory patterns, in which case w e would expect students to sort the explanations into eight categories with three explanations in each.
 Second, according to species, in which case w e would expect students to sort the explanations into three categories with eight explanations in each.
 If students did not sort the explanations on the basis of either patterns or species, then the pattern of their groupings would deviate from either of these two ideal patterns.
 Method Subjects Fortynine firstyear undergraduate students were recruited for this study.
 Students' prior knowledge of evolutionary biology was assessed by asking them to summarize Darwin's theory.
 Data from the summary task are reported elsewhere (LarreamendyJoerns & Ohlsson, 1994).
 Students showed little or no understanding of the Darwinian theory of evolution.
 Materials and Procedure Students were instructed to sort 24 evolutionary explanations into piles on the basis of similarities and to write down the reasons for their grouping.
 The 24 explanations instantiated schemas that were extracted in the two prior studies (Ohlsson, 1991; Ohlsson & Bee, 1992).
 In the present study, the eight explanatory schemas (i.
e.
, needs & advantages, mutation, crossbreeding, dissemination, training, cognition, static selection, and intentional creation) were instantiated three times: one for dinosaurs' size, one for tigers' stripes, and one for birds' wings.
 The explanations were edited to control for word familiarity and length.
 Each explanation was presented on an individual card.
 Table 1 shows three examples.
 Results The data were analyzed with the purpose of deciding whether students sorted the explanations on the basis of explanatory patterns, species or something else.
 Category size ranged from 2 to 12 explanation cards (mean = 6, S D = 2.
09).
 The frequency distribution of number of explanation cards per grouping suggests that neither species alone, nor explanatory patterns alone were the criteria guiding most students' sorts.
 Table 1: Dinosaur explanations based on the schemas of needs & advantages, mutation, and static selection Schema Explanation Needs & advantages During the Jurassic period, ferns and trees were extremely large and tall, and the ground was frequendy flooded.
 There were few plants on ground level.
 Dinosaurs had to reach food high up or in difficulttoreach places, so they became larger to adapt and survive.
 Mutation Millions of years ago there were only small dinosaurs.
 These dinosaurs were dying because they couldn't protect themselves against large predators.
 Then, a mutation occurred and large size dinosaurs evolved.
 This mutation was highly favorable for survival.
 Static Selection Each species has different characteristics.
 Accordingly, some dinosaurs were bigger than others, some were smaller, some had long necks, and others had short necks.
 Eventually, the shorter ones perished because they couldn't adapt to the environment, leaving only the larger dinosaurs able to survive.
 638 S 25 I o U t 20 u u o c S V) 5 (2 15 ^ 10 D a n o cro 3 i §.
 03 CO B.
 3 S.
 3 '̂  3 a n 3_ 5' o' 3 Cd tfl n 3 2 C o 3 s o C/i O" 3 D D V! a 3 ̂3 3 3 00 3 H a wi re 3 3 o 3 H n ĉ  3 S' o 3 H O p; c« y .
̂ H ;< c fei o' 3 t33 a c o O n o 3 S S ^ o 3 o 3 3 5' 3 rt ^ O 3 O 3 Figure 1: Dendrogram for all subjects (N = 49) F r o m a total of 2 9 2 categories formed by all 49 subjects 49 groupings (16.
8%) were exactly in accordance with one of the eight explanatory patterns.
 The remaining 243 groupings were formed either by explanations pertaining to a single species (3.
4%), or by a combination of explanation cards from different explanatory patterns and species (79.
8%).
 T o get a more finegrained picture of the sorts, the data were transformed into individual cooccurrence matrices and analyzed using the S S P S 4.
1 Hierarchical Cluster Analysis Program's single linkage method (nearest neighbor).
 A wholesample matrix w a s constructed by adding all 49 individual matrices.
 Figure 1 shows the dendrogram for this m a trix (explanation cards are identified by a capital letter referring to the species, and the n a m e of the explanatory schema.
 Letter D stands for dinosaurs; letter T for tigers; and, letter B for birds).
 T he dendrogram shows the explanation cards collapsed into two major higherlevel nodes: the creation schema (at the right hand edge in the figure), and a large, complex node comprising the remaining 21 explanations.
 Albeit not all subjects recognized it, the creation schema was the most salient type of explanations for the total sample.
 The node comprising the 21 remaining explanations branches out into two major nodes.
 The first one is the static selection schema which was almost as salient as the creation schema (the second group of three from the right).
 T h e second node c o m prises the remaining 18 explanations which tended to be clustered on the basis of species similarities.
 H o w e v e r , within each species there was a high cooccurrence a m o n g training, cognition, and needs & advantages explanations.
 Mutation explanations were not seen as similar either to other types of explanations, nor to each other.
 T o investigate whether there were subgroups of students within the total sample w h o sorted according to different criteria, the whole sample w a s split into three groups in the following way.
 Each subject was assigned to one of the following groups: (a) those w h o s e sorting actions (i.
e.
, assignment of an explanation card to a category) were m o s d y based on species similarities; (b) those w h o s e sorting actions were mostly based on similarities between explanatory patterns; and (c) those whose sorting actions were not predominantly based on species similarities, or schema similarities.
 T o assign subjects to groups, each cooccurrence frequency in the individual matrices was classified into one of the following categories: (a) cooccurrence between explanations of the same species; (b) cooccurrence between explanations of the same pattern; and (c) cooccurrence between explanations of different schema and different species.
 T h e proportion per subject for each of these categories w a s c o m puted and each subject assigned to one of three groups based on his/her greatest proportion.
 For each group a cooccurrence matrix w a s constructed and a cluster analysis performed.
 Since the cluster analyses of schemaoriented subjects and combinedcriteria subjects yielded similar results, those two groups were merged and the analysis repeated for the merged group.
 Figure 2 shows the dendrogram for the cluster analysis performed on the cooccurrence matrix for the twentysix subjects whose sorting actions were mainly schemaoriented.
 Like the wholesample dendrogram, this dendrogram shows the explanation cards collapsed into two major nodes.
 First, the creation schema (at the leftmost side of the figure).
 Second, a higherlevel node comprising four clearly differentiated schemas (i.
e.
, mutation, crossbreeding, selection, and dissemination), and a rather undifferentiated cluster formed 639 c IE i Q Qi 25 :f 20 15 10 « 5 £ a 00 n n O a 2 S £ S 00 c c 5.
 5.
 =.
 & S ^ 5" o o & ~ ?;• o 3 o 3 3.
 3 5' 3 o 3 3 3' 03 o 3 O c o 3 O S.
 3 3 a.
 p.
 :̂ :̂ 3 ^ 00 00 a 03 Figure 2: Dendrogram for schemaoriented subjects (N = 26) by needs, training and cognition explanations.
 In short, this analysis indicates that these students were able to recognize five schemas: creation, mutation, crossbreeding, dissemination and static selection (see groups at the left edge in the figure).
 The clustering of needs, training and cognition explanations into a single node is consistent with the cooccurrences observed in the wholesample cluster analysis.
 Figure 3 shows the dendrogram for the cluster analysis performed on the cooccurrence matrix for twentythree students whose sorting actions were mainly guided by species similarities.
 This dendrogram consists of two major clusters.
 The first one comprises ail tiger explanations, and stands apart in the dendrogram (see the cluster to the right in the figure).
 The other cluster branches out into two nodes, one of them grouping all dinosaur explanations, and the other all bird explanations.
 Although no single explanatory pattern was fully recognized by this group of students, the dendrogram shows the three creation explanations standing relatively apart within their respective species clusters, which suggests that some students sorted together this type of explanations.
 Discussion The sorting data provides mixed evidence for the hypothesized explanatory patterns.
 Only one subject produced a sort that was exactly in accordance with all eight patterns.
 However, if w e look at the sample as a whole, the students recognized the creation schema with relative ease.
 This schema was clearly isolated in two of the three cluster analyses.
 Although less salient, the explanatory schemas of selection, crossbreeding, mutation, and dissemination were also recognized.
 Explanations based on the schemas of cognition, training, and needs were systematically collapsed into a single explanatory category.
 This cooccurrence occurred both across species and within species.
 These results suggest that some of the schemas that we initially attributed to students were too finegrained.
 In particular, a broader pattern, comprising training, cognition, and needs explanations conforms better to the students' idea that the environment poses demands of various sorts and organisms respond by changing in such a way as to deal with those demands.
 The results show that patterns that emerge in content analyses and thinkaloud protocols may or may not correspond to actual knowledge structures in students' memory.
 Hypotheses drawn from discourse analyses should be validated against additional data.
 In particular, mental models, misconceptions, and explanatory patterns derived from production tasks should be checked against data from recognition tasks.
 Given that there is partial evidence for some explanatory patterns, a number of issues need to be addressed in future research.
 First, online data should be collected to determine how students use these explanatory patterns.
 Following Schank and coworkers (Leake, 1992; Schank, 1986; Schank, Kass, & Reisbeck, 1994), we suggest that the production of evolutionary explanations by students involves three major cognitive processes: schema retrieval, schema instantiation, and explanation evaluation.
 Retrieval processes are particularly important because the activation of one or more patterns is a function of the degree to which both a subject's representation of evolution and his/her ex640 I 25 IS 6 o O 20 2 ^ 15 Q •8 10 8 S 3 o s a 2 c B3 o 3 a t/2 0> (T> O o 3 O :;̂  E.
 3 3 O, B5 O 3 3 a —• ?• r̂' =.
 n o era 3 i o 3 a n o 3 § tJ3 3^ 5' 00 Cd DD ro a n s ?;• O r00 3 3 o 3 ca O 3 O 3 w C/3 01 o 3 03 D3 n n S 3 s a 3 I g .
̂ I 'S o 3 n o oo 3 o 3 g So' <T> 3.
 3 o' 3 3 ^ CP ?• Figure 3: Dendrogram for speciesoriented subjects ( N = 23) planatory goals match the way explanation patterns are indexed in memory.
 For example, the cooccurrence of patterns in some explanations reveals the students' attempt to construct explanations involving multiple explanatory goals.
 Thus, a subject who claims that dinosaurs became gigantic because they needed to adapt and then a single mutation occurred, is focusing on the source of change (explanatory goal 1), as well as on the mechanism of change (explanatory goal 2).
 The cooccurrence of contradictory explanatory patterns within one and same explanation can be attributed to the absence of coherence revision during the evaluation phase of the explanatory process, or to the lack of domainspecific knowledge that may constrain the retrieval of certain schemas in the light of specific explanatory goals (e.
g.
, use of creation and crossbreeding schemas to explain evolutionary change).
 A second question is how the correct explanation pattern is acquired.
 The schema view implies three learning processes that we refer to as relevance determination, concept differentiation, and coordination.
 First, students enter a science course with a vast repertoire of schemas acquired in everyday experience as well as previous study.
 The majority of those schemas are irrelevant rather than incorrect.
 The students cannot know in advance which schemas are relevant for the intellectual game they are about to learn.
 Hence, schemas will be activated with a probability that is some function of their past usefulness.
 In the course of learning, students have to discover which of the activated schemas constitute valid moves in the intellectual game they are trying to master.
 The first step in learning is therefore to round up the relevant components of prior knowledge.
 Second, the schema repertoire suggests that learning requires explication of what Carey (1992) calls undifferentiated categories.
 The concept of undifferentiated categories is well illustrated by the training schema.
 The key feature of this schema is the lack of distinction between phenotypic changes ontogeny, maturation, seasonal variations, aging, effects of athletic training— and evolutionary changes.
 Because many phenotypic changes are driven by activity, so is evolution.
 Without a clear distinction between acquired and inherited traits, the contrast between Lamarckianism and Darwinism that opens most textbook chapters on evolutionary theory cannot be understood.
 Correct understanding of the theory of evolution presupposes that biological categories are differentiated well beyond the level of semantic precision that is typical of common sense discourse.
 Third, students' explanations are typically simpler than Darwinian explanations.
 Where students tend to appeal either to mutations or the environment or selection or dissemination, an expert explanation intertwines these ideas into a more complex mental model of evolution.
 Hence, the schema hypothesis implies that one fundamental dimension of learning is to assemble existing schemas into more complex schemas.
 This assembly hypothesis is related to the coordination process proposed by Piaget (1985).
 The relation between coordinated schemas is not mere association.
 T w o schemas, each of which is well established already, are hooked together in such a way that their coordination acquires a new cognitive function.
 For example, one stepping stone on the way to correct understanding of Darwinism is probably to coordinate the ideas of selection and repetition into a new schema for repeated selection.
 This schema is 641 more complex but also more powerful than either selection or repetition by themselves.
 The view that novice competence consists of a repertoire of schemas has very different implications for the nature of learning than the misconception view (Hewson & Hewson, 1984; Lawson & Weser, 1990; Strike & Posner, 1985).
 Inspecting the schema repertoire we have uncovered in our studies shows that students' prior knowledge is often irrelevant, sometimes fuzzy and always too simple; it is not obviously incorrect or false.
 Instead of rejecting their prior knowledge, students have to determine the relevance of existing schemas, explicate undifferentiated concepts by making the relevant distinctions, and construct more complex schemas by coordinating existing schemas.
 Although data from this study are far from conclusive as to the validity of the schema view, the results invite exploration of alternatives to the naive theory view of misconceptions in science learning.
 If students retrieve, instantiate, and coordinate explanatory patterns during learning effective pedagogical techniques should support these processes.
 Acknowledgments This research was supported, in part, by a grant to The National Research Center on Student Learning from the Office of Educational Research and Improvement (OERI), US Ministry of Education, and in part by fellowships from the Fulbright Commission and the Pan American Leo S.
 Rowe Fund, Organization of American States, to the first author.
 References Benysh, D.
 V.
, Koubek, R.
 J.
, & Calvez, V.
 (1993).
 A comparative review of knowledge structure measurement techniques for interface design.
 International Journal of HumanComputer Interaction, 5 (3), 211237.
 Brewer, W.
 p.
, & Nakamura, G.
 V.
 (1984).
 The nature and functions of schemas.
 In R.
 Wyer & T.
 SruU (Eds.
), Handbook of social cognition (pp.
 119160).
 Hillsdale: Erlbaum.
 Carey, S.
 (1992).
 The origin and evolution of everyday concepts.
 In R.
 N.
 Giere (Ed.
), Minnesota studies in the philosophy of science.
 Volume XV.
 Cognitive models of science (pp.
 89128).
 Minneapolis, M N : University of Minnesota Press.
 Chi, M.
 T.
 H.
, Feltovich, P.
 J.
, & Glaser, R.
 (1981).
 Categorization and representation of physics problems by experts and novices.
 Cognitive Science, 5 (2), 121152.
 diSessa, A.
A.
 (1988).
 Knowledge in pieces.
 In G.
 Forman & P.
B.
 Pufall (Eds.
), Constructivism in the computer age (pp.
 4970).
 Hillsdale, NJ: Eribaum.
 Hewson, P.
 W.
, & Hewson, M.
 G.
 A.
 (1984).
 The role of conceptual conflict in conceptual change and the design of science instruction.
 Instructional Science, 13, 113.
 Kuhn, D.
 (1989) Children and adults as intuitive scientists.
 Psychological Review, 96, 674689.
 LarreamendyJoerns, J.
 & Ohlsson, S.
 (1994).
 The psychological reality of explanatory patterns in evolutionary biology (Technical Report).
 Pittsburgh, PA: University of Pittsburgh.
 Lawson, A.
 E.
, & Weser, J.
 (1990).
 The rejection of nonscientific beliefs about life: Effects of instruction and reasoning skills.
 Journal of Research in Science Teaching, 27, 589606.
 Leake, D.
 (1992).
 Evaluating explanations: A content theory.
 Hillsdale, NJ: Erlbaum.
 McCloskey, M.
 & Kargon, R.
 (1988).
 The meaning and use of historical models in the study of intuitive physics.
 In S.
 Strauss (Ed.
), Ontogeny, phylogeny, and historical development (pp.
 4967).
 Norwood, NJ: Ablex.
 Ohlsson, S.
 (1993).
 Abstract schemas.
 Educational Psychologist, 28 (\), 5166.
 Ohlsson, S.
 (1991).
 Young adults understanding of evolutionary explanations: Preliminary observations.
 Technical Report.
 LRDC.
 University of Pittsburgh.
 Ohlsson, S.
, & Bee, N.
 (1992).
 The effect of expository text on students' explanations of biological evolution (Technical Report).
 Pittsburgh, PA: University of Pittsburgh.
 Ohlsson, S.
, & Bee, N.
 (1993).
 Constructing and reading evolutionary explanations improve (some) students' understanding of Darwin's theory (Technical Report).
 Pittsburgh, PA: University of Pittsburgh.
 Piaget, J.
 (1985).
 The equilibration of cognitive structures: The central problem of intellectual development.
 Chicago, IL: The University of Chicago Press.
 Schank, R.
 (1986).
 Explanatory patterns: Understanding mechanically and creatively.
 Hillsdale, NJ: Erlbaum.
 Schank, R.
, Kass, A.
, & Riesbeck, C.
 K.
, (Eds.
) (1994).
 Inside casebased explanation.
 Hillsdale, NJ: Lawrence Erlbaum.
 Strike, K.
 A.
, & Posner, G.
 J.
 (1985).
 A conceptual change view of learning and understanding.
 In L.
 West and L.
 Pines (Eds.
), Cognitive structure and conceptual change (pp.
 211231).
 New York: Academic Press.
 642 Learning Statistics T h r o u g h Exemplars Nancy C.
 Lavigne McGill University Educational and Counselling Psychology Lab of Applied Cognitive Science 3700 McTavish Montrdal, Qudbec Canada H 3 A 1Y2 cz81@musica.
mcgill.
ca Abstract This paper implements recent proposals for enhancing the learning of mathematics by developing statistics instruction and assessment for eighth grade students that c^italizes on the use of exemplars.
 The goal of instruction was for small groups to learn about statistics by engaging in handson activities as well as to ̂ ply their knowledge and skills by creating statistics projects tfiat involved designing, conducting, and presenting a miniexperimeni.
 Performance criteria which reflected the statistical concepts taught in the instruction were explained to students to ensure their understanding of the task (i.
e.
, project).
 Groups were assigned to two treatmentsexemplars and nonexemplarsAv'hich differed in the degree to which criteria modeled the processes of hypothesis generation, data collection, data analysis, and graphic representation.
 The effectiveness of elaborating on criteria through examples and text (i.
e.
, exemplars) or just text (i.
e.
, nonexemplars) for enhancing learning was examined.
 Both treatments demonstrated significant performance gains from pretest to posttest.
 However, students' understanding of representative sampling was significantly better as a result of receiving the exemplars treatment than the nonexemplars treatment.
 Making criteria more elaborate through examples of performance can thus enhance students' understanding of more abstfact statistical concepts such as sampling.
 Learning Statistics Through Exemplars The National Council of Teachers of Mathematics (NCTM, 1989) has proposed that statistics instruction commence as early as elementary school in order to facihtate the development of highlevel thinking skills such as problem solving and reasoning.
 Formal methods of instruction that merely emphasize computational and memorization skills are therefore insufficient (American Statistical Association [ASA], 1991; Mosteller, 1988; Posten, 1981; Shaufehnessy, 1992).
 Alternative forms of instruction and assessment ihat enable learners to construct their knowledge as well as illustrate and explain their thinking when solving a problem can now be considered.
 However, the abstract nature of statistical content can pose problems for young learners unless such content is made more concrete and meaningful.
 Making statistical content less abstract can be accomplished by cognitive apprenticeships (Collins, Brown, & Newma'!, 1989) S u s a n n e P.
 Lajoie McGill University Educational and Counselling Psychology Lab of Applied Cognitive Science 3700 McTavish Montrdal, Qudbec Canada H3A 1Y2 insl@musicb.
mcgill.
ca that (a) anchor statistical content in concrete examples that model the statistical problemsolving process (i.
e.
, exemplars), (b) guide learners through impasses while they apply knowledge acquired through modeling, and (c) fade assistance when proficiency is attained.
 The objective of this study was to examine the effectiveness of an instructional method that focused on modeling, one component of the cognitive apprenticeship model, for facilitating secondary students' learning of descriptive statistics.
 T w o research questions were posed: (a) does providing concrete examples of statistical procedures facilitate the learning of abstract content and (b) do students acquire depth or breadth of knowledge.
 Theoretical Framework According to educators and researchers, current statistics education is inadequate due to (a) insufficient conceptual background given to students (Garfield & Ahlgren, 1988; Posten, 1981), (b) an emphasis on the abstract nature of the content (Mosteller, 1988) and (c) a reliance on formal methods of instruction (Posten, 1981).
 These factors result in (a) a reliance on intuitions or opinions which can cause difficulties in reasoning about sampling (Jacobs, 1993; Schwartz, Goldman, Moore, Zech, Smart, MayfieldStewart, Vye, & Barron, 1994; Tversky & Kahneman, 1971) and probability (Kahneman & Tversky, 1973, 1982; Tversky & Kahneman, 1973, 1983) and (b) an understanding of the mean as a computational rather than conceptual act (Pollatsetsek, Lima, & Well, 1981).
 Such difficulties make developing statistics instruction for grades 58 problematic where the proposed content includes measures of central tendency and variation, population, sampling, and anomalies (American Statistical Association [ASA], 1991).
 One way to address shortcomings of statistics education for enhancing highlevel thinking is to provide a learning context in which students are granted opportunities to (a) directly observe expert performance through concrete examples that model statistical problem solving, (b) emulate expert performance by applying statistical knowledge on handson activities, (c) focus on interpretation by using computer software for analyzing and representing data, and (d) expand statistical 643 mailto:cz81@musica.
mcgill.
camailto:insl@musicb.
mcgill.
caknowledge through prompts presented in the lorm of questions that encourage further thinking.
 Method Twentyone eighth grade mathematics students (nine females and twelve males) participated in this study.
 Students were divided into eight mixedability groups, each consisting of two to three students of mixed ability in mathematics.
 Ability groupings were formed by the experimenters based on the teacher's rating (i.
e.
, high, medium, low) of each student's performance as measured by classroom assessments from the beginning of the I ear.
 Each group worked on an Apple®Macmtosh™ workstation which was set up in the students' regular mathematics classroom.
 A form of cognitive apprenticeship (Colhns et al.
, 1989) was adopted to teach students descriptive statistics (i.
e.
, measures of central tendency and variation, I)opulation, sampUng, and anomalies).
 T w o phases of apprenticeship were provided.
 The first phase consisted of modeUng procedures, coaching students, and fading assistance on instructional activities that situated learning in worthwhile and engaging problem solving tasks.
 T w o skills were modeled in the activities: statistical problem solving and the use of software applications such as Mystat™ (Systat, 1988) and Cricketgraph™ (Cricket Software, 1989) as tools for computing and representing statistics.
 Coaching was provided by the mathematics teacher, six graduate students, and prompts which were meant to encourage students to reason about data, to facilitate discussions of statistical concepts, and to extend students' learning beyond the information given (Resnick, 198^; llosenshine & Meister, 1992).
 Fading consisted of gradually withdrawing assistance as students attained mastery.
 The instruction enabled learners to acquire the knowledge of facts and tools required to conduct their own experiment as a group project and consequently to perform on openended test essays.
 Prior to conducting their o w n experiments groups of i tudents were randomly assigned to two treatments: nonexemplars and exemplars.
 These treatments consisted of the second phase of apprenticeship which stricdy focused on modeling the process of designing, conducuing, and presenting an experiment More specifically, computer software, HyperCard™ (Claris Corporation, 1991), was used to provide information which modeled hypothesis generation, data collection, data analysis, and data representation.
 These processes were conveyed as performance criteria in each treatment.
 The nonexemplars and exemplars treatments differed in the extent to which (a) performance criteria for developing and assessing experiments were made visible 10 students (Frederiksen & Collins, 1989) ard (b) statistical procedures for designing and cond^jting research were made more concrete.
 Although each criterion and procedure was described textually in both treatments, only the exemplars treatment pro aded (a) digitized video clips that modeled hypothesis generation as well as the collection, analysis, interpretation, and representation of data by providing examples of performance of students participating in a similar study the previous year and (b) prompts that guided discussions regarding differences between examples (see Figures 1 and 2).
 In this sense, the exemplars served as a tool for (a) ensuring that students were aware of and understood the criteria for conducting an experiment and (b) making procedures more concrete through modeling by providing several examples (i.
e.
, digitized video clips) of peers explaining how they designed and conducted their experiment during their presentations.
 This paper focuses on the effectiveness of the exemplars approach in making statistical procedures less ambiguous through modeling.
 The effectiveness of this treatment was examined in terms of students' performance on an openended pre and post test which was analyzed quantitatively and qualitatively and on projects which was analyzed qualitatively.
 Since the exemplars approach was intended to situate statistical procedures in concrete examples, it was expected to be a more effective tool than the nonexemplars approach for enhancing statistical learning and engendering the knowledge acquisition of statistical procedures such as hypothesis generation, data collection, and data analysis.
 Results Quantitative analysis of the following were conducted: (a) students' overall test performance to determine whether the exemplars treatment was more effective for enhancing statistical learning than the nonexemplars treatment, (b) students' performance on individual test items to explore whether the exemplars treatment was more effective in fostering knowledge acquisition of particular concepts and procedures than the nonexemplars treatment, and (c) students' performance on individual test items to examine whether knowledge of a few or many concepts and procedures was acquired.
 Qualitative analysis of written responses to test items and of performance on presentations of projects were conducted to determine whether students acquired depth or breadth of knowledge as a result of the instruction.
 Finally, interrater reliabilities were performed to examine consistency between raters.
 Quantitative analysis of students' overall test performance examined whether or not type of treatment (nonexemplars or exemplars) affected students' test scores (pre and post).
 Results from the Subject{Treatment (2)) x Test (2) A N O V A demonstrated that there were no significant differences between the two treatments (F(l, I6)=0.
010, p>0.
05).
 However, a significant test effect was found which indicated change in statistical knowledge for all students (F(l, 16)=50.
130,p<0.
05).
 Students receiving the nonexemplars (A/pre=6.
636, Mpost=13.
818) and exemplars (Mpre=5.
714, A/post=15.
143) treatments acquired a substantial amount of statistical knowledge as a result of instruction.
 644 I M s ^ d b i g Q S i ^ IMis ̂ia]fi%BBs You can analyze the infonnation that you have gathered by obtaining statistics for the mean, median, mode, and range, You must explain the results.
 This demonstrates that you understand the significance of the results.
 You must also consider h o w your results would change if ttie study had been done dlfierently (10 points).
 Dr.
 Suwjm* Ujoie "̂  TOC I Quit | ^ | i Figure 1: Example criterion provided by the nonexemplars approach: Data analysis.
 I M h P s ^ B a s & f l s j i D ft® ©ftaftflsftfles You can analyze the infonnation that yoxi have gathered by obtaining statistics for the mean, median, mode, and range.
 You must exjdain the results, This demonstrates that you understand the significance of the results, You must also anslderhawyonr resolts woold change if the study had been done different^' (10 points).
 After looking at the videos, discuss amongst yourselves the differences between the two and why one is better than the other.
 Dr.
 Stiganne Ltjoie ~| Abev* Av*r«9* I Av*r*q* TOC I Quit i ^ | i Figure 2: Example criterion provided by the exemplars approach: Data analysis.
 645 To determine whether knowledge gains differed by treatment and whether these were limited to some content or inclusive of all content, individual Subject {Treatment (2)) x Test (2) A N O V A s were performed on test items measuring each of the following statistical concepts and procedures: statistics, data, gr^h interpretation, outlier, hypothesis generation and identification, population, sample representativeness, sample size, randomization, sample, median, mean, and range.
 The Bonferroni procedure (Kirk, 1982) was ^plied to adjust for Type I error in each of these analyses.
 Significant interaction effects for sample representativeness (F(l,16)=8.
581, p<O.
0l), sample size (F(l,16)=6.
862.
p<0.
01).
 and statistics (F(l,16)= 4.
899, p<O.
0l) demonstrated that knowledge gains related to sampling differed by treatment The Scheff6 S procedure (Kiik, 1982, pp.
 121122) for making posthoc comparisons indicated that the difference in performance from pre to post test on items of sample representativeness was significant for the exemplars treatment (F(l, 16)=24.
225, p<0.
05) but not for the nonexemplars treatment (F(l, 16)=2.
172,p>0.
05).
 Moreover, this difference was significant at post (f (1, 16)=6.
425, p<0.
05) but not at pre (F(l, 16)=2.
581, p>0.
05).
 This finding suggested that students' understanding of representative sampling was facilitated through the use of concrete examples which modeled the procedure.
 Results for sample size indicated that there was a significant pre and post test difference for both the exemplars (F(l, 16)=36.
413,p<0.
05) and nonexemplars (F(l, 16)=11.
388,p<0.
05) treatments.
 Finally, results for the concept of statistics indicated that there was a significant difference between the exemplars and nonexemplars treatments at pre (F(l, 16)=4.
944, p<0.
05) but not at post (F(l, 16)=0.
825, p>0.
05) and that the difference from pre to post test was significant for the nonexemplars treatment (F(l, 16)=20.
988, p<0.
05) but not for the exemplars treatment (F(l, 16)=0.
675,;7>0.
05).
 Significant test effects for statistics (F(l, )6)= 12.
214, p<0.
01).
 gr^h interpretation (F(l, 16)=14.
473, fxO.
Ol), hypothesis generation and identification (F(l, 16)=14.
141,/x0.
01), sample representativeness (F(l, 16)=22.
712.
p<0.
01), sample size (F(l, 16)=46.
622, /xO.
Ol), sample (F(l, 16)=12.
287,/k0.
01), and range (F(l, 16)=10.
670.
p<0.
01) demonstrated that students acquired knowledge of many concepts as a result of instruction.
 However, qualitative analysis of written responses to test items (pre and post) and presentations revealed that students' understanding of the content was general which suggested that breadth rather than depth of knowledge was acquired.
 Not all content was understood by students.
 S o m e concepts and procedures, notably measures of central tendency, were problematic for learners.
 Students were unable to calculate the mean, median, and mode by hand despite knowing how to do so.
 In addition, students had difficulty distinguishing the mean from the median, often defining the median as the "average" rather than the "middle number," terms which in the instruction, were used exclusively to define the mean and median respectively.
 This confusion suggested that the concepts mean and median were not fully understood.
 Moreover, performance on group presentations indicated that most students did not analyze their data.
 Most groups calculated percentages rather than means for describing their data.
 Given that all their research questions entailed collecting frequency data this fmding is not surprising.
 However, it is unclear from group presentations whether students understood that the mean was an inappropriate measure for analyzing frequency data.
 Student responses during the question periods that followed the presentations seemed to suggest that measures of central tendency were not used to analyze the data since gr^hs were deemed sufficient for conveying the results.
 Interrater reliabilities were conducted to examine consistency in the ratings given by two graduate students on the pre and post tests.
 The high correlations fw pre (r=0.
982) and post (r=0.
987) indicated that the scoring criteria for assessing test performance were clear to raters.
 This finding suggests that the test results were reliable.
 Conclusions and Implications The present study demonstrates that statistical learning for young learners can be facilitated by a method of instruction that models procedures by providing various exemplars of peers explaining how they engaged in the experimentation process.
 Substantial knowledge gains from pre to post test were demonstrated.
 The increase in knowledge is considerable given the fourday duration of the study.
 Within this time span, students acquired knowledge of many statistical concepts and pHocedures, however, responses to test items and performance on project presentations indicated that depth of understanding was not acquired.
 This finding may be accounted for by the high content coverage, limited time in which to learn such content, and emphasis on general skills.
 According to Pollatsek et al.
 (1981) and Zawojewski (1988), conceptual difficulties in understanding the mean, for instance, are due to formal methods of instruction which emphasize specific skills such as memorization of algorithms.
 However, this study suggests that instruction emphasizing interpretation without sufficient experience witii computation can lead to difficulties in acquiring conceptual understanding.
 Although conceptual understanding was not attained, this study suggests that additional modeling through the use of concrete examples (i.
e.
, exemplars) can facilitate students' understanding of representative sampling.
 Providing students with multiple representations of realistic performance to make abstract concepts such as representative sampling more concrete can therefore enhance learning.
 However, the choice of representations is crucial.
 Exemplars must be rich enough to diff̂ erentiate the levels of performance that are used to illusUBte various statistical procedures.
 Witiiout 646 such differentiation, the effects of making concepts and procedures less abstract will be minimal.
 This study was limited in that the examples were insufficiently differentiated This study was a first attempt at incorporating one aspect of the cognitive ̂ )prenticeship method of instruction for eighth graders.
 However, much more work is required to develop a strong instructional tool that incorporates all the relevant features of the cognitive apprenticeship model.
 This study is limited by insufficient standardization of the instruction.
 Scaffolding was provided by graduate students who had to be trained rather than by an instructional medium that provided identical instruction to all students (e.
g.
, computCTbased instruction or an intelligent tutoring system [ITS]).
 Developing such a tool is the next phase of this research.
 References American Statistical Association (1991).
 Guidelines for the teaching of statistics K12 mathematics curriculum.
 Landover, M D : Corporate Press.
 Claris Corporation.
 (1991).
 HyperCard Version 2.
1 [Computer program].
 Santa Clara, CA: Apple Computer Inc.
 Collins, A.
, Brown, J.
 S.
, & Newman, S.
 E.
 (1989).
 Cognitive apprenticeship: Teaching the craft of reading, writing, and mathematics.
 In L.
 B.
 Resnick (^±), Knowing, learning, and instruction: Essays in honor of Robert Glaser.
 Hillsdale, NJ: Earlbaum.
 Cricket Software Inc.
 (1989).
 Cricket Graph Version 1.
31 [Computer program].
 Valley Stream Parkway, PA: Author.
 Fredriksen.
 J.
 R.
 & Collins, A.
 (1989).
 A systems approach to educational testing.
 Educational Researcher.
 18 (9), 2132.
 Garfield, J.
, & Ahlgren, A.
 (1988).
 Difficulties in learning basic concepts in probability and statistics: Implications for research.
 Journal for Research in Mathematics Education.
 19 (1), 4463.
 acobs, V.
 R.
 (1993).
 Stochastics in middle school: An exploration of students' informal knowledge.
 Unpublished master's thesis.
 University of Wisconson, Madison, WI.
 Kahneman, D.
, & Tversky, A.
 (1973).
 On the psychology of prediction.
 Psychological Review, 80 (4).
 237251.
 Kahneman, D.
, & Tversky, A.
 (1982).
 On the study of statistical intuitions.
 Cognition.
 11 (2), 123141.
 Kirk, R.
 E.
 (1982).
 Experimental design: Procedures for the behavioral sciences (2nd ed.
).
 Monterey, CA: Brooks/Cole Publishing Company.
 Lavigne, N.
 C.
 (1994).
 Authentic assessme it: A library of exemplars for enhancing statistics performance.
 Unpublished master's thesis.
 McGill University, Montreal, Quebec.
 Mosteller, F.
 (1980).
 Classroom and platform performance.
 The American Statistician, 34 (1), H 17.
 Mosteller, F.
 (1988).
 Btoadening the scope of statistics and statistical education.
 The American Statistician, 42 (2), 9399.
 National Council of Teachers of Mathematics Commission on Standards for School Mathematics (1989).
 Curriculum and evaluation standards for school mathematics.
 Reston, VA: Author.
 Nisbett, R.
 E.
, Krantz, D.
 H.
, Jepson, C , & Kunda, Z.
 (1983).
 The use of statistical heuristics in everyday inductive reasoning.
 Psychological Review, 90 (4), 339363.
 Pollatsek, A.
, Lima, S.
, & Well, A.
 (1981).
 Concept or computation: Students' misconceptions of the mean.
 Educational Studies in Mathematics, 12, 191204.
 Posten, H.
 O.
 (1981).
 Review of statistical teaching materials for 1116year olds.
 The American Statistician, 35 (4), 258259.
 Resnick, L.
 B.
 (1989).
 Treating mathematics as an illstructured discipline.
 In C.
 I.
 Randall & E.
 A.
 Silver (Eds.
), The teaching and assessing of mathematical problem solving (pp.
 3260 ).
 Reston, VA: National Council of Teachers of Mathematics.
 Rosenshine, B.
, & Meister, C.
 (1992).
 The use of scaffolds for teaching higherlevel cognitive strategies.
 Educational Leadership, 49 (8), 2633.
 Schwartz, D.
, Goldman, S.
, Moore, A.
, Zech, L.
, Smart, L.
, MayfieldStewart, C , Vye, N.
, & Barron, L.
 (1994, April).
 Adolescent understanding of sampling in the context of a survey.
 Paper presented at the annual meeting of the American Educational Research Association, N e w Orleans, LA.
 Shaughnessy, J.
 M .
 (1992).
 Research in probability and statistics: Reflections and directions.
 In D.
 Grouws (Ed.
), Handbook for research in mathematics teaching and learning (pp.
 465494).
 N e w York: Macmillan Publishing.
 Systat Inc.
 (1988).
 Mystat Version 1.
0: A personal version of SyStat.
 [Computer program].
 Evanston, IL: Author.
 Tversky, A.
, & Kahneman.
 D.
 (1971).
 Belief in the law of small numbers.
 Psychological Bulletin, 76 (2), 105110.
 Tversky, A.
, & Kahneman, D.
 (1973).
 Availability: A heuristic forjudging frequency and probability.
 Cognitive Psychology , 5 , 207232.
 Tversky, A.
, & Kahneman, D.
 (1983).
 Extensional versus intuitive reasoning: The conjunction fallacy in probability judgement.
 Psychological Review, 90 (4), 293315.
 Zawojewski, J.
 S.
 (1988).
 Teaching statistics: Mean, median, and mode.
 Arithmetic Teacher, 35 (7), 2526.
 647 Parsing and Recovery Vincenzo Lombardo Dipariimenio di Informatica  Universita* di Torino c.
so Svizzera, 185  10149 Torino  Italy Centro di Scienza Cognitiva  Universita' di Torino via Lagrange, 3  10123 Torino  Italy v i n c e n z o Q d i .
 u n i t o .
 i t Abstract The paper introduces a general model of recovery from errors in parsing.
 The mechanism proposed returns selectively on the choice points, in order to identify the one that was badly resolved, and could have caused the error.
 Then, it selects an alternative previously discarded and finally selectively repairs the appropriate fragments between the ambiguous region and the breakdown region.
 Both the psycholinguistic and the computational features of the model are put in evidence.
 Introduction The resoluiion of syntactic ambiguities has received much aiiention in the literature.
 Attachment preferences have been devised with both the goals of explaining the behavior of the human parser (Kimball, 1973; Frazier & Fodor, 1978; Ford, Bresnan & Kaplan, 1982) and equipping a system with an efficient mechanism for the selection of a promising syntactic structure (Shieber, 1983; Hobbs & Bear.
 1990; Huyck & Lytinen, 1993); partofspeech disambiguation has been dealt with in the context of deterministic parsers (Milne, 1986) and automatic text tagging (Church, 1988; DeRose, 1988; Hindle, 1989).
 So far, cognitive models have made much progress in accounting for the initial preferences in human parsing and in characterizing gardenpath sentences; automatic systems have improved the capability of reducing the size of the search space by selecting plausible structures according to cognitive and computational criteria and restricted domain knowledge.
 Path selection tries to optimize local operations, when only the current input phrase and some portions of syntactic (in incremental processing also semantic and contextual) structures are accessible.
 However, the best local choice can turn out to be wrong.
 Most models of human parsing roughly distinguish two classes of failures, irrecoverable gardenpaths and simple locally revisable sentences; most system architectures include bookkeeping mechanisms that avoid blind backtracking.
 Computational models of recovery are very rare in the literature.
 The goal of this paper is to introduce a general model of recovery that Lakes cognitive insights as a starting point.
 The model has been tested on a set of heuristics that recover some wellknown cases of breakdown, reported in the literature on syntactic ambiguity and garden path theory.
 The organization of the paper is as follows.
 The next section introduces the parsing process, in order to understand what situation the system encounters at the breakdown point, in terms of active structures and abandoned paths.
 The recovery mechanism is described in the third section, by considering the specific phases that compose the global process.
 Finally, some conclusion and comments on the related work are reported.
 The appendix reports a small subset of the sentences used for testing.
 The Parsing Algorithm The parsing algorithm goes lefttoright, pursuing a selective topdown strategy that joins the predictive power of topdown parsers and the bottomup filter provided by scanning the category of the word in input.
 This strategy accounts for two aspects of the human processor: on one hand, the facility of committing syntactic expectations, on the other, the datadriven triggering of such a facility.
 At the points of nondeterminism, the parser pursues a limited form of parallelism, in order to evaluate the best path to follow.
 In this phase the parser takes advantage of the notion of compact representation (subtree sharing and local packing (Tomita, 1987)) in order to avoid duplicating the same structure on several paths (fig.
 la).
 Some parts of the structure cannot be shared by all the paths: for instance, the three edges NPPP, VPPP, SPP, in fig.
 la are mutually exclusive.
 To signal that some elements cannot occur together in the same structure, the processor labels them with indices: an index has the form i.
j, and identifies the jth alternative for the ith point of non determinism.
 Elements labelled i.
j cannot cooccur with elements labelled i.
k, k̂ ĵ.
 Given the topdown character of the parsing process, an index associated with an element is intended to label the whole subtree rooted in it.
 The parts of the structure that do not depend on a particular choice are left unlabelled and are meant to belong to the structure whatever path is followed.
 A path is precisely defined as an exhaustive set of indices that can cooccur, where exhaustive means that the set contains at least one representative of each ambiguity encountered, and, because of cooccurrence, it contains exactly one.
 The structure that corresponds to a path is one possible parse.
 The path to follow results from an evaluation, in terms of syntactic preference and semantic consistency, of the various partial structures built in the parallel phase.
 One parse, called the aciive parse and corresponding to a specific path, is selected for continuation.
 The remaining partial structures are not deleted, even if not reachable in the currently aciive path, and are possibly reconsidered in the recovery phase.
 648 s ̂  / ^ V ^  ^ 3 NP VP^ ^<s^ / \ ^ < ^ John V NP \ 1 A ^ ^ sent the book PP on the table (a) S / \ NP VP _ _ _ _ _ _^ / \ " — John V NP^ A ^ ^ sent the book PP / N on the table (b) .
 >^ PP / N to Anne Figure 1.
 T w o snapshots in parsing: the structures are simplified to point out the index mechanism.
 Let us consider the analysis of the sentence "John sent the book on the table to Anne" (see fig.
 1).
 The attachment of "on the table" is ambiguous (fig.
 la) and the three alternatives are labelled l.
j, j£ (1, 2, 3}.
 The three possibilities are mutually exclusive and the structure in fig.
 la actually represents three partial parses, each including just one of the attachments.
 Attachment preferences lead to a preferred structure (the alternative which is preferred in fig.
lb (1.
1) corresponds to Late Closure).
 Finally, the last PP is attached to V P without ambiguity, because of the subcategorization constraints given by "sent" and the preferred attachment of a PP headed by "to" to an aciion (sent) rather than an object.
 (table, book).
 The index 1.
1 also labels the new attachment because V P has been made reachable after the selection of 1.
1 at the previous nondeterministic point (compare with selecting 1.
2 or 1.
3).
 Recovery Psycholinguislic literature has not paid much attention to the problem of recovery, even if a more or less explicit mechanism has been widely conjectured, given the garden path phenomena and the general limitations of the working memory^.
 One of the results of the psycholinguistic research has been the selective rcanalysis hypothesis (Frazicr & Rayner, 1982), which suggests the existence of a human capability to "quickly identify the source of an erroneous analysis of temporarily ambiguous material".
 In terms of a computational model, an "intelligent" recovery mechanism should not try out each choice point (like a standard backtracking procedure), but should carry on a selective search.
 The expectations that remain unsatisfied in the currently active parse and the features carried by the input material that caused the breakdown (included a premature end of sentence) form a body of information that guides a heuristicbased search of choice points.
 Once the wrong choice is identified, the same information contributes to select an alternative choice among those previously discarded.
 Finally, the active parse is repaired complying with the path change.
 The recovery mechanism presented in this paper takes the selective reanalysis hypothesis as a starting point.
 The model (fig.
 2), that has been equipped with a set of heuristics that account for common breakdowns reported in the literature, consists of three phases: error diagnosis, that uanslates the information available at the breakdown point into a unique symbol; selection of an active index i.
j and proposal of an alternative index i.
k (k?tj), given the error diagnosed and the active structure; repair of the elements of the representation labelled i.
j.
 These phases are described in detail in the following sections.
 Diagnosis The output of the diagnostic module is an error type, a symbol that conveys the useful information available at the breakdown point.
 The taxonomy of the possible errors is shown in fig.
 3.
 There are two major error classes: Extra, that indicates linguistic material in excess with respect to the expectations, and Missing, that indicates that an element that was expected is "missing".
 The error is more informative if it is possible to identify the syntactic category of a phrase in excess (e.
g.
 ExtraNP) or expected (e.
g.
 MissingVerb) or the grammatical relation deducible from the surface form of a phrase (e.
g.
 she ExtraSubj) or predicted by the currently active subcategorization frame (e.
g.
 MissingObj).
 The low levels of the taxonomy (not in the figure) contain very specific types that account for further syntactic features, like gender, number, finiteness of verbs (diagnostics)^ error code /^SELECTION OF AN ALTERNATIVE PATH i <i.
j, i.
k> syntactic structure / o Q / K 1 REPAIR 'Some exceptions to tliis claiming are summarized in section 5.
 Figure 2.
 The recovery model.
 649 ErrorType ExtraType NlissingType pe Mis / \ / \ ExtraCat ExtraCase MissingCat MissingCase Figure 3.
 Taxonomy of error types: the leaves are omitted (they depend on the specific grammar and subcategorization frames).
 Here are some examples of garden paths, that if interpreted in an unbiased context originate the error types in brackets: 1) The horse raced past the bam/e// (Bever, 1970) {ExtraVerb) 2) The prime number few 0 (Milne, 1982) (MissingVerb) 3) That information is important is doubtful (Tomita, 1987) (ExtraVerb) 4) I gave h£r food for the dog 0 (MissingRecipient) The breakdown point is indicated by a word in italics or the symbol 0 (end of sentence); the ambiguity point, where the wrong choice was made, is underlined.
 The diagnostic module is a set of rules that take into account the situation at the moment of the breakdown, in terms of the features of the input word and of structures built, and produce an error symbol.
 Most breakdowns are covered by two very intuitive rules, namely Rl) IF the input phrase is of category Cat T H E N return ExtraCat R2) Let N be a node IF endofsentence & a phrase of category Cat.
 expected as a dependent of N, is missing T H E N return MissingCat Specific rules diagnose more informative error symbols: R3) IF the input word is a finite verb & no subject for it has been found yet T H E N return MissingSubj Each error symbol covers a set of breakdown phenomena: error symbols are determined empirically and their number depends on the size of the grammar and the expertise of a system in recovery.
 A subset of the sentences used for testing the model is displayed in the appendix, together with the error code detected.
 Selection of an alternative path The goal of this phase is to identify an active choice i.
j that led to the breakdown.
 Each error code has a search procedure associated, that selects in the active parse an element that, according to some heuristic, could be "related" to the error code.
 If this element is labelled with an index (i.
j), this means that its construction was the result of a preference matter rather than a deterministic process, and, then, it could be a candidate for revision.
 A n alternative index i.
k, that satisfies some further conditions, is returned.
 The search procedures incorporate some rationale underlying the error type.
 For instance, in the case of Extraverb, it could be guessed (see SI below) that some word encountered was incorrectly parsed as the (current) verb, thus preventing the correct parsing of the current input word ("raced" in ex.
 1).
 Here are some examples: ExtraVerb SI) Search for a verbal node labelled with an index i.
j > Return i.
k such that introduces a verb expectation S2) Search a subcategorization frame curretly active such that: 1.
 it is labelled with i.
j 2.
 the corresponding verb has an alternative subcategorization {labelled i.
k) that contains a clausal complement > Return i.
k ExtraSubj S3) Search for the current SUBJ, say N P m , labelled with i.
j •> Return i.
k such that N P m is not SUBJ MissingSubj S4) Search for the N P immediately preceding the input verb such that its attachment is labelled with an index i.
j " > Return i.
k such that N P is SUBJ The refinement of the error types guarantees the nonoverlapping of the applicability conditions for the search procedures: at the moment, the testing on the search procedures have produced incouraging results, since no conflicts arose.
 Repair The last phase involves the adjustment of the syntactic structure according to the new active path given by the previous path where iJc has replaced i.
j.
 The first step is to include in the active parse the element E, labelled i.
k, that was selected in the previous phase.
 Then, repair computes the new nodes suitable for expansion and starts a forward processing that is very similar to the parsing algorithm outlined above with some differences.
 The aim is to save computation time by reusing those structures that are compatible with the new active path, because not dependent on the choice indexed i.
j that revealed to be wrong.
 The repairing phase is described by the algorithm in fig.
 4.
 The repairing phase (see fig.
 4) "reparses" the words comprised between the ambiguous region (BEGIN), just repaired with the new selection, and the disambiguating region (END), where the breakdown occurred.
 "Reparsing" is very similar to the syntactic analysis illustrated in section 2 with one major difference: if the word in input is already parsed in a structure S that is still active after the change of path (it does not depend on the wrong choice), then only the attachment to the new active structure is recomputed and, in case of ambiguity, the best attachment of S is evaluated and the "reparsing" jumps to the input word that comes after S; otherwise w is parsed in the usual way.
 W h e n the "rc650 parsing" arrives at the input word that caused the breakdown, the parsing process is restarted to finish the analysis.
 set B E G I N to the rightmost word in the ambiguous region selected in the phase 2 set E N D to the the current input word for each word w from B E G I N to E N D dfl compute the set of reachable nodes if w already belongs to a s&ucture S that is active in the new path then compute the possible attachments of the structure S to the reachable nodes select the best attachment jump to the first input word that follows the structure S else parse w Figure 4.
 The repairing algorithm.
 An Example The syntactic structure adopted in our implementation is a dependency tree (see fig.
 5), a set of binary headmodifiers relations over the words, that represent the predicateargument structure of the sentence.
^ The topdown lefttoright parsing algorithm "creates" nodes of a certain syntactic category and then "fills" them with one input word.
 The correct parse of the example sentence, "Though Hilda finally agreed to sing the songs she chose turned out to be just awful", is represented in fig.
 5 (in the following figures, for the sake of simplicity, w e will omit the relation labels on the arcs).
 though' turned p \ \ vcompl scompl fubj \ songs out to red d e ^ \rclause Y^cd agreed the chose be ^"bj/Cadv/ >^compl Luh) Hilda finally to she \pred \pred awful aadv / Sing just Figure 5.
 Dependency tree of the sentence T h o u g h Hilda finally agreed to sing the songs she chose turned out to be just awful.
 The word order is given by the orientation of the arcs.
 Labels on arcs represent the functions of modifiers, and are used in the semantic interpretation.
 The respective merits of constituency and dependency approaches as well as the relative mathematical power are discussed in a number of publications.
 The choice of this structure does not affect the generality of the recovery model.
 After the unambiguous parsing of "Though Hilda finally agreed" as a sentential complement of a "yettocome" main verb (empty left side of node VI in fig.
 6), the attachment of "to sing" is competed between an Early Closure of "agreed", as would be required by Though Hilda finally agreedi.
) to sing those songs she ought to be a soprano and a Late Closure, as in Though Hilda finally agreed to sing(,} the songs she chose turned out to be just awful giving the attachment labelled 1.
2 and 1.
1 respectively (fig.
 6).
 If we follow the L C preference (1.
1), the attachment for "the songs" is ambiguous between an E C and a L C of "sing", as exemplified by the two possible continuations Though Hilda finally agreed to sing{.
) the songs she chose turned out to be just awful Though Hilda finally agreed to sing the songs(,) she chose very awful tunes If w e prefer again L C (2.
1 in fig.
 6), w e have two attachments for "she", namely "sing" (LC) and the main verb of the sentence which is yet to come, both acceptable in the global contexts given respectively by Though Hilda finally agreed to sing(,) the songs she chose turned out to be just awful and Though Hilda finally agreed to sing the songs(,) she chose very awful tunes The choice for L C gives the structure in fig.
 6, where the currently active path is given by the set (1.
1, 2.
1, 3.
1}, and the abandoned choices are represented as dashed arcs.
 Notice that the node VI is "empty" in the active path.
 VI (verb) 11 2.
1 3.
2 chose3 22/ /3.
2 Hilda finally to songs / the ' chose Figure 6.
 Syntactic structures after parsing "Though Hilda finally agreed to sing the songs she chose".
 The active arcs are given by plain lines, dashed lines are part of abandoned paths.
 The active path is given by the set of indices {1.
1, 2.
1, 3.
1).
 "chose" in VI is not active, since its index 3.
2 is not active.
 651 file:///rclausefile:///predfile:///predthough acrccd .
 y " / / W ^ Hilda finally lo i \ / sing / V > / • / ' sonfs / Vl(verb) 1 „.
,,~^\emply" / / / / / ' 7 /32 J 1 1 1 1 1 the ' chose / / she 1 2.
1 3.
2 chos^ Figure 7.
 When the word "turned" arrives, an error MissingSubj is generated (rule R3) and the procedure S4 selects the N P rooted in "songs" and the index 2.
1 for revision.
 The alternative choice 2.
2 connects "songs" with VI (fig.
 7).
 The repairing phase inserts "turned" into the structure: the reachable nodes are "chose", "songs" and empty VI, but the only possible operation is to insert "turned" into VI.
 The rest of the input gives no problems and the final structure with the active indices is in fig.
 8.
 Related Work and Conclusion The paper has introduced a general model of recovery that selectively returns to the points in the structure that could have caused the error, retracts the pans that were built in consequence of the error and repairs the appropriate fragments between the ambiguous region and the breakdown region, in order to restart the normal parsing.
 Some recent attempts in the literature have some similarities with this mechanism.
 Abney (1993) introduces a though agreed / l\ Hilda finally to 1.
1 2.
2 turned songs out to / V* \ the chose be she awful smg just Figure 8.
 The complete dependency structure, given by the path (1.
1,2.
2,3.
1).
 repairing mechanism into the incremental parser CASS.
 C A S S works on lagged input text and the repairing filters propose new phrase structures in correspondence of specific error labels, that are particular non terminal symbols with productions associated.
 Some TMSbased proposals have tried to apply general techniques of reason maintenance to natural language: the J T M S approach (Zemik & Brown, 1988) has been criticized because of the impossibility to evaluate the best parsing route in presence of multiple alternatives; the A T M S approach (Chamiak & Goldman, 1988), which overcomes this drawback by maintaining multiple interpretations in assumptionbased contexts and switching between them, leads to a combinatorial explosion and is not able to perform default reasoning (this approach can be simplified by ATMSstyling a chart parser (Wiren, 1990)).
 In the field of cognitive modeling, Eiselt (1989) describes a recovery mechanism mostly applied to lexical ambiguity resolution in the context of a computational model called C O M P E R E (Mahesh & Eiselt, 1994); Stevenson (1994) has introduced a unified model for parsing and recovery that aims to account for the fine scalability of behaviors of human parsing, in dependency of recency factors.
 In psycholinguistic terms, the model takes into account the expertise that human subjects own on recovery: an error label refers to a type of block that is recognizable by a human listener, since s/he aheady underwent and overcame the same difficulty in the past.
 This paper is centered on syntactic ambiguities and the consequences derived from a wrong syntactic choice.
 However, the technique, which already accounts for errors in subcategorization, can be extended to cope with general semantic failures and erroneous pragmatic inferences.
 The heuristics introduced can be furtherly refined through the analysis of the larger set of examples and after a testing on real texts.
 An interesting problem concerns the revision of interpretation triggered by the appearance of further evidence in favor of an abandoned path and not by a complete breakdown.
 Finally, there is no treatment of illformed input.
 Appendix MissingCase a.
 1) 1 gave her food for the dog A ERROR: MissingDative (give) AMBIGUITY: ADJECTIVE/PRONOUN (her) CHOICE: ADJECTIVE a.
2) I put the book in the bathroom A ERROR: MissingDestination(put) AMBIGUITY: PP ATTACHMENT (NPA'ERB) CHOICE: NP ATTACHMENT a.
3) John told the girl jhal he had married thai he never loved her ERROR: MissingObj(marry) AMBIGUITY: R E L P R O N / C O M P L E M E N T I Z E R (that) CHOICE: COMPLEMENTIZER a.
4) Though George went on reading the story really bothered him ERROR: MissingSubj(bothered) 652 AMBIGUITY: LC/EC (reading) CHOICE: LC ExtraCase b.
l) He put the cattle in the barn out to pasture for spring grazing ERROR: ExtraDestination(put) AMBIGUITY: PP ATTACHMENT (NP/VERB) CHOICE: VERB ATTACHMENT b.
2) He mailed the ticket lo London to Mary ERROR: ExuaDestination(mail) AMBIGUITY: PP ATTACHMENT (NPA'ERB) CHOICE: VERB ATTACHMENT b.
3) I told the girl ihai you kissed the story ERROR: ExtraObj(tell) AMBIGUITY: RELPRON/COMPLEMENTIZER (that) CHOICE: COMPLEMENTIZER b.
4) I gave h£r food to the dog ERROR: ExtraDative(give) AMBIGUITY: ADJECTIVE/PRONOUN (her) CHOICE: PRONOUN MissingVerb C.
I) The prime number few A AMBIGUITY: ADJECTIVE /NOUN (prime) CHOICE: N O U N C.
2) The woman rushed to the hospital and forgot her laundry A AMBIGUITY: FINITE/INHNTTE (rushed) CHOICE: INFINITE ExtraVerb d.
l) The horse raced past the harnfell /s^BIGUITY: FINITE/INFINITE (raced) CHOICE: FINITE d.
2) That information is important is doubtful AMBIGUITY: DET/COMPLEMENTIZER (that) CHOICE: DET References Abney, S.
 (1993).
 Rapid Incremental Parsing with Repair, Proceedings of the 6th New OED Conference: Electronic Text Research (pp.
 19).
 Waterloo, Ontario.
 Bever, T.
 (1970).
 The Cognitive Bias for Linguistic Structures.
 In Hayes J.
 (Ed.
), Cognition and the Development of Language (pp.
 279352).
 New York: John Wiley And Sons.
 Chamiak, E.
 & Goldman, R.
 (1988).
 A Logic for Semantic Interpretation.
 In Proceedings of 26th Annual Meeting of the Association for Computational Linguistics (pp.
 8794).
 Buffalo.
 Church, K.
 (1988).
 A Stochastic Pans Program and Noun Phrase Parser for Unrestricted Text.
 In Proceedings of the Second Conference of Applied Natural Language Processing (pp.
 136143).
 DeRose, S.
J.
 (1988).
 Grammatical Category Disambiguation by Statistical Optimization.
 Computational Linguistics, 14, 3139.
 Eisclt, K.
 (1989).
 Inference Processing and Error Recovery in Sentence Understanding.
 (Tech.
 Report 8924).
 Doctoral Dissertation.
 Irvine, CA: University of California.
 Ford, M.
, Bresnan, J.
 & Kaplan, R.
 (1982).
 A competencebased theory of syntactic closure.
 In Bresnan J.
 (ed.
), The Mental Representation of Gramatical Relations, Cambridge, MA: MIT Press.
 Frazier, L.
 & Fodor, J.
 D.
 (1978).
 The Sausage Machine: A new twostage parsing model, Cognition 6, 291325.
 Frazier, L.
 & Rayner, K.
 (1982).
 Making and Correcting Errors during Sentence Comprehension: Eye Movementsin the Analysis of Structurally Ambiguous Sentences, Cognitive Psychology 14, 178210.
 Hindle, D.
 (1989).
 Acquiring disambiguation rules from text.
 In Proceedings of 27th Annual Meeting of the Association for Computational Linguistics.
 Hobbs, J.
R.
 & Bear, J.
 (1990).
 Two Principles of Parsing Preferences.
 In Proceedings of the Thirteenth International Conference on Computational Linguistics.
 Helsinki.
 Huyck, C.
R.
 & Lytinen, S.
 L.
 (1993).
 Efficient Heuristic Natural Language Parsing.
 In Proceedings of the National Conference on Artificial Intelligence (pp.
 386391).
 Kimball, J.
 P.
 (1973).
 Seven principles of surface structure parsing in natural language.
 Cognition, 2, 1547.
 Mahesh, K.
 & Eiselt, K.
 P.
 (1994).
 Uniform Representations for SyntaxSemantics Arbitration.
 In Proceedings of the Sixteenth Annual Meeting of the Cognitive Science Society (pp.
 589594).
 Atlanta, GA: Lawrence Erlbaum Associates.
 Milne, R.
 (1982).
 Predicting Garden Path Sentences.
 Cognitive Science 6, 349373.
 Milne, R.
 (1986).
 Resolving ambiguities in a deterministic parser.
 Computational Linguistics 12, 112.
 Shieber, S.
 M.
 (1983).
 Sentence disambiguation by a shiftreduce parsing technique.
 In Proceedings of 21st Annual Meeting of the Association for Computational Linguistics (pp.
 113118).
 Cambridge, MA.
 Stevenson, S.
 (1994).
 A Unified Model of Preference and Recovery Mechanisms in Human Parsing.
 In Proceedings of the Sixteenth Annual Meeting of the Cognitive Science Society (pp.
 824829).
 Atlanta, GA: Lawrence Erlbaum Associates.
 Tomita, M.
 (1987).
 An Efficient AugmentedContextFrce Parsing Algorithm.
 Computational Linguistics 13, 3146.
 Wiren, M.
 (1990).
 Incremental Parsing and Reason Maintenance.
 In Proceedings of the Thirteenth International Conference on Computational Linguistics (pp.
 287292).
 Helsinki.
 Zernik, U.
 & Brown, A.
 (1988).
 Default Reasoning m Natural Language Processing.
 In Proceedings of the Twelfth International Conference on Computational Linguistics (pp.
 801805).
 Budapest.
 653 Mutability a n d the Determinants of Conceptual Transformability Bradley C.
 Love Department of Cognitive and Linguistic Sciences Brown University Providence, RI029121978 love©cog.
 brown.
 edu Steven A.
 Sloman Department of Cognitive and Linguistic Sciences Brown University Providence, RI 029121978 slomanQcog.
brown.
edu Abstract Features differ in their mutability.
 For example, a robin could still be a robin even if it lacked a red breast; but it would probably not count as one if it lacked bones.
 One hypothesis to explain this differential transformability is that having bones is more critical to a biological theory than having a red breast is.
 W e reject this hypothesis in favor of a theory of mutability based solely on local dependency links and expressed in the form of an iterative equation.
 W e hypothesize that features are immutable to the extent other features depend on them and offer supporting data.
 1.
 Introduction and background The study of conceptual use and conceptual transformation has taken two distinct directions.
 O n one hand, some theorists assert that human conceptualization is theorybased, in the sense that concepts cohae by virtue of explanatory relations that hold between concepts and their components (e.
g.
, Carey, 1985; Keil, 1989; Murphy & Medin, 1985; W e U m a n , 1990).
 O n the other hand, some theorists take what Rips (1990) has termed the Loose view of concepts.
 These theorists explain poformance on categorization, reasoning, and other conceptual tasks using statistical, similaritybased, or associative models of cognitive processing (e.
g.
, Holyoak & Thagard, 1989; Sloman, in press; Tversky, 1977).
 O n the theorybased view, relations between concepts and their components come in qualitatively different varieties.
 For instance, the theorybased view assumes multiple forms of <3ejpef)d&ncy relations between the components of concepts.
 For the concept robin, the dependency between the feature "can fly" and the feature "has wings" is causal.
 However, for the concept guitar, the feature "makes music" is not causally related to "makes sound", but is rather a specialization of it (cf.
 Collins & Michalski, 1989).
 In sum, on the theorybased view, relations are labeled by their semantic role.
 In contrast, on the Loose view, the relations binding concepts may vary in their magnitudes but they are all of the same semantic type.
 O n this view, only one type of relation is necessary to bind concepts and the components of a concept.
 For example, both causal and specialization relations would be classified simply as dqjendeaicy relations.
 Our aim is to provide support for this hypothesis.
 W e believe that much of human conceptualization can be explained without appealing to labeled relations.
 W e focus on tasks that involve conceptual transformations of evayday concepts and offa evidence that the ease of transforming a feature can be measured on a unidimensional scale of mutability, a scale that we believe is central to explaining performance on a variety of cognitive tasks.
 W e also test the hypothesis that mutability is detamined by a uniform type of dependency relation between the features of a concept.
 More specifically, w e hypothesize that a feature is immutable to the extent that other (immutable) features of the concept depend upon it.
 2.
 The scale of mutability For any category, we have a notion of what members of that category should be like.
 For instance, when one thinks about robins, one envisions a creature that eats, builds nests, flies, has wings, a red breast, feathers, and so on.
 Nevertheless, one can successfully perform conceptual transformations in which one can imagine a robin that does not build nests but is still a robin.
 Consider the two statements below, each of which describes a robin that is atypical: (A) The robin does not have a red breast, but is otherwise normal.
 (B) The robin does not ever eat, but is otherwise normal.
 Clearly, you are less likely to encounter the robin described by Statement (B) than the one described by Statement (A) because (B) describes a more difficult conceptual transformation.
 Something that does not have a red breast is more easily imagined to be a robin than something that does not eat because eating is more central in our representation of "robinhood" than is a red breast.
 Features that are central to a representation, like "eats", will be referred to as immutable, while those that are more 654 easily transformed, like "has a red breast", will be rrferred to as mutable.
 3.
 Determinants of mutability 3.
1 Variability One possible source of mutability judgments is the perceived variability of features across category members.
 Features that are almost always present will have low variability and thus be immutable in the sense that exceptions are rare.
 Features present in about half the members of a category are highly variable and necessarily mutable.
 Variability however does not provide a sufficient explanation for mutability because the psychological determinants of variability itself and the sets it is measured across are not welldefined.
 Variability does not even have meaning for cases in which one has only a single experience with the category token.
 Moreover, we know perceptions of variability are not the only source of mutability judgments because differences in mutability exist even when variability is held constant.
 Variability and mutability can even oppose one another.
 Consider the feature "is curved" for the categories banana and boomerang.
 In banana, the feature has low variability (all bananas arc curved), but is mutable (we can easily imagine a banana that is not curved).
 In boomerang, the feature "is curved" happens to be variable, but nevertheless seems immutable (Medin & Shoben, 1988).
 This reversal can be accounted for in terms of the dqjendency relations between the features of each category and the feature "is curved".
 N o other features depend upon "is curved" in bananas, while other features do dqiend upon it in boomerang.
 In sum, mutability and variability are related inasmuch as both types of judgments are sensitive, directy or indirectly, to the extent to which a feature actually does vary across instances.
 W e predict therefore that the two judgments will be correlated.
 However, the judgments are not the same; mutability is a property of conceptual structure and variability is an extensional property of frequency distributions.
 W e therefore expect the two judgments to sometimes diverge.
 3.
2 Dependency Our centrality hypothesis states that those features that have many other features depending upon them will be immutable, while those features that do not have other features depending upon them will be mutable.
 Transforming a representation by varying an immutable feature will be difficult because it will be disruptive.
 Other features that depend upon the immutable feature will also change and this can have ramifications for the entire representation.
 Performing conceptual transformations across mutable features is relatively easy because little hinges on these features; they are relatively peripheral.
 W e express this hypothesis using the following iterative equation: Ciiti = XAijCj, (1) where C ^ is the immutability of feature i at time t and A^ is the dependency link from feature j to feature i (the dependence oi feature j upon feature i).
 According to the equation, the immutability of feature i is detamined at each time step by summing across the immutability of every other feature multiplied by that feature's degree of dependence upon feature i.
 In other words, if a highly immutable feature dq)ends upon feature i, feature i becomes more immutable than if a mutable feanjre were instead to depend upon it.
 A feature cannot become central to a representation merely because a paiphCTal feature depends upon it.
 The feature would be much more central if a feature dqiended upon it that many other features, in turn, depended upon.
 If feature X dqjends upon feature Y, and feature Y depends upon feature Z, then feature X also dqiends upon feature Z.
 All other things being equal, feature Z would be less immutable if feature X did not depend upon feature Y.
 These nonlocal effects are accommodated by the iterative nature of Equation (1).
 To implement the model, immutability ratings must be set to some initial arbitrary value.
 The model iterates until it converges.
 Mathematically, the model is a repetitive matrix multiplication and is known to converge to a stable solution in a small number of steps (Wilkinson, 1965).
 The solution is a family of vectors in the direction of the eigenvector of the dependency matrix with the largest eigenvalue.
 The model converges when it is attracted to a state in which satisfactory immutability assignments are made for all features simultaneously.
 Equation (1) describes our attempt to reduce mutability to pairwise, unlabeled dependency relations.
 These relations can be conceived of as associative strengths.
 Although w e cannot justify assigning them a probabilistic interpretation, the value of A,j may turn out to be a nondecreasing function of Pr{ feature j I feature i} Pr{feature j).
 W e do not present a model of the origin of the dependencies.
 W e assume that they have multiple sources, including the detection of feature covariations and causal explanations of category structure.
 4.
 Testing the model A series of three studies was performed to explore the relations between mutability, dependency, and variability.
 W e test two predictions: i.
 Mutability judgments can be fit by Equation (1) using empirically obtained depaxlency judgments; ii.
 Mutability judgments are correlated with 655 judgments of variability.
 Each study involved questionnaires which were filled out by 20 Brown University undergraduatCvS w h o were paid for their participation.
 4.
1 Study 1: Assessing the mutability of the features of a category In this study, mutability ratings were collected for the features of the categories Guitar, Apple, Chair, and Robin.
 The features used for these categories were taken firom Rosch, Mervis, Gray, Johnson, and BoyesBraem (1976).
 Rosch et.
 al.
 used a threestep procedure to collect features.
 First, subjects were given 90 seconds to list features for a category.
 Second, responses were tallied and feamres listed by less than one third of the subjects were discarded.
 Next, seven judges deleted features that they believed were not true of all category members and aided previously listed features that they believed were true of all category members.
 At the end of this process, the categories Chair, Guitar, and Apple each had 9 features, while the category Robin had 14 features.
 In Study 1, subjects gave mutability judgments for these features.
 Before making their mutability judgments, subjects were told what the features of each category were, and were asked not to deviate drastically fiom this conception of the category.
 They were then asked to answer questions like, " H o w easily can you imagine a real apple that is not round?" Subjects responded with a number from 0 to 1 that reflected the ease of the transformation.
 At the end of each section, subjects were asked to list all items for which they had drastically changed their perception of the category (e.
g.
 the subject considered a toy robin instead of a real one).
 These items (about 9 percent) were discarded.
 4.
2 Study 2: Measuring dependency relations Subjects were shown, simultaneously, all the features of a particular category from the previous study.
 Each feature was inscribed in a circle and subjects were asked to draw arrows from each feature to each other feature they judged the feature dependent upon, creating a gr^h like those shown in Figure 1.
 Three different colored markers were used to indicate the strength of the dependency.
 The weakest links were assigned the value 1, medium links 2, and the strongest links 3.
 Instructions were clarified using a graph of the category "12", with mathematical features like "can be divided by 6".
 4.
3 Study 3: Assessing the variability of the features of a category The features and categories from the previous studies were used.
 Subjects were asked questions such as "What percentage of robins have a red breast?" and they responded with a number between 0 and 100.
 Variability was calculated by transforming percentage estimates using the binomial variability measure X/1(X)*(1  X/100) for each feature.
 4.
4 Results and discussion Figure 1 displays the mean dependency link values and mutability judgments (on a scale of 0 to 1) given by subjects.
 To maintain the readability of the graphs, only the strongest dependencies have been drawn (an average of 1.
25 links per feature), although all dependency information was used in our simulations.
 From these graphs, one can see that features with few other features depending upon them tend to be mutable while features with many features depending upon them tend to be immutable, as predicted.
 Table 1 presents Spearman rank correlations between mutability judgments and three dependency models across item means.
 The first model simply sums the incoming dependencies to compute immutability.
 This model's pafonmance confirms our intuition that a feature's immtability varies with the number of other features that depend upon it.
 The second model is Equation (1) itself.
 Clearly, Equation (1) outperforms the incoming connections model, demonstrating that a feature's immutability is not only a function of a feature's incoming connections, but also a function of a feature's place in an overall dependency structure.
 This result confirms the need fw the iterative aspect of Equation (1).
 In the third model, the modified model, a nonlinearity was added to Equation (1) to optimize the fit to mutability judgments.
 In this model, the result of each iteration was normalized to fall in the range 0 to 1, then raised to a power in the range 0 to 1, chosen to maximize the resulting correlation.
 This model gives slightly better predictions of immutability than Equation (1), but its advantage is modest relative to its greater complexity.
 Table 1: Rank correlations of three models of dependency with mutability judgments for four categories, data b o m Studies 1 and 2.
 Category <::halr GuiUr Apple R^ln Sum of dependencies M .
45 .
58 .
75 Equation (1) .
̂ i .
.
il .
66 .
59 Opiimized Equation (1) .
̂ i .
75 .
60 .
74 All of the correlations for the basic model (Equation (1)) and optimized model in Table 1 are statistically greats than 0 using a significance level of 0.
05 except for three: those for the basic model of Guitar and both models of Apple.
 However, all the correlations are significant at the 0.
10 level.
 W e have also tried other variations on Equation (1), none of which consistently perform as well 656 Chair: Robin: Comlorlibl S5 Wood Arms Apple: Small I ttttthttrs Radbout Moves Two leg Mit womtfl 58 Lays egg 86 Chirps Hds n*«l Guitar: Flound Sweet ou eat it Grows on trees Figure 1: Category graphs.
 The arrows point from a feature to one that it depends ujwn.
 Mean mutability judgments are also shown for each categoryfeature.
 as that model.
 Therefore, because of its combination of simplicity and empirical adequacy, w e conclude that Equation (I) is the appropriate model of mutability and that w e succeeded in predicting mutability judgments using unlabeled dependency relations.
 Our method of measuring mutability spawned an unexpected factor limiting the performance of our model .
 Extremely immutable features, like "is living" for robin, arc so immutable that they tend to cause subjects to consider a different category.
 Subjects are unable to imagine a real robin that lays eggs, eats worms, and flies but is not living and therefore instead imagine a toy or decomposing robin.
 In the context of the new category, the feature is no longer judged immutable although its Wood dependency relations predict that it should be.
 Mutability judgments for such features had bimodal distributions, suggesting that some subjects experienced difficulty performing the transformation and that others did not perform the task w e asked of them.
 Despite our efforts to eliminate such judgments from analysis (see section 4.
1), w e were not always able to because subjects w o e not always aware of their error.
 Three features led to this problem: one each from the categories Robin, Guitar, and Apple.
 The rank correlations between mutability judgments and Equation (1) improve if w e eliminate these features from analysis to .
74, .
69, and .
66 for the categories Robin, Guitar, and Apple, respectively.
 Table 2 presents Spearman rank correlations between mutability and variability judgments across item means.
 As expected, features judged variable also tended to be judged mutable (p < .
05 in all four cases).
 Relatively high correlations should be expected for variability because, in those cases in which variability does vary 657 across features, it is closely related to mutability at a conceptual level.
 Indeed, their correlations may be high because judgments of mutability served as a surrogate for judgments of variability.
 They are also closely related at a task level.
 Variability judgments are made at the same ontological level as mutability judgments in that both consist of judgments about isolated categoryfeatures.
 In contrast, dqiendency judgments considered pairwise relations amongst all the features of a category.
 Table 2: Rank correlations of mutability (Study 1) and variability (Snidy 3) judgments for four categories.
 Chair "Cui uitar Apple Correlation •3r In conclusion, the results demonstrate that unlabeled dependency relations are effective in predicting mutability.
 N o aspect of the data suggests that the performance of the dependency model could be improved by considering labeled relations.
 The feature gn^hs of Figure 1 d) display further structure.
 For instance, in the Apple graph, two subnetworks of features can be discerned, one concerning the reproductive aspects of apples and the other containing the food related features of apples.
 HowevCT, this structure is discernible without attributions of causality or any other label to dqKndency links.
 Furthermore, although this structure is undoubtedly useful for certain cognitive tasks (such as, probably, analogical reasoning), w e have no reason to believe that it contributes to determining the transfOTmabiUty of a feature.
 Admittedly, our conclusion would be more compelling if w e had directly contrasted our model's results with those obtained with a labeled relations model.
 Unfortunately, the thewybased view remains too illspecified to provide such a model.
 5.
 The role of mutability in other c o n c e p t u a l tasks W e believe that mutability can serve as an explanatory device in a variety of cognitive tasks.
 5.
1 Categorization Mutability plays a role in determining the relative importance of features in judgments of category membership.
 A token that matches a category representation in all but a mutable dimension should be a better candidate for category membership than a token that differs in an immutable dimension (Medin & Shoben, 1988).
 For example, w e expect robins without red breasts to be categorized as robins with higher probability than robins that do not eat W e have unpublished results that support this view.
 W e asked subjects questions like, "Can something be a robin if it does not have a red breast?" The percentage of "yes" responses were highly correlated with mutability judgments in all four categories.
 5.
2 Determining surprise and regret in evaluating events and concepts Kahneman and Miller (1986) have documented the effects of mutability in the domain of events.
 In this domain, mutability refers to the "undoability" of a situation.
 Kahneman and Miller found that events with a negative outcome elicit more regret if they are seen as mutable.
 For instance, missing an airline flight by five minutes was judged more regrettable than missing it by half an hour, presumably because one could more easUy transform the situation in which the flight was missed by five minutes into a situation in which the flight was not missed.
 Mutability is also a useful indicator of surprise.
 Greater surprise should be elicited from subjects upon viewing an object varying in an immutable dimension than an object varying in a mutable dimension.
 For instance, encountering a robin that does not have wings would be more surprising than encountering a robin that does not chirp.
 5.
3 Explanation generation and evaluation Mutability may be a factor in the generation of explanations.
 A n appropriate explanation for what makes a good computer would not center upon highly immutable features like "is a three dimensional object" or "performs calculations", but would instead center upon features that are more mutable like "has a very fast clock speed" or "has a large cache".
 Explanations that focus on immutable features will be unsatisfactory.
 Because oxygen is an immutable feature of the atmosphere, an explanation that a building burned down because there was oxygen in the atmosphere seems inadequate (Kahneman and Miller, 1986).
 5.
4.
 Problem solving In reasoning tasks where a forward or backward infCTence must be made to determine how to move from one problem state to another, mutability may indicate the features of the problem space that are manipulable.
 For instance, if an autonomous agent must manipulate objects in its environment to achieve some goal state configuration of objects, a good strategy might be to first focus on solutions involving easily transformable objects (objects not affixed to the ground, light objects, objects without other objects on top of them, etc.
).
 658 5.
5 Metaphor Mutability may play a role in the construction and interpretation of met^hors.
 Sometimes, metaphorical statements map characteristics of the source onto the target Mutability could help determine what features of the target could be successfully m^jped onto.
 Mutable features could be mapped onto, while immutable features would resist reinterpretation.
 Consider this example.
 (C) The surgeon is a butcher.
 Our representation of surgeon contains the features "has medical training" and "cuts with great precision and care".
 Our representation of butcher contains neither of these features.
 Alignable features of butcher could be mapped onto the representation of surgeon.
 The feature "has medical training" is a fairly immutable feature of surgeon and resists conceptual transformation, while the feature "cut with great precision and care" is mutable and is mapped onto by butcher.
 The resulting representation of surgeon is one in which the surgeon has medical training, but is not highly skilled at operating.
 6.
 Conclusion More woik needs to be done in analyzing the determinants of mutability, the nature of dependency relations, their organization at all category levels, and their role in cognitive processes.
 Our hope is to contribute to the understanding of how the intaxlependencies between the elements that compose our concepts govern how our concepts cohere and transform.
 At present, that understanding remains mutable.
 Acknowledgement This work was supported by a grant from Brown University to Steven Sloman.
 References Carey, S.
 (1985).
 Conceptual Change in Childhood.
 Cambridge: M I T Press.
 Collins, A.
 & Michalski, R.
 (1989).
 The logic of plausible reasoning: a core theory.
 Cognitive Science, 13, 150.
 Holyoak, K.
 J.
 & Thagard, P.
 R.
 (1989).
 Analogical mapping by constraint satisfaction.
 Cognitive Science, 13, 295355.
 Kahneman, D.
 & Miller, D.
 T.
 (1986).
 Norm Theory: Comparing Reality to Its Alternatives.
 Psychological Review, 93, 136153.
 Keil, F.
 C.
 (1989).
 Semantic and conceptual development: An ontological perspective.
 Cambridge, M A : Harvard University Press.
 Medin, D.
 L.
 & Shoben, E.
 J.
 (1988).
 Context and structure in conceptual combination.
 Cognitive Psychology, 20, 158190.
 Murphy, G.
 L.
 & Medin, D.
 L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Rips.
 L.
 J.
 (1990).
 Reasoning.
 Annual Review d" Psychology.
 41.
 321353.
 Rosch.
 E.
.
 Mervis, C.
 B.
, Gray, W.
, Johnson, D.
, & BoyesBraem.
 P.
 (1976).
 Basic Objects in natural categories.
 Cognitive Psychology, 8, 382439.
 Sloman, S.
 A.
 (in press).
 The empirical case for two systems of reasoning.
 Psychological Bulletin.
 Tversky, A.
 (1977).
 Features of Similarity.
 Psychological Review.
 84, 327352.
 Wellman, H.
 M.
 (1990).
 The child's theory of mind.
 Cambridge: M I T Press.
 Wilkinson, J.
 H.
 (1965).
 The algebraic eigenvalue problem.
 Oxford: Clarendon Press.
 659 Semantic and Associative Priming in HighDimensional Semantic Space Kevin Lund Department of Psychology University of California, Riverside Riverside, C A 92521 kevin(ilocutus .
 u c r .
 e d u C u r t B u r g e s s Department of Psychology University of California, Riverside Riverside, C A 92521 c u r t @ c a s s a n d r a .
 u c r .
 e d u R u t h A n n Atchley Department of Psychology University of California, Riverside Riverside, C A 92521 r u t h a n n @ m o r i a r t y .
 u c r .
 e d u Abstract We present a model of semantic memory that utilizes a highdimensional semantic space constructed from a cooccurrence matrix.
 This matrix was formed by analyzing a 160 million word corpus.
 Word vectors were then obtained by extracting rows and columns of this matrix.
 These vectors were subjected to multidimensional scaling.
 Words were found to cluster semantically, suggesting that interword distance may be interpretable as a measure of semantic similarity.
 In attempting to replicate with our simulation the semantic and associative priming experiment by Shelton and Martin (1992), we found that semantic similarity plays a larger role in priming than what they would suggest.
 Vectors were formed for three different types of related words that may more orthogonally control for association and similarity, and interpair distances were computed for both related and unrelated primetarget pairs.
 A priming effect was found for pairs that were only semantically related, as well as for word pairs that were both semantically and associatively related.
 No priming was found for word pairs which were strictly associatively related (no semantic overlap).
 This finding was replicated in a singleword priming experiment using a lexical decision procedure with human subjects.
 The lack of associative priming is discussed in relation to prior experiments that have found robust associative priming.
 W e conclude that our priming results are driven by semantic overlap rather than by associativity, and that prior results finding associative priming are due, at least in part, to semantic overlap within the associated word pairs.
 I n t r o d u c t i o n In cognitive psychology the concept of the semantic network was introduced by Collins and Quillian (1969).
 In their model, semantic meaning or concepts were represented by nodes which corresponded to individual words.
 Links connected these nodes as a function of the type of relationship they shared, and each link varied in length reflecting the strength of the relationship.
 A n outcome of such a model is that processing one concept will facilitate the subsequent processing of a related concept.
 Meyer and Schvaneveldt (1971) provided an early demonstration of how recognizing semantically related words ( B R E A D  B U T T E R ) can speed the lexical decision latencies compared to seeing unrelated words ( F L O O R  B U T T E R ) .
 Semantic memory research utilizing the lexical decision (or naming) task in the last two decades has produced one of the largest bodies of cognitive psychological literature (see Neely, 1991).
 The presence of the semantic priming effect is one of the most robust effects in the literature, although the exact nature of the word relationships and the nature of the task and methodology can influence the magnitude and presence of priming (Fischler, 1977; Neely, 1991).
 In general, however, regardless of the theory, information processed at a semantic level facilitates related semantic information (semantic features: Smith, Shoben, & Rips, 1974; nodal networks: Collins & Quillian, 1969; prototype models: Rosch, 1973; associative relationships: Lupker, 1984; distributed connectionist representations: McClelland & Kawamoto, 1986; or mental models: JohnsonLaird, 1983).
 Attempting to derive models of semantic memory that would allow the computation of a distance between two concepts and that could be used to reflect semantic relatedness using psychometric techniques has a long history in cognitive psychology dating back at least to Osgood, et al.
 (1957).
 A c o m m o n approach has been to use multidimensional scaling on (many thousands of) human judgments of similarity (Smith, Shoben, & Rips, 1974; Schvaneveldt, 1990).
 More recently, investigators using large scale corpora have attempted to extract semantic information directly from text.
 Gallant (1991) has developed a methodology that extracts a distributed set of semantic microfeatures utilizing the context in which a word is found.
 However, a drawback to his approach is that the features for the core meaning have to be determined by a human judge.
 The model w e have developed accounts for a wide range of semantic effects in the cognitive and neuropsychological literature (Burgess & Lund, in press; Lund & Burgess, in press).
 In this paper w e focus on the facilitation effect, known as semantic priming, that is found when a word is preceded by a semantically related word.
 W e refer to our model as H A L , for Hyperspace Analogue to Language.
 W e use a large text corpus of 160 million words to initially track lexical cooccurrence within a 10 word moving window.
 From the cooccurrences, w e develop a cognitively plausible 200 dimensional semantic space by using the most informational dimensions.
 The development of our model was strongly influenced by the work of Schiitze (1992) who has developed a similar model for information retrieval.
 Our goal has been to incorporate cognitive constraints into a highdimensional semantic space model and to extend this 660 mailto:curt@cassandra.
ucr.
edumailto:ruthann@moriarty.
ucr.
eduapproach to determine if it would account for the semantic phenomena found in the cognitive science hterature.
 Four experiments are presented here.
 First we demonstrate the semantic nature of the word vectors that we extract using HAL.
 W e then use the model to generate word vectors for three types of related word stimuli from two previously published studies and show that the semantic relatedness effect is present for the two categories of words that share semantic features and is absent for the words that are associatively, but not semantically, related.
 In the final experiment, with human subjects, we replicate the effect we found with the model.
 Simulation Methods Matrix construction The basic methodology of the simulation is to develop a matrix of word cooccurrence values for a given vocabulary.
 This matrix will then be divided into cooccurrence vectors for each word, which can be analyzed for semantic content.
 An analysis of cooccurrence must define a window size; that is, the largest number of words that may occur between a pair of words such that the pair may be considered to cooccur.
 The limiting case of a small (useful) window is a width of one, which would correspond to counting only immediately adjacent words as cooccurrants.
 At the other end of the spectrum, one may count all words within a logical division of the input text as cooccurring equally (see Landauer, 1994; Schvaneveldt, 1990).
 A very small window may miss constructs spanning several words (lengthy noun phrases, for instance), while large windows risk introducing large numbers of extraneous cooccurrences.
 Therefore, we chose a window width of ten words.
 Our hopes are that this preserves locality of reference, while obscuring the effects of different syntactic constructions.
 This syntax independence may be important when comparing results from different languages.
 As a further move away from dependence on syntax (or any structuring of the language under consideration other than that given by the division of words), sentence boundaries are ignored.
 Within this tenword window, cooccurrence values are inversely proportional to the number of words separating a specific pair.
 A word pair separated by a nineword gap, for instance, would gain a cooccurrence strength of one, while the same pair appearing adjacent to one another would receive an increment of ten.
 Cognitive plausibility was a constraint, and a tenword window with decreasing cooccurrence strength seemed within these bounds (Gemsbacher, 1990).
 The product of this procedure is an NbyN matrix, where N is the number of words in the vocabulary being considered.
 It is this matrix which we will demonstrate to contain significant amounts of semantic information.
 Text source.
 The corpus that was analyzed was approximately 160,000,000 words of English text gathered from Usenet.
 All newsgroups containing English dialog were included.
 This source has a number of properties which we found appealing.
 First, it is voluminous.
 It was clear that in order to obtain reliable data across a large vocabulary, a large amount of text would be required.
 Usenet was attractive in that it could supply several million words of text per day, indefinitely.
 Second, Usenet is diverse.
 Virtually no subject goes undiscussed, which allows the construction of a very broadly based cooccurrence data set.
 This turns out to be useful when attempting to apply the data to various stimulus sets.
 There is little chance of running across words or word senses which were not encountered during matrix construction.
 Third, the text is conversational.
 Rather than the formal business reports or specialized dictionaries found in other corpora, Usenet text resembles everyday speech more closely than most corpora.
 That the model works with noisy, conversational input suggests that it can robustly deal with some of the same problems that the humanlanguage comprehender encounters.
 Vocabulary.
 The vocabulary used for the analysis consisted of the 70,000 most frequently occurring symbols within the corpus.
 A check against the standard Unix dictionary showed that only one half of these were valid English words.
 The abundance of nonword symbols is not a practical problem, though, since the datareduction step involves extracting information and frequent nonword symbols (including slang words and misspellings) presumably carry useful information.
 Data reduction.
 The cooccurrence tabulation produces a 70,000 by 70,000 matrix.
 Each row of this vector represents the degree to which each word in the vocabulary preceded the word corresponding to the row, while each column represents the cooccurrence values for words following the word corresponding to the column.
 A full cooccurrence vector for a word consists of both the row and the column for that word.
 The following experiments operate on groups of these cooccurrence vectors.
 To reduce the amount of data involved, the column variances of the particular vectors used in each experiment are computed, and the columns with he smallest variances are discarded.
 W e find that variance drops sharply across the first hundred elements, and is very low by the two hundredth element; accordingly, the 139,800 columns with the lowest variance are discarded.
 This leaves a 200element vector for each word.
 Empirically, these shortened vectors provide similar results to the fulllength vectors, while being much easier to work with.
 These vectors (whether length 140,000 or 200) can be viewed as the coordinates of points in a highdimensional space, with each word occupying one point.
 Using this representation, differences between two words' cooccurrence vectors can be measured as the distance between the highdimensional points defined by their vectors.
 E x p e r i m e n t 1 Methods A number of words, informally chosen to represent three categories (animal types, body parts, and geographical locations) were used in an initial analysis of semantic content for the cooccurrence vectors.
 A vector of length 200 was extracted for each word, and, treating each vector as a set 661 of coordinates in a 200dimensional Euclidean space, a distance matrix was formed.
 Our hypothesis was that this distance matrix, representing the interpoint distances for the chosen set of words, would operate as a similarity matrix.
 Each element in the matrix represented the distance between two of the chosen words in the highdimensional space.
 This matrix was analyzed by a multidimensional scaling algorithm ( M D S ) , which projects points from a highdimensional space into a lowerdimensional space, in a nonlinear fashion that attempts to preserve the distances between points as much as possible.
 The lowerdimensional projection allows us to visualize the spatial relationships between the cooccurrence vectors.
 The twodimensional M D S solution is shown in Figure 1.
 'ankle / •leg / ' shoulder X ' toe • finger X "wrist X • nose X • puppy ^ »ear* gyg X \ ^ ^ hand.
f^„,„ • • kitten \ .
 foe? *'/ .
 ''°°''' ^^ X • cow / ^ V • lion X asia ^^ X china france «, VV.
 / • 'pe=.
 .
 , .
 r " \ ^ • eunerica ^̂ ^ Hawaii ^ • • oyster * mouse • turtle \ Figure 1: Exploratory multidimensional scaling Results & Discussion Visual inspection suggests that the three groups of words were differentiated by this procedure.
 Geographic regions are distinct from the other two groups, while animals and body parts overlap at "tooth" (a salient body part for animals).
 Given that words with similar meanings tended to be close to each other in the simulation data, we conclude that the most informational vector elements from the cooccurrence matrix carry semantic information.
 However, recent research suggests that socalled semantic priming may, in fact, be carried by associative relationships rather than semantic similarity (Shelton & Martin, 1992).
 In Experiment two our goal was to simulate a pattern of semantic and associative priming results found in the literature using the semantic vectors extracted with H A L and to determine the correspondence of the vector information to semantic and associative characteristics of words.
 Experiment 2 Subject responses to words that are preceded by words related to them are facilitated, presumably by the prime having lowered the recognition threshold for the related target.
 Shelton and Martin (1992) found that automatic priming using a lexical decision task does not occur for items that are only semantically related, yet does occur when items are both associatively and semantically related.
 This pattern of results held for only the single presentation procedure in which a subject makes a lexical decision to each word as they are presented one after another, rather than the standard singleword priming procedure where there is a discrete trial usually consisting of a fixation point, a prime word, followed by a target.
 Shelton and Martin attribute semantic priming to controlled processes, such as subject expectancy.
 Thus, they conclude, automatic priming will obtain only for items which are associatively related and not for items that are only semantically related.
 The results from Experiment 1 suggest that the distances between words are semantic in nature and that the distances might roughly correspond to reaction time latencies from experiments like Shelton and Martin's.
 In this experiment we attempt to replicate Shelton and Martin's Experiment 4, using their stimuli, in which they find priming for the associated items, but not for the semantically related items.
 W e reason that since we are calculating priming effects using HAL's vector representations that we have eliminated the possibility of attentional processing and strategic effects that Shelton and Martin suggest are necessary for true semantic priming.
 Methods The relatedness or priming effect for an item was calculated by subtracting the distance of the related pair from an unrelated word pair (using the same target).
 Semantic vectors of length 200 were formed, and for each word pair the Euclidean distance between the words was computed.
 Results are shown in Table 1.
 Distances are given in Riverside Semantic Units (RSUs), which are are completely arbitrary and based upon normalized vectors.
 Table 1 Semantic Associated Semantic Distances for Shelton & Martin Related Unrelated Priming 366 429 63 310 407 97 Results & Discussion Table 1 presents the semantic distances and priming effects.
 In the analysis of variance, there was a main effect for relatedness, demonstrating that the semantic distances for all related pairs was shorter than that for the unrelated pairs, F(l,70) = 15.
43, p =.
0001.
 There was not an interaction, F<\.
 These results are not completely consistent with those found by Shelton and Martin who did not find a priming effect for the semantically related items.
 W e suggest several possibilities for this inconsistency.
 First, a methodological reason.
 The single presentation procedure in all their experiments resulted in overall faster reaction times than the singleword priming procedures.
 A number of investigators have demonstrated that semantic effects tend to be minimized or disappear with either faster responses or faster subjects (Hines, et al.
, 1986; Chiarello, et al.
, 1990).
 662 A more theoretical concern has to due with the stimuli.
 Both the semantically and the associatively related items used by Shelton and Martin share semantic characteristics, but more importantly, according to Shelton and Martin, is that the word pairs in the semantic condition are not associated.
 A closer look at their stimuli (see Table 2 for examples and semantic distances) suggests that the two conditions may not be semantic related to the same degree.
 W e suggest that the semantic condition had a number of weak examples of related items (e.
g.
, P E A S  G R A P E S , M A I D  W I F E ) , whereas, the associated condition had a number of items which were strongly semantically related (e.
g.
, R O A D STREET, G I R L  B O Y ) .
 The means of semantic distances from Table 1, further suggest this is the case (semantic related, 366; associated related, 310) with the associated condition being marginally more semantically similar, F(l,70) = 3.
63; p =.
061.
 Experiment 3 is an attempt to more orthogonally manipulate the stimulus constraints of semantic relatedness and associativity.
 Table 2: Stimuli from Shelton & Martin Experiment Semantic Word pair Good nose Pairs car Weak maid Pairs peas hand wagon wife papes Associated Dist.
 Word pair Dist.
 340 coffee cup 575 348 light lamp 542 580 road street 170 541 girl boy 215 E x p e r i m e n t 3 Chiarello, Burgess, Richards, and Pollack (1990) used three types of word pairs to try and differentiate the contribution of semantic similarity and association in priming.
 Examples of the three types of words (semantically similar words, associated words, and words which are both semantically similar and associatively related) can be seen in Table 3.
 Semantically related words (TABLEBED) are instances of the same category and share a number of features.
 Associated words ( M O L D  B R E A D ) are those which are associated as determined by human wordassociation norms and tend to cooccur in sentential phrases.
 These items, however, are not instances of the same category and therefore share few semantic features.
 The third type of word relation are pairs that are both semantically and associatively related ( U N C L E  A U N T ) .
 These word relations should allow us to distinguish between the associative and semantic components of our "semantic" vectors.
 Semantically similar pairs were of the same superordinate semantic category and, thus, are likely to occur in similar contexts.
 Word cooccurrence or simple association reflects the temporal nature of language, whereas semantics pertains more to the internal features of words.
 Spence and Owens (1990) found that the production likelihood in wordassociation norms correlated with word cooccurrence.
 Thus, if the vectors generated by H A L are semantic in nature, we should see shorter distances between the word pairs of both semantic conditions than between word pairs in the associated condition.
 Alternatively, the nature of the semantic relationships could more directly correspond to the cooccurrence association.
 In such a case, we would expect a similar magnitude of primetarget distance in all three relatedness conditions.
 Table 3: Example word pairs (Experiments 3 and 4) Semantic Associated Both table music flea circle pan bed art ant cross bowl cradle mug mold waist nest baby beer bread belt bird ale uncle ball sofa butter beer aunt bat chair bread Methods This experiment used the word pairs from Chiarello et al.
 (1990), which are divided into the three relatedness groups.
 The relatedness or priming effect for an item was calculated by subtracting the distance of the related pair from an unrelated word pair (using the same target).
 Results and Discussion The left side of Table 4 presents the semantic distances, priming effects, and standardized priming effects.
 In the analysis of variance, there were two factors; type of relation (semantic, associated, semantic and associated) and relatedness (related, unrelated).
 There was a main effect for relatedness, demonstrating that the semantic distances for related pairs was shorter than that for the unrelated pairs, Fl ,270) = 11.
62, p = .
0008.
 There was also a main effect for type, F(2,270) = 4.
24, p = .
015.
 There was not an interaction, F(2,270) = 1.
25,p = .
28.
 Planned comparisons were made at each level of word relation in order to determine priming by stimulus type.
 Visual inspection of Table 4 suggests that the priming effect for the associated trials was much less than the effect for both of the semantically related conditions.
 The analysis of variance is consistent with this observation.
 Priming is found for the semantic condition, /^(1,88) = 6.
48, p = .
012, and the semantic and associated condition, F(l,92) = 5.
79,p = .
018, but not for the associated only condition, F < I.
 Standardized scores are computed by dividing by the semanticonly score.
 This pattern of results is consistent with the hypothesis that the vectors associated with each word do carry semantic information, but do not as strongly carry the associative information that would reflect the temporal characteristics inherent in words that cooccur.
 Our claim, to be discussed in more detail later, is that the word vectors are semantic in nature, even though their origin is from a cooccurrence matrix that tracked temporal sequence.
 It would be important to see if this pattern of results can Table 4: simulation distances (in RSUs and ms) H A L simulation Human subjects Sem.
 Assoc.
 Both Sem.
 Assoc.
 Both R U UR Std.
 347 413 66 1.
0 322 339 17 0.
26 331 391 60 0.
91 643 673 30 1.
0 623 634 11 0.
36 603 631 28 0.
93 663 be replicated with human subjects.
 Chiarello et al.
 (1990), whose stimuli w e utilized, used a divided visualfield methodology since they were primarily interested in priming in the cerebral hemispheres.
 In Experiment 4, w e use these stimuli in a singleword priming study with human subjects, centrally presenting all stimuli.
 Experiment 4 Methods Sixtyfour undergraduate students participated in order to earn course credit.
 The stimuli used in this experiment included the items used in Experiment 3, as well as, an equal number of wordnonword trials, since a lexical decision task was employed.
 The target words were balanced for both word length and printed frequency for a total of 288 word pairs.
 A n experimental list included these trials and was preceded by four "warm up" trials.
 Word primes were counterbalanced so that a target would be preceded by a related word in one list and an unrelated word in a second list.
 This allowed the targets to act as their own controls.
 Of the related wordword trials, one third were word pairs that were only semantically related, one third were only associatively related, and a third were semantically and associatively related.
 Stimulus presentation and timing was conducted on 486 PCs.
 Each trial began with a 500 m s fixation cross, followed by a prime at this location for 300 ms immediately followed by the target which remained until either the subject made a lexical decision or 2500 m s elapsed.
 Accuracy feedback was provided, along with a timeout signal for responses over 2500 ms.
 Results and Discussion The reactiontime latencies, priming effects, and standardized priming effects are presented in the right half of Table 4.
 Error rates were under 3 % and showed no interesting variation.
 This analysis parallels the analysis presented in Experiment 3.
 Reaction times were faster to related trials than to unrelated trials, F(l ,270) = 14.
70, p = .
0002.
 There was also a main effect for type, F(2,270)= 16.
14, p.
000\.
 There was not an interaction, F < \.
 Planned comparisons were made at each level of word relation in order to determine priming by stimulus type.
 Inspection of Table 4 suggests that the pattern of reactiontime priming is similar to that found in Experiment 3, i.
e.
, the priming for the associated trials was less than that for both the trials in the semantically related conditions.
 Priming obtains for the semantic condition, F(l,88) = 5.
82, p = .
017, and the semantic and associated condition, F(l,92)= 12.
38, p=.
0007.
 but not for the associated only condition, F(l,90)= 1.
14,p = .
28.
 The results of Experiment 4 are virtually identical to those of Experiment 3.
 The similar pattern of results suggests that the semantic vectors that are extracted from the corpus are cognitively plausible, and that they incorporate higherlevel semantic information that may, in part, correspond to semantic category and semantic feature similarity.
 G e n e r a l Discussion Several important conclusions can be drawn from this series of experiments.
 The basic relatedness or priming effect so often demonstrated in the memory literature can be reproduced using the semantic vectors from the H A L simulation.
 This priming effect, however, was not a general effect that was seen with just any set of related word pairs.
 A crucial aspect to the relatedness effect was that it seems to hinge more on the semantic relationships between words than on the associative relationships.
 There was no reliable effect of associativity.
 The nature of our associative items in Experiments 3 and 4 was that the targets were strong associates of the primes.
 Intuitively, there is a strong contiguous aspect to these stimuli.
 For example, M O L D  B R E A D and C R A D L E  B A B Y are word pairs that seem likely to occur together in a phrase or sentence.
 Historically in the literature on associativity, temporal order or contiguity has been conceded to be the most important principle in learning (Deese, 1965).
 W e concede that firstorder association is important in learning, however, our view is that these firstorder temporal associations are not an important part of structural semantics.
 W e want to make clear, though, that w e consider secondorder association, that is, the patterns of intercorrelations amongst word use, to be a principal building block of semantic structure.
 It is something akin to these intercorrelations that w e propose that w e extract with the 200 most variant, or informational, elements in our semantic vectors for each word.
 W e have demonstrated that in order to show a priming effect in the simulation, semantic similarity is required.
 An examination of the word pairs suggests at least a partial explanation for this.
 Semantically similar word pairs are interchangeable within a sentence; the resulting sentences may be pragmatically improbable, but they are not nonsensical (sentences la and lb).
 Associatedonly pairs tend to produce awkward sentences when interchanged, sentences that often cannot be taken literally (sentences 2a and 2b).
 The semantic vectors take us beyond simple cooccurrence in that they are really measures of context.
 Being interchangeable, the semantically similar words tend to appear in similar contexts, and so have similar vector representations.
 la) The child slept on the bed.
 lb) The child slept on the table.
 2a) The child slept in the cradle.
 2b) The child slept in the baby.
 Being "associated," without semantic similarity, was not sufficient in a word pair to produce priming in the simulation.
 The same pattern of results obtained with the human subjects.
 Obtaining reliable associated priming is sometimes difficult (see Chiarello, et al.
, 1990; Shelton & Martin, 1992, Exp.
 3).
 The vectorbased semantic distances, being ultimately derived from human linguistic output, can be construed as humanbased estimates of word similarity.
 Fischler (1977) found a correlation of 0.
31 between human estimates of semantic similarity and facilitation in a priming experiment.
 664 This finding closely parallels our correlation of 0.
24 between semantic distances and reaction time.
 Thus, we can conclude that HAL's semantic distances are reliable predictors of lexicaldecision latencies.
 Fischler further found a correlation of essentially zero (0.
01) between his assessment of associative relation and facilitation, which matches our finding of little to no priming in the associatedonly case (with both simulation and humans).
 There is something of a paradox when comparing the present results with a number of findings in the literature.
 For example, although Fischler (1977) found no correlation between the magnitude of priming and an index of associativity with his associated stimuli, he did, unlike us, find a priming effect with the trials.
 W e suspect that the priming effect was a function of the semantic relationships of his word pairs.
 When we extracted semantic vectors for his associated stimuli we found that the three pairs of words with the closest semantic vector representations carried 1/3 of the priming effect.
 These items such as ROADSTREET, are similar to our semantic and associated items.
 Similarly, Shelton and Martin (1992) found that associated items resulted in priming, whereas semantically similar, but nonassociated, items did not.
 Again, though, as they note, their "associated" items possess considerable semantic similarity (e.
g.
, GIRLBOY, QUEENKING; see Table 2), not unlike the situation in Fischler's experiment.
 W e would expect a robust priming effect with stimuli like these, but not as a result of the associative component.
 Shelton and Martin's semantically related items (e.
g.
, DIRTCEMENT, SOUPJUICE), we suspect, are simply not similar enough to produce priming in a bottomup fashion.
 A major goal of this line of research was to develop a model of semantic memory from the analysis of a large language corpus.
 A fundamental methodology for investigating semantic organization is the priming experiment.
 One of the first obligations of any such model must be to account for the range of priming effects found in the literature.
 H A L has succeeded in producing a set of results that make a clear distinction between two types of information inherent in word relationships.
 W e conclude that semantic information underlies the word priming effect and that firstorder associative information is not as crucial as previously thought.
 Further, the results suggest a theoretical explanation for the difficulty in finding associatedonly priming.
 If a major organizing principle of semantic memory is the analysis of immediate word context, words will be organized by semantic similarity rather than associativity, as in our simulations.
 So far, our evidence shows this to be the case.
 A final conclusion is that we have presented a methodology that exploits the regularities of language in a large text corpus such that the extraction of semantic information is possible.
 The methodology employed in H A L does not require supervised learning or other system feedback and works on very noisy, speechlike, input.
 A limitation to previous models of semantic processing is that either the semantic representations required extremely timeconsuming human judgments about the items or the semantic representations were simply conjectural.
 H A L is a model that provides the generation of semantic representations of real words used in real language.
 Acknowledgments This research was supported by a NSF Presidential Faculty Fellow award SBR9453406 and a U.
C.
 Academic Senate Research Grant to Curt Burgess.
 W e thank Chad Audet and Dr.
 Catherine Decker for their assistance.
 References Burgess, C , & Lund, K.
 (in press).
 Modeling the cerebral asymmetries of semantic memory in highdimensional space: HAL's brain (abstract).
 Brain and Cognition.
 Chiarello, C , Burgess, C , Richards, L.
, & Pollock, A.
 (1990).
 Semantic and associative priming in the cerebral hemispheres: Some words do, some words don't .
 .
 .
sometimes, some places.
 Brain & Language, 38,75104.
 Collins, A.
M.
, & Quillian, M.
R.
 (1969).
 Retrieval time from semantic memory.
 Journal of Verbal Learning and Verbal Behavior, 8, 240247.
 Deese, J.
 (1965).
 The structure of associations in language and thought.
 Baltimore: John Hopkins Press.
 Fischler, I.
 (1977).
 Semantic facilitation without association in a lexical decision task.
 Memory & Cognition, 5, 335339.
 Gernsbacher, M.
A.
 (1990).
 Language comprehension as structure building.
 Hillsdale, NJ: LEA.
 Hines, D.
, Czerwinski, M.
, Sawyer, P.
K.
, & Dwyer, M .
 (1986).
 Automatic semantic priming: Effect of category exemplar level and word association level.
 Journal of Experimental Psychology: Human Perception and Performance, 12,370379.
 Landauer, T.
K.
, & Dumais, S.
 (1994).
 Memory model reads encyclopedia, passes vocabulary test.
 Paper presented at the Psychonomics Society.
 Lund, K.
, & Burgess, C.
 (in press).
 Hyperspace Analogue to Language (HAL): A general model of semantic representation (abstract).
 Brain arul Cognition.
 Meyer, D.
E.
, & Schvaneveldt, R.
W.
 (1971).
 Facilitation in recognizing pairs of words: Evidence of a dependence between retrieval operations.
 Journal of Experimental Psychology,9^,221235.
 Neely, J.
H.
 (1991).
 Semantic priming effects in visual word recognition: A selective review of current findings and theories.
 In D.
 Besner and G.
W.
 Humphrey (Eds.
), Basic processes in reading: Visual word recognition (pp.
 264336).
 Hillsdale, NJ: LEA.
 Osgood, C.
E.
, Suci, G.
J.
, & Tannenbaum, P.
H.
 (1957).
 The measurement of meaning.
 Urbana: University of Illinois Press.
 Schiitze, Hinrich (1992).
 Dimensions of Meaning.
 Proceedings of Supercomputing.
 Schvaneveldt, R.
W.
 (1990).
 Pathfinder associative networks: Studies in knowledge organization.
 Norwood, NJ: Ablex.
 Shelton, J.
R.
, & Martin, R.
C.
 (1992).
 H o w semantic is automatic semantic priming? Journal of Experimental Psychology: Learning, Memory, and Cognition, 18, 11911210.
 Smith, E.
E.
, Shoben, E.
J.
, & Rips, L.
J.
 (1974).
 Structure and process in semantic memory: A featural model for semantic decisions.
 Psychological Review, 81, 214241.
 Spence, D.
P.
, & Owens, K.
C.
 (1990).
 Lexical cooccurrence and association strength.
 Journal of Psycholinguistic Re search, \9,3\l?>'iQ.
 665 S t e p s T o w a r d R e a l  t i m e N a t u r a l L a n g u a g e Processing Steven L.
 Lytinen and Noriko Tomuro DePaul University Department of Comuter Science and Information Systems Chicago IL 60604 lytinen@cs.
depaul.
edu Abstract Understanding language is a seemingly effortless task for people.
 Not only can they understand the meaning of sentences with great accuracy, they do so quickly: in most cases, people understand language in linear time.
 In constrast, understanding language is not so easy for computers.
 Even ignoring problems of accuracy, natural language processing systems ane much slower than people aje.
 All current NLP systems that fully analyze both the syntactic structure and semantic meaning of text fall short of human performance in this respect.
 In this paper, we present an attempt to develop a linear time algorithm for parsing natural language using unification grammcirs.
 While the computational complexity of the algorithm is, in the worst case, no better than that of many other algorithms, empirical testing indicates improved averagecase performance.
 Although linear performance has not yet been achieved, we will discuss possible improvements that may result in an averagecase linear time algorithm.
 Introduction Unification grammar has become a popular formalism to use in natural language processing (NLP) systems.
 Unfortunately, the formal power of unification grammar makes it difficult to implement an efficient unificationbased parser.
 A common approach is to build a unificationbased parser on top of a contextfree chart parser.
 The result is an algorithm that is at least O(n^) in the v̂ orst case (since this is the worstcase complexity of contextfree chart parsing), and perhaps worse, due to the additional work of performing unifications.
 Adding to the difficulties is the inclusion of semantic information in many unificationbased systems, such as in H P S G (Pollard and Sag, 1988) and in our own previous work (Lytinen, 1992).
 This can greatly increase the size and complexity of a grammar, which also has an adverse effect on performance of a parsing algorithm.
 Thus, unificationbased parsers for complex grammars capable of processing any significant subset of English or other natural languages, even for a limiteddomain application, yield quite poor performance.
 Indeed, empirial examinations of unificationbase parsers indicate that average case performance of these systems also falls short of linear (Shann, 1991).
 Other popular parsing algorithms, such as Tomita's algorithm (Tomita, 1986), also fail to achieve linear performance, even without the inclusion of semantic interpretation.
 How efficient should we expect N L P systems to be? One way to answer this question is to observe human performance in understanding language.
 Although there are exceptional constructions (e.
g.
, gardenpath sentences) that can cause problems in comprehension, it seems that in general people process text in linear time.
 Thus, if we expect an N L P system to match human performance, a reasonable goal is to achieve linear performance in the average case, with perhaps significantly worse worstcase performance.
 This paper describes an attempt to implement an averagecase linear time unificationbased parser.
 The algorithm that has been implemented is a mixture of topdown and bottomup chart parsing.
 In the topdown component, semantic information encoded in the grammar is utilized as much £is possible in the production of active edges (i.
e.
, expectations for what is to come next in a sentence).
 The general philosophy is to use this information to produce as specific expectations as possible, thus limiting the possible alternative parses that need to be pursued.
 While the worstcase performance of this algorithm is no better than other unificationbased parsers based on contextfree chart parsing, the hypothesis is that the utilization of both syntactic and semantic constraints in topdown expectations will significantly improve average case performance.
 The parsing algorithm has been implemented as part of the LINK system (Lytinen, 1992).
 Specifically, the topdown version of LINK (TDLINK) has been implemented as an alternative version of the system which we used in the Fifth Message Understanding Competition (MUC5) (Lytinen et al.
, 1993), so that its performance could be tested on a preexisting corpus and grammar.
 M U C  5 systems processed newspaper articles describing new developments in the field of microelectronics.
 Our original M U C  5 system used a bottomup chart parser, very similar to PATRII (Shieber, 1986).
 T D L I N K was tested on a random sample of sentences from the M U C  5 corpus.
 The test results are reported and analyzed in this paper.
 While T D L I N K does not appear to achieve average case linear processing time on the sample sentences, the number of edges entered into the chart for a sentence does appear to increase linearly with sentence length, on average.
 This is an encouraging result, since in contextfree chart parsing, processing time is linearly proportional to the number of edges.
 Possible reasons for why edges and processing 666 mailto:lytinen@cs.
depaul.
edutime do not seem to be linearly proportional in T D L I N K , and proposals for achieving linear processing time based on T D L I N K , are discussed in section 5.
 link's Unification Grammar link's knowledge base can be thought of as consisting of three modules: a grammar, a lexicon, and a set of domain knowledge.
 All of these types of knowledge are encoded in unification constraint rules.
 These rules are very similar in form to other unification grammars, such as PATRII.
 Figure 1 shows a small piece of a simple knowledge base.
 Consider the S rule (eqs.
 15) in the example grammar.
 Each equation in this rule specifies a property that any node labeled S (a complete sentence) must have.
 A property consists of a path, or a sequence of arcs with the appropriate labels starting from the node in question; and a value, which is another node to be found at the end of the path.
 Equations specify the values of properties in one of two ways.
 They may specify the label of the node to be found at the end of the path, as in equations 1 and 2 (i.
e.
, the arc from an S node labeled 1 leads to a node labeled NP).
 Or, they may specify that two paths must lead to the identical node, as in equations 35.
 Identity here is defined by the unification operation; i.
e, if two paths must lead to the identical node, then the nodes at the end of the two paths must unify.
 Unification merges the properties of two nodes; thus, two paths can unify if their values have no properties that explicitly contradict each other.
 Functionally, the S rule encodes information about English sentences as follows.
 Equations 1 and 2 specify that a sentence is made up of two subconstituents: a N P and a VP.
 Ordering of these constituents is implicit in the numbering of the paths.
 Equation 3 assigns the H E A D of the sentence to be the VP, by unifying the VP's H E A D path with the H E A D path of the S.
 This will be discussed further shortly.
 Equation 4 specifies that the N P and the V P must agree in number and person.
 These syntactic properties are found under the A G R (agreement) feature of each constituent.
 Finally, equation 5 assigns the N P to be the subject of the sentence.
 The H E A D property referred to in equations 35 is used to propagate information up and down the D A G .
 This is accomplished by unification of H E A D links, as in equation 3.
 Because of this equation, any information on the H E A D of the V P is accessible from the S node.
 Other rules assign the heads of other constituents, such as a verb group (VG) to be the H E A D of the V P (in the two V P rules; eqs.
 7 and 11), and a verb (V) to be the H E A D of a V G (eqs.
 15 and 18).
 Lexical items typically provide the values that are propagated by H E A D links.
 They are encoded in the same form as grammar rules.
 Typical values provided by lexical rules include syntactic feature information, such as the A G R feature; as well as semantic information, which causes a semantic interpretation of the sentence to be constructed as parsing proceeds.
 For example, in the entry for "eats", eq.
 20 specifies that "eats" is a transtive verb, and eqs.
 2122 specify the word's syntactic agree(defineclass S (1) = N P (2) = V P (head) = (2 head) (head agr) = (1 head agr) (head subj) = (1 head)) (defineclass V P (1) = V G (head) = (1 head) (head type) = intrans) (defineclass V P (1) = V G (2) = NP (head) = (1 head) (head type) = trans (head dobj) = (2 head)) (defineclass V G (1) = V (head) = (1 head)) (defineclass V G (1) = AUXES (2) = V (head) = (2 head)) (defineclass V (1) = eats (head type) = trans (head agr number) = sing (head agr person) = 3rd (head rep) = EATFOOD (head subj rep) = (head rep actor) (head dobj rep) = (head rep object)) (defineclass EATFOOD (actor) = ANIMATE (object) = F O O D (instrument) = UTENSIL) <1> <2> <3> <4> <5> <6> <7> <8> <9> <10> <11> <12> <13> <14> <15> <16> <17> <18> <19> <20> <21> <22> <23> <24> <25> <26> <27> <28> Figure 1: A set of example LINK rules 667 meat features, found under the A G R property.
 Eq.
 23 provides semantic information about the word, specifying that "eats" means EATFOOD.
 Eqs.
 2425 specify mappings from syntactic to semantic dependencies.
 24 states that whatever constituent fills the SUBJECT role will also be assigned as the A C T O R of the EATFOOD.
 Similarly, 25 specifies that the syntactic direct object (DOBJ) is assigned as the semantic OBJECT.
 The mapping equations are used in conjunction with the system's domain knowledge, to impose restrictions on the semantic properties (i.
e.
, the values of the REP path) of the subject and direct object of "eats" (i.
e.
, the A C T O R and OBJECT of the EATFOOD).
 Domain knowledge is also encoded in constraint rules, as exemplified by the EATFOOD rule (eqs.
 2628).
 Because of the mapping provided by "eats" between its subject and the A C T O R of the EATFOOD, the restriction that this constituent's representation must be ANIMAT E is propagated up to the NP that fills the SUBJ role specified by equation 26.
 Similarly, the F O O D restriction on the object of an EATFOOD would propagate to the NP assigned as the direct object (DOBJ) of "eats.
" The Parsing Algorithm TDLINK is a bottomup, breadthfirst, lefttoright chart parser which uses topdown expectations (active edges) to eliminate the construction of edges which could not possibly fit into the overall parse of a sentence.
 TDLINK also filters edges based on a singleword lookahead.
 Labels of edges in TDLINK are more complex than is the case in contextfree chart parsers: the labels of both active and complete edges are directed acyclic graphs (DAGs), which encode the syntactic category of a constituent (the normal label of an edge in a contextfree chart parser) as well as other syntactic and semantic features of the constituent.
 These features are specified in the definitions of lexical items, as well as in some of the grammar rules, as we saw in section 2.
 Active edges are used in conjunction with a reachability table in order to find potential connections between an expected D A G and the next word in the sentence.
 This is done as follows: first, the word is looked up in the dictionary.
 The result is a list of one or more DAGs, each of which corresponds to a sense of the word.
 Next, the syntactic label of each word sense D A G is used, along with the syntactic labels of each expected DAG, to look up possible connections in the reachability table.
 The table lookup results in a list of grammar rules which, if applied, would connect the word to the expectation.
 Let us illustrate with a simple example sentence, "Pat eats the sandwich.
" After processing "Pat", TDLINK has built an active edge labelled S, with an expectation to find a V P beginning at the word "eats" (since the S rule states that a V P should follow the NP).
 The reachability table provides the information that "eats" can be connected to the expectation in two ways: by applying the first V G rule (eqs.
 1415), followed by either V P rule (eqs.
 68 or 913).
 In other words, the table provides the information that "eats" must start a verb phrase, and that the VP may be transitive (with a direct object) or intransitive (without an object).
 After comparing all active expectations with the next word in the sentence, TDLINK applies the sequences of rules provided by the reachability table in a bottomup fashion.
 After each possible sequence is finished, the resulting D A G is unified with the expectation, to make sure that all of their features are compatible.
 If so, the new edges are added to the chart; if not, they are discarded.
 In our example, since the T R A N S feature of "eats" turns out to be incompatible with the INTRANS feature in eq.
 8, one of the rule sequences applied is discarded, leaving only an active VP edge, with the expectation that an NP (the direct object of the verb) will follow.
̂  In addition, the NP expectation also contains the information that this NP should refer to a type of FOOD.
 While it is a syntactic feature in this example which disambiguates the parse and causes edges to be discarded, in general either syntactic or semantic features (or a combination) can resolve an ambiguity.
 For example, semantic information would eliminate the active/passive ambiguity in "The log cut by Pat was big" at the word "cut", assuming that semantics required a log to be the OBJECT, rather than the ACTOR, of the action CUT.
 The early resolution of ambiguity has the potential to dramatically improve averagecase parsing performance.
 Empirical Results TDLINK was incorporated into our existing MUC5 system (Lytinen et a/.
, 1993), replacing the existing bottomup chart parser that had been used in MUC5.
 The system was then run on 100 randomly chosen sentences from the MUC5 corpus.
̂  27 of these sentences were sucessfuUy parsed by TDLINK using our MUC5 grammar.
 These 27 sentences form the basis of the performance analysis.
 First, TDLINK's performance was compared against the performance of the purely bottomup version of LINK.
 TDLINK achieved a factor of 4 speedup (measured in CPU time), on average, compared with LINK's performance on the 27 sentences.
 Performance improvement also increased with sentence length.
 Next, TDLINK's performance was analyzed on absolute terms.
 Figure 2 shows a plot of sentence length vs.
 the number of edges entered in the chart for the 27 sentences.
 A weighted R^ analysis indicates that the bestfitting polynomial for this data is a straight line (R^ = .
86).
 This is an encouraging result, because parsing time in contextfree chart parsing is linearly proportional to the number of edges entered in the chart.
 ^ Even without the incompatible features, the intransitive VP edge in this case would be discarded at this point due to lookahead.
 ^Our MUC5 system contained a filtering mechanism, which discarded all sentences that did not contain at least one word whose meaning was relevant to the domain.
 Those sentences judged to be irrelevant by the filter were not included in the random sample.
 668 300 200100y = 0.
18252 + 6.
8878x R'̂ 2 = 0.
8W) 120000 T y = 221.
92  191.
63X + 119.
02x^2 R'^2 = 0.
935 100000 • 80000 60000 4000020000 • 09 40 Figure 2: Edges vs.
 sentences length in T D L I N K Figure 3: C P U time vs.
 sentences length in T D L I N K The number of edges constructed was also compared against the minimum number of edges that could possibly be constructed in a complete parse of each of the sentences.
 This is the number of edges that would be constructed by a chart parser which always parsed every sentence as unambiguous at all stages of the parse.
 The ratio of the number of edges constructed by T D L I N K , divided by the minimum number of edges, remained virtually constant vs.
 word length, with a value of 2.
5.
 This means that, on average, between 2 and 3 different possible interpretations of a sentence were active as a parse proceeded.
 The number of interpretations did not increase with sentence length, another encouraging sign.
 Figure 3 shows a plot of C P U time used vs.
 sentence length.
 A weighted R^ analysis indicates that the bestfitting polynomial for this data is a quadratic (R^ = .
953), indicating that T D L I N K did not achieve averagecase linear time performance on the test sentences.
 Thus, it appears that the number of edges in the chart is not linearly proportional to processing time in T D L I N K .
 Discussion There are two possible sources for additional processing time in T D L I N K .
 First, the system may unsuccessfully apply enough rules that the time to build discarded edges overshadows the time to build edges that are entered into the chart.
 Second, as the sentence progresses, the application of a rule becomes more expensive.
 This is because the D A G labels of edges further along in the chart become more and more complex.
 Since unification in LINK is a destructive operation, whenever more than one interpretation is being pursued by the parser, D A G s must be copied before unification is performed, so that additions made to one interpretation do not affect other interpreatations.
 The more complex the D A G , the more expensive copying is.
 It may be that the time required to copy D A G s is overshadowing the rest of the overhead required in constructing a new edge, meaning that edge construction is not a constant time operation.
 Both of these possible difficulties will be discussed below.
 Discarded Edges Sometimes a rule is applied which eventually results in a failed unification.
 The reason that this happens is due to the bottomup application of rules found in the reachability table.
 Thus, all the information contained in expectations, except for an expectation's syntactic category, is not used until after a sequence of rules that connect a word to an expectation has already been applied.
 This may result in a lot of unnecessary work, if the newly constructed edges are discarded due to a failed unification at the end of the process.
 W e saw an example of this scenario in section 3: T D L I N K tried to construct two V P edges beginning with the word "eats", only to discard the edge corresponding to the V P rule for intransitive verbs.
 The reachability table only utilizes the syntactic category of an expectation and a word.
 If additional information from expectations could be utilized during the bottomup construction of edges which connect a word to an expectation, it might be possible to cut down on the number of discarded edges that are constructed by T D L I N K .
 W e are currently investigating ways to do this.
 First, we wish to modify the reachability table entries to a form wherein additional information from expectations is directly accessible from a word.
 This way, rule sequences which will lead to unsuccessful unification at the end of bottomup application can be eliminated from consideration immediately, and the number of discarded edges will decrease.
 Connection between an expectation and a word can be automatically constructed by precompiling the list of grammar rules in each table entry; one complete D A G which connects two categories will have the 669 expectation in its root node and the word in its leftcorner descendant position, and it will indicate what features (of all kinds) must unify between them.
 By using this complete D A G , both syntactic and semantic information contained in an expectation at any point in the parse can be brought down to a word: when the expectation is unified with the complete D A G at the top node, the leftcorner descendant will inherit some features which must be found in the next input word.
 Complete D A G s can also bring down the features specified in the grammar rules to a word: some of the syntactic and semantic features tested during bottomup rule application are propagated down and become directly accessible from the the leftcorner descendant.
 Then, those features are used to cut down the number of discarded edges: if, during the parse, the input word does not unify with the leftcorner descenddant of the complete D A G , then no edge will be created.
 FYom the previous example sentence "Pat eats the sandwich.
", in processing "eats" from the input, the intransitive V P rule will be eliminated from consideration immediately after the unsuccessful unification of "eats" with this rule's expected verb.
 By using complete D A G s , since no processing time will be wasted by discarded edges, we expect C P U time to decrease.
 W e are presently implementing a version of T D L I N K which uses this reachability table.
 In this version, complete D A G s are simplified into D A G s with the topmost category (expectation) and the leftcorner descendant (word).
 Those two categories are directly connected by a special arc named LC; each D A G is associated with one or more rule sequences which compile into the D A G .
 Although no features from the intermediate rules are recorded in the D A G except for the ones propagated to an expectation or a word, bottomup rule application is still required to test if the rule sequence will actually lead to successful unification.
 However, additinal information from expectations can still be utilized to disambiguate the parse and eliminate discarded edges.
 Another modification we wish to make to the reachability table is the rule hierarchy.
 W e like to organize the grammar rules which connect an expectation to a word into a discrimination network where each node in the network indicates a value to be found for a specific feature in the word and the grammar rules to select or eliminate.
 This discrimination network can be constructed automatically by using the complete D A G s described above.
 After complete D A G s are created for all rule sequences, features in the leftcorner descendants are further analyzed to form a hierarchy of featurevalue tests.
 In our example, under the table entry for connecting a V P expectation with a V, the T Y P E feature would be tested first in the discrimination net.
 If a value other than INTRANSITIVE is found in the word, this eliminates the first V P rule (eqs.
 1618) from consideration, and if a value other than T R A N S I T I V E is found, this eliminates the second V P rule (eqs.
 1923).
 Since rules are selected by value lookup which requires constant time rather than D A G unification, by using this rule hierarchy, we expect the parsing performance to improve significantly.
 DAG copying The second potential impediment to achieving linear performance in T D L I N K is the amount of D A G copying that is currently done during unification.
 In TDLINK, features are added to previous expectations as parsing proceeds; thus, copying expectation D A G s necessarily becomes expensive by more than a linear factor.
 In other words, the time required to copy D A G s may be overshadowing the time to construct an edge.
 If we can minimize the amount of this expensive D A G copying, the processing time may stay linearly proportional to the number of edges.
 One way to minimize D A G copying is to modify unification in T D L I N K to a nondestructive operation; a resulting new D A G is created only if two D A G s unify.
 However, this nondestructive unification must be no more expensive than the destructive one; depending on how it is implemented, processing time to decide if two D A G s unify may alone be as expensive as copying them.
 Attempts to build efficient nondestructive unification algorithms have shown promise (Wroblewski, 1990; Godden, 1990).
 Nondestructive unification will be most effective when unification is applied to D A G s that are fairly big and imcompatible.
 This situation can happen at two places in TDLINK: at the end of bottomup rule apphcation when the expectation is unified with the resulting D A G , and at the end of each grammar rule when all the children are unified to form the parent D A G .
 Significant reduction in the expense of copying these large D A G s may result in linear performance of our algorithm.
 References Godden, K.
 (1990).
 Lazy unification.
 In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics, Pittsburgh PA, pp.
 180187.
 Lytinen, S.
 (1992).
 A unificationbased, integrated natural language processing system.
 Computers and Mathematics with Apphcattons, 23(69), pp.
 403418.
 Lytinen, S.
, Burridge, R.
, Hastings, P.
, and Huyck, C.
 Description of the LINK system used for MUC5.
 In Proceedings of the Fifth Message Understanding Conference (MUC5), Baltimore M D , August 1993, pp.
 293304.
 Pollard, C , and Sag, I.
 (1987).
 Informationbased Syntax and Semantics.
 Stanford, CA: Center for the Study of Language and Information.
 Shann, P.
 (1991).
 Experiments with G L R and chart parsing.
 In Tomita, M.
 (ed), Generalized LR Parsing.
 Boston: Kluwer Academic Publishers, p.
 1734.
 Shieber, S.
 (1986).
 A n Introduction to UnificationBased Approaches to Grammar.
 Stanford, CA: Center for the Study of Language and Information.
 Tomita, M.
 (1986).
 Efficient Parsing for Natural Language.
 Boston: Kluwer Academic Publishers.
 Wroblewski, D.
 (1990).
 Efficient nondestructive unification.
 In Proceedings of the Eighth National Conference on Artificial Intelligence, Boston M A , pp.
 491496.
 670 Speaking of W i n e : Verbal and Perceptual Expertise Mediate Verbal Overshadowing in a Taste Recognition T a s k Joseph M.
 Melcher 651 Learning Research & Development Center University of Pittsburgh Pittsburgh, P A 15260 melcher@vms.
cis.
pitt.
edu Abstract J o n a t h a n W .
 Schooler 632 Learning Research & Development Center University of Pittsburgh Pittsburgh, P A 15260 schooier@vms.
cis.
pitt.
edu When subjects generate a detailed, memorybased description of complex visual stimuli such as faces, their recognition performance can be worse than nondescribing controls.
 This effect, termed verbal overshadowing.
 typically occurs when the stimulus is difficult to describe, not normally verbalized in detail, and when subjects are naive about the task demands.
 Verbal overshadowing has previously been shown to effect visually based memory (for faces and colors).
 This experiment was designed to: 1) detect verbal overshadowing in another sense modality, taste, and 2) to determine if domainrelated expertise modulates susceptibility to verbal overshadowing.
 Wine tasting was chosen as a domain in which to attempt to control subjects' relative levels of verbal and perceptual expertise.
 Based on suggestive data from previous face recognition studies, it was hypothesized that subjects whose perceptual expertise was greater than their domainrelated verbal expertise (termed Intermediates) would show verbal overshadowing.
 On the other hand, subjects with relatively equal perceptual and verbal expertise, either low/low (Novices) or high/high (Experts) would not show verbalization effects.
 After tasting a target red wine Verbalization subjects wrote detailed taste descriptions from memory while controls participated in an unrelated verbal task.
 All subjects then attempted to identify the target wine from among three foils.
 As predicted, the verbalizing Intermediates performed significantly worse than the nonverbalizing controls on Trial 1.
 Noeffect of verbalization was observed for either the novices or experts.
 The results are explained in terms of the differential development of perceptual and verbal skills in the course of becoming an expert.
 Keywords: Verbalization effects, expertise, memory, language, taste recognition.
 How often do we seriously try to communicate the nuances of perceptual experiences beyond the conventional of everyday speech? W e say, "He was very handsome:' "The soup was delicious:" "The coffee tasted exotic, but bitter.
" Do such recountings revive experiences or are they merely impressionistic dabs that capture only the coarsest details of our experiences? Then what about this description:? "It was a well balanced wine, almost certainly a Pinot Noir, rather oakey, tinged with a hint of blackberries and a faint.
 rather endearing mustiness.
" Does this more elaborated description reflect qualitatively better sensation and perception and better recollection of the experience that produced it? Other questions w e have been exploring are: Does describing a memory help or hurt memory for perceptions? Does verbal expertise in a domain enable more effective perceptual discrimination, description, and/or recollection? Motivated by these questions about the nature of the relationships between perception, language, and memory, this study sought to explore the effects of verbalization and expertise on subjects' ability to recognize wine taste samples.
 The ancients knew that forming mental images enhances memory for words (e.
g.
.
 Bower & Winzenz, 1970; Paivio, 1969).
 Similarly, verbal encoding normally enhances recognition of auditory and visual targets (e.
g.
, Bartlett, 1977; Bower & Holyoak, 1973; Carmichael, Hogan, & Walter, 1932; Daniel & and Ellis, 1972).
 Paivio's (1986) dualcode theory proposes that using both verbal and nonverbal encoding enhances memory by forming two potential routes for recall or recognition.
 However, Schooler and EngstlerSchooler (1990) found that memory facilitation from dual encoding breaks down when subjects verbalize stimuli that are difficult to adequately capture words.
 Specifically, they found that postencoding verbal description of visually complex stimuli such as faces and colors impaired subjects' subsequent recognition performance  an effect they termed verbal overshadowing.
 In verbal overshadowing, the failure to benefit from dual encoding is attributed to the relative nonutility of the verbal code.
 In paradigms in which a dual coding is found to be useful, exclusive access to the verbal code can enable the subject to effectively carry out the task.
 For example, either remembering the image of a dog or the word "dog" is sufficient to enable one to recall that "dog" was a memory item.
 Thus access to either a visual or a verbal code can enable successful performance, thereby enabling subjects who have both codes to perform more effectively than those who have only one or the other (cf.
 Paivio, 1986).
 However, for stimuli such as faces, possession of a verbal code may be of minimal benefit because, verbal 671 mailto:melcher@vms.
cis.
pitt.
edumailto:schooier@vms.
cis.
pitt.
edudescriptions are notoriously inadequate representations of ones memory for a face (cf.
 Fallshore & Schooler, 1995; Polanyi, 1967).
 Thus, attempting to rely on a verbal code for remembering a face may not only fail to facilitate performance, it may actually hamper performance to the degree that one relies on the verbal code at the expense of the visual one.
 Consistent with this view, recent studies have observed verbal overshadowing effects for a variety of tasks for which relying on a purely verbal representation could be disruptive, including memory for various perceptual stimuli such as music (Houser, Fiore, & Schooler, 1995), maps (Fiore, 1994), and visual forms (e.
g.
, Brandimonte, Schooler, & Gabbino, 1995) as well as other difficulttodescribe cognitive activities such as insight problem solving (Schooler, Ohlsson, & Brooks, 1993) and affective decision making.
 Configural and featural processes in encoding a n d recognition In short, verbal overshadowing effects can be broadly construed as resulting from inappropriate use of a verbal code when a nonverbal/perceptual code may be more appropriate.
 This characterization leaves open the question the precise nature of the information that is disregarded as a result of verbalization.
 Recent research suggests that the visual information disregarded following verbalization may specifically be the configural properties of the stimulus.
 Specifically, verbalization may encourage the reliance on featural processing associated with the verbal code, while discouraging the configural processing associated with the visual code.
 In vision, configural processing provides gestaltic overviews of shape, topography and dimension (cf Marr, 1982), as well as color, and where appropriate, motion perception.
 These processes occur rapidly, in parallel, and preconsciously.
 O n the other hand, featural perception is associated with more conscious awareness of discrete packets of information (Diamond & Carey, 1986).
 It is more analytical, insofar as it involves separate, consciously motivated analyses of discrete features that contributed to configural processing; it also involves verbal labeling.
 Featureoriented processing takes place relatively slowly and serially; discrete features are necessarily noted one at a time.
 Note, finally, that it is relatively difficult to describe the (subconscious) processes of lowlevel perception.
 For example, in vision, to precisely name shades of color, or to describe topology and spatial relationships, such as the precise geometrical configuration of the eyes, nose, and mouth, etc.
 A verbal overshadowing mechanism Verbal overshadowing appears to be caused when subjects w h o have encoded information using perceptual/configural processes are subsequently asked to recode that information using more verbal/featural processes, and thereby inappropriately draw on verbal/featural information at recognition.
 Schooler and EngstlerSchooler found that verbal overshadowing could be reversed by forcing subjects to make speeded recognition decisions (Schooler & EngstlerSchooler, 1990).
 This manipulation apparently causes subjects to switch back to their original configural representation.
 Central to the above analysis is the suggestion that verbal overshadowing produces impairment when access to perceptual/configural information provides a more veridical reflection of the experience than access to the verbal/featural information.
 Accordingly, the better an individual is at representing perceptual knowledge in featural/verbal code, the less impaired they should be by verbalization ~ the central hypothesis of this study.
 Verbal and perceptual expertise and susceptibility to verbal overshadowing It is important to note that verbal overshadowing has so far only been found under conditions in which subjects have perceptual, but not verbal, expertise in a domain.
 This discrepancy leads to the hypothesis that susceptibility to verbal overshadowing depends on the relative strengths of one's verbal and perceptual expertise in a domain.
 Consistent with this view are recent findings (Fallshore & Schooler, in press; Schooler, Ryan, Fallshore, & Melcher, 1995) suggesting that increasing perceptual expertise in a domain may increase susceptibility to verbal overshadowing if it is not accompanied by verbal expertise.
 Schooler et al.
 (in press) have noted that "with increasing expertise comes a greater use of configural considerations in which multiple elements interact.
" Likewise, Fallshore and Schooler (in press) have found that Caucasian subjects who described Caucasian faces (for which they presumably have high perceptual expertise, i.
e.
, exposure and familiarity) were more impaired at recognition than when they described AfricanAmerican faces (for which they presumably have lower perceptual expertise.
).
 They explained these results as follows: Due to greater perceptual expertise, the Caucasians processed ownrace faces configurally but processed otherrace faces featurally (cf Brigham & Malpass, 1985; Diamond & Carey, 1986).
 Fallshore and Schooler further hypothesized that postencoding verbalization disrupts memory for configural representations but not for featural representations.
 This suggests that postencoding verbalization is disruptive when it cannot capture the nuances of the underlying configural representation.
 Likewise, postencoding verbalization is not likely to be disruptive to the extent that the initial processing was featural.
 In the case of Caucasians trying to recognize AfricanAmerican faces (where they have neither perceptual nor verbal expertise) verbal overshadowing did not occur.
 In short, Fallshore & Schooler's results suggest that verbal overshadowing effects occur when perceptual expertise is high and verbal expertise is low, whereas it does not occur when both verbal and perceptual expertise are modest.
 However, what happens when individuals possess both perceptual and verbal expertise? According to the present analysis such individuals may also be less vulnerable to verbal overshadowing.
 This study used a winetasting task because, in the course of their training, wine experts learn an extensive vocabulary dedicated to taste and odor detection and 672 classification in wines.
 A domainspecific vocabulary may provide a precision and depth that is lacking in ordinary language, thereby facilitating the recall of both the configural and featural processing of percc|)(iial experience.
 For instance, Lehrer (1983) and Solomon (1990) have that wine experts have more precise wine taste discrimination than novices and that better discrimination may be linked to linguistic skill in the domain.
 These results are consistent with the hypothesis that verbal expertise commensurate with perceptual expertise may prevent verbal overshadowing.
 They are also consistent with Schooler, et al.
's (in press) contention that perceptual expertise should be more vulnerable to verbalization effects than expertise based on conceptual or propositionai knowledge.
 It should be noted that increasing verbal expertise in any domain necessarily involves more elaborated conceptual and propositionai knowledge.
 In wine, for instance, verbal expertise is associated with varietal classification, various standard taste categories, etc.
 Of course, the degree to which knowledge is strictly propositionai varies between domains.
 Wine classification is arguably less precisely propositionai and conceptual than, say, disease diagnosis.
 Summary and predictions This study was designed to examine the degree to which verbal overshadowing in the domain of wine recognition may be mediated by individuals relative level of levels of perceptual and verbal expertise.
 If the rationale just outlined is correct, persons with relatively more perceptual than verbal expertise (herein, subjects w h o report drinking red wine relatively frequently, but who have little formal training in wine) should be handicapped by the fact that their ability to talk about wines lags their perceptual discrimination skills.
 In contrast, novices (individuals who drink red wine less than once a month), should be relatively unaffected by verbalization since their perceptual an verbal expertise are commensurately underdeveloped.
 Such a finding would conceptually replicate Fallshore & Schooler's finding that other race face recognition is relatively immune to verbalization.
 Finally, wine experts (professionals or individuals with marked wine training) should also show an immunity to verbalization effects, in this case because their verbal and perceptual expertise are both commensurately advanced To test for the hypothesized interaction between level of expertise and verbalization, subjects were categorized according to their perceptual expertise (frequency of red wine consumption) and verbal expertise (amount of formal wine training).
 The Novices rarely or never drank red wine and had no training.
 The Intermediates consumed red wine moderately to frequently but had limited wine training.
 The Experts were frequent consumers who were either wine professionals or had extensive formal training.
 It was predicted that there would be no difference in recognition accuracy between verbalizing and control Experts and Novices but that Intermediates' recognition would be impaired by postencoding verbalization.
 Method Subjects.
 The subjects were 107 adults between the ages of 21 and 78.
 Materials and Design.
 The wines were eight red varietals from six countries.
 O n each of two trials the wines were arrayed in one of four Latin squares presentation orders; the target wine appeared equally often in each of the four serial positions.
 Stimulus set presentation counterbalanced over the trials.
 This was a 3 (Novice/Intermediate/Expert) x 2 (Verbal/Nonverbal) x 2 (Trial) design with expertise and verbalization as betweensubjects factors, trial as a withinsubjects factor, and target discrimination as the dependent variable.
 Procedure.
 Prior to the trials, subjects completed a questionnaire designed to categorize their levels of wine expertise.
 It included questions on frequency of red wine consumption, the subject's wine training background, and five general wine knowledge quiz items.
 O n each of two trials the subjects received a tray of cups with the target and the recognition test array.
 Subjects tasted the target after having been told to "pay attention to any or all aspects of the sample except for its appearance.
" Verbal subjects were asked to: "describe this wine as precisely and in as much detail as you can.
 Describe it uniquely, so that someone else would match it to your description.
 Consider all elements of the wine's taste, smell, feel, or related associations.
 .
 .
".
 Control subjects worked a crossword puzzle during the four minute retention interval.
 The subjects were then given these recognition test instructions: "The set of four cups contain four different wines.
 One of them is the wine you just tasted.
 The other three are different.
 You are to taste each wine in order.
 After you taste each sample, please indicate on the page how sure you are whether it is the wine you just tasted.
 .
 .
".
 The subjects indicated their confidence that each sample in the array was/was not the target, on a scale where 7 indicated an absolute "yes" and 1 indicated an absolute "no.
" The confidence ratings were converted to a discrimination score for each trial.
 This value was the difference between the confidence rating for the target wine minus the mean rating for the three distractors.
 A score of 6 indicates perfect discrimination (giving the target the highest score and each distractor the lowest); 0 indicates random discrimination, and negative scores indicate false alarms (ranking one or more distractors higher than the target).
 Results The relationship between verbalization and expertise was mediated by a significant threeway interaction between verbalization, expertise, and trial F(2,196) = 4.
43, £ < .
01.
 This trial interaction reflects the fact that verbal overshadowing disappeared on the second trial  typical in this paradigm (e.
g.
, Fallshore & Schooler, in press; Schooler & Melcher, unpublished data).
 W e therefore 673 focus on Trial 1, when subjects were naive about the verbalization and recognition tasks.
 Figure 1 illustrates Trial 1 performance.
 There was a significant Expertise x Verbalization interaction, F(2.
99)=5.
10.
 £=.
008, driven by significant verbal overshadowing among the Intermediates, t(45)=2.
80, 2=.
0O8 and nearly significant enhancement among the Novices, 1(35)=2.
01, ̂ =.
052.
 The enhancement for Experts was nonsignificant (£>.
6).
 Finally, there was a significant main effect of Expertise, F(2,99)=6.
20, ]2=.
003, important insofar as it validates the expertise ranking criteria.
 VertDal Nonverbal Novice Intermediate Expert Figure 1: M e a n discrimination as a function of expertise and verbalization The current conceptualization of verbal overshadowing is that it happens when persons w h o lack the requisite verbal skill shift from the default, nonverbally coded configural memory representation to an inferior featural representation, encoded verbally.
 Conversely, persons w h o possess high verbal skill in the domain should tend to benefit from their more precise dual encoding facility.
 To test this interpretation, all potentially relevant recognition discrimination predictor variables' were entered into a stepwise regression to determine which were most predictive of performance for the Verbalization and the Nonverbalization subjects.
 The regression showed that Nonverbalizers' discrimination was significantly predicted only by the measure of perceptual expertise (consumption frequency) (r=.
39) whereas Verbal izers' discrimination was only significantly predicted by the measure of verbal expertise (wine knowledge) (r=.
45; both ps < .
01).
 None of the other variables entered significantly into the stepwise regression model.
 Discussion The most important result of this experiment is that its successful manipulation of perceptual and verbal expertise confirms that verbal overshadowing is most likely to occur when ' These variables were: 1) red wine consumption frequency, 2) wine knowledge score, 3) age, 4) gender, and 5) target placement in the recognition arrays.
 verbal expertise is outflanked by perceptual expertise in a domain.
 In other words, verbal overshadowing results when people w h o lack the requisite verbal skill nevertheless attempt to verbally/featurally recode a configural representation in memory.
 This view was supported by the finding that the only subjects whose performance was impaired by verbalization were the those with relatively high perceptual expertise (frequent red wine consumers) but little verbal expertise (little formal wine training).
 The role of expertise in mediating the verbalization effects was further illustrated by the stepwise regression analysis examining the relationship between expertise and performance as a function of verbalization condition.
 This analysis revealed that perceptual expertise was the only significant predictor of Nonverbalizers' discrimination whereas the Verbalizers' discrimination was significantly predicted only by verbal expertise.
 These findings suggest that Nonverbalizers tend to rely on their configural representation whereas Verbalizers tend to rely on their verbal (i.
e.
, featural) representation  which helps them to the extent that they are capable verbalizers.
 This pattern suggests that verbalization shifted the Intermediates away from the configural processing at which they are relatively expert to the featural processing at which they are less adept.
 Since the novices and experts had better equated verbal and perceptual skills (low/low and high/high) only the intermediates' performance suffered as result of 674 the verbalizationinduced shift from perceptual to verbal processing.
 T w o other aspects of the intermediates are also worth noting.
 First, in terms of relative perceptual and verbal expertise their wine expertises are analogous to the average person's face expertise: They have relatively extensive experience with tasting wine (and viewing faces) but relatively less experience in describing wine (and faces).
 Second, the Intermediates' descriptions demonstrated relatively well developed winerelated verbal skill.
 They often used Expertlike vocabulary and categories (e.
g.
, balance, nose) but by definition (of limited training) it is reasonable to presume that this skill is less well practiced (Lawless, 1985; Lehrer, 1983; Solomon, 1990).
 Therefore, the connections between perceptual and verbal nodes are presumably not as strong, not as precisely mapped, nor as automatically activated as among the experts.
 The trial effect As noted in the results, this experiment generated a trial effect often observed in this paradigm (see Schooler, et al.
, in press): The verbal overshadowing effect ameliorates or disappears after the first trial.
 The most likely explanation is that verbal overshadowing is due to subjects' initially encoding in the default configural mode, which is resistant to featural analysis when verbal skill is poorly developed.
 Once subjects have experienced the task demands of the encoding, verbalization, and recognition task they appear to encode the stimuli in a manner more congruent with the needs of verbal description.
 This experiment did not yield data that directly address this question, but there is other evidence that subjects change their encoding after the first trial.
 Schooler and Fallshore (1994) found some evidence that verbal descriptions improve over trials.
 In an ongoing study, subjects are asked whether they were aware of any faceencoding and/or recognition strategy changes after the first trial.
 Almost to a subject, they state something to the effect that on the first trial they "look at the whole face.
" O n the second and third trials, however, they almost invariably say that they began to inspect the target for specific features that they could verbalize and/or use as benchmarks for the recognition judgments (Schooler & Melcher, unpublished data).
 That is, these perceptual experts seem to be consciously considering the verbalizable aspects of the stimuli.
 It is quite conceivable that the wine intermediates took this tack, for on the second trial, the verbalizers' recognition improved dramatically equalling the nonverbalizers.
 Differential development of perceptual a n d verbal skills This study may help illuminate mechanisms underlying earlier research which uncovered differential development between perceptual and verbal skills.
 The earliest suggestions appeared when KarmiloffSmith & Inhelder (1974/75) discovered that young children rather quickly learned how to balance "trick" blocks (containing hidden weights).
 They simply used proprioceptive feedback to determine what works.
 However, somewhat older children with more sophisticated knowledge of physics took longer to learn to balance the blocks.
 Finally, the oldest of the three groups of children again learned quickly.
 KarmiloffSmith and Inhelder hypothesized that the middle group's failures were based on an implicit theory about balancing (i.
e.
, the best strategy is to balance at the geometric center).
 However, this otherwise implicit theory caused them to tend to ignore contrary evidence (the effect of the hidden weights).
 The oldest children performed well, presumably because they could more explicitly reconcile their theory with contrary evidence to generate a more general theory.
 A particularly startling finding was that the middlerange kids who failed could nevertheless perform the task if they closed their eyes and relied once again on proprioceptive feedback.
 In short, the perceptual (i.
e.
, proprioceptive feedback skill) developed more quickly than the conceptual (akin to verbal knowledge or expertise).
 Children who had not yet developed the requisite level of sophistication in articulating physical theory, were therefore handicapped.
 A m o n g adults, Lesgold, Feltovich, Glaser, & W a n g (1981) and Lesgold et al.
 (1988) have found that verbal skill apparently matures more slowly than perceptual skill in radiology.
 Lesgold et al.
 (1988) studied radiologists as they learned to read xray photographs and found that partway through their training students suffered a decrease in their ability to diagnose lung abnormalizes.
 Lesgold et al.
 speculated that this drop might reflect differences between a fast "perceptual" learning and a slower "cognitive" learning such that "an emerging cognitive ability will have to contend with a stronger perceptual ability already in place" (p.
 337, emphasis added).
 In the context of the present findings, it might be suggested that as radiology students initially acquired cognitive ability at reading xrays, they may have been more predisposed to verbalize diagnostic hypotheses based on pattern recognition, or configural, perception.
 Their possibly undeveloped verbal skill may then temporarily fail to support their perceptual skill.
 However, as their cognitive/verbal skill develops, the mismatch 675 between the verbal and perceptual knowledge may disappear, and with it, the interfering effects of verbalization.
 This explanation raises the intriguing possibility that although verbalization initially overshadows perceptual expertise, with practice it may facilitate it.
 Acknowledgments The writing and research reported here was supported by a grant to the second author from the National Institute of Mental Health.
 References Bartlett, J.
C.
 (1977).
 Remembering environmental sounds: The role of verbalization at input.
 Memory & Cognition, 5, 404414.
 Bower, G.
H.
 and Holyoake, K.
 (1973).
 Encoding and naturalistic memory for natural sounds.
 Journal of Experimental Psychology, 101, 360366.
 Bower, G.
H.
 & Karlin, M.
B.
 (1974).
 Depth of processing pictures of faces and recognition memory.
 Journal of Experimental Psychology, 103,4,151151.
 Bower, G.
H.
 & Winzenz, D.
 (1970).
 Comparison of associative learning strategies.
 Psychonomic Science, 20, 119120.
 Brigham, T.
C.
 & Malpass, R.
S.
 (1985).
 The role of experience and context in the recognition of faces of own and otherrace.
 Journal of Social Issues, 41, 139155.
 Carmichael, L.
, Hogan, H.
P.
, & Walter, A.
A.
 (1932).
 An experimental study of the effect of language on the reproduction of visually perceived forms.
 Journal of Experimental Psychology, 15, 7386.
 Diamond, R.
 & Carey, S.
 (1986).
 W h y faces are and are not special: An effect of expertise.
 Journal of Experimental Psychology: General, 775,2,107117.
 Daniel, T.
C, & Ellis, H.
C.
 (1972).
 Stimulus codability and longterm recognition memory for visual form.
 Journal of Experimental Psychology, 93, 8389.
 Fallshore, M.
 & Schooler, J.
W.
 (1992).
 Parallels between the disruptive effects of verbalization, nonexpertise, and inversion on face recognition.
 Poster presented at the Annual Meeting of the Psychonomic Society, N e w Orleans, LA.
 Fallshore, M .
 & Schooler, J.
W.
 (in press).
 The verbal vulnerability of perceptual expertise.
 Fiore, S.
M.
 (1994).
 Verbal overshadowing of macrospatial memory.
 Unpublished masters thesis.
 University of Pittsburgh.
 Houser, T.
 & Schooler, J.
W.
 (1994).
 [Verbal overshadowing of memory for musical phrases.
] Unpublished data.
 KarmiloffSmith, A.
 & Inhelder, B.
 (1974/75).
 If you want to get ahead, get a theory.
 Cognition, 3,3, 195212.
 Klatsky, R.
A.
, Martin, G.
L.
, & Kane, R.
A.
 (1982).
 Semantic interpretation effects on memory for faces.
 Memory and Cognition, 10, 195206.
 Langlois, J.
H.
, Roggman, L.
A.
, & Musselman, L.
 (1994).
 What is average and what is not average about attractive faces? Psychological Science, 5,4,214220.
 Lawless, H.
T.
 (1978).
 Recognition of common odors, pictures, and simple shapes.
 Perception and Psychophysics, 24, 6, 493495.
 Lawless, H.
T.
 (1985).
 Flavor description of white wine by "expert" and nonexpert wine consumers.
 Journal of Food Science, 49, 120123.
 Lehrer, A.
 (1983).
 Wine and conversation.
 Bloomington: Indiana Univ.
 Press.
 Lesgold, A.
 M.
, Rubinson, H.
 Feltovich, P.
 Glaser, R.
 Klopfer, D.
 & Wang, Y.
 (1988).
 Expertise in a complex skill: diagnosing XRay pictures.
 In The Nature of Expertise.
, M.
T.
H.
 Chi, R.
 Glaser, & M.
J.
 Farr (Eds.
).
 Hillsdale, N.
J.
: Earlbaum.
 Marr, D.
 (1982) Vision.
 San Francisco: Freeman.
 Paivio, A.
 (1969).
 Mental imagery in associative learning and memory.
 Psychological Review, 76,241263.
 Paivio, A.
 (1986).
 Mental representations: A dual coding approach.
 N e w York: Oxford University Press.
 Polanyi, M.
 (1967).
 The tacit dimension.
 N e w York: Doubleday & Co.
, Inc.
 Schooler, J.
W.
 (1989).
 Verbalization can impair the nonverbal components of visual memories.
 Paper presented at the annual meeting of the Psychonomic Society.
 Schooler, J.
W.
 & EngstlerSchooler, T.
 (1990).
 Verbal overshadowing of visual memories: Some things are better left unsaid.
 Cognitive Psychology, 22, 3671.
 Schooler, J.
W.
 & Fallshore, M.
 (1990).
 Does expertise help to mediate the verbal overshadowing effect? Paper presented at the Annual Meeting of The Psychonomic Society, N e w Orleans, LA.
 Schooler, J.
W.
, Ohisson, S.
, and Brooks, K.
 (1992).
 Thoughts beyond words: When language overshadows insight.
 Journal of Experimental Psychology: General, 122, 2, 166183.
 Schooler, J.
W.
, Ryan, R.
D.
.
 Fallshore, M.
F.
, & Melcher, J.
M.
 (in press).
 Knowing more than you can tell: The relationship between language 676 and expertise.
 In R.
E.
 Nisbett & J.
 Caverni (Eds.
) The Psychology of Expertise.
 Amsterdam, The Netherlands: Elsevier.
 Solomon, G.
E.
A.
 (1990).
 The psychology of novice and expert wine talk.
 American Journal of Psychology, 103, 4, 495517.
 Wells, G.
L.
 & Hryciw, B.
 (1984).
 Memory for faces: Encoding and retrieval operations.
 Memory & Cognition, 12, 338344.
 677 StructureMapping vs.
 Highlevel Perception: T h e Mistaken Fight Over T h e Explanation of Analogy Clayton T.
 Morrison and Eric Dietrich Philosophy And Computers & Cognitive Science (PACCS) State University of N e w York Binghamton, N Y 139026000 clayton(ituring.
pacss .
binghamton.
 edu diet r i c h @ t u r i n g .
 p a c s s .
binghainton.
edu Abstract There is currently a competition between two theories that propose to explain the cognitive phenomenon of analogy: Dedre Centner's StructureMapping Theory and Douglas Hofstadter's theory of Analogy as Highlevel Perception.
 W e argue that the competition between the two theories is illfounded because they arc after two different aspects of analogy: structuremapping seeks a "horizontal" view of analogy where the phenomena is examined at the level of already existing psychological representations, and where the task is to identify what processes are common to all or most analogy function; Highlevel Perception, on the other hand, seeks a "vertical" view of analogy in which the goal is to explain the processes that make up the construction of represenUtions.
 An integrated theory of analogy should encompass both horizontal and vertical views.
 Introduction In this paper, w e argue that there is a mistaken competition between two theories of analogy: Dedre Centner's structuremoping theory (SMT), and Douglas Hofstadtar's theory of analogy as highlevel pCTception (HLP).
 Proponents of either theory have developed arguments claiming that their theory captures more c^ analogy than the other.
 The task of this paper is to separate these combatants and show that their theories are after explanations of different aspects of analogy phenomena, not necessarily pitted against one another.
 Summary Of The Positions Centner's S M T (Centner, 1980, 1983, 1989) describes analogy as a product of structuremapping.
 A basic assumption of S M T is that our psychological concepts have a structtire to them.
 According to Centner, these structures are the psychological representations of relations between perceptual and conceptual objects.
 According to S M T , an analogy, the ability to recognize that "one thing is like another," is a mapping of one structure onto another according to a similarity comparison based on the relations represented in the concept structures.
 Cenmer and others have set out to onpirically test the explanatory power of this conception with respect to human analogical production (Centner, Falkenhainer & Skorstad, 1987; Centner & Imai, 1992; Centoer & Landers, 1985; Centner & Rattermann, 1991; Centoer, Rattermann & Forbus, 1993; Kotovsky & Centoer, 1990).
 S M T has two key strengths: 1) it makes a clean distinction between analogies and other types of similarity comparisons (abstraction, anomaly, literal similarity, and mere ^pearance), both in theory and as evidenced in psychological examination; and 2) it is generally applicable — rather than requiring a specific algorithm for each potential analogy, or even a collection of algorithms for each domain of comparison, the generalized structure of knowledge representation and the structuremapping algorithm makes it possible for any properly constructed knowledge structure to be compared and considered for structuremoping.
 The StructureMapping Engine (SME) (Falkenhainer, Forbus & Centoer, 1986, 1989; Centoer, Falkenhainer & Skorstad, 1987) is a computer model intended to simulate the structoremoping process of Centoer's theory.
 When given a properly constructed representation, S M E can find a mapping between toe appropriate relations for each representation.
 A system of analogical retrieval, called M A C / F A C (Centoer, 1989; Centoer & Forbus, 1991; Centoer, Ratterman & Forbus, 1993), provides a plausible metood by which a huge database of structured knowledge representations may be searched and an item retrieved from it wito little computational strain.
 M A C / F A C includes S M E as toe key component toat performs toe structuremapping.
 Douglas Hofstadter and several of his graduate students (Hofstadter, 1984; Hofstadter, MitcheU & French, 1987; Chalmers et al.
, 1992; MitcheU, 1993; Hofstadter et al.
, 1995) propose a different approach to the explanation of analogy by which an analogy is conceived of as the product of a more general cognitive function called highlevel perception.
 H L P is the process by which an organism's representation of a situation at a conceptual level is consonicted based on an interaction between highlevel concepts and lowlevel perceptoal processes: highlevel concepts influence lowlevel perceptual processing, while what is perceived at a low level affects the activation of highlevel concepts as a representation of the situation is constructed.
^ The Copycat project, designed by Hofstadter and MitcheU (1992; MitcheU, 1990, 1993; MitcheU & 'The conceptual level is the level at which concepts begin to play a role; a concept is anything from object recognition (e.
g.
, recognizing an apple) to the ability to grasp complex relations and situations (e.
g.
, that BiU Clinton is in the Democratic Party).
 678 http://binghainton.
eduHofstadter, 1990), is a model of analogy as highlevel perception.
 Copycat is intended to embody the principles of highlevel perception by building it's own representation of an analogy situation in a sin^lified letterdomain.
 In order to really get at H L P , we must now turn to Hofsladler's criticisms of Centner, and thus the confrontation between structuremapping and highlevel perception.
 The Fight The theory of highlevel perception is first introduced in print in the ps^r.
 Highlevel perception: representation and analogy, by CFlfi (Chahners, et al.
, 1992).
 The main thesis of their paper is that H L P is deq)ly interwoven with other cognitive processes.
 They argue that much of the woik in AI has attempted to model conceptual processes independently of perceptual processes, but that this approach cannot lead to a satisfactory understanding of the human mind.
 Therefore, they argue, researchers in AI must integrate perceptual processing into their modeling of cognition.
 As an example of highlevel cognition that depends on highlevel perception (and vice versa), C F H take up the cognitive process of analogy.
 They posit that, "when people make analogies, they are perceiving some aspects of the structures of two situations — the essences of those situations, in some sense — as identical" (Chahners et al.
, 1992, p.
l93).
 The structures of the representations of these situations are, they propose, the product of highlevel perception.
 Analogical thought also provides an illustration of the flexible nature of our perceptual abilities.
 For instance, making an analogy requires highlighting various aspects of a situation, and the aspects that are highlighted are often not the most obvious features from the beginning.
 The perception of the situation can change radically, depending on the analogy w e are making.
 C F H divide the processes involved in analogical thought into two basic components.
 One is situation perception, the filtering and organizing of data involved in a given situation according to a given context A n d the other is mapping, the taking of the representations of two situations and fmding appropriate correspondences between components of one representation with components of the other to produce the analogy matchup.
 C F H claim that, "it is by no means apparent that these processes are cleanly separable; they seem to interact in a deep way" (Chalmers et al.
, 1992, p.
l95).
 They propose that because perception underlies analogy, w e are tempted to divide the process of analogy sequentially into situation perception, followed by mapping (as Centner's analogy architecture suggests).
 However, analogy is deeply involved in the situation perception stage as well; perceptions of many situations are possible because of analogical mappings.
 Thus, C F H conclude that situation perception and m o p i n g processes go handinhand.
 For these reasons, C F H believe that perception must be accounted for in a model of analogical thought — something they claim has not been taken into account by current models of analogy.
 C F H make use of three technical terms in characterizing the pitfalls of separating perception from highlevel cognition.
 The first term is that of handcoding representations.
 This refers to the structuring of representations by humans.
 Handcoding becomes a fallacy when an implementer's representations beg all the interesting cognitive questions; i.
e.
, when the implementer encodes all the information needed to complete the task (e.
g.
, B A C O N ' ) .
 The second term is rigidity, a feature of representations in which they are inflexible or unable to change.
 This, C F H claim, m a y be a result of handcoding representations rather than having the mechanism build them through some sort of constructive process.
 The third term is 2020 hindsight, which occurs when a researcher develops a mechanism that relies on handcoded concepts rather than a mechanism that independently arrives at a representational structure for a particular concept The mechanism using the handcoded representations is said to be guilty of 2020 hindsight^ C F H accuse Cenmer's model of analogy of bypassing the process of perception.
 They say that Centner's ^proach involves starting with fixed, handcoded representations which are compared and a mapping between them is performed.
 CFIfs criticisms are focused on the difficulties that arise out of the rigidity of SME's representations, the foremost of which is the inability to change representations as needed during processing.
 According to Centner's model, C F H claim, mapping is the only process involved in analogy.
 In S M E , representations are handcoded, and thus building is ignored — it is assumed that "correct representations" will be available through some external process.
 The result of SME's dependence on rigid representations is that decisions in representation must be precisely the right one's before processing starts.
 But such information as to which one's are correct is not available ahead of time unless (even to some extent) the analogy to be made is known ahead of time.
 A n d this is what makes S M E guUty of 2020 hindsight.
 ^Tbc authors of this paper arc David J.
 Chalmers, Robert M.
 French and Douglas Hofstadter.
 W e will refer to the authors as C F H for abbreviation.
 'The creators (Langley et al.
) of B A C O N , a model of scientific discoveiy, claim that B A C O N is able to make scientific discoveries, such as Kepler's third law of planetary motion.
 However, the model is given precisely the data required to derive the law, so that it's "discovery" is reduced to a rather simple deduction that any beginning physics student should be able to deduce.
 For this reason, Chalmers et al.
 accuse B A C O N of having 2020 hindsight in being given only what is needed, when in fact the actual cognitive processes involved in such scientific discoveries are faced with the much more monumental task of paring down what is relevant and making careful hypotheses paired with testing, all part of an intricate process of induction.
 ^This fallacy is close to the fallacy of begging the question: faexample, claiming that a program has independendy arrived at a "discovery," when the "discovCTy" was already coded by the programmer into the program.
 For an excellent discussion of this sort of fallacy concerning two other programs, A M and EURISKO, see Koza 1992.
 pp.
232236.
 679 Talking Cross Purposes While these characterizations are true, C F H may have inaccurately construed what Centner et al.
 claim S M E can do.
 C F H claim that, "the S M E program is said to discover an analogy between an atom and the solar system" (Chalmers et al.
, 1992, p.
 196; emphasis added).
 This is not true.
 S M E is intended to explain what happens in the comprehension of an analogy between an atom and the solar system (Genmer, 1983; Centner.
 1989).
 It is not being proposed as a model of discovoy through analogy (unlike B A C O N , where C F W s criticisms do seem apt).
 It seems there is an important distinction which both Centner and C F H have missed.
 It begins with an approach that is not made explicit by Centner concerning what the structuremapping theory is an explanation of.
 First outlined in Centner 1983, the StructureMapping Theory is described as an explanation of how analogies are produced.
 In order to get this explanation, however, Centner claims that the theory is aimed at answering the following question: bow is it that one derives meaning from an analogy? (Centner, 1983, p.
l55) This latter characterization makes structuremoping an explanation of bow analogies are understood or compreheruied — the analogy has already been given, but the agent must produce a mi^ping in order to interpret the analogy.
 It is not clear that the processes of production and comprehension are the same.
 O n the one hand, there are the situations where one may hear an analogy or be presented with one and then come to understand iL In most examples of how structuremapping works, and especially in the operation of S M E , the theory is presented as explaining this kind of situation.
 Production, on the other band, seems to involve a different kind of situation: an agent obsoves events or situations and is able, on its own, to construct a similarity comparison between two situations (one observed and one recalled) and thus produce a novel analogy.
 While both understanding and production situations may share the common aspect of structure mapping, the conditions that lead to and influence the comparison are very different All the conditions that surround the m o p i n g are vital to understanding whether an analogy is being understood or whether a novel analogy is being produced — to leave the conditions of the mapping ambiguous seems to be a mistake.
 To claim that they are the same process is a profound statement about cognition.
 Whether structuremoping is claiming this, or if it is only a model of analogy comprehension, is not made clear in Cenmer's central papers (1980,1983,1989).
 Centner's theory is a theory of understanding (spedfically, for good analogies) but she doesn't have a theory of bow analogies are created in the first place.
 For example, she has a theory of what happened when Rutherford thought "the atom is like that solar system" and of what may go on when we are given this information, but she does not have a theory of how he managed to create this analogy in the first place.
 In other words, she doesn't have a theory of where structures come from (but she is working on it; see her treatment of unpacking in Kotovsky & Centner, 1990).
 HowevCT, she does have a theory of what analogies are, given already existing structures.
 Thus, it appears that it is an explanation of analogy comprehension that structuremopiQg is ultimately after.
 The situation Centner is explaining is consistently presented as an agent being given an analogy and the agent then performs the mapping to create a new representation, thus highlighting how the two situations are analogous.
 This is to be distinguished from the case of novel, independent, and unprompted analogy creation.
 It seems that C F H may have gotten their mistaken impression of Centner from this ambiguity between analogy comprehension and production.
 This also demonstrates that C F H probably don't make a distinction between the two.
 A model may exist in which these two are in oneandthesame mechanism, but as Centner's model op^^^i^ to demonstrate, ia not accounting for representation construction, analogy comprehension might be separated from analogy production.
 S M E is a model of analogy understanding or comprehension, where the cognitive agent is given the analogy and must understand it given its current knowledge database (i.
e.
, construct a representation from existing ones).
 In this case, there may be no need for construction of novel representations, and this limits its capacity to capture the dynamic aspects of natural analogy production.
 Any model that doesn't take this into account will be dependent on someone (or some module) to organize the information in a suitable manner so that a mapping can take place.
 So the dependence on handco(Ung representations has severely limited the ability of S M E to capture creative analogical production in the wild.
 However, as S M E is a model of analogy understanding, it is immune to CFITs criticisms based on creating an analogy because in understanding, the handcodings they look for (handcoding the representations) may be legitimate.
 In light of this, it is no surprise that S M E doesn't do what C F H would like to see — they have mistaken what S M E is explaining.
 This mistaken accusation as to what Centner ultimately claims S M E can do is very telling.
 The key criticisms that C F H bring to bear, with respect to what is missed in not accounting for representation construction, depead on S M E being intended to explain how representations are constructed.
 H L P seems to be after the an explanation of novel analogy production.
 Their explanatory task, from which their criticisms against structuremoping are derived, are aimed at bow the analogy situation is perceived, and thus, how representations are constructed in the first place.
 But this seems to be something that S M E isn't trying to do.
 C F H and the S M E researchers are talking at cross purposes.
 The View Of Analogy From The Horizontal A n d T n e Vertical The fight between Hofstadt^ and Cenmer appears unwarranted, particularly in light of the fact that they are after different aspects of analogical reasoning.
 And C F H have in some sense been unfair in their criticisms of S M E .
 Their 1992 papCT is written as though S M T and approaches like it had completely missed what analogy was about Instead, they addressed a new issue in analogy, and likewise failed to appreciate the perspective S M T addresses.
 680 But what has happened here? Both explanations seem important to an understanding o( analogy, yet we are arguing that they are talking past one another.
 W e claim that this a result of the two different sets of perspectives and goals in considering analogy phenomena.
 This is best described using a spatial metaphor of horizontal and vertical po^pectives.
 O n the one hand, we have S M T , which looks at analogy from a horizontal perspective: S M T views analogy in it's variety of forms and psychological manifestations, over a variety of different comparison domains, and searches for the common mechanism(s) involved in all these cases.
 This perspective is Ukewise seen in S M E , which embodies the positive aspects of S M T by onploying explicit structuremoping and being a general mechanism for all kinds of possible comparison domains.
 HLP, on the other hand, looks at analogy from a vertical pCTspective: H L P views axialogy as a process from the bottom up; as a representationbuilding process based on lowlevel perceptual processes interacting with highlevel concepts.
 Copycat embodies the positive aspects of H L P by demonstrating how representations might be constructed, and by not depending on human handcoding once set up in it's microdomain.
 This met^hor also helps to make sense out of the criticisms that each theory has of the other in that we can now see what questions they don't answer.
 First, S M E does not have an answer for the handcoding problem.
 C F H and Mitchell are correct in that S M E does not account for a very compelling problem: where do the representations upon which mapping is performed come from? In light d this question, S M E appears artificial.
 Copycat, on the other hand, is constrained by domain specificity: it can only produce analogies in a limited letterdomain.
 And it is unclear as to how the Copycatstyle architecture can be extended to other, more psychologically plausible domains (Morrison, 1994).
 Thus, a similarly compelling problem is left unansw^ed with Copycat: H o w do we account for the ability to produce analogies between practically any 6omainl Both of these are daunting problems, and while each theory proposes to answer one, it has failed to captured the odier.
 Table 1 is a summary comparison of S M E and Copycat to highlight the two perspectives, what they are successful in explaining, and where they don't Conclusion W e are left with a key question: can the two problems above be solved and in a luiified way? As things stand now, it seems as though we are in a dilemma in that the attempts of S M T and H L P to model one aspect of analogy resulted in missing another.
 And this is particularly compelling when one considers the extent and complexity of each — these models and the theories behind them are among the most respectable cognitive science has to offer.
 And while they may not have gotten the whole picture, they do offer important perspectives of analogy phenomena.
 In spite of this dilemma, we do wish to keep the faith and continue to believe that a comprehensive theory of analogy does exist A comprehensive theory of analogy should be able to view analogy from all sides; it should be able to tell a complete story using both horizontal and vertical po^pectives; and it should be able to explain bow analogies are produced as well as understood, according to the same model (this issue is addressed in Morrison, 1994).
 While we do not have a theory to offer, we do think that we have added perspective to the "fight" that is taking place — perspective that gives us a deepo^ understanding of the theoretical terrain to be covered in a comprehensive theory of analogy, and what current approaches have to offer to such theory.
 Table 1: Summary Comparison of S M E and Copycat: Pros and Cons SME PROS: Employs explicit and welldefined structuremapping  if knowledge is structured (and we believe it is), then there must be some sort of structuremapping that takes place to link up baseknowledge to targetknowledge Based solidly on a robust psychological theory developed over almost two decades of empirical investigation Generally applicable to all domains of analogical comparison CONS: Handcoding  can't produce it's own representations.
 Thus, depends on work done by humans (or implausible separate representation module).
 Copycat PROS: In a vague way, captures the notion of representation construction  closer to novel representation production Once set up by humans in a specific domain (the letterdomain), it operates independently of humans CONS: Domain specificity  can only produce analogies in limited letterdomain References Chahners, D.
 J.
, French, R.
 M.
, & Hofstadter, D.
 R.
 (1992).
 Highlevel perception, representation, and analogy: A critique of artificial intelligence methodology.
 Journal of Ejqjerimental & Theoretical Artificial Intelligence A.
\%52\\.
 Falkenhainer, B.
, Forbus, K.
 D.
, & Centner, D.
 (1986).
 The structuremapping engine.
 In Proceedings of the American Association for Artificial Intelligence (pp.
 272277), Philadelphia.
 Falkenhainer, B.
, Forbus, K.
 D.
, & Centner, D.
 (1989).
 The StructureMoping Engine: algorithm and examples.
 Artificial Intelligence 41:163.
 Centner, D.
 (1980).
 The Structure of analogical models in science (BBN Tech.
 Rep.
 4451).
 Cambridge, M A : Bolt, Beranek & Nevmian.
 681 Centner, D.
 (1983).
 Struauremapping: A theoretical framewoik fw analogy.
 Cognitive Science 7:155170.
 Centner, D.
 (1989).
 The mechanisms of analogical learning.
 In Vosniadou, S.
 & Ortony, A.
 (Eds.
), Similarity and Analogical Reasoning (pp.
 199241).
 Cambridge: Cambridge University Press.
 Centner, D.
, Falkenhainer, B.
, & Skorstad, J.
 (1987, January).
 Metjq^or.
 The good, the bad, and the ugly.
 In Proceedings of the Third Conference on Theoretical Issues in Natural Language Processing (pp.
 155159).
 Las Cruces, NM.
 Centner, D.
 & Forbus, K.
 (1991).
 MAC/FAC: A model of similaritybased retrieval.
 In Proceedings of the Thirteenth Annual Conference of the Cognitive Science Society.
 Hillsdale, NJ: Lawrence Earlbaum Associates.
 Centner.
 D.
, & Imai, M.
 (1992).
 Is the future always ahead? Evidence for systemm^pings in understanding q)acetime metjqthors.
 In Proceedings of the Fourteenth Annual Conference of the Cognitive Science Society.
 Chicago, IL.
 Centner, D.
 & Landers, R.
 (1985, November).
 Analogical remindings: A good match is hard to fmd.
 In Proceedings of the International Conference on Systems, Man, and Cybernetics.
 Tucson, AZ.
 Cenmer, D.
, & Rattermann, M.
 J.
 (1991).
 Language and the career of similarity.
 In Gelman, S.
 A.
 & Byrnes, J.
 P.
 (Eds.
), Perspectives on thought and language: Interrelations in development.
 London: Cambridge UnivCTsity Press.
 Centner, D.
, Ratterman, M.
, & Forbus, K.
 (1993).
 The roles oi similarity in transfer.
 Separating retrievability bom inferential soundness.
 Cognitive Psychology 25: 524575.
 Hofstadter, D.
 R.
 (1984).
 The Copycat project: An experiment in nondeterministic and creative analogies (Memo 755).
 Cambridge, M A : MIT, Artificial Intelligence Laboratory.
 Hofstadter.
 D.
 R.
 & MitcheU, M.
 (1992).
 An overview of the Copycat project In Holyoak, K.
J.
 & Bamden.
 J.
 (Eds.
) Connectionist Approaches to Analogy, Metaphor, and CaseBased Reasoning (Norwood, NJ: Ablex).
 Hofstadter, D.
 R.
 & MitcheU, M.
, & French, R.
 M.
 (1987).
 Fluid concepts and creative analogies: A theory and its computer implementation.
 Technical report 10, Cognitive Science and Machine Intelligence Laboratoiy, University of Michigan, Ann Arbor.
 Hofstadter, D.
 R.
 et al.
 (1995).
 Fluid Concepts and Creative Analogies.
 New Yoric: Basic Books.
 Kotovsky.
 L.
 & Centner, D.
 (1990).
 Pack Light You will go farther.
 In Proceedings of the Second Midwest Artificial Intelligence and Cognitive Science Society Conference, (pp.
6072).
 Mitchell, M.
 (1990).
 Copycat A computer model of highlevel po'ception and conceptual slippage in analogymaking.
 Doctoral dissertation.
 University of Michigan.
 Mitchell, M.
 (1993).
 AnalogyMaking as Perception: A Computer Model.
 Cambridge: The MIT Press.
 MitcheU, M.
 & Hofstadter.
 D.
 R.
 (1990).
 The emergence of understanding in a computer model of concepts and analogymaking.
 Physica D 42:322334.
 Morrison.
 C.
 T.
 (1994).
 Analogy and Constructive Representation.
 Master's Thesis.
 Dept of Philosophy.
 SUNY Binghamton.
 Bingbamton, NY.
 682 W h y Semantics Lags Behind Phonology in W o r d Indentification Charles A.
 Perfetti 644LRDC University of Pittsburgh Pittsburgh, PA 15260 perfettiQvms.
cis.
pitt.
edu Li Hai Tan 640 LRDC University of Pittsburgh Pittsburgh PA 15260 tanievms.
cis.
pitt.
edu Sulan Zhang 641 LRDC University of Pittsburgh Pittsburgh P A 15260 Mara C.
 Georgi 645 LRDC University of Pittsburgh Pittsburgh P A 15260 sulanOvms.
cis.
pitt.
edu georgi@vms.
cis.
pitt.
edu Abstract Because meaning is both the common outcome and the typical goal of language processing, including reading, semantic processes have received a privileged position, especially in cognitive science accounts that emphasize semantic, goal driven components in language.
 Even in accounts of written word identification, a "lowlevel" process, it is typical to assume that semantic outputs are achieved with optional contributions of phonology.
 Our goal here is to present evidence for an alternative perspective, one that gives phonology a central rather than a peripheral, optional role in word identification.
 W e first briefly discuss a writing system comparison that is important to this perspective.
 W e then summarize recent published and unpublished research that gives definition to our conclusion that phonology is a central and universal component of word reading.
 Perfetti, Zhang and Berent (1992) proposed a Universal Phonological Principle (UPP) in reading, a set of three correlated principles concerning the role of phonology across writing systems.
 The central principle is that, in any writing system, encounters with printed words automatically lead to phonological activation.
 This activation includes phoneme constituents of the word and its pronunciation.
 W e focus here on the second principle: Writing systems constrain the details but not the inevitability of phonological processing.
 The UPP claims that all writing systems, regardless of orthographic depth, lead to phonological involvement, although not necessarily mediation.
 Chinese is an important test for the UPP.
 (The idea that writing systems constrain word reading was proposed in the Orthographic Depth Hypothesis of Frost, Katz and Bentin, 1987.
) Chinese writing is usually considered a logography, i.
e.
, a system in which the basic unit in writing associates with a unit of meaning (morpheme) in the spoken language.
 A pure logography would be controlled by a morphological principle, and reading would produce meaning without any reference to a word's phoneme constituents.
 In a pure logography, there is no letterlike unit; neither is there a syllablelike unit in the usual sense, making a logography in principle very different from both alphabetic and syllabary systems.
 The idea that Chinese is a pure logographic system.
 however, has come under critical scrutiny.
 DeFrancis (1989), for example, argues that the phonological component in Chinese writing has been underestimated by the simple logographic analysis.
 Phonetic elements were not as important in earlier Chinese but the writing system has evolved, according to DeFrancis, into a system that is dominated by compound symbols that carry both semantic and phonetic information.
 Such compound symbols consisting of two single characters comprise a substantial portion of Chinese characters (82%, according to Zhou, 1978).
 Zhou estimates that 3 9 % of these compounds contain a component with a pronunciation similar or identical to that of the compound, leaving 6 1 % with a pronunciation different from that of the compound, a condition of possible interference.
 Thus the value of the phonetic compound in ordinary reading is unclear at this stage of research on Chinese reading.
 However, the argument that there is a significant phonological component for the Chinese writing system is beyond dispute.
 Moreover, whether there is a role for character components in word identification is not central for our argument ~ which is that the retrieval of phonological word forms occurs as a routine part of Chinese reading.
 Chinese Reading: No Semantics without Phonology? The view that Chinese is a meaningbased logography has led to a corresponding idea about Chinese reading: The process is one of scripttomeaning.
 In this view, Chinese readers apply a visualtomeaning route in which phonology plays no role.
 However, recent evidence suggests a rather different view of reading Chinese, one in which skilled Chinese readers activate phonology as part of the reading process.
 Phonology in Chinese Text Reading The first point to make is that reading Chinese is not different from reading English in its use of phonology, once words have been identified.
 Earlier studies suggesting that Chinese readers show a reliance on phonological codes in memory (Tzeng, Hung, & Wang, 1977) and comprehension tasks (Tzeng & Hung, 1980), places reading Chinese in the same category as reading English, French, or Japanese.
 Phonological codes are activated in a working memory 683 http://pitt.
eduhttp://pitt.
edumailto:georgi@vms.
cis.
pitt.
edusystem in support of comprehension (Baddeley, 1979; Levy, 1977; Perfetti & McCutchen, 1982; Slowiaczek & Clifton, 1980).
 More recently.
 Zhang and Perfetti (1993) report evidence that confirms the functional working memory locus of phonological processes in Chinese text reading using tonguetwisters, sentences or paragraphs that repeat initial phonemes (Haber & Haber.
 1982; McCutchen & Perfetti, 1982).
 Phonology in Chinese Word Identification a n d Lexical Access According to the UPP, there should be a role for phonology at the earliest point permitted by the writing system.
 In a field that has long sanctioned a distinction between "prelexical" and "postlexical" phonology, our claim, instead, is that word identification in Chinese is "atlexical'.
 Chinese reading suggests, perhaps in a way that alphabetic writing systems do not, that "prelexical" vs.
 "postlexical" is a complex and perhaps a misleading question.
 More generally, all word reading events, including meaning access, involve word identification, and thus all word reading involves phonology.
 According to the UPP, there should be phonological activation as the character is actually identified.
 Evidence comes from the priming experiments of Perfetti and Zhang (1991), which primed a briefly presented target character with a briefly presented prime character.
 These experiments varied the duration of the character prime and exposed the target for 35ms under an average 5 0 % threshold.
 If the pronunciation of the prime is activated as it is recognized, it should be available to facilitate target identification.
 By 50ms of prime exposure, both semantic and phonological facilitation effects were found.
 Importantly, semantic effects were not found prior to phonological effects.
 In an experiment that assured the prime duration was sufficient for recognition (180 ms), very large phonemic effects (and smaller semantic effects) were found on naming times (Perfetti & Zhang, 1991; Exp.
 4).
 In these experiments, there has been no instance in which a semantic effect precedes or is larger than a phonological effect.
 The implication for word identification is that the phonological form of the word represented by the character is what is identified and that prior activation of that phonological form aids identification.
 The Time Course of Phonological and S e m a n t i c Activation From the research we have reviewed so far, we cannot be sure about the processes that occur during silent character reading when the reader is attending to meaning.
 If there is no semantics without phonology, we expect some evidence for it in a task that focuses on meaning.
 W e turn to two related aspects of this question: First, does phonological activation occur in a silent reading task in which phonology is not necessary and even detrimental? Second, what is the time course of activation of semantic and phonological information in single character word identification? If the identification of a word constitutes a highly cohesive binding of graphemic, phonological, and semantic information, neither phonological nor semantic components can be easily suppressed.
 Perfetti and Zhang (1995) exploited interference as a window on these questions.
 In one task, the synonym judgment task, subjects were presented with successive characters and asked to decide whether the second character had the same meaning as the first.
 Here we looked for phonological interference.
 Some of the second characters had the same pronunciation as the first character, while having no meaning similarity.
 (See Table 1 for materials.
) In the homophone case, the first character is pronounced [shi] and has the meaning "matter".
 The second character is also pronounced [shi] but has an unrelated meaning.
 The subject should say "No" to this pair of characters because they are not similar in meaning.
 In the corresponding control characters, the second character is again [shi] but now is completely unrelated to the first character.
 Time to reject homophone pairs could be compared with control pairs.
 If subjects can ignore the pronunciation of the characters in making a meaning judgment, then the times to reject homophone foils and control foils should not differ.
 However, if phonological activation cannot be bypassed, then the fact that the name of the two characters is the same would interfere with making a meaning judgment.
 The second task, homophone judgment, used the same characters, but required the subject to make a phonological judgment.
 Here, the subject saw two successive characters and judged whether the second character had the same pronunciation as the first.
 The second character was either a control, having no similarity to the first character, or a synonym.
 (These materials are also in Table 1.
) With the change in task, the correct responses are reversed.
 What was a "No" trial for a meaning comparison is now a "Yes" trial for a pronunciation comparison; what was a "Yes" trial for meaning is now a foil trial for pronunciation.
 The control trials are the same.
 Again the logic is that if semantic information can be bypassed in judging phonology, then rejection times for control and synonym foils should not differ.
 The important result of this basic interference situation is that native Mandarin speakers living in Pittsburgh showed phonological interference when asked to make a semantic judgment.
 They also showed semantic interference when asked to make a phonological judgment, but this effect was smaller (Exp.
 1) and later occurring (Exp.
 2).
 The more general question is the time course of semantic and phonological activation.
 In the interference paradigm, the standard view of Chinese reading predicts only semantic interference.
 This standard view, the meaningwithoutphonology hypothesis, is disconfirmed by the phonological interference results just described.
 There is a weaker interpretation of the standard view, however, on which it 684 Table 1: Examples of materials from Pertetti and Zhang, 1995.
 Pronunciation Translation Correct response Synonym Judgment Homophone Judgment Homophone Control Synonym m n m ^ « m [Shi] [Shi] [qing] [Shi] [kan] [Shi] matter see clear see look at see N O N O YES YES N O N O assumes only that semantics is privileged (firstaccessed) rather than the only information accessed.
 This retreat of the standard view implies the meaningfirst hypothesis.
 Semantic information is available independently of the character name and precedes phonological information.
 Our contrasting view is the phonology plus meaning hypothesis, noncommittal on timecourse but clearly asserting that there should be no semantics without phonology.
 This time course question, in the interference paradigm, is tested by varying the S O A between the first character and the second character.
 At very short SOAs, there is little time to get full information from the first character, so the subject should be selective if possible.
 If a semantic judgment is required, then the subject should go for semantic information.
 Perfetti and Zhang (1995) varied S O A between 90 and 260 ms.
 For the shortest duration, this means the first character was viewable for only 80 ms, plus 10 ms ISI, prior to the presentation of the second character, a duration at the margins of correct character identification.
 Is there some duration at which only semantic interference but not homophonic interference is obtained? The answer is no.
 In the meaning judgment task, homophone rejection took longer than control foil rejection at each SOA.
 Thus, even at 90 ms there is phonological interference.
 However, in the phonological judgment task, meaning interference did not appear until 140 ms.
 Combining the results allows estimates of time course functions from 90 to 310 SOA.
 Figure 1 shows a phonological interference function, measured in the synonym judgment task, and a semantic interference function, measured in the homophone judgment task.
 Phonological interference is the difference between homophones and controls, and semantic interference is the difference between semantic and control foils.
 As can be seen, semantic interference emerges later than phonological interference.
 With due caution concerning acrosstask comparisons, the time course data are incompatible with both the meaningwithoutphonology and the meaningbeforephonology views; they are consistent with the phonology plus meaning hypothesis.
 Phonological a n d Se m a n t i c Interference lnt»rl«r«nc* (In mt) Stknukw Onist Aayndirony (In ms) ' »mnu\Vo •*PkonologloK Figure 1: The time course of semantic and phonological interference.
 TimeCourse 2: Semantic Vagueness W e turn finally to a study that helps illuminate why phonological activation does not lag behind semantic activation.
 The heart of the argument is that the relationship 685 between form and meaning is more contextdependent and more variable than the relationship between form and form.
 Word identification in both English and Chinese provides access to various kinds of information, in particular access to a specific phonological object and something about meaning.
 But there is a striking gap between "phonological object" and "something about meaning".
 The phonological form of a word is well specified; the meaning of a word is not.
 Word meanings can be reasonably considered as ranges of values that are filled in by contexts.
 Not only are words ambiguous in meaning, the interpretations of their potential meanings depend on context.
 For example, safe has a range of meanings: Noun.
 A place to keep valuables.
 Adjective 1.
 being free from harm.
 Adjective 2.
 Baseball: Judged to have reached base ahead of an attempted putout.
 These three meanings are not unrelated, so one might argue for some economy of semantic organization, compared with word forms that are fully polysemous with unrelated meanings.
 So much the better for our argument, which is that, even for a word like safe, which appears to have a single meaning with extended referential possibilities, there is not a single reliable semantic value that is a good candidate for a contextfree meaning retrieval.
 What kind of lexical process "extracts" just the right meaning from a word? The literature on word disambiguation oscillates between a view that selective access of word meaning is impossible and one that allows at least dominant meanings of ambiguous words to be preselected by a context.
 (See Simpson, 1994.
) Evidence usually depends on responses to single words that are associates of one or the other meaning of the ambiguous word.
 Although such associations do not constitute the meaning of a word in any deep sense, they are what is detected within a few millliseconds of the exposure of a word in these priming experiments.
 So for safe, associates such as "money", "jewels", "out", etc.
 might appear, either selectively or all at once.
 This glut of meaning associates stands in strong contrast to the single phonological form connected to safe.
 The phonological object /seyf/ isn't just an "associate" oi safe, it is its unique identity.
 Reading processes take advantage of this reliable form rather than merely accepting the vagaries of meaning.
 Phonological form thus becomes the foundation for whatever meaning comes along.
 This may be as true in Chinese as it is in English, according to the UPP.
 In recent research.
 Tan (1994) demonstrated the importance of semantic vagueness on Chinese word identification in a masking paradigm.
 The basic idea is that isolated word meaning varies from relatively precise to relatively vague.
 That is, the lexical semantics of words with vague meanings are more context dependent than are words with precise meanings.
 Our extension of this meaning vagueness hypothesis employed a brief exposure priming task.
 Subjects, native Chinese speakers, were asked to name Chinese characters (single word compounds) that were preceded by primes presented very briefly for between 40 and 110 ms.
 Primes were of five types.
 A baseline control number sign (#), an unrelated word, a graphically similar word, a semantically similar word, and a phonologically similar word.
 The basic question concerned time course: Given our evidence for rapid phonological and somewhat slower semantic activation in an interference paradigm, could we observe the same time course effects in brief exposure priming and would we find that the time course of semantic priming depended on the semantic precision of the primes? The results of the exf)eriment are shown in Figure 2 as difference scores, the difference between each mask type and the numbersymbol baseline.
 The graphic prime produced a pattern of facilitation followed at longer S O A s by inhibition which was eliminated by the longest SOA.
 Most important, we see a replication of the faster activation of phonological information over semantic information, and a difference between precisemeaning primes and vaguemeaning primes.
 For precisemeaning primes the time course of semantic and phonological effects replicates what we found in the interference experiments: Phonological effects were found by 43ms, but semantic effects were delayed by 14ms.
 However, for vaguemeaning primes, the lag of semantic activation was further increased by about 28ms.
 Thus we have clear evidence that semantic information sufficient for facilitation effects depends on the precision of meaning associated with the prime.
 If we can generalize this observation across paradigms, we have a general principle that accounts for a timecourse difference between the activation of phonological and semantic information: Phonological activation precedes semantic activation because it is bound more reliably to printed symbols (formform binding) than is semantic information (formmeaning binding.
) W e expect this to be true across writing systems, because it depends, not on details of lexical access, but on a functional analysis of the role of phonology in word understanding.
 Semantically V a g u e Primes 1M 100 •rMKIS 07 U SOA (in tM) Figure 2a: The difference scores for semantically vague primes.
 686 Semantically Exact Primes 100 100 07 U 80A (In tns) ^•rm»lil« •Hi»o»»i«nlo KlHwirtta ^Ui«l«l»d Figure 2b: The difference scores for semantically exact primes.
 Acknowledgements This research was partially funded by a grant to the first author from the National Science Foundation (SBR9223125).
 References Baddeley, A.
D.
 (1979).
 Working memory and reading.
 In P.
A.
 Kolers, M.
E.
 Wrolstad, & H.
 Bouma (Eds.
), Procession of visible language.
 Vol 1 (pp.
 355370).
 New York: Plenum Press.
 DeFrancis, J.
 (1989).
 Visible speech: The diverse oneness of writing systems.
 Honolulu: University of Hawaii.
 Frost, R.
, Katz, L.
, & Bentin, S.
 (1987).
 Strategies for visual word recognition and orthographical depth: A multilingual comparison.
 Journal of Experimental Psychology: Human Perception and Performance, 13, 104115.
 Haber, L.
R.
, & Haber, R.
N.
 (1982).
 Does silent reading involve articulation? Evidence from tonguetwisters.
 American Journal of Psychology, 95, 409419.
 Levy, B.
A.
 (1977).
 Reading: Speech and meaning processes.
 Journal of Verbal Learning and Verbal Behavior, 16, 623638.
 McCutchen, D.
, & Perfetti, C.
A.
 (1982).
 The visual tonguetwister effect: Phonological activation in silent reading.
 Journal of Verbal Learning and Verbal Behavior, 21, 672687.
 Advances in basic research and practice (pp.
 237269).
 N e w York: Academic Press.
 Perfetti, C.
A.
, & Zhang, S.
 (1991).
 Phonological processes in reading Chinese characters.
 Journal of Experimental Psychology: Learning.
 Memory, and Cognition, 17, 633643.
 Perfetti, C.
A.
, & Zhang, S.
 (1995).
 Very early phonological activation in reading Chinese.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 21, Perfetti, C.
A.
, Zhang, S.
, & Berent, L (1992).
 Reading in English and Chinese: Evidence for a "universal" phonological principle.
 In R.
 Frost & L.
 Katz (Eds.
), Orthography, phonology, morphology, and meaning (pp.
 227248).
 Amsterdam: NorthHolland.
 Simpson, G.
B.
 (1994).
 Context and the processing of ambiguous words.
 In M.
A.
 Gernsbacher (Ed.
), Handbook of psycholinguistics (pp.
 359374).
 N e w York: Academic Press.
 Slowiaczek, M.
L.
, & Clifton, C.
 (1980).
 Subvocalization and reading for meaning.
 Journal of Verbal Learning and Verbal Behavior, ̂ 9, 573582.
 Tan, L.
H.
 (1994).
 The activation of early phonological code before access to meaning in written Chinese.
 Unpublished doctoral dissertation, University of Hong Kong.
 Tzeng, O.
J.
L.
, & Hung, D.
L.
 (1980).
 Reading in a nonalphabetic writing system: Some experimental studies.
 In J.
F.
 Kavanagh & R.
L Venezky (Eds.
), Orthography.
 reading and dyslexia.
 Baltimore: University Park Press.
 Tzeng, O.
J.
L, Hung, D.
L.
, & Wang, W.
 SY.
 (1977).
 Speech recoding in reading Chinese characters.
 Journal of Experimental Psychology: Human Learning and Memory.
 3, 621630.
 Zhang, S.
, & Perfetti, C.
A.
 (1993).
 The tongue twister effect in reading Chinese.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 19, 10821093.
 Zhou, Y.
G.
 (1978).
 To what degree are the "phonetics" of presentday Chinese characters still phonetic? Zhongguo Yuwen, 146, 172177.
 Perfetti, C.
A.
, & McCutchen.
 D.
 (1982).
 Speech processes in reading.
 In N.
 Lass (Ed.
).
 Speech and language: 687 T h e Processing of Associations versus the Processing of Relations and S y m b o l s : A Systematic Compariso n Steven Phillips Department of Computer Science University of Queensland Brisbane 4072 Australia stevep@etl.
go.
jp G r a e m e S.
 Halford Department of Psychology University of Queensland Brisbane 4072 Australia gsh@psych.
psy.
uq.
02.
au William H.
 Wilson School of Computer Science & Engineering University of New South Wales Sydney 2052 Australia bi1lw@cse.
unsw.
edu.
au Abstract A mathematical basis is proposed for the distinction between associative and relational (symbolic) processing.
 Associations can be contrasted with relations in terms of ordered pairs versus general ordered Ntuples, and unidirectional access versus omnidirectional access.
 Relations also have additional properties: they can exhibit predicateargument bindings, they can be arguments to higherorder structures, and they can participate in operations of selection, projection, join, union, intersection, and difference.
 Relations can be used to represent structures such as lists, trees and graphs, and relational insUnces can be thought of as propositions.
 Within neural net architectures, feedforward networks can be identified with associative processing, and tensor product networks with relational processing.
 Relations have the essential properties of symbolic processing; flexibility, accessibility, and utility for representing complex data structures.
 Introduction We propose a mathematical basis for the distinction between associative and relational processing.
 W e suggest this distinction captures much of the meaning contained in the distinction between traditional associationism and symbolic processing, and has implications for neural network modelling of psychological tasks.
 W e illustrate our argument using the balancescale (which balances when the product of weights and distances on the two sides are equal, that is when W ] Di = W f Dr).
 A co m m o n form of assessment has been to ask participants to predict the balance state (whether the beam will balance, or which side will go down) when various combinations of weights are placed at various distances from the fulcrum (Siegler, 1981).
 Other assessments require participants to specify the weight or distance on one side that will balance a particular combination of weight and distance on the other side (Surber & Gzesh, 1984) To demonstrate understanding, a participant must be able to retrieve any variable, given the rest (e.
g.
 given W ] , Di, W j , and the outcome B A L A N C E it should be possible to specify Dr; given W i , Dj, W j , and Dr.
 it should be possible to specify the state of balance).
 Thus w e say that access to a relational concept should be onviidirectional.
 A n example of an association would be a rabbit running on seeing a/ojr, that is; fox » run.
 It is a link between two elements, fox and run.
 It is unidirectional, because running does not automatically activate a representation of fox.
 Associative Versus Relational Processing In this section, we give an abstract description of the associative and relational modes of processing.
 Associative Processing Data Structures In an associative system we assume the existence of a set of symbols S = {ai, a2, •.
.
, a^}.
 The primary data structure of an associative system is a set of pairs of symbols A, denoted: A = {(ai,aj) I ai.
aj e S and ai cues aj) Operations There are three basic operations in an associative system: • Cue  takes the symbol ai and returns its associated symbol aj, from the set of pairs in A.
 Fcue(ai) » aj • Form association  takes two symbols ai and aj and adds the pair to the set A to form a new set A".
 Fassoc(ai.
aj) > A' = A u {(ai,aj)} • Delete association  takes a pair and removes it from the set A to form a new set A'.
 FdeLa(ai^j) > A' = A \ {(ai,aj)} The basic symbols may themselves be composed of other symbols (i.
e.
, they are not necessarily atomic).
 In this way, associations may be formed between three or more basic symbols, or between complex representations.
 Relational Processing Data structures A relational system consists of a set of relations (Ri) where each relation Ri (of arity, i.
e.
 number of components, n(i)), corresponds to a set of n(i)tuples: Ri = l(xi Xn(i)) € SiiX.
.
.
xSin(i) I Ri(xi Xn(i)) holds) For example, if Si = {john, mary, tom}, and S2 is the set of natural numbers, then a relation hasage on 81x82 might be written as the set of pairs {(john,24), (mary, 22), (tom,3)}.
 A relation can also be conceptualised as a table.
 For example, the relations "hasage" and "loves" may be represented by the following tables: 688 mailto:stevep@etl.
go.
jpmailto:gsh@psych.
psy.
uq.
02.
aumailto:bi1lw@cse.
unsw.
edu.
auPredicate hasage hasage hasage Predicate loves loves loves Objeci John mary torn Person John John mary Years 24 22 3 Objeci niary sue torn It is redundant to store the predicate name as a separate column in the table, however, we have adopted this convention to allow for situations in which the arguments act as cues for accessing the predicate.
 Each row of the table is a tuple from the set which formally constitutes the relation.
 It is also convenient to write a relation in terms of its attributes  that is, the types of the arguments it takes.
 Thus, R<s> denotes a relation R with attribute sequence s = Ai An.
 For example, the binary relation 'hasage' can be identified as: hasage<(^ject,years>.
 Relations are a general purpose data structure, and in fact can be used to represent other commonly used data structures, such as lists, trees and graphs.
 For example, the list of objects Li = [john, mary, torn] can be represented by the relation: islistof<list, head, tail> = ((Ll, john, L2), (L2.
 mary, L3), (L3, torn, nil)}.
 (Here nU is a constant representing an empty list.
) Furthermore, relational instances (i.
e.
, rows of a table) have an assigned truth value (i.
e.
, T R U E ) , and so can be thought of as propositions.
 For example, largerthan(whale,man) is a proposition that is T R U E .
 Operations We provide informal definitions of relational operators: • Fseiect" given a relation and one or more components, returns the row(s) with those components.
 Example 1: FseiecKhasageJ>erson=tom) * (tom3).
 * Fproject " given a relation and one or more attributes (column names), returns those columns of the table.
 Example 2: Fproject(loves, Person) » (john, john, mary}.
 • Fjoin  takes two tables and returns a new table joined at common components in specified columns.
 Example 3: Fjoin could be used to "paste together" the relation hasage, defined above, with a relation hasheight = lOohn, 175), (mary, 165), (tom.
95)} (where the second component is height in centimetres), joining at the Person column, to produce a new relation ageandheight = {(John, 24, 175), (mary, 22, 165), (torn, 3, 95)}.
 Example 4: Consider the relation smallerthan<animall, animal2> = {mouse, cat), (cat, dog), (dog, horse)}.
 A more complicated form of Fjoin could be used to "paste together" one instance of relation smallerthan, joining at the animal2 column, with another instance of the same relation smallerthan, joining at the animall column, to produce a new relation (call it "muchsmallerthan") = {(mouse, dog), (cat, horse)}.
 This example composes the relation with itself, much as in transitive inference.
 In addition, there are setlike operators, Funion' Finterseclion.
 and Fdifference.
 which form the settheoretic union, intersection and difference of two relations with the same attribute lists, and operators Fadd_r.
 Fdel_r.
 a"d Fupdate.
r.
 for adding, deleting, and updating relational instances (Codd, 1990).
 Comparison Between Associative and Relational Modes Both associanve and relational systems utilise links between component symbols to construct more complex symbols.
 However, beyond this similarity there are significant differences in their processabiJity.
 Compositionality: Associations are limited to pairs of symbols, whereas relations can be between arbitrarily many symbols (including pairs).
 Furthermore, associations do not recognise a predicate (a symbol for the relationship between other symbols).
 Relations on the other hand are predicated.
 This is a crucial distinction between associations as implicit representations (representations that are not available to other processes), and relations as explicit representations (relations that are available to other processes).
 The predicate is the explicitation of links between symbols.
 Because a relation is explicitated via the predicate symbol, relations are available as arguments to other relations.
 Associations may cue other associations through chaining, but they are not themselves available for association.
 Relations, on the other hand, can exist between other relations.
 For example, the relation "because" can take the unary relation "cried" and the binary relations "kissed" as arguments: because(cried(Tom), kissed(JohnAlary)).
 Directionality: Associative systems are unidirectional: the first component can cue the second, but not the reverse.
 Relations, however, are in general omnidirectional.
 Any subset of components can be used to access the remaining components.
 The number of returned relational instances will, of course, depend on the uniqueness of the supplied components.
 Structure sensitivity: Associative systems are structurally very weak.
 A n associative system can be conceptualised as a single table of two columns.
 Relational systems, by contrast, are stronger structurally.
 Components are accessible purely by their roles.
 Furthermore, new relations can be created on the basis of structural operations.
 A relation R can be used to generate its inverse by using the project operator (i.
e.
, R"^= Fproject(R<Al,A2>, A 2 , Al)).
 For example, > (greaterthan) can be mapped to < (lessthan), by swapping arguments, without having to learn an entirely new table of associations.
 In other words, relational systems have the capacity to create virtual tables, thus circumventing extensive retraining.
 Implications The data structures and operations defined in the previous section have a number of implications in terms of resources (both time and space) for models utilising these two modes of processing.
 Suppose we a relation R<subject, relation.
 689 object> includes the concepts "John loves Mary" and "Sue loves Tom", from which there is sufficient information to correctly answer questions such as: "Who loves Mary?"; W h o does Sue love?"; and "What is the relationship between Sue and Tom?".
 A n associative system, where the only complex data structure is a pair, must construct new symbols in order to correctly answer these questions.
 For example, (lovesMary, John), (Suebeloved, Tom), and (SueTomrelation, loves).
 Each question is matched against the first component of each pair.
 The pair with the closest match triggers the second component resulting in the correct answer.
 In fact, each concept requires three associations, one for each possible response (e.
g.
, loves, John, Mary).
 A relational system, using the same two concepts, only requires a single table with two entries: (lovesjohn, Mary), and Ooves.
Sue, Tom).
 The select and project operators are sufficient to extract any combination of components.
 For example, Fproject( Fselect(R.
 <relation=loves,object=Mary>), subject) = John; Fproject( FselectO^.
 <(subjectJohn),(object,Mary)>), relation) = loves.
 In the relational case, only one entry per concept is required.
 Thus, a relational system uses less space than an equivalent associative system.
 However, the associative system only makes one match to the lefthand side of each pair, whereas the relational system must align the input cues with the appropriate relational components.
 The reduction in space is at the expense of additional processing required to perform some sort of structural alignment in the relational system.
 The flexibility of relational operators relates to a further implication which is generalisation.
 Suppose we have the concept: "a whale is larger than a horse", which implies the related concept "a horse is smaller than a whale".
 In an associative system both concepts require separate learning steps (i.
e.
, use of the Fassoc operator).
 The relational system, by contrast, need only be trained on the first instance.
 Since the inverse relation can be constructed dynamically via the project operator, it is not necessary to have also been trained on the second concept for subsequent processing.
 Thus, relations have a greater degree of genCTalisation.
 Neural Network Implementations This section suggests neural network architectures that can readily be used to implement systems with similar properties to the associative and relational systems that we have described in the preceding section.
 Of course, neural network architectures may be of enormous variety, and we do not mean to suggest that these are the only N N architectures that match associative/relational systems (see for instance Hinton (1988)).
 Feedforward networks (FFN) FFN (for example, Rumelhart, Hinton, & Williams.
 1986) have two modes of operation: (1) processing mode  input activations are prc^agated throughout the network resulting in output activations; and (2) learning mode  error signals are propagated throughout the network resulting in changes to connection weights.
 The first mode corresponds to the Fassoc operator.
 The network returns a vector which is some (possibly nonlinear) combination of matched fust argument vectors.
 The second mode corresponds to the ^assoc and Fdei_a operators by adding/deleting new inputoutput pairs encoded as weighted connections.
 FFNs have demonstrated generalisation in the sense that component symbols can be brought together to form a new symbol at the hidden layer of units.
 It is not necessary for the network to be trained on all combinations (see, for example.
 Phillips & Wiles, 1993).
 However, this form of generalisation is different from generalisation to all functions implied by a relation.
 A FFN, in general, cannot demonstrate this degree of generalisation and therefore is not a relational processor.
 To illustrate this point, consider the simple case of representing and processing the following binary relation: R 2 = |(a,b)).
 Derivable from this relation are two functions: fi(a) = b, and f2(b) = a.
 To completely represent R2, an F F N must implement the second order function: F(fi,a) = b; F(f2,b)=a.
 For this simple relation R2, the codomain of F can be completely determined by the second arguments (i.
e.
, a and b) only.
 Dropping the first arguments for simplicity, the F F N must implement the function: F(a) 4 b; F(b) ^ a.
 Since, in general, there is no similarity between a and b, the FFN must be trained on both instances of the function F before the network is guaranteed to implement F, in the sense of approximating F at abovechance level over repeated trials, and therefore, representing R2.
 Hence, a standard F F N implementation of relational representations necessitates being trained on all implicated functions.
 The second crucial point is that the relationship between component symbols is encoded as weighted connections and activation functions between groups of units.
 These weights (encodings) are, in general, not available to other processes within the FFN, although they may be analyzed via external processes such as cluster analysis or principal components analysis.
 In other words, the predicate (i.
e.
, the name for the set of pairs) is implicit to the system, not explicit as in a relational system.
 The properties of unidirectionality and implicit predication identify the FFN as an associative system.
 So FFNs can be used to implement an association in a nahiral way.
 Tensor Networks (TN) In a tensor network, predicate and arguments are bound together via an organisation of unit connectivity that implements the outer product operator (Halford, Wilson, Guo, Gayler, Wiles, & Stewart, 1994), which contrasts with Smolensky's (1990) use of the tensor where role and filler components are bound together via the outer product.
 The arguments are supplied as inputs, and weights are updated as the outer product of the two inputs.
 This allows for either a or b, applied to the right set of input units to 690 map to the other vector (by implementing the inner product operator).
 Mathematically, the learning process can be thought of as a function TL (for tensor learning), which, given a lensor network F and (say) a pair to leam.
 (a.
b).
 returns a modified version F of F that "knows*" the pair (a.
b): TL(F, (a.
b)) > F.
 where F(a, J » b.
 F"L,b) > a.
 The important point is that T need only be applied once to represent both implicated functions.
 Thus, at one crucial point the tensor network operates in the relational mode of processing.
 Secondly, since the predicateargument bindings can be explicitly represented as an activation tensor, this tensor can also be used as an argument to other tensors (via the outer product), thereby implementing relations between relations.
 Thus, the properties of omnidirectionality and generalization to implicated functions identifies the tensor network as an implementation of a relational system.
 Psychological tasks McClelland (1995) has modelled human performance on the balance scale as a threelayered network.
 There are input units which code the weights and distances on the left and right, a hidden layer, and output units which code the balancestate.
 The model gives a good fit to human performance in predicting the balance state, and captures the important torque difference effect (the size of the difference in torque between left and right affects judgment).
 However the model computes only one function: given W], Di, Wr and Dj it computes the balancestale.
 The balance scale can also be represented as a tensor product of five vectors representing the balance state, and each of the input variables, Wi, Di, W^, Dj (Halford, 1993).
 With this representation, any variable can be output, given the remaining variables as input (given any four of Wj.
 Di, Wf, Dr and balancestate, the remaining variable can be determined).
 This model is relational, and gives omnidirectional access, whereas the threelayered net is associative, and gives unidirectional access.
 The threelayered network does not represent human understanding of the balance scale, because we would be reluctant to attribute complete understanding to a person who could compute only one function in this situation.
 There are of course other considerations which favor the feedforward network model (e.
g.
 simulating the torque difference effect), and we would not contend that either model is necessarily superior at this stage.
 However the example neatly illustrates an important difference between associative and relational models of cognitive tasks.
 Conclusion Relations capture many of the properties of symbolic thought.
 Whereas associations are unidirectional, access to relations is omnidirectional, and so relations have the flexibility characteristic of symbolic thought.
 There are predicates explicitly representing relations, making them accessible to other cognitive processes, whereas there is no explicit symbol for an associative link.
 Relations can represent symbolic structures such as propositions, lists.
 trees and graphs.
 W e have argued that feedforward networks can be used in a natural way to implement associative modes of processing, and thai relational modes of processing can be implemented using tensor product networks.
 We have characterized the difference between associations and relations and their processing in lerms of mathematical properties, and linked each to suitable neural network architectures, and psychological tasks.
 References Codd, E.
F.
 (1990).
 The Relational Model for Database Management: Version 2.
 AddisonWesley.
 Halford, G.
S.
 (1993).
 Children's understanding: the development of menial models.
 Hillsdale, N.
 J.
: Erlbaum.
 Halford, G.
S.
, Wilson, W.
H.
, Guo, J.
, Gayler, R.
W.
, Wiles, J.
, & Stewart, J.
E.
M.
 (1994).
 Connectionisl implications for processing capacity limitations in analogies.
 In K.
 J.
 Holyoak & J.
 Barnden (Eds.
), Advances in connnectionist and neural computation theory.
 Vol.
 2: Analogical connections (pp.
 363415).
 Norwood, NJ: Ablex.
 Hinton, G.
E.
 (1990) Mapping partwhole hierarchies into connectionist networks.
 Artificial Intelligence 46, 4775.
 McClelland, J.
L.
 (1995).
 A connectionist perspective on knowledge and development.
 In T.
 Simon & G.
 S.
 Halford (Eds.
), Developing Cognitive Competence: New Approaches to Cognitive Modelling.
 Hillsdale, NJ: Erlbaum.
 Phillips, S.
, & Wiles, J.
 (1993).
 Exponential Generalizations from a Polynomial Number of Examples in a Combinatorial Domain.
 In Proceeedings of the International Joint Conference on Neural Networks, (pp.
 505508).
 Nagoya.
 Japan: Rumelhart, D.
E.
, Hinton, G.
E.
, & Williams, R.
J.
 (1986).
 Learning internal representations by error propagation.
 In D.
 E.
 Rumelhart & J.
 L.
 McClelland (Eds.
), Parallel Distributed Processing: Explorations in the Microsiructure of Cognition (pp.
 318362).
 Cambridge: MIT Press.
 Siegler, R.
 S.
 (1981).
 Developmental sequences within and between concepts.
 Monographs of the Society for Research in Child Development, 46, 184.
 Smolensky, P.
 (1990).
 Tensor product variable binding and the representation of symboUc structures in connectionisl systems.
 Artificial Intelligence.
 46(12).
 159216.
 Surber, C.
 F.
, & Gzesh, S.
 M.
 (1984).
 Reversible operations in the balance scale task.
 Journal of Experimental Child Psychology.
 38, 254274.
 691 A Visual Routines Based M o d e l of G r a p h Understanding Yusuf Pisan The Institute for the Learning Sciences Northwestern University y  p i s a n @ n w u .
 e d u Abstract We present a model of graph understanding and describe our implementation of the model in a computer program called SKETCHY.
 S K E T C H Y uses a combination of general graph knowledge and domain knowledge to describe graphs, answer questions, perform comparative analyses, and detect contradictions in problem solving assumptions.
 S K E T C H Y has generated reasonable graph summaries for 65 graphs from multiple domains.
 SKETCHY illustrates the robustness of our model of graph understanding.
 I n t r o d u c t i o n Understanding diagrams is an important part of human cognition, requiring integration of perceptual information and conceptual knowledge.
 Diagrams are used to solve problems, to give explanations, to summarize information and to represent spatial relations.
 Diagrams serve both as devices to aid in visualization of the situation and as shortterm fast access memory devices for holding information (Larkin & Simon, 1987).
 Diagrams have been successfully integrated with computer programs to explain complex mechanical and dynamic systems (Forbus, Nielsen & Fallings, 1991; Kim, 1993).
 Diagram comprehension requires being able to identify objects, determine the relevant features for a particular problem and map the graphical features to the domain.
 A graph is a specialized form of diagrammatic representation.
 Previous psychological research (Gattis & Holyoak, 1994; Pinker, 1990; Schiano & Tversky, 1992) shows that graphs form a symbolic system different than pictures with their own set of symbols and rules.
 Different graph formats emphasize different relationships between variables.
 For instance, pie graphs are used to show percentages, bar graphs and step graphs to show relative amounts, scatter plots to show trends in data and line graphs to show continuous changes.
 In this paper, we only consider line graphs.
 W e present a model of graph understanding and describe our implementation of the model in a computer program called S K E T C H Y .
 S K E T C H Y uses a combination of general graph knowledge and domain knowledge to describe graphs, answer questions, including comparative analyses, and detect contradictions in problem solving assumptions.
 S K E T C H Y has generated reasonable interpretations for all the graphs in a college level thermodynamics textbook (Whalley, 1992) as well as interpretations for a number of graphs from economics (Ekelund & ToUison, 1986).
 Section 2 presents our model of graph understanding.
 Section 3 gives examples from S K E T C H Y , Section 4 discusses relevant work on graphs in psychology and vision and Section 5 describes possible extensions to the model and to the computer program S K E T C H Y .
 A Model of Graph Understanding Understanding graphs is a subset of the general problem of understanding diagrams.
 As such, graph understanding requires reasoning about spatial properties and relations and interpreting them in conceptual terms.
 Unlike general diagrams, graphs are composed of a small set of primitives (axes, lines, points, areas and labels), which simplifies object recognition.
 In a graph, points, lines and areas represent conceptual relationships in the domain.
 By characterizing the possible relationships among graph objects, we have constructed a model of graph understanding that is not tied to a specific domain.
 Conceptual Visual Routines Domain Translator GRAPH Questions & Answers Domain owledg Knowlecfee Figure 1: Architecture for graph understanding Figure 1 shows the architecture for graph understanding.
 Conceptual questions are constructed using the vocabulary of the domain that the graph is about.
 The domain translator uses general graph knowledge and domain specific knowledge to convert the questions into graphical relations.
 Visual routines take graphical relationships as their input, inspect the graph to gather the necessary information and return the information to the domain translator.
 Depending on the results the domain translator might initiate other visual routines to answer the question.
 When all the necessary information is obtained from the graph, the domain translator converts the graphical relationships into the vocabulary of the domain and generates an answer to the question.
 This paper examines the information processing necessary for graph understanding.
 W e ignore the problem of recognizing 692 mailto:ypisan@nwu.
eduan image as a specific type of graph (Pinker, 1990) and how visual routines can be implemented (Ullman, 1984) as these problems have been addressed by other researchers.
 D o m a i n Translator T w o kinds of knowledge are needed when translating a question from conceptual terms to graphical relations: general graph knowledge and domain specific knowledge.
 For example, to answer the question "When is S U P P L Y equal to D E M A N D ? " the domain translator first needs to identify what objects are being referred to by S U P P L Y and DEM A N D .
 The graph labels serve as the necessary semantic information connecting the graph objects to the concepts in the domain.
 The domain translator initiates visual routines which inspect the graph to find the objects with labels S U P P L Y and D E M A N D .
 If no objects with those labels are found, domain knowledge is used to connect S U P P L Y and D E M A N D to the graph objects present.
 Graph conventions make up an important part of general graph knowledge.
 W h e n there are no scales on the axes, lines going up and to the right are interpreted as having a positive slope and signifying that variables on the axes are qualitatively proportional to each other.
 Steeper lines are interpreted as showing relations where the variable represented on the Y axis is increasing faster.
 T w o regions with equal areas are interpreted as being equal in magnitude.
 Although domain specific knowledge can override graph conventions, graphs in most domains follow graph conventions closely.
 As a result, general graph knowledge can be applied to new domains to produce reasonable graph interpretations even when there is very little or no domain knowledge.
 General graph knowledge also guides in identifying the important features of a graph.
 A n image can be described in an infinite number of ways, so people use heuristics for summarizing graphical information, some general and some specific to task or domain.
 S o m e of the heuristics that we have observed people to use (and are implemented in S K E T C H Y ) are: • Only include information for objects with labels.
 • Include coordinates of labeled points if the axes have scales.
 • If a point is on a line or on the border of an area, include this information.
 • Include information about any qualitative changes in line slopes and describe each qualitative region separately.
 • If lines intersect, include this in the graph description.
 • Mention changes due to modifications.
 Each line in a graph represents a different relationship between the variables on the axes.
 For example, the supply line represents how the amount produced increases with increasing prices and the demand line represents how the amount demanded decreases with increasing prices.
 Intersection of two lines represents a point of equality between two relationships, often representing important values in the domain, and is always included in graph summaries.
 In the supply and demand example, the intersection point represents the equilibrium point for the market determining the current price.
 Qualitative changes in line slopes are included in the summary since a change in line direction represents a change in the type of relation between the variables.
 Points usually represent important domain specific values and arc included in the graph summary.
 Graphs provide a natural way of performing comparative analysis (Weld, 1990) by combining qualitative and quantitative information.
 Comparative analysis is the problem of predicting how a system will react to perturbations in its parameters.
 Purely qualitative techniques for comparative analysis, such as the methods used by Weld, are limited in their prediction capacity because the net effect of opposing influences cannot be determined.
 In graphs, lines carve up the twodimensional space defining qualitative regions, which enable qualitative analysis while still maintaining access to numerical values.
 In Section 3, w e present an example of how S K E T C H Y performs comparative analysis.
 The domain translator uses the visual routine processor to extract information from the diagram.
 It begins by calling visual routines that identify entities in the graph.
 If the entities are not found, domain knowledge is used to suggest other graphical interpretations.
 Then it uses other visual routines to compute relationships between the objects based on the query.
 These relationships are then translated back into conceptual terms to produce an answer to the question.
 Visual Routines After the conceptual question is translated into graphical terms by the translator, visual routines are invoked to gather the necessary information from the graph.
 Ullman (1984) suggests how psychologically plausible elemental operations (such as bounded activation and boundary tracing) can be combined to construct visual routines.
 Visual routines are used to retrieve coordinates of objects, determine spatial orientations, find about interactions, and get information about size and changes in the graph.
 Table 1: Examples of visual routines and how they are used Visual Routine examine label coordinateatpoint rightof, leftof, above, below inside, outside steeper, flatter bigger, smaller vertical, horizontal changeinslope touches, intersects online, onborder, formsborder E x a m p l e of Use Used to find the object being queried For calculating slope, getting the value of a point Used for finding spatial relations of objects to each other.
 Necessary when axes do not have scales Used for determining the relationship between an area and a point or line segment For comparing slopes of lines qualitatively Comparing sizes Special cases for line slope being zero or infinity For dividing lines into regions Possible relationship between objects Specifying a limit point either for an area or a line 693 Table 1 shows the visual routines used to interpret graphs.
 The visual routines in Table 1 are given in terms of object pairs, but they can also be used to find objects that satisfy a specific relationship.
 Examples from SKETCHY S K E T C H Y is a fully implemented computer program based on our model of graph interpretation.
 Given a graph produced by a simple interface, S K E T C H Y can provide natural summarizations, answer questions, perform comparative analyses, and detect contradictions in problem solving assumptions.
 S K E T C H Y has been fully tested on 65 graphs from two domains (economics and engineering thermodynamics), which suggests that the model is robust.
 This section illustrates S K E T C H Y ' s operation on representative examples, to better show how the model works.
 Graph Summarization Figure 2 shows a graph from a thermodynamics textbook.
 Understanding this graph is essential for solving many thermodynamics problems since all substcinces exhibit the same qualitative behavior shown.
 The graph shows three regions (liquid, liquid/vapour, and vapour regions) corresponding to the phase(s) a substance can be in.
 The temperature lines, which are contours of equal temperature, effectively add a third dimension to the graph.
 S K E T C H Y produces the graph description given in Figure 3 using general graph knowledge and graph labels, but without indepth domain knowledge about temperature, pressure, volume or the phases a substance can be in.
 Pressure Volume Figure 2: Compression of carbon dioxide SKETCHY's summary captures important features of the graph, but it contains more information than a person might give in explaining the graph to someone else.
 Part of becoming an expert in the domain is learning how to concisely state the relevant features of a graph for the current task.
 Including task specific control information would make S K E T C H Y ' s summary more concise.
 For line 31C: VOLUME and PRESSURE are inversely proportional .
 For line 20C: The slope of 20C has discontinuities ;associating discontinuities with regions Inside region LIQUID: VOLUME INCREASE and PRESSURE DECREASE.
 Inside region LIQUIDANDVAPOUR: VOLUME INCREASE and PRESSURE CONSTANT.
 Inside region VAPOUR: VOLUME INCREASE and PRESSURE DECREASE.
 CRITICALPOINT is on lines (31C) CRITICALPOINT is on regions (LIQUID LIQUIDANDVAPOUR VAPOUR) For TEMPERATURE contour: As TEMPERATURE increases the slopes of TEMPERATURE lines become more LINEAR.
 ;basis for Boyle's Law For a constant PRESSURE: As VOLUME increases TEMPERATURE INCREASE.
 VOLUME and TEMPERATURE are directly proportional .
 For a constant VOLUME: As PRESSURE increases TEMPERATURE INCREASE.
 PRESSURE and TEMPERATURE are directly proportional .
 Figure 3: S K E T C H Y ' s description of carbon dioxide compression graph Comparative Analysis Graphs are an ideal representation for comparative analysis since they combine qualitative and quantitative information.
 S K E T C H Y demonstrates comparative analysis can be done via visual processes on a graph.
 Analyzing engineering cycles is an important task in thermodynamics.
 The basic cycle for a steam power plant is the Rankine cycle, shown in Figure 5.
 A c o m m o n modification to the Rankine cycle is superheating the steam in the boiler to increase the efficiency of the cycle.
 The net work of the cycle before modification is represented by area 12341 and after modification by l23'4'l.
 The area under 1233' represents the total heat put into the system.
 ;using graph interpretation rules For point 3: The ENTROPY of 3 INCREASE.
 The TEMPERATURE of 3 INCREASE.
 For point 4 : The ENTROPY of 4 INCREASE.
 The TEMPERATURE of 4 CONSTANT.
 For region WORK: The area covered by WORK INCREASE.
 For region HEAT: 694 The area covered by HEAT INCREASE.
 ;using thermodynamics knowledge For variable EFFICIENCY: EFFICIENCY has INCREASE.
 Figure 4: S K E T C H Y ' s explanation Tonpcnnire 1 ( / / / \ // WORK HEAT 4 1* \ .
•••• \ 4' \ \ Enlropy Figure 5: Effect of superheating on Rankine cycle Qualitative methods alone are sufficient to reach the conclusion that W O R K and H E A T have increased as a result of modification.
 Efficiency, defined as the amount of work divided by the am o u n t of heat, is represented indirectly through work and heat as areas in the graph.
 Determining whether efficiency has increased or not cannot be resolved qualitatively.
 S K E T C H Y uses visual routines to calculate the changes in areas and determines that the efficiency of the cycle is increased.
 Using SKETCHY in Problem Solving W e have connected S K E T C H Y to CyclePad (Forbus & Whalley, 1994) an intelligent learning environment for engineering thermodynamics.
 An important problem in such learning environments is detecting contradictory student assumptions and explaining them in an easily grasped fashion.
 S K E T C H Y uses studentsupplied assumptions and numerical values computed by CyclePad to automatically draw temperatureentropy diagrams.
 Students can express design changes using these diagrams.
 Modifications to CyclePad's parameters that lead to visually detectable contradictions are found by SKETCHY's thermodynamics domain rules and it warns the student about them (c.
f.
 Figure 7).
 666" «l.
</6230Hi 60 _ Temperature Heater^^"^ / / 7 \ \ \ Pump U J /4 Cooler 2 » Turbine J 17 t.
 0 2 4 6 666 52137623085 60 Temperature Heater Turbine Pump Entropy Figure 6: The graph before and after user modification You cannot change the value of (t s4) Changing the value would violate (isothermal (fluidflow s3 s4)) Figure 7: SKETCHY's report of detecting the contradiction Related Work One inspiration for S K E T C H Y is the Metric Diagram/Place Vocabulary model of spatial reasoning (Forbus, 1980; Forbus, Nielsen & Fallings, 1991).
 SKETCHY's Visual Routine Processor is its Metric Diagram.
 Ullman (1984) introduced the concept of visual routines as a goaloriented visual processing facility.
 Visual routines express domainspecific visual skills.
 Mahoney (1992) extends Ullman's work by defining image chunks, formed using topological information, that can be used for higher level goals.
 In S K E T C H Y w e ignore the problem of recognizing and identifying graph objects and concentrate on interpreting their interactions.
 A natural extension to S K E T C H Y would be implementing image chunks, which would enable S K E T C H Y to analyze scanned images.
 This extension would not fundamentally alter our model of graph understanding.
 695 P O L Y A (McDougal & Hammond, 1993) uses visual operators to specify which objects in the diagram to inspect in the course of solving geometry proofs.
 POLYA's operators are very specific to the geometry domain (such as LOOKATLEFTBASEANGLE).
 SONJ A (Chapman, 1991) on the other hand uses very general action oriented visual operators for playing a video game.
 SKETCHY's operators are specific for examining line graphs.
 Pinker (1990) describes psychological factors contributing to difficulty in reading graphs.
 Pinker suggests a similar architecture to S K E T C H Y , but his main emphasis is on recognition of different graph types through general graph schemas and the difficulties in understanding different graphs, rather than providing a concrete computational model for graph interpretation.
 Currently S K E T C H Y does not have any internal model for processing capacity or selective attention, both of which would be useful in increasing its psychological plausibility.
 Gattis and Holyoak (1994) look at the impact of goals and conceptual understanding on graph interpretation.
 Gattis and Holyoak's most significant finding is that the variable being queried should be assigned to the vertical axis, so that steeper lines can map to faster changes in the queried variable.
 W e view this result as further evidence that graph semantics and graph interpretation is separate from the domain the graph is about.
 Lohse (1993) describes a computer program called UCIE which uses graph schemas to predict resp)onse times to answer questions about the graph.
 UCIE's graph schemas for information retrieval are similar to SKETCHY's general graph knowledge.
 UCIE's shortterm and longterm memory models could be incorporated into S K E T C H Y to get similar response time predictions.
 SKETCHY's graph descriptions are mainly produced by domain independent graph rules.
 Tabachneck, Leonardo and Simon (1994) demonstrate how novices have difficulty integrating visual and verbal information.
 Novices fail to provide answers that could be obtained by simple perception whereas experts see the answer immediately.
 When domain rules are not used, S K E T C H Y suffers from a similar problem.
 S K E T C H Y cannot answer any questions about variables besides the ones explicitly mentioned on the graph even when the answer is visually available.
 Part of becoming an expert in a domain is creating the necessary domain rules, so that inferences about objects not labeled in the graph can be made.
 Discussion W e have presented a model for interpreting graphs and illustrated its capabilities via examples solved by S K E T C H Y , a computer implementation of the model.
 S K E T C H Y has generated reasonable interpretations for 65 graphs from thermodynamics and economics showing that our model is broadly applicable.
 Extending S K E T C H Y to other graph types such as bar graphs and pie charts appears straightforward.
 The major difficulty appears to be increasing the library of visual routines to recognize and compare these compound graphical elements.
 Extending our model to general diagrams would require developing functional representations for objects that will be in the diagrams.
 Currently we are incorporating S K E T C H Y into a new cognitive simulation of student problem solving in engineering thermodynamics.
 A cknowledgements Special thanks to my advisor Ken Forbus for his comments and encouragement.
 This research was funded by the Computer Science Division of the Office of Naval Reseiuch.
 References Chapman, D.
 (1991).
 Vision, Instruction, and Action.
 Cambridge, M A : M IT Press.
 Ekelund, R.
 B.
 & Tollison, R.
 D.
 (1986) Economics.
 Boston: Little, Brown.
 Gattis, M.
 & Holyoak, K.
 J.
 (1994).
 H o w graphs mediate analog and symbolic representation.
 In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp.
 346350).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Forbus, K.
 (1980) Spatial and qualitative aspects of reasoning about motion.
 In Proceedings of the First Annual AAAI Conference (pp.
 170173).
 Los Altos, CA: William Kaufmann Inc.
 Forbus, K.
, Nielsen P.
 & Faltings, B.
 (1991) Qualitative spatial reasoning: the clock project.
 Artificial Intelligence, 51,417471.
 Forbus, K.
 & Whalley, P.
 B.
 (1994).
 Using qualitative physics to build articulate software for thermodynamics education.
 In Proceedings of the Twelfth Annual A A A I Conference (pp.
 11751182).
 Menlo Park, CA: AAAI Press/MIT Press Kim, H.
 (1993) Qualitative reasoning about fluids and mechanics.
 Doctoral Dissertation.
 UrbanaChampaign: University of Illinois at UrbanaChampaign.
 Kosslyn, S.
 M.
 (1989).
 Understanding charts and graphs.
 Applied cognitive psychology, 3, 185226.
 Larkin, J.
 H.
 & Simon, H.
 A.
 (1987).
 W h y a diagram is (sometimes) worth ten thousand words.
 Cognitive Science, 11,6599.
 Lohse, G.
 L.
 (1993).
 A cognitive model for understanding graphical perception.
 HumanComputer Interaction, 8 (4), 353388.
 Mahoney, J.
 V.
 (1992).
 Image chunks and their applications.
 Technical Report EDL923, Xerox Pare, Palo Alto, CA.
 McDougal, T.
 F & Hammond, K.
 J.
 (1993).
 Representing and using procedural knowledge to build geometry proofs.
 In Proceedings of the Eleventh Annual AAAI Conference, (pp.
 6065).
 Menlo Park, CA: A A A I Press/MIT Press.
 Pinker, S.
 (1990).
 A theory of graph comprehension.
 In R.
 Freedle (Ed.
), Artificial intelligence and the future of testing (pp.
 73126).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Schiano, D.
 J.
 & Tversky, B.
 (1992).
 Structure and strategy in encoding simplified graphs.
 Memory & Cognition, 20, 1220.
 696 Tabachneck, H.
, Leonardo A.
 M.
 & Simon, H.
 A.
 (1994).
 H o w does an expert use a graph? A model of visual and verbal inferencing in economics.
 In Proceedings of the Sixteenth Annual conference of the Cognitive Science Society (pp.
 842847).
 Hillsdale, NJ: Lawrence Eribaum Associates.
 Ullman, S.
 (1984).
 Visual Routines.
 Cognition, 18, 97159.
 Weld, D.
 S.
 (1990).
 Theories of comparative analysis.
 Cambridge, M A : The MIT Press.
 Whalley, P.
 B.
 (1992).
 Basic Engineering Thermodynamics.
 Oxford, N Y : Oxford University Press.
 697 A M o d e l of Conversation Processing Based on Micro Conversational Events Massimo Poesio University of Edinburgh Centre for Cognitive Science 2 Buccleuch Place Edinburgh E H 8 9LW.
 Scotland, U K p o e s i o @ c o g s c i .
 e d .
 a c .
 u k Abstract I present a theory of discourse interpretation based on the hypothesis that the common ground of a conversation contains a record not only of complete speech acts, but, more in general, of each action of uttering a contribution to the conversation: single words, word fragments, and fillers.
 I call the action of uttering a "minimar contribution a MICRO CONVERSATIONAL EVENT.
 This model can serve as the basis for accounts of reference resolution in spoken conversations, as well as the interaction between parsing, repair, and reference resolution.
 The Problem Traditional 'discourse models' such as (Webber, 1979; Grosz and Sidner, 1986; Kamp and Reyle, 1993) have been developed on the basis of facts about anaphoric reference and other forms of contextual dependency.
 The theories of anaphoric processing that include a detailed account of how the discourse model gets updated in response to a sentence / utterance, such as Discourse Representation Theory (DRT) (Kamp and Reyle, 1993) and related 'dynamic' theories, are all based on the assumption that interactions consist of complete, wellformed sentences.
 But in real conversations, complete and wellformed sentences are quite rare: conversations like in (1), from the TRAINS corpus,^ include large numbers of repairs^ and interruptions; one speaker's output typically alternates with the other speaker's acknowledgments.
 (1) 9.
1 9.
2 9.
3 9.
4 9.
5 10.
1 11.
1 12.
1 M: S: M: S: SO we should move the erigine at Avon engine E to engine El El okay ^The TRAINS project at the University of Rochester (Allen et al.
, 1995) studies taskoriented conversations.
 The project involves both collecting a corpus of conversations between human beings involved in a task—the TRAINS domain is transportation of goods by train— and developing theories about the aspects of natural language interpretation and plan reasoning observed in these transcripts.
 An annotated subset of the conversations in the corpus is in (Gross, Allen, and Traum, 1993).
 ^For example, Hindle (1983) reports that approximately 10% of spontaneous utterances contain disfluencies including selfrepair.
 Heeman and Allen (1994) report that the in TRAINS corpus, 2 5 % of turns contain at least one repair.
 13.
1 13.
2 13.
3 13.
4 13.
5 14.
1 M: S: engine El to Bath to / or we could actually move it to Dansville to pick up the boxcar there okay In (Poesio, 1994; Poesio and Traum, 1995) a version of Discourse Representation Theory was proposed, based on the idea from speech act theory and the AI work on intention recognition that the c o m m o n ground includes a record of each speech act that occurred in a conversation.
 The theory is generalized here by relaxing the assumption that the input to discourse interpretation consists of complete sentences.
 This extension can serve as the basis for systems that have to engage in conversations such as (1).
 The theory is also meant to provide a foundation for theories of discourse interpretation in which repairs, grounding, and similar processes interact with processes such as reference resolution, scope disambiguation, and reference resolution; hypotheses about the form of such interaction are also discussed.
 Discourse Models for Conversations A Formal Model of Discourse Discourse Representation Theory (DRT) (Kamp and Reyle, 1993) and related 'dynamic' theories such as Dynamic Predicate Logic) are the formal expression of intuitions also contained in discourse models such as Karttunen's or Webber's.
 The model of a discourse in DRT is a DISCOURSE REPRESENTATION Structure (DRS), a pair consisting of a set of discourse REFERENTS and a set of conditions (facts) that is typically represented in 'box' fashion, as in (3).
 (2) (3) Engine E2 is at Avon.
 xw engine E2(x) Avon(w) at(̂ ,H') The two advantages of the DRT model of discourse update are its clear semantics and the detailed account of how the discourse model gets updated by each utterance (the Drs CONSTRUCTION ALGORITHM).
 The Contribution of a sentence to 698 mailto:poesio@cogsci.
ed.
ac.
ukthe discourse model is computed in two steps: first, the previous discourse mode! is augmented with an 'uninterpreted condition' that provides information about the syntactic structure of the sentence; second, rewrite rules are applied to the DRS thus augmented.
 The rewrite rules add new conditions or new discourse referents to the DRS, or 'flesh out' the interpretation of the uninterpreted condition.
 The sentence The boxcar is also at Avon and is hooked to it results at first in the DRS in (5), with an 'uninterpreted condition'; at the end of the construction algorithm, the DRS in (6) is obtained.
 Note that the construction algorithm results in two new referents, for the boxcar and it; note also that the previously introduced discourse referent x is made available as antecedents of the pronoun u.
̂  (4) Engine E2 is at Avon.
 The boxcar is also at Avon and is hooked to it.
 (5) engine E2{jc) Avon(w) at(x,w) [s [np the boxcar] [yp is also at Avon and is hooked to it]] (6) x w y u engine EZU) AvonCw) at(x,w) boxcarQ) at{y,w) hookedto(_y,M) u = x Conversation Representation Theory Many recent theories of pronouns interpretation, definite description interpretation, and VP ellipsis resolution have been formalized in terms of a formal discourse model such as DRT, which makes precise claims about language and is easily implementable.
 But DRT lacks some crucial features required in a model of conversation.
 A model of the information used by processes such as reference resolution must include the pragmatic information used by such processes: for example, focusing information, and information about the subordination relations between utterances that result in DISCOURSE SEGMENTS (Grosz and Sidner, 1986).
 This information is not provided by the standard DRT model.
 Furthermore, the DRT model is based on the assumption that all utterances are assertions, whereas utterances in a real conversation can serve a much wider range of purposes.
 The models of discourse developed in the AI literature on intention recognition include the needed pragmatic information.
 They are based on the assumption that utterances are actions in their own right, performed to achieve DISCOURSE GOALS whose hierarchical structure determines the structure of the discourse (Cohen and Perrault, 1979; Allen and Perrauit, 1980; Grosz and Sidner, 1986).
 What is missing from these models is what D R T has: a precise specification of what is available for reference at a given point in the conversation, and a detailed account of the update process associated with a sentence.
 A combination of the two research traditions seems highly desirable.
 Such a unified theory.
 Conversation Representation Theory (CRT), was proposed in (Poesio, 1994) and further developed in (Poesio and Traum, 1995).
 The theory is based on the formulation of speech act theory adopted in Situation Semantics (Barwise and Perry, 1983), according to which the common ground consists of information about the DISCOURSE SITUATION (the set of actions performed by the participants to the conversation) rather than the described SITUATION (the situation which is the topic of the conversation); the participants in a conversations recover information about the latter from their information about the former.
 CRT preserves much of the formal machinery of DRT, including the update algorithm; but the DRS modeling the c o m m on ground as a whole (the R O O T Drs) is reinterpreted as consisting of information about the occurrence of speech acts or, as I will call them, conversational events.
 Each utterance thus introduces two situations: a conversational evenf* and a described situation.
 The madeup minidialog in (7) is represented in CRT as in (8).
 (7) A: Engine E2 is at Avon.
 B: The boxcar is also at Avon and is hooked to it.
 (8) eel tl ce2 t2 s eel: it\\(A,B,s: eel @ tl eel: ii\\{BA, s: eel @ t2 X w enginefx) Avon(w) ai(x,w) yu boxcarfyj sA(y,w) hookedto(>',M) U = X ) ) The DRS in (8) represents a discourse situation in which two conversational events occurred, eel and ce2, both of which are about the described situation s.
 The first two conditions assert that eel is an event of A telling B that the described situation s includes an engine located at Avon, and that eel took 'Space prevents a detailed discussion of the algorithm.
 (KampandReyle, 1993).
 See ""in Situation Semantics, events are considered a special type of situation.
 699 place at time tl.
 The third and fourth condition assert that ce2 is an event, taking place at time /2, of B telling A that boxcar V is also in Avon, and is hooked to u.
 Anaphoric accessibility is preserved by modifying the interpretation of DRSs and by adding a new type of condition, indicated in (8) by expressions of the form s:(l>.
 A DRS is treated in C R T as a situation type, i.
e.
, as denoting the set of situations which can be made to verify the conditions contained in the DRS once appropriate values for the discourse referents have been found.
 Conditions like s.
K, then, assert that a situation s is of the type specified by the DRS K.
 More precisely: Expressions in C R T are assigned a value with respect to a situation, a variable assignment, and a set of cases, one for each situation.
 A n expression of the form s:K asserts that s is of the type specified by K, and furthermore, it shifts the parameters of evaluation so that the value of the discourse markers occurring in K is provided by the case associated with the value of s.
 This ensures that the D R S in the complement of ce2 is evaluated with respect to the same case that is used to evaluate the expressions in the complement of ce7, e.
g.
, that x is accessible from within the complement of ce2.
 The update algorithm of D R T is (minimally) modified as follows.
 The first step in the D R T construction algorithm is replaced by the application of a CONVERSATIONAL EVENT GENERATION RULES that update the existing model of the discourse situation by adding two new discourse referents (a conversational event and a time) and two conditions, one asserting the occurrence of the appropriate locutionary act (one of teil, ask, and instruct), the other recording the time at which it occurred.
 The process of DRS construction can then proceed much as in (Kamp and Reyle, 1993), except that the whole process of rewriting takes place within the DRS that is the complement of the locutionary act.
 DRSs like (8) are the final result of this process.
 The model in (7), although a very simplified representafion of the conversation in (8), also includes the pragmatic information required to perform reference resolution and speech actsbased reasoning, such as inferring subordinafion relations.
 The subordination relations between conversational events can be inferred by reasoning about the agents' intentions, all information that, as well, could be included in the model of the conversation (although for simplicity hasn't been represented here).
 Although the descriptions of the conversational events in (8) are very abstract, they can serve as the basis for reasoning processes such as those discussed in (Allen and Perrault, 1980; Traum andHinkelman, 1992); in fact, various algorithms of this sort have been developed in connection with TRAINS.
 The model of interpretation underlying CRT involves the generation of multiple hypotheses in parallel, some (or all) of which are then discarded.
 The model, based on a 'priorifized' version of default logic similar to Brewka's (1991), and appears to be roughly compatible with the findings of the literature on lexical disambiguation, syntactic disambiguafion, and reference resolution (Seidenberg et al.
, 1982; Gibson, 1991) and with cognitively motivated computational models of sentence such as Jurafsky's S A L (Jurafsky, 1992) and C O M P E R E (Eiselt, Mahesh, and Holbrook, 1993).
 The model does not include a commitment to the way the hypotheses are pruned.
 Micro Conversational Events Basic Idea The central idea of this paper is that a model of the common ground such as the one in CRT, in which the common ground is a representation of the discourse situation, generalizes naturally into a model in which the apparently complex effects of utterances such as those in (1) can be explained rather simply.
 If we accept that the common ground includes a record of each utterance, it is but a small step to assume that the common ground contains a record of the events of uttering units smaller than sentences, such as single words, 'fillphrases' like hmm, or word fragments.
 In other words, it becomes easier to think that each minimal contribution to a conversation^ consUtute a 'microspeech act' —or, as I will call them, a MICRO CONVERSATIONAL EVENT—whose occurrence leads to a 'microupdate' of the c o m mon ground.
^ For example, let us assume that speaker A utters the wordform the.
 I propose that as a result the common ground gets updated with the following information: (9) .
.
.
cei ficei uti ficei: utters(A,(s,"the")) ^ce\ @ fxti sub(/[icei ,cei) This update is the result of a microCONVERSational EVENT GENERATION RULE that replaces the conversational event generation rules described in the previous section.
 The information added to the common ground by such a rule includes the fact that a microconversational event ^ice\ occurred, uttered by A, and with argument the wordform the.
 The fact that fxcei is subordinate to a conversational event cei also becomes part of the common ground.
 The expression {s, "the") denotes the value of the second element of the pair, interpreted with respect to the case associated with s.
 The update just presented may result in further updates as other processes are 'triggered' by the occurrence of the microti will assume here for simplicity reasons that the 'minimal incremental units' are words.
 Other hypotheses made in the literature are that phonemes or prosodic phrases serve as minima! incremental unit.
 ®The 'microutterances' hypothesis has been made in work on Situation Theory such as (Gawron and Peters, 1990), although not in relation with work on processing spoken conversations.
 In that literature the hypothesis is motivated on theoretical grounds, rather than to explain phenomena such as those discussed in this paper, and its details haven't been worked out yet.
 700 conversational event.
 If the utterance fragment is recognized as a lexeme, at least lexical interpretation and disambiguation take place.
 The formulation of an hypothesis about lexical interpretation can be expressed as a rewriting operation that replaces the word form with its lexical interpretation.
 (More than one such hypothesis will be generated in the case of lexical disambiguation.
) In this example, the assertion that A uttered the word form the will be replaced by the assertion that A uttered the determiner the, as shown in (10).
 Expressions such as (̂ .
[oet ̂ ^^1) ̂ ^ logical expressions, whose "underspecified' semantics is described in (Poesio, 1994).
 (10) Hcei: utters(A, {s,[Detthe])) The same process is repeated after each utterance fragment.
 Assume this next utterance fragment is again a lexical item, the word engine.
 After lexical disambiguation, the c o m m o n ground contains the additional information: (11) .
.
.
 ficeo nt2 Hce2: fice2 ( sub(/i curren utters(/\,(s,[N engine])) e2,cei) tCE = cei At the end of an utterance unit, a "macro' conversational event (i.
e.
, a speech act in the sense traditionally used in the Al literature, such as 'inform', 'request', etc.
) may then be obtained out of the micro conversational events by means of reasoning processes such as those proposed in the AI literature, except that in the present model such inference processes do not require the utterance of a complete sentence.
 Incremental Parsing In order to discuss more in detail how this model can be applied to account for the complex interactions between parsing, repair, and reference resolution displayed in conversations such as (1), several assumptions about how parsing and repair work need to be discussed; I will do this in the next section.
 In order to provide an account of the otherinitiated repair in 10.
1, however, the model of update just sketched only has to be supplemented with the assumption that at least some discourse interpretation processes can work off microconversational events without waiting for an 'utterance completion' signal.
 After fj.
ce2 has been added to the c o m m o n ground, a parser working in an incremental fashion^ and operating on the subset of microconversational events that have been successfully processed by lexical disambiguation^ may determine that a Noun Phrase just occurred.
^ This information may be added ^Evidence that the parser works in this way is discussed, for example, in (Grain and Steedman, 1985; Jurafsky, 1992).
 ®See below.
 Ît is immaterial for the present purposes whether this decision to the c o m m o n ground in the form of a condition to the effect that a microconversational event nces of uttering an N P with constituents ̂ cei and nce2 occurred.
 After this update, the c o m m o n ground contains not only the fact that a determiner and a noun were uttered, but also the fact that they combined to form a noun phrase.
 (12) l̂ce3 uti fices: utters(/l,(s, [np^cci /xce2])) ^ice^ @ nt2 subifice3,cei) The parser may not have enough evidence to combine the lexically interpretable microces into microces describing larger phrases; in this case, no larger constituent is added to the comm o n ground.
 Incremental reference resolution The otherinitiated repair of utterance 10.
1 in (1) may be taken as evidence that definite description interpretation takes place incrementally, as well.
 At that point in the conversation M has clearly decided that the engine at Avon is not engine E.
 This suggests that after processing utterances 9.
2 and 9.
3 M has enough information to start processing the definite NP, hence, that the reference resolution process can be triggered by the occurrence of a microconversational event of uttering a definite NP.
 Except for the fact that they are initiated by a microconversational event rather than a complete conversational event, the processes concerned with finding the referent of a definite description and with updating the c o m m o n ground if that referent is identified proceed much as discussed in (Poesio, 1994).
 The discourse referents associated with the situation s may serve as the antecedent of the definite.
 Applications Parsing with Filler Phrases a n d Fragments In addition to providing an explanation of h o w referential expressions can be interpreted before a sentence is completed, the theory just discussed suggests a simple model of the processing that takes place when 'parsable' input such as lexical items alternates with 'unparsable' input such as fill phrases or word fragments.
 T w o such cases are illustrated by the examples in (13) and (14).
 (All of these examples are from the T R A I N S corpus.
) (13) 145.
1 145.
2 145.
3 M: no we / : we took the sh/ : uh dadadada involved pragmatical information or was arrived at on the basis of syntactic information only, in a completely modular fashion.
 I.
e.
, the present model does not commit us either to a 'modular' or to an 'integrated' view of sentence processing.
 701 145.
4 : no still / 145.
5 : still take the shortest route (14) 39.
4 : so then send the 3 9.
5 : send the / [2sec] 3 9.
6 : send the orange car .
.
 back In (13), the utterance of the initial parts of a noun phrase is followed by 'filling phrases' like uhhh.
 In (14), the speaker utters send and the three times each before continuing its utterance.
 Although one could Ury to complicate the grammar in order to account for such phenomena, the model of discourse update just presented allows for a simpler explanation of the processing that goes on in these cases.
 According to this account, the parser is not the first module to operate on the input, and therefore the other modules do not get only what the parser 'lets through', as it were.
 Instead, everything that is uttered becomes part of the conversational record, and the parser only works on the subset of this input that it is actually competent to deal with.
 The microconversational events that are not recognized as lexical items are either 'skipped' or dealt with by other processes, as we shall see below.
 The following interaction between the parser and the rest of sentence processing can be envisaged on the basis of the microconversational events model: I.
 Every new microconversational event activates the lexicon, that attempts to classify the new input.
 2.
 Whenever the input is recognized as a proper lexical item, the parser is activated.
 The parser used in TRAINS, discussed in (Allen et al.
, 1995), makes use of a chart to generate all interpretations in parallel and relies on statistical informadon to choose the best one.
 All interpretations of lower plausibility are discarded.
 The only difference I am assuming here is that the parser is invoked on the input after every word or after every phrase boundary, and therefore this process of parallel hyothesis generation and statistical choice is repeated every time, much as in Jurafsky's S A L architecture (Jurafsky, 1992).
 3.
 The parser updates the discourse model by adding a new microconversational event as discussed above whenever it has obtained a single hypothesis about a portion of the utterance.
 W h e n more than one hypothesis are statistically equivalent, no micro conversational event is added.
 Thus, in the case of (13), the fillphrase sh uh dadadada is simply skipped over by the parser since it cannot be assigned a lexical entry.
 (The more complex interaction in (14) is discussed below.
) This architecture results both in a simpler theory and in computational advantages (in that complicating the grammar always results in increased ambiguities).
 Parsing and Repairs The microconversational events model also allows for a simple theory of the interaction between parsing and a 'local' model of repair such as the algorithm in (Heeman and Allen, 1994), in which speech repairs are detected and corrected online and using only local clues.
 The assumptions about the structure of repairs adopted in the model are shown in (15) (from (Heeman and Allen, 1994), p.
 297).
 (15) g o I to I oranI um I go I to I Corning mil m21 x| int I et I mil in2 I These models work by identifying the socalled INTERRUPTION POINT (identified in (15) by a  ) , skipping over EDITING TERMS such as um, identifying the REPArandum, i.
e.
, the parts of the input to be replaced, and replacing the reparandum with a REPAIR PATTERN.
 It is typically (although not always) the case that the repair pattern contains one 'matching element' for each element in the reparandum, as shown in (15).
 What is important for m y purposes is, first of all, and most obviously, that the process of repair affects the parser, in the sense that in the syntactic structure eventually assigned to an utterance the repaired terms have been replaced with the terms of the repair pattern.
 In order for this to happen, it is necessary for there to be an exchange of information between the parser and the repair module.
 Furthermore, this exchange cannot be monodirectional (e.
g.
, the repair module always working off the output of the repair module), because entire phrases can be replaced, not just lexical items, as in the following examples, from Heeman and Allen's paper: (16) After the orange juice is at the oranges are at the OJ factory (17) H o w would that how long would that.
.
.
 In (16), the noun phrase the oranges replaces the NP the orange juice; in (17), the whphrase how long replaces the whphrase how.
 Both of these examples can be reconduced to the simplest form of repair (onetoone replacement) if the repair module is affected by the output of the parser.
 In order for the interaction between parser and repair module to be bidirectional, a common level of representation is needed.
 The microconversational events level is the required level of representation.
 Repairs and Reference Perhaps the most convincing argument in favor of the hypothesis that repairs take place at the microconversational event level is the fact that the processes concerned with reference interpretation and those concerned with repair interact.
 The fragment in (1) contains two examples of such interaction.
 One, the case of otherinifiated repair in 10.
1, has been discussed above.
 A second example of interaction between repair and reference, and furter evidence that the common ground is updated before a sentence is completely interpreted, is the fresh start in (1) (utterances 13.
4 and 13.
5).
 S replaces the proposal introduced in 9.
113.
2 with a new one, but in doing so he^°  as10 The manager in this conversation was played by a male student 702 sumes that the engine at Avon, engine El is part of the common ground.
 If the repair process were to take place before discourse referents are established and reference resolution is performed, the referent would be removed, and we would end up with a pronoun without antecedent.
 Discussion The model of update sketched in the previous sections is a simple extension to standard DRT, yet the result is a model of discourse update that is appropriate for real conversations.
 It can serve as the basis for theories about the interface between repair, incremental parsing, and reference, as sketched in the previous section.
 Ideas such as providing a level at which different modules can interact are familiar from the work on 'blackboard architectures' (HayesRoth, 1985).
 Some aspects of the model, such as the way syntactic and lexical information are integrated, make it compatible with cognitive models of sentence processing such as Jurafsky's.
 One way to see the contribution of the present work is to spell out the details of a conversation processing model consistent with such an architecture, especially as far as the semantic details of reference are concerned.
 The model has been so far tested only by means of hand simulations over the TRAINS corpus.
 Implementations of the modules discussed here (parsing, repair, reference, and DRT update) already exist, however, and work on an integration is under way.
 References Allen, J.
 F.
 and C.
 Perrault.
 1980.
 Analyzing intention in utterances.
 Artificial Intelligence, 15(3): 143178.
 Allen.
 J.
 E, L.
 K.
 Schubert, G.
 Ferguson, P.
 Heeman, C.
 H.
 Hwang, T.
 Kato, M.
 Light, N.
 Martin, B.
 Miller, M .
 Poesio, and D.
 R.
 Traum.
 1995.
 The TRAINS project: a case study in building a conversational planning agent.
 Journal of Experimental and Theoretical AI, 7:7^8.
 Barwise, J.
 and J.
 Perry.
 1983.
 Situations and Attitudes.
 The M I T Press.
 Brewka, G.
 1991.
 Nonmonotonic Reasoning: Logical Foundations of Commonsense.
 , edited by.
 Cambridge University Press.
 Cohen, R R.
 and C.
 R.
 Perrault.
 1979.
 Elements of a plan based theory of speech acts.
 Cognitive Science, 3(3): 177212.
 Crain, S.
 and M.
 Steedman.
 1985.
 On not being led up the garden path: the use of context by the psychological syntax processor.
 In D.
 R.
 Dowty, L.
 Karttunen, and A.
 M.
 Zwicky, editors.
 Natural Language Parsing: Psychological, Computational and Theoretical perspectives.
 Cambridge University Press, N e w York, pages 320358.
 at the University of Rochester Eiselt, K.
 R, K.
 Mahesh, and J.
 K.
 Holbrook.
 1993.
 Having yoourcake and eating it too: Autonomy and interaction in a model of sentence processing.
 InProc.
 ] 1 th National Conference on Artificial Intelligence, pages 380385, WashingIon.
 DC.
 Gawron, J.
 M.
 and S.
 Peters.
 1990.
 Anaphora and Quantification in Situation Semantics.
 Lecture Notes, volume 19.
 CSLI.
 Gibson, E.
 1991.
 A Computational Theory of human linguistic processing: memory limitations and processing breakdown.
 Ph.
D.
 thesis, Carnegie Mellon University, Pittsburgh.
 Gross, D.
, J.
 Allen, and D.
 Traum.
 1993.
 The TRAINS 91 dialogues.
 TRAINS Technical Note 921, Computer Science Dept.
 University of Rochester, June.
 Grosz, B.
 J.
 and C.
 L.
 Sidner.
 1986.
 Attention, intention, and the structure of discourse.
 Computational Linguistics, 12(3): 175204.
 HayesRoth, B.
 1985.
 A blackboard architecture for control.
 Artificial Intelligence, 26:251321.
 Heeman, P.
 A.
 and J.
 F.
 Allen.
 1994.
 Detecting and correcting speech repairs.
 In Proc.
 of the Association for Computational Linguistics.
 Hindle, Donald.
 1983.
 User manual for FIDDITCH, a deterministic parser.
 Technical Memorandum 7590142, Naval Research Laboratories.
 Jurafsky, D.
 1992.
 An OnLine Computational Model of Human Sentence Interpretation: A Theory of the Representation and Use of Linguistic Knowledge.
 Ph.
D.
 thesis.
 University of California at Berkeley, Department of Computer Science.
 Kamp, H.
 and U.
 Reyle.
 1993.
 From Discourse to Logic.
 Dordrecht: D.
 Reidel.
 Roesio, M.
 1994.
 Discourse Interpretation and the Scope of Operators.
 Ph.
D.
 thesis.
 University of Rochester, Department of Computer Science, Rochester, NY.
 Roesio, M.
 and D.
 Traum.
 1995.
 A multipurpose model of conversational context.
 In Proc.
 of the IJCAl Workshop on Context and Knowledge Representation, Montreal, August.
 Seidenberg, M.
 S.
, M.
 K.
 Tanenhaus, J.
 Leiman, and M.
 Bienkowski.
 1982.
 Automatic access of the meanings of ambiguous words in context: some limitations of knowledgebased processing.
 Cognitive Psychology, 14:489537.
 Traum, D.
 R.
 and E.
 A.
 Hinkelman.
 1992.
 Conversation acts in taskoriented spoken dialogue.
 Computational Intelligence, 8(3).
 Special Issue on Nonliteral Language.
 Webber, B.
 L.
 1979.
 A Formal Approach to Discourse Anaphora.
 N e w York: Garland.
 703 T h e Statistics of the Environment Affect the Functional Architecture of Vision in Adulthood: A Reduced Alphanumeric Category Effect in Canadian Mail Sorters Thad A.
 Polk Department of Psychology University of Pennsylvania 3815 Walnut Street Philadelphia, PA 191046196 polkQpsych.
upenn.
edu Martha J.
 Farah Department of Psychology University of Pennsylvania 3815 Walnut Street Philadelphia, PA 191046196 mfarah@psych.
upenn.
edu Abstract Letters are detected more efficiently among digits than among letters.
 This alphanumeric category effect suggests an architectural distinction between letter and number representation in human vision and dissociations between letter and number recognition following brain damage support this interpretation.
 Because letter and number recognition are not innate, this implies that experience can shape the functional architecture of vision.
 A possible explanation is that letters cooccur with letters in the environment while numbers cooccur with numbers; such statistics cause segregation of letter and number representations in artificial neural networks.
 To test the general hypothesis that environmental statistics affect the architecture of vision, and the specific hypothesis that withincategory cooccurrence causes the alphanumeric category effect, we measured the effect in foreign mail sorters who process Canadian zip codes (which violate the cooccurrence statistics) and in control subjects.
 As predicted, foreign mail sorters showed a smaller category effect The Alphanumeric Category Effect a n d the C o  O c c u r r e n c e Hypothesis A central goal of cognitive psychology is to characterize the fiinctional architecture, that is, the set of informationprocessing subsystems underlying cognition.
 In the case of vision, a productive behavioral approach to elucidating the architecture has been to study popout effects.
 A visual target is said to popout if it is detected quickly and without serial search (i.
e.
, response time is relatively independent of the number of distractors).
 Treisman and colleagues (Treisman, 1988; Treisman & Gelade, 1980) have shown that targets that differ from distractors by the presence of certain, socalled primitive, visual features (e.
g.
, color, orientation, motion) popout, while targets that differ by the presence of other features do not (i.
e.
, they require slower, serial search).
 Treisman and Gelade (1980) proposed an influential featureintegration theory in which primitive featiues are processed automatically and in parallel in specialized modules, called feature maps.
 This hypothesis is consistent with neuroscientific evidence for spatially segregated, cortical areas that are specialized for processing such features (Cowey, 1979; Van Essen & Maunsell, 1983).
 A similar popout effect occurs for letters and digits: A letter target is detected more quickly and accurately among digit distractors than among distinct letter distractors and vice versa (EHincan, 1980; Duncan, 1983a; Egeth, Jonides, & Wall, 1972; Jonides & Gleitman, 1972; Merikle, 1980; Schneider & Shiffrin, 1977; von Wright, 1972).
 Although this alphanumeric category effect can disappear when using letterdigit pairs that are matched for visual similarity (Cardosi, 1986; Krueger, 1984), this approach makes between category items (letters and digits) more visually similar, on average, than within category items (different letters) and hence may mask the effect; when both between and within category similarity are controlled, the category effect reemerges (Dixon & Shedden, 1987).
 This evidence suggests that category information about alphanumeric stimuli is computed automatically, rapidly and in parallel in much the same way information about primitive visual features is processed.
 Consistent with this hypothesis, braindamaged patients can be selectively impaired at letter recognition relative to number recognition (Gardner, 1974; Hecaen & Kremin, 1976) and viceversa (Cipolotti, 1995), suggesting that letter and digit recognition are carried out by distinct modules or maps.
 Although it is natural to assume that the visual processing of color, motion, and other primitive features are innate, letter and digit recognition certainly are not: They are not phylogenetically old, they are not shared by all normal adults, and they require systematic training to develop.
 If the fiinctional architecture of vision (in normal adult readers) includes maps devoted to letter and digit recognition, as the behavioral and neuropsychological data suggest, then the environment must be playing a role in shaping that architectiue.
 H o w might it do so? The fact that neural learning is fundamentally correlationbased suggests that temporal correlations in the environment may provide an answer.
 For example, stimuli within a category (e.
g.
, letters) tend to occur in close temporal proximity (e.
g.
, in text), but stimuli between categories (e.
g.
, letters and digits) occur in such close temporal proximity much less often.
 This statistical feature of the environment could interact with correlationbased learning in the brain to lead to maps for letter and digit recognition.
 Polk and Farah (1993,1995) implemented this hypothesis in a simple neural network model that used a Hebbian learning rule.
 W h e n this network was presented with inputs that satisfy these cooccurrence statistics, it spontaneously selforganized to produce maps for letters and digits.
 An Empirical Test of the CoOccurrence Hypothesis If the development of such maps is due to the cooccurrence of letters with letters and digits with digits, then the alphanu704 mailto:mfarah@psych.
upenn.
edu850 800750700iO 650550 D LL Q LD Postal Controls Sorters Subject Group Figure 1: Mean reaction time (with standard error bars) for correct responses on targetpresent trials for the foreign mail sorters and postal controls in both the letteramongletters (LL) and letteramongdigits (LD) conditions.
 meric category effect should be smaller in subjects w h o regularly see letters and digits together.
 Such subjects should have less segregated maps and, as a result, letters should not pop out from digits as much as they do for control subjects.
 This prediction offers the appealing possibility of directly observing the effects of environmental cooccurrence on the functional architecture of vision.
 To test this prediction w e compared the alphanumeric category effect in foreign mail sorters with that in postal worker controls.
 Foreign mail sorters spend roughly 4 hours per day processing Canadian zip codes in which letters and digits occur together (they alternate).
 Method Subjects.
 10 foreign mail sorters and 16 postal controls from the Philadelphia Air Mail Facility were paid $20 for their participation.
 The foreign mail sorters had all been operating the Letter Sorting Machine for at least 6 months prior to their participation.
 Task.
 The experiment was run on a Macintosh Ilsi computer with a 14" screen.
 Displays were made up of digits and uppercase letters from the Geneva typeface in 10 point font.
 The task and procedure were modeled on those of Duncan (1983b), experiment 1.
 On each trial, the computer first presented the target letter in the center of the screen (either an A or a Z, randomly chosen).
 Once the subject pressed the spacebar indicating they were ready to proceed, the screen went blank for 1600 msec and then presented a fixation point at the center of the screen.
 After 400 msec the fixation point was replaced by a circular array of two, four, or six characters whose diameter subtended a visual angle of 3.
4 degrees and which was centered on the fixation point.
 O n half the trials, this array included the target letter, on half the trials it did not.
 In the letteramongdigit (LD) trials, the distractors were selected randomly from the set 3, 5, 6, 8, 9.
 In the letteramongletter (LL) trials, the distractors were selected randomly from the set C, E, F, H, J, K, L, N, P, R, S, T, U, V, X, Y.
 The subjects pressed a key with their right index finger if the target was present and with their left index finger if the target was absent.
 After the response, the screen went blank for 2 sec followed by the target for the next trial.
 There were 12 possible positions in the circular array in which characters could appear, arranged like a clock.
 The positions in the array were grouped into six pairs (12 and 1 o'clock, 2 and 3 o'clock,.
.
.
, 10 and 11 o'clock).
 Characters appeared in random positions in the array except that two characters never appeared in the same group and at least one pair of characters appeared in diametrically opposite groups (e.
g.
, one character in the 121 o'clock group and one character in the 67 o'clock group).
 Procedure.
 After being instructed, each subject received a block of L D trials and a block of L L trials with the order randomized across subjects.
 Each block consisted of 24 practice trials (not analyzed), a break, and 108 test trials.
 Within each set of 108 test trials, the following factors were varied orthogonally: 3 (two, four, or six characters) x 2 (target present vs.
 absent) x 6 (target positions; a d u m m y variable for target absent trials) x 2 (A or Z).
 Otherwise, trial sequences were randomized for each block and subject.
 Results Figure 1 shows the mean reaction time for correct responses on targetpresent trials for the foreign mail sorters and postal con705 o —I ra 1.
25n 1.
2251.
21.
1751.
151.
1251.
11.
0751.
051.
0251 ' 1 1 " Postal Controls Sorters Subject Group Figxire 2: Mean ratio of reaction times (with standard error bars) in the two conditions (LL/LD) for the two subject groups.
 trols in both the letteramongleiters (LL) and letteramongdigits (LD) conditions.
 In keeping with the traditional category effect, there was a main effect for condition, with L D trials being reliably fastw than L L trials, t(25) = 4.
367, p < .
001, onetailed.
 Although the foreign mail sorters were on avCTage faster than controls (627 msec vs.
 721 msec) this effect did not achieve significance, t(24) = 1.
429, p >.
 15, twotailed.
 The interaction between subject group and condition, however, was significant; the foreign mail sorters showed a smaller difference between the L L and L D conditions than did the controls (i.
e.
, a reduced category effect as measured by L L  L D difference), t(24) = 1.
816, p < .
05, onetailed.
 Figure 2 shows the mean ratio of reaction times in the two conditions (LL/LD) for the two subject groups.
 The foreign mail sorters also showed a reduced category effect as measured by the LL/LD ratio, t(24) = 1.
864, p < .
05, onetailed.
 Figure 3 shows the mean reaction times for the two subject groups when the three slowest controls are excluded, thus making their average response time in the L D condition faster than that for the sorters.
 In keeping with the overall results, the L D condition was significantly faster than the L L condition, t(22)=4.
785, p < .
001, onetailed, and the foreign mail sorters showed a reduced category effect as measured by the LLLD difference, t(21 )= 1.
881, p < .
05, onetailed, and by the LL/LD ratio, t(21) = 2.
060, p < .
05, onetailed.
 There was a crossova interaction in this case, with control subjects responding faster than sorters in the L D condition, but slower than sorters in the L L condition.
 There was not a significant main effect for subject group, t(21) = 0.
583, p > .
50, twotailed.
 Figiue 4 shows the same results with a set of 8 college graduates in place of the postal controls.
 Once again, the L D condition was significantly faster than the L L condition, t(17) = 3.
208, p < .
01, onetailed, and the foreign mail sorters showed a reduced category effect as measured by the LLL D difference, t(16) = 2.
271, p < .
05, onetailed, and by the LL/LD ratio, t(16) = 2.
792, p < .
01, onetailed.
 Again, this was a crossover interaction with controls responding faster than sorters in the L D condition, but slower than sorters in the L L condition.
 There was not a significant main effect for subject group, t(16) = 0.
438, p > .
50, twotailed.
 Discussion In keeping with the prediction of the cooccurrence hypothesis, foreign mail sorters showed a reduced category effect as measured by the absolute difference in response times (RT in the letteramongletter [LL] condition  R T in the letteramongdigit [LD] condition.
 Figure 1) and by the ratio of response times ((RT in LL)/(RT in L D ) , Figure 2).
 To ensure that these results were not the result of a floor effect (RT for the sorters in the L D condition approaching a floor and therefore reducing the effect), w e excluded the three slowest postal worker controls for one analysis (Figure 3) and used college graduates whose RTs were faster for another (Figure 4).
 In both cases, the control group showed a larger category effect than the foreign mail sorters, even though both these groups were faster than the sorters in the L D condition.
 These crossover interactions eliminate any obvious interpretations based on artifacts.
 The cooccurrence hypothesis may also explain other examples of environmental influences on the functional architecture.
 There is evidence for the neural segregation of handwriting vs.
 other manual control tasks (Alexander, Fischer, & Friedman, 1992) (and even script and print can be selectively impaired by brain damage, Kinsbourne and Hiltbrunner, personal communication), of melody recognition vs.
 the recognition of other sounds (Peretz, 1993), and of each language in bilinguals (Ojemann, 1983).
 These examples also involve 706 800 u Si E 0) c 750650625600575550 D LL Q LD Fast Postal Controls Sorters Subject Group Figure 3: Mean reaction times (with standard error bars) for the two subject groups when the three slowest controls are excluded.
 influences on the functional architecture that are presumably not innate.
 And in keeping with the cooccurrence hypothesis, stimuli within these categories often occur in close temporal proximity: Handwriting a character is usually immediately preceded and followed by writing another character (and script characters are temporally correlated with other script characters, but print characters are correlated with print), musical sounds tend to cooccur with other musical sounds, and spoken words tend to cooccur with spoken words from the same language.
 Conversely, stimuli between different categories (e.
g.
, script and print) occur in such close temporal proximity less often.
 References Alexander, M .
 P.
, Fischer, R.
 S.
, and Friedman, R.
 (1992).
 Lesion localization in apractic agraphia.
 Archives of Neurology, 49(3), 246251.
 Cardosi, K.
 M .
 (1986).
 S o m e determining factors of the alphanumeric category effect.
 Perception a n d Psychophysics, 4(K5), 311330.
 Cipolotti, L.
 (1995).
 Multiple routes for reading words, w h y not numbers? Evidence from a case of arable numeral dyslexia.
 Cognitive Neuropsychology, to appear.
 Cowey, A.
 (1979), Cortical maps and visual perception: The Grindley Memorial Lecture.
 Quarterly Journal of Experimental Psychology: Human Experimental Psychology, 31(1), 117.
 Dixon, P.
 and Shedden, J.
 M .
 (1987).
 Conceptual and physical differences in the category effect.
 Perception and Psychophysics, 42(5), 457464.
 Duncan, J.
 (1980).
 The locus of interference in the perception of simultaneous stimuli.
 Psychological Review, 87(3), 272300.
 Duncan, J.
 (1983a).
 Perceptual selection based on alphanumeric class: Evidence from partial reports.
 Perception and Psychophysics, 33(6), 533547.
 Duncan, J.
 (1983b).
 Category effects in visual search: A failure to replicate the 'ohzero' phenomenon.
 Perception and Psychophysics, 34(3), 221232.
 Egeth, H.
, Jonides, J.
 and Wall, S.
 (1972).
 Parallel processing of multielement displays.
 Cognitive Psychology, 3(4), 674698.
 Gardner, H.
 (1974).
 The naming of objects and symbols by children and aphasic patients.
 Journal of Psycholinguistic Research, 3, 133149.
 Hecaen, H.
 and Kremin, H.
 (1976).
 Neurolinguistic research on reading disorders resulting from left hemisphere lesions: Aphasic and 'pure' alexia.
 In H.
 Whitaker and H.
A.
 Whitaker (Eds.
), Studies in Neurolinguistics.
 Academic Press, N e w York.
 Jonides, J.
 and Gleitman, H.
 (1972).
 A conceptual category effect in visual search: O as letter or as digit.
 Perception and Psychophysics, 12(6), 457460.
 Krueger, L.
 E.
 (1984).
 The category effect in visual search depends on physical rather than conceptual differences.
 Perception and Psychophysics, 35(6), 558564.
 Merikle, P.
 M .
 (1980).
 Selection from visual persistence by perceptual groups and category membership.
 Journal of Experimental Psychology: General, 109(3), 279295.
 Ojemann, G.
 (1983).
 Brain organization for language from the perspective of electrical stimulation mapping.
 Behavioral and Brain Sciences, 6(2), pp.
 189230.
 Peretz, I.
 (1993).
 Auditory atonalia for melodies.
 Cognitive Neuropsychology, 10( 1), 21 56.
 707 800 750m LD 550500450 NonPostal Controls Sorters Subject Group Figure 4: Mean reaction times (with standard error bars) with a set of 8 college graduates in place of the postal controls.
 Polk, T.
 A.
 and Farah, M.
 J.
 (in press).
 Brain localization for arbitrary stimulus categories: A simple account based on Hebbian learning.
 Proceedings of the National Academy of Sciences.
 Polk, T.
 A.
 and Farah, M .
 J.
 (1993).
 The development of modularity for arbitrary stimulus categories in a Hebbian selforganizing network: Explaining the dissociability of letters and numbers.
 Proceedings of the 23rd Annual Meeting of the Society for Neuroscience, 844.
 Schneider, W .
 and Shiffrin, R.
 M .
 (1977).
 Controlled and automatic human information processing: I.
 Detection, search and attention.
 Psychological Review, 84(1), 166.
 Treisman, A.
 M .
 (1988).
 Features and objects: The Fourteenth Bartlett Memorial Lecture.
 Quarterly Journal of Experimental Psychology: Human Experimental Psychology, 40Ai2), 201231.
 Treisman, A.
 M .
 and Gelade, G.
 (1980).
 A featureintegration theory of attention.
 Cognitive Psychology, 12(1), 97136.
 Van Essen, D.
 and Maunsell, J.
 (1983).
 Hierarchical organization and functional streams in the visual cortex.
 Trends in Neurosciences, 6(9), 370375.
 von Wright, J.
 M .
 (1972).
 O n the problem of selection in iconic memory.
 Scandinavian Journal of Psychology, 13(3), 159171.
 708 Skilled like a Person: A Comparison of H u m a n and C o m p u t e r G a m e Playing Mary Jo Rattermann Cognitive Science and Cultural Studies Adele Sinunons Hall Hampshire College Amherst, M A 01002 mjr@neural.
hampshire.
edu Susan L.
 Epstein E)epartment of Computer Science Hunter College and The Graduate School of the City University of New York 695 Park Avenue New York, N Y 10021 epstein@roz.
hunter.
edu Abstract The subject of this paper is the role of transferable commonsense principles in the acquisition of gameplaying expertise.
 W e argue that individuals skilled in a domain develop expertise because they know and apply these principles, and that most gameplaying programs do not play like people.
 The paper describes Hoyle, a model of an expert game player that relies on the use of commonsense principles, limited memory, and useful knowledge to learn to play twoperson, perfect information finiteboard games expertly.
 W e then describe an experiment in which human subjects played three such games against a computer expert.
 After playing these games, the subjects evaluated Hoyle's gameplaying principles in the context of their own behavior Verbal protocols and subjects' evaluations revealed considerable overlap between the principles preferred by our subjects and those preferred by Hoyle.
 Using learning time as a measure of difficulty, the subjects' performance and Hoyle's performance ordered the three games identically.
 This experiment also revealed differences in the use of gameplaying principles between skilled and unskilled players: skilled players judged the gameplaying principles to be more effective than did unskilled players, skilled players used several different principles while unskilled players relied on one principle, and skilled players anticipated their opponent's moves while unskilled players merely reacted.
 Introduction The use of transferable commonsense principles as a hallmark of expertise is tlie subject of this paper.
 It is the thesis of tJiis work that an individual skilled in a particular domain is able to develop expertise more thoroughly and more rapidly because she knows and applies a set of commonsense principles.
 Our research is based in the domain of twoperson, perfect information, finiteboard games.
 W e argue that most gameplaying programs do not play like people, and present a model of expert game playing called Hoyle, which implements commonsense gameplaying principles.
 W e describe an experiment that identifies some of the commonsense principles people use, and offers psychological evidence that the ability to use and evaluate commonsense principles is one of the differences between skilled and unskilled human gameplayers.
 Further, w e discuss the plausibility of Hoyle as a cognitive model of human expert game playing.
 Throughout this paper, game denotes a set of rules, playing pieces, and a board, while contest distinguishes a single experience playing a game.
 A state is a situation in a game, described completely by the location of the playing pieces on the board and whose turn it is to move.
 For example, tictactoe is a game at which two people might play a contest, beginning with a state that is an empty board with X to move.
 The gam e tree for a game is the space of all its possible states, connected by the moves that lead from one state to another.
 Finally, a commonsense strategy is a generally applicable predilection to select an alternative because it satisfies a particular criterion.
 How Human Experts Play Games Contrary to popular belief, experts do not have distinctive mental abilities (like exceptional powers of concentration, enormous memories, or high IQ's), nor do they perform extensive forward search into the game tree, nor rely on statistical measures of typicality or concrete visual images (Binet, 1894; Chamess, 1981; Djakow, Petrowski, & Rudik, 1927; Holding, 1985).
 What they do have are perceptual focus of attention, carefully organized knowledge, and efficient procedures to manipulate that knowledge.
 In particular, gameplaying experts summarize some of their knowledge in concepts, both as verbal memories and as unordered spatial patterns called chunks.
 A grandmaster's recall is better than an ordinary person's for chess positions, but only for chess positions that are meaningful, i.
e.
, ones that would arise during the play of a contest (Chase & Simon, 1973).
 In general, empirical evidence indicates that skilled people in many domains have better memories, but only for meaningful patterns, and that, given the same knowledge, an imskilled person remains unskilled.
 (See, for example, (Egan & Schwartz, 1979; Engle & Bukstel, 1978; Shneiderman, 1976).
) A n expert's memory is organized around higherlevel concepts, not perceptual characteristics.
 709 mailto:mjr@neural.
hampshire.
edumailto:epstein@roz.
hunter.
eduso tliat a single board configuration that could arise in eidier of two different games is chunked and recalled dilTerenUy, depending upon the g a m e in which it is perceived (Bsenstadt & Kareev, 1975).
 Finally, chess masters consider both their possible moves and the possible moves of their opponents, and use these phms to direct the search process, making it simpler and more efficient (Holding, 1985).
 How Computer Experts Play Games The typical gameplaying program is very different from the human expert.
 It plays only one game, e.
g.
, checkers or Go.
 With a few notable exceptions, such a program does not leani or plan or retain its experience, and it camiot explain its decisions.
 It relies on large, perfect memory and fast, deep search.
 The memory describes standard openings (early move sequences favored by human experts) and may also include a database indicating the best possible result from many states in the endgame.
 The program plays the relevant opening as long as it is applicable, and applies the endgame knowledge as soon as possible.
 In between, during the middlegame, the program calculates a numerical description of the worth of many possible subsequent states and selects the move that maximizes the mover's potential strength, while minimizing that of her opponent.
 Each state is rated by the program's heuristic evaluation function, a computation based upon gamedependent features selected by the programmer from among those highly regarded by human experts.
 A feature is a description, like "the black king is in check," that is considered a significant component of a static judgment on the strength of any state relative to all other possible states.
 The typical gameplaying program searches as fast and as deep as it can, evaluating encoimtered states and backing up their values to select the best next move.
 If a gameplaying program were supplied with the ideal evaluation function, or if it could always search to the end of possible contests where the rules determined who had won, then the program would play perfectly.
 Otherwise, its decision is simply a heuristic approximation, one which selects the current move that maximizes the program's estimated ability to win.
 Although this type of massive memory and search program produces an impressive game player, even the best of them are often defeated by the best human players (Anantharaman, Campbell, & Hsu, 1990; Beriiner & Ebeling, 1989).
 Further, the necessary memory requirements and speed of the search algorithm makes this kind of gameplaying program psychologically implausible; people simply cannot, and do not, play this way.
 How Hoyle Plays Games Hoyle is a program that learns to play twoperson, perfect information, finiteboard games.
 It is based on a learning and problemsolving architecture called F O R R , predicated upon multiple rationales for decision making (Epstein, 1994).
 The philosophy behind F O R R is that a set of possibly overlapping, approximately correct general principles for decision making can collaborate to achieve a pragmatic synergy.
 T h e individual reasons identified for a particular skill like g a m e playing are collected, rather than structured.
 acquired useful knowledge current state I legaj_ moves Tier 1 St̂ llow search and interence based on perlecl knowledge Victory Panic Enough make Absolute decision? »'move Tier 2.
 Heuristic opinions Shortcut Coverage Blackboard I Voting Figure 1: H o w Hoyle makes decisions.
 to permit flexibility in a wide range of tasks.
 Hoyle learns to play in competition against a handcrafted, external expert program for each specific n e w game.
 Hoyle begins with only the rules for a new game and some general knowledge about game playing, such as taking turns and stopping when someone has won.
 A s seen in Figure 1, whenever it is Hoyle's turn to m o v e , a hierarchy of resourcelimited procedures called Advisors is provided with the current game state, the legal moves, and any useful knowledge (described below) already acquired about the game.
 Hoyle has 23 heuristic Advisors, or commonsense principles for ga me playing, in two tiers.
 T h e first tier sequentially attempts to compute a decision based upon correct knowledge, shallow search, and simple inference, such as Victory's "make a m o v e that wins the contest immediately.
" If no single decision is forthcoming, then the second tier collectively makes m a n y less reliable recommendations based upon narrow viewpoints, like Material's "maximize the number of your markers and minimize the number of your opponent's.
" Based on the Advisors' responses, a simple arithmetic vote selects a move.
 During play, Hoyle searches no more than two ply (one m o v e for each contestant) ahead in the contest.
 Further details on Hoyle are available in (Epstein, 1992).
 A FORRbased program learns from its experience to make better decisions based on acquired useful knowledge.
 Useful knowledge is expected to be relevant to future decisions and is probably correct in the full context of the search space.
 Each item of useful knowledge is associated with at least one learning algorithm, e.
g.
, explanationbased learning or induction.
 The learning algorithms are highly selective about what they retain, m a y generalize, and may choose to discard previously acquired knowledge.
 Examples of Hoyle's useful knowledge include good openings, significant states (roots of subtrees whose gametheoretic value is a win for some contestant), and forks (overlapping plans that are a function of both the rules and the topology of die game board).
 Individual Advisors can apply current useful knowledge to construct their recommendations.
 For example, Open tries to reproduce only early play that has been successful in previous experience.
 Victory supports 710 moves to significant win states, and Pitchfork exploits forks both offensively and defensively.
 Unlike more traditional gameplaying programs.
 Hoyle does not rely upon massive memory, nor does it perform extensive searches in the game tree during play.
 Railicr, it learns from its previous experience, looks no more than one move ahead for each contestant, uses very little memory, and applies commonsense principles (its Advisors) to the game at band.
 Further, and most importantly, Hoyle can become expert in many different games, an ability not possessed by programs designed aroimd vast memory and massive search of gamespecific features.
 Hoyle is also an effective game player; it has learned to play 18 different games expertly in competition with a human or programmed opponent.
 Hoyle's learning time averages as few as 14 contests and rarely exceeds 100 contests (Epstein, 1993).
 Hoyle's primary components (the Advisors, shallow search, and useful knowledge) are more psychologically plausible than those of other expert gameplaying programs.
 Thus, the structure and logic of Hoyle seem ideally suited to guide the study of expertise in humans.
 Further, several of the board games Hoyle learns are simple enough to be mastered by a subject within an experimental session.
 Thus, the goal of the following experiment is to investigate whether the process used by Hoyle to become an expert is similar to that used by humans as they become experts.
 The Experiment Subjects The subjects were 8 college students, recruited from the general population and paid for their participation.
 Procedure The subjects were told they would be playing three different games against a computer expert.
 They were also told that they were being tape recorded, and that they should verbalize their thought processes while playing the games.
 To remind the subjects of the importance of verbalization during play, the words "Think out loud!" were displayed next to the game boards.
 The order of presentation of the three games was counterbalanced across subjects, and for each game the subjects and the computer expert alternated moving first.
 X X X X X o o o o achl 0 0 0 0 tictactoe Figure 2: The game boards for achi and tictactoe.
 The subjects were not told about Hoyle's Advisors until after playing against the computer.
 They played each game until they reached a criterion of 7 consecutive draws or 25 contests, after which they were switched to the next randomly assigned game.
 After playing all three games, the subjects were given a list of Hoyle's Advisors and asked to rate their effectiveness, frequency of use, and order of use.
 Materials Three twoperson, perfect information, finite board games: tictactoe, lose tictactoe and achi, were adapted for play on a Macintosh Quadra.
 Their game boards appear in Figure 2.
 Each of the programs was an expert, i.
e.
, it was designed to play perfectly, making the best possible move in any state.
 If there was more than one such move the expert program selected one at random to provide a broad range of highquality experience.
 Between two perfect players each of diese games is a draw, but the goal in play is always to win while simultaneously preventing tlie other contestant from doing so.
 Tictactoe is the classic 3 x 3 grid game where a win is three of your markers (either X' s or O' s) in a row either vertically, horizontally or diagonally.
 Lose tictactoe is a variant of tictactoe, in which three of your markers in a row loses the game.
 Achi is played on the board shown in Figure 2, which is isomorphic to the tictactoe grid.
 Contestants begin with 4 markers, either white or black, and alternate placing them on the board.
 Play begins when a player places a marker at the intersection of two or more lines.
 There are nine such positions (corresponding to the nine positions on a tictactoe grid).
 Once all eight markers have been placed on the board, a turn consists of moving one's own marker to the single empty position.
 A win at achi is three of your markers in a row, either vertically, horizontally or diagonally.
 Play ends in a draw when the same state is cycled through an agreed upon number of times.
 For Hoyle and our program, that number was 3.
 The subjects were also asked to fill out three questionnaires designed to examine their use of 17 of Hoyle's Advisors and their definitions, as in Table 1.
 (Six Advisors for more complex games were deemed irrelevant in the context of these games and therefore omitted.
) Each subject was asked to rate on a scale of 1 to 5 for each game the effectiveness of each Advisor, how frequently they had used each Advisor, and the order in which they had used them.
 Results W e used a contrastive analysis technique to divide the subjects into two groups, skilled and unskilled game players, based on the total number of contests necessary to reach criterion (Chi, Bassok, Lewis, Reimann, & Glaser, 1989).
 The four skilled game players reached criterion or played 25 contests in all three games after a total of 44 to 51 contests; the four unskilled game players reached criterion or played 25 contests in all three games after a total of 57 to 88 contests.
 Of the four skilled game players, all reached criterion in tictactoe, lluee in achi, and two in lose tictactoe.
 Of the four unskilled game players, three reached criterion in tictactoe, one in achi, and none in lose tictactoe.
 711 Table 1: Hoyle's Advisors aiid their definitions as renamed and described to the subjects.
 Advisor Definition BUnders Select a move to further a simple plan, with no regard for your opponent's plans.
 Defense Select a move to defend against your opponent's simple plans.
 Don't Lose D o not make a move that will result in a loss.
 Enough Rope If your opponent would have a losing move on diis board, avoid blocking it, i.
e.
, leave the opponent the opportunity to "hang itself.
" Fork Chose a move giving you more than one opportunity to win, while blocking moves giving your opponent more than one opportunity to win.
 Greedy Make moves that advance more than one winning configuration.
 Lookahead "Look" two moves ahead, and based on this choose your next move.
 Panic If your opponent has a winning move on this board, block it.
 Resign If this is a certain loss, resign.
 Victory If you can find a wiruiing move , take it.
 Again Repeat winning or drawing moves you have made.
 Not Again Copycat Leery Patsy Start Win D o not repeat previously losing moves you have made.
 Mimic opponent's winning or drawing moves.
 Avoid moves that your intuition tells you have led to a loss in the past.
 Reproduce the visual pattern made by the pieces of the winning or drawing player.
 and avoid the visual pattems made by the pieces of the losing player.
 Repeat previously successful observed op{X)nent's opening.
 If you remember a certain win, make the winmng move.
 Subject Protocols The goal of this analysis was to determine if the gameplaying principles (defined as the procedures used to optimize performance) verbalized by our subjects revealed the same principles embodied by Hoyle's Advisors.
 T o this end, the protocols produced by the subjects during play were first transcribed and any gameplaying principles were noted.
 These principles were then compared to Hoyle's Advisors, and the frequency of Hoyle's Advisors within the subject's gameplaying principles was recorded.
 During the coding procedures the judge was blind to the skill status of the subject.
 This analysis revealed a remarkable overlap between Hoyle's Advisors and the gameplaying principles verbalized by our subjects.
 Of the 17 relevant Advisors, 10 appeared in the subjects' protocols at least 3 times, suggesting that the Advisors used by Hoyle are also the gameplaying principles used by our subjects.
 Differences between the manner in which skilled and unskilled players used these principles were also evident.
 First, skilled game players tended to verbalize several different types of principles when playing against the computer, verbalizing an average of five diffoent Advisors during their play, while unskilled players verbalized an average of three different Advisors.
 Second, the skilled players used their gameplaying principles much more often than the unskilled players  an average of 16 times, in contrast to an average of 10 times for the unskilled players.
 Finally, the particular principles verbalized by the two groups also differed; the skilled players verbalized "Lookahead" 2 5 % of die time, and relied on "Defense" 17%, "Again" 11%, and "Patsy" 11%.
 The unskilled players used "Defense" quite often (30%), and were also very likely to use "Patsy" as a strategy, mentioning it over 1 7 % of the time.
 Subject Ratings  Effectiveness The effectiveness ratings revealed that the skilled players rated the Advisors as significantly more effective than did their unskilled counterparts.
 This was confirmed by oneway analysis of variance (Skilled versus Unskilled) performed on the subject's effectiveness ratings, collapsed across Advisor type, (F (1,28) = 6.
93, p < .
05).
 Given that the skilled players rated the Advisors as more effective overall, we next asked whether tliere were differences between players of different skill levels within each game, and further, if those differences applied for specific Advisors.
 A series of item analyses (Ttests, alpha <.
10) comparing the effectiveness ratings of skilled and unskilled players for each Advisor revealed that in tictactoe, the skilled and unskilled players differed in their ratings of only two Advisors, in lose tictactoe they differed in the their ratings of five Advisors, and in achi they differed in their ratings of seven Advisors.
 Subject Ratings  Frequency Unlike the effectiveness ratings, there were no significant differences between the skilled and unskilled players in their overall frequency of use ratings for the Advisors.
 (This was confirmed by oneway analysis of variance.
 Skilled versus Unskilled, F (1, 28) = 2.
09,/?>.
10) Item analyses, however, revealed a difference between skilled and unskilled players for 10 of Hoyle's Advisors, with the skilled players rating the frequency of use significantly higher for six of the Advisors, and die unskilled players rating the frequency of use significantly higher for the remaining four.
 Interestingly, one of the Advisors rated higher by the unskilled players was Patsy, a result mirrored by the analysis of Uieir protocols in which Patsy was also used more often by the unskilled players.
 Comparing Hoyle to Humans The analysis of the subjects' protocols revealed that the majority of the principles used by Hoyle are in fact used by humans when acquiring expertise in game playing.
 Further evidence is provided by the comparison of the Tier 2 Advisors Hoyle finds most significant (consistently supportive of expert decisions) and relevant (makes 712 recommendations) to the Tier 2 Advisors used most often by our subjects, as reflected by their protocols.
 (Because Hoyle treats its Tier 1 Advisors as always significant, only those in Tier 2 were analyzed here.
) This analysis revealed that two of the three Advisors most frequently used by our siibjccls.
 Defense and Again, were also rated as among the most significant by Hoyle for all three games used in this experiment.
 Further analysis performed on the subjects' ratings of the Advisors for frequency of use and effectiveness also revealed a significant overlap in the use of Defense and Again.
 Discussion The results of this experiment support our conjecture that Hoyle is a plausible model of human game playing.
 The analysis of the subjects' protocols revealed a significant overlap between the Advisors used by Hoyle and the gameplaying principles used by our subjects.
 Further, there was a significant overlap between the Tier 2 Advisors that Hoyle found significant and relevant and the subjects' ratings of these Advisors as highly effective and frequently used.
 This finding supports the proposal that the commonsense principles Hoyle finds useful when learning to play a game are also the principles humans find useful.
 A further commonality between Hoyle and our human subjects is found by analyzing the number of contests required to learn to play each of the three games.
 This analysis revealed that for both Hoyle and our subjects lose tictactoe was the most difficult game to learn (196 contests for our subjects), followed by achi (153), and then tictactoe (99).
 Hoyle reached criterion in these games considerably faster (X contests for lose tictactoe, X contests for achi and 16 contests for tictactoe) but revealed the same ordering of difficulty.
 The similarity between Hoyle's performance and human performance has implications for computer modeling of human expertise.
 Although the use of massive memory and fast search algorithms is a very effective way to produce expert performance in computers, such programs do not readily transfer to new games, nor is their dependence on extensive search psychologically valid.
 This research suggests tliat Hoyle, with its use of commonsense gameplaying principles, limited memory, and useful knowledge, is a plausible model of human performance.
 Thus, Hoyle is psychologically plausible, is as effective in learning new games as the traditional computer models of expertise (Epstein, 1992), and has the ability to transfer its skill to new games.
 The use of Hoyle's Advisors as a tool to study the acquisition of expertise in humans has revealed several differences between skilled and unskilled game players, supported by the subject's comments before they were told about Advisors: • Skilled players use a variety of different gameplaying principles and use them frequendy when learning to play a new game.
 Unskilled players do not use these principles as frequently, and when they do, tend to repeat the same principles.
 This conclusion is supported by an unskilled player w h o noted, "(My) tendency is to have three strategies.
.
.
.
 retain about two of them and then screw up on {the other)" • Skilled players rated Hoyle's Advisors as significantly more effective overall than did unskilled players, suggesting that they recognize the usefulness of gameplaying principles while imskilled players do not.
 This appreciation of the effectiveness of these principles may be a component of skilled game playing; when learning a new game the skilled player may be more likely to look for, and recognize, beneficial principles when they occur during the coiuse of a contest.
 In contrast, the unskilled player may not look for, or notice, beneficial principles, and thus will not have a repertoire of principles at his disposal.
 This conjecture is supported by the finding that skilled players used many different Advisors while unskilled players tended to use one or two Advisors repeatedly.
 • The analysis of the subjects' protocols suggests a difference in the playing styles of skilled and unskilled players.
 Specifically, skilled players were likely to "Lookahead" several moves and choose their plays based on their analysis.
 Unskilled players, in contrast, were likely to respond with a good "Defense" to the computer's offensive moves.
 This is particularly evident in an unskilled subject's statement: "at this point I don't even have a strategy now V m Just kind of responding to its moves "T^^ns suggests that as expertise is acquired the focus shifts from reacting to the behavior of your opponent to anticipating its moves and playing accordingly.
 • The protocols revealed that skilled players placed Patsy in the top four Advisors used when learning these games.
 Hoyle too found Patsy to be a highly relevant Advisor, ranked approximately the same way as skilled players value it.
 (Further work with F O R R suggests that later there is a shift back to patternbased reactivity, one that was neither anticipated nor measured for in this research (Epstein & Gelfand, 1995).
) • Item analyses of the effectiveness ratings revealed that the differences between the ratings of skilled and unskilled players increased as the games became less familiar, with the skilled players rating the Advisors as more effective.
 This suggests that as the games became less familiar skilled players relied more on Advisors than did the unskilled players.
 • A n analysis of the number of contests to criterion revealed that the easiest game to learn was tictactoe, followed by achi (the most unfamiliar game), and lastly, by lose tictactoe.
 This result suggests a role for analogical transfer between aclii and tictactoe  two different games that share isomorphic rule structures.
 This conjecture is supported by statements made by two of the skilled game players: "In the first game I didn't know it was tictactoe because.
.
.
.
 I was looking for these squares and I didn't think there was a place like it in the corners," and "it's sort of like a polka dot version of tictactoe.
" Finally, some of Hoyle's Advisors have also been found to be valid for extremely novice game players: six to nineyearold children.
 Crowley and Siegler (1993) found that when playing tictactoe, grade school children used principles such as "Win," "Fork," and "Block.
" While die children could fiexibly use these principles in response to 713 task demands, they also tended to adhere to a set order of use.
 Both of these characteristics are similar to the perfonnance of Hoyle, and suggest that, with the proper adjustments.
 Hoyle could be modified to play like a child.
 There is also evidence that people use FORRlike Advisors in chip design (Biswas.
 Goldman.
 Fisher.
 Bhuva.
 & Glewwe.
 1995).
 Conclusion Previous work (e.
g.
, Epstein.
 1993) has shown that Hoyle is an effective computational gameplayer that efficiently becomes an expert in several different games.
 This research supports the conjecture that Hoyle, a game learning program that uses conmionsense gameplaying principles, limited memory, and useful knowledge, is also a plausible model of the acquisition of expertise in humans.
 Additionally, this work reveals differences between skilled and unskilled players: skilled players use a variety of gameplaying principles and use them frequently while unskilled players rely on one or two principles, skilled players anticipate their opponent's moves while unskilled players merely react, and skilled players may notice relational similarity and use that similarity to their advantage.
 A c k n o w l e d g m e n t s This work was supported in part by a Hampshire College Faculty Development Grant to the first audior and NSF grant #9001936 to the second author.
 W e wish to thank Mike O'Neal for testing the human subjects, and Lee Spector and Jason Juneau for designing and implementing the expert gameplaying programs used in this work.
 References Ananlharaman.
 T.
, Campbell, M.
 S.
, & Hsu, F.
h.
 (1990).
 Singular extensions: Adding selectivity to bruteforce searching.
 Artificial Intelligence, 43,9910.
 Berliner.
 H.
 & Ebeling, C.
 (1989).
 Pattern knowledge and search: The SUPREM architecture.
 Artificial Intelligence, 38, 161198.
 Biswas.
 G.
.
 Goldman.
 S.
.
 Fisher, D.
.
 Bhuva, B.
.
 & Glewwe, G.
 (1995).
 Assessing design activity in complex C M O S circuit design.
 In P.
 Nichols, S.
 Chipman, & R.
 Breiman, (Eds) Cognitively diagnostic assessment.
 Hillsdale, NJ: Erlbaum.
 Binet, A.
 (1894).
 Psychologie des grands calculateurs et joueurs d'echecs.
 Paris: Hadiette.
 Chamess, N.
 (1981).
 Search in chess: Age and skill differences.
 Journal of Experimental Psychology: Human Perception and Performance, 7,467476.
 Chase, W.
 G.
 & Simon, H.
 A.
 (1973).
 The mind's eye in chess.
 In W .
 G.
 Chase (Ed.
), Visual information processing (pp.
 215281).
 New York: Academic Press.
 Chi, M.
 T.
 H.
.
 Bassok, M.
, Lewis, M.
 W.
, Reimann, P.
 & Glaser, R.
 (1989).
 Selfexplanations; How students study and use examples in learning to solve problems.
 Cognitive Science, 13, 145182.
 Crowley.
 K.
 & Siegler, R.
 S.
 (1993).
 Flexible strategy use in young children's tictactoe.
 Cognitive Science, 17, 531561.
 Djakow.
 1.
 N.
, Petrowski, N.
 W.
 & Rudik, P.
 A.
 (1927).
 Psychologie des schachspiels.
 Berlin: de Gruyter.
 Egan.
 D.
 E.
 & Schwartz.
 B.
 J.
 (1979).
 Chunking in recall of symbolic drawings.
 Memory and Cognition, 7, 149158.
 Engle, R.
 W.
 & Bukstel, L.
 (1978).
 Memory processes among bridge players of differing expertise.
 American Journal of Psychology, 91,673689.
 Eisenstadt, M.
 & Kareev, Y.
 (1975).
 Aspects of human problem solving: The use of internal representations.
 In D.
 A.
 Norman, & D.
 E.
 Rumelhart (Ed), Explorations in cognition (pp.
 308346).
 San Francisco: Freeman.
 Epstein, S.
 L.
 (1992).
 Prior knowledge strengthens learning to control search in weak theory domains.
 International Journal of Intelligent Systems, 7, 547586.
 Epstein, S.
 L.
 (1993).
 The Hoyle Learning Experiments (CSTR9302).
 Hunter College, Department of Computer Science.
 Epstein, S.
 L.
 (1994).
 For the right reasons: The FORR architecture for learning in a skill domain.
 Cognitive Science, 18, 479511.
 Epstein, S.
L.
 & Gelfand.
 J.
 (1995).
 Learning spatiallyoriented gameplaying agents through experience.
 In Proceedings of the 17th Annual Meeting of the Cognitive Science Society, Hillsdale.
 NJ:Erlbaum.
 Holding, D.
 (1985).
 The psychology of chess skill.
 Hillsdale, NJ: Lawrence Erlbaum.
 Shneiderman.
 B.
 (1976).
 Exploratory experiments in programmer behavior.
 International Journal of Computer and Information Sciences, 5, 123143.
 714 A DualRoute Model that Learns to Pronounce English W o r d s Roger W.
 Remington NASA Ames Research Center MS 2622 Moffett Field, C A 94035 rwr@cs.
emu.
edu Craig S.
 Miller Computer Science Department Carnegie Mellon University Pittsburgh, PA 152133891 cmiller@cs.
cmu.
edu Abstract This paper describes a model that learns to pronounce English words.
 Learning occurs in two modules: 1) a rulebased module that constructs pronunciations by phonetic analysis of the letter string, and 2) a wholeword module that leams to associate subsets of letters to the pronunciation, without phonetic analysis.
 In a simulation on a corpus of over 300 words the model produced pronunciation latencies consistent with the effects of word frequency and orthographic regularity observed in human data.
 Imphcations of the model for theories of visual word processing and reading instruction are discussed.
 Introduction Mastering English word pronunciation is made difficult by the many inconsistencies in English spelling to sound correspondences.
 As a result, the skilled reader of English cannot be content with learning a small set of generally applicable rules, but instead must master a large number of highly specific rules and their exceptions.
 For example, a rule that would pronounce the word 'bough' would have to specify the entire word to distinguish it from 'rough' or 'through.
' It is not surprising that many children have great difficulty learning to read English, and many adults remain poor readers.
 If we understood how knowledge about pronunciation was acquired and represented, it might be possible to design more effective instructional techniques.
 Our understanding of how pronunciation knowledge is learned and represented can be furthered by modeling the process with the goal of simulating the behavior of the human learner.
 This approach has been taken by Coltheart et al (1993), Seidenberg & McClelland (1989), and Seidenberg et al (1995).
 The model of Coltheart et al (1993) learns symbolic pronunciation rules which specify letterphoneme correspondences for specific letter contexts.
 Each rule receives a weight proportional to the number of different words in which the rule applies.
 This procedure weights letterphoneme correspondences on the basis of their predictive value across words, rather than on the frequency of occurrence alone.
 This model generates correct pronunciations for a large proportion of English words.
 The models of Seidenberg & McClelland (1989) and Seidenberg et al (1995) learn to pronounce words by adjusting the weights between word features and phoneme units in a connectionist network.
 Their models are sensitive to the relative frequency of specific letterphoneme correspondences in specific contexts.
 Both Seidenberg & McClelland (1989) and Seidenberg et al (1995) train their systems by presenting words in proportion to their (log) frequency of occurrence in English text.
 Thus, weights in their models are sensitive to both the regularity across words and the frequencies of the individual words in which specific mappings appear.
 The two connectionist models differ considerably, but each has been successful in accounting for important regularities in isolated word and nonword pronunciation, demonstrating that a uniform process of phonetic analysis can simulate a diverse range of human pronunciation data.
 In general, however, the psychological literature suggests that multiple distinct memory systems are involved in learning complex tasks (see Baddeley 1990).
 Researchers in reading have long debated the role of phonetic analysis and visual recognition in reading individual words (e.
g.
, Paap et al 1987).
 Differences in learning strategy or ability can result in different patterns of performance.
 Teaching methods have tended to reflect the changing preferences for phonetic analysis vs.
 wholeword recognition with little understanding of how this affects reading fluency.
 In this paper we report results of simulations that explore how multiple learning algorithms could cooperate to learn to pronounce a large corpus of English words.
 Because we ultimately simulate the acquisition of reading skill under different instructional techniques, we choose an architecture that can capture the contribution of both phonetic analysis and wholeword techniques.
 Learning proceeds in two distinct modules: 1) a rulebased module that learns specific lettertophoneme rules, and 2) a wholeword module that leams to map word features to the complete pronunciation without phonetic analysis.
 After training, some words are pronounced by the application of phonetic rules, others by complete or partial mappings of letters to whole word pronunciations.
 Model Description The model is implemented in the Soar cognitive architecture (Newell 1990).
 In Soar, all knowledge is stored in longterm memory as productions, which fire when their conditions are matched by elements in working memory.
 When a production fires its output is placed in working memory.
 In Soar, productions propose, select, and apply operators, which are Soar's basic units for modifying internal representations.
 When a Soar model initially encounters a problem, it may not yet have the productions needed to propose or select the appropriate operator.
 At this point, Soar reaches an impasse and must create a subgoal in which other existing knowledge can be used to resolve the impasse.
 For example, Soar may engage in lookahead search by trying out one of the com715 mailto:rwr@cs.
emu.
edumailto:cmiller@cs.
cmu.
edupeting operators to see if it produces a familiar word.
 Soar learns by resolving impasses.
 Once an impasse is resolved, the subgoal knowledge used in the resolution is "chunked" into a single production which will then immediately fire the next time the same problem is encountered.
 Since a chunk summarizes the performance of several operators, chunking produces more efficient processing resulting in a speedup in performance.
 Also, depending on the generality of the chunked production, the selection knowledge may transfer to similar problems.
 Soar's chunking mechanism is the basis for our model's learning algorithms.
 The important functionality of the model is contained in two modules: the rulebased module, and the wholeword module.
 The rulebased module attempts to construct a pronunciation by phonetic analysis.
 Knowledge about letterphoneme correspondences are stored as rules that produce phonemes given a letter context.
 Prior to training, the rulebased module is given rules for all individual letterphoneme correspondences (including letter pairs, such as 'th,' that map onto single phonemes).
 These rules are not sufficient to reliably construct pronunciations.
 All vowels and some consonants have more than one phoneme correspondence, and the model must learn to resolve this ambiguity by learning rules for choosing the correct phoneme.
 The greater the consistency in letterphoneme mapping for a particular context, the greater the opportunity for learning rules that generalize to other words.
 The wholeword module begins with no domain knowledge.
 During training, its algorithm will create rules which map one or more of the letters in a word to the entire pronunciation for the word.
 To describe the model's functioning, consider how the model might learn to pronounce its first word, 'dog' [/dog/] (the phonetic notation used in Seidenberg & McClelland, 1989 will be used throughout).
 The model first attempts to match a pronunciation production to the entire letter string ('dog').
 With sufficient exposure to a word there is a high likelihood that a chunk will have been created that associates the entire letter string to the correct pronunciation.
 If so, the model produces the pronunciation in the minimum number of steps.
 If no such chunk exists, as is the case upon initial presentation of a word, an impasse results and the model first tries to construct a pronunciation by phonetic analysis in the rule system.
 In the rule system, phonetic analysis proceeds by successively selecting a phoneme for each letter working from the beginning of the word to the end.
 A n index pointer is set to the first letter ('d') and rules that assign phoneme values to the letter 'd' are proposed.
 Since there are some double letters that map onto single phonemes (e.
g.
, 'th' —• /T/) and since prior learning may have produced rules which consider the subsequent letter context, rules that map 'do' and 'dog' are also matched.
 Rules which match a larger context are preferred, thereby creating a bias in favor of rules with more specific contextsensitive assignments during learning.
 At the outset, however, there are no more specific rules for the 'd' in 'dog' and given that *d' is unambiguous, the phoneme /d/ is chosen as the first phoneme, and the index pointer updated to the 'o'.
 The vowel "o' has several phonetic realizations.
 A n impasse is reached because there is no knowledge yet to use to select one of the options.
 A subgoal is created to resolve this impasse.
 In the current implementation, operators in the subgoal choose randomly from the set of possible phonemes and then attempt to complete the word pronunciation.
 If the correct pronunciation is generated, the model learns by associating the correct pronunciation of the 'o' with the subsequent two letters.
 For the 'o' in 'dog' it will build a rule that prefers the phoneme lol for the letter 'o' when followed by a wordfinal 'g'.
 If the model chooses correctly in this subgoal, it returns the correct phoneme for 'o' to the phonetic analysis subgoal.
 If the model chooses incorrectly, our current implementation expends no further resources and simply guesses among the remaining operators.
 In either case, the index pointer advances to 'g', which can either be realized as a hard or soft 'g'.
 Again, an impasse results and the subgoal process is repeated for 'g'.
 If the rulebased module correctly assembles the pronunciation, it summarizes its processing by building a chunk that produces /dog/ from 'dog'.
 It may also have built a rule to pronounce 'o' when followed by wordfinal 'g' and/or a rule to pronounce wordfinal 'g'.
 The chances of correctly pronouncing 'dog' on the first try are about 1 in 12.
 The initial set of letterphoneme rules specify 6 alternate phonemes for 'o' and 2 for 'g'.
 Both mappings must be correctly assigned before learning will occur.
 Likewise, the rule for "o' followed by wordfinal 'g' has a 1 in 12 chance of being learned, since again both mappings must be correctly assigned.
 The final 'g' rule however has a 1 in 2 chance of being learned.
 In general, our model is biased to resolve ambiguities at or near the end of a word before those at or near the beginning.
 Repeated exposures to the word 'dog' will increase the likelihood of one or more of the rules being learned.
 Likewise, repeated exposure to words with wordfinal 'g' and with wordfinal og' will eventually produce rules that resolve those ambiguities.
 Thus, with a few exposures to 'dog' and 'log' there is a reasonable probability of quickly generating pronunciations for 'bog', 'cog' and even nonwords such as 'mog'.
 The model will learn less useful chunks if initially exposed to many words with irregular letterphoneme correspondences.
 Since the more regular letterphoneme correspondences occur more often by definition, there is a greater probability of learning regular correspondences in the rulebased module.
 Initially, the chance of correctly pronouncing a word is small, even for a very regular word like 'dog'.
 If the phonetic analysis fails the wholeword module attempts to generate a pronunciation.
 The algorithm used in the wholeword module is adapted from the Symbolic Category Acquisition (SCA) algorithm of Miller (1993).
 Input to S C A is an object defined by features; output is a category to which the object is assigned based on the set of features.
 Here, S C A treats the letters in a word as features, and the pronunciation as the category.
 As training progresses S C A builds productions that map an increasing number of letters in a word to the pronunciation.
 In this way, repeated exposure leads to more specific productions, until at the end there is a production that associates the entire letter string with the correct pronunciation.
 It is possible to learn to pronounce a word solely by the wholeword module.
 Once there is a chunk that matches the entire 716 letter string that chunk will fire in the first stage of processing and will be pronounced in minimum lime, regardless of whether that chunk was created in the rulebased module or the wholeword module.
 Because letter strings are always being matched to whole pronunciations, the wholeword system does not learn productions of general utility In contrast, productions in the rulebased system specify single letter pronunciations for specific contexts that can appear in many words.
 This distinction captures an important difference between wholeword reading and phonetic analysis.
 Simulation We evaluated the model by training it on a corpus of words of varying frequency and orthographic regularity.
 The combined effects of word frequency and orthographic regularity produce a highly reliable pattern of pronunciation times in human data.
 High frequency words are pronounced more rapidly than low frequency words.
 Orthographically regular low frequency words are pronounced more rapidly than orthographically irregular low frequency words.
 But, regularity has no effect on high frequency words, many of which are irregular.
 If our model correctly simulates pronunciation difficulty, then it should produce pronunciation latencies that at least preserve the ordinal relationships seen in the human data.
 W e use the number of Soar operators selected as a measure of pronunciation latency.
 The greater the number of operators required for a task, the greater the difficulty and, hence, the greater the latency.
 Our model requires a minimum of 2 operators for a fully learned word: one to perceive the letter string, and one to generate the pronunciation.
 If a word is not fully learned, additional operators will be needed for the phonetic analysis and the wholeword generation.
 The maximum number of operators depends on the nature of the input and prior exposure and cannot be calculated directly.
 The maximum observed in this simulation was 46 operators.
 J.
 McClelland graciously provided us with the word list used by Seidenberg & McClelland (1989).
 W e created a word list containing regular and exception words by selecting items from the Seidenberg & McClelland word list that had already been categorized on the basis of orthographic regularity (see Seidenberg & McClelland, 1989).
 Consistent and regular words have regular orthography and were both categorized as regular.
 Exception words and some strange words (e.
g.
 'aisle') have irregular orthography and were grouped together as exception words.
 The strange words with consistent, regular orthography (e.
g.
 'yelp') were categorized as regular.
 This yielded a total of 208 regular words and 127 exception words.
 To simulate word frequency, the number of exposures to each word was determined by dividing its log frequency by the log frequency of the least frequent word.
 This procedure maintains the ratio of log frequencies between words.
 For analysis, the resulting frequency ratios were then partitioned into three equally spaced frequency categories.
 Each word was thus categorized as a 'high' 'medium' or 'low' frequency word.
 The resulting list was randomized to avoid biasing the model by systematic presentation effects.
 Five repetitions of the list were run and statistics computed after each run.
 Table 1: Model Latencies by Frequency Preq Regular Exception ER Low Med High 10.
12 3.
50 2.
27 12.
20 4.
22 2.
34 2.
08 .
72 .
07 Table 2: Model Latencies by Training Cycle Freq Low Med High Run 1 2 3 4 5 1 2 3 4 5 1 2 3 4 5 Regular 20.
04 11.
50 7.
71 6.
13 5.
26 8.
86 2.
67 2.
00 2.
00 2.
00 3.
33 2.
00 2.
00 2.
00 2.
00 Exception 21.
67 14.
15 10.
28 8.
26 6.
64 12.
63 2.
50 2.
00 2.
00 2.
00 3.
70 2.
00 2.
00 2.
00 2.
00 ER 1.
63 2.
65 2.
51 2.
13 1.
38 3.
77 .
17 0 0 0 .
43 0 0 0 0 Table 1 shows a frequency by regularity interaction similar to that seen in the human data.
 The advantage of regularity seen for low frequency words is systematically reduced with increasing frequency.
 Table 2 shows the data broken down by runs.
 The advantage of regularity decreases in all frequency groups as the number of runs increases.
 However, this decrease is much less for the lowest frequency words.
 Interestingly, with enough exposure all words are pronounced very quickly.
 This too is a feature of the human data.
 Good readers do not show the effect of orthographic regularity for low frequency words, presumably because they have seen even moderately low frequency words many times.
 Like our model, human readers seem to be sensitive to the absolute amount of exposure, not just to the relative frequency.
 The rulebased system learns chunks that resolve letter ambiguities by looking at the immediate letter context.
 These rules should generalize to words with similar contexts, speeding up the learning of new words.
 This trend appears in Table 2.
 If the rulebased system is learning useful chunks, generalization should be more effective with regular words than exception words.
 Table 3 shows that 5 9 % of the correct recognitions occurred in the rulebased module, 4 1 % in the wholeword module.
 The conditional probability of a rulebased solution given a regular word was p(rule | regular) = .
66, while p(whole | regular) = .
34.
 The rulebased system pronounced almost twice as many regular words as the wholeword module.
 In contrast, the conditional probabilities for exception words was: p(rule | exception) = .
46, p(whole I exception) = .
54.
 The wholeword module pronounced a slightly greater proportion of exception words than the rulebased module.
 This is consistent with our initial expectation that analysis should be more effective for regular words than for irregular words.
 717 Table 3: Relative Frequency of Process Method RuleBased WholeWord Regular Exception .
44 .
15 .
23 .
18 Discussion We have shown how even a simple twoprocess model can account for important aspects of human data on visual word pronunciation.
 One obvious concern is that w e have produced only qualitative fits, relying on the overall similarity of patterns between the human response time results and operator count, which measures the computational complexity of the problem for our Soar model.
 A related concern is that the model learns too quickly.
 Performance is at asymptote after only 15 exposures to a corpus of over 300 words.
 Surely, this exceeds human learning rates.
 Consider, however, that there are many parameters that could be adjusted to improve the correspondence to response time and learning rate data.
 Changing the input features from letters to letter features, for example, would alter the learning rate of both modules, create chunks that mapped fragments of two letters onto a phoneme, and affect the contexts over which generalization would occur.
 Likewise, by tinkering with the phonetic analysis and the S C A algorithm w e could fine tune the number of operators.
 For example, gradually increasing the specificity of the chunks with training would alter both the learning rate and the relative number of operators for regular and exception words.
 And so on.
 For present purposes though w e deliberately avoided the temptation to adjust parameters to achieve a better fit.
 Because w e are striving for a model with breadth that could also simulate different methods of reading instruction, it seemed prudent to explore a very simple, straightforward architecture, and not risk overfitting by arbitrarily adjusting parameters.
 A reliance on ordinal fits also avoids assumptions about the relative scale properties of response time and operators.
 Newell (1990) derives a estimate of 60120 msec for a decision cycle which has proven useful in fitting data in some contexts.
 Each decision cycle represents the selection of an operator, and any such estimation assumes that each operator takes an approximately constant time.
 This approximation may fail because it does not adequately reflect brain processing, or because operators within a model are not matched for computational complexity.
 Ordinal fits make fewer potentially erroneous assumptions.
 What do w e feel are the theoretically important features of our model? Certainly, there is a theoretical stance taken in using a dualroute approach.
 Because we wish ultimately to model the effects of different instructional methods, it is important to explore the hypothesis that they produce different internal representations.
 The model also asserts that phonetic analysis rules are taught, not inferred from practice.
 The effect of practice is to condition the application of the rules.
 The model currently has no way of creating phonetic rules without explicit knowledge of the individual letterphoneme correspondences.
 Without this knowledge all learning will be done in the wholeword system, whose rules will not generalize.
 This is a strong assertion.
 Later implementations may relax this to enable the model to reason about the possible letterphoneme relationships in words it has learned in the wholeword module.
 However, w e know of no data that would suggest that such reasoning is done implicitly when reading, nor data that would suggest that the rules for phonetic analysis can be learned implicitly from wholeword instruction/reading.
 Our current hypothesis is that if children can learn phonetic rules by inference, then it is not a byproduct of reading, but a separate deliberate process.
 Another feature of the model is the assumption that fully learned words are "recognized" and not pronounced by phonetic analysis.
 Phonetic analysis occurs only for words that have not been fully learned.
 With enough exposure then, many words will be pronounced as wholewords.
 Currently, this exposure is in terms of absolute frequency.
 The higher a word's frequency, the more often it is encountered, and the greater the opportunity for one of the two system to learn it completely.
 The only effect of relative frequency is to alter the probability that a given word will be encountered.
 It is not clear yet whether the strong form of this is correct.
 The evidence that good readers show no difference in pronunciation times for regular and irregular words suggests that the absolute number of times a word is encountered is important.
 Our model perhaps exaggerates the effect of absolute frequency by learning so quickly, but this serves the useful purpose of focusing interest on this factor Finally, the model is sensitive to the order in which it encounters training examples.
 If given regular words, it will learn chunks that can be usefully generalized.
 If first exposed to irregular words, the chunks will be less useful.
 Again, the effect may be exaggerated by the simplicity of the model, but this too leads to interesting and testable predictions for reading instruction.
 A simple dual process model of human visual word pronunciation was presented that successfully simulates the combined effects of word frequency and orthographic regularity.
 The simplicity of the model exaggerates the effects of certain factors, such as absolute frequency and order effects in training, providing useful insights into factors which may also affect how w e learn to read.
 Acknowledgements This research was sponsored in part by the McDonnell Foundation, Grant JSMF 9134, and by the Markle Foundation.
 The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the McDonnell Foundation or the Markle Foundation.
 References Baddeley, A.
 (1990).
 H u m a n Memory: Theory and Practice.
 Boston, M A : Allyn and Bacon.
 Coltheart, M.
, Curtis, B.
, Atkins, R, & Haller, M .
 (1993).
 Models of reading aloud: Dualroute and parallel distributed processing.
 Psychological Review, 100, 589608.
 Miller, C.
 S.
 (1993).
 Modeling Concept Acquisition in the Context of a Unified Theory of Cognition.
 P h D thesis, The University of Michigan.
 Also available as Technical Report CSETR15793.
 718 Newell, A.
 (1990).
 Unified Theories of Cognition.
 Cambridge, M A : Harvard University Press.
 Paap, K.
 R.
, McDonald, J.
 E.
, Schvaneveldt, R.
 W.
, & Noel, R.
 W.
 (1987).
 Frequency and pronounceability in visually presented naming and lexical decision tasks.
 In Coltheart, M.
 (Ed.
), Attention and Performance Xll: The Psychology of Reading.
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Seidenberg, M.
 S.
 & McClelland.
 J.
 L.
 (1989).
 A distributed, developmental model of word recognition and naming.
 Psychological Review, 96, 523568.
 Seidenberg, M.
 S.
, Plaut, D.
 C , Peterson, A.
 S.
, McClelland, J.
 L.
, & McRae, K.
 (1994).
 Nonword pronunciation and models of word recognition.
 Journal of Experimental Psychology: Human Perception and Performance, 20, 11771196.
 719 Mental Models and Rule Rephrasing Juliet Richardson Department of Psychology Lancaster University Lancaster, LAI 4YF, United Kingdom.
 J.
Richardson@uk.
ac.
lancaster Thomas C.
 Ormerod Department of Psychology Lancaster University Lancaster, LAI 4YF, United Kingdom.
 T.
OrmerodQuk.
ac.
lancaster Abstract An experiment is reported which uses a rephrasing task to investigate factors affecting the formation of initial mental models.
 It was found that both the syntax and the thematic content of the rule affect the initial model set̂  formed: the syntax determines the form of the initial model set and the semantics add to this initial set through the representation of subjects' prior knowledge about the situation in question.
 Specifically, causal content invokes general knowledge about causal relationships which leads to the addition of models representing counterfactual situations in the initial model set.
 In comparison, familiar content invokes specific knowledge which leads to the completion of existing models in the initial set.
 Thus, our experiment enables an extension of mental models to be made that accounts for the diffoential effects of general and specific prior knowledge.
 Introduction The mental models theory developed by JohnsonLaird (1983) has been used to provide an account of many of the phenomena observed in human deductive reasoning (see Evans, Newstead and Byrne, 1993; JohnsonLaird and Byrne, 1991) and language more generally (see JohnsonLaird, 1983).
 However a number of authors (e.
g.
 Evans, 1993) suggest that the failure to provide an extensive account of the effects of varying problem content is a weakness in the theory.
 If mental models theory is to provide a comprehensive account of reasoning and linguistic performance then this problem must be addressed.
 According to mental models theory, in deductive reasoning tasks the subject forms models representing each premise.
 The information contained in these initial models ^ W e use the term 'model set' to describe the set of one or more individual models that subjects form as a mental representation of premise information: this avoids the ambiguity of 'mental model' referring both to individual modeb that contribute to a mental representation and to the whole representation of premise information.
 Like JohnsonLaird and Byrne (1991) we distinguish between initial model sets and fleshedout model sets as two stages in model formation.
 At each stage the model sets may be complete (i.
e.
 having an exhaustive representation of all contingencies) or incomplete.
 is then combined to form one model from which conclusions can be drawn.
 In such tasks factors affecting the formation of models and the drawing of conclusions are confounded.
 In order to study in isolation the effects of rule content on model formation a task is required in v ^ c h the subject does not have to manipulate premise information to draw a conclusion.
 Rephrasing between logically equivalent linguistic forms (e.
g.
 Cheng and Holyoak, 1985; Fillenbaum, 1975, 1976; Ormerod, Manktelow and Jones, 1993) is one such task.
 For example, a subject may be given the rule "If it is raining then the ground is not dry" and asked to produce a rephrasing in the form Either.
.
.
or.
.
.
 such as "Either it is raining or the ground is dry".
 If subjects use an initial model set representing the first rule to produce a rephrasing of it then their accuracy at rephrasing rules will reflect this initial model formation.
 By presenting rules with different rule contents to be rephrased the effect of rule content on initial mental model formation can be investigated.
 The experiment reported in this paper examines the psychological treatment of conditional (If.
.
.
then.
.
.
) and disjunctive (Either.
.
.
or.
.
.
) forms in a rephrasing task.
 This particular rephrasing has not been previously reported in the literature although there is a large body of research investigating conditional and disjunctive reasoning separately.
 Mental models theory already provides accounts of disjunctive and conditional reasoning with arbitrary contents; the rephrasing task provides data that can be used to extend these accounts to include reasoning with realistic contents.
 Logical Equivalence of Conditionals and Disjunctives A conditional of the form IfP then Q can be interpreted in two ways: either as a biconditional where If P then Q imphes the converse IfQ then P, or as an implication wliere Q can occur in the absence of P.
 Similarly, a disjunctive of the form Either P or Q can be interpreted in two ways: it can be exclusively interpreted as Either P or Q but not both, or inclusively interpreted as Either P or Q or both.
 If truth tables for the two forms are compared (see JohnsonLaird and Byrne, 1991, pp 78) then the logical equivalence of biconditionals and exclusive disjunctives and of implications and inclusive disjunctives can be observed.
 720 A Mental Models Account of Conditional and Disjunctive Reasoning JohnsonLaird and Byrne's (1991) mental models theory provides a plausible psychological account of rephrasing.
 The theory proposes that subjects construct an initial, possibly incomplete, model set of the given premises.
 This set is then fleshed out if necessary to provide a complete model set and is used to formulate and evaluate possible inferences.
 For example, given the premise "If the letter is A then the number is 2" an initial model set as shown below will be formed^:If a subject is given the further premise T h e letter is not A" and is asked what follows, the initial model set can then be fleshed out as a biconditional or as an implication as shown below:[A] [A] [A] [A] [2] [2] [2] [2] Biconditional Implication H A ] [2] The biconditional model set supports the conclusion "The number is not 2" whilst the implication model set supports no unique conclusion A similar account is provided for disjunctive reasoning.
 For example, given the premise "Either the letter is A or the number is not 2" a set of two initial models as shown below will be formed:If the subject is given the fiirther premise "The letter is A" and is asked what follows, then the initial model set can be fleshed out in two possible ways corresponding to exclusive or inclusive interpretations:[A] [A] [2] [2] Exclusive ^ JohnsonLaird and Byrne (1991) provide a notation for describing mental models in which —• denotes a negated component, ••• denotes the possibility of further models and [ ] denotes the exhaustive representation of one contingency with respect to another within the model set.
 [A] [A] [A] [2] [2] [2] Inclusive The exclusive model set supports the conclusion "The number is not 2" wiiilst the inclusive model set supports no unique conclusion.
 The initial model sets formed for logically equivalent conditionals and disjunctives differ.
 Conditionals have a single model in which both components are represented, whilst disjunctives have two models each representing one of the components (see also JohnsonLaird, Byrne and Schaeken, 1994, Table 1, p424).
 Thus if a subject forms an initially unfleshed out model then s/he will not be able to use this to produce a rephrasing without fleshing it out.
 However the fleshed out model sets for logically equivalent conditionals and disjunctives are equivalent.
 For example, the fleshed out model set for a biconditional interpretation of "If the letter is A then the number is 2" is the same as the model sets for exclusive interpretations of "Either the letter is not A or the number is not 2" and "Either the letter is A or the number is not 2".
 Whereas if an implicational interpretation is made, then the fleshed out model set formed is only identical to the model set for an inclusive interpretation of "Either the letter is not A or the number is 2" (see JohnsonLaird and Byrne, 1991, pp4351).
 Thus only fully fleshed out mental model sets support the production of rephrasings and even then the number of possible correct rephrasings is affected by the particular interpretation made.
 Effects of Prior Knowledge on Rule Interpretation The truthtable analysis and mental models theory show h o w the logical and psychological equivalence of conditionals and disjunctives depends upon their interpretation.
 The literature indicates two factors that affect the interpretation of conditionals: familiarity and causality.
 Markovits (1986) found that unfamiliar conditionals were more likely to be interpreted as biconditionals.
 H e argued that for familiar conditionals subjects more easily generate examples of the consequent occurring without the antecedent.
 Therefore, they are more likely to interpret a familiar conditional as an implication and an unfamiliar conditional as a biconditional.
 It seems that prior knowledge of specific instances discourages a biconditional interpretation.
 Marcus & Rips (1979) found that biconditional interpretations were more likely for causal rather than noncausal conditionals.
 A similar explanation to that proposed by Markovits can also account for this finding, invoking general rather than specific knowledge.
 People have general knowledge about causal relationships, notably that the consequent does not usually occur in the absence of the antecedent in causal events.
 Thus, general knowledge about causality directs the subject to form a biconditional interpretation.
 Several factors affect the interpretation of disjunctives.
 For example, Newstead, Griggs, & Chrostowski (1984) 721 found that altering the context led to different interpretations of disjunctives.
 For example, a threat context led to more exclusive interpretations than a qualification context.
 It is likely that knowledge of specific and general cases directs the interpretation of disjunctives in a similar way to conditionals.
 Mental Models and Thematic Content If JohnsonLaird and Byrne's (1991) mental models theory is to provide a comprehensive account then it must explain the effects of thematic content.
 Although the existing mental models account of the effects of content on reasoning is incomplete (see Evans, 1993) it does provide an account of the effects of causal content.
 For conditionals expressing causal relationships, JohnsonLaird and Byrne state that "general knowledge informs the choice of what to represent in the models" (1991, p70).
 They propose that the subject forms an initial model set representing the actual and counterfactual situations associated with the causal relationship.
 This is consistent with the proposal that causal content evokes general prior knowledge directing the subject to a biconditional interpretation.
 For example, if the subject is given a causal assertion such as "If the vase hadn't been dropped then it wouldn't have broken", then the possibility of one event occurring in the absence of the other is not considered and the model set is built accordingly:[dropped] [broken] Actual Counterfactual [1 dropped] [i broken] Although JohnsonLaird and Byrne do not explicitly describe h o w familiar content (i.
e.
 specific prior knowledge) affects the mental models formed, one might propose a similar account to that for causahty.
 If the subject is given a rule with unfamiliar content such as "If the quark is blue then the schmidt number is 10", then s/he will have no prior knowledge of occasions when the schmidt number is 10 but the quark is not blue.
 S/he will be unlikely to consider this contingency, and will form an initial model set reflecting its absence:[blue] [10] The exhaustive representation of affirmative antecedent and consequent components in this initial model set represents an assumption, following from the subject's failure to consider all contingencies, that the schmidt number is 10 only when the quark is blue.
 This initial model set can only be fleshed out in a manner consistent with a biconditional interpretation:[blue] [10] [.
blue] [,10] Thus, Markovits' findings concerning unfamiliar content and Marcus & Rips' findings concerning causality can both be accounted for by mental models theory.
 If the content is causal, then subjects incorporate general prior knowledge into their model sets, whereas if the content is unfamiliar it is the absence of specific prior knowledge that influences the model set formed.
 In both cases, subjects build initial model sets that can only be fleshed out in a way consistent with a biconditional interpretation.
 This analysis suggests that familiarity and causahty affect the formation of initial model sets rather than their subsequent fleshingout.
 It also seems probable that the initial model sets determine performance in a rephrasing task.
 Thus, manipulating the familiarity and causality of rule content is likely to have a large effect on rephrasing performance.
 The Experiment This experiment investigated effects of familiarity and causality on rephrasing between conditionals and disjunctives.
 Subjects received a task in which they were required to rephrase a given conditional into a disjunctive or vice versa.
 The initial model sets for disjunctives and conditionals are not equivalent whereas the fleshed out sets are.
 Thus if an incomplete initial model set is formed it will need to be fleshed out in order to produce a rephrasing.
 Fleshing out of mental model sets places a cognitive load on the subject and can lead to errors.
 Thus rephrasing performance should be worse when the rule content is unfamiUar or noncausal and the initial model sets need to be fleshed out.
 Another prediction about rephrasing performance also emerges from the effect of content on initial model set formation.
 One of the principles of mental models theory is that the more models that are formed the greater the load on working memory, with consequent reductions in reasoning performance.
 If one initial model is formed for a conditional and two initial models are formed for a disjunctive, then one can predict an asymmetry in rephrasing performance: rephrasing will be harder from a disjunctive into a conditional than when the rephrasing is in the opposite direction.
 This asymmetry should be observed when the initial model set is not fleshed out, in other words when the content is noncausal and unfamiliar.
 Method Subjects.
 Seventy one students from Loughborough University participated in the study as part of a first year course in Experimental Psychology.
 Materials and Design.
 Four factors were manipulated in this experiment.
 The first was the betweensubjects factor of causality: subjects were randomly assigned to rephrase either causal rules or noncausal rules.
 The other factors were all withinsubjects.
 The first of these was familiarity: subjects received both familiar (everyday situations) and unfamiliar (chemical processes) rules to rephrase.
 The rules were rated for familiarity and causality by two independent judges, whose judgements agreed 100% with our own.
 The second withinsubjects factor was the original rule: subjects generated disjunctive rephrasings from an original conditional and vice versa.
 The final factor was polarity: for 722 each type (e.
g.
 familiar causal disjunctives) subjects were presented with the four possible combinations of negated components.
 Therefore, in total, each subject rephrased sixteen rules.
 Procedure.
 The experiment was presented in a booklet containing instructions followed by the sixteen trials, one p ^ page, in a different randomised (xder for each subject.
 Subjects wrote their rephrasings in the booklet at their own pace, but were unable to change answers in the Ught of subsequent rephrasings.
 The duration of the experiment was 20 minutes.
 Results and Discussion Subjects' attempted rephrasings were judged correct if they could be judged logically equivalent to the original rule according to any possible interpretation of that original rule.
 Thus for each rule two possible forms of rephrasing were allowed.
 Also, implicit as well as explicit negatives were allowed, for example "in" was allowed in place of "not out".
 Table 1 summarises the data obtained from this experiment in terms of average percentage of correct rephrasings for each original rule and content.
 These data were subjected to an analysis of variance to test for main effects of and interactions between original rule, familiarity and causality.
 Original Rule There was a significant main effect of original rule, F(l, 69)=4.
22, p<0.
05.
 Performance was better when rephrasing from a conditional (76 J 7c correct) than from a disjunctive (72.
1% correct).
 Rephrasing from a disjunctive is harder than from a conditional because the two models represented in the initial model set for a disjunctive place a greater load on working memory than the single model for a conditional.
 As predicted this effect was greatest for noncausal and unfamiliar content, in other words, when the initial model was predicted to be incomplete.
 Familiarity.
 There was a significant main effect of familiarity, F(l, 69)=34.
37, /7<0.
001.
 Rephrasing from familiar rules (81.
5% correct) was significantly better than rephrasing from unfamiliar rules (67.
2% correct).
 The presence of unfamiliar content leads to the formation of incomplete initial model sets, which makes subsequent rephrasing harder because the subject must attempt to flesh out the model set.
 Fleshing out model sets increases the processing load faced by subjects, thereby increasing the UkeUhood of errors.
 Thus rephrasing performance is worse in the presence of unfamiliar content v^en the initial mental model is incomplete and must be fleshed out.
 There was also a significant twoway interaction between original rule and familiarity, F(l, 69)=65.
44, p<0.
001.
 Rephrasing from disjunctives was better •when the content was familiar (88.
5% correct) than when it was unfamiliar (55.
7% correct).
 This effect of familiarity was not seen in rephrasing from conditionals (74.
7% correct  familiar, 78.
8% correct  unfamiliar).
 Familiar rule content should invoke specific knowledge which causes secondary additions to the initial models set Table 1: Mean percentages of correct rephrasings obtained in the experiment.
 Initial Rule Familiarity Causality Example Rule Mean % Correct Model Set Familiar Causal If the milk is left out of the fridge then it will go off 85.
6 [out] [off] [.
out] [.
off] Noncausal If it is a satsuma then it is orange 63.
7 satsuma orange Conditional Unfamiliar Causal If the ethanol passes through a separator then chlorate will be removed 85.
0 [pass] [remove] [.
 pass] [.
 remove] Familiar Disjunctive Noncausal If a solid contains chloride then it absorbs water Causal Either you drink a bottle of whisky or you will stay sober Noncausal Either it is a frog or it walks Causal Either the hypersorber contains hydrogen or the channel will emit Unfamiliar benzene Noncausal Either the gas is ammonia or its Schmidt number is 0.
8 72.
6 93.
8 83.
1 66.
9 44.
4 [chloride] [drink] [.
drink] [frog] [frog] [contain] [.
 contain] ammonia [absorbs] [1 sober] [sober] [.
 walks] [walks] [1 emit] [emit] 0.
8 723 formed by the representation of the rule syntax.
 Two, albeit incomplete, models emerge through the representation of a disjunctive's syntax.
 For example, given the rule "Either it is a flamingo or it is not pink", representation of the syntax alone gives the following incomplete initial model set:flamingo I pink The effect of familiar content will be to add the missing components of the existing models in the initial model set (i.
e.
 subjects have specific knowledge that flamingos are pink and that things that are not pink cannot be flamingos):[flamingo] [pink] [1 flamingo] [1 pink] On the other hand, given the conditional "If it is a flamingo then it is pink", representation of the syntax alone gives only a single model in the initial model set:flamingo pink The negative contingency is not represented in this initial model set, and the presence of familiar content about pink flamingos does not encourage the subject to consider things that are not flamingos or things that are not pink.
 Thus familiar content does not add models to the initial model set, but only completes partial models that are already represented.
 Causality.
 There was a significant main effect of causality, F(l, 69)=16.
02, p<0.
001.
 Rephrasing from causal rules (82.
8% correct) was significantly better than rephrasing from noncausal rules (66.
0% correct).
 The presence of noncausal content leads to the formation of incomplete initial model sets making subsequent rephrasing harder because of the need to flesh out the model set.
 This effect of causality was strongest when the original rule was a conditional, with a smaller effect when it was a disjunctive.
 JohnsonLaird and Byrne (1991) argue that the presence of causal content leads to the explicit representation of counterfactual contingencies in the initial model set of conditionals.
 Thus, the representation of causal content creates nsw models in the initial model set for a conditional, enabling its completion.
 The smaller effect of causality on disjunctives may simply be because a partial representation of a counterfactual model already exists in the representation of the disjunctive syntax.
 Summary JohnsonLaird and Byrne's (1991) mental models theory appears to provide a parsimonious and coherent account of rephrasing performance.
 T w o factors contribute to an initial model set: representing the syntactic form of the original rule, and representing the thematic content embodied in the rule.
 Effects of familiarity and causality can be explained as secondary additions to the initial model set created by representing the rule syntax.
 Table 1 shows the mental models formed for different combinations of rule form and rule content.
 The effect of causal content is, as suggested by JohnsonLaird and Byrne (1991), to add an additional model representing the counterfactual contingency to the initial model set of a conditional.
 W h e n the initial rule is a disjunctive a partial counterfactual model is included in the representation of the rule syntax.
 Therefore causal content does not add extra models to the initial model set for a disjunctive.
 The effect of familiar content is to complete the partial models within the initial model set representing the rule syntax.
 Familiar content does not, in itself, add new models to the initial model set.
 Acknowledgements The first author was fiinded by a research studentship awarded by British Gas pic.
 The experiment was conducted whilst the authors were at the Department of Human Sciences, Loughborough University.
 W e thank Linden Ball and Jeremy Miles for providing assistance with statistics and commenting on drafts.
 References Cheng, P.
W.
 and Holyoak, KJ.
 (1985).
 Pragmatic reasoning schemas.
 Cognitive Psychology, 17,391416.
 Evans, J.
 S.
 B.
 T.
 (1993).
 O n rules, models and understanding.
 Behavioral and Brain Sciences, 16, 345346.
 Evans, J.
S.
B.
T.
, Newstead, S.
E.
 and Byrne, R.
M.
J.
 (1993).
 H uman reasoning: the psychology of deduction.
 Hove: Lawrence Erlbaum Associates.
 Fillenbaum, S.
 (1975).
 If: some uses.
 Psychological Research, 37,245260.
 Fillenbaum, S.
 (1976).
 Inducements: on the phrasing and logic of conditional promises, threats and warnings.
 Psychological Research, 38,231250.
 JohnsonLaird, P.
N.
 (1983).
 Mental models: towards a cognitive science of language, inference and consciousness.
 Cambridge: Cambridge University Press.
 JohnsonLaird, P.
N.
 and Byrne, R.
MJ.
 (1991).
 Deduction.
 London: Lawrence Erlbaum Associates.
 JohnsonLaird, P.
N.
, Byrne, R.
M.
J, and Schaeken, W .
 (1994).
 W h y models rather than rules give a better account of propositional reasoning: a reply to Bonatti and to O'Brien, Braine and Yang.
 Psychological Review, 101(4), 734739.
 Marcus, S.
L.
 and Rips, L.
J.
 (1979).
 Conditional reasoning.
 Journal of Verbal Learning and Verbal Behaviour, 18, 199223.
 Markovits, H.
 (1986).
 Familiarity effects in conditional reasoning.
 Journal of Educational Psychology, 78(6), 492494.
 Newstead, S.
E.
, Griggs, R.
A.
 and Chrostowski, J.
J.
 (1984).
 Reasoning with reaUstic disjunctives.
 Quarterly Journal of Experimental Psychology, 36A, 611627.
 Ormerod, T.
C.
, Manktelow, K.
I.
 and Jones, G.
V.
 (1993).
 Reasoning with three types of conditional: biases and mental models.
 Quarterly Journal of Experimental Psychology, 46A(4), 653677.
 724 H o w People Reason about Temporal Relations Walter Schaeken Laboratory of Experimental Psychology Department of Psychology Tiensestraat 102 B3000 Leuven Belgium waiter.
schaeken@psy.
kuleuven.
ac.
be Philip N.
 JohnsonLaird Department of Psychology Princeton University Green Hall Princeton, NJ 08544 USA phil@clarity.
Princeton.
edu Abstract The paper describes a theory of temporal reasoning and its implementation in a computer program.
 The theory postulates that individuals construct mental models, and it predicts that inferences that call for only one model to be constructed, such as: a happens before b.
 b happens before c.
 d happens while b.
 e happens while c.
 What is the temporal relation between d and e? will be easier than those that call for multiple models, such as a problem identical to the previous one except for its first premise: a happens before c.
 Experiment 1 showed that subjects were faster and more accurate with onemodel problems than with multiplemodel problems.
 They look more time to read a premise leading to multiple models than the corresponding premise in a onemodel problem.
 Experiment 2 showed that if the question came first and was presented with all the premises, then subjects can ignore an irrelevant premise.
 As predicted, the difference between onemodel and multiplemodel problems with valid conclusions then disappeared.
 Experiment 3 showed that the size of a model, i.
e.
, the number of events in it, and the distance apart of the critical events, also affected performance.
 Introduction Cognitive scientists have studied many aspects of time, but they have not hitherto investigated reasoning about temporal relations.
 Here is an example: After the plane flew through the storm, the pilot radioed the tower.
 The damage occurred while the plane flew through the storm.
 What is the temporal relation between the damage and the pilot radioing the tower? The answer, of course, is that the damage occurred before the pilot radioed the tower, and this answer is valid, i.
e.
, it must be true given that the premises are true.
 Temporal inferences are ubiquitous and often important, but h o w people make them is presently unknown.
 Our aim in this paper is to offer a solution to this problem.
 W e first outline h o w the theory of mental models accounts for temporal reasoning, next w e describe its implementation in a computer program, and finally w e report the results of three experiments that corroborate the theory.
 Mental Models and Temporal Reasoning: A Theory and an Algorithm The theory of mental models postulates that reasoning deductive or inductive ~ is a process in which reasoners first represent the meaning of premises, and then use this representation together with their knowledge to construct mental models of the relevant situations (see e.
g.
, JohnsonLaird & Byrne, 1991).
 If a conclusion is true in all the models of the premises, then it is necessary (valid); if it is true in most of the models of the premises, then it is probable; if it is true in at least some model of the premises, then it is possible; and if it is true in only a few models of the premises, then it is improbable.
 According to the model theory, the assertion: After the plane flew through the storm, the pilot radioed the tower.
 calls for a model that w e represent in the following diagram: s r in which the time axis runs from left to right, 's' denotes a model of the plane flying through the storm, and 'r' denotes a model of the pilot radioing the tower.
 Events can be conceived (and described) as momentary or as having durations, definite or indefinite.
 Hence, s is assumed to last for a certain duration that ends at some point prior to r.
 The assertion: The damage occurred while the plane flew through the storm.
 calls for the following addition to the model: s r d where 'd' denotes a model of the damage happening, and the 725 mailto:waiter.
schaeken@psy.
kuleuven.
ac.
bemailto:phil@clarity.
Princeton.
eduvertical dimension in the diagram is used to represent contemporaneity.
 This model corresponds to infinitely many different situations that have in common only the truth of the two premises, e.
g.
, the model contains no representation of the precise time at which the damage occurred.
 Yet, the conclusion: The damage occurred before the pilot radioed the tower is true in this model, and it is not falsified by any model of the premises.
 W e have implemented a computer program (in C o m m o n Lisp) that carries out temporal inferences using models.
 The program has a contextfree grammar for a fragment of English that contains assertions of the form, 'a happens before b', 'b happens while c', and so on.
 It constructs a semantic representation of any sentence in the fragment, using the meanings of words and semantic rules associated with each rule in the grammar.
 This semantic representation is then used to update the set of models.
 Given the semantic representation of the assertion: a hi^jpens before b, the program checks whether a or b is already represented in any model of the discourse.
 It then chooses the appropriate procedure: 1.
 If neither referent occurs in a model, the program starts a new model.
 2.
 If one referent but not the other occurs in a model, the model is updated to include the new referent.
 3.
 If the two referents occur in different models, these models are combined appropriately.
 4.
 If both referents occur in the same model(s), then the premise is verified in the model(s).
 Because the program constructs all possible models of coreferential premises, verifying an assertion yields one of the following three responses: the assertion is a valid deduction (it is true in all the models); it was previously possibly false (it is false in some of the models, which are duly eliminated); or it is inconsistent with the previous premises (i.
e.
, it is false in all the models).
 Given a question about the relation between two events, the program formulates a conclusion if a common relation holds between them over all the models of the premises; otherwise, it responds that there is no definite relation between the two events, either because different relations occur in different models or because the events do not occur in any one model.
 For example, given the following problem: a happens before b.
 b happens before c.
 d happens while a.
 e happens while c.
 What is the relation between d and e? the program constructs the following model: a b c d e from which it formulates the answer that d happens before e.
 Where the premises are rjot coreferential, as in: a happens while b c happens while d What is the relation between a and d? each premise has a separate model, and the models cannot be integrated into a single model because they are not coreferential.
 Hence, there is no definite relation between a and d.
 Some temporal descriptions are indeterminate, e.
g.
,: a happens before c b happens before c do not fix the temporal order of a and b.
 In such cases, the program constructs models corresponding to the three possibilities: a happens before b, b happens before a, a and b happen contemporaneously.
 This procedure is, in principle, an intractable one: it yields an exponential growth in the number of models as the indeterminacies mount up.
 Yet, the procedure is feasible as long as there is only a small number of indeterminacies.
 Human performance degrades with an increasing number of models  a predictable phenomenon if the human inferential system uses an intractable algorithm and a working memory of limited capacity.
 The program is restricted in the number of models that it can construct in trying to solve a problem (by analogy with a limited capacity working memory).
 When the models it has constructed exceed this number, it then searches for a chain of premises interrelating the two events in the question, and constructs models only from them.
 (If there is no question, then the program cannot use this strategy.
) Likewise, when human reasoners have immediate access to the question and the premises, they should construct models for just those premises that are relevant to the answer to the question.
 The advantages of this strategy are twofold.
 First, it ignores all irrelevant premises that are not part of the chain connecting one event in the question to the other.
 Second, it deals with the premises in a coreferential order in which each premise after the first refers to an event already represented in the set of models.
 Three Experiments on Temporal Reasoning The model theory predicts that an inference that depends on one model should yield fewer errors and take less time than one that depends on multiple models.
 W e have carried out several studies to investigate this prediction, and Experiment 1 is such a study in which we also examined another prediction of the model theory: The time taken to read a premise that calls for the construction of multiple models should be longer than the time taken to read the corresponding premise in a onemodel problem.
 This prediction cannot be made by a theory based on formal rules of inference  if one were to be formulated for temporal reasoning  because models would play no part in such a theory (cf Braine & O'Brien, 1991; Rips, 1994).
 W e examined four sorts of deductions: 1.
 Onemodel problems with only relevant premises: a happens before b.
 726 b happens before c.
 d happens while a.
 e happens while c.
 What is the relation between d and e? This problem has the following model: a b c d e If subjects were to use formal rules of inference, they would have to exploit the transitivity of "before' to establish that a happens before c.
 2.
 Onemodel problems with an irrelevant first premise (though this fact is not obvious to reasoners): a happens before b.
 b happens before c.
 d happens while b.
 e happens while c.
 What is the relation between d and e? This problem has the following model: a b c d e If subjects were to use formal rules of inference, this problem should be easier than the previous one, because there is no need to exploit transitivity, though they might be misled by the irrelevant first premise.
 3.
 Multiplemodel problems with a valid answer (but an irrelevant first premise): a happens before c.
 b happens before c.
 d happens while b.
 e happens while c.
 What is the relation between d and e? This problem has at least the following two models: a b c d e and b a c d e which support the answer d happens before e.
 If subjects were to use formal rules, this pwoblem should be no harder than the previous one because they have identical formal derivations.
 The second premise in problems of this sort calls for the construction of two alternative models, because of the indeterminacy between a and b.
 Hence, according to the model theory, it should take longer to read (and to interpret) this premise than the second premise of the onemodel problems.
 4.
 Multiplemodel problems with no valid answer: a happens before c b happens before c.
 d happens while b.
 e happens while a.
 What is the relation between d and e? This problem has the following alternative models: a b c e d and b a c d e which do not support a valid answer to the question.
 Reasoners must consider both of these models in order to realize that there is no valid answer.
 In contrast, reasoners who overlook one of the models of a multiplemodel problem with a valid conclusion may nevertheless draw the correct conclusion, which by definition holds for any model of the premises.
 24 students at the University of Leuven with no training in logic acted as their own controls and carried out eight versions of each of the four sorts of problems, and the order of presentation was randomized for each subject.
 The materials concerned daily activities by two persons, the main clause was prior to the subordinate clause in each premise, and the eight different versions of each sort of problem were constructed in order to counterbalance the temporal connectives.
 The premises were presented one after another under the subjects' control, so that premise 1 dis^peared when premise 2 appeared, and so on.
 The experiment was carried out by computer in order to record the reading time for each premise and the time to respond to the final question.
 The subjects were correct for 9 3 % of the onemodel problems with only relevant premises, 8 9 % of the onemodel problems with an irrelevant premise, 8 1 % of the multiplemodel problems with valid answers, and 4 4 % of the multiplemodel problems with no valid answers.
 There was no rehable difference in accuracy of solutions between the two sorts of onemodel problem (Wilcoxon's T = 50 , n = 11, U.
S.
).
 However, there was the following reliable trend in correct answers: onemodel problems were easier than multiplemodel problems with valid answers, which were easier than multiplemodel problems with no valid answers (by subjects.
 Page's L = 315, n = 24, e < .
(X)01; and by materials.
 Page's L = lll,n = 8, e < .
001).
 In addition, the onemodel problems were answered correctly more often than multiplemodel problems with valid answers (Wilcoxon's T = 167, n = 20 , e < 02).
 The pattern of correct answers accordingly corroborates the model theory and is likely to run counter to any theory based on formal rules of inference.
 The mean latencies to respond to the questions for the four sorts of problems were as follows: I M problems with an irrelevant premise: 5.
8 sec Transitive I M problems: 7.
0 sec M M problems with valid answers: 8.
7 sec M M problems with no valid answers: 10.
7 sec The response times to the question were faster for one model problems than for multiplemodel problems (Fi 23 = 7.
03, g < .
02).
 Likewise, the reading times of the second premise were reliably faster for onemodel problems than for multiplemodel problems (Fj 23 = 6.
3, 2 < .
02).
 This difference corroborates the crucial prediction, because the 727 second premise calls for the construction of alternative models in the multiplemodel case, but not in the onemodel case.
 Multiplemodel problems with a valid conclusion contain an irrelevant premise.
 Its presence is not the cause of their difficulty, because onemodel problems with irrelevant premises are easier than the multiplemodel problems.
 As our program shows, if the premises are interpreted under the guidance of the events referred to in the question, then irrelevant premises will be ignored and the multiplemodel problems with valid conclusions thereby become onemodel problems.
 In Experiment 2, w e presented all the premises together either followed by the question or else preceded by the question.
 W e tested 32 students at Leuven w h o acted as their own controls in a counterbalanced blocked design.
 W h e n the question was last, the difference in difficulty between the onemodel problems (94% correct) and the multiplemodel problems with valid conclusions (86% correct) was reliable (Wilcoxon's T = 90, n = 14, E < .
001).
 But, as w e predicted, when the question was first, the difference in difficulty between the onemodel problems (98% correct) and the multiplemodel problems with valid conclusions (98% correct) disappeared.
 Multiplemodel problems with no valid answer have no irrelevant premises and so should be unaffected by the position of the question, and indeed they remained difficult both when the question was first (56% correct) and when it was last (57% correct).
 Multiple models are difficult because they increase the load on the processing capacity of working memory.
 The size of a model is likely to have a similar effect, and w e have also carried out several experiments in order to investigate it In Experiment 3, each sort of problem concerned either six events or eight events, and the temporal between the two events in the question was either small or large.
 A n example of a 'smallinterval' problem for one model with six events is: a b e d X y and an example for one model with eight events is: a b c d e f X y where x and y are the two events in the question.
 A previous experiment had shown that smallinterval problems increase in difficulty as the number of events in a problem increases.
 In the 'largeinterval' problems, the events in the question were always maximally apart, i.
e.
, there were no irrelevant premises.
 A n example of a largeinterval problem for one model with six events is: a b e d X y and an example for one model with eight events is: a b c d e f X y A previous experiment had failed to detect any effect on accuracy of the size of the model with largeinterval problems  a surprising result if one believes in formal derivations since each extra event caUs for an extra step in the derivation.
 W e tested 24 students, who acted as their own controls and carried out four versions of each of the different sorts of problems and 16 multiplemodel problems with no valid answers.
 The problems were in a different order for each subject.
 The premises were presented one at a time on the computer screen under the subjects' control.
 Table 1 presents the percentages of correct responses for each of the eight sorts of problems with valid conclusions.
 Overall, the onemodel problems (86% correct) were easier than multiplemodel problems (80% correct: Wilcoxon's T = 136.
5, n = 18, B < .
05).
 The largeinterval problems were reliably easier Table 1: The percentages of correct responses for each of eight different sorts of problems in Experiment 3.
 6 events 8 events 6 events 8 events Smallinterval problems I M problems M M problems 94 83 72 72 I ̂ rgeinterval problems I M problems M M problems 95 92 83 73 than the smallinterval problems (86% versus Wilcoxon's T = 96, n = 15, £ < .
05).
 The problems based on 6 events were significandy easier than the problems based on 8 events (77.
4% versus 64.
2%; Wilcoxon's T = 282.
5, n = 24, E < .
0001).
 The difference between the smallinterval onemodel problems based on six events and eight events was significant (Wilcoxon's T = 78, n = 12, e < .
005).
 This difference was also significant for the largeinterval onemodel problems (Wilcoxon's T = 91, n = 14, 2 < .
05).
 However, there was a significant interaction: The difference between the two sorts of smallinterval problems was greater than the difference between the two sorts of largeinterval problems (Wilcoxon's I = 92, n = 15, p < 05).
 Hence, although largeinterval problems may increase in difficulty as the number of events increases, they do not do so as rapidly as smallinterval problems.
 This factor may underiie the threeway interaction (Wilcoxon's T = 31.
5, n = 13, e < .
05): With 6 events, the difference in difficulty between one model and multiple models is evident in smallinterval problems but not in largeinterval problems (which may be showing a 'ceiling' effect); whereas with 8 events, the difference in difficulty between one model and multiple models is evident in largeinterval problems but not in smallinterval problems (which may be showing a 'floor' 728 effect).
 G e n e r a l Discussion The experimental results suggest that reasoning about temporal relations depends on mental models rather than formal rules of inference.
 In general, the subjects in Experiment 1 read the four premises progressively faster, but contrary to this trend they took reliably longer to read a premise that led to multiple models than to read a corresponding premise in a onemodel problem.
 Likewise, a description consistent with just one model yielded an easier inference than a description consistent with more than one model, and the difference held whether or not there was an irrelevant premise (and regardless of the length of a formal derivation of the conclusion).
 Vandierendonck and D e Vooght (1994) have independently obtained similar results.
 W e have also corroborated them in a study of temporal relations established by tense and aspect, e.
g.
,: John has cleaned the house.
 He is taking a shower.
 He is going to read the paper.
 Mary always does the dishes when John cleans the house.
 She always drinks her coffee when he reads the paper.
 What is the temporal relation between Mary doing the dishes and drinking her coffee? Multiple models of temporal relations arise because of an indeterminacy, which in turn depends on an irrelevant premise for problems with valid answers.
 W h e n reasoners can use the question to guide their processing of the premises, they can ignore the irrelevant premise and in this way convert the problem into a onemodel one.
 Experiment 2 confirmed that subjects do indeed use this strategy, because the difference in difficulty between the two sorts of problems disappears in this case.
 The first two experiments were based on the assumption that models of five events were small enough to be accommodated within working memory.
 As Experiment 3 showed, the size of a model does affect performance, and so too does the interval ~ the number of intervening events  between the two events in the question.
 Perh^s surprisingly, a larger interval yields a more accurate performance than a small interval.
 The cause of this effect is by no means certain.
 One possibility is that there is an 'endanchor' effect, and another that the larger interval makes the order of events more discriminable (see Potts, 1978).
 An earlier study of spatial reasoning showed that onemodel problems were easier than multiplemodel problems (Byrne & JohnsonLaird, 1989).
 Rips (1994, p.
 415) has criticized this experiment on the grounds that the instructions biased the subjects "to use an imaginal strategy that favored the mentalmodel predictions (or placed a strong task demand on them to respond as if they were trying to image the arrays .
.
.
)".
 W e are sceptical about these claims, but in any case neither the instructions nor the materials of the present experiments lend themselves to an imaginal strategy, real or simulated.
 In the absence of a rule theory for temporal reasoning  and Rips does not advance one  it is hard to rebut such theories, but we note that our results provide an interesting challenge to rule theories.
 They predict, for example, that onemodel problems with an irrelevant premise have a shorter derivation than onemodel problems with no irrelevant premises, yet Experiment 1 failed to detect any difference between them.
 If one argues, as Rips does, that the irrelevant premise led subjects astray, then one cannot explain why such problems are easier than the multiplemodel problems with valid answers.
 They too have an irrelevant premise, and they have an identical derivation to the onemodel problems with irrelevant premises.
 The irrelevant premise can play no part in a formal derivation, but it does play a part in the building of models: In the former case, the result is one model; in the latter case, the result is multiple models.
 Finally, the use of mental models in temporal reasoning has one considerable theoretical advantage over other methods.
 It yields a decision procedure.
 A n inference is valid if its conclusion holds in all the possible models of the premises, and it is invalid if it fails to hold in at least one of the possible models of the problems.
 Granted that problems remain within the capacity of working memory, then it is a simple matter to decide whether or not an inference is valid: One examines all the models of the premises.
 Acknowledgements Schaeken's research is supported by the National Fund for Scientific Research of Belgium and the Nuttin Foundation.
 JohnsonLaird's research is supported in part by the John S.
 McDonnell foundation.
 References Braine, M.
 D.
 S.
, & O'Brien.
 D.
 P.
 (1991).
 A theory of If: A lexical entry, reasoning program, and pragmatic principles.
 Psychological Review, 98, 182203.
 Byrne, R.
 M .
 J.
, & JohnsonLaird, P.
 N.
 (1989).
 Spatial reasoning.
 Journal of Memory and Language, 28,564575.
 JohnsonLaird, P.
 N.
, & Byrne, R.
 M .
 J.
 (1991).
 Deduction.
 HiUsdale, NJ: Erlbaum.
 Potts, G.
 R.
 (1978).
 The role of inference in memory for real and artificial information.
 In R.
 Revlin & R.
 E.
 Mayer (Eds.
), H u m a n Reasoning (pp.
 139161).
 Washington.
 D C : Winston.
 Rips, L.
 J.
 (1994).
 The Psychology of Procf: Deductive Reasoning in H u m a n Thinking.
 Cambridge, M A : M I T Press.
 729 Vandierendonck, A.
, & De Vooghi, G.
 (1994).
 Is reasoning with time concepts based on a spatialized representation of time? Report of the Department of General Psychology, University of Ghent, Belgium.
 730 Arguing and Reasoning in a TechnologyBased Class Banich Schwarz The Hebrew University Jerusalem, Israel insschwar@pluto.
 huj i .
 ac.
 il Abstract This study has the descriptive aim of showing if and how epistemic procedures typical to mathematical reasoning can be practiced by children when they are in a social situation that supports their individual linguistic and cognitive activity.
 The present paper consists of a finegrained analysis confronting argumentative skills and epistemic actions of a group of four students functioning in a Grade 9 mathematics class.
 The four students were presented with a mathematical problemsituation typical of a one year long experiment whose domain was an introductory course about functions.
 This activity was typical in the sense that: (i) it demanded inquiry; (ii) students worked in groups; (iii) they had computerized tools at their disposition; (iv) they were invited to discuss their work in a whole class forum.
 The role of the technological tools as a trigger for the application of argumentative skills is investigated.
 Introduction Research in school discourse and in knowledge acquisition belong to two distinct traditions.
 School discourse has been the object of many sociolinguistic studies (e.
g.
, Cazden, 1986; Sinclair & Coulthard, 1975).
 However, such studies have been interested in the conversational features of this form of discourse, and did not focus on how school discourse leads to knowledge acquisition.
 Similarly, most of teachinglearning studies focusing on knowledge acquisition in particular domains neglected the role of discourse in this process.
 However, pioneering studies have already focused on the relation between reasoning in a particular domain and argumentative skills (e.
g.
, Pontecorvo & Girardet, 1993; Resnick, Salmon, Zeitz, Wathen, & Holowchak, 1993), in varied domains such as historical reasoning or nuclear power policy.
 Moreover, investigating the role that technological tools can play in the construction of this relation is also quite a new endeavor (see the studies undertaken by Meira, 1991, Roschelle, 1992, and Schwarz, in press).
 The Activity Theory: A Methodology for Analyzing TeachingLearning Settings with a Vygotskian Perspective Our approach is to analyze school discourse through Leont'ev's method (1981) that frames the teaching activity, and its specific actions and operations.
 The activity construct in Leont'ev's sense refers to the most global level of analysis.
 It explains the sociocultural R i n a H e r s h k o w i t z The Weizmann Institute Rehovot, Israel n t h e r s h k @ w i c c m a i l .
 w e i z m a n n .
 a c .
 i l interpretation imposed on the context by the participants.
 It is characterized by a discursive interaction and a cognitive function pursued by the teacher, who proposes (explicitly or implicitly) her or his general goals to the children's group and often recycles them in the course of the discussion.
 The second level of the Activity Theory, the level of actions is embedded in the activity.
 Actions are driven by a goal about which the participants can share awareness.
 It explains where there is a cultural interpersonal mediation between teacher and child or among children working together.
 It consists of reasoning sequences in which particular epistemic actions are pursued.
 In the mathematical domain, examples of such reasoning sequences are planning, or constructing an hypothesis.
 Within these reasoning sequences, Leonte'ev's third level of analysis looks at the molecular operations carried out through the idea units.
 Each idea unit is submitted to a double categorization, looking at the specific argumentative operations and at the epistemic operations used by children.
 Defining the Levels of Analysis of a M a t h e m a t i c a l School Setting W e used Leont'ev's methodology to analyze a school session in a technologybased mathematics class.
 At the activity level, the teacher conducted a one year long introductory course about functions, in a parochial school, with fortytwo 9*" grade girls.
 The teacher based her instruction on problems characterized by: (i) open ended problemsituations demanding the use of inquiry skills; (ii) work in groups, students being encouraged to discuss the solution paths; (iii) the availability of computerized tools; (iv) aftermath reflection in whole class forum, and/or in written group reports.
 Details about the experiment are given elsewhere (Hershkowitz and Schwarz, 1995).
 One typical problemsituation, "Overseas Inc.
", is described here in terms of Leonte'ev's levels.
 A distinction is being made between two types of operations: (a) the argumentative operations that give an account of the collective discursive activity, and (b) the epistemic operations through which the knowledge domain is analyzed.
 The Activity around the "Overseas Inc.
" ProblemSituation The Overseas Inc.
 problemsituation is initiated by a homework assignment given to all the individuals of the class.
 Its formulation is: The freight company "Overseas Inc.
" uses containers to ship goods by sea from country to country.
 The containers 731 mailto:nthershk@wiccmail.
weizmann.
ac.
ilare big boxes made of wood.
 Their base needs to be a square, and their volume must be 2.
25 m^.
 The containers must also be open at their top.
 Can you find two or three examples of such containers? You may use paper to construct such a container, or draw it and label its dimensions.
 In that case, you may use a 1/20 reduction (Jmfor the container= 5cm of the paper).
 O n the day the assignment is due, the students (equipped with the models of containers they brought to school) are given a worksheet.
 Its formulation is: As wood is expensive, the company is interested in designing ideal containers with as little wood as possible.
 Can you figure out how the ideal container looks? Guess and explain.
 Can you help the company to find out the exact dimensions of the ideal container? The teacher invited the students to organize themselves in groups of four, and to work in any way they wanted.
 They had graphical calculators at their disposal.
 The groups worked basically alone, although the teacher was available to help.
 At the end of the activity, the girls were invited to participate in an open discussion about the process that they undertook during the construction of their hypotheses and of their solution paths within the different groups.
 Group reports were collected before the discussion began.
 The Actions of the Activity At the second level of analysis, argumentative phases in which a dominant collective goalmediated action is pursued were identified.
 Thirteen such actions were observed for "Overseas Inc.
": The teacher gives first a preparing task (1), a homework assignment consisting of a worksheet in which students are asked to construct several models.
 During the presentation (2), the teacher asks the students first to hypothesize the solution.
 Then, students organize themselves in groups of four.
 The four girls whose work was analyzed, first undertake computations (3) while manipulating the models they have brought in.
 They collaborate to jointly add up all the elements of the surface.
 They distribute their efforts and group the computations of each of the models in a c o m m o n table.
 Then, two of the girls formulate their own hypotheses (4), and the group tries to understand these conflicting hypotheses.
 These interactions cause the participants to justify and to defend (5) these hypotheses.
 One of the girls decides to find out which of them is right (6).
 Gradually, the students jointly construct an hypothesis (7).
 They come to understand that each of the previous hypotheses is "locally" right, but that none of them takes into account the overall variation of the surface.
 After a short retreat to the old hypotheses (8), the students recognize that they cannot go further in the elaboration of a better hypothesis and they jointly decide to turn to the solution (9).
 They return to the table (10), but at that time in a more controlled way: They define their role: one makes variations for small decreasing values of the side, another for big increasing values of it.
 They finally decide to turn to an algebraic formula of the surface (11), and they use the graphical calculator (12) to display the graph of the function, and read its minimum.
 In the last part of the lesson, the teacher asks the groups of students to discuss about the strategies used by each of them.
 This segment is a synthesis (13) in which students reflect upon their and others work, the teacher being a moderator among the contributions of the participants.
 The analysis of the work of four girls solving "Overseas Inc.
" is done in the next subsection, at the level of operations, argumentative and epistemic.
 This analysis is preceded here by a categorization of these operations.
 General Categorization of Argumentative Operations The argumentative operations are those listed by Toulmin (1958), and adopted by Pontecorvo and Girardet (1993) in their analysis of arguing in historical topics.
 These are: Claim: Any clause that states a position (that can be claimed).
 Justification: Any clause that furnishes adequate grounds or warrants for a claim.
 Concession: Any clause that concedes something to an addressee, admitting a point claimed in the dispute.
 Opposition: Any claim that denies what has been claimed by another, with or without giving reasons.
 Counteropposition: Any claim that opposes another's opposition, which can be more or less justified.
 General Categorization of Epistemic Operations These operations are grounded on the explanation procedures in terms of the mathematical content to which they refer.
 Schoenfeld (1992) recognized several kinds of epistemic operations that correspond to the explanation procedures that are used for interpreting and solving mathematical problems.
 The first kind consists of higher level metacognitive procedures, which are the basis of mathematical interpretative activity; they deal with regulatory processes and with evaluation of the adequacy of moves (or control).
 For example, these operations can consist of choosing or evaluating which strategy to choose for tackling a particular problem, or of deciding to leave a heuristic method after a long enough search.
 The second kind includes heuristics, such as the use of analogies, the search for patterns, hypothesizing, or simplifying a problem.
 The third kind of epistemic operations is the appeal to resources.
 Resources are a very rich list of facts, theorems, definitions, procedures, etc.
 that are at the disposition of the learner.
 Some examples are: reading graphs, inferring the order of magnitude of a variable quantity from a table or a formula, or knowing the solution of a particular task previously done.
 A full list of resources is impossible to write down, because it depends on the task, and on cognitive development: a procedure can be a heuristic for some, while for others, it is a fact.
 The list 732 given in the following is then specific to the four girls solving "Overseas Inc.
".
 It is organized into metacognitive /regulatory operations (I), heuristics (II).
 and appeal to resources (III).
 Reflection: (I) Reflecting upon one's previous moves, or planning further ones.
 Control (I) Asserting/checking with an evaluative dimension.
 Predication (1) Asserting without any evaluative dimension.
 Hypothesis (II) Figuring out a fact, a rule or a law.
 Hypothesizing may be grounded on numerical data, previous knowledge, or experience.
 Extreme cases (II) Use of extreme cases in order to find out a law.
 Analogy (II) Search for an analogical case Change of rep.
 (II) The change of external representation as a strategic move to see a problem from a new perspective.
 Appeal to resources (III) (retrieving of information considered as relevant to the topic by the speaker).
 It can be: Definition (A statement about the nature of an object, or a quantity).
 Exemplar cases, (numeric data, models,.
.
), Rules, General Principles, Authority (expert, previously solved problems,.
.
.
), Procedures (reading graphs; computations, etc.
).
 Again, these epistemic operations were carried out in a social interaction setting by particular linguistic and cognitive operations, which can be identified as argumentative operations because of their linkage of social arguing and individual reasoning.
 Our hypothesis is that children as novices in the mathematical domain can learn to master these latter operations by practicing them in appropriate learning environments, especially in environments such as that created in this experiment.
 Examples of Interaction In the following examples, we present some excerpts of interaction between the four participants, Hanna, Miriam, Liat and Osnat.
 The four girls were videotaped, then their discourse was transcribed.
 The protocols are accompanied by VCRtime (first column), argumentative operations (third column), and epistemic operations (fourth column).
 It is important to notice that the participants used three models they constructed at home: a "long" box with narrow base, a "short" box with large base, and a box with comparable dimensions.
 The first excerpt (Table 1) shows the actions of formulating and defending o w n hypotheses (actions 45).
 This excerpt begins by a phase during which students investigate the nature of the problem.
 They clarify that the surface includes the lateral faces and the base, and that the problem (to find as less wood as possible) means to minimalize the surface.
 At 48:10, Liat concludes that surface and quantity of wood mean the same.
 At 48:15, Osnat relates to a hypothesis that was not uttered, but it might be that she derived it from her interpretation of Liat claim.
 She justifies the hypothesis by appealing to a principle: as the sides contribute four times to the overall surface (as opposed to the base), the height has to be minimal.
 Liat changes representation (she uses the models) to complete the justification.
 However, this move is problematic in the short run: She shows that the short model has a very big base.
 Hanna opposes to Osnat hypothesis, the shorter is the height, the bigger is the base, and consequently the larger is the surface.
 This excerpt shows two main points.
 First, the students were very often engaged in metacognitive/regulatory ("control", "reflection") and heuristic operations ("hypothesis", "change of representation", "extreme cases").
 Such operations characterize highlevel mathematical reasoning, and are generally difficult for students.
 Second, the children conducted an autonomous collective discourse in which mathematical reasoning was supported by the application of rich argumentative skills.
 Quantitative considerations about the distribution of epistemic and argumentative operations are beyond the scope of this descriptive paper.
 A second excerpt (Table 2) shows two roles of computerized tools in relation to argumentafive and epistemic operations.
 This excerpt (actions 912) occurs after Osnat claims and warrants that the surface is smaller when the sides are smaller, and Miriam opposes that the surface is smaller when the base is smaller.
 After the participants realize that two hypotheses formulated previously are "locally" right only, Liat counteropposes the two hypotheses and formulates her o w n hypothesis.
 The counteropposition drawn by Liat makes a compromise between the two previous hypotheses.
 It is interesting that Osnat w h o held one of the "old" hypotheses hurries to check and justify Liat's hypothesis by changing representation with her graphical calculator.
 As for the first excerpt, the four students very often engage in metacognitive and strategic epistemic operations.
 For example, all Hanna's interventions deal with planning the solution or with choosing the right variable (the side of the base or the height).
 The last "change representation" operation is different from the first one; it does not come to justify an argument, but to solve a problem whose planning is clear.
 733 Time 47:06 47:08 47:14 47:20 48:10 48:30 48:35 [Miriam Hahna: Liat: Osnat: Miriam: Protocol reads aloud the question from the worksheet] H o w much did you get? W e got 19.
 The less the surface is, the less wood there will be.
 I'll tell you something [grasps the "long model"] The surface is not only this, it is everything [She points at the base than at the lateral faces] Osnat: Miriam: Osnat: Liat: Hanna: Osnat: Liat: Osnat: Liat: Hanna: Miriam: Osnat: Hanna: No! 1 did not say that.
.
.
 Oh! 1 did not understand really.
.
.
 One moment how could we have less wood? here it has to be the smallest [Osnat points at the sides of the large box] When the surface is smaller, there is less wood.
 Right? See, we see that here [the height], there is 1/2 and there [the base side], 3.
 W h y is it so? It's because here.
.
if it will be the smallest possible, we multiply it by four, we need to multiply by four.
 Because here [Liat points to the base], it will be larger, and here [Liat points to the sides], it will be smaller.
 Multiplied by four, it must be as small as possible Yeah! The smaller it will be, Yeah Smaller is the height, bigger is the surface Are.
 GDeratoi Claim Oppose Concession Claim Hypothesis Justification Justification Opposition Didn't we say the contrary, CounterOpposition that the smaller is the height.
 the smaller is the surface But this is exactly what we said.
 One moment, how did we get it that way? [Liat writes down the hypothesis on the worksheet].
 Miriam: Osnat: Liat: .
.
[inaudible].
.
.
bigger OK.
, it's exactly what we said Tell it in the other way, shorter is the container.
.
.
 Claim Claim Eoistemic Operator Control Appeal def.
 Change of rep.
 Appeal definition Reflection Control N u m .
 data, extr.
 cases Control Start Hypothesis Appeal to principles Change of rep.
 Appeal principles Hypothesis Hypothesis Control Control Inference Table 1 1:03:58 1:04:06 1:05:25 1:05:57 1:06:04 1:06:16 1:06:25 1:06:58 1:07:07 1.
07:37 1:07:47 Liat: Osnat: Hanna: Liat: Miriam: Harma: Osnat: Miriam: Osnat: Miriam: Hanna: It's as if it is not constant, it has to be like that [Liat draws in the air a sketch of a "parabola"] It's worthy to do a table, first we will make big the height [The four students construct a table with four values in the graphical calculator, and plot the corresponding points on a graph] Let's think in a logic way.
 Yeah, but it does not need to be a linear function.
 Yeah, it does not have to go up with the same rate.
 W e have to think which container is the ideal one.
 If it's what you think, then it's a parabola, and the apex is where it seems horizontal and stable.
 Counteropp.
 Justification Counteropp Justincation Claim The yaxis is the surface, and the x axis is the side of the base W e have to be more goal oriented ! First, we make the base grow, that is to say the side of the base.
 and second, the side of the height.
 The variable is the base In m y opinion, the side of the base and the height, and then we'll solve this.
 Oppyjustifi [The four students take their graphical calculator, enter the formula expressing the height as a function of the side of the base.
 then enter the surface as a function of the side, draw the graph of the function and read the minimum] Hypothesis Change of rep.
 Appeal proc.
 Appeal proc.
 Control Appeal prop.
 Appeal prop.
 Control App.
Condition Control/Plan Reflection Control Control/Plan Control/Plan Change rep.
 Appeal proc.
 Table 2 734 In the two excerpts presented here, the technological tools seem secondary, being involved with the "changing representation" episteniic operation only.
 However, the high level of mathematical reasoning the students attained (see Hershkowitz & Schwarz, 1995), was linked lo the lad that the students knew they did not have to carry out technical tasks, and that any claim could be warranted with the computerized tools at their disposal.
 Concluding remarks The Activity Theory has descriptive power: it was a suitable frame to describe the relations between argumentative and mathematical epistemic operations.
 The examples of data presented here show the concomitance of highlevel mathematical reasoning and rich argumentation.
 Studying more specific relations between mathematical reasoning and argumentation at the level of their operations is a domain of research that needs to be investigated in further research.
 Place limitations dictated a somehow discrete picture of the interactions between participants.
 Such an approach misses some features of the dynamics of the group interactions, in which operations contributed by individuals cannot be isolated.
 The computerized tools were important in the sense that students could use "change of representation" as a strategic move for controlling or checking hypotheses, and for justifying (warranting or backing) arguments.
 In other words, the computerized tools enabled the students to use "change of representation" both from an epistemic and an argumentative perspective.
 It is then not surprising that, as shown in Hershkowitz and Schwarz (1995), change of representation was often contiguous to "Aha" occurrences.
 Schoenfeld, A.
 H.
 (1992).
 Learning to think mathematically: Problem solving, Metacognition, and sense making in mathematics.
 In D.
 A.
 Grouws (Ed), Handbook of research on mathematics teaching and learning, 334371.
 Schwarz, B.
 B.
 (in press).
 Understanding symbols with intermediate abstractions: A n analysis of the collaborative construction of mathematical meaning.
 In C.
 Pontecorvo, R.
 Saljo & L.
 B.
 Resnick (Eds.
), Tools, Discourse, and Reasoning, N A T O series, Lucca.
 Sinclair, J.
 M.
, & Coulthard, R.
 M .
 (1975).
 Towards an analysisof discourse.
 London: Oxford University Press.
 Toulmin, S.
 (1958).
 A n introduction to reasoning.
 References Cazden, C.
 B.
 (1986).
 Classroom discourse.
 In M .
 C.
 Wittrock (Ed.
), Handbook of research on teaching (3rd ed.
, pp.
 491).
 N e w York: Macmillan.
 Hershkowitz, R.
 & Schwarz, B.
 B (1995).
 Reflective processes in a technologybased mathematics classroom.
 Paper presented at the American Educational Research Association, San Francisco.
 Leont'ev, A.
 N (1981).
 The problem of activity in psychology.
 In J.
 V.
 Wertsch (Ed.
), The concept of activity in Soviet psychology (pp.
 3771).
 Armonk, N Y : Sharpe.
 Meira, De Lemos, L.
 R.
 (1991).
 Explorations of mathematical sensemaking: A n activity oriented view of children's use and design of mathematical displays, Ph.
D dissertation, U.
 C.
 Berkeley.
 Pontecorvo, C.
 & Girardet, H.
, (1993).
 Arguing and reasoning in understanding historical topics.
 Cognition and instruction, 11(3 & 4), 365395.
 Resnick, L.
 B.
, Salmon, M.
, Zeitz, C.
 M.
, Wathen, S.
 H.
, & Holowchak, M.
 (1993).
 Reasoning in conversation.
 Cognition and instruction, 11(3 & 4), 347364.
 Roschelle, J.
 (1992).
 Learning by collaboration: convergent conceptual change.
 The Journal of the Learning Sciences, 3, 235276.
 735 T o help or not to help^ Mahendra Sekaran San dip Sen Department of Mathematical k Computer Sciences University of Tulsa Telephone: (918) 6312985 Fax: (918) 6313077 Email: mahend®euler.
mcs.
utulsa.
edu, sandip@kolkata.
mcs.
utulsa.
edu Abstract Any designer of intelligent agents in a inultiagent system is faced with the choice of encoding a strategy of interaction with other agents.
 If the nature of other agents are known in advance, a suitable strategy may be chosen from the continuum between completely selfish behavior on one extreme and a philanthropic behavior on the other.
 In an open and dynamic system, however, it is unrealistic to assume that the nature of all other agents, possibly designed and used by users with very different goals and motivations, are known precisely.
 In the presence of this uncertainty, is it possible to build agents that adapt their behavior to interact appropriately with the particular group of agents in the current scenario? W e address this question by borrowing on the simple yet powerful concept of reciprocal behavior.
 W e propose a stochastic decision making scheme which promotes reciprocity among agents.
 Using a package delivery problem we show that reciprocal behavior can lead to systemwide cooperation, and hence close to optim2il global performance can be achieved even though each individued agent chooses actions to benefit itself.
 More interestingly, we show that agents who do not help others perform worse in the long run when compared with reciprocal agents.
 Thus it is to the best interest of every individual agent to help other agents.
 I n t r o d u c t i o n The design of intelligent agents that will interact with other agents in an open, distributed system involve the modeling of other agents and their behavior (Gasser, 1991; Hewitt 1991).
 Assuming all agents will be cooperative in nature, efficient mechanisms can be developed to take advantage of mutual cooperation, which can produce improved global performance.
 But, in an open system, assumptions about cooperative agents or systemwide c o m m on goals are hard to justify.
 More often, we will find different agents have different goals and motivations and no real inclination to help another agent achieve its objectives.
 'With due apology to William .
Shakespeare.
 The above situation may appear to be hopeless.
 If an agent cannot assume other agents to be cooperative, it might as well solve its problems individually.
 But this leads to inefficient problem solving performance because agents miss out on mutually beneficial interactions.
 Even if two individual agents are selfmotivated, they should cooperate if such an arrangement is beneficial for both.
 The question therefore is, when should an agent help another agent? W e cannot rely on inbuilt inclination towards cooperation.
 The decision to cooperate should be made to serve the agent's own interests.
 In this paper, we provide a decisionmaking paradigm that enables autonomous agents to accept or decline requests for cooperation from other agents based on local rather than global considerations.
 W e cissume agent actions to be selfmotivated.
 This means that an agent will help another agent, only if such an action is beneficial to itself in the short or the long run.
 W e use the concept of reciprocity to show that when agents help others who have helped them in the past or can help them in the future, cooperative behavior can evolve out of selfmotivation.
 W e propose a stochastic method for deciding whether one agent should help another agent or not in a particular situation.
 Agents who use this stochastic reciprocity mechanism are called reciprocative agents W e analyze the effects of selfish agents (agents who receive help but do not reciprocate) on the behavior of other reciprocative agents.
 W e also characterize the performance of individual agents (agents who never help each other) and philanthropic agents (agents who always help others if requested), and demonstrate that a society of reciprocative agents can approximate philanthropic behavior under proper environmental conditions.
 Our results show that close to optimal system performance can be obtained without sacrificing individual preferences or autonomy.
 Coordination of multiple agents Multiagent systems are a particular type of distributed artificial intelligence (DAI) system (Bond, 1988), in which autonomous intelligent agents in736 http://mcs.
utulsa.
edumailto:sandip@kolkata.
mcs.
utulsa.
eduhabit a world with no global control or globally consistent knowledge.
 In contrast to cooperative problem solvers (Durfee,Lesser, Corkill, 1989), agents in multiagent systems are not predisposed to help each other out with the resources and capabilities that they possess.
 These agents may still need to coordinate their activities with others to achieve their own local goals.
 They could benefit from receiving information about what others are doing or plan to do, and from sending them information to influence what they do.
 Coordination of problem solvers, both selfish and cooperative, is a key issue in the design of an effective DAI system.
 The search for domainindependent coordination mechanisms has yielded some very diflferent, yet effective, classes of coordination schemes.
 Whereas some of these work uses architectures and protocols designed offline (Fox, 1989; Smith,1980) as coordination structures, others acquire coordination knowledge online (Durfee, 1988; Sekaran Sen, 1994).
 In addition, some of these work assumes agents to be cooperative with c o m m o n systemwide goals (Durfee, 1988; Fox, 1981), and others assume selfmotivated agents with individual goals (Genesereth, 1986; Gmytrasiewicz, 1991).
 The other dimension to consider is if we are analyzing a single instance of agent interaction or if we are considering an ensemble of agent interactions (e.
g.
, in the prisoner's dilemma problem (Rapoport, 1989), most of the formal analysis assume repeated interactions).
 In this paper, we assume agents have individual goals or tasks to complete.
 These individual goals, however, can be achieved more expediently if an agent receives assistance from other agents.
 This suggests that both individual and overall system performance will improve if agents can intelligently share tasks.
 W e will consider agents who repeatedly interact with each other, and hence past history of problem solving can be used to decide future course of action.
 The question here is the following: given that there are scopes for cooperation, how should selfmotivated agents choose when to cooperate and when not to cooperate with another agent? In the following section we provide an online mechanism to answer this question.
 Reciprocal decision making In a companion paper (Sen, 1995) we have shown that reciprocal behavior can be used effectively by agents to balance their workloads.
 In that paper, each tcisk could be carried out by any agent, and agents could exchange tasks to improve local performance.
 In this paper we find out if reciprocity is sufficient to promote cooperation when agents cannot transfer tasks, but can use help from others to reduce the cost of performing an eissigned task.
 W e assume a multiagent system with A^ agents.
 Each agent is assigned to carry out T tasks.
 The jth task assigned to the ith agent is <,j, and if agent i carried out this task on its own, the cost incurred is Clj.
 However, if another agent k helped agent i to carry out this task, the cost incurred by each of them is C ? .
 W e assume that 2 * Cfj < Clj, which implies that if two agents together work on the same task, the combined effort required to process the task is less than what it would take one of them to process it.
 Since the savings, C/^ — Cfj, obtained by the agent being helped is greater than the cost incurred by the helping agent, Cfj, there is a net saving of effort for the entire system.
 This saved effort when combined with reciprocal behavior, can lead to a system with effective individual as well cis group performance.
 So, the gain of an individual is not at the expense of the group.
 The obvious question is why should an agent incur any extra cost for another agent? If we consider only one such decision, cooperation makes little sense.
 If, however, we look at a collection of such decisions, then reciprocal cooperation makes perfect sense.
 Simple reciprocity means that an agent will help another agent if the latter has helped the former in the past.
 But simple reciprocity by itself is not sufficient to evolve cooperative behavior.
 This is because, no one is motivated to take the first cooperative action, and hence nobody ever cooperates! In spite of all the potentials for cooperation and the benefits that it can provide them, agents carry out their own tasks without ever offering to help others.
 In real life, in addition to past experience, reciprocity includes a predictive mechanism.
 A n agent can help another agent, if it expects future benefits from the latter.
 In absence of a general domainindependent predictive mechanism, we propose a much simpler but equally effective stochastic choice mechanism to circumvent the problem of simple reciprocity.
 W e will define S',t and Wik as respectively the savings obtained from and extra cost incurred by agent i from agent k over all of their previous exchanges.
 Also, let Bile — Sik — Wik be the balance of these exchanges (obviously, fi,fc = —Bki).
 W e now present the probability that agent k will help agent i carry out task i,j.
 This probability is calculated as: Pr{i,k,j)= ^ 1 h exp O^fi^LgBk.
 ' where C^^g is the average cost of teisks performed by agent i (this can be computed online or preset), and 0 and r are constants.
 This gives a sigmoidal probability distribution in which the probability of helping increases as the balance increase and is more for less costly tasks.
 W e include the Cavg term because the probability of helping should depend on relative and not absolute cost (if the average cost is 737 I (1.
0/(l,0 + (eJip{(x 12.
5)/4.
0)))) 0.
9 0.
8 0.
4 Extra cost and D from the depot.
 A n agent can carry only one packet at a time by itself or with the help of another agent.
 O n arriving at the depot, an agent is assigned the next packet it is to deliver.
 At this point, it checks for other agents currently located in the depot.
 If so, it asks the other agent for help to deliver this packet.
 This requests m a y or m a y not be honored The cost incurred by agents is the time taken to deliver packets.
 A n agent takes 4 time units to cover unit distance if it is carrying a packet by itself.
 T h e speed of traveling increases to unit distance per time unit w h e n another agent is helping it.
 W h e n agents are returning to depot after delivery, they travel unit distance in unit time.
 Figure 1: Probability distribution for accepting request for cooperation.
 10, incurring an extra cost of 10 is less likely than incurring an extra cost of 1).
 D u e to the stochastic nature of decisionmaking s o m e initial requests for cooperation will be granted whereas others will be denied.
 This will break the deadlock that prevented simple reciprocity from providing the desired system behavior.
 W e present a sa m p l e probability distribution in Figure 1.
 The constant 0 can be used to move the probability curve left (more inclined to cooperate) or right (less inclined to cooperate).
 At the onset of the experiments Bki is 0 for all i and k.
 At this point there is a 0.
5 probability that an agent will help another agent by incurring an extra cost of /? * C^^g.
 The factor t can be used to control the steepness of the curve.
 For a very steep curve approximating a step function, an agent will almost always accept cooperation requests with extra cost less than 0*Cavg, but will rarely accept cooperation requests with an extra cost greater than that value.
 Similar analyses of the effects of /? and r can be made for any cooperation decision after agents have experienced a number of exchanges.
 In essence, /? and r can be used to choose a cooperation level (Goldman, 1994) for the agents at the onset of the experiments.
 The level of cooperation or the inclination to help another agent, however, dynamically changes with problem solving experience.
 A package delivery problem In this section, we present a simple package delivery problem which we will use to demonstrate the effectiveness of our proposed mechanism to evolve cooperative behavior.
 Each of N agents is assigned to deliver T packets from a centralized depot to rand o m destinations located at a distance between 1 E x p e r i m e n t a l results In this section, we present experimental results on the package delivery problem, with agents using the reciprocity mechanism described before to accept or deny a request for help from another agent.
 W e vary the number of agents and packets to be delivered by each agent to examine the effects of different environmental conditions.
 Values of other parameters used are: D = 10, r = 4, and ^ = 0.
5.
 Results are averaged over 10 different randomly generated data sets, where a data set consists of an ordered assignment of package deliveries to agents.
 All the agents are assigned the same number of dehveries.
 The evaluation metric is the total cost incurred by the agents to complete all their deliveries.
 W e used this domain to investigate the effects of agent characteristics on overall systems performance.
 In our experiments, philanthropic agents always agree to help another agent when requested; selfish agents request for help but never help others; individual agents neither cisk for help nor provide help to other agents; reciprocative agents use the balance of cost and savings to stochastically decide whether to accept a given request for cooperation.
 In homogeneous environments (where all agents are of the same type), we expect the group of individual agents and the group of philanthropic agents to provide the two extremes for system performance.
 The individual agents should incur the highest cost to complete their deliveries (because no one is cooperating), whereais the philanthropic agents should should incur the least cost.
 W e expect reciprocative agent behaviors to lie in between.
 The frequency of occurrence of cooperation possibilities should determine which of the two ends of the spectrum is occupied by the reciprocative agents.
 Whether selfish agents can benefit at the expense of reciprocative agents depends on the percentage of selfish agents in the group and the total number of interactions they are likely to encounter.
 It would seem that reciprocative agents should perform bet738 14000 12000 I 10000 I  8000 < 6000 4000 2000 Effea of number of delivenes I/idividual •— Rational •'— Philanthropic B14000 1 hum 12000 Effect of number of agents 1 1 1 r 1 1 1 1 1 1 ( » « « Liilividual »— Rational »L Philanthropic B1 1OOU t "r.
,S.
rrr.
TrrTr.
.
.
.
̂ .
.
.
.
Tr.
.
"r.
.
.
rT.
.
.
T,ti .
 trinnn I I 1 1 1 1 1 1 1 50 100 150 200 250 300 350 400 450 500 Number of deliveries 30 40 50 60 70 80 90 100 Number of agents Figure 2: Average total cost incurred by an agent to Figure 3: Average total cost incurred by an agent to complete all deliveries.
 complete all deliveries.
 ter because with sufficient interactions they become philanthropic towards each other, a possibility denied of the selfish agents.
 For the first set of experiments, we chose the number of agents, A^, as 100 and varied the number of deliveries per agent from 100 to 500 in increments of 100.
 Experiments were performed on homogeneous groups of individual, reciprocative, and philanthropic agents.
 Results from these set of experiments are presented in Figure 2.
 As expected, the performance of the individual agents was the worst, and the philanthropic agents was the best.
 The interesting thing is that the performance of the reciprocative agent is almost identical to that of philanthropic agents.
 This is a significant result because it shows that under proper environmental conditions (frequent and prolonged interactions with possibilities of cooperation), selfmotivated behavior based on reciprocity can produce mutually cooperative behavior that leads to nearoptimal system performance.
 In addition, with more deliveries, the savings in cost incurred is more with reciprocative and philanthropic agents over individual agents.
 The ratio of corresponding points on the two curves should be the same, however, as it is determined by the probability of another agent being able to help one agent with its delivery.
 For the package delivery problem described in the previous section this probability is largely determined by the m a x i m u m distance traversed from the depot, D, and the number of agents, Â .
 W e also performed a similar set of experiments by fixing the number of deliveries per agent at 500 and varying the number of agents from 25 to 50 to 75 to 100.
 Results from these set of experiments are presented in Figure 3.
 Since the average distance of a package destination from the depot is 5.
5, the average cost incurred by an individual agent for delivering a packet is 22 on the way out and 5.
5 on the way back, for a total of 27.
5.
 To deliver 500 packets, therefore, the expected cost incurred by an individual agent is 13,750.
 This fact is verified in the figure.
 As in the previous experiment, the performance of the individual agents was the worst, and the philanthropic agents were the best.
 The performance of the reciprocative agents was very close to that of the philanthropic agents, and these improved with more agents.
 The reason for this improvement was that with more agents, there is more scope for cooperation.
 However, a level of saturation is reached when all cooperation oppurtunities have been exploited.
 At this point, an increase in the number of agents do not lead to further improvement in system performance.
 The next set of experiments were designed to find out the effects of including selfish agents in a group containing reciprocative agents.
 W e expected that selfish agents should be able to obtain some help from reciprocative agents, and their performance would be better than individual agents but not as good as that of reciprocative agents.
 For these set of experiments, we chose TV — 100 and the number of deliveries to be 500.
 W e varied the percentage of selfish agents in the group.
 Results are presented in Figure 4.
 The average performance of the group lies in between the performance of the selfish and reciprocative agents, and moves closer to the performance of the selfish agents as the percentage of the latter is increased.
 The selfish agents are able to exploit the reciprocative agents to improve their performance significantly over individual agents.
 This is because there are many reciprocative agents and they do not share their balance information with other reciprocative agents.
 If a reciprocative agent would liroadrast the continuous denial of request for help by a selfish 739 14000 13000 3 r 12000 llOOO Effect of selfishness Comparison of rational and selfish behavior 10000 Ra ' ' Individual Rational Selfish loiul+Selfish Philanthrope a A 1 1 1 , +O A :'1 —r 1 1 X,.
 f' ••* 1 1 1 D » — 1—••''' *• 1— 1 i J 10 15 :0 25 30 35 40 45 50 Seinshness(%) Selfish 25000 Rational 210111) 17000 " 13000 400 600 Number of deliveries 1000 Figure 4: Average total cost incurred by each agent to complete all deliveries as the percentage of selfish agent in a group of reciprocative agents is varied.
 The individual and the philanthropic agent results do not contain selfish agents and are presented for comparison.
 agent who has got a positive balance with the requesting agent, the selfish agent would not be able to exploit other reciprocative agents.
 Since reciprocative agents incur extra cost for selfish agents without being reciprocated, their performance is noticeably worse than the performance of philanthropic agents.
 So, the presence of selfish agents can lower the performance of the whole group.
 To further analyze the relative performance of selfish and reciprocative agents, we ran a set of experiments varying the number of deliveries while keeping A'̂  = 100 of which 25 agents were selfish in nature.
 Results from these experiments are presented in Figure 5.
 A n interesting result was that with few deliveries to make, selfish agents outperformed reciprocative agents.
 This can be explained by the fact that the number of reciprocative agents were large enough compared to the number of deliveries, which allowed selfish agents to exploit reciprocative agents for most of its deliveries.
 The performance of the reciprocative agents was affected, as they could not recover from the extra cost incurred to help these selfish agents.
 With sufficient deliveries to make, however, reciprocative agents emerged as the clear winners This lends further credence to our claim that it is ultimately beneficial for an agent to be reciprocative rather than selfish in domains where cooperation is always beneficial to the group.
 Conclusions In this paper, we have shown that agents acting in their own selfinterest m a y find it practical to help each other.
 Under appropriate environmental Figure 5: Average total cost incurred by an agent to complete all deliveries with different number of deliveries.
 conditions, such a group of agents can also deliver nearoptimal global performance.
 This is a significant result because in an open, distributed environment, the only defensible strategy an autonomous agent can follow in deciding its actions is that governed by selfinterest.
 Our analysis and experiments show that reciprocal behavior can serve selfinterest as well as global efficiency concerns.
 Since, reciprocating behavior produces better performance in the long run over selfish or exploitative behavior, it is to the best interest of all agents to be reciprocative.
 It is interesting to note that our proposed mechanism will automatically track behavior changes (e.
g.
, if a reciprocative agent becomes selfish) and adjust agent responses accordingly.
 This is a powerful scheme that allows for dynamic behavior adjustment to suit the changes in the environment.
 Our results hold for domains where cooperation always leads to aggregate gains for the group.
 It would be instructive to study the eflfects of relaxing this constraint.
 The current reciprocation scheme can be enhanced or modified to address other types of agent interactions.
 If an agent is unable to individually identify other agents, it can use its overall balance of interactions to decide whether or not to accept a request for cooperation.
 But this also creates new possibilities for exploitative agents.
 W e also plan to investigate more complex domains such as distributed monitoring, distributed information gathering, etc.
 to further evaluate the strengths and limitations of our proposed mechanism.
 References Bond, A.
H.
 k Gasser, L.
 (1988).
 Readings in Distributed AI, San Mateo, CA:Morgan Kaufman Publishers.
 740 Durfee, E.
H.
 (1988).
 Coordination of Distributed Problem 5o/t)ers.
K;uwer Academic Publishers.
 Durfee, E.
H , Lesser, V.
R.
, k Corkill, D.
D.
 (1989).
 Trends in cooperative distributed problem .
solving.
 IEEE Transactions on Knowledge and Data Engineering, l(l):6383.
 Fox, M.
S.
 (1981).
 A n organizational view of distributed systems.
 IEE E Transactions on Systems, Man, and Cybernetics, ll(l):7080.
 Gasser, L (1991.
 Social conceptions of knowledge and action: DAI foundations and open systems semantics.
 Artificial Intelligence, 47(13); 107138.
 Genesereth, M.
, Ginsberg, M.
, & Rosenschein, J.
 (1986).
 Gooperation without communications.
 In Proceedings of the National Conference on Artificial Intelligence, pages 5157, Philadelphia, Pennsylvania, 1986.
 Gmytrasiewicz91, P.
J.
, Durfee, E.
H.
, k Wehe, D.
K.
 (1991).
 A decisiontheoretic approach to coordinating multiagent interactions.
 In Proceedings of the Twelfth International Joint Conference on Artificial Intelligence, pages 6268.
 Goldman, C.
 k Rosenschein, J.
S.
 (1994).
 Emergent coordination through the use of cooperative statechanging rules.
 In Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 408413.
 Hewitt, C.
 (1991).
 Open information systems semantics for distributed artificial intelligence.
 Artificial Intelligence, 47(l3):79106.
 Rapoport, A.
 (1989).
 Prisoner's dilemma.
 In J.
 Eatwell, M.
 Milgate, and P Newman, editors, The New Palgrave: Game Theory, pages 199204.
 Macmillan, London.
 Sekaran, M.
 k Sen, S.
 (1994).
 Learning with friends and foes.
In Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society, pages 800805.
 Sen, S.
 k Sekaran, M.
 (1995).
 Using reciprocity to adapt to others.
 International Joint conference on Artificial Intelligence workshop on Adaptation and Learning in Multiagent Sytems.
 Smith, R.
G.
 (1980).
The contract net protocol: Highlevel communication and control in a distributed problem solver.
 IEEE Transactions on Computers, C29{V2)Al04lll3.
 741 Attitudes to logical i n d e p e n d e n c e : traits in quantifier interpretation Keith Stenning Human Communication Research Centre University of Edinburgh 2, Buccleuch Place, Edinburgh, Scotland keith@cogsci.
ed.
ac.
uk Richard Cox Human Communication Research Centre University of Edinburgh 2, Buccleuch Place, Edinburgh, Scotland rcox@cogsci.
ed.
ac.
uk Abstract Newstead (1989) reports both graphically and sententially elicited data on the interpretation of quantifiers by logically naive undergraduate students.
 The sentential elicitation method fails to make the critical distinction between entailment relations between sentences, and mithvalueinamodel relations between sentences and diagrams.
 The present study modifies the elicitation technique and shows that die resulting sentential data can be insightftiUy described in terms of broad tendencies of response (to over or underinfer) interacting with highly specific grammatical sU^ctures (subject/predicate relationship).
 The resulting categorisation of subjects into four groups is then predictive of graphically elicited behaviour These results are interpreted by conuasting expository and deductive discourse, and proposing that students initially assimilate the latter to the former Introduction Despite their expertise in using natural language, undergraduate students experience considerable difficulties in grasping the interpretation of quantifiers in deductive reasoning when they c o m e to learn elementary logic.
 Characterising students' initial interpretation of quantifiers before they experience formal logic teaching is therefore a necessary preliminary to characterising what formal logic teaching teaches.
 W e here offer evidence that students exhibit a small number of highly coherent patterns of interpretation.
 W e propose that these patterns can be construed as part of student's assimilation of the novel 'game' of logical interpretation to more familiar expository language uses.
 W e believe that this descriptive study of interpretation offers a foundation of a cognitive characterisation of what happens when students' master deductive reasoning.
 In the most systematic existing study of simple quantifier interpretation, Newstead (1989) carried out an experiment investigating initial quantifier interpretations using both sentential and graphical methods of elicitation.
 His results showed some coherence within modalities but what he interpreted as extensive contrasts between modalities.
 These contrasts defied coherent description of systematic styles of interpretation.
 In this study w e show that Newstead's sententially posed questions to his subjects were logically incoherent, and that when they are replaced by logically coherent questions, these are not equivalent to their apparent graphical counterparts.
 The 'inconsistencies' of response observed cannot be confidently attributed either to the incoherence of the questions, or to students' misinterpretation of the quantifiers.
 It is not surprising that subjects offer different answers to different questions.
 O n the other hand, w e do not suggest that students would necessarily offer mutually consistent answers to different questions even if these were well posed.
 W e present here a study which rectifies the logical problems with Newstead's sentential questions and provides evidence from both sententially and graphically posed tasks about quantifier interpretation.
 W e relate the resulting patterns of response to students' other experiences of language.
 The plan of the paper is as follows.
 In the next section w e briefly contrast questions about logical dependence and independence of sentences with questions about the model/nonmodel relations between sentences and Euler diagrams.
 W e then describe an experiment in which undergraduate subjects answered both sententially and graphically posed questions about quantifier interpretations.
 The results are analysed for coherent contrasting patterns of individual response.
 Finally these patterns of response are interpreted as evidence for students' m o d e of assimilation of deductive reasoning to other more familiar types of natural language discourse.
 Questions of interpretation Newstead used sentential questions about quantifier interpretation of the following kind: "If it is true that , is it then true or is it false that " where the first blank was filled by one sentence, and the second by a choice of eight sentences.
 The first p r e m m sentence was of the form Quantifier A B with one of the four quantifiers 'All, Some, None, S o m e .
.
.
not' inserted.
 The second conclusion blank's eight sentences are generated by inserting the same four quantifiers in first, the frame A B , and then the fiame B A .
 The critical feature of note is that these are questions about logical relations between sentences, but the only opportunities for response are 'true' or 'false'.
 In fact, potential conclusion sentences may be related to premisses in three ways: i) as valid conclusions; 2) as sentences whose negations are valid conclusions; 3) as logically independent sentences.
 Given the premiss Some A are B then Some B are /I is a valid conclusion; N o A are B is a sentence whose negation is a valid conclusion; and All A are B is logically independent.
 Newstead posed his questions about sentence relations in 742 mailto:keith@cogsci.
ed.
ac.
ukmailto:rcox@cogsci.
ed.
ac.
ukterms of truth and falsity.
 W e agree that for logically naive students who have not been taught the distinction between truth and validity, this is probably the right choice, and fortunately it is possible to recast relations of validity in terms of truth and falsity.
 Valid conclusions from premisses are ones which are true in all circumstances in which the premisses are also true.
 So questions about validity can be posed by hypothesising that the premisses are true, and then asking whether the conclusions must also be true.
 Similarly, questions about relations of logical inconsistency between sentences can be posed by hypothesising that the premiss sentence is true, and asking whether the conclusions sentence must also be false.
 But crucially, since sentences may be related neither as valid premiss and conclusion, nor as inconsistent, but also as logically independent (with some models of the premiss which make the conclusions true, and some models which make it false), these choices must not be posed as forced exhaustive alternatives.
 Subjects must also be able to express knowledge of logical independence by saying that they cannot tell from the truth of the premiss whether the conclusion is true or false.
 The problem of not allowing responses indicating logical independence does not arise with the graphical questions which Newstead employed.
 Newstead used Eulers Circle diagrams as representations of completely determined interpretations (in the logical sense) and asked whether premiss sentences were true or false in those interpretations.
 Because the models are fully determined (contexts are fully specified) no sentence is logically independent and 'true' and 'false' responses are sufficient for all possible relations.
 Learning to understand and systematically apply the distinction between validity and truth is the core of the conceptual innovation that is required in learning elementary logic.
 Understanding validity requires the detachment of language from context, and generalisation over contexts.
 W e do not expect that students will necesarily have facile access to these logical relations between sentences once they are coherently posed—if that were the case, teaching logic would be an easy task.
 But posing questions about these relations is a prerequisite for obtaining interpretable data about quantifier interpretation and the problems that students experience.
 Prior to running our experiment we expected that students' behaviour with regard to the 'can't tell' response would be diagnostic of their approach to quantifier interpretation.
 Experimental investigation of interpretation The study reported here followed the design of Newstead (1989) closely with the exception of the redesigned sentential questions.
 Newstead used abstract, 'realistic' and 'thematic' material and found that the differences had little effect on responses.
 Since we would not especially expect these materials differences to interact with the change of question instituted here, we used only abstract material.
 Method Undergraduate students who had not been exposed to formal logic teaching were given graphical and sentential questionnaires about their interpretation of the quantifiers all, no, some, some not.
 Subjects Subjects were 138 undergraduate psychology students at the University of Edinburgh.
 They were tested during a lecture on cognitive psychology.
 These students are drawn from a wide range of departments across the entire University with a predominance of social science faculty students.
 Few of these students had received any formal logical training at high school although some may have experienced "set diagrams' like those used in the current study in the mathematics curriculum.
 None of the students had taken logic courses in the University at the point at which this study was run.
 Materials and Procedure Two questionnaires were used in this study.
 The order of presentation of the questionnaires was counterbalanced across subjects such that half the subjects received the graphical (EC) condition first and half received the sentential condition (11) first.
 The Eulers circle (EC) or 'graphical' condition consisted of the five diagrams depicted in figure 1 ofNewstead (1989)and was similar to the E C task described in that paper.
 Diagram 1 was the identity relation (circle 'A' and circle 'B' superimposed); diagram 2 showed a small circle 'A' inside larger circle 'B'; diagram 3 showed a small circle 'B' inside circle 'A', diagram 4 showed circles 'A' and 'B' intersecting and diagram 5 showed 2 nonoverlapping, disjoint circles 'A' and 'B'.
 Below the diagrams the 4 premises were listed in the order ALL, N O , S O M E , SOME.
.
.
NOT.
 Adjacent to each premise were the numbers 1 to 5.
 Subjects were instructed : "Below this paragraph there are five circle diagrams labelled 1 to 5.
 They represent sets of objects (A's and B's).
 Below the circle diagrams there are four statements.
 Please circle the number(s) of the diagram(s) that the sentence is true of.
 If you think 'All A's are B's' is true of diagram 3, circle 3 alongside that sentence.
 You may circle more than one number per statement.
 Please interpret "some" to mean "at least one and possibly all".
 The sentential condition was similar to the immediate inference (II) task described by Newstead (1989) with the exception that an additional response option ("Can't tell") was provided.
 As in Newstead (1989), the questionnaire consisted of four pages.
 At the top of each page one of the four standard quantified statements was displayed: All A's are B's; N o A's are B's; Some A's are B's and Some A's are not B's.
 These were the premiss statements.
 Beneath the stimulus statements the four quantified statements were listed (All A's are B's etc) and the converses of these (All B's are A's etc).
 These were the response statements.
 Alongside the eight response statements were response options 'T' (true), 'F' (false) and 'Can't tell'.
 The order of the four stimulus statement pages was randomised across subjects.
 Subjects were instructed: 743 *' This is a study of the way people draw conclusions from information.
 O n each of the following pages there is a statement at the top of the page.
 A n example is 'All A's are B's'.
 Assume that the statements are true and that there are both A's and B's.
 Below each statement is a line.
 Below the line are some more statements.
 For each of the statements below the line, decide whether you believe it is true, false or 'can't tell' given the truth of the sentence at the top of the page.
 Indicate your belief by circling O N E of either 'T (true) , 'F' (false) or 'Can't teir.
 Examples: • if you believe that 'No A's are B's' is true given the true statement 'AH A's are B's' then circle T • if you believe that 'Some A's are not B's' is false given the true statement 'No A's are B's' then circle F Again, please note that you should interpret 'some' to mean "at least one and possibly all.
' Subjects were allowed as much time as they needed to complete the tasks (approximately 20 minutes).
 Results Task order effects Seventy subjects received the Euler's Circle task first and 68 subjects received the Immediate Inference (II) task first.
 The effect of task order upon response patterns in the Euler's circle task was examined.
 Response patterns were very similar in all cases except for the S O M E As A R E Bs condition.
 Seventeen subjects who received the E C task first responded with the 'B within A' and 'A intersects B' diagrams compared to 7 subjects in the group that received the II task first.
 Conversely, 24 subjects who received the E C task first responded by nominating 4 diagrams (the identity relation, A within B, B within A and A intersects B) compared to 16 in the II first group.
 N o other task order effects were observed.
 Task order effects upon responses in the sentential task were also examined.
 Frequency tables of stimulus condition (ALL, N O , S O M E , SOME.
.
NOT) crossed with the 8 response statements were separately constructed for 'True', 'False' and 'Can't tell' responses.
 N o task order effects were observed.
 Euler's Circle (EC) task Table 1 shows the proportion of correct responses for each quantifier.
 Correct responses are defined as: A L L  diagrams 1 & 2 only; N O  diagram 5 only; S O M E  diagrams 1,2,3 & 4 only; and SOME.
.
.
NOT  diagrams 3,4 & 5 only.
 The results closely agree with those of Newstead (1989).
 Conversion errors on EC task Conversion errors occur when subjects interpret, for example, 'ALL A's are B's' to imply that 'ALL B's are A's'.
 Conversion of 'ALL' (i.
e.
 choice of diagram 1 alone) was evident in 28 subjects (20%).
 Newstead (1989) reports an incidence of 3 3 % in experiment 1 (n=40) and 2 0 % in experiment 2 (n=30).
 Conversion of Table 1: Proportion of correct responses for each quantifier (n=138).
 Statement ALL NO SOME SOME.
NOT Fraction 84/138 112/138 40/138 52/138 Proportion .
61 .
81 .
29 .
38 Newstead .
60 .
75 .
33 .
29 Table 2: N u m b e r of subjects producing Gricean errors  E C task(n=138).
 Response DIAGRAM 3 ONLY DIAGRAM 4 ONLY DIAGRAMS 3 & 4 TOTAL SOME SOME.
NOT 4 8 27 20 24 24 55 52 'SOME.
.
.
NOT' (choice of diagrams 4 & 5 alone) was demonstrated by 9 subjects (6.
5%).
 Newstead (1989) reports 4 % (experiment 1) and 5 % (experiment 2).
 Gricean errors on E C task Gricean errors are equivalent to an interpretation of S O M E and SOME.
.
NOT according to conversational implicatures rather than logical (formal) interpretation.
 Note that subjects were instructed to adopt a logical interpretation.
 Gricean errors are indicated by the failure of subjects to choose diagrams corresponding to universal relationships for S O M E and SOME.
.
.
NOT conditions.
 In the case of S O M E , 24 (17%) subjects chose diagrams 3 & 4 alone.
 Newstead (1989) reports 1 4 % in his study.
 For SOME.
.
.
NOT, 24 subjects (17%) chose diagrams 3 & 4 alone (Newstead reports 21%).
 Table 2 shows the number of subjects who chose diagram 3 alone, 4 alone or both 3 & 4.
 The percentage of subjects showing Gricean responses (Table 2) are 4 0 % ( S O M E ) and 3 8 % (SOME.
.
.
NOT).
 The figures reported by Newstead (1989) are, respectively, 3 0 % and 2 7 % (page 86).
 Immediate inference (II) task Complete data {i.
e.
 for both II and E C tasks) was obtained from 125 of the 138 subjects.
 Table 3 shows the proportion of 'true', 'false' and 'can't tell' reponses to each quantifier in the immediate inference (sentential) condition, along with the correct responses.
 In table 3, Newstead's (1989) results are shown in brackets if the results of the present study differ by more than .
07 from those reported by Newstead (1989  table 2, page 86).
 In table 3, primed conclusion quantifiers (e.
g.
 A') represent the converse conditions (eg A L L B's are A's etc).
 The introduction of the 'Can't tell' response option in the current study resulted in a marked lowering of conversion and Gricean errors of interpretation compared to the results of Newstead (1989).
 Table 4 compares proportion of correct responses for the E C and II tasks.
 Correct responses for the E C task were defined above in section 4.
1.
 On the II task, correct responses 744 Table 3: Proportion of subjects responding 'True', 'False', and 'Can't Tell' to syllogism statements in the immediate inference condition, along with correct responses.
 Table 5: Frequencies of subjects making numbers of errors on Q AB.
QBA? questions.
 TRUE Conclusion All Air No No' Some Some' Some not Some not' FALSE All Air No No' Some Some' Some.
not Some not' CAN'T TELL All Air No No' Some Some' Some, not Some not' CORRECT All All' No No' Some Some' Some.
not Some.
not' Premiss ALL .
99 33(.
57) .
00 .
06 85 .
64(87) 04 .
12(47) NO .
00 04 98 59(80) 02 04 75 52(77) SOME .
10 .
06 .
00 .
00 .
98 .
70(87) .
51(93) .
33(83) S'M NOT .
01 06 .
06 .
03 59(83) .
44(.
77) .
96 .
56(90) .
00 .
14 .
98 66 09 .
07 .
92 .
33 96 .
66 .
00 06 96 61 .
16 .
10 40 .
27 .
97 68 .
00 .
04 .
01 .
04 .
96 .
47 .
60 .
41 .
01 .
04 .
01 .
04 .
00 .
52 .
00 .
25 .
05 .
27 .
03 .
54 .
00 .
26 .
00 .
32 .
00 .
32 .
06 .
34 .
49 64 .
00 .
29 .
00 .
24 .
46 61 .
00 .
45 ,33 .
52 ,38 .
48 ,00 36 _ T CT F F T T F CT F F T T F F T T CT CT F F T T CT CT F CT CT CT CT CT T CT Table 4: Proportion of subjects giving correct responses to II task and E C task items Task condition 11 EC ALL NO SOME SOME NOT .
22 .
43 .
23 .
06 .
61 .
81 .
29 .
38 were defined as shown in table 3.
 For all statements, a m u c h higher proportions of correct conclusions are associated with the Eulers circle task than with the immediate inference task.
 Subject Profiles Although grouped data provides a comparison to earlier work and it is possible to examine piecemeal correlations between answers to different questions, our real interest is in finding patterns of interpretation characterising a subject's interpretative scheme as a configuration.
 There is a large space of possible patterns of response across both graphical and sentential questions (rather less than 1 million), and therefore a considerable problem in finding useful descriptions.
 W e approached this problem by exploring students' responses to logical independence and their use of the C T response.
 A n early observation was that a substantial group of students responded C T whenever asked a question in which subject and predicate were transposed.
 Not only would these stuCTfor T/F 0 1 2 8 Totals 0 3 1 0 0 1 0 0 0 14 19 1 4 0 1 0 1 0 1 3 2 12 2 10 0 0 1 3 0 3 1 0 18 T/F forCT 3 4 5 6 1 1 7 2 1 0 0 3 1 0 0 1 0 1 1 0 0 0 2 1 0 1 0 1 0 2 0 II 19 11 6 5 0 1 0 0 1 0 0 0 7 7 6 5 0 0 1 0 0 0 0 12 8 13 2 0 1 0 0 0 0 0 16 Tot 65 11 6 3 8 1 7 6 18 125 dents respond C T when given, for example.
 All A are B and asked whether All B are A, but they would respond the same way when given Some A are B and asked whether Some B are A.
 Further investigation showed that there was also a substantial group of students who never responded C T to any question with transposed subject and predicate.
 Not only would these students respond, for example, T when given All A are B and asked whether Some B are A, but they would also respond the same way when given i4///4 are Band asked whether/\//5 are A.
 Further investigation revealed that this strong bimodality of response distribution also occured to questions where subject and predicate were not transposed.
 For convenience, we label a tendency to respond C T where T or F is correct hesitancy and a tendency to respond either T or F where C T is correct, rashness.
 Table 5 exhibits the distribution of subjects across these response tendencies.
 Rashness and hesitancy can potentially be exhibited both when the conclusion sentence preserves subject/predicate (henceforth inplace) and when it changes (henceforth outofplace).
 Table 5 shows that no subjects have strong tendencies to be rash on inplace questions and hesitant on outofplace questions.
 These results suggest a scheme for insightful abstraction over the sentential response data.
 Setting thresholds on the number of C T responses required to qualify as hesitant, and and on the number of T or F responses to qualify as rash can be done both within Q A B questions and Q B A questions.
 This reduces the space to four binary dimensions.
 Hierarchical loglinear modelling {e.
g.
 Stevens, 1992) revealed that 3 secondorder terms (rashness on inplace questions by rashness outofplace; rashness outofplace by hesitancy outofplace; rashness inplace by hesitancy outofplace) made statistically significant contributions to a model of the data.
 The technique also permitted the cutoff points on each dimension used to categorize subjects to be iteratively adjusted until residuals were minimized.
 The selected cutoff points were 0, > = 1 responses for rashness on inplace items; < 5, > = 5 for rashness on outofplace items; and < 6, > = 6 for hesitancy on outofplace items.
 As it turns out, there are no subjects who are hesitant on inplace questions and so only three of these dimensions are useful in presenting the data.
 Figure 1 shows the number of subjects at the vertices of the cube defined by these three dimensions.
 745 \ .
 f ^ \ 1 43 28 \ 5 \ Table 6: Numbers of subjects classified by rashness and hestitancy on outofplace questions, and by ECconversion.
 25 Hesitant (iut<irplaoe *• Figure 1: Frequencies of subjects classified as rash or hesitant on outofplace questions and rash on inplace questions.
 Only four of the possible eight categories have more than five subjects in them.
 A substantial number of subjects (28) are neither rash nor hesitant on either inplace or outofplace questions.
 The other three substantial categories all consist of exhibiting a single type of error tendency either rashness on inplace questions (21), rashness on outofplace questions (43), or hesitancy on outofplaceitems (25), but few subjects show two or more of these tendencies.
 Relations between sentential and graphical behaviour A full analysis of the graphical responses is beyond the scope of this paper.
 Our initial concern is to show that the graphical behaviour exhibited is strongly related to the sentential behaviour as elicited in the present study and categorised here.
 Most sententially based theories of syllogistic reasoning performance (e.
g.
 Chapman & Chapman 1959) have claimed that the 'illicit conversion' of All A are B into All B are A is centrally implicated in reasoners' errors.
 This lead Newstead (1989) to take 'graphical conversion' (as exhibited in the choice of only the identity diagram to represent All A are B) as a.
 graphical equivalent of sentential conversion, and to point out the lack of correlation between sentential and graphical behaviour in his data.
 W e therefore take graphical conversion defined in the same way as a convenient feature of graphical behaviour to correlate with our analysis of sentential behaviour.
 Twentyfive of our subjects exhibited this graphical pattern of choice.
 Table 6 shows the relations between this graphical conversion response, rashness on outofplace questions, and hesitancy on outofplace questions.
 Finally, table 7 shows the number of subjects making various graphical response combinations to S O M E and S O M E N O T premisses, as a function of rashness and hesitancy on outofplace items.
 Discussion Typically, the data used in the literature to examine interpretation and to explain reasoning patterns has consisted of ECconv no yes 1 Totals Hesitancy No I Yes Rash outofplace no yes 46 33 3 12 49 45 no yes 20 1 10 0 30 1 Totals 100 25 125 Table 7: No.
's of subjects m a k i n g various graphical response combinations to S o m e and S o m e  n o t premisses, classified by rashness and hesitancy o n outofplace questions.
 1 S O M E Choices Not Rash Rash 1234 24 6 124 1 2 Not Hesitant 134 14 2 2 1 3 234 5 2 34 8 14 4 6 10 1 Hesitant Not Rash Rash 8 1 4 1 2 2 0 0 1 0 2 0 10 1 1 SOMENOT Choices Not Rash Rash 345 30 7 34 12 9 Not Hesitant 3 45 4 0 2 3 4 5 9 5 1 2 0 2 4 1 Hesitant Not Rash Rash 12 0 3 0 2 6 0 1 5 1 0 0 0 0 responses to particular inferences.
 The field has concentrated on specific errors — especially on errors of commission (e.
g.
 illicit conversion) rather than on errors of omission (e.
g.
 failing to conclude from Some A are B that Some B are A).
 Our analysis of the sentential data shows that there are strong response tendencies which generalise across particular logical inferences.
 Hesitancy and rashness are traits.
 These traits are especially strong across quantifiers within preserved subject/predicate structures, and within changed subject/predicate structures.
 Furthermore, errors of omission are as common as errors of commission.
 These observations show at very least the incompleteness of existing frameworks of explanation such as Grice's, which by their nature can only explain errors of commission, and only with specific quantifiers.
 W h e n it is understood that questions about the validity of inferences are quite distinct from questions about truth value in a particular model, behaviour can be shown to be far more coherent than previously appreciated.
 Patterns of answers to sentential questions about validity are predictive of patterns of answers to graphical questions about truth values in models.
 If behaviour is systematic but does not conform to a logical model, this raises the question how it should be modelled.
 The most prevalent theoretical model in discussions of quantifier interpretation is that of Grice's (1975) conversational principles.
 Grice's maxims allow hearers to make reasonable inferences about the speaker's intentions.
 Some A are B is taken to imply that Not all A are B because it is supposed that the 746 speaker would have been maximally informative, and therefore would have said All A are B if that was what they meant.
 The prevalence of this inference (and others like it) in the present data is all the more suprising in the light of the explicit instruction not to draw it.
 Suprising or not this is a result replicated from Newstead's and other studies.
 Grice's maxims are embedded in a theory of a certain kind of discourse.
 It assumes that the participants are cooperating and that their goal is to transfer information from one to the other.
 In deductive discourse, the use of language that logic is most directly designed to model, there is no automatic assumption of cooperation, neither is transfer of information the goal.
 Drawing a valid inference from a premiss is, by definition uninformative at the object level of information at which Grice couches his theory.
 Grice's approach suggests a class of explanation for why there is anything to learn in logic classes and why it can prove so arduous.
 If our natural language skills are primarily honed on the comprehension and production of expository discourse aimed at the cooperative interchange of information about which the participants' knowledge is initially unequal, then we might suppose that learning deductive discourse requires unlearning many of these skills.
 W e have to learn to turn off deeply embedded habits of drawing conversational implicatures.
 Insofar as it goes, this appears to us to be a promising theoretical direction, but it is important to realise how incomplete the program is.
 Grice offers no theory of how deductions are informative, even though it is clear that deduction is goal driven discourse which is sometimes cooperative and which does inform.
 Similarly many of the implicatures Grice describes assume the speaker is omniscient with regard to the domain at issue and it is not clear why such assumptions are so readily made.
 Specifically, Grice does not provide any explanation of where assumptions of omniscience originate.
 It is true that some interpretation errors accord with Grice's maxims but it is equally clear that many do not.
 More importantly, his kind of theory, as it stands, offers no explanation of the extremely prevalent errors of omission in our data.
 W h y should students fail to appreciate that Some A are B entails that Some B are Al And why should there be any correlation between errors of omission and of commission? And between errors across quantifiers? And with subject/predicate structure? The most striking feature of our sentential data is the degree to which traits of error behaviour are defined by differences between inferences in which subjects and predicates maintain their status in sentences (inplace questions), and ones in which their status changes (outofplace questions).
 It appears that learning when subject/predicate status has logical implications, and when it does not is also a major part of the task of learning logic.
 This can be expressed in terms of learning to adopt an 'extensionalist stance' in which both subject and predicate terms denote sets, and that attribution is understood as asserting relations between sets.
 This is definitely not our initial understanding of the semantics of our natural language.
 In natural language, one of the important functions of subject/predicate structuring is to indicate the information asymmetries between participants in cooperative expository discourse.
 Subjects paradigmatically denote shared knowledge; and predicates convey the information which is being transferred.
 Thus our results show the need for deepening the Gricean approach into a fuller theory of how the different kinds of discourse work, so that we can specify both beginning and endpoints of students' learning trajectories.
 The relation between traits of rashness and hesitancy as narrowly defined in this study, and other known traits from the student modelling literature {e.
g.
 Jonassen & Grabowski, 1993) is an important topic for future research.
 Are these general, almost temperamental traits, which are here exhibited interacting with the learning of new discourse functions for specific grammatical structures, or do they have no broader significance beyond this particular setting? D o the patterns of response constitute profiles characteristic of individuals, or are they stages on a common trajectory from naive to sophisticated understanding? H o w responsive are they to educational intervention? Our belief is that answers to these questions will provide a much needed theory of how logic is embedded in social practices.
 Learning the discourse of deduction and understanding how it relates to the discourse of exposition is all about understanding different possible social relations in communication.
 Exposition is discourse with knowledge and "authority for information' asymmetrical between participants.
 Deduction is discourse with symmetrical knowledge and authority for knowledge.
 It would be suprising if learning such a profound communicative shift is not affected by broad behavioural traits.
 References Chapman, L.
 J.
 & Chapman, J.
 P.
 (1959).
 Atmosphere effect reexamined.
 Journal of Experimental Psychology, 58, 220226.
 Grice, H.
P.
 (1975).
 Logic and conversation.
 In P.
 Cole & J.
L.
 Morgan (Eds.
), SyntcLx and semantics: Volume 3  Speech Acts, N e w York:Academic Press, 4158.
 Jonassen, D.
H.
 & Grabowski, B.
L.
 (1993).
 Handbook of individual differences, learning and instruction.
, Hillsdale, NJ: Lawrence Erlbaum Associates.
 Newstead, S.
E.
 (1989).
 Interpretation errors in syllogistic reasoning.
 Journal of Memory and Language, 28, 7891.
 Stevens, J.
 (1992).
 Applied multivariate statistics for the social sciences.
, Hillsdale, NJ: Lawrence Erlbaum Associates.
 Acknowledgements The assistance of Dr N.
 Chater in allowing testing during his lecture is gratefully acknowledged.
 W e would also like to thank Dr Robert Inder and Richard Tobin for programming assistance.
 747 A r g u m e n t s and Adjuncts: A Computational Explanation of Asymmetries in Attachment Preferences Suzanne Stevenson Center tor Cognitive Science and Dept.
 of Computer Science Rutgers University N e w Brunswick, NJ U8903 s u z a n n e O r u c c s .
 r u t g e r s .
 e d u Abstract An explanatory model of ambiguity resolution in human parsing must denve a multitude of preference behaviors from a concise computational framework.
 One behavior that has been difficult to account for concisely is the preference to interpret an ambiguous phrase as an argument of a predicate, rather than as a modifier that is less integrally related to a phrase (an adjunct).
 Previous accounts of the argument preference have rehed on assumptions about adjuncts requiring a more complex structure or entaiJing a delay in their mterpretation.
 This paper explores a more fundamental distinction between arguments and adjuncts—that the numberof potential arguments of a predicate is fixed, while the number of adjuncts for a phrase is unpredictable.
 This simple difference has important computational consequences withm the competitive attachment model of human parsing.
 The model exhibits a preference for arguments over adjuncts due to the necessary differences in competitive properties of the two types of attachment site.
 The competitive differences also entail that adjuncts accommodate more easily than arguments to contextual effects.
 The model thus provides a concise and explanatory account of these argument/adjunct asymmetries, avoiding the unnecessary structural or interpretive assumptions made within other approaches.
 Introduction In developing a model of human parsing, it is crucial to discover a small set of computational principles that can account for the human ability to effectively resolve linguistic ambiguities.
 A n explanatory model must derive a multitude of observed human preference behaviors from a concise computational firamework.
 One aspect of human syntactic processing that has proven resistant to integration within an explanatory account is the following argument attachment preference: People prefer to interpret an ambiguous phrase as an argument of a predicate—for example, as the direct or indirect object of a verb—rather as an adjunct, which is a modifier of a phrase.
 As cin example, consider a sentence beginning Sara put the boxes on the table.
.
.
, in which the atuichment of the prepositional phrase (PP) on the table is jimbiguous.
 The PP can attach to the verb phrase as the location argument of the verb put (i.
e.
, the place where Sara put the boxes), or to the noun phrjtse as an adjunct modifier of the noun boxes (i.
e.
, the boxes jire those that are on the tiible).
 In a choice of this kind between £in cirgument and adjunct attachment for a phrase, the humjin parser shows a strong preference for interpreting the ajnbiguous phrase i\s an <'irgument.
 Explaining the argument atuichmeni preference has been an important goal in modeling humjin pjirsing, <ind yet to date, no theory hjis given an account of this phenomenon that avoids ad hoc assumptions about adjuncts.
 Some theories assume that an adjunct attachment requires a more complex structure than an argument attachment.
 The preference for the argument attachment then follows from a more general preference for building simpler syntactic structures (Frazier, 1978, 1990; Gorrell, 1995).
 However, a strict adherence to this type of structural complexity approach cannot easily accommodate the accumulating evidence that lexical, semantic, and discourse contexts affect initial attachment decisions (e.
g.
, MacDonald, Pesirlmutter, & Seidenberg, 1994; SpiveyKnowlton, Trueswell, & Tanenhaus, 1993; Taraban & McClelland, 1990).
 Furthermore, the crucial assumption in such an account—that adjunct attachments require the online addition of more nodes into the parse tree— is not a computational necessity.
 For example, in parsing approaches based on preallocated X templates (e.
g.
, Lin, 1993; MacDonald et al.
, 1994; Stevenson, 1994a), the structurebuilding costs of arguments and adjuncts is equivalent.
 Other models posit that the increased difficulty of processing adjuncts arises in the interpretive component of the language processor, rather than in the structurebuilding component.
 Some models fonnulate this as an explicit preference for thematic (argument) attachments (Abney, 1989; Gibson, 1991; Pritchett, 1992); related approaches assume that determining the thematic role of an argument in the discourse is faster than determining that of an adjunct (Crocker, 1992; M c R o y & Hirst, 1990; Weinberg, 1991).
 None of these approaches depend on adjuncts having increased structural complexity.
 However, the evidence cited above that strongly supports the immediacy of contextual influences makes it less plausible that receiving a thematic role or not from a predicate would lead to a significant difference in complexity or speed of interpretation.
 Thus, the thematic/nonthernatic distinction between arguments and adjuncts, like the structural distinction, appears unable to provide an explanatory account of the argument preference.
 In fact, neither structural complexity nor interpretive difficulty is a necessary property of the adjunct modifying relationship.
 The proponents of both the structural and the interpretive approaches are building into these models the ob748 served iirgument/adjunct distinction, by explicitly formulating a treebuilding or interpretive cost to be jissociated with adjuncts.
 O n the other hjind, a purely contextuid approach relying entirely on differential frequencies of lexic;il associations (e.
g.
, MacDonald et al.
, 1994) appe;us simply to restate the original problem, since presumably diflerent frequencies are not accidental but cirise from some more fundamental distinction.
^ The question then is: Are there any necessary properties of adjuncts that differentiate them computJitionjdly from arguments? Surprisingly, there is a very simple difference between arguments <'ind adjuncts whose consequences have not previously been explored.
 Namely, nodes in a pcirse tree license ivn exact number of arguments—0, 1, 2, or 3—Jind each of those individual arguments may be optionjil or obligatory.
 By contr<LSt, nodes can be modified by an jirbitrary number of adjuncts—0 or more—each of which is idways optional.
 Note that this is essentially the definition of what it means to be an adjunct as opposed to an argument.
 In the competitive attachment parser (Stevenson, 1994a), this simple, fundamental difference between arguments and adjuncts leads to an imporuint difference in computational properties between the two types of attachment sites.
 In the model, attachments are decided by a competitive process of spreading numeric activation through a massively parallel network, which directly represents the possible parse tree structures.
 A competition for activation at each attachment site focuses the activation within the network onto the preferred set of attachments.
 The competitive attachment process has been shown to provide an explanatory account of a number of human behaviors in processing syntactic ambiguities that involve argument attachments (Stevenson, 1993a, 1993b, 1994b).
 This paper discusses the extensions that are required to ensure the activation of the appropriate number of attachments to an argument or adjunct attachment site.
 The result is a necessary difference in the degree of competition at argument and adjunct sites, which leads to asymmetries in their behavior.
 One important consequence is that the competitive attachment model mimics the iirgument attachment preference observed in human parsing.
 The paper demonstrates additional asymmetries of argument and adjunct attachments, ;is well us the smooth integration of contextual preferences ;ind recency effects into the relevant attachment competitions.
 The results extend the explanatory account of the model by showing how independently motivated properties of the competitive attachment mechanism concisely account for differences in the humjin parsing of arguments and adjuncts.
 The Competitive Attachment Process The competitive attachment model is implemented within a hybrid connectionist framework, in which a parsing network directly represents syntactic phrases and the potential attach(cO ' Furthermore, a purely contextual account of the data thus far appears insufficient.
 For example, Hindle & Rooth (1993) found that a statistical model of PP attachment, based on lexical associations derived from a large corpus, achieved only 8 0 % accuracy even when tested on (previously unseen) sentences from the same corpus.
 Sara the boxes • active argument attachment G Inactive argument attachment # active adjunct attachment O Inactive adjunct attachment (b) boxes Sara Figure 1: (a) The competitive attachment network piusing Sara put the boxes on the table, at the word on.
 Attachment nodes connect potential sisters in the parse tree; attachments to empty (e) nodes represent unfilled attachment sites, (b) The partial parse tree represented by (a).
 ments among them.
 The network is created "on the fly" in response to a sequence of words; each word triggers the activation of a phrase <uid its initialization with the appropriate grammatical features.
 The current phrase is connected to the existing network with attachment nodes, which represent the potential attachment of the current phrase at each of the attachment sites along the right edge of the partial parse tree being developed; see Figure 1.
 Attachment nodes connect two potential sisters in the parse tree; compare the network of Figure 1(a) with the partial parse tree that it represents in Figure 1(b).
 After the current phrase has been connected to the developing parse tree structure, the network enters a spreading activation loop in which the attachment nodes compete for the available activation.
 W h e n the network settles, the set of winning attachments represents the preferred piû se tree structure for the input, up to and including the current phrsise.
 The number of iterations required for the network to settle indicates the degree of difficulty in deciding on the current set of attachments.
 T w o factors that influence the outcome <md speed of the attachment competition will be relevjint to the results here.
 749 First, each link between a phrasjil node and ;in attachment node hiis a weight that affects the proportion of activation that the attachment node receives froin the phrasiil node.
 The weights integrate all contextuiU preferences; they may derive directly from the thematic grid of a lexical entry, but :»re ;ilso subject to sem.
'uitic ;ind discourse inlluence.
 In this paper, the different possible weight values on ;in attachment link will be classitied as a weitk, moderate, or strong contextual preference.
 A second importjuit factor in the activation of attachments is the numeric decay of phnuses over time.
 This process results in more recent phrases having more activation to contribute to attachment nodes, making the attachments to more recent phrases more likely to win.
 The competitive activation functions of the parsing network focus activation onto a set of attachments that are most consistent with these influences.
 The Competitive Properties of A r g u m e n t s a n d Adjuncts The precise number of arguments for a word is specified in the lexicon.
 Hence, when the nodes of a phrase iire activated, an argument attachment site is established corresponding to each of the specified arguments.
 In order to satisfy its lexical specification, each argument attachment site must activate exactly one attachment node.
^ To accomplish this, the numeric functions that focus activation onto a preferred attachment must be highly competitive—i.
e.
, they must have sharp "winnertakeall" behavior, so that only a single argument attachment node is activated.
'' Previous work has shown that the argument attachment activation functions achieve this necessary singlewinnertakeall behavior (Stevenson, 1994a).
 As mentioned above, adjuncts are fundainentally different from arguments in this regard, since an arbitriiry number of adjuncts may modify a given phrase.
 Because the number of adjuncts of a phrase cannot be known ahead of time, a single attachment site for each potential iidjunct cannot be allocated along with the phrase, in a manner similar to the allocation of argument attachment sites.
 The model is thus forced to allow an arbitrary number of attachments to be activated by a single adjunct site.
 (Whether that site is an X' or X P is irrelevant to the results here.
) Because the competitive activation functions for arguments sharply focus activation onto a single attachment possibility, they are unable to support the simultaneous activation of multiple attachments.
 Adjunct sites must employ a much less competitive activation function— one which enables multiple adjunct attachments by allowing "multiplewinnerstakeall" behavior.
 Perhaps surprisingly, no additional activation functions had to be added to the model to satisfy the requirements of adjuncts.
 The parser already incorporated a "multiplewinnerstakeall" activation function for the stack data structure, which is used for proper input sequencing (Stevenson, 1994a).
 Thus, the required behavior for The attachment may be to an "empty" node if the argument is optional (or a trace); see Stevenson (1993b).
 'Specifier attachment sites have the same requirement, since they also license exactly one attachment; thus, they are able to use the same activation functions as argument sites.
 adjuncts is achieved through an existing and independently necess<'U7 mechjinism of the model.
 Furthermore, the stack ;ind adjunct activation functions arc precisely the s;une ;ls the ;irgument functions, except for a piiriuneter that adjusts the degree of competition at the attachment site.
 As <in ex;unple of multiple adjunct attachments, consider a .
sentence such ;ls: (1) I [vp went [pp with Sara] [pp from London] (pp to Madrid! [pp on TWA]].
 The verb phrase (VP) is modified by four separate prepositional phrases (PPs), necessitating multiple adjunct attJichinents to the VP.
 The first PP, with Sara, atuiches to the V P in 17 iterations of the network.
 This is quite fast, representing an easy attachment for the psirser; in fact, this is the siune number of iterations required for the parser to decide on the attachment of a phrase to an obligatory argument site.
 In contrast to other models (e.
g.
, Frazier, 1978; McRoy & Hirst, 1990), there is no inherent slowdown in the speed of syntactic operations solely due to the attachment of a phrase as an adjunct rather than as ni\ argument, if there are no competing attachment sites.
 In processing the remainder of sentence (1), the next three PPs successfully activate attachments to the VP, in each case requiring 22 network iterations.
"* Thus, the degree of competitiveness of an adjunct attachment site is indeed mild enough to support attachment of arbitrary numbers of adjuncts, as required.
 Syntactic Ambiguity and Attachment Competitions As explained above, potential attachments to an adjunct site must not compete too strongly with each other, or modification of a single node by multiple adjuncts would not be supported.
 The decreased level of competition means that the available activation at an adjunct site is spread more evenly across the potential attachments.
 During an attachment competition, nodes that connect to an adjunct site can maintain similar activation levels.
 This contrasts with argument sites, where the available activation must be focused onto a single attachment.
 These sites force a greater difference between the activation levels of the attachment nodes connected to them.
 The result is that one attachment node at an argument site typically becomes a much stronger attractor of additional activation, while all the attachment nodes at an adjunct site attract activation less strongly.
 The crucial consequence for the modeling of human behavior is that the decrease in competitiveness among attachment nodes for activation from the same adjunct site has the indirect effect of decreasing the ability of those attachment nodes to compete with attachments to other (adjunct or argument) sites.
 Thus, in situations of synuictic ambiguity, when more than one attachment site is competing to activate an attachment to the current phrase, asymmetries •"The attachment of additional adjuncts to the same phrase is slower than attachment of the first because there is an increase in competition for the activation being output from the VP.
 750 in argument and adjunct attachment behaviors arise from their differing competitive properties.
 Competition between Two Adjunct Sites First consider the following wellknown ex;un|)ic, in which two different adjunct sites compete for the attachment of a single phrase: (2) I [vp saw [np the man [pp with the telescope].
 The V P saw iind the N P the man compete for the attachment of the PP as an adjunct.
 Models of human parsing disagree on the preferred attxichment in these crises.
 S o m e theories claim that there is a VPattachment preference (Abney, 1989; Frazier, 1990), while others predict that the most recent (NP) attachment is preferred (Gibson et al.
, 1995; M c R o y & Hirst, 1990).
 The competitive attachment model provides Jin account that captures the variability in intuition surrounding this structure.
 In the parsing network, the decay of activation of phrasal nodes entails a general recency effect (Stevenson, 1994b), leading to a preference for the PP to modify the more recent phrase (the NP ) .
 However, the decision to attach to the most recent phrase is affected by only slight changes in lexical or contextual preferences.
 If the V P shows even a slight preference to have a modifier (or the N P to not have a modifier), then the PP will attach as the adjunct of the V P instead of the NP, requiring only one or two more iterations than the attachment to the N P in the neutrjil context case.
 Thus, a slight change in preference c;in cause the parser to change the preferred attachment site, with minimal cost in the time it tiikes to make the attachment.
 By smoothly integrating both recency cuid contextual preferences, the model accounts for the evidence that, in these types of modification structures, appropriate contexts can easily change syntactic attachment preferences, with little or no penality in processing time (Taraban & McClelland, 1990).
 Lexical or contextual preferences can similarly change the preference to attach a phrase from the more recent to the less recent of two argument attiichment sites.
 By contr.
xst with adjunct attJichments, however, it is quite costly to do .
so.
 The high degree of competitiveness of <irgument sites causes a slowdown of 2 5  3 5 % for the network to settle on the less recent of two cirgument attachments (Stevenson, 1994a).
 The competitive attachment model thus predicts that adjunct attachments more easily accommodate to contextual influences thiin argument attachments.
 This behavior does not rely on an iissumption regarding a difference in when thematic or semantic interpreUition occurs, but rather results from neces.
ScUy differences in the competitive properties of making adjunct versus Jirgument atuichments.
 Thus, behavioral asymmetries between jirguments ;ind adjuncts .
'uise even when they Jire not in competition with each other.
 Competition between Argument and Adjunct Sites N o w let's turn to cases in which ;in adjunct atUichment site competes with nn argument attiichment site.
 This typeof competition may show up even within the sjune phnise, Jis in the ttM dalm the clolm Figure 2: (a) Moderatetostrong ;u"gument preference.
 (b) Weiik argument preference.
 N P beginning with the claim in: (3a) The evidence supported [np the claim [cp that Sara is innocent]] (3b) TTie evidence supported [np the cljiim [cp that the prospector disputed t ]] In (3a), the C P (clausal phrase) is a complement clause that attaches as an itrgument of claim, while in (3b) the C P is a relative clause that attaches us a modifier of the NP.
 Thus, at the word that, the parser is choosing between an argument and adjunct attachment site for the CP.
 The competitive attachment model does not m;ike £in adjunct attachment less desirable in direct comparison with an argument attachment; there is no builtin difference in their weights or activation levels.
 However, as described above, the decrease in competitiveness among attachments at the adjunct site has the indirect effect of making the adjunct site less able to compete with other attachment sites.
 Thus, the network settles on the .
irgument attachment for the CP, exhibiting an argument attachment preference, its in Figure 2(a).
 However, the adjunct attachment possibility is not irrelevant, as can be seen when lexical or contextual preferences are taken into account.
 In this configuration, if the contextujil preference for the ctfgument is moderate to strong, then the current phnise will attach as an jugument.
 O n the other h.
'ind, if the preference for the argument is weitk, the phrase will instead attach as an adjunct; see Figure 2(b).
 Again w e see that lexic<il or contextu<il preferences may affect the pjirser's attachment decision.
 However, in a choice between an i\igument cind cin adjunct attiichment, the greater competitiveness of the cirgument site entails that a significiint change in extem£il preference is required in order to overcome the i\Tgument atuichment preference and select the adjunct attachment instead.
 The choice of argument or adjunct attachment is thus susceptible to contextual influences, but slight changes in preference cire insufficient to shift activation away from the highly competitive argument attachments.
 It is importJint to emphiisize here that the preference for the argument attiichment Jiri.
ses solely from independently motivated properties of the competitive activation functions, ;ind not from some inherent difference in v;due assigned to ;trgument :ind adjunct attachments.
 In the competitive attiichinent model, adjuncts iire assumed to satisfy gr.
unmaticid constniints as well .
is arguments (in contrast to approaches such as in Gibson (1991) or Pritchett (1992)), giving them equ;dly highapnon activation levels.
 The demonstrated argument at751 tai hinent preference here is noi a result of a builtin thematic preference, ;ls it is in a number ot other models (e.
g.
.
 Abney, 198y; Crocker, 1992; Gibson, 1991; Pritchett, 1992; Weinberg, 1991).
 This is ;ui importiint distinction, since in most ot these models, the preference for an iirgument over ;in adjunct is absolute; such ;in account does not lend itself well to the shifts in preference that are observable within different lexic.
'd and discourse contexts.
 The competitive attachment model can explain both thegenend preference for jin ;irgumenl attachment, as well as the ability of contextujd influences to moderate that preference.
 The Argument Attachment Preference and Recency In example (3).
 the relative recency of the competing attachment sites is not a factor because they are located within the saine phnLse.
 This contrasts with exjunple (4), in which a higher jirgument attachment is competing with a lower, more recent adjunct attachment: (4) Sara [vp put [np the boxes [pp on the table].
 Here the PP may attach as the second argument of the verb put.
 or iis the modifier of the N P the boxes.
 In spite of a strong and robust human preference for more recent attachments (e.
g.
, Frazier, 1978; Gibson, 1991; Kimball, 1973; Stevenson, 1994b), whichby itself would predict that the PP attaches to the iinmediately preceding NP, the human parser instead prefers the argument attachment to the verb.
 This preference is clearly demonstrated in an input that is incompatible with the argument preference; consider the following sentence that requires the more recent adjunct attachment for the PP on the table, so thai the PP onto the handtruck can attach as the argument of the verb: (5) #Sara [vp put [np the boxes [pp on the table]] [pp onto the handtruck].
 Because the iirgument attachment preference misleads the hum.
ui parser, this sentence causes people to experience severe processing difficulty, called a garden path (indicated by the hash mark "#").
^ Thus, the argument attachment preference appejirs to override the strong and consistent recency effects within the hum.
'in parser.
 Many pjirsing models account for recency effects with a builtin ambiguity resolution suategy, which must then be explicitly ordered behind the iirgument attachment preference so that it will not overapply in these types of cases (Abney, 1989; Frazier, 1978,1990; Gibson, 1991).
^ The smooth inteniction in the competitive attachment model between the decay of phrases and the preference for argument attachments contrasts with these other solutions in which heuristics must Saia ^Note, however, that some evidence has shown that the garden path effect in these and related examples can be avoided given appropriately biasing contexts (e.
g.
, MacDonald et al.
, 1994; SpiveyKnowlton et al.
, 1993; Taraban & McClelland, 1990).
 ®ln Gibson's model, principles apply simultaneously, and so cannot be serially ordered.
 Instead, to achieve the correct prioritization of argument/adjunct effects and recency, his "Principle of Recency Preference" must treat argument and adjunct attachments differently.
 Ih* "o*** Figure 3: The model demonstrates a preference for a much less recent .
'irgument site over a very recent adjunct site.
 be explicitly n'lnked.
 Figure 1(a) shows the attachment decision at the P P for the word on in examples (4) £ind (5).
 Despite a strong, general preference for more recent attachments, the coinpetitive attachment parsing network settles on the cirgument attachment for the P P due to the fundamental distinction in degree of competition between arguments and adjuncts.
 Even when the distance froin the current phrase to an avmlable argument site is m u c h greater than the distance to an adjunct site, the h u m a n parser still prefers the argument attachment.
 For example, sentence (6) also produces a garden path effect (Gibson, 1991): (6) #Sara [vp put the boxes that John [ v p saw [pp on the table] [pp onto the handtruck].
 Here the adjunct attachment for the P P on the table (to the V P saw) is m u c h more recent than the argument attachment (to the verb put); compare the distance between the pairs of potential attachment sites in Figure 1(a) Jind Figure 3.
 However, the ;irgument atuichment preference remains and the P P on the table is again misinterpreted by the humfin parser as the argument of the verb, leading to processing difficulty at the next PP.
 Consistent with this observation, the competitive attachment model also chooses the argument attiichment for the PP on the table in this example, as shown in Figure 3.
 Models with builtin thematic and recency preferences (e.
g.
, Abney, 1989; Gibson, 1991) predict that the garden path effect can be avoided if the embedded verb saw in sentence (6) is replaced by a verb like threw, that can itself take a PP argument.
 In these models, in a sentence like (7), the P P on the table attaches as an (optional) argument of the verb threw, leaving put's argument site open for the fin;d P P onto the handtruck: (7) ?Sara [vp put the boxes that John [vp threw [pp on the tfible]] [pp onto the hjuidtruck].
 The decision of the competitive attachment model does not conform with this view.
 Given an optional argument attachinent in the embedded clause, the network will still settle on 752 the obligatory c'lrgumenl attrichment for on the table, attaching the PP to the higher verb put, thereby not avoiding the gitrdcn path.
 However, if the lower verb threw has even a slight prclerence to occur with the optional ;irgument.
 then the hrsi PP is attached to that verb iind the g;irden path is avoided.
 Thus, in the competitive attiichment model, the ability to avoid the garden path relies not on a discrete fact of the lower verb being able to take a PP Jirgument, but rather on the preference of the lower verb to do so.
 Although I know of no experimentiil evidence that bejirs on this, I believe the prediction of the competitive attachment inodel is more likely to be borne out, given the evidence for lexical ;ind sem;intic influences on attachment preferences.
 Conclusions This paper has demonstrated that the competitive attachment model exhibits asymmetries in processing argument and adjunct attachments due to the competitivepropeniesof theactivation functions underlying the two types of attachment.
 The advjintage claimed for the explanation given here compared to other approaches is that the competitive attachment model does not rely on building in dubious .
ussumptions regiirding the structure and interpretiition of adjuncts.
 A n obvious question to ask is why the account is more explanatory, if the difference between arguments and adjuncts is iilso "builtinto" the competitive attachment parser, by providing argument and adjunct attachment sites with different spreading activation functions.
^ The crucial point is that the difference in processing mechanisms is necessary to accommodate a fundamental distinction—that the number of potential arguments of a predicate is fixed, while the number of adjuncts for a phrase is unpredictiible.
 The model thus has iin explanatory advantage over approaches in which argument/adjunct asymmetries arise from controversial structural properties of adjuncts, or from unnecessary assumptions regarding differential speeds of interpretation.
 References Abney, S.
 (1989).
 "A Computational Model of Human Parsing.
" Journal of Psycholinguisiic Research 18:1.
 129144.
 Crocker, M.
 (1992).
 "A Logical Model of Competence and Performance in the Human Sentence Processor.
" Doctoral dissertation.
 University of Edinburgh.
 Fnizier, L.
 (1978).
 "On Comprehending Sentences: Syntactic Piirsing Strategies.
" Doctoral dissertation.
 University of Connecticut.
 Frazier, L.
 (1990).
 "Parsing Modifiers: Special Prupose Routines in the Human Sentence Processing Mechanism.
" In D.
 Balota, G.
 Flores d'Arcais, & K.
 Rayner, Eds.
, Comprehension Processes in Reading, Hillsdale, NJ: Lawrence Erlbaum.
 Gibson, E.
 (1991).
 "A Computational Theory of Human Linguistic Processing: Memory Limitations £ind J*rocessing 'in fact, as mentioned earlier, the same activation functions are used, with only a parametric difference in the degree of competition induced.
 Breakdown.
' Doctoral dis.
sertation, CarnegieMellon University.
 Gibson, E.
, N.
 Peiirlmutter, E.
 CansecoGonzalez, and G.
 Hickok (1995).
 "Recency F*reference in the Hum^m Sentence Processing Mechiinism.
" M^muscript, MIT.
 Gorrell, P.
 (1995).
 Syntax and Parsing.
 Cambridge University Press.
 Hindle, D.
 <'md M.
 Rooth (1993).
 "Structural Ambiguity and Lexical Relations.
" Computational Linguistics 19:1, 103120.
 Kimball, J.
 (1973).
 "Seven Principles of Surface Structure Parsing in Natural Liuiguage.
" Cognition 2:1, 1547.
 Lin, D.
 (1993).
 "PrincipleBased Parsing without Overgeneration.
" Proceedings of the 31st Annual Meeting of the Associationfor Computational Linguistics, 112120.
 MacDonald.
 M.
, N.
 Pearlmutter, and M .
 Seidenberg (1994).
 "Lexical Nature of Syntactic Ambiguity Resolution.
" Psychological Review 101:4,676703.
 McRoy.
 S.
 and G.
 Hirst (1990).
 "RaceBased Parsing and Syntactic Dis<unbiguation.
" Cognitive Science 14, 313353.
 Pritchett.
 B.
 (1992).
 Gramnuitical Competence and Parsing Performance.
 University of Chicago Press.
 SpiveyKnowlton, M.
, J.
 Trueswell, and M .
 Tanenhaus (1993).
 "Context Effects in Syntactic A m biguity Resolution: Discourse and Semantic Influences in Parsing Reduced Relative Clauses.
" Canadian Journal of Experimental Psychology 47:2,276309.
 Stevenson, S.
 (1993a).
 "Establishing LongDistance Dependencies in a Hybrid Network Model of Human Parsing.
" Proceedings of the 15th Annual Conference of the Cognitive Science Society, 982987.
 Stevenson, S.
 (1993b).
 "A CompetitionBased Explanation of Syntactic Attachment Preferences cUid Garden Path Phenomena.
" Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, 266273.
 Stevenson, S.
 (1994a).
 "A Competitive Attachment Model for Resolving Syntactic Ambiguities in Natural Ljinguage Parsing.
" Doctoral dissertation.
 University of Maryland.
 Rutgers Center for Cognitive Science, TR18.
 Stevenson, S.
 (1994b).
 "Competition and Recency in a Hybrid Network Model of Syntactic Disambiguation"y<;Mrna/ of Psycholinguistic Research 23:4, 295322.
 Taraban, R.
 juid J.
 McClelland (1990).
 "P;irsing juid Comprehension: A MultipleConstriiint View.
" In D.
 Balota, G.
 Flores d'Arcjiis, & K.
 Rayner, Eds.
, Comprehension Processes in Reading, Hillsdiile, NJ: Lawrence Erlbaum.
 Weinberg, A.
 (1991).
 "A Parsing Theory for the Nineties: Minimal Commitment.
" Manuscript, University of Maryland.
 753 B r i d g i n g t h e C o n c e p t u a l G a p Hiroaki Suzuki Department of Education Aoyama Gakuin University 4425 Shibuya ShibuyaKu, Tokyo 150 Japan susanCri.
aoyama.
ac.
jp Abstract This paper claims that, contrary to the "Theoryoriented" approach to cognitive development and instruction, children's informal concepts play important roles in learning, and reports two cases that support the constructivist view of learning.
 It is widely believed that children's knowledge about various domains is organized into coherent systems, i.
e.
, theories.
 Although this approach provides a new perspective on knowledge organization, too much emphasis on the conceptual difference makes the interaction of prior knowledge and learning materials impossible.
 Without the interaction, learned rules remained uninterpreted.
 Consequently they can be applied only to a restricted set of problems.
 A case from mathematics revejJed that students' informal concept of concentration can be bridged to the formad one, by rewording quantitative terms in problems with quzditative terms.
 A case from physics showed that by combining fragmentJiry understandings, students could acquire the concept of force decomposition which is difficult to learn by formal instruction.
 Finally, instructional techniques are proposed that make use of informal concepts as a partial base analog to enrich students' understanding.
 Introduction Recent studies on cognitive development have revealed that even young children have a great deal of knowledge in various domains such as physics, biology, mathematics, psychology, etc.
 This finding leads not a few researchers to claim that children's knowledge of the domain is not merely an incomplete version of the adults' one, but that it is organized into a coherent system, "Theory.
" W h a t does it mean by theories? Wellman and Gelman (1992) suggested that theories involve the distinctive ontology, causal mechanism, and coherence.
 A n observed phenomenon is reduced to presupposed entities by the ontology of the theory, while the behaviors of these entities are explained or predicted by the causal mechanism of the theory.
 Some researchers claim that children have their own theories that are fundamentally different from adults' ones.
 Seminal work by Carey gave evidence that children's theory of biology is organized by the naive psychology (Carey, 1985).
 That is, people are a prototype of living things and any biological judgments are made in terms of the similarity to the prototype.
 The problem here is how the conceptual change occurs, the shift from one theory to another.
 Unfortunately few researchers have made it clear.
 One of the reason is that the conceptual change is logically very difficult.
 Strictly speaking, two different theories are incommensurable in the sense that certain terms in one theory do not correspond to any terms in another.
 Cases showing incomensurability can be found abundantly in the history of science.
 By comparing the modern thermal dynamics with the preceding one, Wiser and Carey (1983) showed that scientists in the 17th century presumed the existence of hot/cold particles which have no correspondents in the modern theory and explained thermal equilibrium in terms of the emission of these particles.
 Furthermore, counterevidence is not effective for the theory change.
 Counterevidence is sometimes resolved by adding new elements to the existing theory.
 For example, the fact that burned objects become heavier appears to be counterevidence for the "phlogiston" theory of combustion.
 However, scientists at this age thought that phlogiston had "lightness.
" Since phlogiston was supposed to be consumed during the combustion, lightness lost.
 That was how the scientists explained why burned objects become heavier after the combustion.
 If the same were true for the conceptual change in students, it would follow that students cannot acquire a new theory.
 Actually, in some domains, concepts such as force, natural selection, heat, etc.
, have been found to be quite difficult to learn.
 Chi (1993) claimed that these are members of the "acausal interaction" category in the ontological tree.
 This category involves many characteristics that distinguish itself from the others.
 Members of this category do not have any causes, the beginning, nor the end and proceed according to constraining relations among their components.
 These characteristics make the understanding of this category quite difficult.
 Chi further claimed that the main source of the misunderstanding lies in the fact that people try to assimilate these concepts to categories familiar to them.
 Most of the misunderstandings in physics are caused by making force belong to the matter category.
 For example, naive people hold that force is a kind of impetus and can be used up.
 This view leads them to think that motion is initiated by agent's giving force, that force decreases because it is consumed during motion, and that motion ends when force is used up.
 The implication of Chi's claim for the instruction is to teach the existence and characteristics of the new cate754 http://ac.
jpformal concept informal concept Figure 1: The relationship between formal and informal concepts.
 The dotted circle represents a set of problems to which a formal concept can potentially be applied.
 The black circle represents a set of problems to which a formal concept at the early stage of learning can actually be applied.
 The shadowed circle represents a set of problems to which an informal concept can be applied.
 gory, and to prevent them from being related to others, at least, at the early stage of learning.
 Problems of Variable Interpretation Some sorts of theorylike knowledge should be necessary to take into account the early competence and difficulties in learning.
 However, the radical theoryoriented approach leads us to the problem of incommensurability.
 Furthermore, it is highly dubious that one can keep informal concepts out in formal instruction, for the following reason.
 W h e n learning formal rules, learners are expected not only to memorize them but also to apply them to new situations.
 In order to do this, it is necessary for them to interpret variables in the rule.
 In other words, learners should specify what a variable refers to or what class a variable represents.
 W h e n applying a rule, learners also have to interpret information in a given problem and map it to corresponding variable in the rule.
 Thus, interpretation is a key to learning formal rules.
 Interpretation is especially crucial in learning physics rules.
 Unlike rules in logic, physics rules involve variables that must be interpreted as specific classes of entities in the world (Suzuki, 1994).
 A proper interpretation of variables requires full understanding of the domain.
 However, it is the end product of learning, not the prerequisite for it.
 Thus, learners sometimes give up the interpretation of variables.
 However, without interpretation, variables in the formal rule are mere "symbols" in the sense that they do not have any referents in the real world.
 In consequence, learners who do not interpret variables exhibit strong context specificity.
 They can apply the rule only to a very limited set of problems that are sufficiently similar to those used in the practice (diSessa, 1983; Reed, 1993).
 For example, most students can solve a? — b^, when they learn an algebraic such as x"̂  — y"̂  = (x t y){x — y).
 However, more than half of the students cannot solve 4x^ — y^.
 Even fewer students can solve x'̂  — y^ • This indicates that students interpret the variable x and y in the original formula as letters and the exponent as a mere superscript.
 What knowledge is responsible for interpretation if one does not have knowledge of the domain to be learned? One of the knowledge structures for interpretation should be our prior knowledge of the domain that has been acquired through everyday experience.
 Informal concepts, in contr2ist to formal ones, are "grounded," because they are originally developed to deal with real world problems.
 In describing pprims, diSessa (1993) characterized the nature of informal concepts.
 According to his description, "they are ready schemata in terms of which one sees and explains the world" (pp.
 112).
 Figure 1 illustrates the relationship between informal concepts, formal concepts, and the real world.
 Although the formal concept potentially has wide applicability (the dotted circle), it covers only a small subset of the real world problems (the black circle) at the early period of learning.
 In contrast, the informal concept has greater applicability compared with the formal counterpart at the initial stage of learning (the shadowed circle).
 If the formal concept is related to a corresponding informal concept, it acquires greater applicability to real world problems, because it can make use of the interface of informal concept to the real world.
 The theoryoriented approach has another problem, the status of informal concepts after instruction.
 If instruction proceeds without referring to the related informal concepts, it follows that two kinds of concepts coexist in learners' knowledge base.
 If so, it is highly likely that students are at a loss as to which concepts should be used.
 To make the matters worse, informal knowledge has been reinforced repeatedly, because it is used very often and gives approximately the right answer in many occasions (Holland et al.
, 1986).
 Consequently, 755 the informal knowledge is more likely to be triggered than the formal ones.
 Even when the use of the informal concepts is explicitly inhibited, students do not know why they have to use the formal concepts rather than informal ones.
 Such learning is far from proper understanding and appreciation of scientific concepts.
 Examining the utilities of theoretical constructs and clarifying the relationships between them are crucial parts of scientific activity.
 Utilizing Informal Concepts in F o r m a l Instruction The discussion above shows that informal concepts do and should affect the process of learning formal concepts, and that relating formal and informal concepts enables learners to achieve deeper understanding, and prevents them from the mechanical memorization.
 Actually, there are domains that children spontaneously use their informal concepts to predict the behaviors of unfamiliar things.
 Biology is a good example of it.
 A series of experiments conducted by Inagaki and Hatano showed that even young children can make use of prior knowledge about humans in making predictions about behaviors of other living things (Inagaki k Hatano, 1987, 1991).
 Additionally, they do not use the prior knowledge haphazardly.
 Their use is constrained by similarity of a living thing in question to humans.
 Another source of evidence comes from a series of studies by Cheng and her colleagues (Cheng, et al.
, 1986).
 In their previous study (Cheng & Holyoak, 1985), they revealed that people spontaneously acquire a schema that is functionally equivalent to the rules of conditional reasoning when problems involve permission conditions of someone's action.
 They used this schema as a base analog to teach the logical conditional and gave the Wason's selection tasks as a posttest.
 The result is that subjects' performance dramatically improved.
 However, one might argue that these are exceptional cases.
 In other domains, informal concepts cannot be used directly in formal instruction.
 There are at least two cases that should be distinguished.
 The first case is that although learners have relevant informal concepts, they fail to use them spontaneously.
 This will be discussed in the next section by analyzing students' informal knowledge of concentration.
 The second ceise is that useful informal concepts appear not to be available.
 This will be discussed in the third section, by investigating students' knowledge offeree decomposition.
 How to Activate Informal Knowledge: A Case from Mathematics A consistent finding in research on learning and instruction is that people have considerable difficulties in making use of prior knowledge in situations where it is relevant (Gick & Holyoak, 1980; Reed, 1993).
 In other words, human knowledge is so contextbound that it cannot be used in difi"erent contexts.
 I requested more than a hundred of sixth graders to solve the following problem: When lOOg of 5 0 % orange juice is mixed with 500g of 100% orange juice, what is the percentage of the mixed juice? Estimate the percentage.
 30% to 40% of them added the two concentration values.
 Moreover, about 8 0 % of the answers were higher than the pure orange juice (100%).
 According to the results, they appear not to understand nonadditivity of intensive quantities.
 The results seem to be in line with Chi's claim.
 Since concentration is a member of intensive quantity, it must not be added each other.
 However, students at this age are so familiar with extensive quantities (weight, length, etc.
) that they tend to assimilate concentration to this type of quantity, though concentration is a member of intensive quantity.
 However, a posttest interview showed that it is not always the case.
 After the experiment, I asked one student who had failed on the above problem whether she could make pure orange juice by mixing two cans of 5 0 % orange juice.
 Her answer was "absolutely not.
" This anecdote suggests that they might understand the nonadditivity principle, but that they could not apply the principle to the above problems.
 W h y could not they use it? It is often the case that two congruent knowledge structures originated from different experiences have distinct views for the world.
 By observing his daughter's calculation of multidigit subtraction, Lawler (1981) found that she had several microviews.
 Each microview involved a distinct view for problems and encoded information differently.
 For example, the money microview encoded 75 | 26 as four quarters and a penny, while the decadal microview decomposed the same problems as tens and ones.
 The same might be true for students' understanding of nonadditivity, because concentration is termed differently in the real world and classroom.
 For example, in everyday life, concentration is expressed by a qualitative term, such as sweeter, less sweet, salty or less salty.
 Concentration is expressed numerically in mathematics, on the other hand.
 If it is true, the everyday concept of concentration is likely to be triggered when such qualitative terms are used, rather than quantitative terms.
 In order to test this hypothesis, 35 sixth graders were examined in the following three conditions (Suzuki, 1987).
 In the mathematical condition, students were given juice mixing problems where concentrations were expressed numerically.
 The form of the problem was as follows: "When Xg of x % juice was mixed with Yg of y% juice, estimate the concentration of the resultant juice.
" Answers were judged to be correct when their estimates were between the concentrations of two original juices.
 This condition was expected to facilitate quantitative encoding of the concentrations.
 In the real condition, real juices were presented, but the problems had the same verbal form as in the mathematical condition.
 In the third condition, the qualitative condition, the problems had the following form: When very sweet tea with X spoonfuls of sugar was mixed with less sweet tea with Y spoonfuls of sugar, did the mixed tea get sweeter, less sweet or the same as the original? This condition was 756 Table 1: The number of the correct estimates on the juicemixing problems.
 Numbers in parentheses represent the proportions.
 Math Real Qualitative Equal (50%l50%) 9(25,7) 17(48.
6) 33(94.
3) Diffprenl (50%+100% 13(37.
1) 20(57.
1) 26(74,3) expected to encourage students to represent concentrations qualitatively.
 Two types of problems were used, E Q U A L and DIFF E R E N T .
 In the E Q U A L problems, two juices which had the same concentration values were used in the mathematical and real conditions.
 In the qualitative condition, two cups of tea with the same spoonfuls of sugar were used.
 While in the mathematical and real conditions 5 0 % and 100% orange juices were used as D I F F E R E N T problems, two cups of tea with different spoonfuls sugar were used in the qualitative condition.
 The results presented in Table 1 clearly show that sixth graders properly understood the nonadditivity principle.
 Whe n the form of the problems was modified so as to trigger their informal concept, the proportion of the correct estimates dramatically increased.
 Hence, their difficulties lie not in the lack of understanding but in the failure of applying their informal knowledge to problems with the mathematical form.
 These results show that the informal concept of nonadditivity is, at least, functionally equivalent to the formal counterparts and indicate that information that can be encoded is different between the two.
 It first appears that students assimilated the unfamiliar quantity into a wrong category.
 However, a careful analysis of the encoding mechanism revealed that students have informal knowledge functionally equivalent to the formal counterpart.
 Coordinating Fragments: A Case from Physics However, one might still argue that the above example is a lucky case, because entities in the informal concept of concentration can be translated directly to the formal one.
 In other domains such as physics, it is often impossible to find informal concepts that are directly mapped to the formal counterparts.
 For example, McCloskey and his colleagues showed that people sometimes predict the movement of a falling body correctly, against the notorious straightdown belief (McCloskey, et al.
, 1983).
 However, such a prediction is made only when the falling object moved autonomously before falling down.
 If the object is carried by something else, they cannot make the correct prediction.
 Since the autonomy of the movement has nothing to do with formal physics, it is impossible to find a formal concept that can be mapped to the informal one.
 The notion of "distributed encoding," proposed by diSessa, is useful to deal with such an incompatibility between formal and informal concepts (diSessa, 1993).
 He described that a physical law was distributed over many pprims which play some roles in understanding and using the law.
 This means that some components of a physics law are shared by one informal concept, and other components by other concepts.
 N o single informal concept corresponds to a physics law, but coordinating these concepts could promote proper understanding of physics laws.
 Suzuki (1990) explored this possibility.
 In his studies, students were required to answer the problem shown in Figure 2(a).
 This figure illustrates a situation where two individuals are trying to hold a 10kg bag.
 The question was how much force was required for an individual to keep the bag held.
 To solve this problem, one must decompose the downward vector into two along with the strings.
 One way to decompose it is to construct a parallelogram whose diagonal line is a reverse vector of the downward one (as shown in Figure 2(b)).
 While this procedure is rather simple, it sometimes produces incredible results.
 W h e n the angle of two strings is 120 degree, the force required for an individual is as much as the downward force.
 It means that each individual has to exert lOkg force to keep the 10kg bag held.
 The reason is that two men are pulling against each other as well as holding the bag.
 In other words, horizontal vectors are involved in holding the bag.
 A preliminary study revealed that force decomposition problems were quite difficult even for university students.
 More than 80 % of students' estimates were less than 10kg (mostly, 6 to 8kg).
 To investigate sources of their difficulty, we conducted three instructional experiments.
 The first experiment examined a possibility that students merely forgot the rule of force decomposition or they could not realize the applicability of the force decomposition rule to the above problem.
 Thus, we explained the notion of force decomposition and taught the parallelogram construction method, by using an example problem.
 The second experiment explored a possibility that students' difficulty lies in their ignorance of conceptual cispects of force decomposition, that is, the angle dependency.
 Thus, we emphasized that the amount of the horizontal force was dependent on the angle along which the downward force was decomposed, by using multiple examples.
 In the third experiment, we taught subjects the procedures of parallelogram construction in a stepbystep way and gave three example problems to facilitate proceduralization of the rule.
 However, none of the instruction facilitate subjects' performance, as shown in Table 2.
 They usually neglected the existence of horizontal forces and simply divided downward force by the number of holders, then used the anchoring strategy to adjust their judgments.
 However, it is not always the case.
 Another study revealed that students could attend to the horizontal forces when force decomposition was instantiated in a ropepulling contest situation.
 Most of the students' answers exceeded the weight of the object to be held.
 757 o o o (a) (b) Figure 2: (a) The problem used in the experiment.
 This figure illustrates that two men are trying to keep a 10kg bag held, whose two straps construct an angle of 150 degree.
 Subjects were required to estimate how much force is required for an individual, (b) The figure illustrates the parallelogram construction method for the decomposition of force.
 Table 2: The results of the three instructional experiments.
 The first column represents subjects' estimates of the required force (X) for an individual.
 X < 5kg X = 5kg 5kg < X < 10kg X > 10kg Exp.
 1 Reminding 4.
4 14.
8 58.
8 22.
1 Exp.
 2 Angle Dependency 14.
9 12.
8 51.
1 21.
3 Exp.
 3 Proceduralization 4.
3 47.
8 22.
8 25.
0 These results show that people have two schemas concerning force decomposition.
 One of them, the collaboration schema, encodes vertical forces and the number of agents (holders) and computes required forces, by dividing the former by the latter.
 This schema generates estimate of required force that is less than the weight of the object being held.
 Another, the competition schema, mainly encodes horizontal forces and computes relatively greater amount of forces.
 The results also indicate a possibility that informal concepts are fragmentary and that the components of the formal concept of force decomposition are distributed in two schemas.
 If so, it is expected that by coordinating two schemas (fragments), students could realize the existence of horizontal and vertical forces and understand the formal concept of force decomposition.
 In order to enhance students' coordination of the two schemas, we explicitly mentioned the presence of two kinds of forces.
 First, by showing a figure of a ropepulling situation, subjects were told that horizontal forces were present because two individuals were pulling against each other.
 Next, subjects were asked to notice the fact that the these two were holding a 2kg object, and were told that vertical force exists because of their holding the object.
 Finally, the force decomposition rule, the parallelogram construction method, was introduced so that two kinds of forces were composed.
 The results showed that the proportion of the correct estimates was more than 50%.
 In contrast, that of the control group who had not been given such instruction was only 8%.
 These results indicate that fragments of understanding can be organized into coherent one by providing subjects with a situation where both the fragments are involved.
 The encoding of the force decomposition rule here seems to be distributed across the competition and collaboration schemas (diSessa, 1993).
 Discussion The theoryoriented approach provides a new perspective for the study of learning and cognitive development.
 It has revealed that children's knowledge constitutes a coherent system which provides efficient constraints in learning in informationally problematic environments.
 However, its instructional application, especially when the incommensurability is emphasized, is not very much attractive and in a sense wrong.
 It is not attractive because this approach explains theory change only in terms of the replacement of an old theory with a new one.
 Thus, the issue of reorganization of knowledge remains intact.
 It is in a sense wrong because this approach misses what is shared between formal and informal concepts.
 It also misses the roles that informal concepts play in understanding and applying formal ones.
 The results of the experiments revealed that informal concepts can be building blocks for understanding and applying formal concepts.
 Furthermore, it provides useful techniques for teachers to teach formal concepts, without isolating them.
 Bridging informal concepts to formal ones Sometimes it is difficult for students to use their informal concepts in classroom problem solving contexts.
 It is 758 because the encoding functions are different between the two types of concepts.
 As shown in the experiment, the informal knowledge of the nonadditivity principle articulates the world (|ualitatively.
 If a problem involved qualitative lerins, the informal knowledge was likely to be triggered and gave approximately the right answer.
 However, when concentration values were presented numerically, the knowledge was less likely to be activated.
 In this case, teachers can help students by translating quantitative terms to qualitative ones.
 For example, it might be helpful to tell students that 100% juice is thicker than 5 0 % juice.
 Although it is less likely that the informal concept enables students to invent the proper mathematical solution, it monitors the problemsolving processes and the solution by constraining the possible combination of mathematical operations (Suzuki, 1987).
 More generally, educators as well as researchers should be very careful in analyzing students' errors.
 Their erroneous answers do not always reflect lack of understanding.
 Rather, these answers may be generated by a sort of repair heuristics triggered when their informal knowledge can not encode the information in a given problem.
 Knowledge spontaneously acquired through everyday experience often has diff"erent encoding functions from those of formal concepts.
 Coordinating fragmentary understandings Informal concepts are sometimes fragmentary, and components of a formal concept are distributed across different informal concepts.
 As shown in the experiments on force decomposition, the collaboration schema encodes the vertical force and divides it by the number of agents.
 However, this schema cannot deal with horizontal forces.
 On the other hand, the competition schema encodes the horizontal forces, but cannot encode and process the vertical force.
 In these cases, it is necessary for teachers to look for or devise a situation in which fragmentary understandings are naturally involved.
 Then, they can explain which components of the informal knowledge are relevant for which aspects of the situation, by emphasizing the examination of the situation from multiple perspectives.
 This technique can be regarded as an instructional application of diSessa's "KnowledgeinPeace" theory.
 While emphasizing to view a situation from multiple perspectives changes the cuing priorities of the two schemas, presenting the formal concept in terms of two schemas leads its distributed encoding.
 References Carey, S.
 (1985) Conceptual Change in Childhood.
 Cambridge, MIT.
 Cheng, P W.
, & Holyoak, K.
 J.
 (1985) Pragmatic reasoning schemas.
 Cognitive Psychology,17, 391416.
 Cheng, P.
 W.
,Holyoak, K.
 J.
, Nisbett, R.
 E.
,& Oliver, L.
 M.
 (1986) Pragmatic versus syntactic approaches to training deductive reasoning.
 Cognitive Psychology, 18, 293328.
 Chi, M.
 T.
 H (1993) Barriers to conceptual change in learning science concepts: A theoretical conjecture.
 Proceedings of the Fifteenth Annual Conference of Cognitive Science Society.
 diSessa, A.
 (1983) Unlearning Aristotelian physics: A Study of knowledgebased learning, Cognitive Science, 6, 3375.
 disessa diSessa, A.
 (1993) Toward an epistemology of physics.
 Cognition & Instruction, 10, 105227.
 Gick, M.
 L.
 k Holyoak, K.
 J.
 (1980) Analogical problem solving.
 Cognitive Psychology, 12, 306355.
 Holland, J.
 H.
, Holyoak, K.
 J.
, Nisbett, R.
 E.
, & Thagard, P.
 R.
 1986 Induction: Processes of Inference, Learning, and Discovery.
 Cambridge, M A : M I T Press Inagaki, K.
 &: Hatano, G.
 (1987) Young children's spontaneous personification as analogy.
 Child Development, 58,10131020.
 Inagaki, K.
 & Hatano, G.
 (1991) Constrained person analogy in young children's biological inference.
 Cognitive Development, 6, 219231.
 Lawler, R.
 W .
 (1981) The progressive construction of mind.
 Cognitive Science, 5, 130.
 McCloskey, M.
, Washburn, A.
, k Felch, L.
 (1983) Intuitive physics: The straightdown beliefs and its origin.
 Journal of Experimental Psychology: Learning, M e m ory, and Cognition, 9, 636649.
 Reed, S.
 K.
 (1993) A schemabased theory of transfer.
 In D.
 K.
 Detterman & R.
 J.
 Sternberg (Eds.
) Transfer on Trial.
 Norwood, NJ: Ablex.
 Suzuki, H.
 (1987) The roles of formal and informal knowledge in mathematical problemsolving.
 Paper presented at ninth biennial meetings of the International Society for the Study of Behavioural Development.
 July, Tokyo Suzuki, H.
 (1990) Pragmaticallybased representation as a source of naive concepts in physics.
 Paper presented at the Symposium on "Use of students' informal knowledge cis the basis of instruction" at 22nd International Congress of Applied Psychology, Kyoto, July.
 Suzuki, H.
 (1994) The centrality of analogy in knowledge acquisition in instructional contexts.
 H u m a n Development, 37, 207219.
 Wellman, H.
 M.
 k Gelman, S.
 A.
 (1992).
 Cognitive development: Foundational theories of core domains.
 Annual Review of Psychology, 43, 337375.
 Wiser, M.
 k Carey, S.
 (1983) W h e n heat and temperature were one.
 In D.
 Gentner k A.
 L.
 Stevens (Eds.
) Mental Models.
 Hillsdale, NJ: Erlbaum.
 759 Representing the bilingual's two lexicons.
 Michael S.
C.
 Thomas Department of Experimental Psychology.
 University of Oxford, South Parks Road, Oxford OXl 3UD.
 UK.
 inichael.
 thomas@psy.
 ox.
 ac .
 uk Kim Plunkett Department of Experimental Psychology, University of Oxford, South Parks Road, Oxford O X l 3 U D .
 UK.
 plunkettOpsy.
ox.
ac.
uk Abstract A review of empirical work suggests that the lexical representations of a bilingual's two languages are independent (Smith, 1991), but may also be sensitive to between language similarity patterns (e.
g.
 Cristoffanini, Kirsner, and Mi lech, 1986).
 Some researchers hold that infant bilinguals do not initially differentiate between their two languages (e.
g.
 Redlinger & Park, 1980).
 Yet by the age of two they appear to have acquired separate linguistic systems for each language (Lanza, 1992).
 This paper explores the hypothesis that the separation of lexical representations in biUnguals is a functional rather than an architectural one.
 It suggests that the separation may be driven by differences in the structure of the input to a common architectural system.
 Connectionist simulations are presented modelling the representation of two sets of lexical information.
 These simulations explore the conditions required to create functionally independent lexical representations in a single neural network.
 It is shown that a single network may acquire a second language after learning a first (avoiding the traditional problem of catastrophic interference in these networks).
 Further it is shown that in a single network, the functional independence of representations is dependent on interlanguage similarity patterns.
 The latter finding is difficult to account for in a model that postulates architecturally separate lexical representations.
 Introduction Studies involving children learning two languages indicate that even as young as two years old they are aware that there are two distinct languages present in the linguistically mixed environment to which they are exposed.
 These children acquire two separate language systems, and can be observed to switch between the use of their two languages in a coherent fashion, depending on the linguistic context negotiated with their parents (Lanza, 1992).
 Adult bilinguals show a high degree of skill in using either of their integrated language systems, appearing to be able to set aside one of their systems while operating in the other.
 The impression in both of these cases is of functionally separate language systems.
 Research in the language processing of adult bilinguals has investigated h o w the bilingual's two language systems m a y be represented in his or her cognitive system.
 There are several theories as to the relation of the two systems, but the majority view is that there are separate lexical representations for each language, but combined semantic representations (see Smith, 1991, for a review).
 The evidence for this view comes mainly from repetition and semantic priming effects.
 Repetition priming effects are obtained from tasks such as lexical decision, word fragment completion, and perceptual identification.
 Semantic priming effects come mainly from recall performance and classification tasks.
 Conclusions are based on the assumption that if one task serves as a prime for a second, then it is accessing the same underlying representation.
 Although findings are mixed, suggesting a sensitivity to experimental conditions and task design (Durgunoglu and Roediger, 1987), it appears that tasks which access semantic representations allow priming between the bilingual's two languages (e.
g.
 Caramazza and Brones, 1980; Kolers and Gonzalez, 1980; MacLeod, 1976), but those that access lexical information alone allow only priming within each language (e.
g.
 Scarborough, Gerard, and Cortese, 1984; Watkins and Peynircioglu, 1983).
 For example, in the case of a FrenchEnglish bilingual, if in some task.
 M e n were followed by dog, the response time to dog would be reduced if the task involved, say, semantic classification, but not if it involved, say, lexical decision.
 There is also evidence to suggest that word similarity plays a role in bilingual lexical processing.
 For example, if a word exists in both languages (such as pain in French and English) or is morphologically similar in each language, between language priming effects have been found (Cristoffanini, Kirsner, and Milech, 1986; Gerard and Scarborough, 1989; Kerkman, 1984).
 Between language interference at the lexical level has been found for words that are legal in both languages but not for those that have characteristics unique to each language (Grainger and Beauvillain, 1987).
 This evidence implies that the lexical representations of each language m a y not be as distinct as previously thought.
 In this paper, w e will explore the hypothesis that bilingual lexical representation is best accounted for using a model that stores both languages in a single network.
 Recent work within the connectionist framework has shown that a functional separation in psycholinguistic processing need not be taken to imply separation at the level 760 of mechanism (Rumelhart and McClelland, 1986; Plunkett and Marchman, 1993).
 Here, w e examine the possibility that, for bilinguals, the description of their overall language system as having two lexicons may merely be a functional one, and that the evidence to date need not necessarily imply the existence of two physically separate structures.
 W e will show that: 1.
 T w o sets of lexical information can be stored in the same network, even when training on the second set follows that on the first (modelling the case of second language acquisition).
 2.
 Second language learning in a single network device can be achieved without catastrophic interference from the second language.
 3.
 The network is sensitive to the similarity of words in the two languages.
 Words that are dissimilar show more functional independence than those that are similar.
 Learning two lexicons in a single network.
 The independence of the representations underlying lexical processing implies that there is no interference between these representations.
 Learning independent representations is easily achieved in a neural network by training on simultaneously presented orthogonal languages (i.
e.
 those which have no features in common).
 However in the case of second language learning, where exposure to the second language occurs only after the first has been learned, neural networks experience the problem of CatasUophic Interference (CI).
 If training on one set of patterns ceases and training on another inconsistent set commences, information about the first set may be overwritten.
 This disruption occurs since the same connection weights are required to do a different job in learning the mappings for each pattern set.
 With simultaneous training, the network has the opportunity to find a set of weights that can do both jobs.
 But with sequential training, the connections responsible for learning the first set are changed so that they can learn the second, and this may damage the network's performance on the first set.
 In terms of lexical representation, CI would translate into a second language learner overwriting their first language with their second, which clearly does not happen.
 Standard solutions to CI have involved orthogonalizing the representations for each input/output mapping, so that they no longer use the same connections.
 Each new mapping can be learned separately without disrupting any that have been learned before (see Sharkey & Sharkey, 1994, for a review of these techniques).
 However, such solutions cannot be learned using a standard backpropagation network, and more seriously, the ability of these networks to generalize between patterns is lost.
 It is important to retain the generalization between patterns if w e are to capture the empirical data on lexical processing.
 W e require another solution to CI that preserves generalization within lexicons but not between them.
 A Dual Route Model.
 Within lexicon generalization would be easy to achieve in a dual route model.
 A separate network would be devoted to the representation of each lexicon.
 Generalization would occur within each route, but since the routes were physically separated, no generalization would take place between the lexicons.
 A simple dual route model, however, fails to capture important characteristics of the data, namely that interlanguage similarity is significant in establishing the independence of the representations.
 Furthermore, ftom the perspective of bilingual acquisition, no account is provided of how the child discovers that there are two languages in its linguistic environment and hence determines the need for a dualroute representation.
 Many researchers hold that infant bilinguals do not initially differentiate the two languages (e.
g.
 Redlinger and Park, 1980; Vihman, 1985).
 The onesystem view of bilingual development supposes that the bilingual child must undergo a process of language differentiation through which two separate linguistic systems are gradually formed.
 If a child is to assign two routes to its system at a point when it detects that there are two languages present, it would need have some firm basis on which to make such a judgement.
 The child should not, for instance, assign two routes to its system merely because its parents have different accents, or slightly different vocabularies.
 Yet it must, if they are using different languages.
 Identifying the presence of two (or for that matter three) languages is not a trivial matter, especially if they are closely related.
 The decision to construct multiple lexical representations would, therefore, appear to be contingent upon a careful analysis of the characteristics of the ambient linguistic environment.
 The onesystem view of bilingual development could, on the other hand, be taken to suggest that the child starts out with a single mechanism underlying its language learning, but that this mechanism develops representations which come to exhibit functional independence.
 A Single Route Model.
 A single route model of bilingual and lexical representation would suppose that a single mechanism underlies lexical processing in both children and adults.
 In the child, a single route model need make no assumptions about differentiation of the two languages at the onset of learning.
 Initially, the languages are treated in an identical fashion and are only differentiated by learning the pattern of characteristics unique to each language.
 This suggests that the separation of representations may be driven by differences in the structure of the input to a c o m m o n architectural system.
 In the adult, the bilingual lexicons may have achieved a status of functional modularity within the single mechanism though residual patterns of interference between the two languages may be observed for items that are similar in both linguistic systems.
 The issue as to whether single or dual mechanisms are involved in bilingual language processing is not merely a 761 theoretical nicety.
 Each account has different implications for our understanding of how languages are learned and for the patterns of errors and mastery observed en route to the mature adult system.
 Even in the mature adult state, residual traces of the moulding forces of development can still be observed and used to reconstruct that process.
 Simulations.
 Two simulations are presented in this paper.
 The first simulation demonstrates that a single network can store information about two separate lexicons even when training on the second lexicon follows that on the first.
 In effect, this simulation offers a solution to the problem of CI between distinct training sets in a network, while maintaining the desirable property of generalization within a training set.
 The solution requires no domain specific modifications to the backpropagation algorithm.
 The second simulation addresses the problem of simultaneous acquisition of two partially overlapping lexical systems.
 It demonstrates how the functional independence of lexical items depends on their interlanguage similarity.
 It is argued that these results offer a plausible simulation of patterns of lexical priming in adult bilinguals and language differentiation in the language learner.
 Architecture.
 The simulations used 3layer feedforward networks, trained using the backpropagation algorithm.
 The networks were set the task of autoencoding two sets of languagelike information.
 In the autoencoding task, a network usually has fewer hidden units than input or output units.
 This hidden unit 'botdeneck' forces the network to create a more efficient representation of the sets of input patterns by removing unnecessary redundancies.
 If the network is required to learn two input sets, it must therefore discover the features that characterize both those input sets.
 IVaining sets.
 T w o sets of items were constructed for each simulation, corresponding to the lexical representations of simple words in different languages.
 The input sets were constructed using orthogonal representations for the encoding of individual lexical constituents.
 This form of representation provided a stringent method for controlling word similarity in each pair of languages.
 The orthogonal word constituents can be thought of as corresponding to either letters or phonemes.
 Each language was defined in terms of its own set of orthographic/phonological rules.
 The constituents were classified as consonants or vowels.
 Only certain combinations of consonants and vowels were permissible in each language.
 These rules were then used to generate tokens in the language.
 The words were 3 letters/phonemes long with a choice of 10 letters/phonemes in each position.
 Since we used an orthogonal representation for the letters/phonemes, the network required 30 input and output units to code the lexical information.
 Language Specific Units.
 Bilinguals can selectively access information about either of their two languages.
 If two languages are to be stored in a single network, information specifying language membership must therefore be associated with each item.
 W e can think of each item as being lagged for membership in a language on the basis of language specific features available to the language learner.
 For example, in spoken French there is a tendency to nasalize phonemes, and Chinese is a tonal language.
 The information which distinguishes the two languages is presented to the network on an extra set of Language Specific Input Units.
 Since the task is autoencoding, there is a corresponding set of output units.
 T w o orthogonal vectors are used to represent this information.
 For example, if there were two Language Specific Units, a vector of (1, 0) might index one language, and a vector of (0, 1) the other.
 Figure 1 shows the network architecture.
 Word Output Units Language Specific Units Hidden Units f Word Input Units Language Specific Units j V y Figure 1: Network Architecture.
 Simulation 1.
 Modelling second language acquisition in a single network demands that w e avoid disruption of the performance on the first input set by training on the second.
 This disruption is maximized when no information learned during training on the first set is useful in learning the second set.
 There is no advantage for the network to retain information about the first input set, so the connections are changed maximally to learn the second set.
 Simulation 1 explored the effect of varying the amount of language tagging information available to the network.
 This manipulation provided the opportunity to evaluate the relative success of second language acquisition under conditions where interlanguage differences could be easily quantified.
 To model the hardest case for second language acquisition, two languages were constructed which were based on the same orthographic/phonological rules but which used different letters/phonemes.
 Each language comprised 32 words.
 The rules and alphabets used are shown in Figure 2.
 The network had the architecture shown in Figure 1, with 20 hidden units used to enforce the representational bottleneck.
 The network was trained to autoassociate the words in LI.
 W h e n the error asymptoted, training on LI ceased, and training on L2 commenced.
 The mean squared error on the Word Output Units (see Figure 1) was measured for each language 762 2 Language Specific Units 16 Language Specific Units 30 Language Specific Units 60 Language Specific Units 0.
3n o fc UJ £ (0 3 cr «0.
1a> 0 0.
3n 0.
20.
3 n "I )"'•• 0 0.
10.
3n 0.
20.
1, j ^ 0 1—'—I • I—'—I—' I 200 400 600 800 1000 1—'—I—'—I—'—r 200 400 600 8001000 0 200 400 600 8001000 0 200 400 600 800 1000 Epochs of Learning Epochs of Learning Epochs of Learning Epochs of Learning (a) (b) (c) (d) Figure 3: Graphs a) to d) show the eUmination of Catastrophic Interference as the number of Language Specific Units is increased throughout this process.
 Simulations were repeated at four levels of language specific tagging, namely where the number of units tagging each language was 7, 8, 15, and 30.
 LI: L2: Alphabet: Alphabet: Vowels: o, i.
 Vowels: a, e.
 Consonants: f, p, g.
 Consonants: b, t, c Rules: CVV, CVC, VCV, V V C Figure 2: Languages used in Simulation 1.
 Results.
 The resulting learning profiles are shown in Figure 3a) to d).
 Each figure plots the mean squared error on the Word Output Units for all items in a training set, with the error for each language plotted separately.
 Figure 3a) shows the error for each language when the number of language separating units is set to two.
 LI improves in performance until it is virtually error free.
 W h e n training on the first language ceases and the second language is introduced (after 500 epochs of learning), the error on LI increases while that on L2 gradually disappears.
 In other words w e observe catastrophic interference from L2 on LI.
 However, as the number of language specific units is increased, as shown in Figure 3b) to Figure 3d), there is a decreasing level of catastrophic interference fiom L 2 on LI during the second phase of training.
 By the time the number of language specific units reaches 30 per language, the catastrophic interference has disappeared.
 Discussion.
 These results show that a single network can learn two lexicons when training on the second follows that on the first, provided there is sufficient language specific information to separate the languages.
 Increasing the amount of language specific information eliminates catastrophic interference because it allows the backpropagation algorithm greater scope to develop orthogonal internal representations for each language.
 The language specific information that tags language membership biases the network's interpretation of the input sets so that the representations it forms for each are quite different.
 Since these representations are different, the weights from which they emerge tend to be different: training on L 2 no longer tends to change weights that contain information about LI.
 If one imagines the network defining a representational space, then the bias that the language specific information provides allows the network to partition this space and place each language in a different partition.
 Although the representational resources to avoid catastrophic interference are costly, there is little evidence to suggest that the neural substrate for language acquisition is a limiting factor.
 For example, there is evidence that children have up to 5 0 % more brain cell connections than adults (Collins &Kuczaj, 1991, p.
50).
 The simulation outlined here depicts the most extreme case of second language acquisition, where learning the second language occurs without any further exposure to the first language.
 Second language acquisition occurs more often in the context of continued first language usage, serving as additional language exposure rather than as a replacement.
 This simulation shows that catastrophic interference is avoidable in the most extreme case.
 The more usual case would be easier for the network to solve, since input sets would be trained with an element of simultaneity.
 The simulation does not, however, offer us the opportunity to examine the role of interlanguage similarity in bilingual language processing, since by design there is no similarity between the languages at all.
 This was the goal of the next simulation.
 Simulation 2.
 This simulation demonstrates two points.
 Firstly, similarity is important in establishing the independence of lexical representations in a single network.
 Secondly, as well as simulating data difficult to account for in the simple dual route approach, a single network simulates human data previously taken as strong evidence of separate lexical representations.
 Similarity Effects.
 T w o languages were constructed which shared the same letters/phonemes and 3 out of 4 orthographic/phonological 763 rules.
 T h e rules are shown in Figure 4.
 Words in each language could be categorized into three classes in the following way: (1) Those that exist in both languages.
 (2) Those that are legal in both languages but exist in only one language.
 (3) Those that exist and are legal in only one language.
 Examples taken from French and English fulfilling these criteria are (1) pain & pain, (2) trop & time, and (3) soeur & cough respectively.
 The word classes were constructed to reflect a similarity gradient between the languages.
 Each language comprised 78 words.
 The network was trained on both languages simultaneously.
 To reflect the greater similarity of the languages, only eight units were used to code the language specific information.
 In order to store the greater number of patterns, 45 hidden units were used'.
 Alphabet:Vowels: a, e, i, o, u.
 Consonants: s, t, b, g, p.
 LI Rules: L 2 Rules: c w , cvc, vcv, w c .
 cvv, cvc, vcc, w c .
 High frequency: 4 duplications in the input set.
 L o w frequency: 1 token in the input set.
 Figure 4: Languages used in Simulation 2.
 Results.
 Figure 5a) summarizes h o w the network represents words from the three classes outlined above.
 T h e hidden unit activation obtained w h e n a word is presented to the network m a y be thought of as a point in representational space.
 For each class, the hidden unit activations for all the words in that class were averaged together to define its 'centre of gravity' in representational space.
 This graph shows the distance between the centres of gravity for the same classes in each language.
 It shows that words that exist in both languages (Class 1) are closest together in this space.
 Words that exist and are legal in only one language (Class 3) are 10.
5_1.
2 s i0,8• 0.
6 Q Single Class 1 Class 2 Class 3 Word Class (a) High Low Frequency (b) Figure 5: a) Distance between W o r d Classes; b) Class 1: Error by frequency 1.
 Other simulations indicated that increasing the number of hidden units actually served to partition the representational space less adequately.
 Greater numbers of hidden units led to the languages being less separated in this space, and thus less independent.
 furthest apart.
 Words that exist in one language but are legal in the other (Class 2) represent an intermediate case.
 Discussion.
 Studies that have investigated bilingual lexical representation (and the importance of similarity in processing) have used priming paradigms.
 In the context of the network models employed here, priming m a y be thought of as activation persisting in a network.
 T he more similar the activation is between two words, the more likely it is that activation persisting from processing one word will facilitate processing of the next word, and therefore serve as a prime for the next word.
 The distance between two points in representational space is a measure of the similarity of two patterns of activation.
 Figure 5a) can therefore be interpreted as a measure of the degree to which words within a class will prime words in the same class in the other language.
 Recall that in experiments using the lexical decision task, priming between languages was found for words that existed in both languages, i.
e.
 Class 1 words (e.
g.
 Gerard and Scarborough, 1989).
 Cristoffanini et al (1986) found between language priming to a slightly lesser degree for morphologically similar but not identical words, corresponding to Class 2 words.
 Scarborough et al (1984) found no priming for orthographically distinct translation equivalents, corresponding roughly to Class 3 words.
 This simulation shows that the similarity gradient in the input between the languages translates into the functional independence of the representations.
 Frequency Effects.
 Words in Class 1 m a y have a different meaning in each language (for example pain means bread in French).
 In such cases, it is likely that the same lexical item will have a different frequency in each language.
 Using such words, Gerard and Scarborough (1989) showed that SpanishEnglish bilinguals responded in a lexical decision task according to the within language frequency.
 They interpreted this evidence as favouring the view that the lexical representations for each were independent.
 T o examine this issue in the model, words were defined as having a high or low frequency.
 High frequency words were presented to the network four times as often during training.
 For the words existing in both languages, half were high frequency in LI and low frequency in L 2 , the other half high frequency in L 2 and low frequency in LI.
 In networks modelling lexical representation, it has been shown that the error score which results w h e n a word is presented to a network m a y in some circumstances be interpreted as equivalent to a subject's reaction time in the lexical decision task (Seidenberg and McClelland, 1989).
 In this part of the simulation, w e examined the error score for words in Class 1 in both languages.
 A n additional simulation was performed in an attempt to control for absolute levels of error score separating high frequency and low frequency words.
 This control 764 involved training each language on a separate network with 30 input and output units and 22 hidden units.
 Results & Discussion.
 Figure 5b) shows the mean squared error when the network was tested on the Class 1 words, split by frequency.
 Since both languages show the same pattern of results, we depict the error scores for both languages averaged together.
 The results from the control simulation are shown on the same graph.
 This figure shows that performance on these words varies with within language frequency.
 Lower error scores are observed for high frequency words, even though these words have the same form and are stored in the same network.
 There is only a small difference between the error scores for the single and separate network solutions.
 W e interpret the lower error scores for high frequency words as indicating faster response times to high frequency words than low frequency words.
 Hence within language frequency effects can be observed even when both languages are represented in the same device.
 Conclusions.
 In this paper, we have offered a solution to the logical problem of how a child can simultaneously acquire two languages without the need for innate assumptions concerning the cognitive architecture required to represent these languages, yet as adults show behavior suggesting separate routes for the processing of lexical information in each language.
 Evidence for independent lexical representations may be taken as a functional description of the behavior of a single mechanism.
 Furthermore, second language acquisition can be achieved in a single network whilst avoiding the potential problem of catastrophic interference.
 Importantly, the single network model can account for data that a simple dual route model cannot account for, namely the role of similarity in lexical processing, and can also simulate sensitivity to within language frequency—a finding that has previously been taken as strong evidence for separate lexical representations in bilinguals.
 Acknowledgements The work in the paper is supported in part by a BBSRC grant.
 W e are grateful to Sharon McHale, Denis Mareschal, Neil Forester, and Chrys Meula.
 References Caramazza, A.
 & Brones, I.
 (1980).
 Semantic classification by bilinguals.
 Canadian Journal of Psychology, 34, 7781.
 Collins, W.
 A.
 & Kuczaj, S.
 A.
 (1991).
 Developmental Psychology: Childhood and Adolescence.
 Macmillan: New York.
 Cristoffanini, R, Kirsner, K.
, & Milech, D.
 (1986) Bilingual lexical representation: The status of cognates.
 Quarterly Journal of Experimental Psychology, 38A, 367394.
 Durgunoglu, A.
 Y.
 & Roediger, H.
 L.
 (1987).
 Test differences in accessing bilingual memory.
 Journal of Memory and Language.
 26, 377391.
 Grainger, J.
 & Beauvillain, C.
 (1987).
 Language blocking and lexical access in bilinguals.
 Quarterly Journal of Experimental Psychology, 39A, 295319.
 Kerkman, J.
 P.
 M.
 (1984).
 Word recognition in two languages.
 In A.
 Homassen, L.
 Noordman, & P.
 Eling (Eds.
), The Reading Process.
 Lisse: Swets Zeitlinger.
 Kolers, P.
 A.
 & Gonzalez, E.
 (1980).
 Memory for words, synonyms and translations.
 Journal of Experimental Psychology: Human Learning and Memory, 6, 5365.
 Lanza, E.
 (1992).
 Can bilingual twoyearolds codeswitch? Journal of Child Language, 19, 633658.
 MacLeod, C.
 M.
 (1976).
 Bilingual episodic memory: Acquisition and forgetting.
 Journal of Verbal Learning and Verbal Behavior, 15, 3^12>U.
 Plunkett, K.
R.
 & Marchman, V.
 (1993).
 From rote learning to system building: acquiring verb morphology in children and connectionist nets.
 Cognition, 48, 149.
 Rumelhart, D.
E.
 & McClelland, J.
L.
 (1986).
 On learning the past tense of English verbs, in McClelland, J.
L.
, Rumelhart, D.
E.
, and the PDP Research Group (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol.
2, (Ch.
21).
 MIT Press.
 Redlinger, W.
 & Park, T.
 Z.
 (1980).
 Language mixing in young bilingual children.
 Journal of Child Language, 7, 337352.
 Scarborough, D.
 L.
, Gerard, L.
, & Cortese C.
 (1984).
 Independence of lexical access in bilingual word recognition.
 Journal of Verbal Learning and Verbal Behavior, 23, 8499.
 Seidenberg M.
 S.
 & McClelland, J.
 L.
 (1989).
 A distributed, developmental model of word recognition and naming.
 Psychological Review, 96.
 523568.
 Sharkey, N.
E.
 & Sharkey, A.
J.
C.
 (1994).
 Understanding Catastrophic Interference in Neural Nets.
 (Technical Report).
 Department of Computer Science, University of Sheffield, U.
K.
 Smith, M.
 (1991) On the recruitment of semantic information for word fragment completion: evidence from bilingual priming.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 17, 234244.
 Vihman, M.
 (1985).
 Language differentiation by the bilingual iniani.
 Journal of Child Language, 12, 297324.
 Watkins, M.
 J.
 & Peynircioglu, Z.
 F.
 (1983).
 On the nature of word recall: Evidence of linguistic specificity.
 Journal of Verbal Learning and Verbal Behavior, 22, 385394.
 765 Gestalt Principles and Parallel Constraint Satisfaction Processes: T h e Parallels Eric J.
 Vanman Department of Psychology University of Southern California Los Angeles, CA 900891061 vanman@usc.
edu Stephen J.
 Read Department of Psychology University of Southern California Los Angeles, CA 900891061 read@almaak.
use.
edu Lynn C.
 Miller CAAS University of Southern California Los Angeles, C A 900891694 lmiller@uscvin Abstract This paper examines the tremendous similarities between the Parallel Constraint Satisfaction Processes that are a central part of many connectionist models and the Gestalt principles that played a central role in the history of Psychology.
 Gestalt Psychology played a major role in a number of areas in psychology, such as perception, reasoning and problem solving, causal reasoning, and many key aspects of social psychology, such as social perception, group interaction, and belief consistency.
 Many of the key assumptions of Gestalt Psychology have resurfaced in recent connectionist models.
 W e propose that Parallel Constraint Satisfaction Processes provide a computational implementation of many of the central principles of Gestalt Psychology.
 In this paper we discuss the clear parallels between each of five key assumptions of Gestalt Psychology and aspects of Parallel Constraint Satisfaction Processes.
 The five assumptions we examine are: (1) psychological processing can be treated as interactions in fields of forces, (2) psychological processing is holistic, (3) the whole is greater than the sum its parts, (4) the importance of the structure of cognitive elements; how things are connected and related, and (5) the emphasis on cognitive dynamics, and such concepts as change, equilibrium, and tension.
 Introduction The historical contributions of gestalt psychology to the foundations of social psychology, cognitive psychology, and especially, perception, are well known.
 Koffka, KOhler, and Wertheimer influenced psychology not only directly through their seminal theory and research, but also through the training of others w h o made significant contributions to different areas of psychology.
 For example, the names of Asch, Lewin, Heider, and Festtnger are well known to the social psychologist when discussing such concepts as dissonance, balance, and person perception.
 Gestalt principles were central to each.
 Yet, despite their historical and theoretical importemce, Gestalt principles are largely absent from most current psychological theorizing.
 W h y ? Gestalt processes stressed holistic processing and interactions among fields of psychological forces.
 Such concepts m a y have struck many as too metaphoric and mystical.
 A second difficulty was simply grappling with the overwhehning richness and complexity of interaction implied by basic Gestalt principles.
 Individuals must integrate large amounts of information in a short time, while concurrently planning, enacting, and monitoring their own behavior.
 Initial attempts to address this complexity can be found in Gestalt theorizing.
 Gestah processes provided a mechanism by which multiple interacting pieces of information could be integrated within a narrow time.
 But, capturing such dynamics m a y have seemed beyond the reach of the empirical and theoretical tools of the day.
 However, recent work in connectionism, specifically parallel constraint satisfaction models, suggests that seemingly metaphorical Gestalt processes can be given a concrete implementation (Spelhnan & Holy oak, 1992).
 In this paper, w e first briefly discuss the general concept of parallel constraint satisfaction processes.
 W e follow this with an analysis of the commonalties between these processes and the various Gestalt concepts.
 The main point of this paper is to demonstrate that many of the issues and insights addressed by connectionist models have a long history in psychology, gomg back at least to the early 1900s in the work of the Gestalt psychologists.
 Parallel Constraint Satisfaction Processes In many connectionist models processing can be viewed as a parallel constraint satisfaction process, where activation is passed around the nodes in the network until all the node activations asymptote or "relax" into a state that satisfies the constraints among the nodes (e.
g.
.
 Hertz, Krogh, & Palmer, 1991; Murre, 1992; Rumelhart & McClelland, 1986).
 A parallel constraint satisfaction network consists of a set of nodes and the links among them, where the nodes represent hypotheses about the presence or absence of various features, and positive and negative links represent the extent to which the hypotheses are consistent or inconsistent with one another.
 The weights on the links indicate the strength of the consistency or inconsistency between the nodes or hypotheses.
 Thus, the links represent a set of constraints among the hypotheses.
 Activation is spread among all the nodes until the activation of each node asymptotes and the network "settles".
 Because the activation of a node is a result of all of its positive and negative links to other nodes, its final activation is a solution to the constraints represented by the links.
 Moreover, because activafion is spread in parallel, this process results in a global solution to the constraints 766 mailto:vanman@usc.
edumailto:read@almaak.
use.
eduamong the entire set of nodes.
 Hopfield (1982, 1984; also see Hertz et al.
, 1991) has shown that such a system can be treated as if it has an energy, where the energy of the system is a function of the activations of the nodes and the weights among them.
 Moreover, evaluating a parallel constraint satisfaction network with symmetric links can be viewed as an attempt to minimize the system's energy.
 Solving for the constraints is a gradient descent process, moving toward a minimum (or valley) in an energy surface that represents all the possible states of the system (Hertz et al.
, 1991).
 A system that has settled or relaxed can be viewed as having reached a valley in the energy surface, representing a minimum state of energy for the entire system Such networks are dynamic systems, as their state evolves over time.
 Essentially, the energy of the system corresponds to its degree of organization.
 High energy corresponds to less organization and low energy corresponds to greater organization.
 Thus, a parallel constraint satisfaction process can be viewed as attempting to find the maximal degree of organization consistent with the constraints imposed by the relations among the nodes.
 The Relation of Gestalt Principles of Parallel Constraint Satisfaction Processes We turn now to an examination of some of the basic assumptions of Gestah psychology and their close parallels with the characteristics of parallel constraint satisfaction systems.
 W e focus on five key assumptions of Gestalt Psychology: (1) that psychological processing can be thought of in terms of interactions in fields of forces, (2) that processing is holistic rather than atomistic or elementalistic, (3) that the whole of the perception or concept is greater than the sum of its parts, (4) that the structure of a stimulus, how its components are connected and related, plays a critical role in how it is perceived or thought about, and (5) that the psychological field is a dynamic system.
 Psychological Processing Conceptualized as Interactions in Fields of Forces When Wertheimer, Koffka, and KOhler began to develop their theoretical framework of Gestalt Psychology, they viewed traditional psychology as being essentially atomistic and mechanistic, and proposed instead the adoption of physical field theory as their model (Henle, 1986).
 Building on Faraday's ideas about fields in physics, the gestalt psychologists proposed that such fields also exist in the psychological realm and included forces, tensions, and states of equilibria as did their counterparts in physics.
 According to Koffka (1935), "if the locus of behavior is the physical world, then the field concept which is so powerful a tool in physics must be applied to behavior" (p.
 49).
 Koffka argued that these fields were no less real than those of physics, and it was the goal of psychology to study behavior's causal relation to these fields, and to identify and understand the forces that caused behavior to occur.
 Given this insistence on understanding psychological processing in terms of interactions among fields of forces, it is of considerable interest that research on connectionist models and parallel constraint satisfaction processes has shown that there are precise mathematical parallels between the behavior of neural networks described by these models and the behavior of various kinds of physical systems, such as interacting magnetic fields.
 For example.
 Hertz et al.
 (1991), following work by others, point out that one important kind of neural network model, a Hopfield net (Hopfield, 1982, 1984), is precisely equivalent, mathematically, to certain kinds of simplified (but highly useful) models describing the interactions of the magnetic fields of individual atoms in a magnetic material.
 The patterns of influence between individual atoms in this magnetic material correspond to the patterns of influence among neurons in a Hopfield network.
 Further, researchers have applied a host of ideas from statistical mechanics and thermodynamics to the analysis of neural network models (e.
g.
.
 Hertz et al.
, 1991; Hinton & Sejnowski, 1986).
 Therefore, at an abstract, conceptual level, the behavior of psychological systems and processes is similar to, or maybe even isomorphic with the behavior of certain kinds of dynamic physical systems that can be treated in terms of interacting force fields.
 Thus, the intuitions of the Gestalt psychologists may have been on the right track and their attempts to analyze psychological phenomena in terms of interacting psychological and social fields of forces, may not have been misdirected.
 Psychological Processing is Holistic At the time of Wertheimer's (1912) first experiments in perception, psychologists and physiologists considered nervous system processes to be composed of the excitations of individual receptor cells that then moved along an "independent or isolated" nerve to the brain, where it activated a corresponding independent or isolated brain region.
 Perception (or consciousness) was somehow the sum of all of these excitations.
 Koffka writes "the enormous complexity of behavior was not explained by an equal complexity of processes as such, but only by an equal complexity of a host of separate processes, all of the same general kind but occurring in different places" (p.
 54).
 The gestalt psychologists proposed an alternative: "instead of reacting to local stimuli by local and mutually independent events, the organism responds to the pattern of stimuli to which it is exposed.
.
.
a unitary process, a functional whole" (Kohler, 1929, p.
 103).
 Further, the change in any single piece of information could directly influence the perception of the whole.
 Holistic processing has been demonstrated by the use of several familiar visual perception examples such as figures that are perceived in an apparently random configuration of dots, or the perception of an object that completely changes with the slightest change of a single element.
 In social psychology, Asch (1952) theorized that person perception works in much the same fashion.
 Asch proposed that w e perceive other individuals as whole units.
 Like one of the visual illusions studied by Gestalt psychologists, the perception of personality traits is holistic.
 "Each trait 767 possesses the property of a part in a whole.
 The introduction or omission of a single trait may alter the entire impression" (Asch, 1952, p.
 216).
 Asch also suggested that group behavior was holistic, that we could not understand groups by treating them as the sum of the behavior of individuals.
 Again, adding or removing one individual could potentially cause a tremendous change in the behavior of the group.
 Holistic processing of information is precisely what happens in neural network models.
 Items simultaneously send and receive activation to and from all the items to which they are connected.
 As a result, the activation of each item depends on the activation of all other items.
 Thus, there is no way to separate the interpretation of any individual item from the interpretation of the other items to which it is related, because the activation of each element in the network depends upon the activation of all the other elements in the network.
 Moreover, these systems can be seen as a realization of the kinds of processing that Wertheimer (1912) and Koffka (1935) argued were characteristic of the brain.
 Rather than having the perception of an object be due only to "local and mutually independent events" (KOhler, 1929, p.
 103), processing takes place in the interaction among a large number of neurons, and the perception of a stimulus corresponds to a pattern of activation across these neurons.
 The Whole is Greater than the Sum of its Parts This may well be the signature assumption of Gestalt Psychology.
 As a result of their rejection of the atomistic view of psychology, the gestalt psychologists compared their approach to the molar science of physics.
 KOhler (1920) demonstrated that the physicist does not try to understand water solely by conducting a molecular analysis of its constituent atoms, hydrogen and oxygen.
 W h y ? A completely new system is formed by the combination of these atoms that has properties that cannot be derived by adding the individual properties of each.
 In the same way, perceptions of the world or of people cannot be derived simply by adding together individual points of stimulation in the perceptual apparatus or by adding together individual features.
 Rather the combination of perceptual elements leads to new properties that are not simply the sum of the elements.
 One problem Gestalt Psychology always had was that as much as this idea seemed to fit many people's intuitions, it was never quite clear how it could be implemented in an explicit psychological process model.
 However, neural network models can provide a computational implementation of this assumption.
 Because most kinds of neural network models are nonlinear systems, they can model situations in which the addition of small amounts of information or the change of state of a small part of the network can lead to radically different states of the system and therefore quite different meanings.
 For example, if we think of the representation of the possible states of a neural network in terms of the energy surface discussed earlier, then the addition of only a few elements or only a small change in one part of the network is sometimes sufficient to ensure that the system will settle in a very different energy minima.
 That is, the network will arrive at a very different final state.
 One reasons why earlier work on neural networks largely stopped is because Minsky and Papert (1969), in their critique of one kind of neural network, the perceptron, demonstrated that these early networks could only handle linear problems.
 Yet, researchers recognized that psychological processes often required nonlinear processing, in which the end result of processing a set of elements was not based on a linear function of the individual elements.
 Partially in response to this issue, many current models use a nonlinear activation function, where the activation of a node is a nonlinear function of its inputs.
 One way to interpret what the Gestalt Psychologists were claiming is that the meaning of a stimulus configuration cannot be calculated using any kind of linear integration rule, such as averaging or summing a set of stimulus elements (the sum of its parts).
 Currently, there are a several areas in psychology in which it is clear that the processing of stimulus configurations cannot be modeled by a linear function.
 One important example is in work on human categorization.
 Research has demonstrated that oftentimes human categories are not linearly separable; that is, there is no linear function that can be used to calculate category membership (see Medin & Wattenmaker, 1987, for a discussion).
 Instead, nonlinear rules must be used.
 Further, linearly separable categories are no easier to learn than are non linearly separable categories (Medin & Schwanenflugel, 1981).
 Medin and Wattenmaker (1987) argue that linear separability may not be an important constraint on human categories because people's categories ".
.
.
typically have more internal structure than can be captured by an independent summing of evidence or by similarity to a prototype.
" (p.
 37).
 Thus, category membership judgments are often "greater than the sum of their parts.
" Emphasis on Structure: How Things are Connected and Related Gestalt psychologists proposed that our perceptions of the world are guided by organizational principles such as good form, proximity, and similarity.
 Thus, even given an incomplete figure we perceive a circle rather than a set of curved lines, and a triangle rather than three dots.
 W e perceive alternating rows of roses and tulips, rather than an undifferentiated field of flowers.
 These principles not only applied to spafial relations, but temporal ones as well.
 Temporal organization enables our perception of causality.
 Without it, Koffka (1935) wrote, "One billiard ball would run, come in contact with another, stop, and the other would begin to roll.
 T w o trains would collide, leave the tracks, and cars turn turtle and become wrecked; another mere consequence" (p.
 383).
 Heider (1944) incorporated these Gestalt principles into his analysis of causality.
 Viewing cause and effect as parts of a single unit, he demonstrated how similarity and proximity influenced the creation of causal attributions.
 Later (Heider, 1946), he extended this analysis in balance theory.
 For interpersonal perception, the parts of the units 768 are considered to be persons and objects as well as the relations of these to one another.
 People are said to perceive these interpersonal and attitudinal bonds as units.
 The bonds themselves follow the same Gestalt organizational principles.
 For example, similarity creates a balanced state if "all parts of a unit have the same dynamic character (i.
e.
, if all are positive, or all are negative), and if entities with different dynamic character are segregated from each other" (Heider, 1946,p.
 107) Thus, Gestalt Psychologists argued that structure played a central role in the interpretation of stimuli.
 One had to know how elements were organized, what was related to what, and how they were related.
 One could not just sum up all the elements, one had to know how they were organized.
 The same kind of argument has been made for the importance of schema type representations, in which the organization of attributes plays a central role.
 Again this is a key part of parallel constraint satisfaction models.
 The activation (and thus the interpretation) of the elements in the network critically depends on the nature of the connections among the elements.
 Put another way, the final state of the system depends on the pattern of constraints among the elements of the system.
 The final state depends on the structure of the system.
 Different patterns of constraints among precisely the same elements will lead to very different states of the system.
 Emphasis on Dynamics: Change, Equilibrium, Tension Finally, by adopting physical field theory as their model, gestalt psychologists emphasized the dynamics produced by their fields of forces.
 Opposing forces create tensions, which in turn cause change to occur so as to reach some endstate.
 Terms such as Balance, Equilibrium, and Harmony refer to the preferred state of a dynamical system in which the degree of tension is at a minunum.
 Whether it is a perceptual, motivational, or behavioral process, a dynamic striving for the endstate always underlies the process itself.
 Thus, the individual is conceived of as an "equilibriummaintaining system" that in psychology translates into "an interest in the processes by which equilibrium is restored once it is disturbed" (Deutsch, 1968, p.
 421).
 Thus, the idea of tension within a field of forces, and the resulting attempts to reduce that tension, played a central explanatory role in Gestalt Psychology.
 Systems under tension would evolve towards a state that minimized that tension.
 The evolution of the system toward reduced tension was responsible for the movement of the individual through psychological or physical space, resulting in psychological or behavior change.
 This idea of a system under tension that tends to evolve toward a state of minimal tension is remarkably similar to a parallel constraint satisfaction system.
 As parallel constraint satisfaction processes work to satisfy the constraints imposed by the positive and negative relationships and minimize the energy of the system, one way to view what is happening is as an attempt to minimize the degree of tension or conflict in the system.
 One is trying to find the minimum level of tension possible, given the constraints imposed by the actual set of relations among the cognitive elements.
 As many researchers have noted, neural networks can be viewed as trying to find the minimum energy or maximum degree of organization of the system.
 In addition, neural network models can be explicitly characterized as dynamic systems where the state of the system changes over time.
 For example, one can look at how, following initial input, the system evolves over time to an increasing degree of organization, and one can examine the trajectory it follows.
 Or, once a system has reached a minimum or equilibrium state, one can examine how new stimuli first reduce the organization of the system and then examine how the system evolves to a new state.
 Further, certain kinds of networks, such as Hopfield nets (Hopfield, 1982, 1984) and Boltzmann machines (e.
g.
, Hinton & Sejnowski, 1986), have been explicitly characterized as a kind of dynamic system called attractor systems, where the minimums in the energy surface are attractors toward which the state of the system tends or is "pulled" (Hertz et al.
, 1991).
 Summary We have outlined how some of the key ideas and insights of recent work in connectionism have a long history in psychology that can be traced back to the founders of Gestalt psychology.
 In fact, Gestalt psychologists introduced these ideas in a number of areas in psychology.
 And many of these ideas have periodically resurfaced through the years, with parallel constraint satisfaction models providing the latest instance.
 However, one major advantage of current parallel constraint satisfaction models is that they allow us to develop explicit process models that provide computational implementations of many of these recurring insights, as well as allowing us to push our investigations far beyond the bounds of this earlier work.
 References Asch, S.
 E.
 (1952).
 Social psychology.
 EnglewoodCliffs, NJ: PrenticeHall.
 Deutsch, M .
 (1968).
 Field theory in social psychology.
 In G.
 Lindzey & E.
 Aronson (Eds.
^, The Handbook of Social Psychology (2nd Ed.
), (Vol.
 1, pp.
 412487).
 Reading, M A : AddisonWesley.
 Heider, F.
 (1944).
 Social perception and phenomenal causality.
 Psychological Review, 51, 358374.
 Heider, F.
 (1946).
 Attitudes and cognitive organization.
 Journal of Psychology, 21, 107112.
 Hinton, G.
 E.
, & Sejnowski, T.
 J.
 (1986).
 Learning and releaming in Boltzmann machine.
 In D.
E.
 Rummelhart & J.
 L.
 McClelland (Eds.
), Parallel distributed processing: Explorations in the microstructure of cognition.
 Vol.
 I.
 Foundations.
 Cambridge, M A : M I T Press/Bradford Books.
 Hertz, J.
, Krogh, A.
, & Palmer, R.
 G.
 (1991/ Introduction to the theory of neural computation.
 Redwood City, CA: AddisonWesley Publishing Co.
 Hopfield, J.
 J.
 (1982).
 Neural networks and physical systems with emergent collective computational abilities.
 Proceedings of the National Academy of Sciences, U S A , 769 79,25542558.
 Hopfield, J.
 J.
 (1984).
 Neurons with graded responses have collective computational properties like those of twostate neurons.
 Proceedings of the National Academy of Sciences.
 USA,%\, 30883092.
 Koffka, K.
 (1935).
 Principles of Gestalt Psychology.
 New York: Harcourt, Brace.
 KOhler, W.
 (1920).
 Die physischen Gestalten in Ruhe and im stationaren Zustand.
 Braunschweig: F.
 Vieweg.
 KOhler, W.
 (1929).
 Gestalt Psychology.
 New York: Liveright.
 Medin, D.
 L.
, & Schwanenflugel, P.
 L.
 (1981).
 Linear separability in classification learning.
 Journal of Experiemental Psychology: Human Learning and Memory, 7, 355368.
 Medin, D.
 L.
, & Wattenmaker, W.
 D.
 (1987).
 Category cohesiveness, theories, and cognitive archeology.
 In U.
 Neisser (Ed.
), Concepts and Conceptual Development: Ecological and Intellectual Factors in Categorization.
 (pp.
 2562).
 Cambridge University Press: Cambridge, England.
 Minsky, M.
, & Papert, S.
 (1969).
 Perceptrons.
 Cambridge, MA: MIT Press.
 Murre, J.
 M.
 J.
 (1992/ Learning and Categorization in Modular Neural Networks.
 Hillsdale, NJ: Erlbaum.
 Rumelhart, D.
 E.
, & McClelland, J.
 L.
 (1986).
 PDP models and general issues in Cognitive Science.
 In Rumelhart, D.
 E.
, & McClelland, J.
 L.
 (Eds).
 Parallel Distributed Processing: Explorations in the Microstructure of Cognition.
 Vol.
 1.
 Foundations, (pp.
 110146).
 Cambridge, M A : MIT Press/Bradford Books.
 Spelhnan, B.
 A.
 & Holyoak, K.
 J.
 (1992).
 If Saddam is Hitler then Who is George Bush? Analogical mapping between systems of social roles.
 Journal of Personality and Social Psychology, 62, 913933.
 Wertheimer, M.
 (1912).
 Experimentelle Studien Qber das Sehen von Bewegung.
 Zeitschrift fiir Psychologie, 61, 161265.
 (Translation in T.
 Shipley (Ed.
;, Classics in psychology.
 New York: Philosophical Libray, 1961.
) 770 Does HypothesisInstruction Improve Learning? Regina VoUmeyer Institut fiir Psychologic Universitat Potsdam 14415 Potsdam, Geimany vollmeye§rz.
unipotsdam.
de Bruce D.
 Burns Department of Psychology University of California, Los Angeles Los Angeles, California 900951563 burns@psych.
ucla.
edu Abstract Dual space models of problem solving (e.
g.
, Simon & Lea, 1974; Klahr & Dunbar, 1988) assume that the problem space for a task consists of two spaces: an hypothesis space and an experiment space.
 In hypothesis space, hypotheses about rules governing the task are generated, which can then be tested in experiment space.
 However, experiment space can be searched by applying the operators even without knowledge about the task.
 W e predicted that people searching hypothesis space would learn more about the task.
 To test this claim, two experiments were performed in which subjects had to learn to control a system consisting of three input variables that had unknown links to three output variables.
 Subjects first explored the task, then they had to reach goal states for the output variables.
 In both experiments subjects were presented with an hypothesis about one of the links, which should foster search of hypothesis space.
 In Experiment 1, hypothesis instruction improved performance and we showed that it had a similar effect to a manipulation of goal specificity, suggesting that both factors improve learning by encouraging search in hypothesis space.
 In Experiment 2 subjects were given a correct hypothesis or an incorrect hypothesis.
 Both groups performed better than an appropriate control.
 Thus instructions that encourage hypothesis testing appear to improve learning in problem solving.
 Introduction Mayer's (1989) analysis of problem solving claimed that a problem solver applies representational processes to form a representation of a problem, then solution processes are applied to find the solution.
 However, Mayer notes that, as Duncker (1945) argued, representations may not be static and that the interaction of representational and solution processes may be the key to problem solving.
 But what processes form the most appropriate representations? Dual Space Theory and Learning One explanation for why some problem solvers learn more about a problem task than others is given in Klahr and Dunbar's (1988) theory of Scientific Discovery as Dual Search (SDDS).
 They propose that the problem space is separated into two spaces: an hypothesis space and an experiment space.
 Searching the hypothesis space requires formulating exphcit hypotheses about the task, thus, the rules governing the task can be discovered.
 Searching the experiment space only requires applying the legal operators of the task to generate new problem states.
 According to S D D S theory a good representation of the task is gained if the problem solver searches both spaces interactively.
 Such problem solvers induce rules explicitly by searching the hypothesis space and they then test them through search of the experiment space.
 While search of experiment space is necessary for generating and testing hypotheses, a poor knowledge is gained if search of experiment space dominates.
 (However, such problem solvers may be the most successful if the rules are very hard to discover) The claim that problem solvers who formulate and test hypotheses have a better representation has found some support (Klahr & Dunbar, 1988; Recker, Govindaraj, & Vasandani, 1994).
 In particular, Klahr, Fay, and Dunbar (1993) found that subjects who generated hypotheses, even if incorrect, were more successful at solving a complex problem.
 However, these studies used a posthoc classification of which problem space was searched.
 Therefore, to clearly show that using hypotheses improves learning, it is necessary to directly manipulate the likelihood of subjects generating and testing hypotheses.
 Further support for the S D D S theory can be found in our own work (VoUmeyer, Bums, & Holyoak, in press).
 In these studies we used the theoretical framework of Simon and Lea (1974) to which Klahr and Dunbar (1988) also refer.
 Simon and Lea proposed that instance space (comparable with experiment space) is searched if problem solvers are focused on finding a solution for a specific goal, whereas rule space and instance space (rule space is comparable with hypothesis space) are searched if problem solvers are focused on learning the rules of the task.
 Therefore, we varied goal specificity by giving one group a nonspecific goal, to learn as much as possible while exploring the problem task, then we tested their learning by giving them a goal state to reach; whereas another group explored the task with the same instruction, however in addition they were told at the start of the task the specific goal that they had to reach after the exploration phase.
 Consistent with the predictions, problem solvers with the nonspecific goal had more knowledge about the rules governing the task and could apply the learned knowledge equally to two different goal states.
 Problem solvers with a specific goal learned less about the rules governing the task, but they could reach the specific goal they had been 771 mailto:burns@psych.
ucla.
edugiven at the start as well as the nonspecific goal group.
 However, their perfonnance declined when they were given a new goal to which such a solution path could not be readily transferred Rather than learn the rules, they may have learned a solution path while exploring the task.
 These results can be interpreted as supporting the claim that the nonspecific goal group were more likely to search both spaces, whereas the specific goal group were more likely to only search the experiment space.
 In the following two experiments we gave subjects an hypothesis about the structure of the task.
 With this manipulation we wanted to foster search of the hypothesis space.
 Under this condition they should gain more knowledge and consequently reach the goal stale of the task more accurately.
 As the hypothesis also provided more information about the task to the subjects, in the second experiment we attempted to clearly establish that unproved performance was due to search in hypothesis space and not just because more information was given.
 Biology Lab: A Complex Problem Task Vollmeyer, Burns, and Holyoak (in press) used a computerdriven problem task w e called biology lab which was constructed using the shell D Y N A M I S (Funke, 1991).
 This task was again used in the current experiments.
 In Vollmeyer et al.
 subjects had to conuol four output variables by varying four input variables, but in the first experiment we used a system with only three input and output variables.
 Subjects were presented with a cover story telling them that they were in a biology lab in which there were three species of sea animals in a tank (crabs, sea bass, lobster) and that their population could be manipulated by three factors (temperature, oxygen, current).
 The structure of the task (see Figure 1) was complex as one output (sea bass) was influenced by two inputs, and dynamic, as one output (lobster) had a decay (marked with a circle), resulting in the population decaying by 10 % each trial even if nothing was manipulated.
 As the decay was hard to understand we omitted this characteristic in the second experiment, which helps generalize our results to simpler systems.
 temperature oxygen current > 5 crabs sea ba.
ii.
s lobster V ? Figure 1: Biology lab system To explore the task, subjects in Vollmeyer et al.
 (in press) were given a learning phase (tliree rounds of six trials on which numbers were entered for the inputs) and a solution round (six trials) at the end of which subjects had to reach a certain target amount for each output variable.
 VoUineyer et al.
 showed that a good strategy for learning about the task was to vary only one input variable at a time.
 This strategy was given to all subjects in the current experiments in order to reduce their variance.
 Experiment 1 In the first experiment we tested whether subjects given an hypothesis to test about a difficult relation in the problem task would learn more about the structure of the task and reach the goal state for the output variables more accurately than subjects given no hypothesis.
 W e also manipulated goal specificity and predicted on the basis of Vollmeyer et al.
 (in press), that giving subjects a specific goal would produce similar effects to hypothesis instruction.
 Method Subjects.
 Sixty undergraduate students at the University of California, Los Angeles, participated for course credit.
 Design.
 A 2x2 design was used with two levels of hypothesisinstruction (hypothesisinstructed vs.
 uninstructed) and goal specificity (specific vs.
 nonspecific).
 Fifteen subjects were in each condition.
 Procedure.
 The biology lab problem was presented with the underlying structure shown in Figure I.
 Subjects had to learn about the problem in three rounds, each round with six trials and in the fourth round they were asked to reach a specific goal state (namely, 50 aabs, 900 lobsters, and 700 sea bass).
 Subjects in the specific goal condition were presented with these goal states right from the beginning, whereas the nonspecific goal group saw these goal states at the beginning of the solution round for the first time.
 Before starting, all subjects were instructed that the best strategy for exploring the task was to vary only one input variable at a time.
 In addition, the hypothesisinstructed group was told that a researcher believed that lobsters had a decay of 1 0 % and that current had an influence in that each input to current is multiplied by four and then added to the lobsterpopulation.
 Hypothesisinstructed subjects were told to test the hypothesis in order to determine if it was correct.
 Uninstructed groups received no hypothesis.
 After each round of the learning phase (rounds 13) subjects completed a "structure diagram", which consisted of a diagram similar to the one in Figure I, but with all links omitted.
 Subjects were instructed to draw links between variables that they beheved affected each other, and to also assign directions (positive or negative) and weights indicating how strong they thought each influence was.
 After each input trial subjects had to predict the new values for each output variable that they thought would result from their inputs.
 The entire experiment took an hour to complete.
 Results Dependent variables.
 Three dependent variables were analyzed which measured both knowledge and accuracy in 772 reaching the goal stales.
 (1) Structure score.
 The structure diagram was given after each of the three rounds of the learning phase.
 However, as the structure diagram ;ilter round 3 was most informative about subjects' knowledge ai the end of the learning phase, only the structure score lor this round is reported here.
 The knowledge indicated in this diagram was measured as the sum of the number of correct specifications of links, directions, and weights, adjusted with a correction for guessing (see Woodworth & Schlosberg, 1954, p.
 700).
 (2) Prediction error.
 After each input trial during the learning phase subjects had to predict the population for each output variable.
 The absolute difference between the predicted number and the actual number for each of the three output variables was computed.
 As this measure produced a skewed distribution, the distribution was corrected by applying a logarithmic transformation.
 (3) Solution error.
 Solution error in reaching the goal state during round 4 was computed as the sum of the absolute differences between the new goal and the obtained number for each of the three output variables.
 Again, a logarithmic transformation had to be applied.
 Solution error was computed for each of the six trials that comprised round 4.
 Preliminary analyses.
 The structure score and the sum of prediction errors (over three rounds) were measures of knowledge and should correlate, which was the case, r = .
62, p <.
001.
 Having more knowledge should lead to lower solution errors.
 This was confirmed by the correlations for structure score and solution error, r = .
48, p < .
001, and for prediction error and solution error, r = .
57, p < .
001.
 Instructing subjects to test an hypodiesis should help them gain more knowledge as measured by Uieir structure diagram scores.
 In particular, if our manipulation was effective in getting subjects to test the given hypothesis then hypothesisinstructed subjects should be more likely to conectly report the links that were part of dieir hypoUiesis.
 W e found this, as 18 out of 30 in the hypothesisinstructed groups correctly reported the decay factor for lobster compared to 4 out of 30 for uninstructed groups, A?(l) = 12.
12, p < .
001.
 Hypothesis instruction also led more subjects to correctly specify the weight for the relation between current and lobster (also part of Uie hypothesis), 13 out of 30 compared to 1 out of 30 for uninstructed groups, ^(1)= 11.
27, p<.
001.
 Influence of hypothesisinstruction and goal specitlcity on learning.
 The hypothesisinstructed groups (M = 1.
55) should have a higher structure score than the uninstructed groups (M = 1.
07), which was the case, F(l,56) = 4.
58, p < .
05.
 Also, as predicted, the mean structure score for the nonspecific goal groups are higher (M = 1.
56) Uian diat for the specific goal groups (M = 1.
06), F(l,56) = 5.
13, p < .
05.
 There was no interaction between the factors F < 1.
0.
 Surprisingly, over all rounds of the learning phase there was no statistically significant effect of goalspecificity on prediction error, F(l,56) = 1.
69, p > .
05.
 However, Uiere was an effect of hypothesisinstruction on prediction error, F(l,56) = 8.
92, p < .
05, and the interaction of output variable and hypothesisinstruction was significant.
 F(2,112) = 9.
31, p < .
001.
 Therefore w e analyzed each output variable separately.
 For lobster, which was part of the hypothesis, a strong effect of hypothesis on predictions scores was found (see Table 1), F(l,56) = 29.
1.
 p < .
05.
 Although, for aabs and sea bass the difference was not significant, the means were in the expected direction (see Table 1).
 For solution error, an effect of hypoUiesisinstruction was found, F(l,56) = 8.
20, p < .
01, but there was no interaction with output variable, F < 1.
0.
 For our theory it is important to show Uiat hypothesisinstruction helped performance on all output variables, not only the one the given hypothesis refers to, thus w e analyzed each output variable further.
 As can be seen in Table 1, there was an effect on lobster, F(l,56) = 14.
35, p < .
05, and on crabs, F(l,56) = 5.
36, p < .
05.
 (Note diat crabs were not referred to by the hypothesis) The hypothesis effect did not reach significance for sea bass, F(l,56) = 2.
36, p > .
05.
 A s VoUmeyer et al.
 (in press) found there was no effect of goal specificity on solution error, F < 1.
0.
 Table 1.
 Means for hypothesisinstructed (HI) vs.
 uninstructed (HUI) subjects on prediction error and solution error, separated by output variable output variables lobster HI HUI sea bass HI HUI crabs HI HUI prediction error 3.
31 4.
67 3.
25 3.
61 1.
55 1.
88 solution error 3.
36 4.
05 3.
94 4.
49 1.
83 2.
86 S u m m a r y Experiment 1 showed Uiat having subjects test an hypothesis had an effect on learning.
 Hypothesisinstructed subjects learned more about the structure of the task and could predict the outcomes better than the uninstructed groups.
 All output variables were reached more accurately, not just the one referred to by the hypothesis, suggesting that having an hypothesis helps subjects learn about unrelated variables, perhaps through encouraging further hypothesis testing.
 The results for goalspecificity replicated our previous experiment and showed goal specificity effects are generalizable to a different system.
 Subjects learned more about the structure if they had a nonspecific goal, but they reached the goal states as well as the specific goal group, which already had experience in reaching the goal states.
 One surprising effect was that the goal groups did not differ on prediction error, which was another method for measuring knowledge.
 Perhaps this is because the specific goal groups were already focused on bringing about a specific state, which improved prediction, whereas the nonspecific goal groups had more knowledge, but did not focus on reaching specific states.
 The lack of any interaction 773 between goal specificity and hypoUicsisinslrucUon is interesting as it suggests that they may have their eltecLs for similar reasons, that is, by encouraging search of hypothesis space.
 Experiment 2 While Experiment 1 clearly showed that giving subjects an hypothesis improved both their knowledge and their performance, an alternative explanation is possible other than our claim that giving an hypothesis promotes search of hypothesis space.
 Because we gave subjects a correct hypothesis it is possible that they simply interpreted it as extra information and used it to help them control the system.
 Arguing against this possibility is the lack of an interaction on errorscores between output variable and hypothesisinstruction.
 However, if this alternative explanation is valid then giving subjects an hypothesis that is incorrect should eliminate the hypothesis effect.
 Klahr et al.
 (1993) found that subjects w h o generated incorrect hypotheses also performed better than those with no hypotheses, but they did not directly manipulate whether people generated hypotheses.
 Thus in Experiment 2 we tested whether giving subjects an incorrect hypothesis would help them to learn more about the biology lab task, as it would encourage search of hypothesis space.
 To do this w e had three groups: correcthypothesis, incorrecthypothesis, and linkonly.
 The correcthypothesis group was instructed to test a correct hypothesis about a link and its weight.
 T o reduce the usefulness of the information (but not the benefit of testing it) this hypothesis was about the simplest link, that between the input and output variable whose only link was to each other.
 Most subjects in previous experiments learned this particular link, so even if subjects assumed that this hypothesis was correct it would be of little use to them.
 The incorrecthypothesis group was given a hypothesis about the same link, but they were told the wrong weight.
 The linkonly group received the correct information that this same link existed, but no weight was suggested.
 Thus the Unkonly group had the same amount of correct information as the incorrect hypothesis group, but lacked the erroneous link information that made the incorrecthypothesis group's hypothesis a complete one.
 W e predicted that both the correct and incorrect hypothesis groups would perform better than the Unkonly group.
 Odier changes from Experiment 1 were that we changed the variable names and used a simpler biology lab system, as we dropped the decay link.
 Otherwise, the system was the same as that in Figure 1.
 These changes helped us generalize our results.
 Method Subjects.
 Two hundred and thirtysix students at the University of California, Los Angeles, participated.
 Design.
 The experiment had three conditions, that is hypothesisinstruction was varied on three levels: correcthypothesis; incorrecthypothesis; and, linkonly.
 Procedure.
 The biology lab task was presented with the underlying structure shown in Figure 1, except that the decay link was omitted and the variable names were changed.
 The inputs, temperature, current and oxygen, became salt, carbon and lime, respectively.
 The outputs, crabs, sea bass and lobster, became oxygenation, chlorine concentration and temperature, respectively.
 As the task was easier subjects had only two rounds in the learning phase, during which they already knew the goal states for the learning round.
 From the beginning, all groups were given the goal state (namely, an oxygenation of 50, a chloride concentration of 700, and a temperature of 900).
 They had to reach this goal state in the third round.
 In the fourth round, the transfer round, a new goal state was given (namely, an oxygenation of 400, a chloride concentration of 700, and a temperature of 1000).
 All subjects read the instructions explaining the task, and the same good strategy with which to explore the task as was given in Experiment 1.
 W e had three levels of hypothesisinstruction: correct hypothesis, incorrecthypothesis, and Unkonly information.
 In the correcthypothesis group subjects were verbaUy and graphically presented with the hypothesis that lime could have an effect on oxygenation, that is, each input to carbon is multiplied by the weight 2.
0 and then added to the oxygenation value.
 The incorrecthypothesis group was told to test the same link, but the given weight (5.
0) was incorrect.
 Both hypothesis groups were instructed to test their hypothesis.
 The linkonly group subjects were told that there could be a link between lime and oxygenation, but told no weight.
 In a previous experiment (VoUmeyer & Bums, under submission), we had found that giving links without direction or weights did not improve performance, thus Uiis manipulation should be similar to giving subjects no hypothesis.
 Because the system was simpler than that used in Experiment 1, only two rounds were given for the learning phase.
 After each round during this phase subjects completed the structure diagram, for which they were given detailed instructions for how to calculate weights.
 They again had to predict the outcomes for each output variable after each input trial.
 In order to encourage the hypothesis groups to test the hypothesis, these subjects were asked to indicate if they thought the hypothesis was correct by circling "Yes", "No", or "Don't know" after the end of each of the first two rounds.
 This question also measured if subjects given an hypothesis were able to determined it's validity.
 The goal state for the solution round was presented to all subjects right from the beginning, however, they only had to reach that state in the third round.
 Therefore, subjects could decide, whether or not to focus on the specific goal.
 The results of Volhneyer et al.
 (in press) suggested that giving subjects a specific goal from the start discourages Uiem from testing hypotheses, thus giving a specific goal should decrease the a priori probability of subjects testing hypotheses.
 In round 4, subjects were presented with a new goal state which had to be reached.
 The entire experiment took an hour to complete.
 774 Results Dependent variables.
 The same three dependent variables as calculated in Experiment 1 were used, thai is, siructurc score, prediction error, and solution error.
 Suucturc score and prediction error were measures of (he knowledge subjects had of the rules governing the task.
 The solution error indicated whether subjects could apply their knowledge.
 As there was a transfer round in which a new goal state had to be obtained, a transfer error was calculated similar to the solution error.
 Transfer error measured how effectively the knowledge gained through trying to reach one goal state can be transferred to a new goal state.
 Preliminary analyses.
 Again we checked whether our measures for learning were related, and whether our manipulation of hypothesisinstruction was effective.
 The sum of the prediction errors over three rounds and structure score on round 2 should be correlated as they both measure knowledge about the task, which was the case, r = .
26, p < .
001, though this correlation was much lower than it was in Experiment 1.
 Having more knowledge should lead to lower solution and transfer errors, thus these measures should correlate, as we found; structure score and solution error: r = .
61, p < .
001; prediction error and solution error: r = .
57, p < .
001; structure score and transfer error: r = .
46, p < .
001; prediction error and uansfer error: r = .
47, p < .
001.
 Transfer error and solution error were also correlated, r = .
81, p < .
001.
 W h e n asked if the given hypothesis was true, sixtynine percent of responding subjects with the incorrect hypothesis believed it to be wrong, eight percent indicated it was correct, the rest were not sure.
 Eightyone percent of responding subjects with the correct hypothesis believed it to be correct, twelve percent indicated incorrect, the rest were not sure.
 Thus most subjects appear to correctly test the hypothesis.
 As in Experiment 1 we analyzed subjects' success at finding the link that each group was given (lime to oxygenation).
 The difference between the three groups was significant, X^ (2) = 6.
38, p < .
05.
 The correct hypothesis group indicated more often the correct weight (68 of 80) than the incorrect hypothesis group (58 of 78) and the linkonly group (54 of 78).
 Influence of hypothesisinstruction on learning.
 The correct and incorrecthypothesis groups should learn more about the structure of the task.
 However, they do not differ on the structure score, F < 1.
0.
 Together with the low correlation between prediction error and structure scores, this suggest that structure score may not be a good measure of knowledge for a system as simple as tliis.
 As predicted though, the prediction error over the tliree rounds showed an effect of hypothesis condition, f"(2,233) = 5.
36, p < .
01 (see Table 2).
 Linkonly prediction errors are higher than either those of Uie incorrect hypothesis, F(1,I54) = 7.
14, p < .
01, or correct hypoUiesis groups, F( 1,156) = 8.
21, p <.
 01.
 Thus it appears that it is more important that a hypothesis be given, rather than whether the hypothesis is correct.
 If subjects perform better just because of the amount of correct information they are given then the predictions for the output variable oxygenation should have been best for the correct hypothesis group, while there should have been little effect on other variables.
 According to our theory, all output variables should be better predicted, if a hypothesis was given, no matter whether the hypothesis is correct or incorrect.
 A significant interaction between hypothesisinsuuction and output variable allowed us to analyze each single output variable, F(4,466) = 4.
73, p < .
001.
 Table 3 shows the means for the three experimental groups.
 For the crucial comparison, that is hnkonly vs.
 incorrect hypothesis, we found significant differences for the prediction error of chloride concentration, F(l,154) = 7.
96, p < .
01, and for the prediction error of temperature, F(l,154) = 9.
30, p < .
01, however not for the prediction error of oxygenation, ̂ (1,154) = 2.
53, p > .
05, the ouQ)ut variable for which the hypothesis was given.
 All differences between correct and incorrect hypothesis groups were not significant.
 Table 2.
 Means of hypothesisinstruction on the dependent variables linkonly incorrect hypothesis correct hvpothesis prediction error 2.
82 2.
18 2.
11 solution error 2.
61 2.
23 1.
87 transfer error 2.
61 2.
19 1.
83 Table 3.
 Means of hypothesis instruction on the prediction error of the output variables linkonly incorrect hypothesis correct hypothesis chloride concentration 3.
51 2.
83 2.
82 temperature 2.
90 1.
99 2.
02 oxygenation 2.
06 1.
73 1.
49 W e analyzed whether hypothesisinstruction had an influence on solution and transfer error.
 Across both errors there was an effect of hypothesisinstruction, F(2,233) = 3.
97, p < .
05.
 As can be seen in Table 2, there was a difference between the linkonly group and the correct hypothesis group.
 However, the expected differences between the hnkonly group and the incorrect hypothesis group are not significant (solution error: F(l,154) = 1.
86, p > .
05; transfer error: F(l,154) = 1.
93, p > .
05).
 As in Experiment 1 there is no significant interaction between errors and output variables, F(2,466) = .
49, which is important for our point that giving an hypothesis does not only assist performance on the output variable on which the information was given.
 775 S u m m a r y Experiment 2 showed that even hypothesisinstruction with an incorrect hypothesis can improve performance, even when compared to a group given tlie same valid information but without as extensive an hypotJiesis to test.
 This is consistent with the claim that hypothesisinstruction not only provides information, but also leads to another type of processing, that is search in hypothesis space through the generation of hypotheses.
 Discussion Our aim was to find empirical evidence addressing why some people form a good representation during learning of a problem task, while other people have difficulties in finding a solution.
 Our theoretical explanation was based on dual space models, such as S D D S , that assumes that searching the hypothesis space by generating hypotheses helps learning.
 Goal sp)ecificity (Experiment 1) as well as hypothesisinstruction (both experiments) seem to be factors that have an influence on the choice of how to represent the task.
 The results of the two experiments are not always statistically significant on all of the dependent variables, but the pattern on these measures is always as expected.
 Even if we changed the task from a dynamic (Experiment 1) to a simpler task (Experiment 2), or gave an hypothesis about a simple or complex link, the influence of hypothesisinstruction was consistent.
 However, changing the task to a simpler system had consequences on the performance.
 One consequence was that subjects on average learned more about the structure of the simpler task (M = 2.
13) than about a dynamic task {M = 1.
32).
 As most of the people seem to learn the simple task, the structure score does not differentiate anymore.
 This explains why hypothesisinstruction had an effect on structure score in the first, but not in the second experiment.
 Predicting tlie outcome of a manipulation of the input variables demonstrated clear effects of hypothesisinstruction in both experiments.
 With a better representation of the task subjects generating hypotheses are able to reach given goal states more accurately.
 Therefore, w e regard the results as encouraging evidence that problemsolving can be most effective when the problem space is represented as a dual space.
 Such a representation appears to be encouraged if subjects are given an hypothesis, even an incorrect one.
 Other recent studies can be also be interpreted as evidence that search in hypothesis space improves performance.
 Chi, de Leeuw, Chui, and LaVancher (1994) found that instructing subjects to generate explanations of a text while they read it improved learning of its content, despite a fourth of these selfexplanation being incorrect.
 Selfexplanations may be like hypotheses and assist search of hypothesis space.
 Klahr (1994) argues that cognitive psychology and machine learning approaches to scientific discovery have converged towards dualspace theories.
 Machine learning has generally taken a highly data driven approach, which is more akin to search of experiment space.
 But this space needs to be limited in order to make such search tractable, and domain knowledge provided by testing hypothesis may provide these constraints.
 Casebased reasoning would seem to be an extreme form of search of the experiment space.
 But if cases constitute experiment space (past experiments), domain knowledge provides the hypothesis space.
 That casebased reasoning needs to consider more than just cases has been argued by Kolodner (1994).
 Our results demonstrate the importance of finding general rules for a problem instead of simply using a already learned solution path, thus they support a dualspace search approach to reasoning Acknowledgements This research was supported by D F G Grant V o 514/1 to Regina VoUmeyer and N S F Grant SBR9310614.
 References Chi, M.
 T.
 H.
, de Leeuw, N.
, Chiu, MH, & LaVancher, C.
 (1994).
 Eliciting selfexplanation improves understanding.
 Cognitive Science, 18, 439477.
 Duncker, K.
 (1945).
 O n problemsolving.
 Psychological Monographs, 58, 1113.
 Funke, J.
 (1991).
 Solving complex problems: Exploration and control of complex systems.
 In R.
 J.
 Sternberg & P.
 A.
 Frensch (Eds.
), Complex problem solving: Principles and mechanisms (pp.
 185222).
 HiUsdale, NJ: Erlbaum.
 Klahr, D.
 (1994).
 Children, adults, and machines as discovery systems.
 Machine Learning, 14, 313320.
 Klahr, D.
 & Dunbar, K.
 (1988).
 Dual space search during scientific reasoning.
 Cognitive Science, 12, 155.
 Klahr, D.
, Fay, A.
 L.
, & Dunbar, K.
 (1993).
 Heuristics for scientific experimentation: A developmental study.
 Cognitive Psychology, 25, 111146.
 Kolodner, J.
 L.
 (1994).
 Understanding creativity: A casebased approach.
 In S.
 Wess, Althoff, KD, & Richter, M.
 M.
 (Eds.
), Topics in casebased reasoning (pp 320).
 Berlin: SpringerVelag.
 Mayer, R.
 E.
 (1989).
 Human nonadversary problem solving.
 In K.
 J.
 Gilhooly (Ed.
), Human and machine problem solving (pp.
 3956).
 N e w York: Plenum Press.
 Recker, M.
 M.
, Govindaraj, T.
 & Vasandani, V.
 (1994).
 Troubleshooting in a complex, dynamical domain.
 In A.
 R a m & K.
 Eiselt (Eds.
) Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society (pp.
 739744).
 Hillsdale, NJ: Erlbaum.
 Simon, H.
 A.
 & Lea, G.
 (1974).
 Problem solving and rule induction: A unified view.
 In L.
 W .
 Gregg (Ed.
), Knowledge and cognition (pp.
 105127).
 Hillsdale, NJ: Erlbaum.
 Vollmeyer, R.
 & Burns, B.
 (under submission).
 Hypwthesentesten beim Erlemen eines Problems.
[Hypothesis testing in learning a problem task] Vollmeyer, R.
, Burns, B.
 D.
 & Holyoak, K.
 J.
 (in press).
 The impact of goal specificity and systematicity of strategies on the acquisition of problem solving.
 Cognitive Science.
 Woodworth, R.
 S.
 & Schlosberg, H.
 (1954).
 Experimental psychology.
 N e w York: Holt, Rinehart, and Winston.
 776 Domains, Knowledge Structures, and Integration Strategies William D.
 Wattenmaker Deparlmcnl of Psychology Division of Social Sciences Widener University One University Place Chester, P A 19013 william.
d.
wattenmaker@cyber.
widener.
edu Abstract A central issue in cognitive science is whether learning and processing constraints are particular to domains or whether they generalize across domains.
 In this paper the domaingenerality of a particular type of constraint, linear separability, was examined.
 Prior research has found that decisions in the social domain are often consistent with linear separability but this is rarely true of decisions in the object domain.
 Two experiments were conducted to examine the generality of this result by using fiindamentally different types of social and object materials than have been used in previous research.
 In both experiments different integration strategies were observed in social and object domains, and as in prior research many more Summation sorts occurred with social materials.
 These results indicate that previous differences that have been observed between object and social domains generalize to very different types of object and social materials.
 At a general level the results indicate that the structure of knowledge varies with domain, and consequently it will be difficult to formulate domaingeneral constraints in terms of abstract structural properties such as linear separability.
 Introduction A central issue in cognitive science concerns the domaingenerality of learning and processing constraints.
 Are learning and processing constraints particular to domains or do they generalize across domains? The research in this article investigated the extent to which linear separability constrained categorization decisions in different content domains.
 Linear separability is a principle that is relevant to categorization processes (e.
g.
 Medin & Schwanenflugel, 1981; Waldmann & Holyoak, 1990; Wattenmaker, Dewey, Murphy, & Medin, 1986), connectionist modeling (e.
g.
, Gluck & Bower, 1988), and machine learning (Nilsson, 1965).
 In relation to categorization, linearly separable categories are categories that can be partitioned on the basis of a weighted, additive combination of component information.
 In a series of experiments, Wattenmaker (in press) found that linear separability was a much more important constraint on decisions in the social than the object domain.
 It was concluded that different knowledge structures were activated in social and object domains, and that these differences in knowledge structures produced differences in encoding and integration strategies.
 The integration strategies that were activated in the social domain were compatible with linear separability, but the strategies that were activated in the object domain were inconsistent with linear separability.
 Thus, this research indicated that the naturalness of abstract structures and prmciples such as linear separability will vary with content domain.
 The present research was designed to test the generality of these results.
 This was accomplished by using different social materials and different object materials than were used in the Wattenmaker (in press) studies.
 Indeed, there are many different types of social and object concepts, and withm the social and the object domains concepts have very different structures.
 Thus, it is possible that the compatibility between the social domain and linear separability and the incompatibility between the object domain and linear separability might be limited to a subset of concepts within each of these domains.
 Experiment 1 In the Wattenmaker (m press) studies, the social categories were either traits (extroverted, cautious, etc.
) or occupations (lawyer, doctor, etc.
).
 In this experiment w e attempted to use social materials that had a very different structure.
 To accomplish this w e used social events as the social categories.
 Event categories such as political rally seem to be less abstract than trait categories such as extrovert, and the flexibility in interpretation that characterizes the processing of traits and behaviors seems to be greatly reduced with social events.
 Flexibility in interpretation and reliance on abstract representations rather than exemplars seem to be important factors for producing compatibility with linearly separable structures (see Wattenmaker, in press).
 Thus, the structure of social events might be much less compatible with linear separability.
 To investigate this possibility, participants were presented with descriptions of social events or descriptions of objects, and they were asked to divide the examples into two equalsized groups.
 Four pairs of social event categories and four pairs of object categories were used in the experiment.
 These categories are listed in Table 2.
 As an illustration of the features that were used, the rock concert vs.
 poetry reading events were represented by the following featiires: the audience was large vs.
 the audience was small; many members of the audience were intoxicated vs.
 few members of the audience were intoxicated; several people at the event were rude vs.
 most people at the event were polite; and the atmosphere for the event was jovial vs.
 the atmosphere for the event was serious.
 The first of each 777 mailto:william.
d.
wattenmaker@cyber.
widener.
eduof these pairs was associated with a rock concert and the second with a poetry reading.
 As an illustration of the object categories, the bird vs.
 not bird object categories were represented by the features: flies vs.
 does not fly, is light in weight vs.
 is heavy in weight; eats worms and insects vs.
 does not eat worms and insects; and builds a nest in a tree vs.
 does not build a nest in a tree.
 The first of each of these features was associated with the bird category.
 The social and object descriptions were constructed from the same underlying structure (represented by the abstract notation in Table 1), but this structure was represented by object or social characteristics.
 Consider, for example, the social task in which the relevant categories were rock concert vs.
 poetry reading.
 Each of the four contrasting features listed above was randomly assigned to one of the dimensions in Table 1 (e.
g.
, the contrast between a large vs.
 a small audience might be assigned to Dl), and the I's in Table 1 were represented by features of a rock concert whereas the O's were represented by features of a poetry reading.
 Thus, for one randomization, Exemplar 1 (1110) in Table 1 was represented as the audience was large, many members of the audience were intoxicated, several people at the event were rude, and the atmosphere for the event was serious; Exemplar 2 (1101) was represented as the audience was large, many members of the audience were intoxicated, most people at the event were polite, and the atmosphere for the event was jovial.
 Thus, in this condition the four examples on the left side of Table 1 had three features that were typical of a rock concert and only one feature that was typical of a poetry reading.
 Alternatively, the four examples on the right side of Table 1 had three features that were typical of a poetry reading and only one feature that was typical of a rock concert.
 The examples for the other three pairs of social event categories (listed in Table 2) were also constructed from Table 1 using this same procedure except that different features were used.
 Table 1: Abstract representation of the linearly separable categories used in Experiments 1 and 2.
 LINEARLY SEPARABLE CATEGORIES Category A Category B Dimension Dimension Exemplar Dl D2 D3 D4 Exemplar D i m m D l Al 1 1 1 0 Bl 0 0 0 1 A2 1 1 0 1 B2 0 0 1 0 A3 1 0 1 1 B3 0 1 0 0 A4 0 1 1 1 B4 1 0 0 0 For the object materials the I's and O's in Table 1 were represented by the features that were used to represent the object materials.
 For example, in the bird vs.
 not bird condition.
 Exemplar 1 (1110) v/as flies, light in weight, eats worms and insects, and does not build a nest in a tree; Exemplar 2 (1101) was flies, light in weight, does not eat worms and insects, and builds a nest in a tree.
 Thus, in this condition each example on the left side of Table 1 had three features that were typical of a bird and only one feature that was not typical of a bird.
 Alternatively, each example on the right side of Table 1 had three features that were not typical of a bird and only one feature that was typical of a bird.
 The examples for the other three pairs of object categories (listed in Table 2) were also constructed from Table 1 using this same procedure.
 For the social task participants were presented with 8 descriptions that were constructed from Table 1 using the procedure described above.
 The eight descriptions were constructed from either the rock concert/poetry reading features, the elevator/bar features, the football game/opera features, or from the political rally/movie features.
 Each subject received the descriptions from one of these category pairs.
 Likewise, for the object task participants were presented with 8 descriptions that were also constructed from Table 1.
 The eight descriptions were constructed from either the bird/nonbird features, the animal/furniture features, the screwdriver/hammer features, or the airplane/car features.
 In the object and the social task participants were given the relevant category labels (e.
g.
 rock concert vs.
 poetry reading labels) and asked to place four of the eight descriptions in one of the categories and the other four descriptions in the other category.
 Thus, in the rock concert vs.
 poetry reading condition, participants were asked to place four of the descriptions in the rock concert category and four of the descriptions in the poetry reading category.
 Likewise, in the bird vs.
 nonbird condition, participants were asked to place four of the descriptions in the bird category and four of the descriptions in the nonbird category.
 There are many possible ways to partition the examples represented in Table 1.
 If a strategy of summing characteristic features is natural, however, then Exemplars 14 would be placed in one category and Exemplars 58 would be placed in the other category.
 That is, Exemplars 1 4 all have three features that were typical of one of the categories (e.
g.
 rock concert) whereas Exemplars 58 all have three features that were typical of the other category (e.
g.
 poetry reading).
 Thus, if subjects adopt a strategy of summing the number of typical features, then Exemplars 14 will be placed in one category and Exemplars 58 will be placed in the other category.
 These categories would be linearly separable, and they would also be consistent with family resemblance and prototype notions.
 This particular pattern of sorting will be called a Summation sort.
 In prior experiments that used trait and occupation categories as social materials, many more Summation sorts were observed in the social than the object domain (Wattenmaker, in press).
 If these results generalize to other types of categories within the social domain, then there should be more Summation sorts for the social event materials than for the object materials.
 Method Each subject performed a social sort and an object sort.
 The first sort for half of the subjects was a social sort and the first sort for the other subjects was an object sort.
 Fifty subjects participated in the experiment.
 All the features that 778 were used in the experiment were rated to be clearly associated with the correct category (e.
g.
, most people at the event were polite was rated to be highly characteristic of poetry reading).
 All other aspects of the procedure were detailed above.
 Results and Discussion As indicated in Table 2, many more Summation sorts occurred with the social materials than the object materials (.
48 vs.
 .
12).
 A sign test indicated that this difference was highly significant (p <.
01).
 Table 2 reveals that there were large differences in the number of Summation sorts that occurred with the different social categories.
 Future work will be designed to examine exactly what was responsible for these differences.
 However, all four of the social sorts produced more Summation sorts than the object condition that had the highest number of Summation sorts (i.
e.
, the bird vs.
 nonbird condition), and in almost all cases these differences were very large.
 Thus, the differences between the objects and social event categories appear to be very reliable.
 Table 2: Results of Experiment 1.
 Social Evgnt$ Percentage pf Summation Sort? elevator/bar .
42 football game/opera .
54 rock concert/poetry reading .
29 political rally/movie .
73 Average for social events .
48 Qbjeets animal/fiimiture screwdriver/hammer bird/nonbird airplane/car .
15 .
07 .
18 .
08 Average for objects .
12 These results clearly indicate that even when social events are used as social materials people are more likely to sum features and form linearly separable categories in the social than the object domain.
 Thus the compatibility between linear separability and the social domain extends to many different types of social categories, and appears to represent a highly general domain effect.
 Experiment 2 Whereas Experiment 1 used different social materials than had been used in previous research, in this experiment w e attempted to use very different types of object materials.
 Specifically, in Experiment 1 and in all of the experiments reported in Wattenmaker (in press), the object categories were very familiar (birds, furniture, hammers, cars, etc.
).
 These types of object categories are not only very familiar, but they also represent fairly stable categories, they are clearly defined, and have many accessible exemplars.
 In contrast, social terms such as extroverted or cautious can be viewed as less stable, less structured, and to be more abstract.
 Thus, in this experiment w e attempted to design object categories that were less familiar, that did not have a clear structure, were more abstract, and in general, seemed to be more similar to trait categories.
 To accomplish this, w e used object categories that could be viewed as characteristics rather than stable categories.
 For example, in one case the object categories were fragile vs.
 not fragile.
 It is clearly possible to classify an object as fiagile or not, but in relation to concepts such as bird and hammer, fragile does not seem to represent a stable, familiar, and clearly defmed category.
 Indeed object categories of this type can be viewed as more parallel in structure to trait concepts.
 The complete set of object and social categories that were used in this experiment are shown in Table 3.
 As an illustration of the descriptions that were used for the object categories, the features for the fragile vs.
 not fragile categories were: made of glass vs.
 made of plastic; thin sides vs.
 thick sides; very light weight vs.
 medium weight; and very old vs.
 new.
 The first of each of these features was associated with the fragile category.
 The object and social sorts were again constructed from Table 1, using the procedure described in Experiment 1.
 These more abstract and less structured object categories might greatly increase the frequency of Summation sorts for object materials.
 If the differences that have been observed between object and social materials in previous research are attributable to the use of very familiar object categories, then an equal number of Summation sorts should be observed with the social and object materials.
 Alternatively, if the observed differences between object and social domains are highly general, then w e should find more Summation sorts with the social than the object materials.
 Method Each subject performed four sorts: two object and two social sorts.
 Half of the subjects did a social sort, an object sort, a social sort, and finally an object sort; this order was reversed for the other subjects.
 A total of 96 subjects participated in this experiment.
 As in Experiment 1, the features that were used to represent the categories were rated to be clearly associated with the correct category.
 All other aspects of the procedure were identical to Experiment 1.
 Results and Discussion The percentages for the social categories shown in Table 3 represent the percentages of Summation sorts that occurred when the social sort was the first sort a subject performed.
 Likewise, the percentages for the object categories represent the percentages of Summation sorts that occurred when the object sort was the first sort a subject performed.
 W h e n the results of the first, second, third, and fourth sorts were included, then overall 8 0 % of the social sorts were 779 Summation sorts and 5 4 % of the object sorts were Summation sorts.
 A sign test indicated that this difference was highly significant (p <.
01).
 Thus, even when very different object categories were used many more Summation sorts were again observed with social materials.
 Table 3: Results of Experiment 2.
 Social Categpries cautious/not cautious energetic/not energetic extroverted/not extroverted Average of first social sort Object Categories PerQent̂ g? of Summation Sorts from the first sort dangerous to handle/not dangerous to handle fi^gile/not fragile valuable/not valuable Average of first object sort .
83 .
83 .
83 .
83 .
50 .
17 .
67 .
45 Table 3 reveals that there were large differences in the number of Summation sorts that occurred with the different object categories.
 Future work will be designed to examine exactly what was responsible for these differences.
 However, all three of the social sorts produced more Summation sorts than the object condition that had the highest number of Summation sorts (i.
e.
, the valuable vs.
 notvaluable categories).
 Thus, the differences between the object and social categories appear to be very reliable.
 General Discussion In both experiments many more Summation sorts were observed with social materials than object materials.
 This occurred even though the social categories in Experiment 1 were selected to be incompatible with a summation strategy and linear separability, and the object categories in Experiment 2 were selected to be especially compatible with a summation strategy and linear separability.
 These results are consistent with the Wattenmaker (in press) results.
 In the Wattenmaker (in press) experiments, across seven sorting experiments a total of 201 Summation sorts occurred with social materials whereas only 97 Summation sorts occurred with object materials.
 In combination with the present results, these results suggest that the differences between the object and social domains are highly general.
 These differences between the object and social domains seem to reflect basic differences in the structure and nature of the domains.
 Objects are concrete, highly structured entities that are characterized by many different types of relational properties.
 In contrast, social concepts are abstract and the structure and organization of social concepts is less clear.
 Instead of representing concrete entities, social concepts are frequently based on interpretations, inferences, and constructions rather than direct or unambiguous perceptions.
 These basic differences in object and social domains appear to produce many differences in the structure of knowledge and in categorization processes.
 At a general level the results are consistent with the idea that background or world knowledge will have important influences on concept learning (e.
g.
 Murphy & Medin, 1985; Waldmann & Holyoak, 1990; Wattenmaker, etal, 1986).
 A clear implication of these results is that the naturalness or leamability of abstract structures will vary with domain.
 The structure of knowledge appears to vary with domain, and consequently abstract structures or principles such as linear separability will be more important in some domains than others.
 Acknowledgements This research was supported by National Institute of Mental Health Grant MH45585.
 I thank Stephanie Schwartz for technical assistance.
 References Gluck, M.
 A.
 & Bower, G.
 H.
 (1988).
 Evaluation and adaptive network model of human learning.
 Journal of Memory and Language, 2 7, 166195.
 Medin, D.
 L.
 & Schwanenflugel, P.
 J.
 (1981).
 Linear separability in classification learning.
 Journal of Experimental Psychology: Human Learning and Memory, 7, 355368.
 Murphy, G.
L.
 & Medin, D.
L.
 (1985).
 The role of theories in conceptual coherence.
 Psychological Review, 92, 289316.
 Nilsson, N.
J.
 (1965).
 McGraw Hill.
 Learning machines.
 New York: Waldmann, M.
 R.
 & Holyoak, K.
 J.
 (1990).
 Can causal induction be reduced to associative learning? Proceedings of the Twelfth Annual Conference of the Cognitive Science Society (pp.
 190197).
 Hillsdale, NJ: Lawrence Erlbaum Associates.
 Wattenmaker, W.
 D.
, Dewey, G.
 I.
, Murphy, T.
 D.
, & Medin, D.
 L.
 (1986).
 Linear separability and concept learning: Context, relationship properties, and concept naturalness.
 Cognitive Psychology, 18, 158194.
 Wattenmaker, W.
 D.
 (In press).
 Knowledge structures and linear separability: Integrating information in object and social categorization.
 Cognitive Psychology.
 780 Does Metaspace Theory Explain Insight? David F.
 Wolf n Philosophy Department SUNY at Albany Albany, NY 12222 dw4570@cnsunix.
albany.
edu Jonathan Beskin Eric Dietrich PACCS Program in Philosophy Binghamton University Binghamton, NY 139026000 nojQturing.
pacss,binghamton.
edu dietrichScrow.
pacss.
binghamton.
edu Abstract Previous computational theories of problem solving have not accounted for the occasional display of accelerated problem solving by humans working on conceptually hard problems.
 Researchers refer to this behavior as insight.
 Kaplan and Simon describe insight as the selection of a good representation of the problem by the problem solver.
 They propose a dualstate space theory, metaspace theory, to explain insight (lO^lan and Simon, 1990).
 W e show that metaspace theory is unfalsifiable.
 W e then show that the nature of metaspace theory makes it superfluous for the study of human problem solving.
 Introduction Traditional heuristic search space theories cannot account for insight in creative problem solving (Boden, 1988).
 'Insight', is the accelerated rate of problem solving that occurs once the problem soIvct selects a good representation (Kaplan and Simon 1990).
 To explain bow humans select these representations.
 Yiaplaa and Simon employ a dual search space schema.
 Their dualspace architecture consists of a metalevel space whose nodes are themselves possible problem spaces.
 The metalevel space is also a type of problem space, so w e begin with a brief review of heuristic search space theory.
 W e then breifly discuss the importance of representations in creative problem solving.
 Finally, w e argue that search space theory is unfalsifiable and hence unnecessary as a theory of human problem solving.
 Heuristic Search Space Theory Researchers in the paradigm of heuristic search space theory think of problems as problem spaces.
 The 3tuple < 0 , G, I> describes a problem space where: O = a set of operations.
 These specify the rules that enable a state to be transformed into another state.
 G = a set of goal states.
 These states are acceptable as a solution to the problem.
 I = a set of initial states.
 These states describe all the possible starting situations for the problem solving process.
 A problem space consists of all the possible states that the operations can generate from the initial states.
 A problem space is like a mathematical tree in which the root node is the initial state, the nodes are possible states, and the leaves are states on which no further operation apply.
 The set of goal states, G, is a subset of those leaves.
 Heuristic search space theory's basic assumption is that problem solvers search problem spaces.
 Starting at an initial state, problem solvers search for a goal state.
 The 3tuple <D, O, C > defmes a problem solver where: D = a knowledge base that consists of one or more data bases with information £^propriate to a particular task and about the desired goal states.
 The primitives to create spaces for a search are also in the knowledge base.
 O = a set of opo'ations.
 These rules are the options the problem solver m a y poform on any given state.
 These are the same operations as in the definition of the problem space.
 C = a control strategy.
 This selects what operator to apply to the current state.
 It does this by assigning values to the possible states and selects the state that has the best value assigned to iL The control strategy also resolves conflicts that m a y occur from the selection.
 The problem solver creates a search tree to find a path from the initial states to one of the goal states (see Figure 1).
 It accomplishes this by applying operators to the current states.
 This determines all the possible states that could result from the current one.
 The control strategy, C, rates the desirability of these possibilities.
 The state with the most favorable rating will determine which operator, and thereby which state, to select next A n important aspect of heuristic search space theory is the notion of heuristics.
 Heuristics are imperfect problem solving processes that often work.
 Although heuristics do not guarentee a solution, they can solve problems that are otherwise intractable.
 For example, the average game of chess consists of approximately forty moves by each player.
 Its problem space consists of 10"' states.
 A million computers searching a million nodes a second would still require 10'° °  years to search the problem space chess creates.
 Problem spaces like these must be pruned to make 781 mailto:dw4570@cnsunix.
albany.
eduinitial sUlc goalsute Figure 1: Above is a small problem space.
 The darkened lines identify the search tree, which traces a portion of the problem solver's path.
 In this figure the search tree was created by a depthfirst search procedure.
 ' them tractable.
 Heuristics exist in two places within the problem solver.
 They are explicit within the control strategy, C, and are implicit within the set of operations, O.
 These 'rules o( thumb' help the iMX)blem solver streamline its search by eliminating undesirable options from the search.
 Traditionally, each problem space designated one way that a problem solver could characterize a problem.
 Real w(xld problem soIvcts often use multiple representations to s(dve problems.
 For example, when faced with problems that would require an unreasonable amount of search time, people first attempt to change the problem's representation (Sinnott, 1989).
 The reason for this is tiiat an appropriate representation emphasizes relevant featives of the problem, and can drastically reduce the time to solve the problem (Kaplan and Simon, 1990).
 However, this is a secondary feature of representations.
 For many problems, only a small number of representations provide solutions.
 Furthermore.
 some very hard problons cannot be solved without the use of several representations (Minsky, 1991).
 Any flexible problem solving system must be capable of generating multiple representations.
 Heuristic search space theory does not account for representations in problem solving.
 Instead, Newell and Simon state that the theory explains problem solving after a representation is selected (1972).
 Later they suggest tiiat problem solving occurs in one large problem space that incorporates all the representations of the problem (Newell and Simon, 1976).
 However, this explanation of representations cannot account for the ability to r^idly change representations.
 Previous research suggests that complex problons require dual search spaces (Simon and Lea, 1974).
 In dual space framewoilcs, one space contains possible hypoUieses, and each hypothesis is itself a search ^>ace for investigating the hypothesis.
 K^^lan and Simon (1990) rely on Uiis dualspace technique to account for the use of multiple representations in human problem solving.
 Metaspace Theory Kaplan and Simon's dualspace architecture consists of a metalevel space and a set of representation problem spaces.
 They argue that insight occurs in the metaspace.
' The metaspace is a problem space where each node is a unique representation of the problem in the form of a problem space.
 The problem solver in metaspace theory behaves similarly to its counterpart in heuristic search space theory.
 It traverses tiie metaspace searching for a representation that will solve the problem.
 Metaheuristics improve search by pruning the metaspace.
 The four currentiy hypothesized metaheuristics are: Try a Switch, Notice Invariants, Form Hypothesis, and Compare Alternatives (Kaplan and Simon, 1990, p.
 381,402).
 Once Uie problem solver selects a node in the metaspace it enters the search space that Uiat representation creates.
 The problem solver now searches tiiis problon space for a solution to the problem.
 If no operators within the problem space seem to lead to a successftil solution, the problem solver abandons the representation.
^ It then continues its search within the metaspace (see Figure 2).
 A metaspace that could account for any possible representation would be infmite and thereby not computable by fmite beings in a fmite amount of time.
 According to Kaplan and Simon (1990), humans "are not equipped with generators for searching the space of 'all possible representations'" (p.
 403).
 Rather, humans have a subset of these generators.
 Even so, this smaller set of generators must still be vast to accomodate all the representations that humans might use.
 At the moment, the boundaries of this set are unknown, although some representations and metaheuristics are known to be used for some problems (Kaplan and Simon, 1990).
 Problems with Metaspace Theory W e claim that metaspace theory is unfalisifiable.
 This means that no possiUe data about bow humans solve problems can falsify it Given time to analyze a subject's solution to a problem, metaspace theory can always provide an explanation of that solution.
 Therefore, metaspace theory is compatible with any data, no matter bow surprizing, about the way humans solve problems.
 Hence, metaspace theory makes no predictions, and rules out no possibilities.
 It is therefore vacuous; it says nothing about human problem solving.
 W e argue that to make metaspace theory useful to psychology, K^lan and Simon require a theory of problem solving independent of the metaspace framework.
 ' Kaplan and Simon refer to the second space as the metalevel space.
 For brevity, w e refer to it as the metaspace.
 ' Kaplan and Simon have not fully defined this procedure.
 They do suggest that the amount of time spent in the problem space is often a relevant factor (Kaplan and Simon, 1990: p.
 377).
 782 first representation second representation Figure 2: The metaspace is a problem space that contains all possible representations of a given problem.
 It is a search ^ace with each node containing a search space that represents the problem differently.
 The problem solver searches the metaspace for a representation.
 W h e n it selects a node, it enters the search space that that representaion creates and searches for a solution.
 If the operators of this search space do not seem to solve the problem, then the problem solver returns to the metaspace to search for another representation.
 A good theory of problem solving should answer five questions: l)How do subjects think about problems, i.
e.
, what mental representations do subjects use? 2)How do subjects produce and select representations? 3) H o w do subjects use selected representations to solve problems? 4)How do subjects decide when a representation is not working, and what do they then do? S)What information is retained from representation to representation? Metaspace theory fails to answer any of these questions.
 At best, metaspace theory must leave these questions open for future research.
 In short, metaspace theory is best described as a.
 framework for studying problem solving, not a theory of problem solving.
 This framework is reducible to a single simple tenet; viz.
 problem solving is the process of searching for a representation in a metaspace, and then searching selected representations for a solution.
 Kaplan and Simon (1990) hnpUdtly agree that metasp^x theory is a framework for studying probl^n solving.
 Rather than claiming that metaspace theory is a completed theory, they advocate a research program of exploring the representations and metaheuristics that subjects use to solve problems.
 "[Wc] must discover how subjects constrain their search for a new representatioii when the initial one does not suffice, and how the new representation constrains their search for the solution.
 W e must also discover what triggers subjects to shift irom searching for a problem solution to searching for a better problem space in which to conduct the solution search.
" (Kaplan and Simon, 1990: p.
 377) The information that Kaplan and Simon say researcbo^ still need to discovo is the same information that constitutes a theory of problem solving.
 Thus, a researcher can rewrite any theory of problem solving in terms of metaspace theory, including a theory that does not allow for representational change at all.
 To see this, note that one could characterize such a theory as a metaspace with only one node.
 This universal compatibility makes metaspace theory unfalsifiable, and therefore vacuous.
 Some might think metaspace theory is not unfalsifiable, but merely flexible and that this flexibility is a strength.
 One could argue that Kaplan and Simon left the ftamewoik of metaspace open to accommodate any possible future research.
 However, this is not a strength, but a weakness.
 In an attempt to make metaq)ace theory general enough to explain all protAem solving, it fails to explain any problem solving.
 A researcher can account for any experimental results, no matter how surprising, within the metaspace framework by inserting the ^i»x)priate ad hoc representation or metaheuristic.
 There is nothing in the theory to stqj a researcher from adding a new metaheuristic for each observed anomaly in the data as we unravel how humans solve problons.
 A theoiy that does not constrain research also does not provide any guidelines for future exploration.
 A fecund, productive, theory suggests some avenues of research, and denies others.
 A theory's success depends on how well these avenues predict observable behavior, in contrast to bow well other avenues predia the same behavior.
 As an example (̂  a productive theory, consider the case of Rutherford and his "mini solar system" model of the atom.
 Rutherford was a student o( J.
 J.
 Thomson.
 At the turn of the century, Thomson had the best model of the atom, called simply the Thomson model.
 This model was also referred to as the plumpudding model, since it viewed the atom as a large positively charged ball with negatively charged electrons snick in it, like plums in a pudding.
 The Thomson model predicted that alpha particles shot at an atom would not be scattered or deflected from their original path, but would instead pass right through.
 Ruthoford, Geiger, and Marsden performed this experiment in 1909 and discovered, to their amazement, that the alpha particles were scattered every which way.
 The Thomson model bad to be false, some other model had to be correct This was when Rutherford started developing his solar system model, or nuclear model, which concentrated most of the mass of the atom in the nucleus.
 Such a model explains the 783 scattering results.
 Notice the difference with metaspace theory.
 Metaspace theory makes no predictions that might be false.
 The Thcnnson model of the atom was fecund; it guided Rutheiford in desigiting a test of its veracity.
 In stark constrast, unfalsifiable theories, like metaspace theory, are not fecund and do not guide the researcher in any significant way.
' Because the framework offered by metaspace does not guide the researcher, it is useless for problem solving research.
 If a researcher answered all five questions presented above, those answers would alone constitute a theory of problem solving.
 This makes metaspace theory a useless shell, even as a framework.
 This is further evidence that metaspace theory is unfalsifiable.
 Anything that a researcher might say about problem solvers and their strategies can be said irrespective of whether or not one adopts the metaspace architecture.
 The Notice Invariants heuristic is an excellent example.
 This heuristic informs subjects to pay attention to features of the problem that do not change between representations (Kaplan and Simon, 1990: p.
 404f0.
 Kaplan and Simon show that the subjects that solved the mutilated checkerboard problem quickly were ones w h o noticed relevant perceptual invariants sooner.
 These subjects also noticed a wider range of invariants.
 More specifically, the data indicates that fast subjects usually noticed that a domino covers squares of different types (one black and one white), while the two missing squares are of the same color.
 Kaplan and Simon refer to this feature of the mutilated checkerboard problon i& parity.
 The results of the Notice Invariants experiments are important to the understanding of general problem solving regardless of the status of metaspace theory.
 In fact, the Notice Invariants heuristics could have been proposed by psychologists w h o never thought in terms of search spaces, but rather only in terms of constructed representations and representational change.
 This does not logically require any version of search space theory.
* The hypothesis that noticing invariants is important to solving problems suggests future research.
 One possible implication of the data is that it appeared to be more important for subjects to iH>tice invariants between representations than to use any specific representation.
 Noticing the parity feature ahnost invariably led to representations that used this feature to iwove the problem impossible.
 O n e viable interpretation is that the solution representation was merely a vehicle that the subject used to highlight the parity feature.
 If this is the case, then subjects that have not noticed the importance of the parity feature should have a hard time solving the problem even if they are told which representation to use.
 Notice that the research on the Notice Invariants heuristic immediately implies additional experiments and hypotheses to test This line of research constitutes a potential theory of problem solving without any need for metaspace theory.
 As limited as this 'Notice Invariants theoiy' might be, it is much more productive than metaspace theory can ever be.
 In contrast, metaspace theory suggests no research, because it is compatible with any possible theory.
 All that metaspace theory does is provide additional work for the cognitive scientist, who must restate their data in terms of search spaces.
 Cognitive scientists should reject metaspace theory as excess baggage, while retaining the psychological research that investigators of problem solving, such as Kaplan and Simon, have produced.
 At this point w e wish to block the possible objection that w e have ignored evidence in support of metaspace theory.
 Kaplan and Simon (1990: p.
 412) claim that search space theory, "is supported by a substantial body of empirical data".
 Their evidence for this claims comes from interpreting all occurrences of changing representation as search within a metaspace (Kaplan and Simon, p.
 3767).
 If, as w e argued earlier, metaspace theory is unfalsifiable, then no evidence can confirm it.
 N o amount of positive evidence can ever absolutely confirm any theory.
 Rather, one confirms a theoiy by testing it against rival theories (Aronson, 1984: p.
 377fO.
 Rival theories cannot both be true over the same body of data, so an experiment confirms one theory in part by disconfinning an alternate theory.
^ To make this work, the theories must make opposite predictions with regard to the experiment Depending on the outcome of the experiment, one theoiy is correct and the other is wrong.
 This means that an experiment confirms a theoiy only if, by failing, it could potentially disconfirm the theory.
 A theoiy that was compatible with both outcomes of an experiment would not be confirmed by either outcome.
 By definition, an unfalsifiable theoiy is compatible with all potential outcomes.
 Therefore, no amount of evidence could ever confirm an unfalsifiable theory, such as metaspace theory.
 Kaplan and Simon present data that is compatible with metaspace theory, not confirmation of the theory.
 ̂  Conclusion W e showed that the metaspace framework is unfalsifiable.
 Fundamentally, metaspace theory is a theory of selecting representations, when what w e need is a theory of bow representations are constructed during problem solving.
 Cognitive science should therefore jettison it from research on human problem solving.
 Such theories do not inform psychologists, and usually only serve to cloud the issues.
 The only way to make the theory useful for psychology would be to develop a new theoiy of problon solving independent of the metaspace framewoik.
 The ' For more on the importance of fecundity, see Kitcher (1992: pp.
 47  49).
 * A deeper point here is that the researcher could also have produced the Notice Invariants heuristic by analogy to heuristic search space theory without ever using metaspace theory.
 * Already we note a problem as metaspace theory cannot have any rival theories.
 It is compatible with all potential theories of problem solving.
 * Note that while there is evidence in support of the various metaheuristics that Kaplan and Simon (1990) investigate, this does not constitute evidence in favor of metaspace theory.
 Individual metaheuristics are falsifiable, and therefore can be confirmed by experiment Metaspace theory is not falsifiable, and cannot be confirmed.
 784 information metaspace thewy lacks is itself a complete theory of human problem solving.
 Thus, metaspace theory, even as a framework, is a superfluous shell.
 This rejection of metaspace theory does not entail a rejection of all computational theories of psychology.
 On the contrary, we bold that computational theories of psychology are good methodologies for research.
 Examples of good computational theories that are highly informative and subject to falsification are Dedre Gentner's Structure Mapping Engine program in analogy (Centner 1983; Falenhainer, Foibus, and Centner, 1986, 1989) and Stephen Kosslyn's work on mental imagery (Kosslyn, 1994).
 These ^proaches are falsiflable, informative, and consequently important to the field of psychology.
 W e reject metaspace theory, not because it is computational, but because it is useless for the study of problem solving.
 References Barr, A.
 and Feigenbaum, E.
 (1981).
 TTie Handbook to Artificial Intelligence, vol.
 1.
 Los Altos: William Kaufmann Inc.
 Boden, M.
 (1988).
 Computer Models of Mind.
 Cambridge.
 Cambridge University Press.
 Falkenhainer, B.
.
 Forbus, K.
 D.
, and Centner, D.
 (1986).
 "The structuremapping engine".
 Proceedings of the American Association for Artificial Intelligence (pp.
 272277), Philadelphia.
 Falkenhainer, B.
.
 Forbus, K.
 D.
, and Centner.
 D.
 (1989).
 "The StructureMapping Engine: algorithm and examples".
 Artifical Intelligence 41:163.
 Centner, D.
 (1983).
 "Structuremapping: A theoretical framework for analogy".
 Cognitive Science 7:155170.
 Kaplan, C.
 and Simon, H.
 (1990).
 "In Search of Insight".
 Cognitive Psychology 22: 374419.
 Kitcher, P (1992).
 Abusing Science: The Case Against Creationism, Cambridge, M A : M I T Press.
 Kosslyn, S.
 (1994).
 Image and Brain.
 Cambridge, M A : MIT Press.
 Minsky, M .
 (1991).
 "Logical verses Analogical or Symbolic verses Connectionist or Neats verses Scruffy".
 AI Magazine 12: 3551.
 Newell, A.
 and Simon, H.
 (1972).
 Human Problem Solving.
 N e w Jersey: PrenticeHall.
 Newell, A.
 and Simon, H.
 (1976).
 "Computer Science as Empirical Enquiry: Symbols and Search".
 The Tenth Turing Lecture, first published in Communication of the Association of Computing Machinery 19.
 Simon, H.
 and Lea, C.
 (1974).
 "Problem Solving and Rule Induction: A Unified View" in Kiwwledge and Cognition.
 Gregg, L (Ed.
).
 Hillsdale: Lawrence Erlbaum Associates.
 Sinnott, J.
 (1989).
 "A Model for Solutions of Ulstructured Problems: Implications for Everyday and Abstract Problem Solving" in Everyday Problem Solving.
 Sinnott (Ed.
).
 N e w Yoric: PreagCT Publishers.
 785 Effects of CategoryLearning on Categorization A n Analysis of InferenceBased and ClassificationBased Learning Takashi Yamauchi Psychology Department Columbia University New York, NY 10027 takashi@psych.
Columbia.
edu Arthur B.
 Markman Psychology Department Columbia University New York, NY 10027 mar)anan(ipsych.
 Columbia.
 edu Abstract It is widely acknowledged that categories have many functions, but few studies have actually addressed the impact of these functions on the way categories are learned.
 For instance, many categorization experiments predominantly rely on classificationbased incremental learning.
 The problem with this approach is that it implicitly assumes that the function of categorization is separable from the way that categories are learned.
 In this study, we examined the relation between learning and the subsequent use of categories by contrasting three types of categorylearning methods — inferencebased, classificationbased, and a combination of these methods.
 The results of the experiment indicate that there is an intricate relationship between categorylearning and subsequent use of the category.
 The results further suggest that different processing modes may have been adopted by subjects in the different learning conditions.
 The use of categories in a natural setting encompasses diverse functions including communication, analysis, comprehension, inference and comparison.
 A n art historian, for instance, classifies paintings based on their artistic styles, and forms categories such as Gothic, Baroque, Rococo and Romanticism in order to analyze the difference between them.
 Categories m ay be formed for inference as well.
 A person m a y be classified as a Democrat or a Republican by considering her stand on abortion: Similarly, her political affiliation m ay be determined by reflecting on her personality.
 A s these examples illustrate, categories serve various cognitive functions.
 Despite the multifaceted use of categories, classification has been the dominant procedure employed to study categories (though, see Estes (1994) for some alternatives).
 A typical categorization experiment consists of two parts, a learning and a transfer phase.
 During learning, subjects are taught to classify stimuli into groups.
 Following learning, other measures of category structure like typicality ratings are used.
 This regular paradigm is based on the two assumptions: (1) the characteristics of category acquisition can be reliably measured by examining subjects' behavior in a classification task; (2) categorization processes are independent of the context in which the categories are learned.
 The potential danger in this research strategy is that category learning, when reduced to the acquisition of category names, m ay bear little resemblance to the acquisition of natural categories.
 While the representation of categories acquired through classification learning alone may be rich enough to support multiple functions of category use, it is also possible that the manner in which we use a category affects what is learned about it.
 In other words, the type of processing and representation used for category functions m a y be partly determined by the characteristics of learning.
 There is some work that is consistent with the hypothesized link between the way categories are learned and what is acquired.
 Medin and Smith (1981) showed that different strategies adopted during a learning period resulted in qualitatively different performance in a transfer task.
 Elio and Anderson (1984) demonstrated that characteristics of stimulus presentation interacted with analytic and nonanalytic modes of category processing.
 If the nature of categorization is determined by the characteristics of category learning, the mechanism of categorization cannot be adequately explained without analyzing the relation between category learning and the subsequent representation of categories.
 The purpose of this study is to investigate the relationship between category learning and subsequent mechanisms of category use by introducing a new inferencebased learning method.
 A m o n g the many functions of categories, inference plays a central role (Anderson, 1990; Heit 1993; Holland, Holyoak, Nisbett & Thagard, 1986; Murphy & Ross, 1994; Rosch, 1976).
 Holland et al.
 (1986) point out that categories function to give goalrelevant expectations about instances, and Murphy and Medin (1985) suggest that categories are obtained as a consequence of inference, implying an alternative method to study categorization.
 W e compared three types of learning procedures — standard classificationbased learning, inferencebased learning, and a mixture of classification and inference learning.
 In so doing, w e examined the effects produced by inference and classification learning on the system of categorization.
 The learning phase of this study consists of one of three learning conditions — Inferenceonly, Classificationonly, or InferenceandClassification conditions.
 The Classificationonly condition is equivalent to a standard 786 mailto:takashi@psych.
Columbia.
eduIf this figure is in Set A, then the item is either Large or Small.
 Is this figure in Set A or Set B? Is this item Large or Small? Figure 1: (a) A sample stimulus used in the experiment.
 (b) A sample stimulus used in a CriticalFeature inference.
 The choice of a subject reflects either the prototype stimulus (AO — large circle) or the exemplar (A3 — small circle).
 categorylearning format; subjects view a stimulus and classify it with feedback given after each trial.
 In the Inferenceonly condition, subjects are instructed to infer one of two feature values of a stimulus along some dimension given its category label and other feature information.
 For instance in Figure lb, the stimulus is drawn with a specific form, position and color, but the size of the figure must be inferred.
 The InferenceandClassification condition is a mixture of the two described above.
 E x p e r i m e n t Method Participants.
 Seventytwo subjects participated in this study (24 in each condition).
 They were recruited from the Columbia University community and were paid $6.
00 for their participation.
 Materials.
 The stimuli used for this experiment were like those used in the first experiment of Medin and Schaffer's (1978) studies.
 Specifically, the stimuli were geometric figures having four feature dimensions — form, color, size and position (Figure 1).
 The figure was placed on the left or the right side of a 20.
3 x 17.
4 cm rectangular frame drawn with a solid black line on the computer screen.
 The structure of the two categories is illustrated in Table 1 (see Medin, Wattenmaker & Hampson, 1987).
 Eight stimuli (A1A4, B1B4) were divided into two categories.
 As the figure shows, each category is predominant in one of the two values.
 None of the stimuli, however, perfectly matches the dominant value of each category, so that no single feature can unambiguously determine the category division.
 The stimuli AO and BO, which share the most common values with their category members, and the least common values with the contrasting category, can be considered prototypes of each category.
 These stimuli appeared only in the transfer tasks.
 Procedure.
 The basic procedure of the experiment involved three phases — an initial learning phase, a distractor task and a final transfer phase.
 Table 1.
 Category structure used for the experiment.
 F, S, C, and P stand for the four feature dimensions — form, size, color and position respectively, each of which has binary feature values — (1,0) = F(circle, triangle), S(large, small), C(red, green) and P(left, right).
 The stimuli, A1A4 and BlB4, were shown in the learning task.
 All the stimuli, AOA 4 and B0B4 were shown in the transfer phase.
 The values typed with the bold format were called "Criticalfeatures.
" Set A Set B A1 A2 A3 A4 F 1 1 1 0 s 1 1 0 1 c 1 0 1 1 p 0 1 1 1 B1 82 83 84 F 0 0 0 1 s 0 0 1 0 c 0 1 0 0 p 1 0 0 0 AO 1 1 1 1 80 0 0 0 In the initial learning phase, subjects were randomly assigned to one of three experimental conditions — Classificationonly, Inferenceonly and InferenceandClassification.
 For all the three conditions, the entire learning phase consisted of 18 blocks with 8 trials in each block.
 Each stimulus appeared once in each block.
 The order of stimulus presentation was determined randomly.
 In the Classificationonly condition, subjects were shown one of the eight stimuli and were asked to indicate the category to which it belonged by clicking a button with the mouse.
 Initially, no information about the category division was given to subjects; and so subjects had to guess.
 Following subjects' response, feedback was provided; the stimulus and the feedback remained on the screen for three seconds after their response.
 Subjects in the Inferenceonly condition were asked to infer the value of one of the four features of an item given its category label and information about the other three features.
 The stimuli in this condition were depicted with four features — form, color, size and position.
 However, on each trial the value of one feature was unspecified.
 For instance, on a given trial the color of the stimulus might be missing while the other three features and the category label were completely specified.
 On another trial, the size of one stimulus could be left unspecified while all the other information was provided (Figure lb).
 At the onset of a trial, a stimulus was displayed on the screen, and subjects chose one of two values of the missing feature by clicking one of two labeled buttons with the mouse.
 In this study, subjects answered all the feature questions related to each stimulus except for the questions associated with the "exception value" (e.
g.
 the feature value 0 in the category containing predominantly ls).
l For instance, in the stimulus Al, the feature inferences about form, color, and These questions were removed from the learning phase to be used for the Criticalfeature transfer task.
 The detail of this transfer task (Criticalfeature inference task) is described at the end of Procedure section.
 787 Classification o 0) 1 X 5 0.
9Q.
 0.
60.
5 H Infcrencconly I ] InlbrenceandClassificalion ^ Classificationonly Inference Old Stimuli Prototypes Figure 2: The performance for the classification.
 size were asked but the inference about position was omitted.
 The InferenceandClassification condition was a mixture of classification and inference blocks.
 Half of the learning blocks were inference trials, and the remaining were classification.
 T h e order of blocks was determined randomly.
 Following the learning trials, all the subjects participated in a distractor task in which they judged the pronounceability of nonsense words.
 This phase lasted about ten minutes.
 After the distractor phase, subjects participated in the transfer tasks, which were the same for all groups.
 In this phase, both classification and inference tasks were given.
 Subjects were asked to m a k e their decisions based on the categories learned during the initial phase.
 First, subjects were shown ten stimuli in sequence: the eight old stimuli that appeared in the learning phase and two new prototype stimuli (AO and BO).
 They classified each stimulus without feedback.
 They also indicated whether they had seen the stimulus during the learning trials.
^ Following the classification test, subjects proceeded to the inference task in which they inferred the value of one of four features of stimulus given its category label and other three features.
 They performed all possible feature inferences.
 N o feedback was given during the transfer.
 The entire experiment took 30 to 40 minutes.
 Four dependent measures served for our analyses — learning rate of three learning conditions, classification and inference performance, and Criticalfeature inference.
 Learning rate of three learning conditions was measured by calculating the average performance in the last three blocks 2 W e collected the recognition performance data of the subjects on an exploratory basis.
 Because this experiment was not designed to survey recognition performance (i.
e.
, there were only two new stimuli out of ten stimuli), the data did not yield any meaningful results for further analyses.
 I Inferenceonly LJ InferenceandClassification Classificationonh o 0.
9Q.
 0.
6Old Stimuli Critical features Figure 3: The performance for the feature inference.
 The ordinate of the Criticalfeature measure stands for the proportion of prototypeaccordance feature inference.
 in the learning phase.
 The performance of classification and inference was obtained from the transfer task in which all the subjects were exposed to the identical tasks.
 O f the four dependent variables, the special dependent measure, the Criticalfeature inference, needs a further explanation.
 The Criticalfeatures, which are typed with the bold format in Table 1, constitute the irregular values of each category.
 For instance, the values of all the features in Set A are 1 except the values of the Criticalfeatures which are 0.
 In the Criticalfeature inference trials, subjects made inferences to these "excepfion features".
 For instance, in stimulus A l subjects were presented the information about form, size and color but the value of position was left for subjects to infer.
 There are two possible choices in A l , 1 or 0 (left or right).
 A choice of 0 would match the actual exemplar (Al), but a choice of 1 would be congruous with the prototype of the category (AO).
 In other words, inferences based on the exemplar learned would lead subjects to choose 0, but inferences based on the prototype of the category would lead subjects to choose 1.
 Consequently, the choice of feature values on these trials m a y indicate h o w the inferences were made.
 Results The central results of this experiment are illustrated in Figures 2 and 3.
 All dependent measures were analyzed with oneway A N O V A s .
 In order to ensure that the pattern of the observed responses was not a simple reflection of the learning level associated with each condition, w e examined the data separately for all the subjects w h o averaged above 9 0 % correct responses in the last three blocks of the learning trials.
 First, w e analyzed the learning rate for each condition by calculating the average performance in the last three blocks in the learning phase.
 The data showed that the subjects in the Inferenceonly condition obtained a higher 788 learning rate (m= 93.
3%) than did the subjects in either the InferenceandCIassification condition (m= 80.
2%) or the Classificationonly condition (m= 85.
4%); F(2, 69) = 2.
795, p < 0.
07.
 Planned comparisons after the Bonfcronni adjustment indicated that the difference between the Inferenceonly and the InferenceandClassification condition was marginally significant; t(46) = 2.
01, p < 0.
08.
 N o other comparisons approached significance.
 Overall, 19 subjects in the Inferenceonly condition averaged above 9 0 % in the last three blocks of the learning phase, 10 subjects reached this criterion in the InferenceandClassification condition, and 15 subjects reached this criterion in the Classificationonly condition.
 The classification transfer results are shown in Figure 2.
 Unsurprisingly, the data revealed that subjects in the Classificationonly condition classified the old stimuli more accurately (m=87.
5%) than did the subjects in the InferenceandClassification (m=81.
8%) and in the Inferenceonly condition (m=81.
3%).
 Interestingly this difference was not significant; F(2, 69) < 1.
 The same measure of the performance in the subjects above 9 0 % of learning level showed a similar trend: Classificationonly (m= 9 5 % ) , InferenceandClassification (m= 93.
8%) and Inferenceonly (m= 86.
8%).
 As shown in Figure 2, all three groups were quite accurate in classifying prototype stimuli.
 The inference performance for old stimuli indicated that the subjects in the Inferenceonly condition predicted feature values of old stimuli more accurately (m= 94.
4%) than did the subjects in the InferenceandClassification (m= 86.
3%) or in the Classificationonly condition (m= 78.
5%); F(2, 69) = 4.
54, p< 0.
02.
 Planned comparisons revealed a significant difference between the Inferenceonly and the Classificationonly condition; t(46) = 2.
68, p< 0.
05.
 N o other differences reached significance.
 The performance of the subjects above a 9 0 % learning level showed a similar pattern; Inferenceonly (m= 99.
3%), InferenceandClassification (m= 97.
5%) and Classificationonly (m= 87.
2%).
 The differences observed in the three learning conditions clearly reflect the impact of particular types of categorylearning on the transfer task.
 The results obtained in the Criticalfeature inference task suggested that inferences were made in accordance with the prototype more often than would be expected by chance for all three conditions.
 However, the subjects in the Inferenceonly condition tended to select feature values in accordance with the prototypes (m=91.
1%) more often than did the subjects in the InferenceandClassification (m=71.
9%) or in the Inferenceonly condition (m= 71.
9%); F(l, 69) = 4.
36, p < 0.
02.
 Planned comparisons after the Bonferroni adjustment showed that the difference between the Inferenceonly and the Classificationonly condition as well as the difference between the Inferenceonly and the InferenceandClassification condition were significant, respectively; t(46) = 2.
295, p < 0.
05 (Figure 3).
^ The performance of the subjects above a 9 0 % learning level showed a similar trend; Inferenceonly (m= 94.
7%), InferenceandClassification (m= 80%) and Classificationonly (m= 0.
75.
8%).
 General Discussion This experiment suggests that there is an intricate relationship between category learning and subsequent transfer tasks.
 First, all learning conditions provided subjects with some ability to use categories flexibly beyond the manner in which they were learned.
 Subjects in the Classificationonly condition could still perform the inference task at an abovechance level, and subjects in the inference condition could perform the classification task at an abovechance level.
 These results reveal that both classification and inference learning lead to a representation flexible enough to cope with different cognitive tasks.
 Despite the fact that all the learning conditions led to abovechance levels performance in both classification and inference tasks, performance in transfer tasks was generally better when the learning task matched the transfer task.
 It may be the case that each learning condition induced subjects to adopt different processing modes in the transfer tasks.
 The results of this experiment were not consistent with the view that the category label is just another feature of the category and that classifying an exemplar is equivalent to inferring the label given the other features (e.
g.
, Anderson, 1990).
 In particular, the mixed inference and classification learning task was much more difficult than the inference based learning task.
 If classification involved just another inference, then these tasks should not reveal so great a difference in difficulty.
 The results of Criticalfeature inference trials provide an opportunity to examine the kinds of representations used as the basis of inferences.
 Strikingly, in all conditions, subjects' Criticalfeature inferences were congruent with the prototypes, even though the actual exemplars seen suggested the opposite response.
 The level of prototype responding was highest in the conditions involving inference during learning.
 Whether this performance reflects a bias toward prototype formation in learning tasks involving inference, or simply better performance by subjects w h o did inference trials during learning is an open research question.
 This sttidy raises a number of interesting questions for further resear&h.
 Categorization studies so far have been dominated by a claSsificationbased learning format.
 A s shown in this experiment, the performance in the transfer tasks mirrored the method adopted in learning.
 Thus when categories are learned and examined by classification tasks alone, the obtained results may embody characteristics two.
 Subjects in the InferenceandClassification condition inferred the feature values of old stimuli 86.
3% of the time.
 This number is significantly higher than their performance in the Criticalfeature inference, (m= 71.
9%); t(46) = 2.
21, p < 0.
02.
 ^ The difference between the Inferenceonly and the InferenceandClassification condition cannot be solely attributable to the overall difference of the inference performance between the 789 specific to classification but not to categorization.
 Prior studies have analyzed category functions primarily based on classification learning.
 These findings may be more relevant to classification processes than to categorization in general.
 W e suggest that categorization mechanisms such as exemplarbased or prototypebased models need to be reexamined with respect to learning procedures.
 Finally, although this study highlights the complex relationship that exists between category learning and category acquisition, it is far from clear precisely how category learning is related to the mechanisms of category acquisition.
 W e expected that the InferenceandClassification learning condition would yield good performance in both the transfer tasks.
 Contrary to our prediction, the InferenceandClassification condition resulted in moderate levels of performance as compared to other learning conditions.
 In addition, the subjects in the InferenceandClassification condition had the lowest level of learning rate.
 These results may be due to conflicts in the task demands of classification and inference learning.
 Classification, which guides subjects to acquire category labels pertaining to each stimulus, may lead subjects to seek a simple link between an instance and its label.
 Inference, on the other hand, may require encoding relations and correlations between features.
 Conflicts in processing demands may result in poor performance by subjects during both inferencebased and classificationbased learning.
 This question needs to be addressed in future studies in order to illuminate the impact of a multifaceted set of learning tasks on category formation.
 Medin, D.
 L.
, & Smith, E.
 E.
 (1981).
 Strategies and classification learning.
 Journal of Experimental Psychology: Human Learning and Memory, 7, 241253.
 Medin, D.
 L.
, Wattenmaker, W.
 D.
, & Hampson, S.
 E.
 (1987).
 Family resemblance, conceptual cohesiveness, and category construction.
 Cognitive Psychology, 19, 242279.
 Murphy, G.
 L.
, & Medin, D.
 L.
 (1985).
 The roles of theories in conceptual coherence.
 Psychological review.
 Vol.
92.
 289 316.
 Murphy, G.
 L.
, & Ross, B.
 H.
 (1994).
 Predictions from uncertain categorizations, Cognitive Psychology, 27, 148193.
 Rosch, E.
, Mervis, C.
 B.
, Gray, W.
 B.
, Johnson, D.
 M.
, & BoyesBraem, P.
 (1976).
 Basic Objects in Natural Categories.
 Cognitive Psychology, 8̂  382439.
 Acknowledgments We wish to acknowledge the support of Dendre Gentner, Trisha Lindemann, Valerie Makin, Douglas Medin, and YungCheng Shen, who gave us valuable comments and suggestions.
 References Anderson, J.
 R.
 (1990).
 The Adaptive Character of Thought Lawrence Erlbaum Associates, Hillsdale, New Jersey 1990.
 Elio, R.
, & Anderson, J.
 R.
 (1984).
 The effects of information order and learning mode on schema abstraction.
 Memory & Cognition, 12, 2030.
 Estes, W.
 K.
 (1994).
 Classification and Cognition.
 Oxford University Press, New York 1994.
 Heit, E.
 (1992).
 Categorization using chains of examples.
 Cognitive Psychology, 24, 341380.
 Holland, J.
 J.
, Holyoak, K.
 J.
, Nisbett, R.
 E.
, & Thagard, P.
 R.
 (1986).
 Induction: Processes of inference, learning and discovery.
 Cambridge MA: MIT Press.
 Medin, D.
 L.
, & Schaffer, M.
 M.
 (1978).
 Context theory of classification.
 Psychological Review, 85 (3), 207238.
 790 T h e Integration of internal and External Information in Numerical Tasks Jiajie Zhang & Hongbin Wang Department of Psychology & Center for Cognitive Science The Ohio State University 1827 Neil Avenue Columbus, OH 43210 Zhang.
52@osu.
edu wang.
190@osu.
edu Abstract Numerical tasks with Arabic numerals involve the integration of internal and external information and the interaction between perception and cognition.
 2digit number comparison task was selected to study these integration and interaction processes.
 To compare the magnitudes of two 2digit Arabic numerals, we can (1) compare them digitbydigit sequentially, (2) compare corresponding digits in parallel, or (3) encode them as an integrated representation and compare the whole numerical values.
 Previous studies showed that 2digit comparison was holistic when target numerals were compared with a standard held in memory.
 In our experiment target numerals and standards were presented on the same external display at the same time.
 Instead of a holistic comparison, we found that 2digit comparison was a combination of sequential and parallel comparisons.
 The implications of this discrepancy were discussed in terms of the interplay between perception and cognition.
 Although different types of numerals (e.
g.
, Arabic, Roman, Greek, etc.
) all represent the same abstract quanUties— numbers, they can produce dramatically different cognitive behaviors in numerical tasks (e.
g.
, Nickerson, 1988; Zhang & Norman, in press).
 This representational effect, caused by different representations of a conmion structure, can be easily observed by comparing the difficulties and processes of two multiplication tasks: 735 x 278 (Arabic numerals) and D C C X X X V x C C L X X V I I l (Roman numerals, equivalent to 735 x 278).
 In addition, to perform numerical tasks, people usually need to process information distributed across the internal mind and the external environment in an interactive manner (Zhang & Norman, 1994, in press).
 For example, to do 735 x 278 with paper and pencil, w e need to process not just the information in internal representations (e.
g.
, the value of each individual symbol, the addition and multiplication tables, arithmetic procedures, etc.
) but also the information in external representations (e.
g.
, the visual and spatial properties of the symbols, the spatial relations of the partial products, etc.
).
 In this paper, w e use a simple numerical task, number comparison, to examine h o w internal and external information is processed and integrated in numerical tasks and what effects such interactions and integrations have on behavior.
 N u m b e r Comparison The time to compare the magnitudes (larger or smaller) of two 1digit Arabic numerals decreases with the numerical distance between them (Moyer & Landauer, 1967).
 For example, it is faster to compare 1 and 9 than 8 and 9.
 This distance effect resembles that found for physical stimuli such as dot patterns and line lengths, implying that Arabic digits might have an internal representation analogous to a physical continuum.
 Multidigit Arabic numerals have two dimensions: a base dimension represented by the shapes of the ten digits (0, 1, .
.
.
.
 9) and a power dimension represented by positions of the digits (Zhang & Norman, in press).
 The base dimension is an internal representation because the numerical value of each digit has to be memorized, whereas the power dimension is an external representation because the position of a digit can be perceptually inspected.
 Unlike 1digit comparison, which is solely internal, multidigit comparison is based on both internal information (the values of individual digits) and external information (positions of digits).
 Thus, multidigit comparison is a good task for the study of the integration of internal and external information and the interaction between perceptual and cognitive processes.
 To compare the magnitudes of multidigit Arabic numerals, w e can (1) compare them digit by digit sequentially, (2) compare corresponding digits in parallel, or (3) encode them as an integrated representation and compare the whole numerical values.
 In the first case (sequential comparison), only the highest digits should affect the comparison unless they are not sufficient for making decisions.
 In the second case (parallel comparison), lower digits may facilitate or interfere with the comparison of higher digits.
 In the third case (holistic comparison), only the absolute numerical distances should matter.
 Empirical studies have revealed a discrepancy between 2digit comparison and higher multidigit (3 or more) comparison: 2digit comparison is holistic (Dehaene, Dupoux, & Mehler, 1990; Hinrichs, Yurko, & Hu, 1981) whereas higher multidigit comparison is sequential (Hinrichs, Berie, & Mosell, 1982; Poltrock & Schwarte, 1984).
 The holistic comparison of 2digit Arabic numerals was often cited as evidence of a holistic analog internal representation of Arabic numerals.
 This paper addresses two specific issues: (1) whether 2791 mailto:Zhang.
52@osu.
edumailto:wang.
190@osu.
edudigit comparison is indeed holistic and (2) how internal and external information is processed and integrated in 2digit comparison tasks.
 Experiment In the experiments reported by Dehaene et al.
 (1990) and Hinrichs et al.
 (1981), a standard (e.
g.
, 55) was always held in memory and only the target numerals (e.
g.
, 11 to 99 except 55) were presented on an external display and judged whether smaller or larger than the standard.
 In this case, one of the two numerals to be compared (the standard) was already preprocessed.
 In our experiment we made three procedural changes.
 First, the standard and targets were presented simultaneously on an external display such that both numerals had to be processed at the same time.
 Second, instead of one standard, we used two standards (55 and 65) as a withinsubject factor to prevent subjects from preprocessing a specific standard.
 Third, instead of reporting whether a target is smaller or larger than the standard, subjects only decide which of the two presented numerals is larger.
 Such procedural changes are important for the testing of our hypothesis: when both numerals are presented externally, the comparison is based on not just internal but also external information, the concurrent processing of which can generate a different pattern of behavior.
 In order to identify which of the three comparison models can best account for 2digit comparison under our experimental conditions, we need three observations.
 First, if there are reaction time (RT) differences across decades but not within a decade and there are discontinuities across decade boundaries, then sequential comparison is supported.
 Second, if the whole numerical value resulting from the integration of the decade and unit digits is the only determinant of RT, then holistic comparison is most likely.
 Third, if unit digits show a Strooplike congruity effect on RT, then parallel comparison is evident.
 One difficulty with the observation of a congruity effect is that the values of unit digits and the absolute distances from the standard are always confounded.
 For example, a shorter R T to compare 31 and 65 than 39 and 65 can be either due to the facilitation of the 1 in 31 and the interference of the 9 in 39 or the longer distance between 31 and 65 than between 39 and 65 or both.
 However, if we can observe a reverse distance effect across different decades, then we can still single out a congruity effect.
 For example, the RTs for 3639 might be longer than those for 4144 even if 3639 are farther away from 65 than 4144 are.
 Method Subjects.
 The subjects were 32 undergraduate students in introductory psychology courses at The Ohio State University, who participated in the experiment to earn course credit.
 Design and procedure.
 The subjects were seated in about 40 cm from a Macintosh computer in a dark room.
 They were told that two Arabic numerals would appear on the screen simultaneously, one on the left and one on the right side of a fixation point.
 They were asked to press the left key ('z') or the right key ('m') as quickly and accurately as possible depending on whether the numeral on the left or the one on the right side is larger.
 The Macintosh computers (Quadra 700 and Centris 610) used to control the experiment could measure reaction times with a resolution of ±1 ms.
 Each pair of numerals were presented for 2 s, preceded by a fixation point (a '+' sign) of 500 ms and followed by a blank screen of 2 s.
 The 2digit Arabic numerals were in 24 point bold N e w York font (approximately 1.
0 by 0.
65 cm for each digit) and with an equal distance of 0.
95 cm from the fixation point.
 Arabic numerals 11 to 99 (target numerals) except 55 were compared with 55 and 31 to 99 (target numerals) except 65 were compared with 65.
 The standards were presented on the left side for half of the trials and on the right side for the other half, producing a total of 312 uials.
 These 312 trials were randomized for each experimental session and divided into four blocks with 78 trials for each block.
 Each subject was presented 10 randomly generated pairs of 2digit numerals for practice followed by the four blocks of trials with one minute rest between blocks.
 Results For all analyses that follow, trials with a standard on the left side were pooled with the corresponding trials with the same standard on the right side.
 Trials with errors were excluded from the analysis of reaction times (RTs).
 For standard 65, the average error rate was 2.
7%, ranging from 1.
5% in the 30s and 90s to 5.
6% in the 60s.
 For standard 55, the average error rate was 2.
0%, ranging from 0.
64% in the 10s and 90s to 4.
2% in the 50s.
 RTs deviated from the mean for each target by more than three standard deviations were excluded from analyses.
 Separate analyses were conducted for 65 and 55.
 Standard 65.
 The average RTs to compare target numerals with 65 are shown in Figure 1.
 An analysis of the effect of the numerical distances between targets and 65 and the ranges of the targets (smaller or larger than 65) showed a significant distance effect (F(33, 693) = 16.
99, p < 0.
001), a significant range effect (F(l, 21) = 8.
40, p < 0.
009), and a significant interaction (F(33, 693) = 4.
86, p < 0.
001).
 Due to the asymmetrical range effect and the significant interaction between distance and range, we conducted separate analyses on RTs for targets smaller than 65 and those larger than 65.
 Decade and unit effects.
 For targets 3159, the decade effect between 40s and 50s was significant (F(l, 25) =77.
93, p < 0.
(X)1) but that between 30s and 40s was not significant (F(l, 27) = 0.
94, p = 0.
34).
 For each of the decades of 30s, 40s, and 50s, the unit effect was significant (smallest F(8, 216) = 3.
91, p < 0.
001).
 For targets 7199, the decade effect between 70s and 80s and that between 80s and 90s were both significant (smallest F(l, 25) = 14.
02, p < 0.
001) None of the decades of 70s, 80s, and 90s had a significant unit effect (largest F(8, 232) = 1.
29, p = 0.
25).
 The unit effect was further analyzed by linear regression.
 The R T for each target in a decade was subtracted by the mean R T of the corresponding decade, then averaged aaoss 792 30s, 40s, & 50s and across 70s.
 80s, & 90s (see Figure 3A).
 The unit effect was asymmetrical.
 For targets smaller than 65, the units had a strong effect with a slope of 13.
7, which was significantly different than zero (r̂  = 0.
71.
 p < 0.
005).
 However, for targets larger than 65, the units had no significant effect: the slope (0.
66) was not significantly different than zero (r^ = 0.
024, p > 0.
69).
 Separate regression analysis for each decade showed significant unit effect for decades 30s, 40s, and 50s (largest p < 0.
01) but not for decades 70s, 80s, and 90s (smallest p = 0.
25).
 Discontinuity.
 If there is a discontinuity at the boundary of two decades, there should be a sharp change in RT.
 The change in R T across a decade boundary (e.
g.
, RT69  RT70) was compared with the averaged change in R T between adjacent numbers within each of the two adjacent decades (e.
g.
, [(RT68  RT69) + (RT70  RT71)]/2).
 An analysis of variance showed significant discontinuity effects between 30s and 40s, 50s and 60s, 60s and 70s, 70s and 80s, and 80s and 90s (smallest F(l, 30) = 4.
76, p < 0.
05).
 The effect between 40s and 50s was not significant (F(l, 30) = 0.
32, p = 0.
57).
 c 70060030 35 40 45 50 55 60 Figure 1.
 Reaction times for targets compared with 65.
 900I 8001 g 7001 60015 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 Figure 2.
 Reaction times for targets compared with 55.
 793 3050 7090 3 4 5 6 7 (A) Standard 65 1040 6090 3 4 5 6 (B) Standard 55 Figure 3.
 Unit effect for standards 65 and 55.
 The R T for each target in a decade was subtracted by the mean R T of the corresponding decade, then averaged across decades 30s, 40s, and 50s and across 70s, 80s, and 90s for standard 65 and averaged across 10s, 20s, 30s, and 40s and across 60s, 70s, 80s, and 90s for standard 55.
 Congruity Effect.
 For targets smaller than 65, the RTs for targets with units 14 were faster than those with units 69 for decade 30s, 40s, and 50s (smallest F(l, 29) = 23.
82, p < 0.
001), which was consistent with both a congruity effect and a distance effect.
 Most importantly, there was a reverse distance effect across the boundary between 30s and 40s: RTs for 3639 were slower than those for 4144 (F(l, 9) = 20.
80, p < 0.
001)—clear evidence for congruity effect For targets larger than 65, there was neither a congruity effect nor a distance effect within a decade (largest F(l, 29) = 0.
74, p = 0.
40), and there was no reverse distance effect across decade boundaries.
 Standard 55.
 The average RTs to compare target numbers with 55 are shown in Figure 2.
 There was a marginal asymmetrical range (smaller or larger than 55) effect (F(l, 16) = 3.
84, p = 0.
07) and a significant distance effect (F(43, 688) = 15.
23, p < 0.
001).
 The interaction between range and distance was also significant (F(43, 688) = 2.
25, p < 0.
001).
 Separate analyses were conducted for targets smaller than 55 and those larger than 55.
 Decade and Unit Effects.
 For targets 1149, the decade effect was significant between 10s and 20s and between 20s and 30s (smallest F(l, 25) = 22.
34, p < 0.
001), but not between 30s and 40s (F(l, 26) = 2.
38, p = 0.
13).
 For decades 10s, 20s, 30s, and 40s, the unit effect was all significant (smallest F(8, 224) = 2.
27, p < 0.
02).
 For targets 6199, the decade effect was significant between 60s and 70s and between 70s and 80s (smallest F(l, 22) = 27.
66, p < 0.
001), but not between 80s and 90s (F(l, 24) = 0.
50, p = 0.
49).
 The unit effect was significant for 60s (F(8, 232) = 2.
32, p = 0.
02) but not for 70s, 80s, and 90s (largest F(8, 208) = 1.
41, p = 0.
19).
 Linear regression analysis showed an asymmetrical unit effect similar to that found for standard 65 (see Figure 3B): the slope for each decade below 55 was significantly different than zero (largest p < 0.
02) whereas that above 55 was not (smallest p = 0.
19).
 Discontinuity.
 The change in R T across a decade boundary (e.
g.
, RT69  RT70) was compared with the averaged change in R T between adjacent numbers within each of the two adjacent decades (e.
g.
, [(RT68  RT69) + (RT70  RT71)]/2).
 There was a significant discontinuity effect between 60s and 70s (F(l, 30) = 6.
75, p < 0.
01) and a marginal effect between 50s and 60s (F(l, 30) = 3.
80, p = 0.
06).
 There was no discontinuity effect at other decade boundaries (largest F(l, 30) = 2.
91, p = 0.
10).
 Congruity Effect.
 For each decade below 55, the RTs for targets with units 14 were larger than those with units 69 (smallest F(l, 28) = 8.
93, p < 0.
006), which was consistent with both a congruity effect and a distance effect.
 Although there was no reverse distance effect across decade boundaries, there was no significant difference between 1619 and 2124 and between 2629 and 3134, implying that there was neither a congruity nor a distance effect, or that there was a congruity effect countering a distance effect.
 For decades above 55, there was neither a congruity nor a distance effect within 70s, 80s, and 90s (smallest F(l, 26) = 0.
85, p = 0.
37) and only a marginal difference between 6164 and 6669 (F(l, 29) = 4.
68, p < 0.
05).
 N o reverse distance effect across decade boundaries was found for decades above 55.
 Discussion and Conclusion The experimental results showed a complex pattern that can not be easily fitted into a single model.
 Both standards 65 and 55 showed an asymmetrical range effect targets smaller and those larger than the standards were compared in different ways.
 For standard 65, targets larger than 65 were compared sequentially, supported by an insignificant unit effect within each decade, a zero slope of linear regression for each decade, a decade effect, and discontinuities aaoss decade boundaries.
 Targets smaller than 65 were compared in parallel, supported by a unit effect within each decacte and 794 a Strooplike congruity effect (reverse distance effect).
 The holistic comparison model can be clearly rejected for the case of standard 65.
 For standard 55, though the results were not as clearly cut as those for standard 65, the trend was simihir.
 Targets larger than 55 seemed to be compared sequentially, supported by an insignificant unit effect within each decade (except 60s, which can be accounted for by an abnormal low RT for 66), a zero slope for each decade, a decade effect between 60s and 70s and between 70s and 80s, and discontinuities at the boundaries between 50s and 60s and between 60s and 70s.
 For targets smaller than 55, a strong unit effect fcM every decade ruled out sequential comparison but was consistent with both holistic and parallel comparison.
 Although no reverse distance effect was found, an insignificant difference between 1619 and 2124 and between 2629 and 3134 but a strong difference between 2124 and 2629 implied a congruity effect countering a distance effect.
 Thus, parallel comparison was more likely than holistic comparison.
 In the experiments by Dehaene et al.
 and Hinrichs et al.
, the standards were always held in memory and only the targets were presented on an external display, whereas in our experiment the standards and targets were presented and compared on the same external display at the same time.
 Although the abstract task was the same for their studies and our studies (i.
e.
, comparing 2digit numerals), the comparison processes were different.
 This is a demonstration of the representational effect in numerical tasks—different representations of a common abstract structure can cause dramatically different behaviors.
 Our experimental results are clearly evidence against the claim that there is a common internal representation for all types of number representations.
 Different representations are not encoded and transformed into an abstract internal representation.
 Rather, they activate representationspecific processes.
 It is these representationspecific processes, not the abstract processes for the abstract representation, that are the actual mechanisms in numerical tasks.
 judgments of numerical inequality.
 Nature, 215, 15191520.
 Nickerson, R.
 (1988).
 Counting, computing, and the representation of numbers.
 Human Factors, 30,181199.
 Poltrock, S.
 E.
 & Schwartz, D.
 R.
 (1984).
 Comparative judgments of multidigit numbers.
 Journal of Experimental Psychology: Learning, Memory, and Cognition, 10, 3245.
 Zhang, J.
 & Norman, D.
 A.
 (1994).
 Representations in distributed cognitive tasks.
 Cognitive Science, 18,87122.
 Zhang, J.
 & Norman, D.
 A.
 (in press).
 A representational analysis of numeration systems.
 To appear in Cognition.
 Acknowledgements This research was supported by a Seed Grant from The Ohio State University.
 W e would like to thank Gwen Hall for his assistance in the experiments.
 References Dehaene, S.
, Dupoux, E.
 & Mehler, J.
 (1990).
 Is numerical comparison digital? Analogical and symbolic effects in twodigit number comparison.
 Journal of Experimental Psychology: Human Perception and Performance, 16, 626641.
 Hinrichs, J.
 V.
, Berie, J.
 L.
 & MoseU, M.
 K.
 (1982).
 Place information in multidigit number comparison.
 Memory and Cognition, 10,487495.
 Hinrichs, J.
 V.
, Yurko, D.
 S.
 & Hu, J.
 M.
 (1981).
 Twodigit number comparison: Use of place information.
 Journal of Experimental Psychology: Human Perception and Performance, 7, 890901.
 Moyer, R.
 S.
 & Landauer, T.
 K.
 (1967).
 Time required for 795 